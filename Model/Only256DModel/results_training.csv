cuda:0
time: 9.912778377532959
time: 2.3335232734680176
[1, 1] loss_train: 0.058636, loss_test: 0.070040
time: 0.271059513092041
time: 2.241501569747925
[1, 2] loss_train: 0.075775, loss_test: 0.069124
time: 0.24605464935302734
time: 2.2605056762695312
[1, 3] loss_train: 0.078558, loss_test: 0.068124
time: 0.2510550022125244
time: 2.2455050945281982
[1, 4] loss_train: 0.071333, loss_test: 0.067182
time: 0.25005531311035156
time: 2.36953067779541
[1, 5] loss_train: 0.065754, loss_test: 0.066142
time: 0.25305962562561035
time: 2.2515149116516113
[1, 6] loss_train: 0.063427, loss_test: 0.065078
time: 0.2620577812194824
time: 2.2985148429870605
[1, 7] loss_train: 0.073190, loss_test: 0.063893
time: 0.2450544834136963
time: 2.2575056552886963
[1, 8] loss_train: 0.070885, loss_test: 0.062643
time: 0.2630579471588135
time: 2.2575056552886963
[1, 9] loss_train: 0.065802, loss_test: 0.061247
time: 0.24805474281311035
time: 2.2365007400512695
[1, 10] loss_train: 0.067800, loss_test: 0.059750
time: 0.30606842041015625
time: 2.2940351963043213
[1, 11] loss_train: 0.055466, loss_test: 0.058103
time: 0.24605441093444824
time: 2.267509937286377
[1, 12] loss_train: 0.052761, loss_test: 0.056321
time: 0.24405360221862793
time: 2.2824459075927734
[1, 13] loss_train: 0.063184, loss_test: 0.054384
time: 0.25005531311035156
time: 2.310516357421875
[1, 14] loss_train: 0.047945, loss_test: 0.052265
time: 0.24305415153503418
time: 2.294018030166626
[1, 15] loss_train: 0.055044, loss_test: 0.049967
time: 0.2670598030090332
time: 2.3145172595977783
[1, 16] loss_train: 0.047468, loss_test: 0.047529
time: 0.26105713844299316
time: 2.24800705909729
[1, 17] loss_train: 0.043408, loss_test: 0.044949
time: 0.24305343627929688
time: 2.2725090980529785
[1, 18] loss_train: 0.047995, loss_test: 0.042283
time: 0.25005578994750977
time: 2.2655091285705566
[1, 19] loss_train: 0.036235, loss_test: 0.039488
time: 0.24805569648742676
time: 2.3275198936462402
[1, 20] loss_train: 0.047656, loss_test: 0.036620
time: 0.25505733489990234
time: 2.2555043697357178
[1, 21] loss_train: 0.046131, loss_test: 0.033707
time: 0.24205422401428223
time: 2.2935283184051514
[1, 22] loss_train: 0.042125, loss_test: 0.030782
time: 0.24509692192077637
time: 2.2234978675842285
[1, 23] loss_train: 0.030354, loss_test: 0.027897
time: 0.24205327033996582
time: 2.2755093574523926
[1, 24] loss_train: 0.022834, loss_test: 0.025118
time: 0.24205422401428223
time: 2.24650239944458
[1, 25] loss_train: 0.020886, loss_test: 0.022516
time: 0.2450542449951172
time: 2.2615065574645996
[1, 26] loss_train: 0.026758, loss_test: 0.020085
time: 0.24605417251586914
time: 2.31951904296875
[1, 27] loss_train: 0.022788, loss_test: 0.017878
time: 0.25005483627319336
time: 2.3525264263153076
[1, 28] loss_train: 0.021099, loss_test: 0.015942
time: 0.25005531311035156
time: 2.3155176639556885
[1, 29] loss_train: 0.021701, loss_test: 0.014236
time: 0.2490556240081787
time: 2.2755091190338135
[1, 30] loss_train: 0.016235, loss_test: 0.012777
time: 0.2670598030090332
time: 2.257504463195801
[1, 31] loss_train: 0.015487, loss_test: 0.011566
time: 0.24605417251586914
time: 2.2845115661621094
[1, 32] loss_train: 0.017370, loss_test: 0.010570
time: 0.24805450439453125
time: 2.242504596710205
[1, 33] loss_train: 0.008766, loss_test: 0.009808
time: 0.2510550022125244
time: 2.2475032806396484
[1, 34] loss_train: 0.010032, loss_test: 0.009240
time: 0.2510545253753662
time: 2.291513442993164
[1, 35] loss_train: 0.018423, loss_test: 0.008872
time: 0.2540552616119385
time: 2.256507158279419
[1, 36] loss_train: 0.012413, loss_test: 0.008585
time: 0.24505376815795898
time: 2.2505035400390625
[1, 37] loss_train: 0.026034, loss_test: 0.008384
time: 0.26405858993530273
time: 2.2595059871673584
[1, 38] loss_train: 0.006650, loss_test: 0.008235
time: 0.2470552921295166
time: 2.3045153617858887
[1, 39] loss_train: 0.013423, loss_test: 0.008131
time: 0.25505661964416504
time: 2.3035151958465576
[1, 40] loss_train: 0.027116, loss_test: 0.008060
time: 0.2580564022064209
time: 2.243502616882324
[1, 41] loss_train: 0.018053, loss_test: 0.008010
time: 0.2439110279083252
time: 2.2845141887664795
[1, 42] loss_train: 0.005420, loss_test: 0.007984
time: 0.24605393409729004
time: 2.2680108547210693
[1, 43] loss_train: 0.019265, loss_test: 0.007962
time: 0.2490551471710205
time: 2.2640161514282227
[1, 44] loss_train: 0.012675, loss_test: 0.007946
time: 0.24605274200439453
time: 2.2710113525390625
[1, 45] loss_train: 0.017359, loss_test: 0.007912
time: 0.24105334281921387
time: 2.223497152328491
[1, 46] loss_train: 0.007941, loss_test: 0.007863
time: 0.26606059074401855
time: 2.355476140975952
[1, 47] loss_train: 0.012725, loss_test: 0.007830
time: 0.2710604667663574
time: 2.346534252166748
[1, 48] loss_train: 0.002319, loss_test: 0.007795
time: 0.2490553855895996
time: 2.2396390438079834
[1, 49] loss_train: 0.005165, loss_test: 0.007764
time: 0.24805402755737305
time: 2.304515838623047
[1, 50] loss_train: 0.006180, loss_test: 0.007733
time: 0.29006505012512207
time: 2.309999465942383
[1, 51] loss_train: 0.006616, loss_test: 0.007716
time: 0.2520573139190674
time: 2.255505084991455
[1, 52] loss_train: 0.007303, loss_test: 0.007677
time: 0.24405646324157715
time: 2.2905125617980957
[1, 53] loss_train: 0.008829, loss_test: 0.007641
time: 0.24305462837219238
time: 2.269507646560669
[1, 54] loss_train: 0.008678, loss_test: 0.007614
time: 0.24805474281311035
time: 2.28251314163208
[1, 55] loss_train: 0.012598, loss_test: 0.007597
time: 0.2470543384552002
time: 2.2935147285461426
[1, 56] loss_train: 0.008103, loss_test: 0.007586
time: 0.2450542449951172
time: 2.2815098762512207
[1, 57] loss_train: 0.005082, loss_test: 0.007577
time: 0.24605464935302734
time: 2.3130223751068115
[1, 58] loss_train: 0.010483, loss_test: 0.007569
time: 0.24605488777160645
time: 2.2307376861572266
[1, 59] loss_train: 0.006922, loss_test: 0.007558
time: 0.24305319786071777
time: 2.2605104446411133
[1, 60] loss_train: 0.017187, loss_test: 0.007553
time: 0.2600572109222412
time: 2.254504680633545
[1, 61] loss_train: 0.012612, loss_test: 0.007552
time: 0.2450542449951172
time: 2.3025166988372803
[1, 62] loss_train: 0.008736, loss_test: 0.007554
time: 0.2470560073852539
time: 2.309525489807129
[1, 63] loss_train: 0.008933, loss_test: 0.007555
time: 0.2540571689605713
time: 2.2900171279907227
[1, 64] loss_train: 0.010265, loss_test: 0.007557
time: 0.24605369567871094
time: 2.2805111408233643
[1, 65] loss_train: 0.015725, loss_test: 0.007562
time: 0.2600574493408203
time: 2.351548433303833
[1, 66] loss_train: 0.007573, loss_test: 0.007568
time: 0.24605417251586914
time: 2.279510498046875
[1, 67] loss_train: 0.009295, loss_test: 0.007577
time: 0.24805545806884766
time: 2.292020797729492
[1, 68] loss_train: 0.010114, loss_test: 0.007582
time: 0.25005578994750977
time: 2.298513650894165
[1, 69] loss_train: 0.010651, loss_test: 0.007595
time: 0.25005531311035156
time: 2.317518949508667
[1, 70] loss_train: 0.011531, loss_test: 0.007603
time: 0.3520781993865967
time: 2.3515396118164062
[1, 71] loss_train: 0.014583, loss_test: 0.007607
time: 0.2650575637817383
time: 2.323519706726074
[1, 72] loss_train: 0.007639, loss_test: 0.007594
time: 0.2720606327056885
time: 2.357527732849121
[1, 73] loss_train: 0.011237, loss_test: 0.007589
time: 0.25905704498291016
time: 2.363528251647949
[1, 74] loss_train: 0.006314, loss_test: 0.007583
time: 0.2780632972717285
time: 2.4315428733825684
[1, 75] loss_train: 0.014823, loss_test: 0.007581
time: 0.27306079864501953
time: 2.48455548286438
[1, 76] loss_train: 0.007113, loss_test: 0.007569
time: 0.2510557174682617
time: 2.3045151233673096
[1, 77] loss_train: 0.008586, loss_test: 0.007567
time: 0.2490551471710205
time: 2.320518970489502
[1, 78] loss_train: 0.011822, loss_test: 0.007575
time: 0.2470548152923584
time: 2.313518524169922
[1, 79] loss_train: 0.005215, loss_test: 0.007571
time: 0.25005459785461426
time: 2.309516191482544
[1, 80] loss_train: 0.010638, loss_test: 0.007567
time: 0.2670590877532959
time: 2.2890164852142334
[1, 81] loss_train: 0.013633, loss_test: 0.007565
time: 0.25305652618408203
time: 2.2275002002716064
[1, 82] loss_train: 0.009620, loss_test: 0.007563
time: 0.25206923484802246
time: 2.244577169418335
[1, 83] loss_train: 0.010540, loss_test: 0.007563
time: 0.24605393409729004
time: 2.3115265369415283
[1, 84] loss_train: 0.010148, loss_test: 0.007567
time: 0.24407410621643066
time: 2.2775115966796875
[1, 85] loss_train: 0.013283, loss_test: 0.007581
time: 0.24505400657653809
time: 2.2375009059906006
[1, 86] loss_train: 0.010012, loss_test: 0.007582
time: 0.2630589008331299
time: 2.293513536453247
[1, 87] loss_train: 0.007546, loss_test: 0.007587
time: 0.2510559558868408
time: 2.2755086421966553
[1, 88] loss_train: 0.004956, loss_test: 0.007585
time: 0.2450544834136963
time: 2.29447078704834
[1, 89] loss_train: 0.008450, loss_test: 0.007575
time: 0.2470548152923584
time: 2.323519468307495
[1, 90] loss_train: 0.011548, loss_test: 0.007583
time: 0.2730598449707031
time: 2.3745315074920654
[1, 91] loss_train: 0.011503, loss_test: 0.007589
time: 0.25305604934692383
time: 2.386533737182617
[1, 92] loss_train: 0.006700, loss_test: 0.007590
time: 0.2670588493347168
time: 2.3625283241271973
[1, 93] loss_train: 0.007421, loss_test: 0.007567
time: 0.3070681095123291
time: 2.331521987915039
[1, 94] loss_train: 0.005071, loss_test: 0.007529
time: 0.26605868339538574
time: 2.2925126552581787
[1, 95] loss_train: 0.007164, loss_test: 0.007494
time: 0.26105809211730957
time: 2.3475253582000732
[1, 96] loss_train: 0.015142, loss_test: 0.007469
time: 0.27906179428100586
time: 2.3755311965942383
[1, 97] loss_train: 0.007295, loss_test: 0.007440
time: 0.25905656814575195
time: 2.3555264472961426
[1, 98] loss_train: 0.010247, loss_test: 0.007413
time: 0.2540566921234131
time: 2.297513723373413
[1, 99] loss_train: 0.012058, loss_test: 0.007392
time: 0.25305700302124023
time: 2.2785093784332275
[1, 100] loss_train: 0.009010, loss_test: 0.007377
time: 0.2630586624145508
time: 2.2895121574401855
[1, 101] loss_train: 0.009808, loss_test: 0.007365
time: 0.25905704498291016
time: 2.2925126552581787
[1, 102] loss_train: 0.008053, loss_test: 0.007357
time: 0.24305391311645508
time: 2.257505178451538
[1, 103] loss_train: 0.008731, loss_test: 0.007347
time: 0.25305628776550293
time: 2.5035600662231445
[1, 104] loss_train: 0.011432, loss_test: 0.007338
time: 0.2540559768676758
time: 2.3255228996276855
[1, 105] loss_train: 0.004954, loss_test: 0.007331
time: 0.24605488777160645
time: 2.321518898010254
[1, 106] loss_train: 0.005338, loss_test: 0.007319
time: 0.24305415153503418
time: 2.2665069103240967
[1, 107] loss_train: 0.007807, loss_test: 0.007312
time: 0.2490546703338623
time: 2.5115602016448975
[1, 108] loss_train: 0.008541, loss_test: 0.007307
time: 0.331073522567749
time: 2.7096054553985596
[1, 109] loss_train: 0.007429, loss_test: 0.007305
time: 0.3540792465209961
time: 2.470552682876587
[1, 110] loss_train: 0.009116, loss_test: 0.007304
time: 0.34207582473754883
time: 2.471552610397339
[1, 111] loss_train: 0.008214, loss_test: 0.007299
time: 0.35307812690734863
time: 2.254504680633545
[1, 112] loss_train: 0.010735, loss_test: 0.007295
time: 0.2560570240020752
time: 2.3425240516662598
[1, 113] loss_train: 0.005638, loss_test: 0.007291
time: 0.2780618667602539
time: 2.4965744018554688
[1, 114] loss_train: 0.012866, loss_test: 0.007291
time: 0.35007572174072266
time: 2.307515859603882
[1, 115] loss_train: 0.006422, loss_test: 0.007286
time: 0.25505709648132324
time: 2.315524101257324
[1, 116] loss_train: 0.005078, loss_test: 0.007283
time: 0.2520558834075928
time: 2.245504856109619
[1, 117] loss_train: 0.007450, loss_test: 0.007279
time: 0.24105358123779297
time: 2.511564016342163
[1, 118] loss_train: 0.005655, loss_test: 0.007276
time: 0.25705647468566895
time: 2.2314999103546143
[1, 119] loss_train: 0.007650, loss_test: 0.007277
time: 0.3030674457550049
time: 2.319526433944702
[1, 120] loss_train: 0.007639, loss_test: 0.007281
time: 0.25705695152282715
time: 2.2905211448669434
[1, 121] loss_train: 0.004370, loss_test: 0.007287
time: 0.24405336380004883
time: 2.2845141887664795
[1, 122] loss_train: 0.016346, loss_test: 0.007285
time: 0.24605393409729004
time: 2.275944948196411
[1, 123] loss_train: 0.005263, loss_test: 0.007286
time: 0.24302124977111816
time: 2.2959675788879395
[1, 124] loss_train: 0.009101, loss_test: 0.007285
time: 0.24305367469787598
time: 2.2785096168518066
[1, 125] loss_train: 0.019869, loss_test: 0.007275
time: 0.24205350875854492
time: 2.25400972366333
[1, 126] loss_train: 0.005871, loss_test: 0.007269
time: 0.24406647682189941
time: 2.2104945182800293
[1, 127] loss_train: 0.008529, loss_test: 0.007266
time: 0.24805569648742676
time: 2.222496509552002
[1, 128] loss_train: 0.008746, loss_test: 0.007265
time: 0.24305343627929688
time: 2.2818386554718018
[1, 129] loss_train: 0.007854, loss_test: 0.007263
time: 0.24405384063720703
time: 2.2760541439056396
[1, 130] loss_train: 0.016162, loss_test: 0.007267
time: 0.25305628776550293
time: 2.2372243404388428
[1, 131] loss_train: 0.003417, loss_test: 0.007271
time: 0.2548811435699463
time: 2.3120856285095215
[1, 132] loss_train: 0.017836, loss_test: 0.007290
time: 0.24504351615905762
time: 2.2565665245056152
[1, 133] loss_train: 0.008897, loss_test: 0.007313
time: 0.2630589008331299
time: 2.290512800216675
[1, 134] loss_train: 0.005535, loss_test: 0.007324
time: 0.2650587558746338
time: 2.259505271911621
[1, 135] loss_train: 0.017614, loss_test: 0.007349
time: 0.24010801315307617
time: 2.3050196170806885
[1, 136] loss_train: 0.023018, loss_test: 0.007418
time: 0.24205422401428223
time: 2.2445013523101807
[1, 137] loss_train: 0.011623, loss_test: 0.007501
time: 0.2490556240081787
time: 2.2525038719177246
[1, 138] loss_train: 0.006658, loss_test: 0.007584
time: 0.25505638122558594
time: 2.2526512145996094
[1, 139] loss_train: 0.006070, loss_test: 0.007652
time: 0.24805450439453125
time: 2.2322628498077393
[1, 140] loss_train: 0.004410, loss_test: 0.007693
time: 0.26205897331237793
time: 2.2930171489715576
[1, 141] loss_train: 0.011993, loss_test: 0.007721
time: 0.2450544834136963
time: 2.2545042037963867
[1, 142] loss_train: 0.012121, loss_test: 0.007728
time: 0.24405455589294434
time: 2.259080171585083
[1, 143] loss_train: 0.005266, loss_test: 0.007721
time: 0.24605417251586914
time: 2.268507719039917
[1, 144] loss_train: 0.006509, loss_test: 0.007669
time: 0.24406790733337402
time: 2.32551908493042
[1, 145] loss_train: 0.014830, loss_test: 0.007638
time: 0.2470550537109375
time: 2.2335023880004883
[1, 146] loss_train: 0.007585, loss_test: 0.007617
time: 0.25305604934692383
time: 2.2520594596862793
[1, 147] loss_train: 0.011378, loss_test: 0.007587
time: 0.25005650520324707
time: 2.3105480670928955
[1, 148] loss_train: 0.003544, loss_test: 0.007533
time: 0.24305367469787598
time: 2.310533285140991
[1, 149] loss_train: 0.010192, loss_test: 0.007468
time: 0.24105429649353027
time: 2.2024927139282227
[1, 150] loss_train: 0.006693, loss_test: 0.007409
time: 0.26805877685546875
time: 2.2885124683380127
[1, 151] loss_train: 0.007422, loss_test: 0.007369
time: 0.2560567855834961
time: 2.256505012512207
[1, 152] loss_train: 0.006021, loss_test: 0.007337
time: 0.2540566921234131
time: 2.275508403778076
[1, 153] loss_train: 0.015971, loss_test: 0.007326
time: 0.2470545768737793
time: 2.2335002422332764
[1, 154] loss_train: 0.007054, loss_test: 0.007312
time: 0.24305415153503418
time: 2.2625060081481934
[1, 155] loss_train: 0.013206, loss_test: 0.007309
time: 0.24305319786071777
time: 2.242502212524414
[1, 156] loss_train: 0.011579, loss_test: 0.007307
time: 0.24505400657653809
time: 2.303515672683716
[1, 157] loss_train: 0.010425, loss_test: 0.007297
time: 0.2470545768737793
time: 2.3235201835632324
[1, 158] loss_train: 0.007556, loss_test: 0.007292
time: 0.2470541000366211
time: 2.2835118770599365
[1, 159] loss_train: 0.015628, loss_test: 0.007301
time: 0.24605369567871094
time: 2.270508289337158
[1, 160] loss_train: 0.003254, loss_test: 0.007294
time: 0.2780606746673584
time: 2.328521728515625
[1, 161] loss_train: 0.011618, loss_test: 0.007295
time: 0.25905728340148926
time: 2.2675068378448486
[1, 162] loss_train: 0.003515, loss_test: 0.007291
time: 0.24605441093444824
time: 2.271507740020752
[1, 163] loss_train: 0.006659, loss_test: 0.007282
time: 0.2600588798522949
time: 2.283512592315674
[1, 164] loss_train: 0.009070, loss_test: 0.007265
time: 0.2670578956604004
time: 2.3048791885375977
[1, 165] loss_train: 0.005435, loss_test: 0.007252
time: 0.2470543384552002
time: 2.2785112857818604
[1, 166] loss_train: 0.009086, loss_test: 0.007237
time: 0.2470543384552002
time: 2.3125176429748535
[1, 167] loss_train: 0.009845, loss_test: 0.007226
time: 0.24605417251586914
time: 2.25150465965271
[1, 168] loss_train: 0.003779, loss_test: 0.007218
time: 0.24405384063720703
time: 2.3265202045440674
[1, 169] loss_train: 0.005518, loss_test: 0.007201
time: 0.2560584545135498
time: 2.4275407791137695
[1, 170] loss_train: 0.008275, loss_test: 0.007191
time: 0.26405930519104004
time: 2.332521677017212
[1, 171] loss_train: 0.004049, loss_test: 0.007184
time: 0.26605868339538574
time: 2.293513298034668
[1, 172] loss_train: 0.008566, loss_test: 0.007175
time: 0.24805450439453125
time: 2.299516439437866
[1, 173] loss_train: 0.007045, loss_test: 0.007162
time: 0.26806092262268066
time: 2.321519136428833
[1, 174] loss_train: 0.004860, loss_test: 0.007148
time: 0.2450544834136963
time: 2.2683300971984863
[1, 175] loss_train: 0.007021, loss_test: 0.007140
time: 0.25105762481689453
time: 2.252504348754883
[1, 176] loss_train: 0.007594, loss_test: 0.007138
time: 0.24605464935302734
time: 2.297456979751587
[1, 177] loss_train: 0.012596, loss_test: 0.007137
time: 0.24305343627929688
time: 2.2520089149475098
[1, 178] loss_train: 0.008337, loss_test: 0.007136
time: 0.24805474281311035
time: 2.2304985523223877
[1, 179] loss_train: 0.007531, loss_test: 0.007135
time: 0.2490553855895996
time: 2.2585055828094482
[1, 180] loss_train: 0.004514, loss_test: 0.007135
time: 0.25505733489990234
time: 2.2775089740753174
[1, 181] loss_train: 0.003595, loss_test: 0.007137
time: 0.2450542449951172
time: 2.3095169067382812
[1, 182] loss_train: 0.019207, loss_test: 0.007133
time: 0.25705695152282715
time: 2.4715521335601807
[1, 183] loss_train: 0.011191, loss_test: 0.007131
time: 0.25305676460266113
time: 2.296513319015503
[1, 184] loss_train: 0.005745, loss_test: 0.007135
time: 0.2600574493408203
time: 2.2970175743103027
[1, 185] loss_train: 0.008102, loss_test: 0.007141
time: 0.2510552406311035
time: 2.277509927749634
[1, 186] loss_train: 0.004928, loss_test: 0.007143
time: 0.24505376815795898
time: 2.219496726989746
[1, 187] loss_train: 0.003867, loss_test: 0.007139
time: 0.24405455589294434
time: 2.2645061016082764
[1, 188] loss_train: 0.018447, loss_test: 0.007140
time: 0.24405360221862793
time: 2.2615103721618652
[1, 189] loss_train: 0.010211, loss_test: 0.007142
time: 0.24405455589294434
time: 2.267507314682007
[1, 190] loss_train: 0.011702, loss_test: 0.007148
time: 0.26405811309814453
time: 2.282510995864868
[1, 191] loss_train: 0.005941, loss_test: 0.007148
time: 0.29506540298461914
time: 2.3950390815734863
[1, 192] loss_train: 0.007098, loss_test: 0.007149
time: 0.26405906677246094
time: 2.3005142211914062
[1, 193] loss_train: 0.007335, loss_test: 0.007153
time: 0.2510554790496826
time: 2.284510850906372
[1, 194] loss_train: 0.015239, loss_test: 0.007169
time: 0.24605417251586914
time: 2.2965152263641357
[1, 195] loss_train: 0.015953, loss_test: 0.007196
time: 0.25005650520324707
time: 2.297016143798828
[1, 196] loss_train: 0.009436, loss_test: 0.007224
time: 0.24605464935302734
time: 2.275508403778076
[1, 197] loss_train: 0.006772, loss_test: 0.007241
time: 0.2600574493408203
time: 2.2825112342834473
[1, 198] loss_train: 0.008285, loss_test: 0.007250
time: 0.24805474281311035
time: 2.300513744354248
[1, 199] loss_train: 0.012216, loss_test: 0.007268
time: 0.26405835151672363
time: 2.262509346008301
[1, 200] loss_train: 0.009779, loss_test: 0.007297
time: 0.260056734085083
time: 2.316519021987915
[1, 201] loss_train: 0.005313, loss_test: 0.007318
time: 0.254056453704834
time: 2.346524238586426
[1, 202] loss_train: 0.012846, loss_test: 0.007363
time: 0.2540571689605713
time: 2.3295228481292725
[1, 203] loss_train: 0.006486, loss_test: 0.007393
time: 0.2600581645965576
time: 2.3130624294281006
[1, 204] loss_train: 0.007179, loss_test: 0.007388
time: 0.2600588798522949
time: 2.294512987136841
[1, 205] loss_train: 0.009960, loss_test: 0.007372
time: 0.26405835151672363
time: 2.3275234699249268
[1, 206] loss_train: 0.010143, loss_test: 0.007350
time: 0.25005555152893066
time: 2.3720736503601074
[1, 207] loss_train: 0.013046, loss_test: 0.007333
time: 0.26605892181396484
time: 2.342524290084839
[1, 208] loss_train: 0.008543, loss_test: 0.007329
time: 0.2820618152618408
time: 2.3614940643310547
[1, 209] loss_train: 0.003850, loss_test: 0.007299
time: 0.28406310081481934
time: 2.386533260345459
[1, 210] loss_train: 0.004375, loss_test: 0.007262
time: 0.2740607261657715
time: 2.2605085372924805
[1, 211] loss_train: 0.005260, loss_test: 0.007236
time: 0.24305319786071777
time: 2.2094953060150146
[1, 212] loss_train: 0.011913, loss_test: 0.007205
time: 0.24205303192138672
time: 2.280510187149048
[1, 213] loss_train: 0.007989, loss_test: 0.007182
time: 0.26605844497680664
time: 2.303515672683716
[1, 214] loss_train: 0.005443, loss_test: 0.007160
time: 0.2490546703338623
time: 2.283522844314575
[1, 215] loss_train: 0.010974, loss_test: 0.007144
time: 0.24605417251586914
time: 2.2715065479278564
[1, 216] loss_train: 0.003287, loss_test: 0.007120
time: 0.24905610084533691
time: 2.28852915763855
[1, 217] loss_train: 0.007752, loss_test: 0.007096
time: 0.2560570240020752
time: 2.333521842956543
[1, 218] loss_train: 0.007431, loss_test: 0.007077
time: 0.2490546703338623
time: 2.299028158187866
[1, 219] loss_train: 0.006016, loss_test: 0.007061
time: 0.24605417251586914
time: 2.2955141067504883
[1, 220] loss_train: 0.007074, loss_test: 0.007051
time: 0.25705718994140625
time: 2.2685091495513916
[1, 221] loss_train: 0.010218, loss_test: 0.007045
time: 0.24805450439453125
time: 2.2735097408294678
[1, 222] loss_train: 0.006687, loss_test: 0.007040
time: 0.24605417251586914
time: 2.3655285835266113
[1, 223] loss_train: 0.008879, loss_test: 0.007038
time: 0.25905704498291016
time: 2.3625497817993164
[1, 224] loss_train: 0.007677, loss_test: 0.007038
time: 0.26105809211730957
time: 2.3395233154296875
[1, 225] loss_train: 0.004330, loss_test: 0.007041
time: 0.2600572109222412
time: 2.316518783569336
[1, 226] loss_train: 0.005112, loss_test: 0.007047
time: 0.2560567855834961
time: 2.3255200386047363
[1, 227] loss_train: 0.006895, loss_test: 0.007055
time: 0.25905704498291016
time: 2.342524766921997
[1, 228] loss_train: 0.014149, loss_test: 0.007054
time: 0.2540557384490967
time: 2.317518711090088
[1, 229] loss_train: 0.005658, loss_test: 0.007051
time: 0.25005578994750977
time: 2.3495259284973145
[1, 230] loss_train: 0.002655, loss_test: 0.007047
time: 0.29306554794311523
time: 2.3965351581573486
[1, 231] loss_train: 0.007127, loss_test: 0.007047
time: 0.2630589008331299
time: 2.3705291748046875
[1, 232] loss_train: 0.007360, loss_test: 0.007044
time: 0.25906848907470703
time: 2.297513246536255
[1, 233] loss_train: 0.002069, loss_test: 0.007044
time: 0.24305415153503418
time: 2.2615060806274414
[1, 234] loss_train: 0.004993, loss_test: 0.007048
time: 0.25205516815185547
time: 2.3225202560424805
[1, 235] loss_train: 0.004501, loss_test: 0.007050
time: 0.2510552406311035
time: 2.3580307960510254
[1, 236] loss_train: 0.010174, loss_test: 0.007047
time: 0.24405431747436523
time: 2.273508310317993
[1, 237] loss_train: 0.011730, loss_test: 0.007036
time: 0.2510554790496826
time: 2.2965140342712402
[1, 238] loss_train: 0.010551, loss_test: 0.007023
time: 0.26405882835388184
time: 2.4035401344299316
[1, 239] loss_train: 0.005178, loss_test: 0.007017
time: 0.26805877685546875
time: 2.3075168132781982
[1, 240] loss_train: 0.008371, loss_test: 0.007007
time: 0.2620584964752197
time: 2.434544324874878
[1, 241] loss_train: 0.011711, loss_test: 0.007002
time: 0.3090684413909912
time: 2.3545260429382324
[1, 242] loss_train: 0.009580, loss_test: 0.007008
time: 0.2630579471588135
time: 2.483555793762207
[1, 243] loss_train: 0.007421, loss_test: 0.007022
time: 0.26105809211730957
time: 2.2573225498199463
[1, 244] loss_train: 0.003513, loss_test: 0.007039
time: 0.2490551471710205
time: 2.2495031356811523
[1, 245] loss_train: 0.003000, loss_test: 0.007052
time: 0.256056547164917
time: 2.2755091190338135
[1, 246] loss_train: 0.006702, loss_test: 0.007064
time: 0.2540569305419922
time: 2.3405232429504395
[1, 247] loss_train: 0.008087, loss_test: 0.007076
time: 0.24605393409729004
time: 2.244502067565918
[1, 248] loss_train: 0.004097, loss_test: 0.007084
time: 0.2490549087524414
time: 2.493558168411255
[1, 249] loss_train: 0.005189, loss_test: 0.007087
time: 0.24305367469787598
time: 2.509561777114868
[1, 250] loss_train: 0.004529, loss_test: 0.007082
time: 0.2650580406188965
time: 2.2805099487304688
[1, 251] loss_train: 0.015335, loss_test: 0.007087
time: 0.2720603942871094
time: 2.2865121364593506
[1, 252] loss_train: 0.006367, loss_test: 0.007085
time: 0.2510559558868408
time: 2.2525055408477783
[1, 253] loss_train: 0.004839, loss_test: 0.007071
time: 0.24205279350280762
time: 2.231501817703247
[1, 254] loss_train: 0.005087, loss_test: 0.007050
time: 0.2450547218322754
time: 2.2516939640045166
[1, 255] loss_train: 0.007424, loss_test: 0.007031
time: 0.24332094192504883
time: 2.220195770263672
[1, 256] loss_train: 0.007514, loss_test: 0.007017
time: 0.24205350875854492
time: 2.2245140075683594
[1, 257] loss_train: 0.009073, loss_test: 0.007004
time: 0.24305438995361328
time: 2.296513080596924
[1, 258] loss_train: 0.008773, loss_test: 0.006996
time: 0.25505614280700684
time: 2.520564556121826
[1, 259] loss_train: 0.012625, loss_test: 0.006994
time: 0.2490544319152832
time: 2.330521821975708
[1, 260] loss_train: 0.002342, loss_test: 0.006990
time: 0.2850627899169922
time: 2.377532958984375
[1, 261] loss_train: 0.009592, loss_test: 0.006988
time: 0.2490553855895996
time: 2.3875343799591064
[1, 262] loss_train: 0.007523, loss_test: 0.006982
time: 0.2650585174560547
time: 2.2995145320892334
[1, 263] loss_train: 0.008286, loss_test: 0.006977
time: 0.25005578994750977
time: 2.305516481399536
[1, 264] loss_train: 0.010292, loss_test: 0.006971
time: 0.2530558109283447
time: 2.284512996673584
[1, 265] loss_train: 0.011026, loss_test: 0.006968
time: 0.2470550537109375
time: 2.3905344009399414
[1, 266] loss_train: 0.010029, loss_test: 0.006969
time: 0.2670590877532959
time: 2.3355228900909424
[1, 267] loss_train: 0.002777, loss_test: 0.006967
time: 0.2650582790374756
time: 2.2935140132904053
[1, 268] loss_train: 0.013212, loss_test: 0.006971
time: 0.2470541000366211
time: 2.3375234603881836
[1, 269] loss_train: 0.007967, loss_test: 0.006977
time: 0.2800617218017578
time: 2.281510829925537
[1, 270] loss_train: 0.011147, loss_test: 0.006981
time: 0.28106236457824707
time: 2.3365230560302734
[1, 271] loss_train: 0.005351, loss_test: 0.006979
time: 0.27005934715270996
time: 2.330521583557129
[1, 272] loss_train: 0.012697, loss_test: 0.006979
time: 0.24305391311645508
time: 2.2825112342834473
[1, 273] loss_train: 0.006205, loss_test: 0.006976
time: 0.25505661964416504
time: 2.2855114936828613
[1, 274] loss_train: 0.013558, loss_test: 0.006981
time: 0.24605560302734375
time: 2.2915148735046387
[1, 275] loss_train: 0.016896, loss_test: 0.007021
time: 0.24605536460876465
time: 2.274508237838745
[1, 276] loss_train: 0.006459, loss_test: 0.007059
time: 0.25005602836608887
time: 2.3065152168273926
[1, 277] loss_train: 0.013110, loss_test: 0.007123
time: 0.24805569648742676
time: 2.3005146980285645
[1, 278] loss_train: 0.010103, loss_test: 0.007185
time: 0.24605464935302734
time: 2.2284982204437256
[1, 279] loss_train: 0.007398, loss_test: 0.007215
time: 0.24605488777160645
time: 2.2735085487365723
[1, 280] loss_train: 0.006714, loss_test: 0.007219
time: 0.2560575008392334
time: 2.242511749267578
[1, 281] loss_train: 0.008234, loss_test: 0.007188
time: 0.24505352973937988
time: 2.2535042762756348
[1, 282] loss_train: 0.005992, loss_test: 0.007135
time: 0.24405479431152344
time: 2.2635059356689453
[1, 283] loss_train: 0.006488, loss_test: 0.007077
time: 0.24805474281311035
time: 2.270681619644165
[1, 284] loss_train: 0.010904, loss_test: 0.007035
time: 0.24505400657653809
time: 2.3045592308044434
[1, 285] loss_train: 0.004905, loss_test: 0.006987
time: 0.25205564498901367
time: 2.2765097618103027
[1, 286] loss_train: 0.003995, loss_test: 0.006954
time: 0.2565772533416748
time: 2.3145172595977783
[1, 287] loss_train: 0.004222, loss_test: 0.006933
time: 0.2470555305480957
time: 2.284510374069214
[1, 288] loss_train: 0.007452, loss_test: 0.006922
time: 0.2540726661682129
time: 2.314518451690674
[1, 289] loss_train: 0.008524, loss_test: 0.006914
time: 0.2450549602508545
time: 2.345524549484253
[1, 290] loss_train: 0.011423, loss_test: 0.006908
time: 0.26105809211730957
time: 2.3365225791931152
[1, 291] loss_train: 0.014385, loss_test: 0.006902
time: 0.2560563087463379
time: 2.414539337158203
[1, 292] loss_train: 0.013287, loss_test: 0.006901
time: 0.2540559768676758
time: 2.322519540786743
[1, 293] loss_train: 0.003402, loss_test: 0.006898
time: 0.24405407905578613
time: 2.2595059871673584
[1, 294] loss_train: 0.004377, loss_test: 0.006897
time: 0.26105713844299316
time: 2.2675106525421143
[1, 295] loss_train: 0.006230, loss_test: 0.006893
time: 0.24805474281311035
time: 2.2595200538635254
[1, 296] loss_train: 0.018246, loss_test: 0.006904
time: 0.24605393409729004
time: 2.275508403778076
[1, 297] loss_train: 0.008867, loss_test: 0.006919
time: 0.24405455589294434
time: 2.271507978439331
[1, 298] loss_train: 0.003561, loss_test: 0.006931
time: 0.24505400657653809
time: 2.2655069828033447
[1, 299] loss_train: 0.004531, loss_test: 0.006940
time: 0.24505376815795898
time: 2.2735095024108887
[1, 300] loss_train: 0.003709, loss_test: 0.006933
time: 0.25905823707580566
time: 2.281511068344116
[1, 301] loss_train: 0.007620, loss_test: 0.006929
time: 0.2630586624145508
time: 2.3685286045074463
[1, 302] loss_train: 0.017516, loss_test: 0.006944
time: 0.2650601863861084
time: 2.2675068378448486
[1, 303] loss_train: 0.006246, loss_test: 0.006951
time: 0.25005578994750977
time: 2.265643835067749
[1, 304] loss_train: 0.005692, loss_test: 0.006950
time: 0.2520561218261719
time: 2.3005142211914062
[1, 305] loss_train: 0.004630, loss_test: 0.006948
time: 0.25005555152893066
time: 2.289334774017334
[1, 306] loss_train: 0.008551, loss_test: 0.006943
time: 0.2510554790496826
time: 2.2735090255737305
[1, 307] loss_train: 0.005849, loss_test: 0.006925
time: 0.2510554790496826
time: 2.2945163249969482
[1, 308] loss_train: 0.015291, loss_test: 0.006914
time: 0.27005910873413086
time: 2.430544376373291
[1, 309] loss_train: 0.007276, loss_test: 0.006912
time: 0.26405811309814453
time: 2.383533000946045
[1, 310] loss_train: 0.006485, loss_test: 0.006908
time: 0.3010671138763428
time: 2.355527400970459
[1, 311] loss_train: 0.006436, loss_test: 0.006901
time: 0.2620584964752197
time: 2.3995513916015625
[1, 312] loss_train: 0.007087, loss_test: 0.006898
time: 0.2850627899169922
time: 2.3355252742767334
[1, 313] loss_train: 0.000629, loss_test: 0.006893
time: 0.26605892181396484
time: 2.3355233669281006
[1, 314] loss_train: 0.003158, loss_test: 0.006874
time: 0.2510547637939453
time: 2.3005146980285645
[1, 315] loss_train: 0.004583, loss_test: 0.006854
time: 0.2490549087524414
time: 2.332521677017212
[1, 316] loss_train: 0.006870, loss_test: 0.006840
time: 0.2690596580505371
time: 2.4630589485168457
[1, 317] loss_train: 0.006750, loss_test: 0.006834
time: 0.2600584030151367
time: 2.3385226726531982
[1, 318] loss_train: 0.001488, loss_test: 0.006831
time: 0.2510559558868408
time: 2.2711448669433594
[1, 319] loss_train: 0.004010, loss_test: 0.006829
time: 0.25005626678466797
time: 2.3195180892944336
[1, 320] loss_train: 0.005616, loss_test: 0.006830
time: 0.25905728340148926
time: 2.289512872695923
[1, 321] loss_train: 0.001015, loss_test: 0.006837
time: 0.24605393409729004
time: 2.2725090980529785
[1, 322] loss_train: 0.013784, loss_test: 0.006834
time: 0.26248717308044434
time: 2.3485260009765625
[1, 323] loss_train: 0.008639, loss_test: 0.006828
time: 0.2510561943054199
time: 2.4435462951660156
[1, 324] loss_train: 0.004912, loss_test: 0.006826
time: 0.27005887031555176
time: 2.2985148429870605
[1, 325] loss_train: 0.009060, loss_test: 0.006823
time: 0.25505614280700684
time: 2.2855138778686523
[1, 326] loss_train: 0.010047, loss_test: 0.006813
time: 0.25205540657043457
time: 2.26751708984375
[1, 327] loss_train: 0.006499, loss_test: 0.006807
time: 0.24605417251586914
time: 2.256505012512207
[1, 328] loss_train: 0.004932, loss_test: 0.006803
time: 0.2490556240081787
time: 2.291018009185791
[1, 329] loss_train: 0.009757, loss_test: 0.006795
time: 0.28606343269348145
time: 2.3415231704711914
[1, 330] loss_train: 0.007252, loss_test: 0.006788
time: 0.27005982398986816
time: 2.4055380821228027
[1, 331] loss_train: 0.001323, loss_test: 0.006785
time: 0.2554340362548828
time: 2.2675070762634277
[1, 332] loss_train: 0.010703, loss_test: 0.006785
time: 0.2560575008392334
time: 2.290512800216675
[1, 333] loss_train: 0.006077, loss_test: 0.006786
time: 0.2540569305419922
time: 2.3405232429504395
[1, 334] loss_train: 0.004328, loss_test: 0.006790
time: 0.2540557384490967
time: 2.3775322437286377
[1, 335] loss_train: 0.005138, loss_test: 0.006796
time: 0.2820620536804199
time: 2.2975144386291504
[1, 336] loss_train: 0.005457, loss_test: 0.006801
time: 0.25005578994750977
time: 2.31851863861084
[1, 337] loss_train: 0.007023, loss_test: 0.006802
time: 0.2510550022125244
time: 2.3905348777770996
[1, 338] loss_train: 0.002181, loss_test: 0.006804
time: 0.2800612449645996
time: 2.3655295372009277
[1, 339] loss_train: 0.012620, loss_test: 0.006801
time: 0.2450542449951172
time: 2.2655189037323
[1, 340] loss_train: 0.012668, loss_test: 0.006797
time: 0.26205921173095703
time: 2.27150821685791
[1, 341] loss_train: 0.008266, loss_test: 0.006795
time: 0.2490553855895996
time: 2.258504629135132
[1, 342] loss_train: 0.010302, loss_test: 0.006792
time: 0.2560567855834961
time: 2.2905123233795166
[1, 343] loss_train: 0.007597, loss_test: 0.006790
time: 0.31506967544555664
time: 2.419541597366333
[1, 344] loss_train: 0.007007, loss_test: 0.006791
time: 0.26405835151672363
time: 2.2585058212280273
[1, 345] loss_train: 0.008968, loss_test: 0.006790
time: 0.25005483627319336
time: 2.272509813308716
[1, 346] loss_train: 0.007451, loss_test: 0.006791
time: 0.2490541934967041
time: 2.4035379886627197
[1, 347] loss_train: 0.008832, loss_test: 0.006791
time: 0.27906131744384766
time: 2.4125399589538574
[1, 348] loss_train: 0.012538, loss_test: 0.006793
time: 0.27706170082092285
time: 2.3060193061828613
[1, 349] loss_train: 0.003957, loss_test: 0.006795
time: 0.24605393409729004
time: 2.314323902130127
[1, 350] loss_train: 0.004915, loss_test: 0.006796
time: 0.2820627689361572
time: 2.2785096168518066
[1, 351] loss_train: 0.004907, loss_test: 0.006796
time: 0.24405431747436523
time: 2.3025147914886475
[1, 352] loss_train: 0.018709, loss_test: 0.006815
time: 0.26405858993530273
time: 2.3535289764404297
[1, 353] loss_train: 0.003474, loss_test: 0.006833
time: 0.24605417251586914
time: 2.277509927749634
[1, 354] loss_train: 0.007022, loss_test: 0.006845
time: 0.2760612964630127
time: 2.3020172119140625
[1, 355] loss_train: 0.012277, loss_test: 0.006868
time: 0.2600572109222412
time: 2.38053297996521
[1, 356] loss_train: 0.008566, loss_test: 0.006881
time: 0.24605464935302734
time: 2.2555043697357178
[1, 357] loss_train: 0.004806, loss_test: 0.006881
time: 0.25005483627319336
time: 2.305516242980957
[1, 358] loss_train: 0.019641, loss_test: 0.006913
time: 0.2580573558807373
time: 2.3255221843719482
[1, 359] loss_train: 0.003466, loss_test: 0.006937
time: 0.2520561218261719
time: 2.3505256175994873
[1, 360] loss_train: 0.008787, loss_test: 0.006958
time: 0.2620577812194824
time: 2.371046543121338
[1, 361] loss_train: 0.010402, loss_test: 0.006973
time: 0.27306056022644043
time: 2.2474374771118164
[1, 362] loss_train: 0.008252, loss_test: 0.006968
time: 0.2910633087158203
time: 2.305516242980957
[1, 363] loss_train: 0.006360, loss_test: 0.006953
time: 0.24155831336975098
time: 2.2910170555114746
[1, 364] loss_train: 0.006739, loss_test: 0.006934
time: 0.256056547164917
time: 2.248539686203003
[1, 365] loss_train: 0.002165, loss_test: 0.006904
time: 0.27306127548217773
time: 2.355032444000244
[1, 366] loss_train: 0.008115, loss_test: 0.006872
time: 0.26605725288391113
time: 2.381533622741699
[1, 367] loss_train: 0.005085, loss_test: 0.006852
time: 0.287064790725708
time: 2.3275234699249268
[1, 368] loss_train: 0.003718, loss_test: 0.006847
time: 0.2470550537109375
time: 2.2895116806030273
[1, 369] loss_train: 0.005832, loss_test: 0.006849
time: 0.25005578994750977
time: 2.3245198726654053
[1, 370] loss_train: 0.007423, loss_test: 0.006861
time: 0.2620575428009033
time: 2.2995147705078125
[1, 371] loss_train: 0.002821, loss_test: 0.006882
time: 0.2470555305480957
time: 2.2385005950927734
[1, 372] loss_train: 0.012636, loss_test: 0.006873
time: 0.2450551986694336
time: 2.2525036334991455
[1, 373] loss_train: 0.008549, loss_test: 0.006865
time: 0.25005483627319336
time: 2.2365005016326904
[1, 374] loss_train: 0.006823, loss_test: 0.006856
time: 0.2490551471710205
time: 2.265507221221924
[1, 375] loss_train: 0.007038, loss_test: 0.006841
time: 0.24805474281311035
time: 2.2655069828033447
[1, 376] loss_train: 0.005693, loss_test: 0.006830
time: 0.2630581855773926
time: 2.305516004562378
[1, 377] loss_train: 0.002128, loss_test: 0.006827
time: 0.27906155586242676
time: 2.2755095958709717
[1, 378] loss_train: 0.004941, loss_test: 0.006826
time: 0.2690591812133789
time: 2.3509583473205566
[1, 379] loss_train: 0.010295, loss_test: 0.006818
time: 0.24405336380004883
time: 2.265512228012085
[1, 380] loss_train: 0.009036, loss_test: 0.006817
time: 0.2580578327178955
time: 2.2805113792419434
[1, 381] loss_train: 0.007561, loss_test: 0.006826
time: 0.25005578994750977
time: 2.377532482147217
[1, 382] loss_train: 0.008702, loss_test: 0.006837
time: 0.25505685806274414
time: 2.3523573875427246
[1, 383] loss_train: 0.016975, loss_test: 0.006876
time: 0.2500951290130615
time: 2.2735087871551514
[1, 384] loss_train: 0.006204, loss_test: 0.006904
time: 0.25005483627319336
time: 2.270509719848633
[1, 385] loss_train: 0.004771, loss_test: 0.006926
time: 0.2580578327178955
time: 2.2324986457824707
[1, 386] loss_train: 0.003884, loss_test: 0.006932
time: 0.2470552921295166
time: 2.2485029697418213
[1, 387] loss_train: 0.006633, loss_test: 0.006919
time: 0.24805545806884766
time: 2.2425012588500977
[1, 388] loss_train: 0.010018, loss_test: 0.006910
time: 0.24805450439453125
time: 2.301438808441162
[1, 389] loss_train: 0.017381, loss_test: 0.006916
time: 0.24905610084533691
time: 2.2715251445770264
[1, 390] loss_train: 0.007831, loss_test: 0.006912
time: 0.25905752182006836
time: 2.2795095443725586
[1, 391] loss_train: 0.015016, loss_test: 0.006919
time: 0.24505400657653809
time: 2.433544874191284
[1, 392] loss_train: 0.005423, loss_test: 0.006905
time: 0.2620584964752197
time: 2.307515859603882
[1, 393] loss_train: 0.006446, loss_test: 0.006866
time: 0.24805498123168945
time: 2.2365005016326904
[1, 394] loss_train: 0.009578, loss_test: 0.006839
time: 0.25005507469177246
time: 2.3505406379699707
[1, 395] loss_train: 0.007221, loss_test: 0.006817
time: 0.2960658073425293
time: 2.348524808883667
[1, 396] loss_train: 0.011893, loss_test: 0.006799
time: 0.2470552921295166
time: 2.2525036334991455
[1, 397] loss_train: 0.008173, loss_test: 0.006784
time: 0.24605488777160645
time: 2.243502140045166
[1, 398] loss_train: 0.005188, loss_test: 0.006772
time: 0.27306032180786133
time: 2.2995145320892334
[1, 399] loss_train: 0.006289, loss_test: 0.006757
time: 0.25005507469177246
time: 2.270508050918579
[1, 400] loss_train: 0.002238, loss_test: 0.006732
time: 0.27906179428100586
time: 2.3005154132843018
[1, 401] loss_train: 0.009131, loss_test: 0.006734
time: 0.24805450439453125
time: 2.2585055828094482
[1, 402] loss_train: 0.002860, loss_test: 0.006731
time: 0.38608646392822266
time: 2.3165204524993896
[1, 403] loss_train: 0.008803, loss_test: 0.006729
time: 0.26605844497680664
time: 2.3265295028686523
[1, 404] loss_train: 0.004691, loss_test: 0.006722
time: 0.2870635986328125
time: 2.290513753890991
[1, 405] loss_train: 0.011119, loss_test: 0.006719
time: 0.2450547218322754
time: 2.3055174350738525
[1, 406] loss_train: 0.007282, loss_test: 0.006715
time: 0.2450547218322754
time: 2.2505033016204834
[1, 407] loss_train: 0.002610, loss_test: 0.006714
time: 0.2470548152923584
time: 2.2980172634124756
[1, 408] loss_train: 0.013570, loss_test: 0.006710
time: 0.24805474281311035
time: 2.2735087871551514
[1, 409] loss_train: 0.007683, loss_test: 0.006706
time: 0.24205422401428223
time: 2.2895119190216064
[1, 410] loss_train: 0.008858, loss_test: 0.006698
time: 0.25905680656433105
time: 2.358538866043091
[1, 411] loss_train: 0.011278, loss_test: 0.006692
time: 0.252056360244751
time: 2.254504442214966
[1, 412] loss_train: 0.005063, loss_test: 0.006685
time: 0.2490546703338623
time: 2.242502450942993
[1, 413] loss_train: 0.008461, loss_test: 0.006678
time: 0.2490551471710205
time: 2.2555041313171387
[1, 414] loss_train: 0.003989, loss_test: 0.006667
time: 0.24105286598205566
time: 2.291515350341797
[1, 415] loss_train: 0.014341, loss_test: 0.006661
time: 0.24805426597595215
time: 2.2858850955963135
[1, 416] loss_train: 0.015340, loss_test: 0.006661
time: 0.24305415153503418
time: 2.2324986457824707
[1, 417] loss_train: 0.004985, loss_test: 0.006659
time: 0.2450554370880127
time: 2.2446951866149902
[1, 418] loss_train: 0.006923, loss_test: 0.006660
time: 0.24606823921203613
time: 2.2605056762695312
[1, 419] loss_train: 0.005531, loss_test: 0.006658
time: 0.2470545768737793
time: 2.2264983654022217
[1, 420] loss_train: 0.009518, loss_test: 0.006660
time: 0.2630589008331299
time: 2.349525213241577
[1, 421] loss_train: 0.006141, loss_test: 0.006661
time: 0.24405360221862793
time: 2.391535520553589
[1, 422] loss_train: 0.001834, loss_test: 0.006650
time: 0.24505138397216797
time: 2.468552350997925
[1, 423] loss_train: 0.008446, loss_test: 0.006646
time: 0.254056453704834
time: 2.2675070762634277
[1, 424] loss_train: 0.003490, loss_test: 0.006643
time: 0.24505376815795898
time: 2.2945139408111572
[1, 425] loss_train: 0.000969, loss_test: 0.006637
time: 0.2510557174682617
time: 2.306516408920288
[1, 426] loss_train: 0.008194, loss_test: 0.006629
time: 0.25505685806274414
time: 2.3905348777770996
[1, 427] loss_train: 0.003621, loss_test: 0.006614
time: 0.2960660457611084
time: 2.318479299545288
[1, 428] loss_train: 0.003951, loss_test: 0.006603
time: 0.24605393409729004
time: 2.265507459640503
[1, 429] loss_train: 0.002034, loss_test: 0.006594
time: 0.26805877685546875
time: 2.2965142726898193
[1, 430] loss_train: 0.004763, loss_test: 0.006595
time: 0.2580575942993164
time: 2.3305211067199707
[1, 431] loss_train: 0.010973, loss_test: 0.006594
time: 0.2520561218261719
time: 2.343524694442749
[1, 432] loss_train: 0.006715, loss_test: 0.006592
time: 0.25005483627319336
time: 2.2985146045684814
[1, 433] loss_train: 0.008982, loss_test: 0.006585
time: 0.256056547164917
time: 2.3140206336975098
[1, 434] loss_train: 0.005126, loss_test: 0.006581
time: 0.2470552921295166
time: 2.3405234813690186
[1, 435] loss_train: 0.004444, loss_test: 0.006577
time: 0.25505733489990234
time: 2.326519727706909
[1, 436] loss_train: 0.009147, loss_test: 0.006572
time: 0.2540571689605713
time: 2.314519166946411
[1, 437] loss_train: 0.002116, loss_test: 0.006571
time: 0.298065185546875
time: 2.3795318603515625
[1, 438] loss_train: 0.003709, loss_test: 0.006572
time: 0.25005578994750977
time: 2.232499361038208
[1, 439] loss_train: 0.011276, loss_test: 0.006567
time: 0.24605417251586914
time: 2.3255205154418945
[1, 440] loss_train: 0.005134, loss_test: 0.006562
time: 0.265059232711792
time: 2.3210229873657227
[1, 441] loss_train: 0.009704, loss_test: 0.006556
time: 0.2490556240081787
time: 2.309516191482544
[1, 442] loss_train: 0.004966, loss_test: 0.006553
time: 0.2540559768676758
time: 2.3345367908477783
[1, 443] loss_train: 0.003924, loss_test: 0.006550
time: 0.25705671310424805
time: 2.256507396697998
[1, 444] loss_train: 0.020097, loss_test: 0.006546
time: 0.2540555000305176
time: 2.286513566970825
[1, 445] loss_train: 0.007503, loss_test: 0.006552
time: 0.2490546703338623
time: 2.316518545150757
[1, 446] loss_train: 0.001990, loss_test: 0.006564
time: 0.2580568790435791
time: 2.2875547409057617
[1, 447] loss_train: 0.002749, loss_test: 0.006572
time: 0.247053861618042
time: 2.262613534927368
[1, 448] loss_train: 0.002050, loss_test: 0.006572
time: 0.25005602836608887
time: 2.306311845779419
[1, 449] loss_train: 0.003268, loss_test: 0.006564
time: 0.25905799865722656
time: 2.2825098037719727
[1, 450] loss_train: 0.006689, loss_test: 0.006556
time: 0.26405811309814453
time: 2.371539831161499
[1, 451] loss_train: 0.013318, loss_test: 0.006555
time: 0.2670602798461914
time: 2.3009891510009766
[1, 452] loss_train: 0.015830, loss_test: 0.006580
time: 0.25205564498901367
time: 2.2785098552703857
[1, 453] loss_train: 0.009841, loss_test: 0.006617
time: 0.24405407905578613
time: 2.257507085800171
[1, 454] loss_train: 0.005338, loss_test: 0.006645
time: 0.2510550022125244
time: 2.254504442214966
[1, 455] loss_train: 0.007538, loss_test: 0.006669
time: 0.25905871391296387
time: 2.3960492610931396
[1, 456] loss_train: 0.006110, loss_test: 0.006682
time: 0.25305628776550293
time: 2.3180243968963623
[1, 457] loss_train: 0.009732, loss_test: 0.006696
time: 0.247056245803833
time: 2.2785091400146484
[1, 458] loss_train: 0.002191, loss_test: 0.006694
time: 0.24405384063720703
time: 2.3385226726531982
[1, 459] loss_train: 0.006807, loss_test: 0.006691
time: 0.25905728340148926
time: 2.2695083618164062
[1, 460] loss_train: 0.002735, loss_test: 0.006665
time: 0.26405811309814453
time: 2.270508289337158
[1, 461] loss_train: 0.008602, loss_test: 0.006642
time: 0.24405431747436523
time: 2.217495918273926
[1, 462] loss_train: 0.018525, loss_test: 0.006646
time: 0.24205398559570312
time: 2.2515077590942383
[1, 463] loss_train: 0.009489, loss_test: 0.006644
time: 0.2470550537109375
time: 2.3635308742523193
[1, 464] loss_train: 0.003673, loss_test: 0.006626
time: 0.2510554790496826
time: 2.2855114936828613
[1, 465] loss_train: 0.004428, loss_test: 0.006615
time: 0.25005555152893066
time: 2.2565042972564697
[1, 466] loss_train: 0.002913, loss_test: 0.006601
time: 0.25305676460266113
time: 2.2244975566864014
[1, 467] loss_train: 0.005321, loss_test: 0.006600
time: 0.25505590438842773
time: 2.2565054893493652
[1, 468] loss_train: 0.012378, loss_test: 0.006584
time: 0.25005531311035156
time: 2.255504846572876
[1, 469] loss_train: 0.006299, loss_test: 0.006576
time: 0.25505709648132324
time: 2.4375455379486084
[1, 470] loss_train: 0.003573, loss_test: 0.006576
time: 0.30007243156433105
time: 2.4275431632995605
[1, 471] loss_train: 0.002816, loss_test: 0.006581
time: 0.2580568790435791
time: 2.344156503677368
[1, 472] loss_train: 0.013580, loss_test: 0.006559
time: 0.25505638122558594
time: 2.2720119953155518
[1, 473] loss_train: 0.003625, loss_test: 0.006546
time: 0.24305343627929688
time: 2.2405028343200684
[1, 474] loss_train: 0.013105, loss_test: 0.006518
time: 0.25005388259887695
time: 2.2495036125183105
[1, 475] loss_train: 0.012824, loss_test: 0.006484
time: 0.24305343627929688
time: 2.295513868331909
[1, 476] loss_train: 0.004016, loss_test: 0.006474
time: 0.24605441093444824
time: 2.341524362564087
[1, 477] loss_train: 0.008337, loss_test: 0.006478
time: 0.2470548152923584
time: 2.2805190086364746
[1, 478] loss_train: 0.001148, loss_test: 0.006496
time: 0.2470552921295166
time: 2.3275203704833984
[1, 479] loss_train: 0.009713, loss_test: 0.006523
time: 0.24805450439453125
time: 2.2520089149475098
[1, 480] loss_train: 0.006097, loss_test: 0.006553
time: 0.25705671310424805
time: 2.2625694274902344
[1, 481] loss_train: 0.016101, loss_test: 0.006611
time: 0.2430553436279297
time: 2.260505199432373
[1, 482] loss_train: 0.007873, loss_test: 0.006663
time: 0.2600572109222412
time: 2.291513204574585
[1, 483] loss_train: 0.013611, loss_test: 0.006739
time: 0.27205991744995117
time: 2.2645068168640137
[1, 484] loss_train: 0.006125, loss_test: 0.006772
time: 0.24105310440063477
time: 2.3445241451263428
[1, 485] loss_train: 0.013399, loss_test: 0.006806
time: 0.2690608501434326
time: 2.2995145320892334
[1, 486] loss_train: 0.019267, loss_test: 0.006894
time: 0.28106141090393066
time: 2.289512872695923
[1, 487] loss_train: 0.002214, loss_test: 0.006933
time: 0.2620580196380615
time: 2.3035149574279785
[1, 488] loss_train: 0.003275, loss_test: 0.006900
time: 0.2490558624267578
time: 2.3765311241149902
[1, 489] loss_train: 0.009682, loss_test: 0.006851
time: 0.24305438995361328
time: 2.242501735687256
[1, 490] loss_train: 0.003349, loss_test: 0.006777
time: 0.2560560703277588
time: 2.3545289039611816
[1, 491] loss_train: 0.002941, loss_test: 0.006687
time: 0.2490549087524414
time: 2.288120746612549
[1, 492] loss_train: 0.008558, loss_test: 0.006602
time: 0.2510552406311035
time: 2.3345229625701904
[1, 493] loss_train: 0.017923, loss_test: 0.006578
time: 0.2710597515106201
time: 2.329521417617798
[1, 494] loss_train: 0.010977, loss_test: 0.006548
time: 0.2540132999420166
time: 2.351526975631714
[1, 495] loss_train: 0.011585, loss_test: 0.006531
time: 0.2940654754638672
time: 2.3885340690612793
[1, 496] loss_train: 0.007380, loss_test: 0.006514
time: 0.2490549087524414
time: 2.3325228691101074
[1, 497] loss_train: 0.008474, loss_test: 0.006503
time: 0.26605939865112305
time: 2.297513961791992
[1, 498] loss_train: 0.006186, loss_test: 0.006491
time: 0.2490556240081787
time: 2.2955126762390137
[1, 499] loss_train: 0.009791, loss_test: 0.006486
time: 0.25905776023864746
time: 2.268507242202759
[1, 500] loss_train: 0.003809, loss_test: 0.006480
time: 0.25705718994140625
time: 2.307018995285034
[1, 501] loss_train: 0.015476, loss_test: 0.006483
time: 0.2540566921234131
time: 2.282510280609131
[1, 502] loss_train: 0.009258, loss_test: 0.006485
time: 0.24805450439453125
time: 2.2875123023986816
[1, 503] loss_train: 0.009513, loss_test: 0.006488
time: 0.24605393409729004
time: 2.258504867553711
[1, 504] loss_train: 0.007969, loss_test: 0.006492
time: 0.24805569648742676
time: 2.3045153617858887
[1, 505] loss_train: 0.011742, loss_test: 0.006504
time: 0.2510557174682617
time: 2.309519052505493
[1, 506] loss_train: 0.006319, loss_test: 0.006514
time: 0.24405312538146973
time: 2.3225197792053223
[1, 507] loss_train: 0.008418, loss_test: 0.006525
time: 0.2450544834136963
time: 2.221496820449829
[1, 508] loss_train: 0.009719, loss_test: 0.006535
time: 0.24805450439453125
time: 2.3345227241516113
[1, 509] loss_train: 0.013184, loss_test: 0.006550
time: 0.25905776023864746
time: 2.260010242462158
[1, 510] loss_train: 0.001672, loss_test: 0.006540
time: 0.29506540298461914
time: 2.297513723373413
[1, 511] loss_train: 0.009962, loss_test: 0.006526
time: 0.24405384063720703
time: 2.395535945892334
[1, 512] loss_train: 0.006014, loss_test: 0.006504
time: 0.24305295944213867
time: 2.410541296005249
[1, 513] loss_train: 0.008887, loss_test: 0.006484
time: 0.2980668544769287
time: 2.359527111053467
[1, 514] loss_train: 0.013591, loss_test: 0.006485
time: 0.25005531311035156
time: 2.3005142211914062
[1, 515] loss_train: 0.005009, loss_test: 0.006473
time: 0.2540562152862549
time: 2.224477767944336
[1, 516] loss_train: 0.007269, loss_test: 0.006457
time: 0.24305391311645508
time: 2.281511068344116
[1, 517] loss_train: 0.007724, loss_test: 0.006442
time: 0.25205516815185547
time: 2.342524290084839
[1, 518] loss_train: 0.005071, loss_test: 0.006426
time: 0.27205967903137207
time: 2.3570308685302734
[1, 519] loss_train: 0.012071, loss_test: 0.006421
time: 0.27506160736083984
time: 2.2985141277313232
[1, 520] loss_train: 0.005588, loss_test: 0.006416
time: 0.27205967903137207
time: 2.3375258445739746
[1, 521] loss_train: 0.008357, loss_test: 0.006414
time: 0.2720603942871094
time: 2.320521116256714
[1, 522] loss_train: 0.005564, loss_test: 0.006415
time: 0.2470552921295166
time: 2.296513319015503
[1, 523] loss_train: 0.004994, loss_test: 0.006416
time: 0.24605464935302734
time: 2.2765090465545654
[1, 524] loss_train: 0.004798, loss_test: 0.006413
time: 0.24305438995361328
time: 2.3515255451202393
[1, 525] loss_train: 0.005625, loss_test: 0.006409
time: 0.25505614280700684
time: 2.298513412475586
[1, 526] loss_train: 0.002658, loss_test: 0.006406
time: 0.305067777633667
time: 2.3035151958465576
[1, 527] loss_train: 0.003983, loss_test: 0.006405
time: 0.2490546703338623
time: 2.3235204219818115
[1, 528] loss_train: 0.012142, loss_test: 0.006405
time: 0.2580602169036865
time: 2.266507148742676
[1, 529] loss_train: 0.004866, loss_test: 0.006406
time: 0.24605536460876465
time: 2.3005144596099854
[1, 530] loss_train: 0.002749, loss_test: 0.006409
time: 0.26104211807250977
time: 2.2865114212036133
[1, 531] loss_train: 0.004437, loss_test: 0.006414
time: 0.2510561943054199
time: 2.2889299392700195
[1, 532] loss_train: 0.004966, loss_test: 0.006421
time: 0.2470548152923584
time: 2.391535520553589
[1, 533] loss_train: 0.022578, loss_test: 0.006420
time: 0.27706098556518555
time: 2.3305211067199707
[1, 534] loss_train: 0.014583, loss_test: 0.006441
time: 0.25505661964416504
time: 2.260505437850952
[1, 535] loss_train: 0.004779, loss_test: 0.006476
time: 0.24605441093444824
time: 2.2875120639801025
[1, 536] loss_train: 0.004067, loss_test: 0.006509
time: 0.25205540657043457
time: 2.2965142726898193
[1, 537] loss_train: 0.002612, loss_test: 0.006524
time: 0.2520561218261719
time: 2.3085153102874756
[1, 538] loss_train: 0.005759, loss_test: 0.006512
time: 0.2470550537109375
time: 2.3375234603881836
[1, 539] loss_train: 0.010663, loss_test: 0.006487
time: 0.25905680656433105
time: 2.345446825027466
[1, 540] loss_train: 0.011989, loss_test: 0.006488
time: 0.2560570240020752
time: 2.2655065059661865
[1, 541] loss_train: 0.001896, loss_test: 0.006455
time: 0.2470552921295166
time: 2.2895116806030273
[1, 542] loss_train: 0.011347, loss_test: 0.006440
time: 0.25505685806274414
time: 2.334522008895874
[1, 543] loss_train: 0.010331, loss_test: 0.006412
time: 0.25905871391296387
time: 2.2725203037261963
[1, 544] loss_train: 0.006853, loss_test: 0.006383
time: 0.28806447982788086
time: 2.2895116806030273
[1, 545] loss_train: 0.022381, loss_test: 0.006385
time: 0.24305438995361328
time: 2.22249698638916
[1, 546] loss_train: 0.002189, loss_test: 0.006385
time: 0.25005483627319336
time: 2.3600454330444336
[1, 547] loss_train: 0.009064, loss_test: 0.006382
time: 0.24306535720825195
time: 2.2535037994384766
[1, 548] loss_train: 0.007492, loss_test: 0.006376
time: 0.2470545768737793
time: 2.211005926132202
[1, 549] loss_train: 0.002628, loss_test: 0.006367
time: 0.2850635051727295
time: 2.2770137786865234
[1, 550] loss_train: 0.005600, loss_test: 0.006363
time: 0.25305652618408203
time: 2.2347302436828613
[1, 551] loss_train: 0.009674, loss_test: 0.006361
time: 0.24505400657653809
time: 2.265507459640503
[1, 552] loss_train: 0.001817, loss_test: 0.006365
time: 0.2470541000366211
time: 2.2605059146881104
[1, 553] loss_train: 0.001270, loss_test: 0.006379
time: 0.24605512619018555
time: 2.2845115661621094
[1, 554] loss_train: 0.008366, loss_test: 0.006386
time: 0.2666299343109131
time: 2.2725088596343994
[1, 555] loss_train: 0.014158, loss_test: 0.006364
time: 0.24805474281311035
time: 2.306525468826294
[1, 556] loss_train: 0.003982, loss_test: 0.006349
time: 0.265059232711792
time: 2.3625283241271973
[1, 557] loss_train: 0.005317, loss_test: 0.006338
time: 0.2510554790496826
time: 2.370530605316162
[1, 558] loss_train: 0.004407, loss_test: 0.006334
time: 0.29006457328796387
time: 2.3205177783966064
[1, 559] loss_train: 0.004078, loss_test: 0.006335
time: 0.24605655670166016
time: 2.287513256072998
[1, 560] loss_train: 0.002077, loss_test: 0.006333
time: 0.2760615348815918
time: 2.326521396636963
[1, 561] loss_train: 0.005028, loss_test: 0.006330
time: 0.2710599899291992
time: 2.3525259494781494
[1, 562] loss_train: 0.008215, loss_test: 0.006331
time: 0.2580578327178955
time: 2.3295202255249023
[1, 563] loss_train: 0.003897, loss_test: 0.006332
time: 0.25305819511413574
time: 2.256504774093628
[1, 564] loss_train: 0.002819, loss_test: 0.006331
time: 0.24405360221862793
time: 2.258505344390869
[1, 565] loss_train: 0.009284, loss_test: 0.006333
time: 0.25005531311035156
time: 2.3015153408050537
[1, 566] loss_train: 0.006104, loss_test: 0.006334
time: 0.2520573139190674
time: 2.238499164581299
[1, 567] loss_train: 0.003742, loss_test: 0.006335
time: 0.24305462837219238
time: 2.2555060386657715
[1, 568] loss_train: 0.009743, loss_test: 0.006334
time: 0.24205327033996582
time: 2.304518222808838
[1, 569] loss_train: 0.002647, loss_test: 0.006328
time: 0.26105761528015137
time: 2.267507314682007
[1, 570] loss_train: 0.007396, loss_test: 0.006321
time: 0.2670631408691406
time: 2.3565268516540527
[1, 571] loss_train: 0.008608, loss_test: 0.006317
time: 0.25005483627319336
time: 2.267507791519165
[1, 572] loss_train: 0.001913, loss_test: 0.006316
time: 0.24305415153503418
time: 2.234501838684082
[1, 573] loss_train: 0.008414, loss_test: 0.006318
time: 0.24605631828308105
time: 2.2484211921691895
[1, 574] loss_train: 0.009473, loss_test: 0.006317
time: 0.2510552406311035
time: 2.292512893676758
[1, 575] loss_train: 0.004233, loss_test: 0.006317
time: 0.24355745315551758
time: 2.246041774749756
[1, 576] loss_train: 0.001653, loss_test: 0.006319
time: 0.24405431747436523
time: 2.267507314682007
[1, 577] loss_train: 0.018716, loss_test: 0.006301
time: 0.24305486679077148
time: 2.413538694381714
[1, 578] loss_train: 0.004978, loss_test: 0.006296
time: 0.2630581855773926
time: 2.3885338306427
[1, 579] loss_train: 0.007482, loss_test: 0.006302
time: 0.24605512619018555
time: 2.2605082988739014
[1, 580] loss_train: 0.003077, loss_test: 0.006308
time: 0.254056453704834
time: 2.2565207481384277
[1, 581] loss_train: 0.012552, loss_test: 0.006321
time: 0.24406766891479492
time: 2.4495511054992676
[1, 582] loss_train: 0.008876, loss_test: 0.006339
time: 0.367081880569458
time: 2.4945576190948486
[1, 583] loss_train: 0.006864, loss_test: 0.006355
time: 0.24405431747436523
time: 2.345524549484253
[1, 584] loss_train: 0.003142, loss_test: 0.006364
time: 0.24605417251586914
time: 2.2264983654022217
[1, 585] loss_train: 0.010312, loss_test: 0.006392
time: 0.24105167388916016
time: 2.2635061740875244
[1, 586] loss_train: 0.004010, loss_test: 0.006402
time: 0.24405455589294434
time: 2.2555038928985596
[1, 587] loss_train: 0.005414, loss_test: 0.006401
time: 0.24405574798583984
time: 2.2735140323638916
[1, 588] loss_train: 0.008638, loss_test: 0.006385
time: 0.24405527114868164
time: 2.2605044841766357
[1, 589] loss_train: 0.010104, loss_test: 0.006365
time: 0.24305319786071777
time: 2.231499671936035
[1, 590] loss_train: 0.006976, loss_test: 0.006350
time: 0.254561185836792
time: 2.23449969291687
[1, 591] loss_train: 0.007088, loss_test: 0.006337
time: 0.24305391311645508
time: 2.2253639698028564
[1, 592] loss_train: 0.011221, loss_test: 0.006324
time: 0.24605464935302734
time: 2.352031707763672
[1, 593] loss_train: 0.006689, loss_test: 0.006319
time: 0.24305391311645508
time: 2.2395167350769043
[1, 594] loss_train: 0.010694, loss_test: 0.006321
time: 0.24605464935302734
time: 2.2385005950927734
[1, 595] loss_train: 0.010322, loss_test: 0.006318
time: 0.24205350875854492
time: 2.228512763977051
[1, 596] loss_train: 0.005902, loss_test: 0.006319
time: 0.24205327033996582
time: 2.2244980335235596
[1, 597] loss_train: 0.005319, loss_test: 0.006321
time: 0.2400531768798828
time: 2.227499008178711
[1, 598] loss_train: 0.009148, loss_test: 0.006320
time: 0.24205279350280762
time: 2.2094948291778564
[1, 599] loss_train: 0.005530, loss_test: 0.006320
time: 0.24205398559570312
time: 2.2090189456939697
[1, 600] loss_train: 0.008251, loss_test: 0.006320
time: 0.25305628776550293
time: 2.23349928855896
[1, 601] loss_train: 0.005662, loss_test: 0.006311
time: 0.24405956268310547
time: 2.2670555114746094
[1, 602] loss_train: 0.008119, loss_test: 0.006294
time: 0.2520558834075928
time: 2.349045515060425
[1, 603] loss_train: 0.002883, loss_test: 0.006283
time: 0.24405431747436523
time: 2.249502658843994
[1, 604] loss_train: 0.013084, loss_test: 0.006278
time: 0.24305415153503418
time: 2.231498956680298
[1, 605] loss_train: 0.006554, loss_test: 0.006277
time: 0.24305438995361328
time: 2.2405006885528564
[1, 606] loss_train: 0.002584, loss_test: 0.006278
time: 0.24305391311645508
time: 2.305032730102539
[1, 607] loss_train: 0.005276, loss_test: 0.006281
time: 0.24205398559570312
time: 2.2415010929107666
[1, 608] loss_train: 0.006031, loss_test: 0.006285
time: 0.24305415153503418
time: 2.2024919986724854
[1, 609] loss_train: 0.004410, loss_test: 0.006293
time: 0.24205493927001953
time: 2.2285006046295166
[1, 610] loss_train: 0.004252, loss_test: 0.006298
time: 0.25305652618408203
time: 2.2435009479522705
[1, 611] loss_train: 0.012953, loss_test: 0.006308
time: 0.24605512619018555
time: 2.2775120735168457
[1, 612] loss_train: 0.007598, loss_test: 0.006320
time: 0.3230714797973633
time: 2.2505064010620117
[1, 613] loss_train: 0.004326, loss_test: 0.006335
time: 0.24205374717712402
time: 2.2395005226135254
[1, 614] loss_train: 0.006948, loss_test: 0.006344
time: 0.24406766891479492
time: 2.4275426864624023
[1, 615] loss_train: 0.001024, loss_test: 0.006350
time: 0.24805593490600586
time: 2.2535035610198975
[1, 616] loss_train: 0.011735, loss_test: 0.006361
time: 0.24205398559570312
time: 2.2254974842071533
[1, 617] loss_train: 0.004046, loss_test: 0.006341
time: 0.24205327033996582
time: 2.3135287761688232
[1, 618] loss_train: 0.007839, loss_test: 0.006320
time: 0.2510557174682617
time: 2.3715438842773438
[1, 619] loss_train: 0.004509, loss_test: 0.006294
time: 0.2470555305480957
time: 2.2134952545166016
[1, 620] loss_train: 0.001888, loss_test: 0.006277
time: 0.25705718994140625
time: 2.2254979610443115
[1, 621] loss_train: 0.010974, loss_test: 0.006268
time: 0.24105286598205566
time: 2.216496229171753
[1, 622] loss_train: 0.017054, loss_test: 0.006263
time: 0.24205303192138672
time: 2.2224977016448975
[1, 623] loss_train: 0.001954, loss_test: 0.006259
time: 0.24305343627929688
time: 2.2204980850219727
[1, 624] loss_train: 0.005656, loss_test: 0.006253
time: 0.2490549087524414
time: 2.231498956680298
[1, 625] loss_train: 0.006243, loss_test: 0.006249
time: 0.3320732116699219
time: 2.2495036125183105
[1, 626] loss_train: 0.004974, loss_test: 0.006248
time: 0.24605441093444824
time: 2.2475028038024902
[1, 627] loss_train: 0.003486, loss_test: 0.006250
time: 0.24305367469787598
time: 2.356515645980835
[1, 628] loss_train: 0.004385, loss_test: 0.006262
time: 0.2450544834136963
time: 2.438544511795044
[1, 629] loss_train: 0.011435, loss_test: 0.006271
time: 0.38110876083374023
time: 2.302522897720337
[1, 630] loss_train: 0.006352, loss_test: 0.006280
time: 0.25305604934692383
time: 2.2615060806274414
[1, 631] loss_train: 0.007739, loss_test: 0.006289
time: 0.24405407905578613
time: 2.230501413345337
[1, 632] loss_train: 0.004139, loss_test: 0.006302
time: 0.24606776237487793
time: 2.2254979610443115
[1, 633] loss_train: 0.005295, loss_test: 0.006313
time: 0.24305391311645508
time: 2.2084944248199463
[1, 634] loss_train: 0.011628, loss_test: 0.006307
time: 0.24305343627929688
time: 2.2585055828094482
[1, 635] loss_train: 0.008964, loss_test: 0.006300
time: 0.24605464935302734
time: 2.2735090255737305
[1, 636] loss_train: 0.010614, loss_test: 0.006294
time: 0.24805641174316406
time: 2.2254979610443115
[1, 637] loss_train: 0.006041, loss_test: 0.006292
time: 0.24405550956726074
time: 2.3005127906799316
[1, 638] loss_train: 0.006854, loss_test: 0.006297
time: 0.24605488777160645
time: 2.2365095615386963
[1, 639] loss_train: 0.011064, loss_test: 0.006302
time: 0.24105405807495117
time: 2.248502492904663
[1, 640] loss_train: 0.013153, loss_test: 0.006308
time: 0.25305628776550293
time: 2.2135109901428223
[1, 641] loss_train: 0.005383, loss_test: 0.006321
time: 0.2420663833618164
time: 2.339705228805542
[1, 642] loss_train: 0.006867, loss_test: 0.006324
time: 0.24805450439453125
time: 2.1994924545288086
[1, 643] loss_train: 0.012674, loss_test: 0.006333
time: 0.2410721778869629
time: 2.2480528354644775
[1, 644] loss_train: 0.010597, loss_test: 0.006340
time: 0.2400531768798828
time: 2.2045016288757324
[1, 645] loss_train: 0.006417, loss_test: 0.006333
time: 0.24205303192138672
time: 2.215496063232422
[1, 646] loss_train: 0.005788, loss_test: 0.006313
time: 0.24205327033996582
time: 2.242502212524414
[1, 647] loss_train: 0.002302, loss_test: 0.006287
time: 0.24405360221862793
time: 2.2495033740997314
[1, 648] loss_train: 0.007376, loss_test: 0.006264
time: 0.2490556240081787
time: 2.2284982204437256
[1, 649] loss_train: 0.007154, loss_test: 0.006252
time: 0.2450547218322754
time: 2.229498863220215
[1, 650] loss_train: 0.007559, loss_test: 0.006251
time: 0.25305628776550293
time: 2.2245054244995117
[1, 651] loss_train: 0.010953, loss_test: 0.006256
time: 0.24205279350280762
time: 2.343397617340088
[1, 652] loss_train: 0.010527, loss_test: 0.006260
time: 0.24205374717712402
time: 2.2264983654022217
[1, 653] loss_train: 0.003335, loss_test: 0.006264
time: 0.24305367469787598
time: 2.2325000762939453
[1, 654] loss_train: 0.003162, loss_test: 0.006273
time: 0.24805498123168945
time: 2.196491003036499
[1, 655] loss_train: 0.006128, loss_test: 0.006285
time: 0.29306507110595703
time: 2.337552309036255
[1, 656] loss_train: 0.008633, loss_test: 0.006288
time: 0.2420661449432373
time: 2.202786922454834
[1, 657] loss_train: 0.008752, loss_test: 0.006293
time: 0.24205398559570312
time: 2.2024929523468018
[1, 658] loss_train: 0.015387, loss_test: 0.006270
time: 0.24205422401428223
time: 2.1919946670532227
[1, 659] loss_train: 0.021556, loss_test: 0.006248
time: 0.24205374717712402
time: 2.248504877090454
[1, 660] loss_train: 0.006589, loss_test: 0.006250
time: 0.2630581855773926
time: 2.264535903930664
[1, 661] loss_train: 0.010517, loss_test: 0.006281
time: 0.3310732841491699
time: 2.340536594390869
[1, 662] loss_train: 0.004029, loss_test: 0.006330
time: 0.2470545768737793
time: 2.2515039443969727
[1, 663] loss_train: 0.006602, loss_test: 0.006384
time: 0.24105310440063477
time: 2.2365007400512695
[1, 664] loss_train: 0.004942, loss_test: 0.006438
time: 0.24105381965637207
time: 2.236499786376953
[1, 665] loss_train: 0.006410, loss_test: 0.006473
time: 0.24205446243286133
time: 2.2555043697357178
[1, 666] loss_train: 0.009246, loss_test: 0.006490
time: 0.25705862045288086
time: 2.2825088500976562
[1, 667] loss_train: 0.006380, loss_test: 0.006482
time: 0.24405360221862793
time: 2.3290274143218994
[1, 668] loss_train: 0.004489, loss_test: 0.006452
time: 0.24305343627929688
time: 2.385537624359131
[1, 669] loss_train: 0.010545, loss_test: 0.006431
time: 0.2450544834136963
time: 2.2875123023986816
[1, 670] loss_train: 0.014061, loss_test: 0.006423
time: 0.258056640625
time: 2.242501974105835
[1, 671] loss_train: 0.005810, loss_test: 0.006406
time: 0.25006747245788574
time: 2.2715044021606445
[1, 672] loss_train: 0.012990, loss_test: 0.006398
time: 0.24755859375
time: 2.393566370010376
[1, 673] loss_train: 0.014480, loss_test: 0.006409
time: 0.2540557384490967
time: 2.2244977951049805
[1, 674] loss_train: 0.002991, loss_test: 0.006408
time: 0.24405360221862793
time: 2.2235124111175537
[1, 675] loss_train: 0.006196, loss_test: 0.006364
time: 0.2470543384552002
time: 2.217499017715454
[1, 676] loss_train: 0.016726, loss_test: 0.006327
time: 0.2450549602508545
time: 2.367532730102539
[1, 677] loss_train: 0.005163, loss_test: 0.006281
time: 0.24205374717712402
time: 2.2865123748779297
[1, 678] loss_train: 0.011003, loss_test: 0.006248
time: 0.24205708503723145
time: 2.2835116386413574
[1, 679] loss_train: 0.001347, loss_test: 0.006226
time: 0.24106550216674805
time: 2.193490743637085
[1, 680] loss_train: 0.007543, loss_test: 0.006220
time: 0.25305724143981934
time: 2.2505013942718506
[1, 681] loss_train: 0.005917, loss_test: 0.006228
time: 0.25705766677856445
time: 2.312551259994507
[1, 682] loss_train: 0.013781, loss_test: 0.006245
time: 0.25505685806274414
time: 2.248008966445923
[1, 683] loss_train: 0.008271, loss_test: 0.006264
time: 0.38808631896972656
time: 2.5195634365081787
[1, 684] loss_train: 0.021924, loss_test: 0.006236
time: 0.24305319786071777
time: 2.2475032806396484
[1, 685] loss_train: 0.003353, loss_test: 0.006225
time: 0.24305391311645508
time: 2.229498863220215
[1, 686] loss_train: 0.004899, loss_test: 0.006222
time: 0.35007739067077637
time: 2.244502544403076
[1, 687] loss_train: 0.005340, loss_test: 0.006224
time: 0.24305415153503418
time: 2.320521116256714
[1, 688] loss_train: 0.006559, loss_test: 0.006228
time: 0.35007786750793457
time: 2.349524736404419
[1, 689] loss_train: 0.009735, loss_test: 0.006228
time: 0.25408124923706055
time: 2.4365456104278564
[1, 690] loss_train: 0.009098, loss_test: 0.006228
time: 0.25505661964416504
time: 2.503331422805786
[1, 691] loss_train: 0.001155, loss_test: 0.006228
time: 0.24605488777160645
time: 2.235499858856201
[1, 692] loss_train: 0.003892, loss_test: 0.006228
time: 0.24305415153503418
time: 2.311516523361206
[1, 693] loss_train: 0.009679, loss_test: 0.006227
time: 0.24205350875854492
time: 2.2004928588867188
[1, 694] loss_train: 0.004415, loss_test: 0.006226
time: 0.24405431747436523
time: 2.284511089324951
[1, 695] loss_train: 0.001892, loss_test: 0.006226
time: 0.25505566596984863
time: 2.254504680633545
[1, 696] loss_train: 0.001548, loss_test: 0.006233
time: 0.24205327033996582
time: 2.2365009784698486
[1, 697] loss_train: 0.005742, loss_test: 0.006242
time: 0.24805474281311035
time: 2.243501901626587
[1, 698] loss_train: 0.007864, loss_test: 0.006245
time: 0.2540562152862549
time: 2.2745091915130615
[1, 699] loss_train: 0.001145, loss_test: 0.006255
time: 0.24405455589294434
time: 2.312516927719116
[1, 700] loss_train: 0.008318, loss_test: 0.006260
time: 0.27506113052368164
time: 2.3583202362060547
[1, 701] loss_train: 0.004978, loss_test: 0.006266
time: 0.2576942443847656
time: 2.260505437850952
[1, 702] loss_train: 0.004476, loss_test: 0.006274
time: 0.2490553855895996
time: 2.2875118255615234
[1, 703] loss_train: 0.005783, loss_test: 0.006278
time: 0.24405455589294434
time: 2.218496084213257
[1, 704] loss_train: 0.007414, loss_test: 0.006281
time: 0.25305700302124023
time: 2.323518991470337
[1, 705] loss_train: 0.004300, loss_test: 0.006288
time: 0.2580571174621582
time: 2.259505271911621
[1, 706] loss_train: 0.007823, loss_test: 0.006280
time: 0.25305604934692383
time: 2.2745089530944824
[1, 707] loss_train: 0.018725, loss_test: 0.006234
time: 0.26605939865112305
time: 2.2635061740875244
[1, 708] loss_train: 0.008364, loss_test: 0.006217
time: 0.2490549087524414
time: 2.3215200901031494
[1, 709] loss_train: 0.010759, loss_test: 0.006235
time: 0.27306056022644043
time: 2.2415010929107666
[1, 710] loss_train: 0.010210, loss_test: 0.006285
time: 0.2540566921234131
time: 2.259505033493042
[1, 711] loss_train: 0.006911, loss_test: 0.006330
time: 0.25305652618408203
time: 2.3175182342529297
[1, 712] loss_train: 0.004252, loss_test: 0.006333
time: 0.2540562152862549
time: 2.2625062465667725
[1, 713] loss_train: 0.007760, loss_test: 0.006335
time: 0.254056453704834
time: 2.332521438598633
[1, 714] loss_train: 0.003693, loss_test: 0.006325
time: 0.25005507469177246
time: 2.3225197792053223
[1, 715] loss_train: 0.003713, loss_test: 0.006291
time: 0.2560572624206543
time: 2.3575291633605957
[1, 716] loss_train: 0.003066, loss_test: 0.006252
time: 0.24805593490600586
time: 2.2585060596466064
[1, 717] loss_train: 0.010636, loss_test: 0.006225
time: 0.2450544834136963
time: 2.270510196685791
[1, 718] loss_train: 0.003459, loss_test: 0.006204
time: 0.24405336380004883
time: 2.292999029159546
[1, 719] loss_train: 0.006228, loss_test: 0.006195
time: 0.2450547218322754
time: 2.2855114936828613
[1, 720] loss_train: 0.009166, loss_test: 0.006196
time: 0.2580578327178955
time: 2.344524383544922
[1, 721] loss_train: 0.004407, loss_test: 0.006201
time: 0.2470550537109375
time: 2.2945125102996826
[1, 722] loss_train: 0.006572, loss_test: 0.006211
time: 0.2490556240081787
time: 2.255518674850464
[1, 723] loss_train: 0.006776, loss_test: 0.006217
time: 0.24505376815795898
time: 2.291522741317749
[1, 724] loss_train: 0.003124, loss_test: 0.006227
time: 0.2490556240081787
time: 2.2735095024108887
[1, 725] loss_train: 0.014928, loss_test: 0.006230
time: 0.2600581645965576
time: 2.3225221633911133
[1, 726] loss_train: 0.003854, loss_test: 0.006236
time: 0.2580573558807373
time: 2.2925126552581787
[1, 727] loss_train: 0.002782, loss_test: 0.006244
time: 0.2490549087524414
time: 2.3425240516662598
[1, 728] loss_train: 0.002038, loss_test: 0.006251
time: 0.2650589942932129
time: 2.3755314350128174
[1, 729] loss_train: 0.001733, loss_test: 0.006259
time: 0.2510561943054199
time: 2.3185184001922607
[1, 730] loss_train: 0.005651, loss_test: 0.006267
time: 0.25705695152282715
time: 2.291512966156006
[1, 731] loss_train: 0.003876, loss_test: 0.006278
time: 0.25005531311035156
time: 2.2615060806274414
[1, 732] loss_train: 0.002220, loss_test: 0.006288
time: 0.2690589427947998
time: 2.344527244567871
[1, 733] loss_train: 0.006928, loss_test: 0.006300
time: 0.2510559558868408
time: 2.308520555496216
[1, 734] loss_train: 0.008733, loss_test: 0.006304
time: 0.2450566291809082
time: 2.3175179958343506
[1, 735] loss_train: 0.007605, loss_test: 0.006310
time: 0.24605441093444824
time: 2.3345224857330322
[1, 736] loss_train: 0.005276, loss_test: 0.006317
time: 0.2510561943054199
time: 2.3385226726531982
[1, 737] loss_train: 0.001452, loss_test: 0.006328
time: 0.26806020736694336
time: 2.299513816833496
[1, 738] loss_train: 0.001741, loss_test: 0.006345
time: 0.24805569648742676
time: 2.2785093784332275
[1, 739] loss_train: 0.003581, loss_test: 0.006352
time: 0.2800617218017578
time: 2.304515838623047
[1, 740] loss_train: 0.003703, loss_test: 0.006359
time: 0.26105761528015137
time: 2.2635066509246826
[1, 741] loss_train: 0.017777, loss_test: 0.006316
time: 0.2470552921295166
time: 2.235502004623413
[1, 742] loss_train: 0.006772, loss_test: 0.006274
time: 0.2600579261779785
time: 2.2775087356567383
[1, 743] loss_train: 0.008922, loss_test: 0.006236
time: 0.24605536460876465
time: 2.2885115146636963
[1, 744] loss_train: 0.006810, loss_test: 0.006218
time: 0.2490549087524414
time: 2.292512893676758
[1, 745] loss_train: 0.006620, loss_test: 0.006218
time: 0.2470552921295166
time: 2.3525259494781494
[1, 746] loss_train: 0.007367, loss_test: 0.006229
time: 0.2780628204345703
time: 2.4480535984039307
[1, 747] loss_train: 0.005547, loss_test: 0.006247
time: 0.2890646457672119
time: 2.3445398807525635
[1, 748] loss_train: 0.003502, loss_test: 0.006260
time: 0.26105809211730957
time: 2.361527919769287
[1, 749] loss_train: 0.005851, loss_test: 0.006263
time: 0.2530558109283447
time: 2.2545220851898193
[1, 750] loss_train: 0.007116, loss_test: 0.006259
time: 0.2980659008026123
time: 2.3390262126922607
[1, 751] loss_train: 0.011498, loss_test: 0.006261
time: 0.24805450439453125
time: 2.234499454498291
[1, 752] loss_train: 0.014687, loss_test: 0.006277
time: 0.25205516815185547
time: 2.290512800216675
[1, 753] loss_train: 0.006488, loss_test: 0.006285
time: 0.24905681610107422
time: 2.273508071899414
[1, 754] loss_train: 0.003106, loss_test: 0.006276
time: 0.2510552406311035
time: 2.272521734237671
[1, 755] loss_train: 0.015895, loss_test: 0.006262
time: 0.25305676460266113
time: 2.287510871887207
[1, 756] loss_train: 0.009250, loss_test: 0.006246
time: 0.25705718994140625
time: 2.344524383544922
[1, 757] loss_train: 0.010304, loss_test: 0.006223
time: 0.24605417251586914
time: 2.266115188598633
[1, 758] loss_train: 0.004717, loss_test: 0.006202
time: 0.2520558834075928
time: 2.3005146980285645
[1, 759] loss_train: 0.007568, loss_test: 0.006190
time: 0.2470545768737793
time: 2.2835192680358887
[1, 760] loss_train: 0.004689, loss_test: 0.006188
time: 0.25706028938293457
time: 2.372037172317505
[1, 761] loss_train: 0.008070, loss_test: 0.006198
time: 0.2540585994720459
time: 2.3015148639678955
[1, 762] loss_train: 0.002090, loss_test: 0.006222
time: 0.2630574703216553
time: 2.338536500930786
[1, 763] loss_train: 0.017176, loss_test: 0.006223
time: 0.25305604934692383
time: 2.43005108833313
[1, 764] loss_train: 0.013035, loss_test: 0.006210
time: 0.2470555305480957
time: 2.3085169792175293
[1, 765] loss_train: 0.009003, loss_test: 0.006196
time: 0.27505946159362793
time: 2.255009651184082
[1, 766] loss_train: 0.002149, loss_test: 0.006191
time: 0.24805498123168945
time: 2.3345251083374023
[1, 767] loss_train: 0.006210, loss_test: 0.006187
time: 0.26605916023254395
time: 2.25850510597229
[1, 768] loss_train: 0.017001, loss_test: 0.006182
time: 0.2520565986633301
time: 2.251502513885498
[1, 769] loss_train: 0.004422, loss_test: 0.006187
time: 0.247056245803833
time: 2.2695064544677734
[1, 770] loss_train: 0.004237, loss_test: 0.006191
time: 0.2600586414337158
time: 2.308516025543213
[1, 771] loss_train: 0.006103, loss_test: 0.006195
time: 0.2510561943054199
time: 2.3525259494781494
[1, 772] loss_train: 0.009163, loss_test: 0.006200
time: 0.2490553855895996
time: 2.3205180168151855
[1, 773] loss_train: 0.006052, loss_test: 0.006203
time: 0.24605488777160645
time: 2.253504991531372
[1, 774] loss_train: 0.009747, loss_test: 0.006210
time: 0.26205873489379883
time: 2.299514055252075
[1, 775] loss_train: 0.003771, loss_test: 0.006213
time: 0.24505400657653809
time: 2.337523937225342
[1, 776] loss_train: 0.005138, loss_test: 0.006214
time: 0.27906155586242676
time: 2.317112684249878
[1, 777] loss_train: 0.013969, loss_test: 0.006220
time: 0.24505400657653809
time: 2.2465033531188965
[1, 778] loss_train: 0.001941, loss_test: 0.006225
time: 0.24505329132080078
time: 2.289512872695923
[1, 779] loss_train: 0.005299, loss_test: 0.006215
time: 0.2490553855895996
time: 2.2505035400390625
[1, 780] loss_train: 0.003913, loss_test: 0.006204
time: 0.25905942916870117
time: 2.4025394916534424
[1, 781] loss_train: 0.006397, loss_test: 0.006201
time: 0.24405384063720703
time: 2.2965140342712402
[1, 782] loss_train: 0.010169, loss_test: 0.006197
time: 0.24305415153503418
time: 2.2535035610198975
[1, 783] loss_train: 0.006141, loss_test: 0.006198
time: 0.267059326171875
time: 2.3395235538482666
[1, 784] loss_train: 0.007025, loss_test: 0.006202
time: 0.24605488777160645
time: 2.286510705947876
[1, 785] loss_train: 0.007860, loss_test: 0.006195
time: 0.2600572109222412
time: 2.241501808166504
[1, 786] loss_train: 0.001430, loss_test: 0.006195
time: 0.24605488777160645
time: 2.269507646560669
[1, 787] loss_train: 0.010062, loss_test: 0.006192
time: 0.24605441093444824
time: 2.3405237197875977
[1, 788] loss_train: 0.009291, loss_test: 0.006189
time: 0.25005602836608887
time: 2.3105170726776123
[1, 789] loss_train: 0.005463, loss_test: 0.006195
time: 0.2450551986694336
time: 2.2264997959136963
[1, 790] loss_train: 0.013147, loss_test: 0.006204
time: 0.2600569725036621
time: 2.2495031356811523
[1, 791] loss_train: 0.006868, loss_test: 0.006218
time: 0.2450573444366455
time: 2.296510934829712
[1, 792] loss_train: 0.012702, loss_test: 0.006238
time: 0.25005578994750977
time: 2.337522506713867
[1, 793] loss_train: 0.006253, loss_test: 0.006257
time: 0.24905657768249512
time: 2.260505199432373
[1, 794] loss_train: 0.005478, loss_test: 0.006262
time: 0.24605441093444824
time: 2.2725086212158203
[1, 795] loss_train: 0.004656, loss_test: 0.006257
time: 0.2450549602508545
time: 2.3645310401916504
[1, 796] loss_train: 0.006755, loss_test: 0.006245
time: 0.2550473213195801
time: 2.3055176734924316
[1, 797] loss_train: 0.003691, loss_test: 0.006226
time: 0.24905610084533691
time: 2.343484878540039
[1, 798] loss_train: 0.009143, loss_test: 0.006222
time: 0.2490551471710205
time: 2.3965365886688232
[1, 799] loss_train: 0.002594, loss_test: 0.006211
time: 0.2890644073486328
time: 2.396535873413086
[1, 800] loss_train: 0.002716, loss_test: 0.006196
time: 0.27205991744995117
time: 2.3235204219818115
[1, 801] loss_train: 0.014301, loss_test: 0.006191
time: 0.256056547164917
time: 2.2975192070007324
[1, 802] loss_train: 0.004479, loss_test: 0.006188
time: 0.2620577812194824
time: 2.302520513534546
[1, 803] loss_train: 0.011141, loss_test: 0.006192
time: 0.31669092178344727
time: 2.2985141277313232
[1, 804] loss_train: 0.006308, loss_test: 0.006197
time: 0.2540566921234131
time: 2.3745312690734863
[1, 805] loss_train: 0.013262, loss_test: 0.006203
time: 0.24405455589294434
time: 2.2819344997406006
[1, 806] loss_train: 0.007690, loss_test: 0.006215
time: 0.28406524658203125
time: 2.321027994155884
[1, 807] loss_train: 0.002676, loss_test: 0.006220
time: 0.2416081428527832
time: 2.211421251296997
[1, 808] loss_train: 0.005624, loss_test: 0.006225
time: 0.2580575942993164
time: 2.2745089530944824
[1, 809] loss_train: 0.009863, loss_test: 0.006226
time: 0.24305391311645508
time: 2.2520079612731934
[1, 810] loss_train: 0.002083, loss_test: 0.006215
time: 0.254056453704834
time: 2.274507999420166
[1, 811] loss_train: 0.014765, loss_test: 0.006205
time: 0.2470552921295166
time: 2.2465031147003174
[1, 812] loss_train: 0.003758, loss_test: 0.006191
time: 0.25205540657043457
time: 2.241501808166504
[1, 813] loss_train: 0.007849, loss_test: 0.006181
time: 0.24205350875854492
time: 2.2765088081359863
[1, 814] loss_train: 0.008923, loss_test: 0.006176
time: 0.25705814361572266
time: 2.2405009269714355
[1, 815] loss_train: 0.007212, loss_test: 0.006175
time: 0.2510557174682617
time: 2.2535040378570557
[1, 816] loss_train: 0.013388, loss_test: 0.006176
time: 0.24105477333068848
time: 2.2465031147003174
[1, 817] loss_train: 0.007592, loss_test: 0.006185
time: 0.2470543384552002
time: 2.2665228843688965
[1, 818] loss_train: 0.004702, loss_test: 0.006195
time: 0.2520565986633301
time: 2.270507335662842
[1, 819] loss_train: 0.001292, loss_test: 0.006198
time: 0.24805665016174316
time: 2.2475011348724365
[1, 820] loss_train: 0.008539, loss_test: 0.006202
time: 0.25505781173706055
time: 2.2605056762695312
[1, 821] loss_train: 0.002501, loss_test: 0.006202
time: 0.24566435813903809
time: 2.2555065155029297
[1, 822] loss_train: 0.014315, loss_test: 0.006217
time: 0.24305391311645508
time: 2.2615060806274414
[1, 823] loss_train: 0.004336, loss_test: 0.006234
time: 0.25005507469177246
time: 2.2515032291412354
[1, 824] loss_train: 0.007085, loss_test: 0.006252
time: 0.278062105178833
time: 2.232041358947754
[1, 825] loss_train: 0.008745, loss_test: 0.006265
time: 0.24305343627929688
time: 2.2495126724243164
[1, 826] loss_train: 0.009468, loss_test: 0.006272
time: 0.3140702247619629
time: 2.2925126552581787
[1, 827] loss_train: 0.013708, loss_test: 0.006278
time: 0.2470548152923584
time: 2.267507314682007
[1, 828] loss_train: 0.007064, loss_test: 0.006283
time: 0.24105358123779297
time: 2.2665064334869385
[1, 829] loss_train: 0.005866, loss_test: 0.006290
time: 0.2830631732940674
time: 2.311516523361206
[1, 830] loss_train: 0.008529, loss_test: 0.006304
time: 0.2600581645965576
time: 2.2254979610443115
[1, 831] loss_train: 0.010243, loss_test: 0.006294
time: 0.24505352973937988
time: 2.2945199012756348
[1, 832] loss_train: 0.005518, loss_test: 0.006287
time: 0.24305510520935059
time: 2.2405009269714355
[1, 833] loss_train: 0.011969, loss_test: 0.006284
time: 0.24305415153503418
time: 2.2034928798675537
[1, 834] loss_train: 0.002532, loss_test: 0.006245
time: 0.24205398559570312
time: 2.2024919986724854
[1, 835] loss_train: 0.018491, loss_test: 0.006230
time: 0.24305438995361328
time: 2.2009975910186768
[1, 836] loss_train: 0.009539, loss_test: 0.006218
time: 0.24405455589294434
time: 2.2254977226257324
[1, 837] loss_train: 0.003851, loss_test: 0.006209
time: 0.2450544834136963
time: 2.246535301208496
[1, 838] loss_train: 0.013368, loss_test: 0.006220
time: 0.24106597900390625
time: 2.2225143909454346
[1, 839] loss_train: 0.008301, loss_test: 0.006233
time: 0.24305319786071777
time: 2.21551251411438
[1, 840] loss_train: 0.005428, loss_test: 0.006243
time: 0.25305628776550293
time: 2.24603271484375
[1, 841] loss_train: 0.004182, loss_test: 0.006232
time: 0.24205374717712402
time: 2.246501922607422
[1, 842] loss_train: 0.004824, loss_test: 0.006219
time: 0.24105334281921387
time: 2.2385008335113525
[1, 843] loss_train: 0.009079, loss_test: 0.006205
time: 0.24105262756347656
time: 2.237501382827759
[1, 844] loss_train: 0.006806, loss_test: 0.006201
time: 0.24105310440063477
time: 2.2074930667877197
[1, 845] loss_train: 0.009296, loss_test: 0.006198
time: 0.24105429649353027
time: 2.2134947776794434
[1, 846] loss_train: 0.008554, loss_test: 0.006192
time: 0.24306559562683105
time: 2.216001033782959
[1, 847] loss_train: 0.001592, loss_test: 0.006189
time: 0.24205446243286133
time: 2.2265024185180664
[1, 848] loss_train: 0.007088, loss_test: 0.006187
time: 0.24405241012573242
time: 2.250502586364746
[1, 849] loss_train: 0.001428, loss_test: 0.006191
time: 0.24405431747436523
time: 2.2615067958831787
[1, 850] loss_train: 0.002556, loss_test: 0.006205
time: 0.26105809211730957
time: 2.24150013923645
[1, 851] loss_train: 0.000832, loss_test: 0.006230
time: 0.24206328392028809
time: 2.3525261878967285
[1, 852] loss_train: 0.007884, loss_test: 0.006239
time: 0.27506113052368164
time: 2.4055380821228027
[1, 853] loss_train: 0.005072, loss_test: 0.006249
time: 0.24605512619018555
time: 2.249502658843994
[1, 854] loss_train: 0.017644, loss_test: 0.006218
time: 0.2540559768676758
time: 2.2665061950683594
[1, 855] loss_train: 0.001228, loss_test: 0.006211
time: 0.283062219619751
time: 2.217496156692505
[1, 856] loss_train: 0.007220, loss_test: 0.006212
time: 0.24405479431152344
time: 2.329331398010254
[1, 857] loss_train: 0.011174, loss_test: 0.006226
time: 0.2682945728302002
time: 2.3995401859283447
[1, 858] loss_train: 0.001085, loss_test: 0.006255
time: 0.24306988716125488
time: 2.3955345153808594
[1, 859] loss_train: 0.011745, loss_test: 0.006297
time: 0.24506783485412598
time: 2.2625064849853516
[1, 860] loss_train: 0.005237, loss_test: 0.006347
time: 0.3020668029785156
time: 2.381532907485962
[1, 861] loss_train: 0.010954, loss_test: 0.006411
time: 0.3110694885253906
time: 2.2335011959075928
[1, 862] loss_train: 0.003215, loss_test: 0.006454
time: 0.24405360221862793
time: 2.2134947776794434
[1, 863] loss_train: 0.014314, loss_test: 0.006461
time: 0.24305510520935059
time: 2.245222806930542
[1, 864] loss_train: 0.006278, loss_test: 0.006441
time: 0.24305510520935059
time: 2.2325046062469482
[1, 865] loss_train: 0.004756, loss_test: 0.006386
time: 0.2470550537109375
time: 2.217495918273926
[1, 866] loss_train: 0.009937, loss_test: 0.006339
time: 0.2470555305480957
time: 2.257504463195801
[1, 867] loss_train: 0.004194, loss_test: 0.006273
time: 0.24106860160827637
time: 2.2214975357055664
[1, 868] loss_train: 0.005552, loss_test: 0.006226
time: 0.2450544834136963
time: 2.270012617111206
[1, 869] loss_train: 0.003804, loss_test: 0.006200
time: 0.24205327033996582
time: 2.390536308288574
[1, 870] loss_train: 0.009195, loss_test: 0.006187
time: 0.2540559768676758
time: 2.242502212524414
[1, 871] loss_train: 0.009527, loss_test: 0.006177
time: 0.24306702613830566
time: 2.2314977645874023
[1, 872] loss_train: 0.004469, loss_test: 0.006176
time: 0.2450549602508545
time: 2.335524559020996
[1, 873] loss_train: 0.006702, loss_test: 0.006178
time: 0.24105334281921387
time: 2.209494113922119
[1, 874] loss_train: 0.005951, loss_test: 0.006184
time: 0.2420516014099121
time: 2.231501817703247
[1, 875] loss_train: 0.010794, loss_test: 0.006189
time: 0.24305343627929688
time: 2.3575568199157715
[1, 876] loss_train: 0.005236, loss_test: 0.006199
time: 0.33707523345947266
time: 2.333521842956543
[1, 877] loss_train: 0.002399, loss_test: 0.006214
time: 0.24606800079345703
time: 2.2415013313293457
[1, 878] loss_train: 0.004860, loss_test: 0.006234
time: 0.24405455589294434
time: 2.20949387550354
[1, 879] loss_train: 0.007330, loss_test: 0.006254
time: 0.2450547218322754
time: 2.1971850395202637
[1, 880] loss_train: 0.007153, loss_test: 0.006265
time: 0.254056453704834
time: 2.3445308208465576
[1, 881] loss_train: 0.008824, loss_test: 0.006268
time: 0.2690596580505371
time: 2.216496229171753
[1, 882] loss_train: 0.009847, loss_test: 0.006277
time: 0.24306726455688477
time: 2.226498603820801
[1, 883] loss_train: 0.007252, loss_test: 0.006281
time: 0.24205327033996582
time: 2.2260818481445312
[1, 884] loss_train: 0.011929, loss_test: 0.006277
time: 0.24306988716125488
time: 2.2385003566741943
[1, 885] loss_train: 0.005026, loss_test: 0.006265
time: 0.24605441093444824
time: 2.2124950885772705
[1, 886] loss_train: 0.001732, loss_test: 0.006256
time: 0.24305391311645508
time: 2.5905964374542236
[1, 887] loss_train: 0.005082, loss_test: 0.006248
time: 0.2620697021484375
time: 2.4420816898345947
[1, 888] loss_train: 0.005090, loss_test: 0.006242
time: 0.24805569648742676
time: 2.2565152645111084
[1, 889] loss_train: 0.007799, loss_test: 0.006238
time: 0.24405431747436523
time: 2.2385003566741943
[1, 890] loss_train: 0.005942, loss_test: 0.006235
time: 0.2540559768676758
time: 2.2174971103668213
[1, 891] loss_train: 0.006893, loss_test: 0.006233
time: 0.24305367469787598
time: 2.2114944458007812
[1, 892] loss_train: 0.011321, loss_test: 0.006225
time: 0.24305462837219238
time: 2.210493803024292
[1, 893] loss_train: 0.005773, loss_test: 0.006217
time: 0.24505400657653809
time: 2.2895123958587646
[1, 894] loss_train: 0.003197, loss_test: 0.006210
time: 0.28806376457214355
time: 2.309519052505493
[1, 895] loss_train: 0.005371, loss_test: 0.006207
time: 0.2580573558807373
time: 2.2255148887634277
[1, 896] loss_train: 0.002330, loss_test: 0.006206
time: 0.24305486679077148
time: 2.3365671634674072
[1, 897] loss_train: 0.018819, loss_test: 0.006191
time: 0.24305367469787598
time: 2.270508289337158
[1, 898] loss_train: 0.011437, loss_test: 0.006191
time: 0.24305343627929688
time: 2.291513204574585
[1, 899] loss_train: 0.005864, loss_test: 0.006204
time: 0.24605464935302734
time: 2.2545199394226074
[1, 900] loss_train: 0.012539, loss_test: 0.006234
time: 0.2580575942993164
time: 2.2375001907348633
[1, 901] loss_train: 0.003598, loss_test: 0.006261
time: 0.24205422401428223
time: 2.251502752304077
[1, 902] loss_train: 0.003721, loss_test: 0.006261
time: 0.2420670986175537
time: 2.2234997749328613
[1, 903] loss_train: 0.010549, loss_test: 0.006262
time: 0.24205446243286133
time: 2.235499382019043
[1, 904] loss_train: 0.005623, loss_test: 0.006259
time: 0.24305367469787598
time: 2.230499744415283
[1, 905] loss_train: 0.004020, loss_test: 0.006229
time: 0.24205350875854492
time: 2.245502233505249
[1, 906] loss_train: 0.001742, loss_test: 0.006195
time: 0.24405360221862793
time: 2.4485483169555664
[1, 907] loss_train: 0.007791, loss_test: 0.006172
time: 0.24405574798583984
time: 2.220496892929077
[1, 908] loss_train: 0.007717, loss_test: 0.006162
time: 0.24207210540771484
time: 2.230499744415283
[1, 909] loss_train: 0.004169, loss_test: 0.006162
time: 0.24405360221862793
time: 2.218496799468994
[1, 910] loss_train: 0.009166, loss_test: 0.006170
time: 0.25705718994140625
time: 2.2295010089874268
[1, 911] loss_train: 0.004262, loss_test: 0.006182
time: 0.24605464935302734
time: 2.2735085487365723
[1, 912] loss_train: 0.006536, loss_test: 0.006197
time: 0.2470543384552002
time: 2.216496229171753
[1, 913] loss_train: 0.006299, loss_test: 0.006206
time: 0.24405431747436523
time: 2.2395007610321045
[1, 914] loss_train: 0.021392, loss_test: 0.006217
time: 0.24605393409729004
time: 2.208496332168579
[1, 915] loss_train: 0.009470, loss_test: 0.006234
time: 0.24959707260131836
time: 2.236499547958374
[1, 916] loss_train: 0.011276, loss_test: 0.006265
time: 0.24205350875854492
time: 2.224506139755249
[1, 917] loss_train: 0.011519, loss_test: 0.006299
time: 0.24405336380004883
time: 2.231508493423462
[1, 918] loss_train: 0.013498, loss_test: 0.006337
time: 0.24205327033996582
time: 2.249513626098633
[1, 919] loss_train: 0.000510, loss_test: 0.006383
time: 0.24205327033996582
time: 2.211512804031372
[1, 920] loss_train: 0.005438, loss_test: 0.006412
time: 0.2540562152862549
time: 2.233499765396118
[1, 921] loss_train: 0.001004, loss_test: 0.006442
time: 0.24505400657653809
time: 2.255516290664673
[1, 922] loss_train: 0.002635, loss_test: 0.006466
time: 0.24105238914489746
time: 2.2605061531066895
[1, 923] loss_train: 0.011361, loss_test: 0.006445
time: 0.24205303192138672
time: 2.2064943313598633
[1, 924] loss_train: 0.001395, loss_test: 0.006417
time: 0.24206948280334473
time: 2.2595198154449463
[1, 925] loss_train: 0.008986, loss_test: 0.006350
time: 0.24005389213562012
time: 2.2164981365203857
[1, 926] loss_train: 0.005638, loss_test: 0.006294
time: 0.24105358123779297
time: 2.2425010204315186
[1, 927] loss_train: 0.007156, loss_test: 0.006259
time: 0.24305391311645508
time: 2.213512897491455
[1, 928] loss_train: 0.011074, loss_test: 0.006240
time: 0.24505400657653809
time: 2.2535061836242676
[1, 929] loss_train: 0.004617, loss_test: 0.006235
time: 0.24405384063720703
time: 2.2105014324188232
[1, 930] loss_train: 0.004491, loss_test: 0.006245
time: 0.25505661964416504
time: 2.2194983959198
[1, 931] loss_train: 0.018046, loss_test: 0.006237
time: 0.24405384063720703
time: 2.214496374130249
[1, 932] loss_train: 0.011441, loss_test: 0.006213
time: 0.24805426597595215
time: 2.254504680633545
[1, 933] loss_train: 0.008071, loss_test: 0.006196
time: 0.24405455589294434
time: 2.2415008544921875
[1, 934] loss_train: 0.011588, loss_test: 0.006179
time: 0.24405384063720703
time: 2.2495036125183105
[1, 935] loss_train: 0.006513, loss_test: 0.006169
time: 0.24605441093444824
time: 2.278524875640869
[1, 936] loss_train: 0.002583, loss_test: 0.006165
time: 0.2530558109283447
time: 2.220496892929077
[1, 937] loss_train: 0.014970, loss_test: 0.006162
time: 0.24305343627929688
time: 2.2260019779205322
[1, 938] loss_train: 0.007340, loss_test: 0.006165
time: 0.24205279350280762
time: 2.296513319015503
[1, 939] loss_train: 0.010587, loss_test: 0.006171
time: 0.24305367469787598
time: 2.3115289211273193
[1, 940] loss_train: 0.012413, loss_test: 0.006191
time: 0.26105785369873047
time: 2.2690110206604004
[1, 941] loss_train: 0.004483, loss_test: 0.006214
time: 0.24605369567871094
time: 2.2204973697662354
[1, 942] loss_train: 0.005242, loss_test: 0.006225
time: 0.24805450439453125
time: 2.2485036849975586
[1, 943] loss_train: 0.006953, loss_test: 0.006226
time: 0.24605417251586914
time: 2.2225098609924316
[1, 944] loss_train: 0.021413, loss_test: 0.006239
time: 0.24405455589294434
time: 2.236499547958374
[1, 945] loss_train: 0.011254, loss_test: 0.006255
time: 0.2470555305480957
time: 2.2515034675598145
[1, 946] loss_train: 0.013674, loss_test: 0.006277
time: 0.2450547218322754
time: 2.2415013313293457
[1, 947] loss_train: 0.008711, loss_test: 0.006272
time: 0.24605464935302734
time: 2.2645063400268555
[1, 948] loss_train: 0.013423, loss_test: 0.006266
time: 0.24205374717712402
time: 2.266507387161255
[1, 949] loss_train: 0.010843, loss_test: 0.006250
time: 0.24305343627929688
time: 2.2405014038085938
[1, 950] loss_train: 0.009423, loss_test: 0.006233
time: 0.25305652618408203
time: 2.275508403778076
[1, 951] loss_train: 0.005890, loss_test: 0.006208
time: 0.24205422401428223
time: 2.1994919776916504
[1, 952] loss_train: 0.015322, loss_test: 0.006198
time: 0.24305343627929688
time: 2.2545125484466553
[1, 953] loss_train: 0.002887, loss_test: 0.006198
time: 0.24305391311645508
time: 2.1984925270080566
[1, 954] loss_train: 0.011852, loss_test: 0.006210
time: 0.24305415153503418
time: 2.245501756668091
[1, 955] loss_train: 0.006697, loss_test: 0.006228
time: 0.24605441093444824
time: 2.2765095233917236
[1, 956] loss_train: 0.008159, loss_test: 0.006249
time: 0.24605441093444824
time: 2.276517391204834
[1, 957] loss_train: 0.004544, loss_test: 0.006266
time: 0.27905869483947754
time: 2.251006603240967
[1, 958] loss_train: 0.015522, loss_test: 0.006289
time: 0.24605393409729004
time: 2.2525036334991455
[1, 959] loss_train: 0.012758, loss_test: 0.006310
time: 0.25105834007263184
time: 2.26950740814209
[1, 960] loss_train: 0.001087, loss_test: 0.006333
time: 0.2580571174621582
time: 2.3265202045440674
[1, 961] loss_train: 0.011657, loss_test: 0.006355
time: 0.24805569648742676
time: 2.259010076522827
[1, 962] loss_train: 0.008059, loss_test: 0.006369
time: 0.24505376815795898
time: 2.2475035190582275
[1, 963] loss_train: 0.005495, loss_test: 0.006377
time: 0.24906706809997559
time: 2.2495036125183105
[1, 964] loss_train: 0.004071, loss_test: 0.006371
time: 0.24405407905578613
time: 2.2340142726898193
[1, 965] loss_train: 0.006444, loss_test: 0.006349
time: 0.24805450439453125
time: 2.254504442214966
[1, 966] loss_train: 0.005112, loss_test: 0.006330
time: 0.24305438995361328
time: 2.2294986248016357
[1, 967] loss_train: 0.006454, loss_test: 0.006309
time: 0.2450544834136963
time: 2.1904897689819336
[1, 968] loss_train: 0.005830, loss_test: 0.006292
time: 0.24305438995361328
time: 2.211494207382202
[1, 969] loss_train: 0.003867, loss_test: 0.006282
time: 0.24305438995361328
time: 2.246501922607422
[1, 970] loss_train: 0.009799, loss_test: 0.006273
time: 0.2555809020996094
time: 2.24301815032959
[1, 971] loss_train: 0.014118, loss_test: 0.006243
time: 0.24105429649353027
time: 2.223510265350342
[1, 972] loss_train: 0.007446, loss_test: 0.006217
time: 0.24205303192138672
time: 2.2164952754974365
[1, 973] loss_train: 0.005918, loss_test: 0.006195
time: 0.24305438995361328
time: 2.225497245788574
[1, 974] loss_train: 0.010441, loss_test: 0.006176
time: 0.24127507209777832
time: 2.2214980125427246
[1, 975] loss_train: 0.005545, loss_test: 0.006164
time: 0.24305343627929688
time: 2.1964914798736572
[1, 976] loss_train: 0.003871, loss_test: 0.006157
time: 0.24306631088256836
time: 2.2340052127838135
[1, 977] loss_train: 0.011381, loss_test: 0.006152
time: 0.24505376815795898
time: 2.251028060913086
[1, 978] loss_train: 0.002809, loss_test: 0.006153
time: 0.24405336380004883
time: 2.2074942588806152
[1, 979] loss_train: 0.004255, loss_test: 0.006155
time: 0.24205422401428223
time: 2.2385005950927734
[1, 980] loss_train: 0.002428, loss_test: 0.006156
time: 0.2620575428009033
time: 2.270508050918579
[1, 981] loss_train: 0.005293, loss_test: 0.006155
time: 0.24605464935302734
time: 2.257505178451538
[1, 982] loss_train: 0.002266, loss_test: 0.006155
time: 0.2510557174682617
time: 2.221510648727417
[1, 983] loss_train: 0.006577, loss_test: 0.006157
time: 0.24405455589294434
time: 2.2805099487304688
[1, 984] loss_train: 0.003124, loss_test: 0.006162
time: 0.247053861618042
time: 2.22649884223938
[1, 985] loss_train: 0.012500, loss_test: 0.006164
time: 0.24505329132080078
time: 2.2845115661621094
[1, 986] loss_train: 0.005268, loss_test: 0.006165
time: 0.2450544834136963
time: 2.2405033111572266
[1, 987] loss_train: 0.003313, loss_test: 0.006168
time: 0.24905633926391602
time: 2.240501642227173
[1, 988] loss_train: 0.001477, loss_test: 0.006175
time: 0.24505376815795898
time: 2.2718324661254883
[1, 989] loss_train: 0.002556, loss_test: 0.006182
time: 0.24605441093444824
time: 2.2665975093841553
[1, 990] loss_train: 0.010336, loss_test: 0.006182
time: 0.25905680656433105
time: 2.219496965408325
[1, 991] loss_train: 0.006464, loss_test: 0.006184
time: 0.24205398559570312
time: 2.2025063037872314
[1, 992] loss_train: 0.004115, loss_test: 0.006189
time: 0.24405407905578613
time: 2.2490086555480957
[1, 993] loss_train: 0.004834, loss_test: 0.006195
time: 0.24205327033996582
time: 2.1984925270080566
[1, 994] loss_train: 0.017928, loss_test: 0.006189
time: 0.24305319786071777
time: 2.2204997539520264
[1, 995] loss_train: 0.002699, loss_test: 0.006186
time: 0.24405360221862793
time: 2.229027271270752
[1, 996] loss_train: 0.013108, loss_test: 0.006175
time: 0.24106574058532715
time: 2.2405014038085938
[1, 997] loss_train: 0.010488, loss_test: 0.006168
time: 0.24605965614318848
time: 2.198721408843994
[1, 998] loss_train: 0.009390, loss_test: 0.006176
time: 0.24205422401428223
time: 2.2184958457946777
[1, 999] loss_train: 0.004181, loss_test: 0.006192
time: 0.24205398559570312
time: 2.249511957168579
[1, 1000] loss_train: 0.009884, loss_test: 0.006213
time: 0.2530555725097656
time: 2.2365009784698486
[1, 1001] loss_train: 0.008661, loss_test: 0.006236
time: 0.24305415153503418
time: 2.221223831176758
[1, 1002] loss_train: 0.005016, loss_test: 0.006249
time: 0.2410733699798584
time: 2.213494300842285
[1, 1003] loss_train: 0.006183, loss_test: 0.006259
time: 0.24205327033996582
time: 2.217496156692505
[1, 1004] loss_train: 0.009499, loss_test: 0.006259
time: 0.24105381965637207
time: 2.24005126953125
[1, 1005] loss_train: 0.004846, loss_test: 0.006253
time: 0.24205350875854492
time: 2.1964914798736572
[1, 1006] loss_train: 0.005461, loss_test: 0.006245
time: 0.24105405807495117
time: 2.2155063152313232
[1, 1007] loss_train: 0.003895, loss_test: 0.006236
time: 0.24405360221862793
time: 2.228501558303833
[1, 1008] loss_train: 0.004212, loss_test: 0.006243
time: 0.24507904052734375
time: 2.2024922370910645
[1, 1009] loss_train: 0.015578, loss_test: 0.006227
time: 0.24105310440063477
time: 2.242016553878784
[1, 1010] loss_train: 0.008318, loss_test: 0.006211
time: 0.2560572624206543
time: 2.234501361846924
[1, 1011] loss_train: 0.009871, loss_test: 0.006197
time: 0.24205422401428223
time: 2.234501361846924
[1, 1012] loss_train: 0.012958, loss_test: 0.006167
time: 0.24205374717712402
time: 2.216496229171753
[1, 1013] loss_train: 0.004855, loss_test: 0.006153
time: 0.24305367469787598
time: 2.227501153945923
[1, 1014] loss_train: 0.004971, loss_test: 0.006151
time: 0.24205541610717773
time: 2.210494041442871
[1, 1015] loss_train: 0.003434, loss_test: 0.006155
time: 0.24405455589294434
time: 2.2154955863952637
[1, 1016] loss_train: 0.002595, loss_test: 0.006159
time: 0.24205303192138672
time: 2.203493356704712
[1, 1017] loss_train: 0.002175, loss_test: 0.006161
time: 0.24306583404541016
time: 2.230499267578125
[1, 1018] loss_train: 0.007480, loss_test: 0.006163
time: 0.24205398559570312
time: 2.247502565383911
[1, 1019] loss_train: 0.002382, loss_test: 0.006173
time: 0.24305343627929688
time: 2.2094945907592773
[1, 1020] loss_train: 0.008315, loss_test: 0.006192
time: 0.25306057929992676
time: 2.228498935699463
[1, 1021] loss_train: 0.011978, loss_test: 0.006212
time: 0.24205350875854492
time: 2.2407870292663574
[1, 1022] loss_train: 0.008764, loss_test: 0.006225
time: 0.24405431747436523
time: 2.2314987182617188
[1, 1023] loss_train: 0.004307, loss_test: 0.006239
time: 0.24605536460876465
time: 2.2395007610321045
[1, 1024] loss_train: 0.006175, loss_test: 0.006250
time: 0.24505376815795898
time: 2.192995309829712
[1, 1025] loss_train: 0.021022, loss_test: 0.006222
time: 0.24205422401428223
time: 2.203495502471924
[1, 1026] loss_train: 0.013784, loss_test: 0.006199
time: 0.2490549087524414
time: 2.2164738178253174
[1, 1027] loss_train: 0.007903, loss_test: 0.006215
time: 0.24305415153503418
time: 2.2190232276916504
[1, 1028] loss_train: 0.010518, loss_test: 0.006268
time: 0.24205398559570312
time: 2.2384989261627197
[1, 1029] loss_train: 0.011252, loss_test: 0.006339
time: 0.24205422401428223
time: 2.2415010929107666
[1, 1030] loss_train: 0.007892, loss_test: 0.006390
time: 0.2560563087463379
time: 2.2395131587982178
[1, 1031] loss_train: 0.006525, loss_test: 0.006414
time: 0.24205398559570312
time: 2.2144949436187744
[1, 1032] loss_train: 0.004005, loss_test: 0.006361
time: 0.24205422401428223
time: 2.261531114578247
[1, 1033] loss_train: 0.007329, loss_test: 0.006303
time: 0.24305343627929688
time: 2.238506317138672
[1, 1034] loss_train: 0.007127, loss_test: 0.006244
time: 0.2450547218322754
time: 2.2264976501464844
[1, 1035] loss_train: 0.005532, loss_test: 0.006203
time: 0.24205327033996582
time: 2.2607409954071045
[1, 1036] loss_train: 0.004548, loss_test: 0.006185
time: 0.24205350875854492
time: 2.230499029159546
[1, 1037] loss_train: 0.007788, loss_test: 0.006183
time: 0.24405360221862793
time: 2.2230045795440674
[1, 1038] loss_train: 0.004194, loss_test: 0.006197
time: 0.24306726455688477
time: 2.2285008430480957
[1, 1039] loss_train: 0.001545, loss_test: 0.006221
time: 0.2515583038330078
time: 2.2355008125305176
[1, 1040] loss_train: 0.006898, loss_test: 0.006248
time: 0.2540736198425293
time: 2.2224974632263184
[1, 1041] loss_train: 0.007829, loss_test: 0.006272
time: 0.24405455589294434
time: 2.229499101638794
[1, 1042] loss_train: 0.006466, loss_test: 0.006289
time: 0.24205327033996582
time: 2.216496229171753
[1, 1043] loss_train: 0.004123, loss_test: 0.006304
time: 0.24605512619018555
time: 2.213493585586548
[1, 1044] loss_train: 0.007059, loss_test: 0.006313
time: 0.2470564842224121
time: 2.239499568939209
[1, 1045] loss_train: 0.004431, loss_test: 0.006327
time: 0.24405527114868164
time: 2.212507486343384
[1, 1046] loss_train: 0.005803, loss_test: 0.006342
time: 0.24305438995361328
time: 2.198491334915161
[1, 1047] loss_train: 0.005471, loss_test: 0.006352
time: 0.24205398559570312
time: 2.220498561859131
[1, 1048] loss_train: 0.022973, loss_test: 0.006322
time: 0.24605488777160645
time: 2.22249698638916
[1, 1049] loss_train: 0.004926, loss_test: 0.006297
time: 0.24205303192138672
time: 2.2134978771209717
[1, 1050] loss_train: 0.005558, loss_test: 0.006278
time: 0.2540566921234131
time: 2.2403316497802734
[1, 1051] loss_train: 0.008633, loss_test: 0.006257
time: 0.24205398559570312
time: 2.2104947566986084
[1, 1052] loss_train: 0.010891, loss_test: 0.006228
time: 0.24193644523620605
time: 2.2385029792785645
[1, 1053] loss_train: 0.006507, loss_test: 0.006204
time: 0.24205398559570312
time: 2.223497152328491
[1, 1054] loss_train: 0.011227, loss_test: 0.006180
time: 0.24205398559570312
time: 2.2294983863830566
[1, 1055] loss_train: 0.006962, loss_test: 0.006171
time: 0.24305415153503418
time: 2.206493377685547
[1, 1056] loss_train: 0.005577, loss_test: 0.006169
time: 0.24306774139404297
time: 2.235051393508911
[1, 1057] loss_train: 0.010045, loss_test: 0.006170
time: 0.24105405807495117
time: 2.241007089614868
[1, 1058] loss_train: 0.011692, loss_test: 0.006180
time: 0.24405407905578613
time: 2.207493782043457
[1, 1059] loss_train: 0.008102, loss_test: 0.006191
time: 0.24405336380004883
time: 2.223497152328491
[1, 1060] loss_train: 0.016168, loss_test: 0.006215
time: 0.2540562152862549
time: 2.1974918842315674
[1, 1061] loss_train: 0.008933, loss_test: 0.006235
time: 0.2420654296875
time: 2.209017276763916
[1, 1062] loss_train: 0.010511, loss_test: 0.006240
time: 0.24205303192138672
time: 2.229499101638794
[1, 1063] loss_train: 0.011533, loss_test: 0.006244
time: 0.24305367469787598
time: 2.221497058868408
[1, 1064] loss_train: 0.006395, loss_test: 0.006242
time: 0.24305367469787598
time: 2.2134947776794434
[1, 1065] loss_train: 0.005891, loss_test: 0.006237
time: 0.24105453491210938
time: 2.20449161529541
[1, 1066] loss_train: 0.008413, loss_test: 0.006224
time: 0.24205255508422852
time: 2.2345001697540283
[1, 1067] loss_train: 0.002956, loss_test: 0.006202
time: 0.24205350875854492
time: 2.229534387588501
[1, 1068] loss_train: 0.003679, loss_test: 0.006182
time: 0.24205470085144043
time: 2.2164950370788574
[1, 1069] loss_train: 0.006196, loss_test: 0.006164
time: 0.24405431747436523
time: 2.233499526977539
[1, 1070] loss_train: 0.012042, loss_test: 0.006163
time: 0.25705695152282715
time: 2.2355000972747803
[1, 1071] loss_train: 0.014075, loss_test: 0.006165
time: 0.2450559139251709
time: 2.2334980964660645
[1, 1072] loss_train: 0.004758, loss_test: 0.006166
time: 0.24305438995361328
time: 2.2134945392608643
[1, 1073] loss_train: 0.007260, loss_test: 0.006163
time: 0.24405956268310547
time: 2.222496747970581
[1, 1074] loss_train: 0.003724, loss_test: 0.006159
time: 0.24205303192138672
time: 2.232499599456787
[1, 1075] loss_train: 0.006679, loss_test: 0.006159
time: 0.24205327033996582
time: 2.2485029697418213
[1, 1076] loss_train: 0.012594, loss_test: 0.006161
time: 0.24306678771972656
time: 2.1844890117645264
[1, 1077] loss_train: 0.006367, loss_test: 0.006166
time: 0.2490549087524414
time: 2.2383980751037598
[1, 1078] loss_train: 0.005235, loss_test: 0.006170
time: 0.24205374717712402
time: 2.2244977951049805
[1, 1079] loss_train: 0.004112, loss_test: 0.006171
time: 0.24205398559570312
time: 2.2375030517578125
[1, 1080] loss_train: 0.005203, loss_test: 0.006172
time: 0.2540557384490967
time: 2.2515041828155518
[1, 1081] loss_train: 0.002925, loss_test: 0.006171
time: 0.24406790733337402
time: 2.236499786376953
[1, 1082] loss_train: 0.005396, loss_test: 0.006171
time: 0.24205446243286133
time: 2.2705070972442627
[1, 1083] loss_train: 0.003952, loss_test: 0.006171
time: 0.24405384063720703
time: 2.2465028762817383
[1, 1084] loss_train: 0.011062, loss_test: 0.006165
time: 0.24305415153503418
time: 2.2014923095703125
[1, 1085] loss_train: 0.004712, loss_test: 0.006168
time: 0.24105286598205566
time: 2.2134265899658203
[1, 1086] loss_train: 0.004963, loss_test: 0.006176
time: 0.24305462837219238
time: 2.1894896030426025
[1, 1087] loss_train: 0.009812, loss_test: 0.006184
time: 0.24205374717712402
time: 2.293513059616089
[1, 1088] loss_train: 0.001633, loss_test: 0.006196
time: 0.25305604934692383
time: 2.284511089324951
[1, 1089] loss_train: 0.002590, loss_test: 0.006210
time: 0.24505400657653809
time: 2.23815655708313
[1, 1090] loss_train: 0.011016, loss_test: 0.006208
time: 0.2540566921234131
time: 2.1994917392730713
[1, 1091] loss_train: 0.004032, loss_test: 0.006207
time: 0.24305438995361328
time: 2.2014920711517334
[1, 1092] loss_train: 0.009733, loss_test: 0.006188
time: 0.24606752395629883
time: 2.2234978675842285
[1, 1093] loss_train: 0.011747, loss_test: 0.006159
time: 0.24305438995361328
time: 2.209493637084961
[1, 1094] loss_train: 0.004994, loss_test: 0.006148
time: 0.24605488777160645
time: 2.230498790740967
[1, 1095] loss_train: 0.003758, loss_test: 0.006149
time: 0.24505400657653809
time: 2.2064929008483887
[1, 1096] loss_train: 0.008214, loss_test: 0.006158
time: 0.2420492172241211
time: 2.2084944248199463
[1, 1097] loss_train: 0.007420, loss_test: 0.006173
time: 0.24205398559570312
time: 2.2265067100524902
[1, 1098] loss_train: 0.005968, loss_test: 0.006189
time: 0.24205327033996582
time: 2.2345004081726074
[1, 1099] loss_train: 0.003099, loss_test: 0.006186
time: 0.24305343627929688
time: 2.2575201988220215
[1, 1100] loss_train: 0.007684, loss_test: 0.006178
time: 0.25505709648132324
time: 2.3475844860076904
[1, 1101] loss_train: 0.002009, loss_test: 0.006162
time: 0.25005221366882324
time: 2.2495033740997314
[1, 1102] loss_train: 0.002086, loss_test: 0.006151
time: 0.26405835151672363
time: 2.2975142002105713
[1, 1103] loss_train: 0.011505, loss_test: 0.006147
time: 0.24405360221862793
time: 2.2515060901641846
[1, 1104] loss_train: 0.009009, loss_test: 0.006146
time: 0.24805474281311035
time: 2.30651593208313
[1, 1105] loss_train: 0.004403, loss_test: 0.006146
time: 0.2470550537109375
time: 2.2655065059661865
[1, 1106] loss_train: 0.010511, loss_test: 0.006143
time: 0.25305628776550293
time: 2.2630088329315186
[1, 1107] loss_train: 0.005442, loss_test: 0.006141
time: 0.24605607986450195
time: 2.245504856109619
[1, 1108] loss_train: 0.001639, loss_test: 0.006140
time: 0.2490553855895996
time: 2.222496747970581
[1, 1109] loss_train: 0.013131, loss_test: 0.006138
time: 0.24405384063720703
time: 2.217496395111084
[1, 1110] loss_train: 0.003336, loss_test: 0.006143
time: 0.26105761528015137
time: 2.2435052394866943
[1, 1111] loss_train: 0.002919, loss_test: 0.006151
time: 0.24605441093444824
time: 2.239501476287842
[1, 1112] loss_train: 0.004163, loss_test: 0.006158
time: 0.2540557384490967
time: 2.229499101638794
[1, 1113] loss_train: 0.019204, loss_test: 0.006146
time: 0.2450544834136963
time: 2.208516836166382
[1, 1114] loss_train: 0.005251, loss_test: 0.006140
time: 0.24205374717712402
time: 2.270507574081421
[1, 1115] loss_train: 0.004443, loss_test: 0.006136
time: 0.24205422401428223
time: 2.2655158042907715
[1, 1116] loss_train: 0.010563, loss_test: 0.006133
time: 0.24405360221862793
time: 2.2375011444091797
[1, 1117] loss_train: 0.007982, loss_test: 0.006130
time: 0.24255609512329102
time: 2.2340056896209717
[1, 1118] loss_train: 0.005187, loss_test: 0.006126
time: 0.24105381965637207
time: 2.2425453662872314
[1, 1119] loss_train: 0.005253, loss_test: 0.006124
time: 0.2450547218322754
time: 2.2225048542022705
[1, 1120] loss_train: 0.011047, loss_test: 0.006123
time: 0.2540566921234131
time: 2.2665066719055176
[1, 1121] loss_train: 0.009960, loss_test: 0.006128
time: 0.24105358123779297
time: 2.2304985523223877
[1, 1122] loss_train: 0.003626, loss_test: 0.006130
time: 0.24105381965637207
time: 2.234503746032715
[1, 1123] loss_train: 0.007319, loss_test: 0.006133
time: 0.24205303192138672
time: 2.2285118103027344
[1, 1124] loss_train: 0.005639, loss_test: 0.006130
time: 0.24105429649353027
time: 2.2074930667877197
[1, 1125] loss_train: 0.002490, loss_test: 0.006124
time: 0.24205350875854492
time: 2.1914925575256348
[1, 1126] loss_train: 0.010230, loss_test: 0.006130
time: 0.24305343627929688
time: 2.2625064849853516
[1, 1127] loss_train: 0.007281, loss_test: 0.006138
time: 0.24305367469787598
time: 2.206493854522705
[1, 1128] loss_train: 0.008131, loss_test: 0.006143
time: 0.24106574058532715
time: 2.2375659942626953
[1, 1129] loss_train: 0.011066, loss_test: 0.006154
time: 0.24310541152954102
time: 2.2284984588623047
[1, 1130] loss_train: 0.005015, loss_test: 0.006157
time: 0.2560567855834961
time: 2.2395007610321045
[1, 1131] loss_train: 0.003372, loss_test: 0.006150
time: 0.2470552921295166
time: 2.245501756668091
[1, 1132] loss_train: 0.003721, loss_test: 0.006144
time: 0.24605512619018555
time: 2.215010404586792
[1, 1133] loss_train: 0.003508, loss_test: 0.006140
time: 0.252056360244751
time: 2.2014920711517334
[1, 1134] loss_train: 0.018549, loss_test: 0.006133
time: 0.2450551986694336
time: 2.229499578475952
[1, 1135] loss_train: 0.003675, loss_test: 0.006126
time: 0.24605035781860352
time: 2.2475030422210693
[1, 1136] loss_train: 0.008548, loss_test: 0.006118
time: 0.24405384063720703
time: 2.2134954929351807
[1, 1137] loss_train: 0.009461, loss_test: 0.006132
time: 0.24405384063720703
time: 2.216440200805664
[1, 1138] loss_train: 0.007094, loss_test: 0.006164
time: 0.24306893348693848
time: 2.2665038108825684
[1, 1139] loss_train: 0.005649, loss_test: 0.006209
time: 0.24105310440063477
time: 2.226001501083374
[1, 1140] loss_train: 0.007859, loss_test: 0.006269
time: 0.2540557384490967
time: 2.264507293701172
[1, 1141] loss_train: 0.004725, loss_test: 0.006297
time: 0.24205350875854492
time: 2.24753475189209
[1, 1142] loss_train: 0.008268, loss_test: 0.006313
time: 0.24105381965637207
time: 2.229499101638794
[1, 1143] loss_train: 0.007360, loss_test: 0.006312
time: 0.24205398559570312
time: 2.2415127754211426
[1, 1144] loss_train: 0.005576, loss_test: 0.006305
time: 0.24605488777160645
time: 2.259023904800415
[1, 1145] loss_train: 0.002137, loss_test: 0.006293
time: 0.24305319786071777
time: 2.2315025329589844
[1, 1146] loss_train: 0.004441, loss_test: 0.006278
time: 0.24308204650878906
time: 2.235311269760132
[1, 1147] loss_train: 0.005444, loss_test: 0.006262
time: 0.24205327033996582
time: 2.2004928588867188
[1, 1148] loss_train: 0.008726, loss_test: 0.006251
time: 0.24205374717712402
time: 2.2284984588623047
[1, 1149] loss_train: 0.005269, loss_test: 0.006242
time: 0.24105381965637207
time: 2.2070374488830566
[1, 1150] loss_train: 0.003457, loss_test: 0.006240
time: 0.2530558109283447
time: 2.203493595123291
[1, 1151] loss_train: 0.002539, loss_test: 0.006244
time: 0.2470543384552002
time: 2.2335000038146973
[1, 1152] loss_train: 0.008531, loss_test: 0.006247
time: 0.2520565986633301
time: 2.2184956073760986
[1, 1153] loss_train: 0.007729, loss_test: 0.006245
time: 0.24605679512023926
time: 2.2425014972686768
[1, 1154] loss_train: 0.005487, loss_test: 0.006233
time: 0.2490551471710205
time: 2.2515039443969727
[1, 1155] loss_train: 0.010197, loss_test: 0.006207
time: 0.24506688117980957
time: 2.2004919052124023
[1, 1156] loss_train: 0.007558, loss_test: 0.006181
time: 0.2510557174682617
time: 2.2345175743103027
[1, 1157] loss_train: 0.012165, loss_test: 0.006154
time: 0.24105358123779297
time: 2.228498697280884
[1, 1158] loss_train: 0.011422, loss_test: 0.006138
time: 0.24405384063720703
time: 2.2154951095581055
[1, 1159] loss_train: 0.006127, loss_test: 0.006132
time: 0.2435777187347412
time: 2.2244977951049805
[1, 1160] loss_train: 0.006957, loss_test: 0.006136
time: 0.2540566921234131
time: 2.2645063400268555
[1, 1161] loss_train: 0.007771, loss_test: 0.006144
time: 0.24505400657653809
time: 2.232499361038208
[1, 1162] loss_train: 0.002447, loss_test: 0.006151
time: 0.2470557689666748
time: 2.2405004501342773
[1, 1163] loss_train: 0.005304, loss_test: 0.006157
time: 0.24105334281921387
time: 2.241501808166504
[1, 1164] loss_train: 0.005078, loss_test: 0.006160
time: 0.24205350875854492
time: 2.211500883102417
[1, 1165] loss_train: 0.012806, loss_test: 0.006159
time: 0.24305415153503418
time: 2.225203514099121
[1, 1166] loss_train: 0.011977, loss_test: 0.006157
time: 0.24205470085144043
time: 2.2355117797851562
[1, 1167] loss_train: 0.003055, loss_test: 0.006141
time: 0.24205327033996582
time: 2.2144954204559326
[1, 1168] loss_train: 0.006584, loss_test: 0.006131
time: 0.24605512619018555
time: 2.2274978160858154
[1, 1169] loss_train: 0.011817, loss_test: 0.006130
time: 0.24232172966003418
time: 2.199491500854492
[1, 1170] loss_train: 0.002088, loss_test: 0.006129
time: 0.2580575942993164
time: 2.2265169620513916
[1, 1171] loss_train: 0.008477, loss_test: 0.006128
time: 0.2450547218322754
time: 2.244015693664551
[1, 1172] loss_train: 0.009449, loss_test: 0.006128
time: 0.24405312538146973
time: 2.218496322631836
[1, 1173] loss_train: 0.009638, loss_test: 0.006123
time: 0.25267934799194336
time: 2.2029976844787598
[1, 1174] loss_train: 0.020032, loss_test: 0.006119
time: 0.24405407905578613
time: 2.242502212524414
[1, 1175] loss_train: 0.012073, loss_test: 0.006121
time: 0.24509310722351074
time: 2.2244997024536133
[1, 1176] loss_train: 0.003556, loss_test: 0.006123
time: 0.24305391311645508
time: 2.246502161026001
[1, 1177] loss_train: 0.007108, loss_test: 0.006128
time: 0.24605536460876465
time: 2.2715184688568115
[1, 1178] loss_train: 0.001532, loss_test: 0.006138
time: 0.24305391311645508
time: 2.2555043697357178
[1, 1179] loss_train: 0.008514, loss_test: 0.006145
time: 0.24605488777160645
time: 2.2335119247436523
[1, 1180] loss_train: 0.009553, loss_test: 0.006149
time: 0.2550699710845947
time: 2.243502378463745
[1, 1181] loss_train: 0.006786, loss_test: 0.006149
time: 0.24605417251586914
time: 2.2014951705932617
[1, 1182] loss_train: 0.002010, loss_test: 0.006152
time: 0.24805521965026855
time: 2.221498727798462
[1, 1183] loss_train: 0.004770, loss_test: 0.006153
time: 0.24605441093444824
time: 2.2124955654144287
[1, 1184] loss_train: 0.001081, loss_test: 0.006156
time: 0.24405336380004883
time: 2.2124953269958496
[1, 1185] loss_train: 0.008223, loss_test: 0.006155
time: 0.2450547218322754
time: 2.2865231037139893
[1, 1186] loss_train: 0.005164, loss_test: 0.006153
time: 0.24305415153503418
time: 2.265009641647339
[1, 1187] loss_train: 0.010792, loss_test: 0.006145
time: 0.24806785583496094
time: 2.28251314163208
[1, 1188] loss_train: 0.005987, loss_test: 0.006138
time: 0.287064790725708
time: 2.2805120944976807
[1, 1189] loss_train: 0.008132, loss_test: 0.006133
time: 0.2450547218322754
time: 2.2415010929107666
[1, 1190] loss_train: 0.007759, loss_test: 0.006133
time: 0.2540559768676758
time: 2.2295002937316895
[1, 1191] loss_train: 0.009954, loss_test: 0.006142
time: 0.24205279350280762
time: 2.2805099487304688
[1, 1192] loss_train: 0.003953, loss_test: 0.006155
time: 0.24306130409240723
time: 2.2655065059661865
[1, 1193] loss_train: 0.006536, loss_test: 0.006163
time: 0.24505400657653809
time: 2.307516574859619
[1, 1194] loss_train: 0.001470, loss_test: 0.006157
time: 0.2470543384552002
time: 2.255505084991455
[1, 1195] loss_train: 0.005829, loss_test: 0.006149
time: 0.24505376815795898
time: 2.244511604309082
[1, 1196] loss_train: 0.007577, loss_test: 0.006146
time: 0.24205303192138672
time: 2.2325000762939453
[1, 1197] loss_train: 0.006952, loss_test: 0.006145
time: 0.3310728073120117
time: 2.3345232009887695
[1, 1198] loss_train: 0.004815, loss_test: 0.006143
time: 0.29906535148620605
time: 2.352526903152466
[1, 1199] loss_train: 0.005047, loss_test: 0.006143
time: 0.24305391311645508
time: 2.3635284900665283
[1, 1200] loss_train: 0.010236, loss_test: 0.006139
time: 0.256056547164917
time: 2.4330637454986572
[1, 1201] loss_train: 0.011622, loss_test: 0.006131
time: 0.24605512619018555
time: 2.3230366706848145
[1, 1202] loss_train: 0.002781, loss_test: 0.006128
time: 0.24605417251586914
time: 2.312518358230591
[1, 1203] loss_train: 0.015625, loss_test: 0.006123
time: 0.24205327033996582
time: 2.2324986457824707
[1, 1204] loss_train: 0.013700, loss_test: 0.006130
time: 0.24005341529846191
time: 2.2134947776794434
[1, 1205] loss_train: 0.003568, loss_test: 0.006149
time: 0.24305295944213867
time: 2.213999032974243
[1, 1206] loss_train: 0.008484, loss_test: 0.006169
time: 0.24305415153503418
time: 2.217495918273926
[1, 1207] loss_train: 0.008286, loss_test: 0.006168
time: 0.24505376815795898
time: 2.2204973697662354
[1, 1208] loss_train: 0.005917, loss_test: 0.006159
time: 0.25006866455078125
time: 2.2485034465789795
[1, 1209] loss_train: 0.004136, loss_test: 0.006149
time: 0.24405431747436523
time: 2.2451207637786865
[1, 1210] loss_train: 0.006155, loss_test: 0.006146
time: 0.26105833053588867
time: 2.254504680633545
[1, 1211] loss_train: 0.004875, loss_test: 0.006153
time: 0.24505400657653809
time: 2.2825112342834473
[1, 1212] loss_train: 0.007784, loss_test: 0.006164
time: 0.25505661964416504
time: 2.25051212310791
[1, 1213] loss_train: 0.005099, loss_test: 0.006180
time: 0.24405407905578613
time: 2.2630832195281982
[1, 1214] loss_train: 0.006031, loss_test: 0.006198
time: 0.2470543384552002
time: 2.2204971313476562
[1, 1215] loss_train: 0.004226, loss_test: 0.006219
time: 0.24305438995361328
time: 2.2375001907348633
[1, 1216] loss_train: 0.011076, loss_test: 0.006225
time: 0.2490553855895996
time: 2.2465016841888428
[1, 1217] loss_train: 0.001730, loss_test: 0.006234
time: 0.24406814575195312
time: 2.288513660430908
[1, 1218] loss_train: 0.002280, loss_test: 0.006242
time: 0.2490551471710205
time: 2.233499050140381
[1, 1219] loss_train: 0.010197, loss_test: 0.006233
time: 0.2470533847808838
time: 2.2435033321380615
[1, 1220] loss_train: 0.013045, loss_test: 0.006201
time: 0.26606154441833496
time: 2.2481069564819336
[1, 1221] loss_train: 0.002740, loss_test: 0.006178
time: 0.2500579357147217
time: 2.2145087718963623
[1, 1222] loss_train: 0.008793, loss_test: 0.006159
time: 0.2470543384552002
time: 2.231499433517456
[1, 1223] loss_train: 0.012740, loss_test: 0.006145
time: 0.2431802749633789
time: 2.2515037059783936
[1, 1224] loss_train: 0.007571, loss_test: 0.006154
time: 0.2470543384552002
time: 2.2475032806396484
[1, 1225] loss_train: 0.009581, loss_test: 0.006188
time: 0.2450547218322754
time: 2.244501829147339
[1, 1226] loss_train: 0.004476, loss_test: 0.006222
time: 0.24605393409729004
time: 2.2375030517578125
[1, 1227] loss_train: 0.003629, loss_test: 0.006236
time: 0.24505400657653809
time: 2.2325000762939453
[1, 1228] loss_train: 0.011135, loss_test: 0.006244
time: 0.24605536460876465
time: 2.2435038089752197
[1, 1229] loss_train: 0.003216, loss_test: 0.006216
time: 0.24405384063720703
time: 2.243501663208008
[1, 1230] loss_train: 0.015707, loss_test: 0.006213
time: 0.26105761528015137
time: 2.2435050010681152
[1, 1231] loss_train: 0.005124, loss_test: 0.006200
time: 0.24305343627929688
time: 2.268510580062866
[1, 1232] loss_train: 0.010831, loss_test: 0.006188
time: 0.24405360221862793
time: 2.229501485824585
[1, 1233] loss_train: 0.003340, loss_test: 0.006169
time: 0.24405384063720703
time: 2.254506826400757
[1, 1234] loss_train: 0.005566, loss_test: 0.006151
time: 0.24405407905578613
time: 2.2375028133392334
[1, 1235] loss_train: 0.006985, loss_test: 0.006137
time: 0.24205398559570312
time: 2.2105042934417725
[1, 1236] loss_train: 0.011200, loss_test: 0.006128
time: 0.24305391311645508
time: 2.262458324432373
[1, 1237] loss_train: 0.010674, loss_test: 0.006124
time: 0.2420661449432373
time: 2.2525289058685303
[1, 1238] loss_train: 0.009186, loss_test: 0.006123
time: 0.24205327033996582
time: 2.2254979610443115
[1, 1239] loss_train: 0.002954, loss_test: 0.006127
time: 0.2420670986175537
time: 2.2545042037963867
[1, 1240] loss_train: 0.009475, loss_test: 0.006128
time: 0.2530555725097656
time: 2.319519281387329
[1, 1241] loss_train: 0.007523, loss_test: 0.006131
time: 0.24305319786071777
time: 2.280510663986206
[1, 1242] loss_train: 0.003298, loss_test: 0.006134
time: 0.2450549602508545
time: 2.23207426071167
[1, 1243] loss_train: 0.008870, loss_test: 0.006137
time: 0.24405360221862793
time: 2.2270052433013916
[1, 1244] loss_train: 0.005594, loss_test: 0.006138
time: 0.24205446243286133
time: 2.209496259689331
[1, 1245] loss_train: 0.009279, loss_test: 0.006138
time: 0.24205327033996582
time: 2.232499361038208
[1, 1246] loss_train: 0.005925, loss_test: 0.006138
time: 0.24205374717712402
time: 2.277509927749634
[1, 1247] loss_train: 0.004170, loss_test: 0.006139
time: 0.25005507469177246
time: 2.252519130706787
[1, 1248] loss_train: 0.004328, loss_test: 0.006137
time: 0.2450544834136963
time: 2.256505012512207
[1, 1249] loss_train: 0.005094, loss_test: 0.006134
time: 0.2470550537109375
time: 2.2665085792541504
[1, 1250] loss_train: 0.008007, loss_test: 0.006132
time: 0.2540571689605713
time: 2.250502824783325
[1, 1251] loss_train: 0.013083, loss_test: 0.006131
time: 0.2470555305480957
time: 2.2545039653778076
[1, 1252] loss_train: 0.004673, loss_test: 0.006132
time: 0.24802398681640625
time: 2.2815101146698
[1, 1253] loss_train: 0.003130, loss_test: 0.006135
time: 0.24505400657653809
time: 2.2254979610443115
[1, 1254] loss_train: 0.011789, loss_test: 0.006137
time: 0.24305415153503418
time: 2.2535035610198975
[1, 1255] loss_train: 0.006444, loss_test: 0.006138
time: 0.24305343627929688
time: 2.273507595062256
[1, 1256] loss_train: 0.004251, loss_test: 0.006142
time: 0.24605512619018555
time: 2.2715084552764893
[1, 1257] loss_train: 0.007532, loss_test: 0.006146
time: 0.2470552921295166
time: 2.245502233505249
[1, 1258] loss_train: 0.007291, loss_test: 0.006150
time: 0.24305367469787598
time: 2.2635061740875244
[1, 1259] loss_train: 0.005205, loss_test: 0.006151
time: 0.2490556240081787
time: 2.2545132637023926
[1, 1260] loss_train: 0.008841, loss_test: 0.006146
time: 0.2560575008392334
time: 2.254504680633545
[1, 1261] loss_train: 0.007952, loss_test: 0.006141
time: 0.2560560703277588
time: 2.269508123397827
[1, 1262] loss_train: 0.008089, loss_test: 0.006136
time: 0.24205350875854492
time: 2.2475030422210693
[1, 1263] loss_train: 0.002341, loss_test: 0.006132
time: 0.2490553855895996
time: 2.257506847381592
[1, 1264] loss_train: 0.004161, loss_test: 0.006128
time: 0.2450542449951172
time: 2.253504514694214
[1, 1265] loss_train: 0.007584, loss_test: 0.006121
time: 0.25205516815185547
time: 2.279510259628296
[1, 1266] loss_train: 0.000920, loss_test: 0.006118
time: 0.2490556240081787
time: 2.251526355743408
[1, 1267] loss_train: 0.004541, loss_test: 0.006115
time: 0.2470541000366211
time: 2.2355005741119385
[1, 1268] loss_train: 0.007159, loss_test: 0.006114
time: 0.24305367469787598
time: 2.242501735687256
[1, 1269] loss_train: 0.005435, loss_test: 0.006114
time: 0.2470543384552002
time: 2.2465028762817383
[1, 1270] loss_train: 0.003501, loss_test: 0.006116
time: 0.2540566921234131
time: 2.268507242202759
[1, 1271] loss_train: 0.004852, loss_test: 0.006120
time: 0.2470552921295166
time: 2.2795090675354004
[1, 1272] loss_train: 0.005839, loss_test: 0.006125
time: 0.24805569648742676
time: 2.2685232162475586
[1, 1273] loss_train: 0.007748, loss_test: 0.006130
time: 0.24105310440063477
time: 2.2345025539398193
[1, 1274] loss_train: 0.000818, loss_test: 0.006138
time: 0.2430591583251953
time: 2.2415032386779785
[1, 1275] loss_train: 0.005350, loss_test: 0.006145
time: 0.24205422401428223
time: 2.2618236541748047
[1, 1276] loss_train: 0.002043, loss_test: 0.006156
time: 0.24605393409729004
time: 2.254504442214966
[1, 1277] loss_train: 0.001942, loss_test: 0.006171
time: 0.24706816673278809
time: 2.241011142730713
[1, 1278] loss_train: 0.011856, loss_test: 0.006168
time: 0.24505400657653809
time: 2.241501808166504
[1, 1279] loss_train: 0.010262, loss_test: 0.006154
time: 0.24605441093444824
time: 2.207493543624878
[1, 1280] loss_train: 0.007520, loss_test: 0.006144
time: 0.254056453704834
time: 2.2385010719299316
[1, 1281] loss_train: 0.005029, loss_test: 0.006134
time: 0.24105334281921387
time: 2.2280025482177734
[1, 1282] loss_train: 0.004362, loss_test: 0.006124
time: 0.2470545768737793
time: 2.2635066509246826
[1, 1283] loss_train: 0.004484, loss_test: 0.006118
time: 0.24505400657653809
time: 2.2725095748901367
[1, 1284] loss_train: 0.005990, loss_test: 0.006111
time: 0.24405384063720703
time: 2.2615063190460205
[1, 1285] loss_train: 0.011576, loss_test: 0.006100
time: 0.24305415153503418
time: 2.24650239944458
[1, 1286] loss_train: 0.018162, loss_test: 0.006105
time: 0.24505376815795898
time: 2.2565054893493652
[1, 1287] loss_train: 0.002880, loss_test: 0.006137
time: 0.24305343627929688
time: 2.205495834350586
[1, 1288] loss_train: 0.004206, loss_test: 0.006189
time: 0.24205374717712402
time: 2.2730138301849365
[1, 1289] loss_train: 0.006976, loss_test: 0.006240
time: 0.2470552921295166
time: 2.264702796936035
[1, 1290] loss_train: 0.002284, loss_test: 0.006264
time: 0.25705671310424805
time: 2.231501340866089
[1, 1291] loss_train: 0.006255, loss_test: 0.006267
time: 0.24105286598205566
time: 2.220499277114868
[1, 1292] loss_train: 0.009140, loss_test: 0.006240
time: 0.24105310440063477
time: 2.228498697280884
[1, 1293] loss_train: 0.007492, loss_test: 0.006180
time: 0.24505400657653809
time: 2.2094948291778564
[1, 1294] loss_train: 0.004157, loss_test: 0.006135
time: 0.24308061599731445
time: 2.260505437850952
[1, 1295] loss_train: 0.005522, loss_test: 0.006108
time: 0.24205374717712402
time: 2.2405009269714355
[1, 1296] loss_train: 0.008728, loss_test: 0.006093
time: 0.2450547218322754
time: 2.251504898071289
[1, 1297] loss_train: 0.003311, loss_test: 0.006091
time: 0.24605512619018555
time: 2.236504316329956
[1, 1298] loss_train: 0.003381, loss_test: 0.006100
time: 0.24605488777160645
time: 2.2645063400268555
[1, 1299] loss_train: 0.003732, loss_test: 0.006122
time: 0.24105381965637207
time: 2.2655067443847656
[1, 1300] loss_train: 0.007306, loss_test: 0.006147
time: 0.25905704498291016
time: 2.230501890182495
[1, 1301] loss_train: 0.004539, loss_test: 0.006177
time: 0.24305367469787598
time: 2.2244977951049805
[1, 1302] loss_train: 0.004132, loss_test: 0.006214
time: 0.24205350875854492
time: 2.219498872756958
[1, 1303] loss_train: 0.011129, loss_test: 0.006222
time: 0.2420661449432373
time: 2.2145004272460938
[1, 1304] loss_train: 0.006888, loss_test: 0.006219
time: 0.24405360221862793
time: 2.2178423404693604
[1, 1305] loss_train: 0.003167, loss_test: 0.006222
time: 0.24706697463989258
time: 2.256507396697998
[1, 1306] loss_train: 0.006264, loss_test: 0.006228
time: 0.24207353591918945
time: 2.209494113922119
[1, 1307] loss_train: 0.014421, loss_test: 0.006207
time: 0.24605488777160645
time: 2.227020263671875
[1, 1308] loss_train: 0.010185, loss_test: 0.006174
time: 0.23907089233398438
time: 2.248502254486084
[1, 1309] loss_train: 0.003821, loss_test: 0.006153
time: 0.24305486679077148
time: 2.2405171394348145
[1, 1310] loss_train: 0.005359, loss_test: 0.006137
time: 0.2540562152862549
time: 2.2244980335235596
[1, 1311] loss_train: 0.003310, loss_test: 0.006129
time: 0.2490551471710205
time: 2.2595057487487793
[1, 1312] loss_train: 0.007059, loss_test: 0.006119
time: 0.23905253410339355
time: 2.2440056800842285
[1, 1313] loss_train: 0.003971, loss_test: 0.006115
time: 0.2470557689666748
time: 2.2705111503601074
[1, 1314] loss_train: 0.011540, loss_test: 0.006109
time: 0.24505400657653809
time: 2.2645065784454346
[1, 1315] loss_train: 0.010354, loss_test: 0.006108
time: 0.2470557689666748
time: 2.2275021076202393
[1, 1316] loss_train: 0.005363, loss_test: 0.006116
time: 0.24105310440063477
time: 2.2105557918548584
[1, 1317] loss_train: 0.007881, loss_test: 0.006129
time: 0.24405431747436523
time: 2.2154953479766846
[1, 1318] loss_train: 0.012038, loss_test: 0.006133
time: 0.24605464935302734
time: 2.249525547027588
[1, 1319] loss_train: 0.010647, loss_test: 0.006146
time: 0.24106645584106445
time: 2.22951602935791
[1, 1320] loss_train: 0.005638, loss_test: 0.006150
time: 0.2580561637878418
time: 2.254077434539795
[1, 1321] loss_train: 0.004195, loss_test: 0.006133
time: 0.24505329132080078
time: 2.264507293701172
[1, 1322] loss_train: 0.009631, loss_test: 0.006121
time: 0.2490556240081787
time: 2.2535035610198975
[1, 1323] loss_train: 0.006513, loss_test: 0.006110
time: 0.24305462837219238
time: 2.2305095195770264
[1, 1324] loss_train: 0.009963, loss_test: 0.006104
time: 0.24805450439453125
time: 2.239501476287842
[1, 1325] loss_train: 0.002516, loss_test: 0.006092
time: 0.24305438995361328
time: 2.2176625728607178
[1, 1326] loss_train: 0.007457, loss_test: 0.006082
time: 0.24505376815795898
time: 2.230210304260254
[1, 1327] loss_train: 0.015629, loss_test: 0.006078
time: 0.2450551986694336
time: 2.219496488571167
[1, 1328] loss_train: 0.006299, loss_test: 0.006076
time: 0.24106502532958984
time: 2.217496156692505
[1, 1329] loss_train: 0.005363, loss_test: 0.006075
time: 0.24506735801696777
time: 2.217496156692505
[1, 1330] loss_train: 0.003326, loss_test: 0.006074
time: 0.2580568790435791
time: 2.212496757507324
[1, 1331] loss_train: 0.006049, loss_test: 0.006072
time: 0.2420668601989746
time: 2.22149658203125
[1, 1332] loss_train: 0.006392, loss_test: 0.006070
time: 0.24905610084533691
time: 2.2611851692199707
[1, 1333] loss_train: 0.006343, loss_test: 0.006070
time: 0.2490551471710205
time: 2.2214975357055664
[1, 1334] loss_train: 0.006852, loss_test: 0.006072
time: 0.2490553855895996
time: 2.2565529346466064
[1, 1335] loss_train: 0.008357, loss_test: 0.006076
time: 0.24306702613830566
time: 2.244502067565918
[1, 1336] loss_train: 0.015147, loss_test: 0.006071
time: 0.24605536460876465
time: 2.2645063400268555
[1, 1337] loss_train: 0.012799, loss_test: 0.006071
time: 0.25005531311035156
time: 2.2495033740997314
[1, 1338] loss_train: 0.010871, loss_test: 0.006090
time: 0.25305652618408203
time: 2.257528066635132
[1, 1339] loss_train: 0.004347, loss_test: 0.006118
time: 0.2470545768737793
time: 2.2495038509368896
[1, 1340] loss_train: 0.007658, loss_test: 0.006147
time: 0.25905656814575195
time: 2.2565057277679443
[1, 1341] loss_train: 0.002894, loss_test: 0.006155
time: 0.24605417251586914
time: 2.2545084953308105
[1, 1342] loss_train: 0.007150, loss_test: 0.006153
time: 0.25505661964416504
time: 2.2260031700134277
[1, 1343] loss_train: 0.010813, loss_test: 0.006151
time: 0.24392294883728027
time: 2.2665066719055176
[1, 1344] loss_train: 0.014356, loss_test: 0.006147
time: 0.2470555305480957
time: 2.234499216079712
[1, 1345] loss_train: 0.015752, loss_test: 0.006138
time: 0.24205422401428223
time: 2.236501455307007
[1, 1346] loss_train: 0.016810, loss_test: 0.006124
time: 0.2480480670928955
time: 2.230499267578125
[1, 1347] loss_train: 0.010086, loss_test: 0.006116
time: 0.23906707763671875
time: 2.236511468887329
[1, 1348] loss_train: 0.004149, loss_test: 0.006113
time: 0.24706721305847168
time: 2.2224974632263184
[1, 1349] loss_train: 0.016069, loss_test: 0.006115
time: 0.24105286598205566
time: 2.2175133228302
[1, 1350] loss_train: 0.001571, loss_test: 0.006120
time: 0.25705814361572266
time: 2.246502637863159
[1, 1351] loss_train: 0.006774, loss_test: 0.006130
time: 0.24507379531860352
time: 2.2430150508880615
[1, 1352] loss_train: 0.010474, loss_test: 0.006139
time: 0.24405384063720703
time: 2.282510280609131
[1, 1353] loss_train: 0.005635, loss_test: 0.006152
time: 0.24105381965637207
time: 2.2094943523406982
[1, 1354] loss_train: 0.007177, loss_test: 0.006157
time: 0.24506497383117676
time: 2.2385005950927734
[1, 1355] loss_train: 0.004872, loss_test: 0.006154
time: 0.24605560302734375
time: 2.252518892288208
[1, 1356] loss_train: 0.003520, loss_test: 0.006157
time: 0.24655747413635254
time: 2.253504753112793
[1, 1357] loss_train: 0.002041, loss_test: 0.006161
time: 0.24105358123779297
time: 2.2530064582824707
[1, 1358] loss_train: 0.006993, loss_test: 0.006167
time: 0.24405407905578613
time: 2.2375004291534424
[1, 1359] loss_train: 0.005040, loss_test: 0.006171
time: 0.24605727195739746
time: 2.28351092338562
[1, 1360] loss_train: 0.007999, loss_test: 0.006162
time: 0.26105737686157227
time: 2.2735092639923096
[1, 1361] loss_train: 0.003446, loss_test: 0.006153
time: 0.24505376815795898
time: 2.218496322631836
[1, 1362] loss_train: 0.007912, loss_test: 0.006142
time: 0.24007773399353027
time: 2.207493543624878
[1, 1363] loss_train: 0.005689, loss_test: 0.006131
time: 0.24305367469787598
time: 2.207494020462036
[1, 1364] loss_train: 0.003413, loss_test: 0.006119
time: 0.24205303192138672
time: 2.1844890117645264
[1, 1365] loss_train: 0.010891, loss_test: 0.006110
time: 0.24205327033996582
time: 2.196509599685669
[1, 1366] loss_train: 0.008380, loss_test: 0.006110
time: 0.24205374717712402
time: 2.231515407562256
[1, 1367] loss_train: 0.015701, loss_test: 0.006133
time: 0.24305367469787598
time: 2.2190091609954834
[1, 1368] loss_train: 0.005060, loss_test: 0.006171
time: 0.24407124519348145
time: 2.2385005950927734
[1, 1369] loss_train: 0.003743, loss_test: 0.006210
time: 0.24605464935302734
time: 2.216512680053711
[1, 1370] loss_train: 0.001391, loss_test: 0.006240
time: 0.25505709648132324
time: 2.2234976291656494
[1, 1371] loss_train: 0.007836, loss_test: 0.006272
time: 0.2450551986694336
time: 2.22249698638916
[1, 1372] loss_train: 0.003685, loss_test: 0.006267
time: 0.24605417251586914
time: 2.2114951610565186
[1, 1373] loss_train: 0.007259, loss_test: 0.006260
time: 0.24205422401428223
time: 2.1814868450164795
[1, 1374] loss_train: 0.008323, loss_test: 0.006231
time: 0.24205374717712402
time: 2.2445435523986816
[1, 1375] loss_train: 0.010637, loss_test: 0.006208
time: 0.24205350875854492
time: 2.218496561050415
[1, 1376] loss_train: 0.005312, loss_test: 0.006166
time: 0.24205398559570312
time: 2.219498872756958
[1, 1377] loss_train: 0.002446, loss_test: 0.006126
time: 0.2450547218322754
time: 2.2585043907165527
[1, 1378] loss_train: 0.005384, loss_test: 0.006102
time: 0.26252126693725586
time: 2.2905123233795166
[1, 1379] loss_train: 0.012962, loss_test: 0.006094
time: 0.24205374717712402
time: 2.2685084342956543
[1, 1380] loss_train: 0.007893, loss_test: 0.006096
time: 0.2550699710845947
time: 2.284511089324951
[1, 1381] loss_train: 0.006313, loss_test: 0.006108
time: 0.27005982398986816
time: 2.3369998931884766
[1, 1382] loss_train: 0.005370, loss_test: 0.006121
time: 0.24805498123168945
time: 2.3685302734375
[1, 1383] loss_train: 0.004640, loss_test: 0.006135
time: 0.24405431747436523
time: 2.2184958457946777
[1, 1384] loss_train: 0.012901, loss_test: 0.006121
time: 0.24805545806884766
time: 2.2895114421844482
[1, 1385] loss_train: 0.008504, loss_test: 0.006108
time: 0.25305628776550293
time: 2.2475099563598633
[1, 1386] loss_train: 0.005339, loss_test: 0.006101
time: 0.28406357765197754
time: 2.2545042037963867
[1, 1387] loss_train: 0.017093, loss_test: 0.006084
time: 0.24363279342651367
time: 2.2195069789886475
[1, 1388] loss_train: 0.007022, loss_test: 0.006078
time: 0.2470552921295166
time: 2.2234973907470703
[1, 1389] loss_train: 0.010319, loss_test: 0.006098
time: 0.24605369567871094
time: 2.232501745223999
[1, 1390] loss_train: 0.012489, loss_test: 0.006130
time: 0.2600572109222412
time: 2.2702860832214355
[1, 1391] loss_train: 0.002309, loss_test: 0.006162
time: 0.2520558834075928
time: 2.242380380630493
[1, 1392] loss_train: 0.005024, loss_test: 0.006181
time: 0.24605417251586914
time: 2.2615067958831787
[1, 1393] loss_train: 0.005094, loss_test: 0.006176
time: 0.2450542449951172
time: 2.2495033740997314
[1, 1394] loss_train: 0.006474, loss_test: 0.006156
time: 0.25205540657043457
time: 2.2410671710968018
[1, 1395] loss_train: 0.002757, loss_test: 0.006126
time: 0.25205516815185547
time: 2.236503839492798
[1, 1396] loss_train: 0.002652, loss_test: 0.006103
time: 0.2490551471710205
time: 2.2445015907287598
[1, 1397] loss_train: 0.006406, loss_test: 0.006091
time: 0.2490551471710205
time: 2.235499620437622
[1, 1398] loss_train: 0.006076, loss_test: 0.006090
time: 0.24605345726013184
time: 2.2345004081726074
[1, 1399] loss_train: 0.003962, loss_test: 0.006096
time: 0.2450551986694336
time: 2.222503185272217
[1, 1400] loss_train: 0.003890, loss_test: 0.006112
time: 0.25305604934692383
time: 2.195491313934326
[1, 1401] loss_train: 0.005979, loss_test: 0.006133
time: 0.24305415153503418
time: 2.231498956680298
[1, 1402] loss_train: 0.011226, loss_test: 0.006138
time: 0.2470552921295166
time: 2.219496250152588
[1, 1403] loss_train: 0.005812, loss_test: 0.006139
time: 0.24605393409729004
time: 2.2475030422210693
[1, 1404] loss_train: 0.015321, loss_test: 0.006115
time: 0.2420511245727539
time: 2.2405011653900146
[1, 1405] loss_train: 0.005078, loss_test: 0.006097
time: 0.2490546703338623
time: 2.2375006675720215
[1, 1406] loss_train: 0.004430, loss_test: 0.006086
time: 0.24805521965026855
time: 2.2625064849853516
[1, 1407] loss_train: 0.002490, loss_test: 0.006079
time: 0.2470543384552002
time: 2.220513105392456
[1, 1408] loss_train: 0.003948, loss_test: 0.006076
time: 0.24605512619018555
time: 2.2625057697296143
[1, 1409] loss_train: 0.001772, loss_test: 0.006076
time: 0.24505376815795898
time: 2.2345001697540283
[1, 1410] loss_train: 0.015516, loss_test: 0.006070
time: 0.25705671310424805
time: 2.2585058212280273
[1, 1411] loss_train: 0.005629, loss_test: 0.006068
time: 0.24505400657653809
time: 2.2595062255859375
[1, 1412] loss_train: 0.009687, loss_test: 0.006069
time: 0.24506735801696777
time: 2.2385010719299316
[1, 1413] loss_train: 0.008370, loss_test: 0.006071
time: 0.24605393409729004
time: 2.2124955654144287
[1, 1414] loss_train: 0.005841, loss_test: 0.006072
time: 0.24608087539672852
time: 2.242501974105835
[1, 1415] loss_train: 0.005377, loss_test: 0.006072
time: 0.25005555152893066
time: 2.2595055103302
[1, 1416] loss_train: 0.007293, loss_test: 0.006071
time: 0.24205422401428223
time: 2.23249888420105
[1, 1417] loss_train: 0.005152, loss_test: 0.006071
time: 0.24305415153503418
time: 2.2975144386291504
[1, 1418] loss_train: 0.004766, loss_test: 0.006072
time: 0.2540559768676758
time: 2.2415037155151367
[1, 1419] loss_train: 0.009950, loss_test: 0.006076
time: 0.24605464935302734
time: 2.2314999103546143
[1, 1420] loss_train: 0.011204, loss_test: 0.006080
time: 0.2540562152862549
time: 2.27150821685791
[1, 1421] loss_train: 0.015139, loss_test: 0.006084
time: 0.24405407905578613
time: 2.2785096168518066
[1, 1422] loss_train: 0.001617, loss_test: 0.006086
time: 0.24605441093444824
time: 2.244037628173828
[1, 1423] loss_train: 0.004781, loss_test: 0.006087
time: 0.24405360221862793
time: 2.209494113922119
[1, 1424] loss_train: 0.004649, loss_test: 0.006086
time: 0.2490558624267578
time: 2.236598253250122
[1, 1425] loss_train: 0.005913, loss_test: 0.006089
time: 0.24305438995361328
time: 2.285034418106079
[1, 1426] loss_train: 0.004160, loss_test: 0.006098
time: 0.2450549602508545
time: 2.2204973697662354
[1, 1427] loss_train: 0.001455, loss_test: 0.006112
time: 0.24605464935302734
time: 2.2945220470428467
[1, 1428] loss_train: 0.007742, loss_test: 0.006119
time: 0.24405455589294434
time: 2.397547721862793
[1, 1429] loss_train: 0.009303, loss_test: 0.006120
time: 0.24305415153503418
time: 2.323519468307495
[1, 1430] loss_train: 0.001747, loss_test: 0.006124
time: 0.252056360244751
time: 2.2755088806152344
[1, 1431] loss_train: 0.004771, loss_test: 0.006124
time: 0.2470545768737793
time: 2.306516647338867
[1, 1432] loss_train: 0.006962, loss_test: 0.006116
time: 0.24305391311645508
time: 2.268589735031128
[1, 1433] loss_train: 0.009437, loss_test: 0.006109
time: 0.2450549602508545
time: 2.347524881362915
[1, 1434] loss_train: 0.006474, loss_test: 0.006112
time: 0.2440659999847412
time: 2.2134950160980225
[1, 1435] loss_train: 0.008518, loss_test: 0.006123
time: 0.24105334281921387
time: 2.2535037994384766
[1, 1436] loss_train: 0.010693, loss_test: 0.006146
time: 0.3250718116760254
time: 2.272524833679199
[1, 1437] loss_train: 0.001062, loss_test: 0.006158
time: 0.24405431747436523
time: 2.2565064430236816
[1, 1438] loss_train: 0.002532, loss_test: 0.006170
time: 0.25505614280700684
time: 2.2530081272125244
[1, 1439] loss_train: 0.002317, loss_test: 0.006179
time: 0.24605417251586914
time: 2.253526449203491
[1, 1440] loss_train: 0.011471, loss_test: 0.006186
time: 0.25305676460266113
time: 2.2365002632141113
[1, 1441] loss_train: 0.017144, loss_test: 0.006188
time: 0.2510554790496826
time: 2.231498956680298
[1, 1442] loss_train: 0.006640, loss_test: 0.006186
time: 0.24505400657653809
time: 2.24550461769104
[1, 1443] loss_train: 0.005140, loss_test: 0.006173
time: 0.2470552921295166
time: 2.2304983139038086
[1, 1444] loss_train: 0.007117, loss_test: 0.006128
time: 0.24305438995361328
time: 2.2605056762695312
[1, 1445] loss_train: 0.005673, loss_test: 0.006096
time: 0.25005531311035156
time: 2.2485029697418213
[1, 1446] loss_train: 0.009187, loss_test: 0.006070
time: 0.24305343627929688
time: 2.2335000038146973
[1, 1447] loss_train: 0.004888, loss_test: 0.006060
time: 0.24405407905578613
time: 2.227498769760132
[1, 1448] loss_train: 0.006703, loss_test: 0.006066
time: 0.24805450439453125
time: 2.2215051651000977
[1, 1449] loss_train: 0.010478, loss_test: 0.006083
time: 0.24205350875854492
time: 2.216495990753174
[1, 1450] loss_train: 0.010200, loss_test: 0.006111
time: 0.2540569305419922
time: 2.1869935989379883
[1, 1451] loss_train: 0.002131, loss_test: 0.006143
time: 0.2450547218322754
time: 2.205493450164795
[1, 1452] loss_train: 0.003697, loss_test: 0.006178
time: 0.2510554790496826
time: 2.270508050918579
[1, 1453] loss_train: 0.009060, loss_test: 0.006177
time: 0.2490553855895996
time: 2.2485032081604004
[1, 1454] loss_train: 0.011983, loss_test: 0.006163
time: 0.24405193328857422
time: 2.25850510597229
[1, 1455] loss_train: 0.003521, loss_test: 0.006150
time: 0.2470555305480957
time: 2.2144951820373535
[1, 1456] loss_train: 0.003624, loss_test: 0.006136
time: 0.2420666217803955
time: 2.2385010719299316
[1, 1457] loss_train: 0.008263, loss_test: 0.006126
time: 0.24305367469787598
time: 2.2264983654022217
[1, 1458] loss_train: 0.018709, loss_test: 0.006127
time: 0.24105310440063477
time: 2.2114944458007812
[1, 1459] loss_train: 0.007726, loss_test: 0.006127
time: 0.24305486679077148
time: 2.2280590534210205
[1, 1460] loss_train: 0.006212, loss_test: 0.006122
time: 0.25305604934692383
time: 2.203996181488037
[1, 1461] loss_train: 0.006264, loss_test: 0.006120
time: 0.24305438995361328
time: 2.232501983642578
[1, 1462] loss_train: 0.006625, loss_test: 0.006123
time: 0.25006103515625
time: 2.2430038452148438
[1, 1463] loss_train: 0.011423, loss_test: 0.006132
time: 0.2450542449951172
time: 2.2264978885650635
[1, 1464] loss_train: 0.010654, loss_test: 0.006143
time: 0.2450547218322754
time: 2.2355000972747803
[1, 1465] loss_train: 0.009681, loss_test: 0.006156
time: 0.24305319786071777
time: 2.250504493713379
[1, 1466] loss_train: 0.009319, loss_test: 0.006173
time: 0.24305438995361328
time: 2.2485055923461914
[1, 1467] loss_train: 0.009492, loss_test: 0.006182
time: 0.24405455589294434
time: 2.3285202980041504
[1, 1468] loss_train: 0.001268, loss_test: 0.006174
time: 0.2420661449432373
time: 2.261505603790283
[1, 1469] loss_train: 0.014043, loss_test: 0.006166
time: 0.2940654754638672
time: 2.2885117530822754
[1, 1470] loss_train: 0.008515, loss_test: 0.006156
time: 0.25507044792175293
time: 2.219496488571167
[1, 1471] loss_train: 0.002489, loss_test: 0.006135
time: 0.24405360221862793
time: 2.276512384414673
[1, 1472] loss_train: 0.009985, loss_test: 0.006124
time: 0.24386143684387207
time: 2.255505323410034
[1, 1473] loss_train: 0.004858, loss_test: 0.006121
time: 0.24305319786071777
time: 2.3005154132843018
[1, 1474] loss_train: 0.003961, loss_test: 0.006128
time: 0.2690589427947998
time: 2.3515267372131348
[1, 1475] loss_train: 0.007201, loss_test: 0.006138
time: 0.2670586109161377
time: 2.269508123397827
[1, 1476] loss_train: 0.006720, loss_test: 0.006153
time: 0.24406766891479492
time: 2.243501901626587
[1, 1477] loss_train: 0.014565, loss_test: 0.006138
time: 0.2580568790435791
time: 2.252504348754883
[1, 1478] loss_train: 0.002281, loss_test: 0.006129
time: 0.24505376815795898
time: 2.2725090980529785
[1, 1479] loss_train: 0.010696, loss_test: 0.006117
time: 0.2690591812133789
time: 2.306516408920288
[1, 1480] loss_train: 0.007171, loss_test: 0.006112
time: 0.26605844497680664
time: 2.3245208263397217
[1, 1481] loss_train: 0.005291, loss_test: 0.006114
time: 0.2450544834136963
time: 2.2435014247894287
[1, 1482] loss_train: 0.005220, loss_test: 0.006126
time: 0.2470543384552002
time: 2.2345001697540283
[1, 1483] loss_train: 0.012091, loss_test: 0.006140
time: 0.2470712661743164
time: 2.190992593765259
[1, 1484] loss_train: 0.012938, loss_test: 0.006155
time: 0.2470548152923584
time: 2.2194974422454834
[1, 1485] loss_train: 0.006093, loss_test: 0.006174
time: 0.2470548152923584
time: 2.204493284225464
[1, 1486] loss_train: 0.004770, loss_test: 0.006195
time: 0.2470545768737793
time: 2.22149658203125
[1, 1487] loss_train: 0.009253, loss_test: 0.006217
time: 0.2553215026855469
time: 2.2385003566741943
[1, 1488] loss_train: 0.003985, loss_test: 0.006239
time: 0.2460956573486328
time: 2.2225024700164795
[1, 1489] loss_train: 0.008352, loss_test: 0.006251
time: 0.2540559768676758
time: 2.253507137298584
[1, 1490] loss_train: 0.006312, loss_test: 0.006249
time: 0.25705695152282715
time: 2.2254974842071533
[1, 1491] loss_train: 0.004931, loss_test: 0.006242
time: 0.2520558834075928
time: 2.22249698638916
[1, 1492] loss_train: 0.006670, loss_test: 0.006223
time: 0.25005578994750977
time: 2.234499931335449
[1, 1493] loss_train: 0.010474, loss_test: 0.006204
time: 0.2470550537109375
time: 2.2139992713928223
[1, 1494] loss_train: 0.002591, loss_test: 0.006189
time: 0.24605417251586914
time: 2.2184977531433105
[1, 1495] loss_train: 0.009261, loss_test: 0.006165
time: 0.2470550537109375
time: 2.2405011653900146
[1, 1496] loss_train: 0.004015, loss_test: 0.006145
time: 0.2470548152923584
time: 2.2274980545043945
[1, 1497] loss_train: 0.005105, loss_test: 0.006130
time: 0.24605441093444824
time: 2.2094943523406982
[1, 1498] loss_train: 0.004302, loss_test: 0.006120
time: 0.24605441093444824
time: 2.246502637863159
[1, 1499] loss_train: 0.005313, loss_test: 0.006111
time: 0.24605488777160645
time: 2.220000743865967
[1, 1500] loss_train: 0.005797, loss_test: 0.006100
time: 0.2560572624206543
time: 2.233499526977539
[1, 1501] loss_train: 0.014423, loss_test: 0.006089
time: 0.24605393409729004
time: 2.2355005741119385
[1, 1502] loss_train: 0.002375, loss_test: 0.006082
time: 0.24605417251586914
time: 2.2435028553009033
[1, 1503] loss_train: 0.003023, loss_test: 0.006078
time: 0.24805474281311035
time: 2.2385005950927734
[1, 1504] loss_train: 0.004817, loss_test: 0.006075
time: 0.24605941772460938
time: 2.2024924755096436
[1, 1505] loss_train: 0.005606, loss_test: 0.006075
time: 0.2470557689666748
time: 2.222496747970581
[1, 1506] loss_train: 0.002867, loss_test: 0.006082
time: 0.24605441093444824
time: 2.2145047187805176
[1, 1507] loss_train: 0.004249, loss_test: 0.006090
time: 0.2470550537109375
time: 2.258513927459717
[1, 1508] loss_train: 0.012957, loss_test: 0.006086
time: 0.2490677833557129
time: 2.215498685836792
[1, 1509] loss_train: 0.012821, loss_test: 0.006071
time: 0.24805521965026855
time: 2.204493284225464
[1, 1510] loss_train: 0.005472, loss_test: 0.006060
time: 0.2640810012817383
time: 2.229499340057373
[1, 1511] loss_train: 0.005879, loss_test: 0.006054
time: 0.24509263038635254
time: 2.243502616882324
[1, 1512] loss_train: 0.009411, loss_test: 0.006053
time: 0.24981904029846191
time: 2.2365005016326904
[1, 1513] loss_train: 0.009541, loss_test: 0.006061
time: 0.2470541000366211
time: 2.240501880645752
[1, 1514] loss_train: 0.002726, loss_test: 0.006075
time: 0.25005555152893066
time: 2.2144954204559326
[1, 1515] loss_train: 0.004143, loss_test: 0.006085
time: 0.2474226951599121
time: 2.227132558822632
[1, 1516] loss_train: 0.009911, loss_test: 0.006082
time: 0.2470550537109375
time: 2.2615225315093994
[1, 1517] loss_train: 0.003409, loss_test: 0.006074
time: 0.24505329132080078
time: 2.2605276107788086
[1, 1518] loss_train: 0.006936, loss_test: 0.006059
time: 0.2470543384552002
time: 2.2265026569366455
[1, 1519] loss_train: 0.005618, loss_test: 0.006050
time: 0.24605393409729004
time: 2.2190210819244385
[1, 1520] loss_train: 0.005916, loss_test: 0.006048
time: 0.25905799865722656
time: 2.2335073947906494
[1, 1521] loss_train: 0.007415, loss_test: 0.006052
time: 0.24605417251586914
time: 2.278012990951538
[1, 1522] loss_train: 0.006476, loss_test: 0.006061
time: 0.2470684051513672
time: 2.2274982929229736
[1, 1523] loss_train: 0.004874, loss_test: 0.006072
time: 0.24405455589294434
time: 2.2184979915618896
[1, 1524] loss_train: 0.005511, loss_test: 0.006088
time: 0.2470555305480957
time: 2.232137441635132
[1, 1525] loss_train: 0.006138, loss_test: 0.006102
time: 0.2450544834136963
time: 2.2225117683410645
[1, 1526] loss_train: 0.016223, loss_test: 0.006095
time: 0.24605417251586914
time: 2.243502616882324
[1, 1527] loss_train: 0.004921, loss_test: 0.006084
time: 0.25005602836608887
time: 2.2164974212646484
[1, 1528] loss_train: 0.005258, loss_test: 0.006070
time: 0.24605417251586914
time: 2.2405383586883545
[1, 1529] loss_train: 0.010188, loss_test: 0.006053
time: 0.24605441093444824
time: 2.21197509765625
[1, 1530] loss_train: 0.001991, loss_test: 0.006042
time: 0.25905752182006836
time: 2.217499256134033
[1, 1531] loss_train: 0.003318, loss_test: 0.006037
time: 0.24705743789672852
time: 2.207493782043457
[1, 1532] loss_train: 0.006517, loss_test: 0.006035
time: 0.2470684051513672
time: 2.217496395111084
[1, 1533] loss_train: 0.007327, loss_test: 0.006036
time: 0.24805474281311035
time: 2.226518392562866
[1, 1534] loss_train: 0.007089, loss_test: 0.006039
time: 0.2520558834075928
time: 2.2004919052124023
[1, 1535] loss_train: 0.004631, loss_test: 0.006039
time: 0.2510695457458496
time: 2.219320774078369
[1, 1536] loss_train: 0.010074, loss_test: 0.006043
time: 0.24505400657653809
time: 2.230499267578125
[1, 1537] loss_train: 0.008205, loss_test: 0.006052
time: 0.2510554790496826
time: 2.241501808166504
[1, 1538] loss_train: 0.008178, loss_test: 0.006064
time: 0.2450551986694336
time: 2.2255098819732666
[1, 1539] loss_train: 0.012098, loss_test: 0.006089
time: 0.24605464935302734
time: 2.2450337409973145
[1, 1540] loss_train: 0.007720, loss_test: 0.006102
time: 0.256056547164917
time: 2.2495033740997314
[1, 1541] loss_train: 0.001732, loss_test: 0.006100
time: 0.2490551471710205
time: 2.23449969291687
[1, 1542] loss_train: 0.001702, loss_test: 0.006086
time: 0.24605536460876465
time: 2.2435014247894287
[1, 1543] loss_train: 0.009879, loss_test: 0.006067
time: 0.24605488777160645
time: 2.2005083560943604
[1, 1544] loss_train: 0.005011, loss_test: 0.006049
time: 0.24605417251586914
time: 2.2305173873901367
[1, 1545] loss_train: 0.006596, loss_test: 0.006046
time: 0.24605441093444824
time: 2.2465028762817383
[1, 1546] loss_train: 0.004004, loss_test: 0.006053
time: 0.2470543384552002
time: 2.266507625579834
[1, 1547] loss_train: 0.006811, loss_test: 0.006067
time: 0.2470686435699463
time: 2.2284979820251465
[1, 1548] loss_train: 0.004688, loss_test: 0.006086
time: 0.24605488777160645
time: 2.270019292831421
[1, 1549] loss_train: 0.005575, loss_test: 0.006105
time: 0.24505352973937988
time: 2.241502046585083
[1, 1550] loss_train: 0.010120, loss_test: 0.006103
time: 0.2560563087463379
time: 2.232516050338745
[1, 1551] loss_train: 0.012944, loss_test: 0.006084
time: 0.2470552921295166
time: 2.2505030632019043
[1, 1552] loss_train: 0.005460, loss_test: 0.006078
time: 0.24405479431152344
time: 2.230498790740967
[1, 1553] loss_train: 0.003474, loss_test: 0.006077
time: 0.24605417251586914
time: 2.2355027198791504
[1, 1554] loss_train: 0.012513, loss_test: 0.006074
time: 0.2470543384552002
time: 2.2264983654022217
[1, 1555] loss_train: 0.014482, loss_test: 0.006073
time: 0.24505400657653809
time: 2.2335002422332764
[1, 1556] loss_train: 0.010252, loss_test: 0.006075
time: 0.2470560073852539
time: 2.2385122776031494
[1, 1557] loss_train: 0.002432, loss_test: 0.006081
time: 0.2470545768737793
time: 2.2254981994628906
[1, 1558] loss_train: 0.002991, loss_test: 0.006079
time: 0.24805474281311035
time: 2.2265102863311768
[1, 1559] loss_train: 0.003625, loss_test: 0.006078
time: 0.2450542449951172
time: 2.2314000129699707
[1, 1560] loss_train: 0.004337, loss_test: 0.006083
time: 0.2560570240020752
time: 2.2204971313476562
[1, 1561] loss_train: 0.016126, loss_test: 0.006070
time: 0.2490546703338623
time: 2.2305057048797607
[1, 1562] loss_train: 0.003194, loss_test: 0.006064
time: 0.24805521965026855
time: 2.228501081466675
[1, 1563] loss_train: 0.009331, loss_test: 0.006066
time: 0.2470550537109375
time: 2.2385005950927734
[1, 1564] loss_train: 0.008169, loss_test: 0.006070
time: 0.2510561943054199
time: 2.260505199432373
[1, 1565] loss_train: 0.004344, loss_test: 0.006079
time: 0.2450549602508545
time: 2.223497152328491
[1, 1566] loss_train: 0.007517, loss_test: 0.006085
time: 0.25106382369995117
time: 2.246504783630371
[1, 1567] loss_train: 0.004155, loss_test: 0.006079
time: 0.24605441093444824
time: 2.2204971313476562
[1, 1568] loss_train: 0.009882, loss_test: 0.006069
time: 0.25205564498901367
time: 2.219831705093384
[1, 1569] loss_train: 0.008114, loss_test: 0.006057
time: 0.2470543384552002
time: 2.214495897293091
[1, 1570] loss_train: 0.011653, loss_test: 0.006049
time: 0.25705647468566895
time: 2.214932918548584
[1, 1571] loss_train: 0.006408, loss_test: 0.006043
time: 0.2470552921295166
time: 2.276524543762207
[1, 1572] loss_train: 0.006218, loss_test: 0.006040
time: 0.24605369567871094
time: 2.242502212524414
[1, 1573] loss_train: 0.002904, loss_test: 0.006039
time: 0.24606752395629883
time: 2.2775135040283203
[1, 1574] loss_train: 0.005187, loss_test: 0.006041
time: 0.2470550537109375
time: 2.2615058422088623
[1, 1575] loss_train: 0.003540, loss_test: 0.006042
time: 0.24505400657653809
time: 2.2645058631896973
[1, 1576] loss_train: 0.005822, loss_test: 0.006046
time: 0.2470567226409912
time: 2.2174956798553467
[1, 1577] loss_train: 0.018549, loss_test: 0.006044
time: 0.24706768989562988
time: 2.2625064849853516
[1, 1578] loss_train: 0.014820, loss_test: 0.006051
time: 0.24605369567871094
time: 2.2505037784576416
[1, 1579] loss_train: 0.011097, loss_test: 0.006066
time: 0.2450542449951172
time: 2.2129898071289062
[1, 1580] loss_train: 0.006620, loss_test: 0.006083
time: 0.2540559768676758
time: 2.223505973815918
[1, 1581] loss_train: 0.004611, loss_test: 0.006086
time: 0.2470550537109375
time: 2.234499931335449
[1, 1582] loss_train: 0.000980, loss_test: 0.006084
time: 0.24506187438964844
time: 2.3115172386169434
[1, 1583] loss_train: 0.006395, loss_test: 0.006081
time: 0.25505685806274414
time: 2.217495918273926
[1, 1584] loss_train: 0.005411, loss_test: 0.006079
time: 0.2470552921295166
time: 2.2335011959075928
[1, 1585] loss_train: 0.007361, loss_test: 0.006074
time: 0.24305391311645508
time: 2.317518472671509
[1, 1586] loss_train: 0.009081, loss_test: 0.006066
time: 0.30606794357299805
time: 2.3550546169281006
[1, 1587] loss_train: 0.009825, loss_test: 0.006062
time: 0.37961459159851074
time: 1466.6773941516876
[1, 1588] loss_train: 0.015434, loss_test: 0.006061
time: 0.47728753089904785
time: 3.4264414310455322
[1, 1589] loss_train: 0.005784, loss_test: 0.006059
time: 0.46208715438842773
time: 3.8924124240875244
[1, 1590] loss_train: 0.004895, loss_test: 0.006057
time: 0.5242056846618652
time: 3.255159378051758
[1, 1591] loss_train: 0.001836, loss_test: 0.006054
time: 0.43310046195983887
time: 3.2518129348754883
[1, 1592] loss_train: 0.009938, loss_test: 0.006055
time: 0.4057145118713379
time: 3.2325565814971924
[1, 1593] loss_train: 0.008708, loss_test: 0.006062
time: 0.3757188320159912
time: 3.2083981037139893
[1, 1594] loss_train: 0.007730, loss_test: 0.006065
time: 0.37144041061401367
time: 3.236542224884033
[1, 1595] loss_train: 0.007521, loss_test: 0.006063
time: 0.7873265743255615
time: 2.231499433517456
[1, 1596] loss_train: 0.010419, loss_test: 0.006055
time: 0.24605417251586914
time: 2.2433419227600098
[1, 1597] loss_train: 0.005717, loss_test: 0.006048
time: 0.24605464935302734
time: 2.19899845123291
[1, 1598] loss_train: 0.002858, loss_test: 0.006044
time: 0.24405336380004883
time: 2.216498851776123
[1, 1599] loss_train: 0.005568, loss_test: 0.006042
time: 0.25005578994750977
time: 2.23249888420105
[1, 1600] loss_train: 0.009657, loss_test: 0.006040
time: 0.25505638122558594
time: 2.231499433517456
[1, 1601] loss_train: 0.008298, loss_test: 0.006038
time: 0.2470541000366211
time: 2.2395012378692627
[1, 1602] loss_train: 0.005081, loss_test: 0.006037
time: 0.2450551986694336
time: 2.2625057697296143
[1, 1603] loss_train: 0.005250, loss_test: 0.006037
time: 0.25305652618408203
time: 2.2415027618408203
[1, 1604] loss_train: 0.012454, loss_test: 0.006038
time: 0.2470552921295166
time: 2.2294983863830566
[1, 1605] loss_train: 0.008236, loss_test: 0.006036
time: 0.24605441093444824
time: 2.2265002727508545
[1, 1606] loss_train: 0.004029, loss_test: 0.006036
time: 0.24806833267211914
time: 2.202524185180664
[1, 1607] loss_train: 0.006147, loss_test: 0.006037
time: 0.251056432723999
time: 2.2284936904907227
[1, 1608] loss_train: 0.003916, loss_test: 0.006044
time: 0.2440652847290039
time: 2.2094945907592773
[1, 1609] loss_train: 0.005365, loss_test: 0.006052
time: 0.24936413764953613
time: 2.2585055828094482
[1, 1610] loss_train: 0.002141, loss_test: 0.006063
time: 0.2630581855773926
time: 2.2465031147003174
[1, 1611] loss_train: 0.001823, loss_test: 0.006072
time: 0.25705718994140625
time: 2.2144949436187744
[1, 1612] loss_train: 0.020044, loss_test: 0.006063
time: 0.24505376815795898
time: 2.2545082569122314
[1, 1613] loss_train: 0.001034, loss_test: 0.006063
time: 0.2470541000366211
time: 2.2355000972747803
[1, 1614] loss_train: 0.006231, loss_test: 0.006059
time: 0.24405479431152344
time: 2.2279319763183594
[1, 1615] loss_train: 0.003249, loss_test: 0.006058
time: 0.24505400657653809
time: 2.242501735687256
[1, 1616] loss_train: 0.007975, loss_test: 0.006057
time: 0.24305415153503418
time: 2.2235162258148193
[1, 1617] loss_train: 0.006038, loss_test: 0.006058
time: 0.24405455589294434
time: 2.2334985733032227
[1, 1618] loss_train: 0.004476, loss_test: 0.006059
time: 0.2450551986694336
time: 2.225013494491577
[1, 1619] loss_train: 0.008008, loss_test: 0.006056
time: 0.24506735801696777
time: 2.2645068168640137
[1, 1620] loss_train: 0.012177, loss_test: 0.006047
time: 0.2560570240020752
time: 2.265521287918091
[1, 1621] loss_train: 0.002676, loss_test: 0.006042
time: 0.2450551986694336
time: 2.2385005950927734
[1, 1622] loss_train: 0.006907, loss_test: 0.006040
time: 0.24305343627929688
time: 2.229508399963379
[1, 1623] loss_train: 0.004006, loss_test: 0.006038
time: 0.24605464935302734
time: 2.233499526977539
[1, 1624] loss_train: 0.002412, loss_test: 0.006038
time: 0.2450547218322754
time: 2.2294981479644775
[1, 1625] loss_train: 0.003375, loss_test: 0.006044
time: 0.24506592750549316
time: 2.2255070209503174
[1, 1626] loss_train: 0.003978, loss_test: 0.006053
time: 0.24405384063720703
time: 2.2375011444091797
[1, 1627] loss_train: 0.004080, loss_test: 0.006065
time: 0.24305367469787598
time: 2.232499361038208
[1, 1628] loss_train: 0.009966, loss_test: 0.006068
time: 0.25005507469177246
time: 2.231499195098877
[1, 1629] loss_train: 0.005372, loss_test: 0.006070
time: 0.2450547218322754
time: 2.2405006885528564
[1, 1630] loss_train: 0.017892, loss_test: 0.006049
time: 0.256056547164917
time: 2.2515032291412354
[1, 1631] loss_train: 0.010139, loss_test: 0.006026
time: 0.24505376815795898
time: 2.233499765396118
[1, 1632] loss_train: 0.008029, loss_test: 0.006015
time: 0.2450547218322754
time: 2.2095069885253906
[1, 1633] loss_train: 0.005672, loss_test: 0.006018
time: 0.24605417251586914
time: 2.2089977264404297
[1, 1634] loss_train: 0.009390, loss_test: 0.006027
time: 0.2450542449951172
time: 2.2104947566986084
[1, 1635] loss_train: 0.001983, loss_test: 0.006034
time: 0.24805498123168945
time: 2.234499454498291
[1, 1636] loss_train: 0.003048, loss_test: 0.006036
time: 0.2490553855895996
time: 2.234499454498291
[1, 1637] loss_train: 0.002540, loss_test: 0.006039
time: 0.24706768989562988
time: 2.218501091003418
[1, 1638] loss_train: 0.007193, loss_test: 0.006039
time: 0.2470550537109375
time: 2.2114949226379395
[1, 1639] loss_train: 0.005410, loss_test: 0.006040
time: 0.24608373641967773
time: 2.2094924449920654
[1, 1640] loss_train: 0.006358, loss_test: 0.006042
time: 0.2540566921234131
time: 2.279510259628296
[1, 1641] loss_train: 0.006643, loss_test: 0.006044
time: 0.24405455589294434
time: 2.223517417907715
[1, 1642] loss_train: 0.010165, loss_test: 0.006056
time: 0.24605441093444824
time: 2.2345192432403564
[1, 1643] loss_train: 0.010516, loss_test: 0.006059
time: 0.2470543384552002
time: 2.2205042839050293
[1, 1644] loss_train: 0.007689, loss_test: 0.006058
time: 0.24606752395629883
time: 2.208493947982788
[1, 1645] loss_train: 0.006358, loss_test: 0.006054
time: 0.24307918548583984
time: 2.2144980430603027
[1, 1646] loss_train: 0.009196, loss_test: 0.006047
time: 0.24605512619018555
time: 2.2515034675598145
[1, 1647] loss_train: 0.011073, loss_test: 0.006037
time: 0.24305367469787598
time: 2.221532106399536
[1, 1648] loss_train: 0.012065, loss_test: 0.006027
time: 0.24405431747436523
time: 2.18949031829834
[1, 1649] loss_train: 0.009243, loss_test: 0.006015
time: 0.24605464935302734
time: 2.211695909500122
[1, 1650] loss_train: 0.003243, loss_test: 0.006013
time: 0.2580580711364746
time: 2.2625060081481934
[1, 1651] loss_train: 0.011355, loss_test: 0.006023
time: 0.24406647682189941
time: 2.232499122619629
[1, 1652] loss_train: 0.007321, loss_test: 0.006044
time: 0.24605441093444824
time: 2.219496726989746
[1, 1653] loss_train: 0.015928, loss_test: 0.006065
time: 0.25005507469177246
time: 2.2265126705169678
[1, 1654] loss_train: 0.006854, loss_test: 0.006077
time: 0.2470543384552002
time: 2.216496229171753
[1, 1655] loss_train: 0.003497, loss_test: 0.006065
time: 0.2530555725097656
time: 2.3245198726654053
[1, 1656] loss_train: 0.007973, loss_test: 0.006045
time: 0.24605417251586914
time: 2.2375035285949707
[1, 1657] loss_train: 0.002942, loss_test: 0.006027
time: 0.2450542449951172
time: 2.227498769760132
[1, 1658] loss_train: 0.004311, loss_test: 0.006015
time: 0.24506616592407227
time: 2.219496488571167
[1, 1659] loss_train: 0.003841, loss_test: 0.006016
time: 0.25310778617858887
time: 2.2100272178649902
[1, 1660] loss_train: 0.003083, loss_test: 0.006027
time: 0.2560575008392334
time: 2.2425010204315186
[1, 1661] loss_train: 0.009494, loss_test: 0.006037
time: 0.2490556240081787
time: 2.2244973182678223
[1, 1662] loss_train: 0.001683, loss_test: 0.006054
time: 0.24105429649353027
time: 2.217503070831299
[1, 1663] loss_train: 0.007432, loss_test: 0.006069
time: 0.23905110359191895
time: 2.2300126552581787
[1, 1664] loss_train: 0.002603, loss_test: 0.006088
time: 0.2450542449951172
time: 2.2324981689453125
[1, 1665] loss_train: 0.007624, loss_test: 0.006095
time: 0.24805450439453125
time: 2.2520344257354736
[1, 1666] loss_train: 0.011274, loss_test: 0.006085
time: 0.24405384063720703
time: 2.2445027828216553
[1, 1667] loss_train: 0.018541, loss_test: 0.006057
time: 0.24506616592407227
time: 2.2725298404693604
[1, 1668] loss_train: 0.013301, loss_test: 0.006067
time: 0.2450542449951172
time: 2.243502378463745
[1, 1669] loss_train: 0.004571, loss_test: 0.006112
time: 0.24405360221862793
time: 2.20149302482605
[1, 1670] loss_train: 0.006655, loss_test: 0.006123
time: 0.256056547164917
time: 2.297517776489258
[1, 1671] loss_train: 0.004976, loss_test: 0.006118
time: 0.24405336380004883
time: 2.199495315551758
[1, 1672] loss_train: 0.004571, loss_test: 0.006101
time: 0.24405956268310547
time: 2.2344985008239746
[1, 1673] loss_train: 0.013552, loss_test: 0.006084
time: 0.24405455589294434
time: 2.2605156898498535
[1, 1674] loss_train: 0.004110, loss_test: 0.006055
time: 0.24405503273010254
time: 2.219496965408325
[1, 1675] loss_train: 0.005998, loss_test: 0.006037
time: 0.2450544834136963
time: 2.2555043697357178
[1, 1676] loss_train: 0.001459, loss_test: 0.006026
time: 0.24505400657653809
time: 2.2385008335113525
[1, 1677] loss_train: 0.010007, loss_test: 0.006024
time: 0.25005626678466797
time: 2.227092981338501
[1, 1678] loss_train: 0.011077, loss_test: 0.006023
time: 0.24305367469787598
time: 2.2355005741119385
[1, 1679] loss_train: 0.004372, loss_test: 0.006028
time: 0.24805641174316406
time: 2.2244865894317627
[1, 1680] loss_train: 0.013536, loss_test: 0.006035
time: 0.25705766677856445
time: 2.279510259628296
[1, 1681] loss_train: 0.004556, loss_test: 0.006043
time: 0.25505566596984863
time: 2.3190219402313232
[1, 1682] loss_train: 0.004699, loss_test: 0.006054
time: 0.2560572624206543
time: 2.2455027103424072
[1, 1683] loss_train: 0.004012, loss_test: 0.006066
time: 0.24309229850769043
time: 2.2740235328674316
[1, 1684] loss_train: 0.009440, loss_test: 0.006061
time: 0.24534010887145996
time: 2.2485032081604004
[1, 1685] loss_train: 0.006039, loss_test: 0.006057
time: 0.2450544834136963
time: 2.2025012969970703
[1, 1686] loss_train: 0.007270, loss_test: 0.006055
time: 0.2540571689605713
time: 2.2395005226135254
[1, 1687] loss_train: 0.003108, loss_test: 0.006050
time: 0.2470552921295166
time: 2.2154958248138428
[1, 1688] loss_train: 0.010164, loss_test: 0.006052
time: 0.24455809593200684
time: 2.2220101356506348
[1, 1689] loss_train: 0.005736, loss_test: 0.006054
time: 0.24505400657653809
time: 2.2375001907348633
[1, 1690] loss_train: 0.013723, loss_test: 0.006056
time: 0.2560575008392334
time: 2.2645061016082764
[1, 1691] loss_train: 0.006609, loss_test: 0.006050
time: 0.24605417251586914
time: 2.216495990753174
[1, 1692] loss_train: 0.006975, loss_test: 0.006040
time: 0.24405336380004883
time: 2.256009101867676
[1, 1693] loss_train: 0.002764, loss_test: 0.006031
time: 0.2450547218322754
time: 2.221498489379883
[1, 1694] loss_train: 0.007566, loss_test: 0.006027
time: 0.24805498123168945
time: 2.218501567840576
[1, 1695] loss_train: 0.009823, loss_test: 0.006025
time: 0.2450559139251709
time: 2.217495918273926
[1, 1696] loss_train: 0.007761, loss_test: 0.006026
time: 0.2490556240081787
time: 2.239502429962158
[1, 1697] loss_train: 0.002557, loss_test: 0.006029
time: 0.2450544834136963
time: 2.2295005321502686
[1, 1698] loss_train: 0.006687, loss_test: 0.006033
time: 0.2470543384552002
time: 2.232011079788208
[1, 1699] loss_train: 0.003955, loss_test: 0.006034
time: 0.2450542449951172
time: 2.2345004081726074
[1, 1700] loss_train: 0.005983, loss_test: 0.006031
time: 0.25905704498291016
time: 2.2835114002227783
[1, 1701] loss_train: 0.004529, loss_test: 0.006026
time: 0.24805450439453125
time: 2.2630512714385986
[1, 1702] loss_train: 0.002390, loss_test: 0.006024
time: 0.2490551471710205
time: 2.205493450164795
[1, 1703] loss_train: 0.003536, loss_test: 0.006027
time: 0.24405407905578613
time: 2.231499195098877
[1, 1704] loss_train: 0.017581, loss_test: 0.006008
time: 0.24605512619018555
time: 2.2164952754974365
[1, 1705] loss_train: 0.005602, loss_test: 0.006003
time: 0.24305367469787598
time: 2.2104947566986084
[1, 1706] loss_train: 0.008709, loss_test: 0.006011
time: 0.24405384063720703
time: 2.2064931392669678
[1, 1707] loss_train: 0.008001, loss_test: 0.006023
time: 0.24405407905578613
time: 2.2144975662231445
[1, 1708] loss_train: 0.009288, loss_test: 0.006042
time: 0.24605417251586914
time: 2.2064945697784424
[1, 1709] loss_train: 0.011362, loss_test: 0.006065
time: 0.24505376815795898
time: 2.228499174118042
[1, 1710] loss_train: 0.009418, loss_test: 0.006070
time: 0.2540559768676758
time: 2.2395012378692627
[1, 1711] loss_train: 0.005995, loss_test: 0.006070
time: 0.2450559139251709
time: 2.2314999103546143
[1, 1712] loss_train: 0.007812, loss_test: 0.006061
time: 0.24605464935302734
time: 2.23223876953125
[1, 1713] loss_train: 0.002318, loss_test: 0.006048
time: 0.24605512619018555
time: 2.2114944458007812
[1, 1714] loss_train: 0.010527, loss_test: 0.006027
time: 0.24405431747436523
time: 2.2385005950927734
[1, 1715] loss_train: 0.003180, loss_test: 0.006013
time: 0.24505376815795898
time: 2.2505037784576416
[1, 1716] loss_train: 0.002443, loss_test: 0.006011
time: 0.24605464935302734
time: 2.229498863220215
[1, 1717] loss_train: 0.012122, loss_test: 0.006018
time: 0.247056245803833
time: 2.206494092941284
[1, 1718] loss_train: 0.007297, loss_test: 0.006028
time: 0.24605512619018555
time: 2.2005064487457275
[1, 1719] loss_train: 0.006346, loss_test: 0.006040
time: 0.2500569820404053
time: 2.2214975357055664
[1, 1720] loss_train: 0.007422, loss_test: 0.006051
time: 0.25505590438842773
time: 2.2695183753967285
[1, 1721] loss_train: 0.006300, loss_test: 0.006062
time: 0.2510550022125244
time: 2.193491220474243
[1, 1722] loss_train: 0.004462, loss_test: 0.006073
time: 0.24305367469787598
time: 2.209503173828125
[1, 1723] loss_train: 0.013178, loss_test: 0.006063
time: 0.24405360221862793
time: 2.2155075073242188
[1, 1724] loss_train: 0.001991, loss_test: 0.006059
time: 0.24406766891479492
time: 2.2525033950805664
[1, 1725] loss_train: 0.005031, loss_test: 0.006058
time: 0.24205374717712402
time: 2.218496322631836
[1, 1726] loss_train: 0.005514, loss_test: 0.006056
time: 0.2470555305480957
time: 2.2114949226379395
[1, 1727] loss_train: 0.003182, loss_test: 0.006054
time: 0.24405407905578613
time: 2.219496726989746
[1, 1728] loss_train: 0.012084, loss_test: 0.006041
time: 0.256056547164917
time: 2.253504514694214
[1, 1729] loss_train: 0.004823, loss_test: 0.006035
time: 0.24514985084533691
time: 2.2254974842071533
[1, 1730] loss_train: 0.005281, loss_test: 0.006034
time: 0.2580704689025879
time: 2.2495169639587402
[1, 1731] loss_train: 0.011169, loss_test: 0.006042
time: 0.24605345726013184
time: 2.196491241455078
[1, 1732] loss_train: 0.005319, loss_test: 0.006052
time: 0.24505400657653809
time: 2.215498208999634
[1, 1733] loss_train: 0.005225, loss_test: 0.006065
time: 0.24706792831420898
time: 2.215496301651001
[1, 1734] loss_train: 0.011899, loss_test: 0.006070
time: 0.25005483627319336
time: 2.2325010299682617
[1, 1735] loss_train: 0.011732, loss_test: 0.006072
time: 0.2450542449951172
time: 2.2465028762817383
[1, 1736] loss_train: 0.000996, loss_test: 0.006071
time: 0.24810457229614258
time: 2.230836868286133
[1, 1737] loss_train: 0.003666, loss_test: 0.006060
time: 0.24405407905578613
time: 2.259504556655884
[1, 1738] loss_train: 0.004410, loss_test: 0.006057
time: 0.24905633926391602
time: 2.243501663208008
[1, 1739] loss_train: 0.007022, loss_test: 0.006063
time: 0.24506855010986328
time: 2.233499050140381
[1, 1740] loss_train: 0.012178, loss_test: 0.006053
time: 0.26306962966918945
time: 2.255511522293091
[1, 1741] loss_train: 0.004211, loss_test: 0.006046
time: 0.24405455589294434
time: 2.2405004501342773
[1, 1742] loss_train: 0.014523, loss_test: 0.006035
time: 0.2470686435699463
time: 2.193491220474243
[1, 1743] loss_train: 0.007481, loss_test: 0.006027
time: 0.2450547218322754
time: 2.257504940032959
[1, 1744] loss_train: 0.008307, loss_test: 0.006024
time: 0.24605417251586914
time: 2.2305195331573486
[1, 1745] loss_train: 0.009753, loss_test: 0.006024
time: 0.2460780143737793
time: 2.194491147994995
[1, 1746] loss_train: 0.007779, loss_test: 0.006030
time: 0.2450542449951172
time: 2.2646865844726562
[1, 1747] loss_train: 0.007969, loss_test: 0.006034
time: 0.24805569648742676
time: 2.257514715194702
[1, 1748] loss_train: 0.014414, loss_test: 0.006055
time: 0.24405455589294434
time: 2.259518623352051
[1, 1749] loss_train: 0.005597, loss_test: 0.006072
time: 0.24210071563720703
time: 2.2100391387939453
[1, 1750] loss_train: 0.005415, loss_test: 0.006080
time: 0.27306103706359863
time: 2.24650239944458
[1, 1751] loss_train: 0.007614, loss_test: 0.006078
time: 0.24505400657653809
time: 2.265507459640503
[1, 1752] loss_train: 0.015959, loss_test: 0.006072
time: 0.24505352973937988
time: 2.2114956378936768
[1, 1753] loss_train: 0.011246, loss_test: 0.006068
time: 0.24305343627929688
time: 2.189509391784668
[1, 1754] loss_train: 0.005470, loss_test: 0.006064
time: 0.24706697463989258
time: 2.196491241455078
[1, 1755] loss_train: 0.016121, loss_test: 0.006061
time: 0.24405622482299805
time: 2.2264978885650635
[1, 1756] loss_train: 0.003510, loss_test: 0.006053
time: 0.24605393409729004
time: 2.2184970378875732
[1, 1757] loss_train: 0.002258, loss_test: 0.006041
time: 0.24505376815795898
time: 2.1834943294525146
[1, 1758] loss_train: 0.003305, loss_test: 0.006037
time: 0.24505400657653809
time: 2.229499101638794
[1, 1759] loss_train: 0.004927, loss_test: 0.006041
time: 0.2490553855895996
time: 2.213494300842285
[1, 1760] loss_train: 0.002864, loss_test: 0.006054
time: 0.25507259368896484
time: 2.2765095233917236
[1, 1761] loss_train: 0.002506, loss_test: 0.006072
time: 0.2560560703277588
time: 2.2345001697540283
[1, 1762] loss_train: 0.006715, loss_test: 0.006088
time: 0.24605441093444824
time: 2.2605061531066895
[1, 1763] loss_train: 0.007114, loss_test: 0.006098
time: 0.2490551471710205
time: 2.2140073776245117
[1, 1764] loss_train: 0.005556, loss_test: 0.006107
time: 0.24405384063720703
time: 2.218498945236206
[1, 1765] loss_train: 0.010411, loss_test: 0.006098
time: 0.2470548152923584
time: 2.210526704788208
[1, 1766] loss_train: 0.009198, loss_test: 0.006086
time: 0.24305415153503418
time: 2.233502149581909
[1, 1767] loss_train: 0.016277, loss_test: 0.006051
time: 0.24505352973937988
time: 2.24450945854187
[1, 1768] loss_train: 0.006482, loss_test: 0.006025
time: 0.24605512619018555
time: 2.2264978885650635
[1, 1769] loss_train: 0.006080, loss_test: 0.006014
time: 0.24406695365905762
time: 2.215012311935425
[1, 1770] loss_train: 0.001913, loss_test: 0.006014
time: 0.2540559768676758
time: 2.233527183532715
[1, 1771] loss_train: 0.015153, loss_test: 0.006014
time: 0.24405455589294434
time: 2.2535030841827393
[1, 1772] loss_train: 0.005871, loss_test: 0.006021
time: 0.24405455589294434
time: 2.217496156692505
[1, 1773] loss_train: 0.012291, loss_test: 0.006034
time: 0.24405479431152344
time: 2.218496084213257
[1, 1774] loss_train: 0.002839, loss_test: 0.006053
time: 0.24405407905578613
time: 2.2475028038024902
[1, 1775] loss_train: 0.006510, loss_test: 0.006071
time: 0.24906706809997559
time: 2.2315096855163574
[1, 1776] loss_train: 0.013812, loss_test: 0.006082
time: 0.24405336380004883
time: 2.221505880355835
[1, 1777] loss_train: 0.003166, loss_test: 0.006076
time: 0.2450547218322754
time: 2.228020429611206
[1, 1778] loss_train: 0.003256, loss_test: 0.006064
time: 0.24605584144592285
time: 2.199500322341919
[1, 1779] loss_train: 0.007386, loss_test: 0.006040
time: 0.2450544834136963
time: 2.190507173538208
[1, 1780] loss_train: 0.005637, loss_test: 0.006032
time: 0.2600576877593994
time: 2.259505271911621
[1, 1781] loss_train: 0.013396, loss_test: 0.006037
time: 0.24405431747436523
time: 2.2255167961120605
[1, 1782] loss_train: 0.004415, loss_test: 0.006051
time: 0.25005531311035156
time: 2.263516426086426
[1, 1783] loss_train: 0.013741, loss_test: 0.006050
time: 0.2540566921234131
time: 2.25750470161438
[1, 1784] loss_train: 0.006565, loss_test: 0.006059
time: 0.2510557174682617
time: 2.255504608154297
[1, 1785] loss_train: 0.001637, loss_test: 0.006059
time: 0.2490558624267578
time: 2.256505250930786
[1, 1786] loss_train: 0.012088, loss_test: 0.006054
time: 0.24805355072021484
time: 2.2615060806274414
[1, 1787] loss_train: 0.003552, loss_test: 0.006064
time: 0.2450544834136963
time: 2.243501663208008
[1, 1788] loss_train: 0.009985, loss_test: 0.006094
time: 0.2490551471710205
time: 2.257504940032959
[1, 1789] loss_train: 0.007132, loss_test: 0.006129
time: 0.24505400657653809
time: 2.219496726989746
[1, 1790] loss_train: 0.001548, loss_test: 0.006167
time: 0.26105785369873047
time: 2.2635066509246826
[1, 1791] loss_train: 0.000967, loss_test: 0.006215
time: 0.2470548152923584
time: 2.2180042266845703
[1, 1792] loss_train: 0.006772, loss_test: 0.006250
time: 0.24805450439453125
time: 2.242501974105835
[1, 1793] loss_train: 0.006906, loss_test: 0.006265
time: 0.24405384063720703
time: 2.219496726989746
[1, 1794] loss_train: 0.008161, loss_test: 0.006223
time: 0.24805498123168945
time: 2.2365007400512695
[1, 1795] loss_train: 0.009056, loss_test: 0.006173
time: 0.24605512619018555
time: 2.2235074043273926
[1, 1796] loss_train: 0.004177, loss_test: 0.006125
time: 0.24405336380004883
time: 2.239501953125
[1, 1797] loss_train: 0.005532, loss_test: 0.006096
time: 0.24307966232299805
time: 2.219496011734009
[1, 1798] loss_train: 0.007176, loss_test: 0.006089
time: 0.2450549602508545
time: 2.237499475479126
[1, 1799] loss_train: 0.006987, loss_test: 0.006094
time: 0.24105453491210938
time: 2.2560243606567383
[1, 1800] loss_train: 0.005846, loss_test: 0.006111
time: 0.25905752182006836
time: 2.2755088806152344
[1, 1801] loss_train: 0.004044, loss_test: 0.006142
time: 0.2450554370880127
time: 2.2304975986480713
[1, 1802] loss_train: 0.007437, loss_test: 0.006164
time: 0.24706220626831055
time: 2.195507764816284
[1, 1803] loss_train: 0.011949, loss_test: 0.006162
time: 0.2450544834136963
time: 2.2475030422210693
[1, 1804] loss_train: 0.004523, loss_test: 0.006156
time: 0.24409914016723633
time: 2.2505040168762207
[1, 1805] loss_train: 0.012012, loss_test: 0.006108
time: 0.24305295944213867
time: 2.1975033283233643
[1, 1806] loss_train: 0.004083, loss_test: 0.006080
time: 0.24607348442077637
time: 2.249006509780884
[1, 1807] loss_train: 0.004538, loss_test: 0.006065
time: 0.24205350875854492
time: 2.2375004291534424
[1, 1808] loss_train: 0.005779, loss_test: 0.006060
time: 0.2470545768737793
time: 2.2340049743652344
[1, 1809] loss_train: 0.003505, loss_test: 0.006059
time: 0.24605464935302734
time: 2.2515041828155518
[1, 1810] loss_train: 0.010674, loss_test: 0.006064
time: 0.25705742835998535
time: 2.270507335662842
[1, 1811] loss_train: 0.001244, loss_test: 0.006064
time: 0.24605703353881836
time: 2.2585058212280273
[1, 1812] loss_train: 0.003679, loss_test: 0.006058
time: 0.2470550537109375
time: 2.2355000972747803
[1, 1813] loss_train: 0.005469, loss_test: 0.006051
time: 0.24505352973937988
time: 2.2124955654144287
[1, 1814] loss_train: 0.002884, loss_test: 0.006035
time: 0.24505376815795898
time: 2.203493595123291
[1, 1815] loss_train: 0.007054, loss_test: 0.006022
time: 0.24605417251586914
time: 2.221022367477417
[1, 1816] loss_train: 0.003736, loss_test: 0.006019
time: 0.24605441093444824
time: 2.215496063232422
[1, 1817] loss_train: 0.008510, loss_test: 0.006027
time: 0.2490551471710205
time: 2.2245023250579834
[1, 1818] loss_train: 0.003448, loss_test: 0.006044
time: 0.24505376815795898
time: 2.215496063232422
[1, 1819] loss_train: 0.002812, loss_test: 0.006070
time: 0.2470545768737793
time: 2.2510323524475098
[1, 1820] loss_train: 0.009241, loss_test: 0.006113
time: 0.252056360244751
time: 2.271507978439331
[1, 1821] loss_train: 0.006075, loss_test: 0.006144
time: 0.25005578994750977
time: 2.2345352172851562
[1, 1822] loss_train: 0.005495, loss_test: 0.006167
time: 0.24505400657653809
time: 2.2405195236206055
[1, 1823] loss_train: 0.006066, loss_test: 0.006174
time: 0.2530558109283447
time: 2.2525038719177246
[1, 1824] loss_train: 0.007872, loss_test: 0.006153
time: 0.24406719207763672
time: 2.2655062675476074
[1, 1825] loss_train: 0.006387, loss_test: 0.006128
time: 0.24805545806884766
time: 2.260505437850952
[1, 1826] loss_train: 0.006682, loss_test: 0.006088
time: 0.24805474281311035
time: 2.226010799407959
[1, 1827] loss_train: 0.012647, loss_test: 0.006047
time: 0.24805521965026855
time: 2.214498519897461
[1, 1828] loss_train: 0.007949, loss_test: 0.006017
time: 0.24305343627929688
time: 2.2244980335235596
[1, 1829] loss_train: 0.009375, loss_test: 0.006005
time: 0.24305462837219238
time: 2.241053581237793
[1, 1830] loss_train: 0.003241, loss_test: 0.006006
time: 0.2550692558288574
time: 2.252514123916626
[1, 1831] loss_train: 0.004562, loss_test: 0.006012
time: 0.24306750297546387
time: 2.2425010204315186
[1, 1832] loss_train: 0.012466, loss_test: 0.006019
time: 0.24305438995361328
time: 2.251007080078125
[1, 1833] loss_train: 0.012475, loss_test: 0.006028
time: 0.24605464935302734
time: 2.241501569747925
[1, 1834] loss_train: 0.003465, loss_test: 0.006032
time: 0.24405431747436523
time: 2.2755091190338135
[1, 1835] loss_train: 0.006340, loss_test: 0.006027
time: 0.24505352973937988
time: 2.246504783630371
[1, 1836] loss_train: 0.010657, loss_test: 0.006023
time: 0.24605488777160645
time: 2.2495028972625732
[1, 1837] loss_train: 0.002070, loss_test: 0.006013
time: 0.24405455589294434
time: 2.2337889671325684
[1, 1838] loss_train: 0.007402, loss_test: 0.006007
time: 0.24505901336669922
time: 2.2264983654022217
[1, 1839] loss_train: 0.002708, loss_test: 0.006002
time: 0.2450544834136963
time: 2.2284984588623047
[1, 1840] loss_train: 0.010364, loss_test: 0.005999
time: 0.25705575942993164
time: 2.2605063915252686
[1, 1841] loss_train: 0.007226, loss_test: 0.005995
time: 0.24806761741638184
time: 2.2134952545166016
[1, 1842] loss_train: 0.006092, loss_test: 0.005995
time: 0.24405479431152344
time: 2.2310032844543457
[1, 1843] loss_train: 0.015728, loss_test: 0.005992
time: 0.25005507469177246
time: 2.2365028858184814
[1, 1844] loss_train: 0.007733, loss_test: 0.005992
time: 0.24406647682189941
time: 2.2395031452178955
[1, 1845] loss_train: 0.010966, loss_test: 0.005995
time: 0.24606752395629883
time: 2.218496322631836
[1, 1846] loss_train: 0.008094, loss_test: 0.006005
time: 0.2450542449951172
time: 2.229532480239868
[1, 1847] loss_train: 0.006192, loss_test: 0.006029
time: 0.24605655670166016
time: 2.2590081691741943
[1, 1848] loss_train: 0.006167, loss_test: 0.006056
time: 0.2450544834136963
time: 2.205376386642456
[1, 1849] loss_train: 0.006445, loss_test: 0.006078
time: 0.24605488777160645
time: 2.206493377685547
[1, 1850] loss_train: 0.005400, loss_test: 0.006080
time: 0.2580585479736328
time: 2.2554168701171875
[1, 1851] loss_train: 0.007904, loss_test: 0.006072
time: 0.2450544834136963
time: 2.2054929733276367
[1, 1852] loss_train: 0.003027, loss_test: 0.006053
time: 0.24955964088439941
time: 2.261507034301758
[1, 1853] loss_train: 0.001169, loss_test: 0.006025
time: 0.24605488777160645
time: 2.2254981994628906
[1, 1854] loss_train: 0.006939, loss_test: 0.006002
time: 0.25006818771362305
time: 2.195492744445801
[1, 1855] loss_train: 0.011750, loss_test: 0.005991
time: 0.24405431747436523
time: 2.2535037994384766
[1, 1856] loss_train: 0.016870, loss_test: 0.005989
time: 0.24605512619018555
time: 2.247523069381714
[1, 1857] loss_train: 0.007279, loss_test: 0.005986
time: 0.2470548152923584
time: 2.2134950160980225
[1, 1858] loss_train: 0.011662, loss_test: 0.005984
time: 0.24405336380004883
time: 2.2273173332214355
[1, 1859] loss_train: 0.013757, loss_test: 0.005984
time: 0.24605417251586914
time: 2.231499433517456
[1, 1860] loss_train: 0.008264, loss_test: 0.005983
time: 0.26105761528015137
time: 2.2475032806396484
[1, 1861] loss_train: 0.008102, loss_test: 0.005983
time: 0.2440967559814453
time: 2.235499858856201
[1, 1862] loss_train: 0.007050, loss_test: 0.005982
time: 0.24205303192138672
time: 2.2104973793029785
[1, 1863] loss_train: 0.003954, loss_test: 0.005984
time: 0.24405407905578613
time: 2.2334988117218018
[1, 1864] loss_train: 0.011231, loss_test: 0.005987
time: 0.24705219268798828
time: 2.2415106296539307
[1, 1865] loss_train: 0.003123, loss_test: 0.005991
time: 0.24405407905578613
time: 2.2117276191711426
[1, 1866] loss_train: 0.003031, loss_test: 0.006000
time: 0.2450554370880127
time: 2.186373233795166
[1, 1867] loss_train: 0.000725, loss_test: 0.006016
time: 0.2470543384552002
time: 2.1954915523529053
[1, 1868] loss_train: 0.012407, loss_test: 0.006022
time: 0.24605536460876465
time: 2.2275123596191406
[1, 1869] loss_train: 0.001740, loss_test: 0.006033
time: 0.24506640434265137
time: 2.259042501449585
[1, 1870] loss_train: 0.002657, loss_test: 0.006043
time: 0.2560577392578125
time: 2.2540085315704346
[1, 1871] loss_train: 0.006893, loss_test: 0.006041
time: 0.2470550537109375
time: 2.233499526977539
[1, 1872] loss_train: 0.000613, loss_test: 0.006045
time: 0.2450547218322754
time: 2.2639236450195312
[1, 1873] loss_train: 0.005019, loss_test: 0.006051
time: 0.24605441093444824
time: 2.2465031147003174
[1, 1874] loss_train: 0.008958, loss_test: 0.006044
time: 0.2450547218322754
time: 2.2125232219696045
[1, 1875] loss_train: 0.001131, loss_test: 0.006042
time: 0.2490556240081787
time: 2.237517833709717
[1, 1876] loss_train: 0.004292, loss_test: 0.006040
time: 0.24605464935302734
time: 2.2395012378692627
[1, 1877] loss_train: 0.005367, loss_test: 0.006035
time: 0.24907183647155762
time: 2.215496063232422
[1, 1878] loss_train: 0.001883, loss_test: 0.006037
time: 0.2470541000366211
time: 2.236515760421753
[1, 1879] loss_train: 0.016463, loss_test: 0.006024
time: 0.2470543384552002
time: 2.241501569747925
[1, 1880] loss_train: 0.004453, loss_test: 0.006014
time: 0.25707030296325684
time: 2.267512083053589
[1, 1881] loss_train: 0.003402, loss_test: 0.006007
time: 0.25005531311035156
time: 2.2510597705841064
[1, 1882] loss_train: 0.005481, loss_test: 0.006003
time: 0.24507975578308105
time: 2.2254981994628906
[1, 1883] loss_train: 0.010238, loss_test: 0.005996
time: 0.2470552921295166
time: 2.220496892929077
[1, 1884] loss_train: 0.003662, loss_test: 0.005994
time: 0.24505376815795898
time: 2.25053071975708
[1, 1885] loss_train: 0.001717, loss_test: 0.005993
time: 0.24605488777160645
time: 2.2284979820251465
[1, 1886] loss_train: 0.002541, loss_test: 0.005994
time: 0.2450709342956543
time: 2.219496965408325
[1, 1887] loss_train: 0.006491, loss_test: 0.005994
time: 0.2470545768737793
time: 2.208493709564209
[1, 1888] loss_train: 0.008254, loss_test: 0.005995
time: 0.24505352973937988
time: 2.227513074874878
[1, 1889] loss_train: 0.005244, loss_test: 0.005996
time: 0.2470545768737793
time: 2.2154955863952637
[1, 1890] loss_train: 0.008258, loss_test: 0.005997
time: 0.25705647468566895
time: 2.242501974105835
[1, 1891] loss_train: 0.005410, loss_test: 0.005997
time: 0.24405360221862793
time: 2.2264983654022217
[1, 1892] loss_train: 0.003732, loss_test: 0.005999
time: 0.24505400657653809
time: 2.2244980335235596
[1, 1893] loss_train: 0.012523, loss_test: 0.006001
time: 0.24605464935302734
time: 2.2455015182495117
[1, 1894] loss_train: 0.005416, loss_test: 0.006005
time: 0.24605488777160645
time: 2.2214972972869873
[1, 1895] loss_train: 0.006011, loss_test: 0.006006
time: 0.24805474281311035
time: 2.228511095046997
[1, 1896] loss_train: 0.003223, loss_test: 0.006012
time: 0.2450544834136963
time: 2.2505033016204834
[1, 1897] loss_train: 0.003771, loss_test: 0.006019
time: 0.2460634708404541
time: 2.2505133152008057
[1, 1898] loss_train: 0.004066, loss_test: 0.006025
time: 0.2450542449951172
time: 2.2274985313415527
[1, 1899] loss_train: 0.008709, loss_test: 0.006033
time: 0.24506640434265137
time: 2.2290356159210205
[1, 1900] loss_train: 0.011677, loss_test: 0.006016
time: 0.25705647468566895
time: 2.2459800243377686
[1, 1901] loss_train: 0.006493, loss_test: 0.005999
time: 0.2450542449951172
time: 2.227509021759033
[1, 1902] loss_train: 0.013251, loss_test: 0.005998
time: 0.2510552406311035
time: 2.2585055828094482
[1, 1903] loss_train: 0.006162, loss_test: 0.005992
time: 0.24306559562683105
time: 2.2214975357055664
[1, 1904] loss_train: 0.008195, loss_test: 0.005992
time: 0.2510550022125244
time: 2.2475130558013916
[1, 1905] loss_train: 0.009418, loss_test: 0.005989
time: 0.24405360221862793
time: 2.2214972972869873
[1, 1906] loss_train: 0.003212, loss_test: 0.005991
time: 0.25205564498901367
time: 2.2255141735076904
[1, 1907] loss_train: 0.003594, loss_test: 0.005995
time: 0.24405455589294434
time: 2.2650420665740967
[1, 1908] loss_train: 0.010704, loss_test: 0.006000
time: 0.24805665016174316
time: 2.2460131645202637
[1, 1909] loss_train: 0.016723, loss_test: 0.006013
time: 0.2450542449951172
time: 2.247547149658203
[1, 1910] loss_train: 0.007137, loss_test: 0.006029
time: 0.2580568790435791
time: 2.245504140853882
[1, 1911] loss_train: 0.007244, loss_test: 0.006043
time: 0.2450542449951172
time: 2.2605059146881104
[1, 1912] loss_train: 0.005771, loss_test: 0.006056
time: 0.2510673999786377
time: 2.269508123397827
[1, 1913] loss_train: 0.005436, loss_test: 0.006060
time: 0.2450549602508545
time: 2.2034921646118164
[1, 1914] loss_train: 0.010926, loss_test: 0.006061
time: 0.24605464935302734
time: 2.2134952545166016
[1, 1915] loss_train: 0.006916, loss_test: 0.006060
time: 0.24405360221862793
time: 2.2180354595184326
[1, 1916] loss_train: 0.001585, loss_test: 0.006060
time: 0.24505400657653809
time: 2.255296230316162
[1, 1917] loss_train: 0.007862, loss_test: 0.006057
time: 0.2450542449951172
time: 2.219496488571167
[1, 1918] loss_train: 0.010092, loss_test: 0.006049
time: 0.24605417251586914
time: 2.2455027103424072
[1, 1919] loss_train: 0.001274, loss_test: 0.006044
time: 0.25005507469177246
time: 2.2485039234161377
[1, 1920] loss_train: 0.002403, loss_test: 0.006040
time: 0.25705623626708984
time: 2.243502616882324
[1, 1921] loss_train: 0.008950, loss_test: 0.006041
time: 0.2470555305480957
time: 2.235499620437622
[1, 1922] loss_train: 0.007627, loss_test: 0.006037
time: 0.2470543384552002
time: 2.2335002422332764
[1, 1923] loss_train: 0.006473, loss_test: 0.006031
time: 0.24405384063720703
time: 2.2294983863830566
[1, 1924] loss_train: 0.010666, loss_test: 0.006020
time: 0.24405384063720703
time: 2.2495036125183105
[1, 1925] loss_train: 0.001246, loss_test: 0.006014
time: 0.2470552921295166
time: 2.2185187339782715
[1, 1926] loss_train: 0.009587, loss_test: 0.006011
time: 0.24405407905578613
time: 2.221496820449829
[1, 1927] loss_train: 0.005523, loss_test: 0.006010
time: 0.24505400657653809
time: 2.2094948291778564
[1, 1928] loss_train: 0.009708, loss_test: 0.006009
time: 0.2450542449951172
time: 2.2405014038085938
[1, 1929] loss_train: 0.005252, loss_test: 0.006007
time: 0.2510559558868408
time: 2.233499050140381
[1, 1930] loss_train: 0.009189, loss_test: 0.006002
time: 0.256056547164917
time: 2.257505178451538
[1, 1931] loss_train: 0.008210, loss_test: 0.006000
time: 0.2560572624206543
time: 2.2415034770965576
[1, 1932] loss_train: 0.005597, loss_test: 0.005998
time: 0.2450542449951172
time: 2.2505030632019043
[1, 1933] loss_train: 0.002361, loss_test: 0.005996
time: 0.2450544834136963
time: 2.246504545211792
[1, 1934] loss_train: 0.003262, loss_test: 0.005995
time: 0.24606800079345703
time: 2.2235567569732666
[1, 1935] loss_train: 0.014917, loss_test: 0.005995
time: 0.2470543384552002
time: 2.215496063232422
[1, 1936] loss_train: 0.001428, loss_test: 0.005994
time: 0.2450549602508545
time: 2.1954903602600098
[1, 1937] loss_train: 0.004029, loss_test: 0.005994
time: 0.2490837574005127
time: 2.2115049362182617
[1, 1938] loss_train: 0.009206, loss_test: 0.005994
time: 0.24405407905578613
time: 2.2244975566864014
[1, 1939] loss_train: 0.005787, loss_test: 0.005996
time: 0.24605441093444824
time: 2.245511770248413
[1, 1940] loss_train: 0.002829, loss_test: 0.006003
time: 0.2560567855834961
time: 2.255504846572876
[1, 1941] loss_train: 0.008323, loss_test: 0.006009
time: 0.24505400657653809
time: 2.2425122261047363
[1, 1942] loss_train: 0.003354, loss_test: 0.006018
time: 0.24405360221862793
time: 2.2224979400634766
[1, 1943] loss_train: 0.011083, loss_test: 0.006012
time: 0.24605417251586914
time: 2.205501079559326
[1, 1944] loss_train: 0.001971, loss_test: 0.006009
time: 0.24405407905578613
time: 2.2264974117279053
[1, 1945] loss_train: 0.004996, loss_test: 0.006008
time: 0.24505352973937988
time: 2.21449875831604
[1, 1946] loss_train: 0.004401, loss_test: 0.006004
time: 0.2450542449951172
time: 2.2305052280426025
[1, 1947] loss_train: 0.008583, loss_test: 0.005995
time: 0.24505400657653809
time: 2.2210028171539307
[1, 1948] loss_train: 0.008696, loss_test: 0.005987
time: 0.24505376815795898
time: 2.1934914588928223
[1, 1949] loss_train: 0.004259, loss_test: 0.005983
time: 0.24605512619018555
time: 2.2025034427642822
[1, 1950] loss_train: 0.008417, loss_test: 0.005980
time: 0.26105785369873047
time: 2.2500081062316895
[1, 1951] loss_train: 0.008543, loss_test: 0.005978
time: 0.24605441093444824
time: 2.2495033740997314
[1, 1952] loss_train: 0.010221, loss_test: 0.005981
time: 0.24506902694702148
time: 2.2425014972686768
[1, 1953] loss_train: 0.005568, loss_test: 0.005998
time: 0.25005507469177246
time: 2.2124977111816406
[1, 1954] loss_train: 0.008595, loss_test: 0.006017
time: 0.25005459785461426
time: 2.2445027828216553
[1, 1955] loss_train: 0.006521, loss_test: 0.006028
time: 0.24405455589294434
time: 2.2104945182800293
[1, 1956] loss_train: 0.010320, loss_test: 0.006030
time: 0.2490553855895996
time: 2.2294986248016357
[1, 1957] loss_train: 0.005632, loss_test: 0.006030
time: 0.2450551986694336
time: 2.234498977661133
[1, 1958] loss_train: 0.001761, loss_test: 0.006015
time: 0.25005483627319336
time: 2.263507127761841
[1, 1959] loss_train: 0.004651, loss_test: 0.006002
time: 0.24405336380004883
time: 2.212496042251587
[1, 1960] loss_train: 0.014198, loss_test: 0.005991
time: 0.2600572109222412
time: 2.2655067443847656
[1, 1961] loss_train: 0.007218, loss_test: 0.005994
time: 0.24627995491027832
time: 2.21449613571167
[1, 1962] loss_train: 0.006731, loss_test: 0.006010
time: 0.24606585502624512
time: 2.253504514694214
[1, 1963] loss_train: 0.012864, loss_test: 0.006013
time: 0.24506163597106934
time: 2.246502637863159
[1, 1964] loss_train: 0.010433, loss_test: 0.006009
time: 0.24506616592407227
time: 2.2475035190582275
[1, 1965] loss_train: 0.004152, loss_test: 0.006010
time: 0.24405407905578613
time: 2.2415010929107666
[1, 1966] loss_train: 0.010111, loss_test: 0.006002
time: 0.24405431747436523
time: 2.245502233505249
[1, 1967] loss_train: 0.008941, loss_test: 0.005994
time: 0.24505400657653809
time: 2.2395012378692627
[1, 1968] loss_train: 0.002347, loss_test: 0.005996
time: 0.24605441093444824
time: 2.228508710861206
[1, 1969] loss_train: 0.011436, loss_test: 0.006003
time: 0.2450547218322754
time: 2.2515220642089844
[1, 1970] loss_train: 0.012983, loss_test: 0.006014
time: 0.2600574493408203
time: 2.242514133453369
[1, 1971] loss_train: 0.006641, loss_test: 0.006026
time: 0.24405503273010254
time: 2.1984901428222656
[1, 1972] loss_train: 0.009202, loss_test: 0.006031
time: 0.24605488777160645
time: 2.244502305984497
[1, 1973] loss_train: 0.010168, loss_test: 0.006041
time: 0.2450549602508545
time: 2.2044925689697266
[1, 1974] loss_train: 0.004509, loss_test: 0.006031
time: 0.2450544834136963
time: 2.219496488571167
[1, 1975] loss_train: 0.004733, loss_test: 0.006022
time: 0.24405384063720703
time: 2.2160086631774902
[1, 1976] loss_train: 0.002721, loss_test: 0.006009
time: 0.2490553855895996
time: 2.2895119190216064
[1, 1977] loss_train: 0.002216, loss_test: 0.006003
time: 0.254056453704834
time: 2.19799542427063
[1, 1978] loss_train: 0.003857, loss_test: 0.006006
time: 0.24605393409729004
time: 2.254504919052124
[1, 1979] loss_train: 0.008547, loss_test: 0.006012
time: 0.24605417251586914
time: 2.2505035400390625
[1, 1980] loss_train: 0.013478, loss_test: 0.006010
time: 0.2580575942993164
time: 2.2555043697357178
[1, 1981] loss_train: 0.003195, loss_test: 0.006010
time: 0.2470550537109375
time: 2.2240121364593506
[1, 1982] loss_train: 0.001081, loss_test: 0.006012
time: 0.24805474281311035
time: 2.222999334335327
[1, 1983] loss_train: 0.001103, loss_test: 0.006021
time: 0.24405407905578613
time: 2.194491386413574
[1, 1984] loss_train: 0.006008, loss_test: 0.006030
time: 0.247053861618042
time: 2.198995590209961
[1, 1985] loss_train: 0.006809, loss_test: 0.006038
time: 0.2490549087524414
time: 2.230499029159546
[1, 1986] loss_train: 0.011540, loss_test: 0.006041
time: 0.24405431747436523
time: 2.2304985523223877
[1, 1987] loss_train: 0.003973, loss_test: 0.006041
time: 0.24610471725463867
time: 2.217496395111084
[1, 1988] loss_train: 0.015905, loss_test: 0.006045
time: 0.2450542449951172
time: 2.2234978675842285
[1, 1989] loss_train: 0.016229, loss_test: 0.006032
time: 0.2450551986694336
time: 2.2304985523223877
[1, 1990] loss_train: 0.003950, loss_test: 0.006028
time: 0.25505566596984863
time: 2.269507884979248
[1, 1991] loss_train: 0.012663, loss_test: 0.006021
time: 0.2490553855895996
time: 2.2505035400390625
[1, 1992] loss_train: 0.013037, loss_test: 0.006017
time: 0.24506640434265137
time: 2.2320210933685303
[1, 1993] loss_train: 0.004341, loss_test: 0.006021
time: 0.24605464935302734
time: 2.228499174118042
[1, 1994] loss_train: 0.002093, loss_test: 0.006026
time: 0.2450733184814453
time: 2.2224972248077393
[1, 1995] loss_train: 0.008204, loss_test: 0.006040
time: 0.2450542449951172
time: 2.2214977741241455
[1, 1996] loss_train: 0.008901, loss_test: 0.006040
time: 0.24505352973937988
time: 2.229499578475952
[1, 1997] loss_train: 0.002398, loss_test: 0.006033
time: 0.24505352973937988
time: 2.219496965408325
[1, 1998] loss_train: 0.005794, loss_test: 0.006021
time: 0.24706673622131348
time: 2.197512626647949
[1, 1999] loss_train: 0.002915, loss_test: 0.006007
time: 0.24605488777160645
time: 2.2245140075683594
[1, 2000] loss_train: 0.005433, loss_test: 0.006000
time: 0.26106953620910645
time: 2.3015151023864746
[1, 2001] loss_train: 0.005061, loss_test: 0.005999
time: 0.24805474281311035
time: 2.239501476287842
[1, 2002] loss_train: 0.004602, loss_test: 0.006005
time: 0.24706697463989258
time: 2.214495897293091
[1, 2003] loss_train: 0.017715, loss_test: 0.005987
time: 0.24405360221862793
time: 2.2515034675598145
[1, 2004] loss_train: 0.007996, loss_test: 0.005980
time: 0.24605488777160645
time: 2.254504442214966
[1, 2005] loss_train: 0.002946, loss_test: 0.005979
time: 0.2470552921295166
time: 2.237499713897705
[1, 2006] loss_train: 0.003888, loss_test: 0.005986
time: 0.24605464935302734
time: 2.2274982929229736
[1, 2007] loss_train: 0.005463, loss_test: 0.005996
time: 0.24405384063720703
time: 2.2385010719299316
[1, 2008] loss_train: 0.011127, loss_test: 0.006020
time: 0.2450542449951172
time: 2.2314999103546143
[1, 2009] loss_train: 0.004656, loss_test: 0.006057
time: 0.2450544834136963
time: 2.20949387550354
[1, 2010] loss_train: 0.008980, loss_test: 0.006099
time: 0.2600581645965576
time: 2.2935125827789307
[1, 2011] loss_train: 0.002652, loss_test: 0.006100
time: 0.24706768989562988
time: 2.22249698638916
[1, 2012] loss_train: 0.014761, loss_test: 0.006057
time: 0.2520568370819092
time: 2.2505033016204834
[1, 2013] loss_train: 0.010251, loss_test: 0.006021
time: 0.24505400657653809
time: 2.2375009059906006
[1, 2014] loss_train: 0.008465, loss_test: 0.005992
time: 0.2490551471710205
time: 2.267507314682007
[1, 2015] loss_train: 0.008557, loss_test: 0.005975
time: 0.24805474281311035
time: 2.221496820449829
[1, 2016] loss_train: 0.005383, loss_test: 0.005982
time: 0.2490558624267578
time: 2.2335100173950195
[1, 2017] loss_train: 0.010658, loss_test: 0.006006
time: 0.24305367469787598
time: 2.242501974105835
[1, 2018] loss_train: 0.011056, loss_test: 0.006045
time: 0.2520565986633301
time: 2.2285189628601074
[1, 2019] loss_train: 0.012758, loss_test: 0.006080
time: 0.24405360221862793
time: 2.1984922885894775
[1, 2020] loss_train: 0.008686, loss_test: 0.006105
time: 0.25905728340148926
time: 2.24851393699646
[1, 2021] loss_train: 0.003410, loss_test: 0.006128
time: 0.24405574798583984
time: 2.1905035972595215
[1, 2022] loss_train: 0.007830, loss_test: 0.006134
time: 0.24605441093444824
time: 2.258018732070923
[1, 2023] loss_train: 0.002121, loss_test: 0.006142
time: 0.2450549602508545
time: 2.231498956680298
[1, 2024] loss_train: 0.002099, loss_test: 0.006156
time: 0.24405407905578613
time: 2.244504690170288
[1, 2025] loss_train: 0.004716, loss_test: 0.006173
time: 0.24505376815795898
time: 2.2274997234344482
[1, 2026] loss_train: 0.007461, loss_test: 0.006168
time: 0.2450549602508545
time: 2.217496395111084
[1, 2027] loss_train: 0.007771, loss_test: 0.006153
time: 0.2450544834136963
time: 2.2254977226257324
[1, 2028] loss_train: 0.022018, loss_test: 0.006118
time: 0.2450551986694336
time: 2.240499973297119
[1, 2029] loss_train: 0.018285, loss_test: 0.006075
time: 0.2490549087524414
time: 2.2244980335235596
[1, 2030] loss_train: 0.005909, loss_test: 0.006054
time: 0.25705671310424805
time: 2.2605059146881104
[1, 2031] loss_train: 0.002052, loss_test: 0.006045
time: 0.25005531311035156
time: 2.2375011444091797
[1, 2032] loss_train: 0.006714, loss_test: 0.006028
time: 0.24606609344482422
time: 2.2465028762817383
[1, 2033] loss_train: 0.007380, loss_test: 0.006024
time: 0.24605441093444824
time: 2.2084944248199463
[1, 2034] loss_train: 0.004834, loss_test: 0.006032
time: 0.2470548152923584
time: 2.21049427986145
[1, 2035] loss_train: 0.004178, loss_test: 0.006033
time: 0.24405384063720703
time: 2.2195050716400146
[1, 2036] loss_train: 0.007553, loss_test: 0.006020
time: 0.25306105613708496
time: 2.205518960952759
[1, 2037] loss_train: 0.005274, loss_test: 0.006002
time: 0.24808001518249512
time: 2.20149302482605
[1, 2038] loss_train: 0.014546, loss_test: 0.005988
time: 0.2450547218322754
time: 2.230499267578125
[1, 2039] loss_train: 0.003818, loss_test: 0.005985
time: 0.2465674877166748
time: 2.2745087146759033
[1, 2040] loss_train: 0.007611, loss_test: 0.005989
time: 0.26405858993530273
time: 2.300020217895508
[1, 2041] loss_train: 0.010511, loss_test: 0.006000
time: 0.25106072425842285
time: 2.264505624771118
[1, 2042] loss_train: 0.003679, loss_test: 0.006014
time: 0.247056245803833
time: 2.232501268386841
[1, 2043] loss_train: 0.005835, loss_test: 0.006032
time: 0.24906706809997559
time: 2.253504514694214
[1, 2044] loss_train: 0.007601, loss_test: 0.006046
time: 0.2450554370880127
time: 2.1934921741485596
[1, 2045] loss_train: 0.006840, loss_test: 0.006053
time: 0.2470545768737793
time: 2.2044928073883057
[1, 2046] loss_train: 0.003529, loss_test: 0.006056
time: 0.24405312538146973
time: 2.217496156692505
[1, 2047] loss_train: 0.000820, loss_test: 0.006062
time: 0.2470545768737793
time: 2.2233283519744873
[1, 2048] loss_train: 0.017768, loss_test: 0.006037
time: 0.24506735801696777
time: 2.2535040378570557
[1, 2049] loss_train: 0.003710, loss_test: 0.006019
time: 0.24605464935302734
time: 2.205493688583374
[1, 2050] loss_train: 0.006413, loss_test: 0.006002
time: 0.25905728340148926
time: 2.2730369567871094
[1, 2051] loss_train: 0.004991, loss_test: 0.005991
time: 0.24505352973937988
time: 2.2405009269714355
[1, 2052] loss_train: 0.002005, loss_test: 0.005987
time: 0.24605512619018555
time: 2.239506959915161
[1, 2053] loss_train: 0.001744, loss_test: 0.005986
time: 0.24605536460876465
time: 2.2144947052001953
[1, 2054] loss_train: 0.009883, loss_test: 0.005986
time: 0.24405336380004883
time: 2.2024924755096436
[1, 2055] loss_train: 0.006242, loss_test: 0.005985
time: 0.24605441093444824
time: 2.2050247192382812
[1, 2056] loss_train: 0.009630, loss_test: 0.005981
time: 0.24605417251586914
time: 2.206494092941284
[1, 2057] loss_train: 0.001574, loss_test: 0.005978
time: 0.24805450439453125
time: 2.2010083198547363
[1, 2058] loss_train: 0.004758, loss_test: 0.005980
time: 0.24805545806884766
time: 2.1995112895965576
[1, 2059] loss_train: 0.004202, loss_test: 0.005985
time: 0.24505376815795898
time: 2.205493688583374
[1, 2060] loss_train: 0.012598, loss_test: 0.005989
time: 0.2600579261779785
time: 2.245502233505249
[1, 2061] loss_train: 0.010842, loss_test: 0.005982
time: 0.24505400657653809
time: 2.243502140045166
[1, 2062] loss_train: 0.004461, loss_test: 0.005978
time: 0.25005531311035156
time: 2.2385010719299316
[1, 2063] loss_train: 0.012960, loss_test: 0.005976
time: 0.2450547218322754
time: 2.2134945392608643
[1, 2064] loss_train: 0.012609, loss_test: 0.005978
time: 0.24805498123168945
time: 2.205498456954956
[1, 2065] loss_train: 0.001774, loss_test: 0.005981
time: 0.2450542449951172
time: 2.209514617919922
[1, 2066] loss_train: 0.001235, loss_test: 0.005984
time: 0.24586033821105957
time: 2.2495040893554688
[1, 2067] loss_train: 0.004593, loss_test: 0.005988
time: 0.24508070945739746
time: 2.2425012588500977
[1, 2068] loss_train: 0.003620, loss_test: 0.005994
time: 0.2460803985595703
time: 2.2285006046295166
[1, 2069] loss_train: 0.009965, loss_test: 0.006001
time: 0.24506783485412598
time: 2.247185707092285
[1, 2070] loss_train: 0.007636, loss_test: 0.006007
time: 0.2560720443725586
time: 2.2415013313293457
[1, 2071] loss_train: 0.007289, loss_test: 0.006011
time: 0.24605441093444824
time: 2.2254979610443115
[1, 2072] loss_train: 0.009468, loss_test: 0.006014
time: 0.24582314491271973
time: 2.2284984588623047
[1, 2073] loss_train: 0.000650, loss_test: 0.006020
time: 0.24505400657653809
time: 2.2184977531433105
[1, 2074] loss_train: 0.007964, loss_test: 0.006021
time: 0.24305391311645508
time: 2.2173526287078857
[1, 2075] loss_train: 0.004488, loss_test: 0.006026
time: 0.24605441093444824
time: 2.2214972972869873
[1, 2076] loss_train: 0.007076, loss_test: 0.006027
time: 0.24606704711914062
time: 2.243501663208008
[1, 2077] loss_train: 0.008962, loss_test: 0.006021
time: 0.24505972862243652
time: 2.216496229171753
[1, 2078] loss_train: 0.004525, loss_test: 0.006013
time: 0.24605417251586914
time: 2.216496467590332
[1, 2079] loss_train: 0.003462, loss_test: 0.006009
time: 0.24805474281311035
time: 2.2395009994506836
[1, 2080] loss_train: 0.008293, loss_test: 0.006003
time: 0.257068395614624
time: 2.24702525138855
[1, 2081] loss_train: 0.007132, loss_test: 0.005995
time: 0.2540562152862549
time: 2.224498748779297
[1, 2082] loss_train: 0.004608, loss_test: 0.005987
time: 0.24405479431152344
time: 2.2114994525909424
[1, 2083] loss_train: 0.010086, loss_test: 0.005989
time: 0.24860000610351562
time: 2.232499837875366
[1, 2084] loss_train: 0.003392, loss_test: 0.005992
time: 0.2450542449951172
time: 2.2735085487365723
[1, 2085] loss_train: 0.005591, loss_test: 0.005987
time: 0.2510557174682617
time: 2.2425200939178467
[1, 2086] loss_train: 0.013029, loss_test: 0.005967
time: 0.24738144874572754
time: 2.233499526977539
[1, 2087] loss_train: 0.016370, loss_test: 0.005973
time: 0.24706816673278809
time: 2.2591452598571777
[1, 2088] loss_train: 0.008639, loss_test: 0.006041
time: 0.2450544834136963
time: 2.2595160007476807
[1, 2089] loss_train: 0.008844, loss_test: 0.006149
time: 0.2470548152923584
time: 2.2635066509246826
[1, 2090] loss_train: 0.004642, loss_test: 0.006261
time: 0.256056547164917
time: 2.2761762142181396
[1, 2091] loss_train: 0.005796, loss_test: 0.006314
time: 0.2490551471710205
time: 2.288524627685547
[1, 2092] loss_train: 0.010247, loss_test: 0.006268
time: 0.2540566921234131
time: 2.223506212234497
[1, 2093] loss_train: 0.002481, loss_test: 0.006164
time: 0.2490682601928711
time: 2.239501476287842
[1, 2094] loss_train: 0.010494, loss_test: 0.006057
time: 0.24508023262023926
time: 2.2395009994506836
[1, 2095] loss_train: 0.001239, loss_test: 0.005986
time: 0.2490546703338623
time: 2.227499008178711
[1, 2096] loss_train: 0.010777, loss_test: 0.005997
time: 0.24405479431152344
time: 2.257556200027466
[1, 2097] loss_train: 0.006735, loss_test: 0.006053
time: 0.24805545806884766
time: 2.2304985523223877
[1, 2098] loss_train: 0.003732, loss_test: 0.006135
time: 0.25005531311035156
time: 2.228498935699463
[1, 2099] loss_train: 0.004690, loss_test: 0.006208
time: 0.24605417251586914
time: 2.2475030422210693
[1, 2100] loss_train: 0.003515, loss_test: 0.006270
time: 0.2560577392578125
time: 2.2555148601531982
[1, 2101] loss_train: 0.006569, loss_test: 0.006323
time: 0.2470545768737793
time: 2.248021125793457
[1, 2102] loss_train: 0.007783, loss_test: 0.006340
time: 0.24505400657653809
time: 2.2505064010620117
[1, 2103] loss_train: 0.007607, loss_test: 0.006346
time: 0.2450544834136963
time: 2.2415246963500977
[1, 2104] loss_train: 0.000946, loss_test: 0.006356
time: 0.24506616592407227
time: 2.218496799468994
[1, 2105] loss_train: 0.003984, loss_test: 0.006353
time: 0.2450547218322754
time: 2.288513422012329
[1, 2106] loss_train: 0.006089, loss_test: 0.006340
time: 0.24405431747436523
time: 2.2285141944885254
[1, 2107] loss_train: 0.003233, loss_test: 0.006326
time: 0.24605488777160645
time: 2.2375035285949707
[1, 2108] loss_train: 0.008933, loss_test: 0.006283
time: 0.2470548152923584
time: 2.2254979610443115
[1, 2109] loss_train: 0.000866, loss_test: 0.006255
time: 0.2450723648071289
time: 2.232499599456787
[1, 2110] loss_train: 0.008037, loss_test: 0.006217
time: 0.2560575008392334
time: 2.260030746459961
[1, 2111] loss_train: 0.016421, loss_test: 0.006144
time: 0.24605393409729004
time: 2.2254979610443115
[1, 2112] loss_train: 0.007783, loss_test: 0.006083
time: 0.24405360221862793
time: 2.239501476287842
[1, 2113] loss_train: 0.004658, loss_test: 0.006041
time: 0.24505400657653809
time: 2.2345001697540283
[1, 2114] loss_train: 0.002899, loss_test: 0.006024
time: 0.24305343627929688
time: 2.219496726989746
[1, 2115] loss_train: 0.014915, loss_test: 0.006023
time: 0.2450549602508545
time: 2.2415008544921875
[1, 2116] loss_train: 0.008244, loss_test: 0.006049
time: 0.2470543384552002
time: 2.234499931335449
[1, 2117] loss_train: 0.010408, loss_test: 0.006088
time: 0.24605441093444824
time: 2.1844890117645264
[1, 2118] loss_train: 0.008333, loss_test: 0.006098
time: 0.2470545768737793
time: 2.220496892929077
[1, 2119] loss_train: 0.011779, loss_test: 0.006100
time: 0.24605441093444824
time: 2.206493854522705
[1, 2120] loss_train: 0.005082, loss_test: 0.006059
time: 0.25907206535339355
time: 2.257507562637329
[1, 2121] loss_train: 0.006895, loss_test: 0.006020
time: 0.24605417251586914
time: 2.242504119873047
[1, 2122] loss_train: 0.004293, loss_test: 0.005994
time: 0.24907755851745605
time: 2.2455039024353027
[1, 2123] loss_train: 0.007620, loss_test: 0.005982
time: 0.24605488777160645
time: 2.2525057792663574
[1, 2124] loss_train: 0.007518, loss_test: 0.005982
time: 0.251056432723999
time: 2.235499382019043
[1, 2125] loss_train: 0.001714, loss_test: 0.005993
time: 0.2470555305480957
time: 2.2415008544921875
[1, 2126] loss_train: 0.016986, loss_test: 0.005991
time: 0.24805521965026855
time: 2.2365000247955322
[1, 2127] loss_train: 0.010082, loss_test: 0.005982
time: 0.24405360221862793
time: 2.2395009994506836
[1, 2128] loss_train: 0.006941, loss_test: 0.005975
time: 0.25005626678466797
time: 2.249504804611206
[1, 2129] loss_train: 0.002036, loss_test: 0.005972
time: 0.24405431747436523
time: 2.205504894256592
[1, 2130] loss_train: 0.006942, loss_test: 0.005967
time: 0.25905656814575195
time: 2.2565183639526367
[1, 2131] loss_train: 0.002934, loss_test: 0.005965
time: 0.24605393409729004
time: 2.2235071659088135
[1, 2132] loss_train: 0.002276, loss_test: 0.005965
time: 0.25206756591796875
time: 2.2365009784698486
[1, 2133] loss_train: 0.014209, loss_test: 0.005966
time: 0.24505376815795898
time: 2.255504846572876
[1, 2134] loss_train: 0.004873, loss_test: 0.005969
time: 0.24605441093444824
time: 2.2275009155273438
[1, 2135] loss_train: 0.011479, loss_test: 0.005982
time: 0.24405336380004883
time: 2.2335000038146973
[1, 2136] loss_train: 0.004321, loss_test: 0.006004
time: 0.24405455589294434
time: 2.2435247898101807
[1, 2137] loss_train: 0.012291, loss_test: 0.006019
time: 0.24405360221862793
time: 2.230499029159546
[1, 2138] loss_train: 0.009987, loss_test: 0.006018
time: 0.24605441093444824
time: 2.247612714767456
[1, 2139] loss_train: 0.015435, loss_test: 0.006006
time: 0.24605512619018555
time: 2.217495918273926
[1, 2140] loss_train: 0.014871, loss_test: 0.005998
time: 0.25705718994140625
time: 2.284511089324951
[1, 2141] loss_train: 0.002901, loss_test: 0.006004
time: 0.24405336380004883
time: 2.226001501083374
[1, 2142] loss_train: 0.007410, loss_test: 0.006012
time: 0.2490553855895996
time: 2.244502067565918
[1, 2143] loss_train: 0.004637, loss_test: 0.006022
time: 0.24405384063720703
time: 2.192490816116333
[1, 2144] loss_train: 0.003549, loss_test: 0.006032
time: 0.24505376815795898
time: 2.26204252243042
[1, 2145] loss_train: 0.004009, loss_test: 0.006035
time: 0.24606657028198242
time: 2.255505084991455
[1, 2146] loss_train: 0.007746, loss_test: 0.006025
time: 0.24405455589294434
time: 2.218818426132202
[1, 2147] loss_train: 0.002092, loss_test: 0.006018
time: 0.24709415435791016
time: 2.2585058212280273
[1, 2148] loss_train: 0.009418, loss_test: 0.006009
time: 0.2450549602508545
time: 2.2415008544921875
[1, 2149] loss_train: 0.001977, loss_test: 0.005999
time: 0.2470688819885254
time: 2.2465016841888428
[1, 2150] loss_train: 0.004366, loss_test: 0.005994
time: 0.25705766677856445
time: 2.249505043029785
[1, 2151] loss_train: 0.002195, loss_test: 0.005995
time: 0.24405431747436523
time: 2.23349928855896
[1, 2152] loss_train: 0.009001, loss_test: 0.006000
time: 0.24805450439453125
time: 2.2345001697540283
[1, 2153] loss_train: 0.000784, loss_test: 0.006011
time: 0.2450544834136963
time: 2.212494134902954
[1, 2154] loss_train: 0.008295, loss_test: 0.006027
time: 0.2440638542175293
time: 2.2144949436187744
[1, 2155] loss_train: 0.014862, loss_test: 0.006042
time: 0.24605441093444824
time: 2.2475030422210693
[1, 2156] loss_train: 0.003228, loss_test: 0.006061
time: 0.24405479431152344
time: 2.222498655319214
[1, 2157] loss_train: 0.006826, loss_test: 0.006072
time: 0.25005555152893066
time: 2.2715072631835938
[1, 2158] loss_train: 0.007692, loss_test: 0.006082
time: 0.24305486679077148
time: 2.2415003776550293
[1, 2159] loss_train: 0.003513, loss_test: 0.006088
time: 0.2520585060119629
time: 2.235502004623413
[1, 2160] loss_train: 0.022342, loss_test: 0.006055
time: 0.2560563087463379
time: 2.2442820072174072
[1, 2161] loss_train: 0.003734, loss_test: 0.006038
time: 0.2540566921234131
time: 2.237499952316284
[1, 2162] loss_train: 0.003484, loss_test: 0.006022
time: 0.24405360221862793
time: 2.2200300693511963
[1, 2163] loss_train: 0.003609, loss_test: 0.006009
time: 0.2510552406311035
time: 2.243502378463745
[1, 2164] loss_train: 0.009757, loss_test: 0.006004
time: 0.24405384063720703
time: 2.2675065994262695
[1, 2165] loss_train: 0.002421, loss_test: 0.006013
time: 0.252056360244751
time: 2.2445027828216553
[1, 2166] loss_train: 0.007293, loss_test: 0.006037
time: 0.24405360221862793
time: 2.1964919567108154
[1, 2167] loss_train: 0.004819, loss_test: 0.006066
time: 0.24805521965026855
time: 2.2145066261291504
[1, 2168] loss_train: 0.007176, loss_test: 0.006096
time: 0.24707269668579102
time: 2.2515034675598145
[1, 2169] loss_train: 0.006193, loss_test: 0.006109
time: 0.24608063697814941
time: 2.2595081329345703
[1, 2170] loss_train: 0.005674, loss_test: 0.006112
time: 0.255068302154541
time: 2.2725086212158203
[1, 2171] loss_train: 0.008289, loss_test: 0.006111
time: 0.25005531311035156
time: 2.2615065574645996
[1, 2172] loss_train: 0.006917, loss_test: 0.006092
time: 0.2450542449951172
time: 2.283015012741089
[1, 2173] loss_train: 0.005760, loss_test: 0.006068
time: 0.24805450439453125
time: 2.215496063232422
[1, 2174] loss_train: 0.005318, loss_test: 0.006030
time: 0.2450542449951172
time: 2.2645068168640137
[1, 2175] loss_train: 0.012312, loss_test: 0.005992
time: 0.2490551471710205
time: 2.2375004291534424
[1, 2176] loss_train: 0.002782, loss_test: 0.005972
time: 0.24505400657653809
time: 2.218496799468994
[1, 2177] loss_train: 0.009911, loss_test: 0.005962
time: 0.2440659999847412
time: 2.267507314682007
[1, 2178] loss_train: 0.002610, loss_test: 0.005961
time: 0.24405360221862793
time: 2.267542600631714
[1, 2179] loss_train: 0.007423, loss_test: 0.005968
time: 0.25005602836608887
time: 2.2274978160858154
[1, 2180] loss_train: 0.012715, loss_test: 0.005989
time: 0.25505614280700684
time: 2.2274982929229736
[1, 2181] loss_train: 0.007636, loss_test: 0.006015
time: 0.24405407905578613
time: 2.230499267578125
[1, 2182] loss_train: 0.007591, loss_test: 0.006042
time: 0.24405503273010254
time: 2.2284975051879883
[1, 2183] loss_train: 0.002354, loss_test: 0.006066
time: 0.24405431747436523
time: 2.2400076389312744
[1, 2184] loss_train: 0.007234, loss_test: 0.006092
time: 0.24405360221862793
time: 2.2645092010498047
[1, 2185] loss_train: 0.006202, loss_test: 0.006090
time: 0.24506688117980957
time: 2.2655065059661865
[1, 2186] loss_train: 0.008900, loss_test: 0.006076
time: 0.24605488777160645
time: 2.2284982204437256
[1, 2187] loss_train: 0.004744, loss_test: 0.006024
time: 0.2510561943054199
time: 2.248504877090454
[1, 2188] loss_train: 0.010185, loss_test: 0.005986
time: 0.24805498123168945
time: 2.1894896030426025
[1, 2189] loss_train: 0.009361, loss_test: 0.005965
time: 0.24805521965026855
time: 2.2044925689697266
[1, 2190] loss_train: 0.009098, loss_test: 0.005954
time: 0.2560570240020752
time: 2.2475030422210693
[1, 2191] loss_train: 0.007199, loss_test: 0.005954
time: 0.2450542449951172
time: 2.2303004264831543
[1, 2192] loss_train: 0.001564, loss_test: 0.005969
time: 0.24606728553771973
time: 2.22249698638916
[1, 2193] loss_train: 0.005678, loss_test: 0.005993
time: 0.24605417251586914
time: 2.223496913909912
[1, 2194] loss_train: 0.006347, loss_test: 0.006014
time: 0.2450549602508545
time: 2.24550199508667
[1, 2195] loss_train: 0.010395, loss_test: 0.006031
time: 0.24605488777160645
time: 2.2275421619415283
[1, 2196] loss_train: 0.011749, loss_test: 0.006029
time: 0.24805569648742676
time: 2.234499454498291
[1, 2197] loss_train: 0.002879, loss_test: 0.006029
time: 0.2470543384552002
time: 2.257505416870117
[1, 2198] loss_train: 0.007228, loss_test: 0.006027
time: 0.2450544834136963
time: 2.2044930458068848
[1, 2199] loss_train: 0.002330, loss_test: 0.006028
time: 0.24405455589294434
time: 2.2545039653778076
[1, 2200] loss_train: 0.006809, loss_test: 0.006014
time: 0.2620584964752197
time: 2.246501922607422
[1, 2201] loss_train: 0.004319, loss_test: 0.006001
time: 0.2470684051513672
time: 2.2154948711395264
[1, 2202] loss_train: 0.006116, loss_test: 0.005986
time: 0.2490544319152832
time: 2.220496892929077
[1, 2203] loss_train: 0.015748, loss_test: 0.005975
time: 0.2470555305480957
time: 2.229001998901367
[1, 2204] loss_train: 0.009629, loss_test: 0.005971
time: 0.2470548152923584
time: 2.2254981994628906
[1, 2205] loss_train: 0.008164, loss_test: 0.005967
time: 0.2440659999847412
time: 2.2174980640411377
[1, 2206] loss_train: 0.004366, loss_test: 0.005964
time: 0.2450544834136963
time: 2.238007068634033
[1, 2207] loss_train: 0.004130, loss_test: 0.005964
time: 0.24506092071533203
time: 2.260505437850952
[1, 2208] loss_train: 0.008711, loss_test: 0.005962
time: 0.24405384063720703
time: 2.2335102558135986
[1, 2209] loss_train: 0.001759, loss_test: 0.005960
time: 0.24405384063720703
time: 2.2134952545166016
[1, 2210] loss_train: 0.003778, loss_test: 0.005958
time: 0.25905704498291016
time: 2.2435030937194824
[1, 2211] loss_train: 0.002803, loss_test: 0.005956
time: 0.24505400657653809
time: 2.235508441925049
[1, 2212] loss_train: 0.007380, loss_test: 0.005956
time: 0.24406766891479492
time: 2.204493522644043
[1, 2213] loss_train: 0.015631, loss_test: 0.005970
time: 0.2450559139251709
time: 2.210494041442871
[1, 2214] loss_train: 0.005117, loss_test: 0.005994
time: 0.24605441093444824
time: 2.2134957313537598
[1, 2215] loss_train: 0.009956, loss_test: 0.006015
time: 0.24505400657653809
time: 2.24550199508667
[1, 2216] loss_train: 0.007378, loss_test: 0.006029
time: 0.2450542449951172
time: 2.2365024089813232
[1, 2217] loss_train: 0.009824, loss_test: 0.006033
time: 0.2470545768737793
time: 2.219496726989746
[1, 2218] loss_train: 0.008005, loss_test: 0.006023
time: 0.2450542449951172
time: 2.2475030422210693
[1, 2219] loss_train: 0.003580, loss_test: 0.006014
time: 0.24405360221862793
time: 2.208549737930298
[1, 2220] loss_train: 0.007882, loss_test: 0.006001
time: 0.25705695152282715
time: 2.2935123443603516
[1, 2221] loss_train: 0.006578, loss_test: 0.005986
time: 0.24605345726013184
time: 2.235494375228882
[1, 2222] loss_train: 0.007264, loss_test: 0.005971
time: 0.24605441093444824
time: 2.2274985313415527
[1, 2223] loss_train: 0.005069, loss_test: 0.005963
time: 0.24805474281311035
time: 2.23349928855896
[1, 2224] loss_train: 0.014295, loss_test: 0.005959
time: 0.24805569648742676
time: 2.2345080375671387
[1, 2225] loss_train: 0.004310, loss_test: 0.005961
time: 0.2490549087524414
time: 2.212512731552124
[1, 2226] loss_train: 0.003740, loss_test: 0.005963
time: 0.24406743049621582
time: 2.231499433517456
[1, 2227] loss_train: 0.002604, loss_test: 0.005963
time: 0.24805545806884766
time: 2.249502658843994
[1, 2228] loss_train: 0.007881, loss_test: 0.005961
time: 0.24405384063720703
time: 2.2345001697540283
[1, 2229] loss_train: 0.017957, loss_test: 0.005962
time: 0.24806904792785645
time: 2.245015859603882
[1, 2230] loss_train: 0.003539, loss_test: 0.005962
time: 0.25705909729003906
time: 2.306515693664551
[1, 2231] loss_train: 0.004705, loss_test: 0.005961
time: 0.24967145919799805
time: 2.2385001182556152
[1, 2232] loss_train: 0.004562, loss_test: 0.005960
time: 0.24405407905578613
time: 2.2144956588745117
[1, 2233] loss_train: 0.004488, loss_test: 0.005957
time: 0.2470541000366211
time: 2.2395009994506836
[1, 2234] loss_train: 0.008625, loss_test: 0.005958
time: 0.24805498123168945
time: 2.255504608154297
[1, 2235] loss_train: 0.006841, loss_test: 0.005957
time: 0.2470545768737793
time: 2.2560315132141113
[1, 2236] loss_train: 0.003428, loss_test: 0.005959
time: 0.2450551986694336
time: 2.245502233505249
[1, 2237] loss_train: 0.001470, loss_test: 0.005963
time: 0.24805521965026855
time: 2.2109992504119873
[1, 2238] loss_train: 0.006336, loss_test: 0.005968
time: 0.2450542449951172
time: 2.238004446029663
[1, 2239] loss_train: 0.003836, loss_test: 0.005975
time: 0.24405407905578613
time: 2.2224972248077393
[1, 2240] loss_train: 0.003727, loss_test: 0.005981
time: 0.25505566596984863
time: 2.2755095958709717
[1, 2241] loss_train: 0.003976, loss_test: 0.005987
time: 0.24305415153503418
time: 2.2345120906829834
[1, 2242] loss_train: 0.011992, loss_test: 0.005982
time: 0.24305438995361328
time: 2.247502565383911
[1, 2243] loss_train: 0.007999, loss_test: 0.005980
time: 0.24405384063720703
time: 2.2140004634857178
[1, 2244] loss_train: 0.012342, loss_test: 0.005968
time: 0.2470548152923584
time: 2.2114946842193604
[1, 2245] loss_train: 0.004660, loss_test: 0.005963
time: 0.24406838417053223
time: 2.225515842437744
[1, 2246] loss_train: 0.014451, loss_test: 0.005967
time: 0.2450544834136963
time: 2.2264976501464844
[1, 2247] loss_train: 0.003512, loss_test: 0.005988
time: 0.24505400657653809
time: 2.217498540878296
[1, 2248] loss_train: 0.006066, loss_test: 0.006022
time: 0.24605369567871094
time: 2.220496892929077
[1, 2249] loss_train: 0.015674, loss_test: 0.006098
time: 0.2450554370880127
time: 2.235361099243164
[1, 2250] loss_train: 0.005193, loss_test: 0.006153
time: 0.2620580196380615
time: 2.2505037784576416
[1, 2251] loss_train: 0.006458, loss_test: 0.006173
time: 0.24805474281311035
time: 2.241501808166504
[1, 2252] loss_train: 0.003646, loss_test: 0.006176
time: 0.24605488777160645
time: 2.1874911785125732
[1, 2253] loss_train: 0.012200, loss_test: 0.006143
time: 0.24505400657653809
time: 2.229499340057373
[1, 2254] loss_train: 0.005737, loss_test: 0.006098
time: 0.25205516815185547
time: 2.239532947540283
[1, 2255] loss_train: 0.006034, loss_test: 0.006030
time: 0.2450547218322754
time: 2.2204954624176025
[1, 2256] loss_train: 0.008906, loss_test: 0.005984
time: 0.24905729293823242
time: 2.230499744415283
[1, 2257] loss_train: 0.004905, loss_test: 0.005961
time: 0.24405407905578613
time: 2.249502658843994
[1, 2258] loss_train: 0.004886, loss_test: 0.005958
time: 0.24805545806884766
time: 2.248502254486084
[1, 2259] loss_train: 0.003912, loss_test: 0.005968
time: 0.24405407905578613
time: 2.2540392875671387
[1, 2260] loss_train: 0.007051, loss_test: 0.005976
time: 0.25905799865722656
time: 2.2645061016082764
[1, 2261] loss_train: 0.003204, loss_test: 0.005986
time: 0.24305415153503418
time: 2.2235121726989746
[1, 2262] loss_train: 0.005476, loss_test: 0.005995
time: 0.2470550537109375
time: 2.2395009994506836
[1, 2263] loss_train: 0.006205, loss_test: 0.006005
time: 0.24405360221862793
time: 2.2194972038269043
[1, 2264] loss_train: 0.005281, loss_test: 0.006017
time: 0.24406671524047852
time: 2.2605056762695312
[1, 2265] loss_train: 0.012225, loss_test: 0.006025
time: 0.2450551986694336
time: 2.2164955139160156
[1, 2266] loss_train: 0.004902, loss_test: 0.006033
time: 0.24405384063720703
time: 2.2765095233917236
[1, 2267] loss_train: 0.003174, loss_test: 0.006044
time: 0.24505400657653809
time: 2.229499340057373
[1, 2268] loss_train: 0.006752, loss_test: 0.006036
time: 0.24605417251586914
time: 2.209223747253418
[1, 2269] loss_train: 0.004666, loss_test: 0.006027
time: 0.24405431747436523
time: 2.204493761062622
[1, 2270] loss_train: 0.010352, loss_test: 0.006015
time: 0.2560563087463379
time: 2.270573139190674
[1, 2271] loss_train: 0.005745, loss_test: 0.006007
time: 0.24406719207763672
time: 2.244502305984497
[1, 2272] loss_train: 0.004864, loss_test: 0.005994
time: 0.24405479431152344
time: 2.226496934890747
[1, 2273] loss_train: 0.003885, loss_test: 0.005982
time: 0.2450542449951172
time: 2.2124950885772705
[1, 2274] loss_train: 0.004768, loss_test: 0.005976
time: 0.24405384063720703
time: 2.231499433517456
[1, 2275] loss_train: 0.006136, loss_test: 0.005967
time: 0.24405384063720703
time: 2.205495834350586
[1, 2276] loss_train: 0.005203, loss_test: 0.005962
time: 0.24706459045410156
time: 2.234499216079712
[1, 2277] loss_train: 0.005146, loss_test: 0.005960
time: 0.24605512619018555
time: 2.2330143451690674
[1, 2278] loss_train: 0.009668, loss_test: 0.005961
time: 0.24392390251159668
time: 2.249502182006836
[1, 2279] loss_train: 0.020210, loss_test: 0.005970
time: 0.2470564842224121
time: 2.247501850128174
[1, 2280] loss_train: 0.015887, loss_test: 0.005977
time: 0.2580568790435791
time: 2.248518466949463
[1, 2281] loss_train: 0.009480, loss_test: 0.005988
time: 0.24505376815795898
time: 2.244541883468628
[1, 2282] loss_train: 0.004772, loss_test: 0.006001
time: 0.2490558624267578
time: 2.283520460128784
[1, 2283] loss_train: 0.003753, loss_test: 0.006015
time: 0.2450542449951172
time: 2.2375006675720215
[1, 2284] loss_train: 0.010019, loss_test: 0.006027
time: 0.2450547218322754
time: 2.2174949645996094
[1, 2285] loss_train: 0.004409, loss_test: 0.006038
time: 0.2470550537109375
time: 2.228498935699463
[1, 2286] loss_train: 0.012329, loss_test: 0.006045
time: 0.2470555305480957
time: 2.2301530838012695
[1, 2287] loss_train: 0.005376, loss_test: 0.006046
time: 0.24869871139526367
time: 2.2264978885650635
[1, 2288] loss_train: 0.009142, loss_test: 0.006025
time: 0.24505400657653809
time: 2.242868423461914
[1, 2289] loss_train: 0.008741, loss_test: 0.006002
time: 0.24805450439453125
time: 2.219496011734009
[1, 2290] loss_train: 0.004382, loss_test: 0.005989
time: 0.256056547164917
time: 2.262025833129883
[1, 2291] loss_train: 0.003947, loss_test: 0.005989
time: 0.2490551471710205
time: 2.2244977951049805
[1, 2292] loss_train: 0.003091, loss_test: 0.006003
time: 0.2475597858428955
time: 2.2525036334991455
[1, 2293] loss_train: 0.006829, loss_test: 0.006019
time: 0.2470552921295166
time: 2.2545061111450195
[1, 2294] loss_train: 0.011823, loss_test: 0.006040
time: 0.24605488777160645
time: 2.224498987197876
[1, 2295] loss_train: 0.011769, loss_test: 0.006058
time: 0.2470548152923584
time: 2.2525038719177246
[1, 2296] loss_train: 0.007826, loss_test: 0.006075
time: 0.2450542449951172
time: 2.228022336959839
[1, 2297] loss_train: 0.005883, loss_test: 0.006067
time: 0.24305462837219238
time: 2.234499216079712
[1, 2298] loss_train: 0.006558, loss_test: 0.006046
time: 0.2450714111328125
time: 2.278510093688965
[1, 2299] loss_train: 0.004906, loss_test: 0.006028
time: 0.24405431747436523
time: 2.2154953479766846
[1, 2300] loss_train: 0.012072, loss_test: 0.005995
time: 0.25707316398620605
time: 2.2735090255737305
[1, 2301] loss_train: 0.010477, loss_test: 0.005970
time: 0.24805474281311035
time: 2.218496561050415
[1, 2302] loss_train: 0.006511, loss_test: 0.005954
time: 0.24605393409729004
time: 2.2475028038024902
[1, 2303] loss_train: 0.000864, loss_test: 0.005945
time: 0.24405479431152344
time: 2.234499216079712
[1, 2304] loss_train: 0.012332, loss_test: 0.005943
time: 0.24405407905578613
time: 2.2292709350585938
[1, 2305] loss_train: 0.015927, loss_test: 0.005946
time: 0.24405384063720703
time: 2.2284982204437256
[1, 2306] loss_train: 0.006683, loss_test: 0.005952
time: 0.24405455589294434
time: 2.2495031356811523
[1, 2307] loss_train: 0.005906, loss_test: 0.005959
time: 0.24605464935302734
time: 2.2495031356811523
[1, 2308] loss_train: 0.014452, loss_test: 0.005959
time: 0.2450544834136963
time: 2.2405006885528564
[1, 2309] loss_train: 0.005410, loss_test: 0.005961
time: 0.251056432723999
time: 2.244516134262085
[1, 2310] loss_train: 0.013805, loss_test: 0.005953
time: 0.2560558319091797
time: 2.257505416870117
[1, 2311] loss_train: 0.005846, loss_test: 0.005957
time: 0.24405384063720703
time: 2.216510772705078
[1, 2312] loss_train: 0.006912, loss_test: 0.005970
time: 0.2490553855895996
time: 2.269012689590454
[1, 2313] loss_train: 0.008675, loss_test: 0.005980
time: 0.2450544834136963
time: 2.2194957733154297
[1, 2314] loss_train: 0.002764, loss_test: 0.005987
time: 0.2510566711425781
time: 2.266510486602783
[1, 2315] loss_train: 0.003015, loss_test: 0.005984
time: 0.2490549087524414
time: 2.2395036220550537
[1, 2316] loss_train: 0.009251, loss_test: 0.005975
time: 0.24605393409729004
time: 2.230006217956543
[1, 2317] loss_train: 0.000610, loss_test: 0.005975
time: 0.2490682601928711
time: 2.2305002212524414
[1, 2318] loss_train: 0.010540, loss_test: 0.005974
time: 0.2470550537109375
time: 2.242502212524414
[1, 2319] loss_train: 0.005083, loss_test: 0.005974
time: 0.2470548152923584
time: 2.216495990753174
[1, 2320] loss_train: 0.005453, loss_test: 0.005976
time: 0.2630586624145508
time: 2.3115174770355225
[1, 2321] loss_train: 0.009113, loss_test: 0.005977
time: 0.25005674362182617
time: 2.277510643005371
[1, 2322] loss_train: 0.009808, loss_test: 0.005974
time: 0.2490541934967041
time: 2.2395012378692627
[1, 2323] loss_train: 0.003291, loss_test: 0.005970
time: 0.24505400657653809
time: 2.20249342918396
[1, 2324] loss_train: 0.012759, loss_test: 0.005965
time: 0.2490544319152832
time: 2.219496965408325
[1, 2325] loss_train: 0.010926, loss_test: 0.005970
time: 0.24605464935302734
time: 2.205493211746216
[1, 2326] loss_train: 0.003074, loss_test: 0.005981
time: 0.24305367469787598
time: 2.228501319885254
[1, 2327] loss_train: 0.001008, loss_test: 0.006000
time: 0.24805521965026855
time: 2.2385005950927734
[1, 2328] loss_train: 0.011184, loss_test: 0.006019
time: 0.2470543384552002
time: 2.236107587814331
[1, 2329] loss_train: 0.014487, loss_test: 0.006022
time: 0.24805498123168945
time: 2.254504680633545
[1, 2330] loss_train: 0.003994, loss_test: 0.006025
time: 0.25905728340148926
time: 2.2224972248077393
[1, 2331] loss_train: 0.004463, loss_test: 0.006028
time: 0.24405193328857422
time: 2.2765114307403564
[1, 2332] loss_train: 0.001187, loss_test: 0.006033
time: 0.25005507469177246
time: 2.241504430770874
[1, 2333] loss_train: 0.009882, loss_test: 0.006020
time: 0.24505376815795898
time: 2.2124953269958496
[1, 2334] loss_train: 0.011419, loss_test: 0.005996
time: 0.25005483627319336
time: 2.2525041103363037
[1, 2335] loss_train: 0.011301, loss_test: 0.005974
time: 0.24405312538146973
time: 2.293513536453247
[1, 2336] loss_train: 0.015429, loss_test: 0.005959
time: 0.2580568790435791
time: 2.228498697280884
[1, 2337] loss_train: 0.003695, loss_test: 0.005969
time: 0.24505400657653809
time: 2.2195112705230713
[1, 2338] loss_train: 0.001360, loss_test: 0.005990
time: 0.24805521965026855
time: 2.236003875732422
[1, 2339] loss_train: 0.003411, loss_test: 0.006008
time: 0.2560567855834961
time: 2.2625086307525635
[1, 2340] loss_train: 0.007353, loss_test: 0.006021
time: 0.26105737686157227
time: 2.2655069828033447
[1, 2341] loss_train: 0.009006, loss_test: 0.006012
time: 0.25005507469177246
time: 2.331522226333618
[1, 2342] loss_train: 0.002196, loss_test: 0.005991
time: 0.2520558834075928
time: 2.282510757446289
[1, 2343] loss_train: 0.004548, loss_test: 0.005975
time: 0.24806809425354004
time: 2.2865116596221924
[1, 2344] loss_train: 0.005560, loss_test: 0.005965
time: 0.2600572109222412
time: 2.422541379928589
[1, 2345] loss_train: 0.006088, loss_test: 0.005965
time: 0.2560577392578125
time: 2.1924896240234375
[1, 2346] loss_train: 0.001195, loss_test: 0.005970
time: 0.24805569648742676
time: 2.213494300842285
[1, 2347] loss_train: 0.006448, loss_test: 0.005976
time: 0.2450542449951172
time: 2.2375006675720215
[1, 2348] loss_train: 0.010890, loss_test: 0.005974
time: 0.2450547218322754
time: 2.2175302505493164
[1, 2349] loss_train: 0.014741, loss_test: 0.005967
time: 0.24806666374206543
time: 2.2264974117279053
[1, 2350] loss_train: 0.004989, loss_test: 0.005964
time: 0.25705671310424805
time: 2.2515037059783936
[1, 2351] loss_train: 0.006449, loss_test: 0.005963
time: 0.24506855010986328
time: 2.2174952030181885
[1, 2352] loss_train: 0.001881, loss_test: 0.005965
time: 0.2450554370880127
time: 2.22149658203125
[1, 2353] loss_train: 0.003665, loss_test: 0.005965
time: 0.24405479431152344
time: 2.2375001907348633
[1, 2354] loss_train: 0.003937, loss_test: 0.005969
time: 0.24405479431152344
time: 2.2124950885772705
[1, 2355] loss_train: 0.004473, loss_test: 0.005974
time: 0.2470543384552002
time: 2.2355005741119385
[1, 2356] loss_train: 0.002250, loss_test: 0.005981
time: 0.2510552406311035
time: 2.22749924659729
[1, 2357] loss_train: 0.004715, loss_test: 0.005990
time: 0.24707365036010742
time: 2.2595059871673584
[1, 2358] loss_train: 0.003950, loss_test: 0.005998
time: 0.2490558624267578
time: 2.234499216079712
[1, 2359] loss_train: 0.007751, loss_test: 0.006001
time: 0.2450549602508545
time: 2.224499464035034
[1, 2360] loss_train: 0.003806, loss_test: 0.006004
time: 0.26105785369873047
time: 2.2675094604492188
[1, 2361] loss_train: 0.006821, loss_test: 0.006005
time: 0.24605464935302734
time: 2.2105090618133545
[1, 2362] loss_train: 0.003432, loss_test: 0.006006
time: 0.24905657768249512
time: 2.243501901626587
[1, 2363] loss_train: 0.009886, loss_test: 0.005996
time: 0.24405479431152344
time: 2.249502658843994
[1, 2364] loss_train: 0.014091, loss_test: 0.005975
time: 0.24907946586608887
time: 2.232499837875366
[1, 2365] loss_train: 0.007024, loss_test: 0.005958
time: 0.24506711959838867
time: 2.2224977016448975
[1, 2366] loss_train: 0.007315, loss_test: 0.005947
time: 0.24806690216064453
time: 2.2365005016326904
[1, 2367] loss_train: 0.008754, loss_test: 0.005943
time: 0.24405431747436523
time: 2.2425012588500977
[1, 2368] loss_train: 0.008768, loss_test: 0.005943
time: 0.24405431747436523
time: 2.2340052127838135
[1, 2369] loss_train: 0.006702, loss_test: 0.005944
time: 0.24405407905578613
time: 2.228498935699463
[1, 2370] loss_train: 0.007762, loss_test: 0.005949
time: 0.25505590438842773
time: 2.293513536453247
[1, 2371] loss_train: 0.013590, loss_test: 0.005959
time: 0.24505400657653809
time: 2.2175252437591553
[1, 2372] loss_train: 0.005151, loss_test: 0.005969
time: 0.24505400657653809
time: 2.2435014247894287
[1, 2373] loss_train: 0.007557, loss_test: 0.005973
time: 0.24605560302734375
time: 2.195491075515747
[1, 2374] loss_train: 0.008299, loss_test: 0.005979
time: 0.24405407905578613
time: 2.212998867034912
[1, 2375] loss_train: 0.007173, loss_test: 0.005981
time: 0.24305343627929688
time: 2.232499599456787
[1, 2376] loss_train: 0.009829, loss_test: 0.005956
time: 0.24405479431152344
time: 2.248502254486084
[1, 2377] loss_train: 0.003460, loss_test: 0.005948
time: 0.24605536460876465
time: 2.223496913909912
[1, 2378] loss_train: 0.008377, loss_test: 0.005954
time: 0.2450542449951172
time: 2.2375032901763916
[1, 2379] loss_train: 0.003072, loss_test: 0.005973
time: 0.2450542449951172
time: 2.223508358001709
[1, 2380] loss_train: 0.003144, loss_test: 0.006000
time: 0.2560563087463379
time: 2.2755091190338135
[1, 2381] loss_train: 0.005962, loss_test: 0.006029
time: 0.24805498123168945
time: 2.2420175075531006
[1, 2382] loss_train: 0.010109, loss_test: 0.006054
time: 0.24405479431152344
time: 2.2314987182617188
[1, 2383] loss_train: 0.015080, loss_test: 0.006051
time: 0.2490553855895996
time: 2.210513114929199
[1, 2384] loss_train: 0.007620, loss_test: 0.006038
time: 0.2450556755065918
time: 2.2314987182617188
[1, 2385] loss_train: 0.003234, loss_test: 0.006029
time: 0.2456214427947998
time: 2.2355003356933594
[1, 2386] loss_train: 0.006795, loss_test: 0.006017
time: 0.2450547218322754
time: 2.224498987197876
[1, 2387] loss_train: 0.006091, loss_test: 0.006005
time: 0.25005578994750977
time: 2.2415008544921875
[1, 2388] loss_train: 0.007289, loss_test: 0.005996
time: 0.2450549602508545
time: 2.223496913909912
[1, 2389] loss_train: 0.000886, loss_test: 0.005992
time: 0.24805498123168945
time: 2.2431132793426514
[1, 2390] loss_train: 0.011587, loss_test: 0.005981
time: 0.2620577812194824
time: 2.2975308895111084
[1, 2391] loss_train: 0.011631, loss_test: 0.005968
time: 0.25107264518737793
time: 2.2505037784576416
[1, 2392] loss_train: 0.009084, loss_test: 0.005960
time: 0.2450542449951172
time: 2.283511161804199
[1, 2393] loss_train: 0.007793, loss_test: 0.005957
time: 0.2490549087524414
time: 2.205998659133911
[1, 2394] loss_train: 0.003175, loss_test: 0.005958
time: 0.24605441093444824
time: 2.213495969772339
[1, 2395] loss_train: 0.009703, loss_test: 0.005966
time: 0.24805474281311035
time: 2.2370171546936035
[1, 2396] loss_train: 0.006586, loss_test: 0.005975
time: 0.24405479431152344
time: 2.2655062675476074
[1, 2397] loss_train: 0.009610, loss_test: 0.005992
time: 0.2470545768737793
time: 2.2055134773254395
[1, 2398] loss_train: 0.002999, loss_test: 0.006010
time: 0.24405455589294434
time: 2.2375001907348633
[1, 2399] loss_train: 0.002301, loss_test: 0.006026
time: 0.24605464935302734
time: 2.2295103073120117
[1, 2400] loss_train: 0.007735, loss_test: 0.006026
time: 0.2600579261779785
time: 2.273508071899414
[1, 2401] loss_train: 0.010144, loss_test: 0.006006
time: 0.24805498123168945
time: 2.2865116596221924
[1, 2402] loss_train: 0.010591, loss_test: 0.005981
time: 0.25005555152893066
time: 2.247502565383911
[1, 2403] loss_train: 0.004797, loss_test: 0.005963
time: 0.2510559558868408
time: 2.2365000247955322
[1, 2404] loss_train: 0.000639, loss_test: 0.005964
time: 0.24506688117980957
time: 2.2264976501464844
[1, 2405] loss_train: 0.006877, loss_test: 0.005975
time: 0.24605536460876465
time: 2.2435028553009033
[1, 2406] loss_train: 0.005433, loss_test: 0.005996
time: 0.24605560302734375
time: 2.233499050140381
[1, 2407] loss_train: 0.006519, loss_test: 0.006018
time: 0.24405503273010254
time: 2.2244975566864014
[1, 2408] loss_train: 0.008415, loss_test: 0.006039
time: 0.24505400657653809
time: 2.2505037784576416
[1, 2409] loss_train: 0.004043, loss_test: 0.006053
time: 0.2450544834136963
time: 2.2254979610443115
[1, 2410] loss_train: 0.003823, loss_test: 0.006063
time: 0.258056640625
time: 2.297529935836792
[1, 2411] loss_train: 0.004796, loss_test: 0.006069
time: 0.2560563087463379
time: 2.265509605407715
[1, 2412] loss_train: 0.003790, loss_test: 0.006072
time: 0.24805450439453125
time: 2.2485082149505615
[1, 2413] loss_train: 0.004116, loss_test: 0.006068
time: 0.24605417251586914
time: 2.2365000247955322
[1, 2414] loss_train: 0.008859, loss_test: 0.006057
time: 0.2470557689666748
time: 2.2515034675598145
[1, 2415] loss_train: 0.005908, loss_test: 0.006042
time: 0.24605488777160645
time: 2.25050687789917
[1, 2416] loss_train: 0.011639, loss_test: 0.006014
time: 0.2470550537109375
time: 2.2635080814361572
[1, 2417] loss_train: 0.002722, loss_test: 0.005999
time: 0.24505400657653809
time: 2.232499599456787
[1, 2418] loss_train: 0.001287, loss_test: 0.005995
time: 0.24505329132080078
time: 2.2446346282958984
[1, 2419] loss_train: 0.002013, loss_test: 0.005999
time: 0.24505376815795898
time: 2.244513988494873
[1, 2420] loss_train: 0.000823, loss_test: 0.006011
time: 0.2560575008392334
time: 2.2565040588378906
[1, 2421] loss_train: 0.002729, loss_test: 0.006019
time: 0.24405384063720703
time: 2.217496871948242
[1, 2422] loss_train: 0.005253, loss_test: 0.006015
time: 0.2450544834136963
time: 2.225513219833374
[1, 2423] loss_train: 0.002431, loss_test: 0.006016
time: 0.2450551986694336
time: 2.231020212173462
[1, 2424] loss_train: 0.007391, loss_test: 0.006009
time: 0.24606728553771973
time: 2.2284984588623047
[1, 2425] loss_train: 0.001794, loss_test: 0.006007
time: 0.24405384063720703
time: 2.2254981994628906
[1, 2426] loss_train: 0.002793, loss_test: 0.006004
time: 0.24605464935302734
time: 2.2264981269836426
[1, 2427] loss_train: 0.007245, loss_test: 0.006004
time: 0.24405431747436523
time: 2.2425012588500977
[1, 2428] loss_train: 0.008541, loss_test: 0.005995
time: 0.24606776237487793
time: 2.2205069065093994
[1, 2429] loss_train: 0.004548, loss_test: 0.005984
time: 0.2450547218322754
time: 2.210498094558716
[1, 2430] loss_train: 0.003947, loss_test: 0.005974
time: 0.25705623626708984
time: 2.253504753112793
[1, 2431] loss_train: 0.008907, loss_test: 0.005963
time: 0.24405336380004883
time: 2.2605059146881104
[1, 2432] loss_train: 0.000866, loss_test: 0.005954
time: 0.24505400657653809
time: 2.2134976387023926
[1, 2433] loss_train: 0.006281, loss_test: 0.005948
time: 0.24405455589294434
time: 2.220653533935547
[1, 2434] loss_train: 0.008611, loss_test: 0.005946
time: 0.2530555725097656
time: 2.220496892929077
[1, 2435] loss_train: 0.008341, loss_test: 0.005947
time: 0.24305415153503418
time: 2.225497007369995
[1, 2436] loss_train: 0.009583, loss_test: 0.005956
time: 0.2490558624267578
time: 2.2365152835845947
[1, 2437] loss_train: 0.002125, loss_test: 0.005966
time: 0.2470545768737793
time: 2.2294983863830566
[1, 2438] loss_train: 0.009649, loss_test: 0.005979
time: 0.24805569648742676
time: 2.232499599456787
[1, 2439] loss_train: 0.004028, loss_test: 0.005991
time: 0.24405360221862793
time: 2.230499029159546
[1, 2440] loss_train: 0.012330, loss_test: 0.005998
time: 0.2575826644897461
time: 2.2685093879699707
[1, 2441] loss_train: 0.006608, loss_test: 0.005992
time: 0.25705790519714355
time: 2.232499361038208
[1, 2442] loss_train: 0.010599, loss_test: 0.005982
time: 0.24605464935302734
time: 2.231499433517456
[1, 2443] loss_train: 0.007445, loss_test: 0.005970
time: 0.2450542449951172
time: 2.223001718521118
[1, 2444] loss_train: 0.008701, loss_test: 0.005958
time: 0.24405407905578613
time: 2.236504554748535
[1, 2445] loss_train: 0.007486, loss_test: 0.005952
time: 0.24505400657653809
time: 2.2164976596832275
[1, 2446] loss_train: 0.001445, loss_test: 0.005954
time: 0.24405384063720703
time: 2.2455027103424072
[1, 2447] loss_train: 0.011245, loss_test: 0.005958
time: 0.24405384063720703
time: 2.2275006771087646
[1, 2448] loss_train: 0.002281, loss_test: 0.005965
time: 0.24908733367919922
time: 2.231498956680298
[1, 2449] loss_train: 0.010958, loss_test: 0.005968
time: 0.24605464935302734
time: 2.2415008544921875
[1, 2450] loss_train: 0.008899, loss_test: 0.005967
time: 0.2540702819824219
time: 2.264507293701172
[1, 2451] loss_train: 0.008992, loss_test: 0.005964
time: 0.24805402755737305
time: 2.239501476287842
[1, 2452] loss_train: 0.009960, loss_test: 0.005962
time: 0.24506735801696777
time: 2.231499671936035
[1, 2453] loss_train: 0.001690, loss_test: 0.005965
time: 0.24605417251586914
time: 2.2214975357055664
[1, 2454] loss_train: 0.009329, loss_test: 0.005959
time: 0.24405336380004883
time: 2.230501890182495
[1, 2455] loss_train: 0.009646, loss_test: 0.005954
time: 0.2530558109283447
time: 2.226252555847168
[1, 2456] loss_train: 0.005900, loss_test: 0.005954
time: 0.24305391311645508
time: 2.215496063232422
[1, 2457] loss_train: 0.006359, loss_test: 0.005956
time: 0.24505376815795898
time: 2.2310049533843994
[1, 2458] loss_train: 0.005000, loss_test: 0.005960
time: 0.24505400657653809
time: 2.208494186401367
[1, 2459] loss_train: 0.005549, loss_test: 0.005964
time: 0.2490549087524414
time: 2.2425014972686768
[1, 2460] loss_train: 0.008400, loss_test: 0.005971
time: 0.2600579261779785
time: 2.2505040168762207
[1, 2461] loss_train: 0.004850, loss_test: 0.005975
time: 0.2510554790496826
time: 2.2234978675842285
[1, 2462] loss_train: 0.005235, loss_test: 0.005978
time: 0.2510559558868408
time: 2.2785115242004395
[1, 2463] loss_train: 0.005918, loss_test: 0.005982
time: 0.24909186363220215
time: 2.25850510597229
[1, 2464] loss_train: 0.010442, loss_test: 0.005981
time: 0.24506640434265137
time: 2.2255160808563232
[1, 2465] loss_train: 0.007834, loss_test: 0.005977
time: 0.2520561218261719
time: 2.243504047393799
[1, 2466] loss_train: 0.004822, loss_test: 0.005973
time: 0.24606657028198242
time: 2.221498727798462
[1, 2467] loss_train: 0.011539, loss_test: 0.005973
time: 0.24905753135681152
time: 2.2355005741119385
[1, 2468] loss_train: 0.009720, loss_test: 0.005968
time: 0.2440793514251709
time: 2.2154953479766846
[1, 2469] loss_train: 0.012669, loss_test: 0.005955
time: 0.2525796890258789
time: 2.239513635635376
[1, 2470] loss_train: 0.011416, loss_test: 0.005953
time: 0.2560567855834961
time: 2.2585055828094482
[1, 2471] loss_train: 0.003313, loss_test: 0.005954
time: 0.25005507469177246
time: 2.2310032844543457
[1, 2472] loss_train: 0.000826, loss_test: 0.005961
time: 0.24605441093444824
time: 2.245502471923828
[1, 2473] loss_train: 0.005370, loss_test: 0.005972
time: 0.24805474281311035
time: 2.254504442214966
[1, 2474] loss_train: 0.005481, loss_test: 0.005984
time: 0.2450549602508545
time: 2.2515034675598145
[1, 2475] loss_train: 0.011991, loss_test: 0.005988
time: 0.24505400657653809
time: 2.2355003356933594
[1, 2476] loss_train: 0.010793, loss_test: 0.005979
time: 0.24405407905578613
time: 2.23449969291687
[1, 2477] loss_train: 0.010881, loss_test: 0.005967
time: 0.24805474281311035
time: 2.198500156402588
[1, 2478] loss_train: 0.008378, loss_test: 0.005955
time: 0.2450542449951172
time: 2.242501974105835
[1, 2479] loss_train: 0.001919, loss_test: 0.005947
time: 0.2470550537109375
time: 2.2495198249816895
[1, 2480] loss_train: 0.006437, loss_test: 0.005940
time: 0.2560696601867676
time: 2.271507978439331
[1, 2481] loss_train: 0.004664, loss_test: 0.005936
time: 0.24405407905578613
time: 2.24450421333313
[1, 2482] loss_train: 0.005687, loss_test: 0.005933
time: 0.2450549602508545
time: 2.222499370574951
[1, 2483] loss_train: 0.006643, loss_test: 0.005931
time: 0.24405407905578613
time: 2.258513927459717
[1, 2484] loss_train: 0.007296, loss_test: 0.005931
time: 0.24405431747436523
time: 2.2375009059906006
[1, 2485] loss_train: 0.003234, loss_test: 0.005933
time: 0.24305391311645508
time: 2.2174954414367676
[1, 2486] loss_train: 0.000759, loss_test: 0.005939
time: 0.24606704711914062
time: 2.2535033226013184
[1, 2487] loss_train: 0.007803, loss_test: 0.005945
time: 0.24406790733337402
time: 2.228498935699463
[1, 2488] loss_train: 0.007343, loss_test: 0.005948
time: 0.24505400657653809
time: 2.24650239944458
[1, 2489] loss_train: 0.004409, loss_test: 0.005953
time: 0.24605488777160645
time: 2.2175376415252686
[1, 2490] loss_train: 0.009203, loss_test: 0.005970
time: 0.2560563087463379
time: 2.243502616882324
[1, 2491] loss_train: 0.004269, loss_test: 0.005995
time: 0.24405574798583984
time: 2.233502149581909
[1, 2492] loss_train: 0.009896, loss_test: 0.006024
time: 0.24405384063720703
time: 2.2124953269958496
[1, 2493] loss_train: 0.006480, loss_test: 0.006049
time: 0.24505400657653809
time: 2.208494186401367
[1, 2494] loss_train: 0.008316, loss_test: 0.006024
time: 0.2450549602508545
time: 2.259505271911621
[1, 2495] loss_train: 0.005237, loss_test: 0.006002
time: 0.24505376815795898
time: 2.213007688522339
[1, 2496] loss_train: 0.007022, loss_test: 0.005981
time: 0.25206971168518066
time: 2.2195358276367188
[1, 2497] loss_train: 0.016299, loss_test: 0.005968
time: 0.24505376815795898
time: 2.254509449005127
[1, 2498] loss_train: 0.004243, loss_test: 0.005963
time: 0.24904966354370117
time: 2.2355027198791504
[1, 2499] loss_train: 0.005569, loss_test: 0.005963
time: 0.24706816673278809
time: 2.230499267578125
[1, 2500] loss_train: 0.006717, loss_test: 0.005961
time: 0.26105833053588867
time: 2.2665066719055176
[1, 2501] loss_train: 0.005478, loss_test: 0.005951
time: 0.2550697326660156
time: 2.22351336479187
[1, 2502] loss_train: 0.002378, loss_test: 0.005944
time: 0.24806785583496094
time: 2.229499101638794
[1, 2503] loss_train: 0.004409, loss_test: 0.005941
time: 0.24605417251586914
time: 2.2605221271514893
[1, 2504] loss_train: 0.007209, loss_test: 0.005942
time: 0.2479557991027832
time: 2.228498935699463
[1, 2505] loss_train: 0.005254, loss_test: 0.005944
time: 0.2450544834136963
time: 2.2383978366851807
[1, 2506] loss_train: 0.005241, loss_test: 0.005949
time: 0.24805521965026855
time: 2.2395122051239014
[1, 2507] loss_train: 0.002770, loss_test: 0.005956
time: 0.2450547218322754
time: 2.2425014972686768
[1, 2508] loss_train: 0.003546, loss_test: 0.005963
time: 0.24305343627929688
time: 2.2505040168762207
[1, 2509] loss_train: 0.002416, loss_test: 0.005972
time: 0.24505400657653809
time: 2.226008892059326
[1, 2510] loss_train: 0.002824, loss_test: 0.005986
time: 0.256056547164917
time: 2.310046434402466
[1, 2511] loss_train: 0.005194, loss_test: 0.005998
time: 0.24605560302734375
time: 2.227299213409424
[1, 2512] loss_train: 0.001148, loss_test: 0.006010
time: 0.24305415153503418
time: 2.2789812088012695
[1, 2513] loss_train: 0.007419, loss_test: 0.006012
time: 0.2450544834136963
time: 2.2134978771209717
[1, 2514] loss_train: 0.007938, loss_test: 0.006000
time: 0.24405384063720703
time: 2.246502637863159
[1, 2515] loss_train: 0.006903, loss_test: 0.005972
time: 0.2450542449951172
time: 2.20904278755188
[1, 2516] loss_train: 0.004447, loss_test: 0.005953
time: 0.2490553855895996
time: 2.237509250640869
[1, 2517] loss_train: 0.005598, loss_test: 0.005943
time: 0.24705886840820312
time: 2.230499744415283
[1, 2518] loss_train: 0.003006, loss_test: 0.005941
time: 0.24405455589294434
time: 2.22249698638916
[1, 2519] loss_train: 0.004482, loss_test: 0.005944
time: 0.24405360221862793
time: 2.2255232334136963
[1, 2520] loss_train: 0.007299, loss_test: 0.005949
time: 0.256070613861084
time: 2.2540078163146973
[1, 2521] loss_train: 0.002361, loss_test: 0.005958
time: 0.2445535659790039
time: 2.2400035858154297
[1, 2522] loss_train: 0.005625, loss_test: 0.005955
time: 0.24505376815795898
time: 2.230501890182495
[1, 2523] loss_train: 0.005850, loss_test: 0.005954
time: 0.2460801601409912
time: 2.2220592498779297
[1, 2524] loss_train: 0.000773, loss_test: 0.005945
time: 0.24405431747436523
time: 2.240501880645752
[1, 2525] loss_train: 0.005517, loss_test: 0.005938
time: 0.24305438995361328
time: 2.2545130252838135
[1, 2526] loss_train: 0.014075, loss_test: 0.005934
time: 0.2470550537109375
time: 2.196491241455078
[1, 2527] loss_train: 0.012466, loss_test: 0.005930
time: 0.24506616592407227
time: 2.1944916248321533
[1, 2528] loss_train: 0.006571, loss_test: 0.005926
time: 0.24605917930603027
time: 2.2210001945495605
[1, 2529] loss_train: 0.006515, loss_test: 0.005922
time: 0.25005531311035156
time: 2.239501476287842
[1, 2530] loss_train: 0.003924, loss_test: 0.005919
time: 0.25705790519714355
time: 2.275531053543091
[1, 2531] loss_train: 0.004777, loss_test: 0.005918
time: 0.2560575008392334
time: 2.2565042972564697
[1, 2532] loss_train: 0.013320, loss_test: 0.005920
time: 0.25705742835998535
time: 2.360527992248535
[1, 2533] loss_train: 0.003219, loss_test: 0.005923
time: 0.24805498123168945
time: 2.2169995307922363
[1, 2534] loss_train: 0.005396, loss_test: 0.005929
time: 0.25505685806274414
time: 2.3385231494903564
[1, 2535] loss_train: 0.004937, loss_test: 0.005936
time: 0.2560563087463379
time: 2.3255205154418945
[1, 2536] loss_train: 0.006006, loss_test: 0.005944
time: 0.254056453704834
time: 2.295546054840088
[1, 2537] loss_train: 0.005933, loss_test: 0.005951
time: 0.2450551986694336
time: 2.246504783630371
[1, 2538] loss_train: 0.008019, loss_test: 0.005954
time: 0.25205564498901367
time: 2.294513702392578
[1, 2539] loss_train: 0.009664, loss_test: 0.005943
time: 0.36208033561706543
time: 2.3955349922180176
[1, 2540] loss_train: 0.007383, loss_test: 0.005940
time: 0.2620584964752197
time: 2.3905344009399414
[1, 2541] loss_train: 0.004853, loss_test: 0.005939
time: 0.2520565986633301
time: 2.3123044967651367
[1, 2542] loss_train: 0.009772, loss_test: 0.005939
time: 0.2490553855895996
time: 2.2535037994384766
[1, 2543] loss_train: 0.007052, loss_test: 0.005943
time: 0.25005531311035156
time: 2.255505323410034
[1, 2544] loss_train: 0.003036, loss_test: 0.005947
time: 0.25105857849121094
time: 2.2855112552642822
[1, 2545] loss_train: 0.005384, loss_test: 0.005951
time: 0.26105737686157227
time: 2.288511276245117
[1, 2546] loss_train: 0.010391, loss_test: 0.005953
time: 0.24605488777160645
time: 2.2645058631896973
[1, 2547] loss_train: 0.004987, loss_test: 0.005956
time: 0.25305628776550293
time: 2.288560152053833
[1, 2548] loss_train: 0.006338, loss_test: 0.005958
time: 0.2490551471710205
time: 2.2785096168518066
[1, 2549] loss_train: 0.005457, loss_test: 0.005959
time: 0.25305604934692383
time: 2.291520833969116
[1, 2550] loss_train: 0.005289, loss_test: 0.005961
time: 0.25685930252075195
time: 2.257505178451538
[1, 2551] loss_train: 0.009143, loss_test: 0.005962
time: 0.24605441093444824
time: 2.2635059356689453
[1, 2552] loss_train: 0.009220, loss_test: 0.005961
time: 0.25005602836608887
time: 2.294016122817993
[1, 2553] loss_train: 0.004734, loss_test: 0.005962
time: 0.2450549602508545
time: 2.3175182342529297
[1, 2554] loss_train: 0.002352, loss_test: 0.005964
time: 0.25005531311035156
time: 2.2695107460021973
[1, 2555] loss_train: 0.003870, loss_test: 0.005967
time: 0.24605679512023926
time: 2.244502544403076
[1, 2556] loss_train: 0.004717, loss_test: 0.005972
time: 0.2470564842224121
time: 2.240499258041382
[1, 2557] loss_train: 0.007518, loss_test: 0.005977
time: 0.2490558624267578
time: 2.2445034980773926
[1, 2558] loss_train: 0.007529, loss_test: 0.005985
time: 0.24806809425354004
time: 2.2745139598846436
[1, 2559] loss_train: 0.009761, loss_test: 0.005976
time: 0.25505709648132324
time: 2.314518928527832
[1, 2560] loss_train: 0.004312, loss_test: 0.005971
time: 0.2600574493408203
time: 2.405538320541382
[1, 2561] loss_train: 0.006249, loss_test: 0.005954
time: 0.25305652618408203
time: 2.2765209674835205
[1, 2562] loss_train: 0.004782, loss_test: 0.005942
time: 0.2540559768676758
time: 2.243502378463745
[1, 2563] loss_train: 0.003665, loss_test: 0.005937
time: 0.2510559558868408
time: 2.220000743865967
[1, 2564] loss_train: 0.005646, loss_test: 0.005935
time: 0.25006818771362305
time: 2.2645058631896973
[1, 2565] loss_train: 0.008060, loss_test: 0.005936
time: 0.24405431747436523
time: 2.3125174045562744
[1, 2566] loss_train: 0.005094, loss_test: 0.005937
time: 0.2470548152923584
time: 2.249516248703003
[1, 2567] loss_train: 0.015842, loss_test: 0.005947
time: 0.24305367469787598
time: 2.3735315799713135
[1, 2568] loss_train: 0.006395, loss_test: 0.005961
time: 0.2510554790496826
time: 2.3145179748535156
[1, 2569] loss_train: 0.008968, loss_test: 0.005973
time: 0.2760615348815918
time: 2.3165175914764404
[1, 2570] loss_train: 0.009061, loss_test: 0.005979
time: 0.2580568790435791
time: 2.335521936416626
[1, 2571] loss_train: 0.008720, loss_test: 0.005977
time: 0.2470550537109375
time: 2.286511182785034
[1, 2572] loss_train: 0.004995, loss_test: 0.005974
time: 0.2690596580505371
time: 2.2154946327209473
[1, 2573] loss_train: 0.002124, loss_test: 0.005976
time: 0.2490556240081787
time: 2.321535348892212
[1, 2574] loss_train: 0.003996, loss_test: 0.005977
time: 0.24305391311645508
time: 2.225001335144043
[1, 2575] loss_train: 0.004069, loss_test: 0.005977
time: 0.24805474281311035
time: 2.24951171875
[1, 2576] loss_train: 0.004109, loss_test: 0.005979
time: 0.24205303192138672
time: 2.241502046585083
[1, 2577] loss_train: 0.011092, loss_test: 0.005976
time: 0.24605917930603027
time: 2.244502305984497
[1, 2578] loss_train: 0.007856, loss_test: 0.005971
time: 0.24306583404541016
time: 2.2645158767700195
[1, 2579] loss_train: 0.001433, loss_test: 0.005970
time: 0.2520568370819092
time: 2.2630109786987305
[1, 2580] loss_train: 0.010099, loss_test: 0.005959
time: 0.2540557384490967
time: 2.2555055618286133
[1, 2581] loss_train: 0.009018, loss_test: 0.005956
time: 0.24605488777160645
time: 2.2264978885650635
[1, 2582] loss_train: 0.008020, loss_test: 0.005966
time: 0.2560572624206543
time: 2.2425012588500977
[1, 2583] loss_train: 0.006602, loss_test: 0.005988
time: 0.2470545768737793
time: 2.21875262260437
[1, 2584] loss_train: 0.006771, loss_test: 0.006000
time: 0.24305391311645508
time: 2.2775094509124756
[1, 2585] loss_train: 0.009804, loss_test: 0.006007
time: 0.24805545806884766
time: 2.216128349304199
[1, 2586] loss_train: 0.004875, loss_test: 0.006007
time: 0.24405360221862793
time: 2.2134969234466553
[1, 2587] loss_train: 0.003371, loss_test: 0.005999
time: 0.24305391311645508
time: 2.2560088634490967
[1, 2588] loss_train: 0.010986, loss_test: 0.005988
time: 0.251056432723999
time: 2.2395026683807373
[1, 2589] loss_train: 0.006187, loss_test: 0.005976
time: 0.24405384063720703
time: 2.264456033706665
[1, 2590] loss_train: 0.004579, loss_test: 0.005966
time: 0.25905704498291016
time: 2.282510995864868
[1, 2591] loss_train: 0.010919, loss_test: 0.005961
time: 0.24405479431152344
time: 2.289518356323242
[1, 2592] loss_train: 0.002188, loss_test: 0.005962
time: 0.24305415153503418
time: 2.2723190784454346
[1, 2593] loss_train: 0.011483, loss_test: 0.005963
time: 0.2470550537109375
time: 2.2755091190338135
[1, 2594] loss_train: 0.008705, loss_test: 0.005968
time: 0.24305319786071777
time: 2.268507957458496
[1, 2595] loss_train: 0.005295, loss_test: 0.005971
time: 0.25005507469177246
time: 2.2735090255737305
[1, 2596] loss_train: 0.014797, loss_test: 0.005965
time: 0.24805545806884766
time: 2.2834677696228027
[1, 2597] loss_train: 0.004914, loss_test: 0.005963
time: 0.24505400657653809
time: 2.2345099449157715
[1, 2598] loss_train: 0.010295, loss_test: 0.005959
time: 0.2430591583251953
time: 2.2295022010803223
[1, 2599] loss_train: 0.005018, loss_test: 0.005957
time: 0.24805521965026855
time: 2.204498767852783
[1, 2600] loss_train: 0.010973, loss_test: 0.005954
time: 0.256056547164917
time: 2.204496145248413
[1, 2601] loss_train: 0.006788, loss_test: 0.005955
time: 0.25109386444091797
time: 2.244502305984497
[1, 2602] loss_train: 0.011900, loss_test: 0.005958
time: 0.24305391311645508
time: 2.2575252056121826
[1, 2603] loss_train: 0.001434, loss_test: 0.005962
time: 0.24605488777160645
time: 2.2505033016204834
[1, 2604] loss_train: 0.001601, loss_test: 0.005967
time: 0.24305486679077148
time: 2.266772985458374
[1, 2605] loss_train: 0.003714, loss_test: 0.005964
time: 0.2450547218322754
time: 2.2425012588500977
[1, 2606] loss_train: 0.003133, loss_test: 0.005964
time: 0.24405384063720703
time: 2.2655069828033447
[1, 2607] loss_train: 0.007736, loss_test: 0.005961
time: 0.2490558624267578
time: 2.2555177211761475
[1, 2608] loss_train: 0.004152, loss_test: 0.005957
time: 0.24305462837219238
time: 2.223496913909912
[1, 2609] loss_train: 0.004681, loss_test: 0.005956
time: 0.2450547218322754
time: 2.2325072288513184
[1, 2610] loss_train: 0.009701, loss_test: 0.005958
time: 0.25705742835998535
time: 2.224496841430664
[1, 2611] loss_train: 0.014784, loss_test: 0.005952
time: 0.24106669425964355
time: 2.244502305984497
[1, 2612] loss_train: 0.015128, loss_test: 0.005945
time: 0.24405479431152344
time: 2.23349928855896
[1, 2613] loss_train: 0.008950, loss_test: 0.005947
time: 0.24305415153503418
time: 2.205493211746216
[1, 2614] loss_train: 0.011259, loss_test: 0.005973
time: 0.24405431747436523
time: 2.2528622150421143
[1, 2615] loss_train: 0.008944, loss_test: 0.006010
time: 0.24105310440063477
time: 2.208008289337158
[1, 2616] loss_train: 0.005058, loss_test: 0.006043
time: 0.24205422401428223
time: 2.233499050140381
[1, 2617] loss_train: 0.004706, loss_test: 0.006066
time: 0.24605417251586914
time: 2.2204971313476562
[1, 2618] loss_train: 0.003593, loss_test: 0.006078
time: 0.24205327033996582
time: 2.2344110012054443
[1, 2619] loss_train: 0.006047, loss_test: 0.006069
time: 0.2490553855895996
time: 2.24150013923645
[1, 2620] loss_train: 0.001388, loss_test: 0.006062
time: 0.25305652618408203
time: 2.2194979190826416
[1, 2621] loss_train: 0.004771, loss_test: 0.006051
time: 0.24805617332458496
time: 2.213012933731079
[1, 2622] loss_train: 0.004139, loss_test: 0.005999
time: 0.24405455589294434
time: 2.2355000972747803
[1, 2623] loss_train: 0.005482, loss_test: 0.005967
time: 0.24205350875854492
time: 2.251058578491211
[1, 2624] loss_train: 0.006130, loss_test: 0.005946
time: 0.24805521965026855
time: 2.2154955863952637
[1, 2625] loss_train: 0.001092, loss_test: 0.005942
time: 0.25005531311035156
time: 2.2765095233917236
[1, 2626] loss_train: 0.005252, loss_test: 0.005960
time: 0.2470543384552002
time: 2.247767448425293
[1, 2627] loss_train: 0.000732, loss_test: 0.005999
time: 0.24305438995361328
time: 2.208494186401367
[1, 2628] loss_train: 0.005360, loss_test: 0.006045
time: 0.24709439277648926
time: 2.2365007400512695
[1, 2629] loss_train: 0.004682, loss_test: 0.006087
time: 0.24205350875854492
time: 2.2355008125305176
[1, 2630] loss_train: 0.009070, loss_test: 0.006119
time: 0.2580573558807373
time: 2.260505199432373
[1, 2631] loss_train: 0.008251, loss_test: 0.006136
time: 0.25705742835998535
time: 2.2505033016204834
[1, 2632] loss_train: 0.008004, loss_test: 0.006110
time: 0.24405431747436523
time: 2.233499526977539
[1, 2633] loss_train: 0.011597, loss_test: 0.006073
time: 0.2420663833618164
time: 2.2355000972747803
[1, 2634] loss_train: 0.005421, loss_test: 0.006037
time: 0.24265766143798828
time: 2.232509136199951
[1, 2635] loss_train: 0.009870, loss_test: 0.005989
time: 0.24305367469787598
time: 2.219496726989746
[1, 2636] loss_train: 0.007033, loss_test: 0.005964
time: 0.24105334281921387
time: 2.217015027999878
[1, 2637] loss_train: 0.007037, loss_test: 0.005959
time: 0.24405407905578613
time: 2.2345004081726074
[1, 2638] loss_train: 0.023557, loss_test: 0.005983
time: 0.24405312538146973
time: 2.256030321121216
[1, 2639] loss_train: 0.004014, loss_test: 0.006017
time: 0.24405455589294434
time: 2.2254974842071533
[1, 2640] loss_train: 0.004411, loss_test: 0.006036
time: 0.2540714740753174
time: 2.242501974105835
[1, 2641] loss_train: 0.004967, loss_test: 0.006020
time: 0.24305367469787598
time: 2.2785122394561768
[1, 2642] loss_train: 0.007509, loss_test: 0.005988
time: 0.2450542449951172
time: 2.267509937286377
[1, 2643] loss_train: 0.002856, loss_test: 0.005948
time: 0.24305486679077148
time: 2.2815113067626953
[1, 2644] loss_train: 0.000947, loss_test: 0.005929
time: 0.24405431747436523
time: 2.219496726989746
[1, 2645] loss_train: 0.001091, loss_test: 0.005933
time: 0.2450549602508545
time: 2.234498977661133
[1, 2646] loss_train: 0.005125, loss_test: 0.005959
time: 0.24309730529785156
time: 2.229499101638794
[1, 2647] loss_train: 0.001292, loss_test: 0.006002
time: 0.24305367469787598
time: 2.231499433517456
[1, 2648] loss_train: 0.005277, loss_test: 0.006048
time: 0.24105310440063477
time: 2.2214975357055664
[1, 2649] loss_train: 0.007729, loss_test: 0.006088
time: 0.24406838417053223
time: 2.228041410446167
[1, 2650] loss_train: 0.005138, loss_test: 0.006122
time: 0.2540559768676758
time: 2.2455027103424072
[1, 2651] loss_train: 0.000731, loss_test: 0.006160
time: 0.24305343627929688
time: 2.243502140045166
[1, 2652] loss_train: 0.007836, loss_test: 0.006174
time: 0.24405384063720703
time: 2.2625064849853516
[1, 2653] loss_train: 0.004290, loss_test: 0.006178
time: 0.24205279350280762
time: 2.250502347946167
[1, 2654] loss_train: 0.005120, loss_test: 0.006168
time: 0.24305438995361328
time: 2.2304985523223877
[1, 2655] loss_train: 0.009630, loss_test: 0.006118
time: 0.24406647682189941
time: 2.2605056762695312
[1, 2656] loss_train: 0.005072, loss_test: 0.006070
time: 0.24306702613830566
time: 2.2445015907287598
[1, 2657] loss_train: 0.006580, loss_test: 0.006025
time: 0.24305415153503418
time: 2.2154955863952637
[1, 2658] loss_train: 0.008454, loss_test: 0.005974
time: 0.24212074279785156
time: 2.2375009059906006
[1, 2659] loss_train: 0.017186, loss_test: 0.005928
time: 0.24594759941101074
time: 2.2133026123046875
[1, 2660] loss_train: 0.005636, loss_test: 0.005947
time: 0.2620575428009033
time: 2.230498790740967
[1, 2661] loss_train: 0.008083, loss_test: 0.006008
time: 0.24805521965026855
time: 2.244502544403076
[1, 2662] loss_train: 0.008519, loss_test: 0.006060
time: 0.2420330047607422
time: 2.2535040378570557
[1, 2663] loss_train: 0.001222, loss_test: 0.006107
time: 0.24605488777160645
time: 2.2495033740997314
[1, 2664] loss_train: 0.010606, loss_test: 0.006124
time: 0.24305415153503418
time: 2.235499858856201
[1, 2665] loss_train: 0.004812, loss_test: 0.006054
time: 0.2450544834136963
time: 2.2453360557556152
[1, 2666] loss_train: 0.006117, loss_test: 0.005987
time: 0.24305415153503418
time: 2.246534585952759
[1, 2667] loss_train: 0.002372, loss_test: 0.005944
time: 0.24806761741638184
time: 2.261505126953125
[1, 2668] loss_train: 0.001545, loss_test: 0.005916
time: 0.24405407905578613
time: 2.2495031356811523
[1, 2669] loss_train: 0.009348, loss_test: 0.005912
time: 0.2510550022125244
time: 2.2525041103363037
[1, 2670] loss_train: 0.002455, loss_test: 0.005926
time: 0.25505614280700684
time: 2.1994924545288086
[1, 2671] loss_train: 0.008798, loss_test: 0.005951
time: 0.24406790733337402
time: 2.2205073833465576
[1, 2672] loss_train: 0.010042, loss_test: 0.005977
time: 0.24405336380004883
time: 2.2055037021636963
[1, 2673] loss_train: 0.013454, loss_test: 0.005992
time: 0.24405479431152344
time: 2.221496343612671
[1, 2674] loss_train: 0.009669, loss_test: 0.005991
time: 0.24305367469787598
time: 2.228498935699463
[1, 2675] loss_train: 0.007563, loss_test: 0.005980
time: 0.24205327033996582
time: 2.2355191707611084
[1, 2676] loss_train: 0.002375, loss_test: 0.005975
time: 0.24205303192138672
time: 2.247016429901123
[1, 2677] loss_train: 0.002808, loss_test: 0.005964
time: 0.24305343627929688
time: 2.257505178451538
[1, 2678] loss_train: 0.010164, loss_test: 0.005954
time: 0.24207210540771484
time: 2.2244980335235596
[1, 2679] loss_train: 0.003664, loss_test: 0.005944
time: 0.24506831169128418
time: 2.2445015907287598
[1, 2680] loss_train: 0.005441, loss_test: 0.005936
time: 0.2630589008331299
time: 2.2665066719055176
[1, 2681] loss_train: 0.005446, loss_test: 0.005932
time: 0.24606060981750488
time: 2.226499557495117
[1, 2682] loss_train: 0.008315, loss_test: 0.005929
time: 0.24205422401428223
time: 2.23249888420105
[1, 2683] loss_train: 0.004204, loss_test: 0.005933
time: 0.2460792064666748
time: 2.2244975566864014
[1, 2684] loss_train: 0.006439, loss_test: 0.005937
time: 0.24205374717712402
time: 2.2495031356811523
[1, 2685] loss_train: 0.005429, loss_test: 0.005943
time: 0.24357080459594727
time: 2.237509250640869
[1, 2686] loss_train: 0.002487, loss_test: 0.005954
time: 0.24205303192138672
time: 2.2180287837982178
[1, 2687] loss_train: 0.002718, loss_test: 0.005967
time: 0.2470541000366211
time: 2.256505012512207
[1, 2688] loss_train: 0.007459, loss_test: 0.005976
time: 0.24205374717712402
time: 2.2254981994628906
[1, 2689] loss_train: 0.002426, loss_test: 0.005987
time: 0.24205446243286133
time: 2.2184956073760986
[1, 2690] loss_train: 0.009436, loss_test: 0.005988
time: 0.2670717239379883
time: 2.2465198040008545
[1, 2691] loss_train: 0.015174, loss_test: 0.005962
time: 0.24205398559570312
time: 2.2630114555358887
[1, 2692] loss_train: 0.008009, loss_test: 0.005943
time: 0.24805569648742676
time: 2.2505288124084473
[1, 2693] loss_train: 0.005354, loss_test: 0.005930
time: 0.2470552921295166
time: 2.2254977226257324
[1, 2694] loss_train: 0.004080, loss_test: 0.005927
time: 0.2510561943054199
time: 2.234499216079712
[1, 2695] loss_train: 0.001621, loss_test: 0.005926
time: 0.24405455589294434
time: 2.2435014247894287
[1, 2696] loss_train: 0.012263, loss_test: 0.005922
time: 0.2470543384552002
time: 2.2184970378875732
[1, 2697] loss_train: 0.004984, loss_test: 0.005921
time: 0.24405360221862793
time: 2.2455027103424072
[1, 2698] loss_train: 0.012030, loss_test: 0.005919
time: 0.24505400657653809
time: 2.2455055713653564
[1, 2699] loss_train: 0.001802, loss_test: 0.005918
time: 0.24405384063720703
time: 2.2385008335113525
[1, 2700] loss_train: 0.007449, loss_test: 0.005916
time: 0.25705742835998535
time: 2.2525038719177246
[1, 2701] loss_train: 0.012337, loss_test: 0.005918
time: 0.24305343627929688
time: 2.221496343612671
[1, 2702] loss_train: 0.002147, loss_test: 0.005924
time: 0.24305343627929688
time: 2.2345004081726074
[1, 2703] loss_train: 0.010455, loss_test: 0.005928
time: 0.24305415153503418
time: 2.2395031452178955
[1, 2704] loss_train: 0.017919, loss_test: 0.005931
time: 0.243056058883667
time: 2.268507242202759
[1, 2705] loss_train: 0.005606, loss_test: 0.005933
time: 0.24305486679077148
time: 2.2575058937072754
[1, 2706] loss_train: 0.002712, loss_test: 0.005936
time: 0.24305438995361328
time: 2.215494394302368
[1, 2707] loss_train: 0.005375, loss_test: 0.005939
time: 0.24205493927001953
time: 2.2264981269836426
[1, 2708] loss_train: 0.002711, loss_test: 0.005940
time: 0.24505352973937988
time: 2.226498603820801
[1, 2709] loss_train: 0.009268, loss_test: 0.005935
time: 0.24305319786071777
time: 2.2515039443969727
[1, 2710] loss_train: 0.006816, loss_test: 0.005930
time: 0.2540569305419922
time: 2.233551502227783
[1, 2711] loss_train: 0.002832, loss_test: 0.005928
time: 0.252056360244751
time: 2.2326507568359375
[1, 2712] loss_train: 0.004427, loss_test: 0.005929
time: 0.24805474281311035
time: 2.239501476287842
[1, 2713] loss_train: 0.007732, loss_test: 0.005931
time: 0.24205303192138672
time: 2.268508195877075
[1, 2714] loss_train: 0.003328, loss_test: 0.005936
time: 0.24205446243286133
time: 2.2274999618530273
[1, 2715] loss_train: 0.004539, loss_test: 0.005946
time: 0.24405479431152344
time: 2.2445099353790283
[1, 2716] loss_train: 0.005320, loss_test: 0.005951
time: 0.24307894706726074
time: 2.227510452270508
[1, 2717] loss_train: 0.014197, loss_test: 0.005925
time: 0.24405336380004883
time: 2.2245287895202637
[1, 2718] loss_train: 0.007119, loss_test: 0.005914
time: 0.24305391311645508
time: 2.2044930458068848
[1, 2719] loss_train: 0.004739, loss_test: 0.005914
time: 0.24205327033996582
time: 2.2435319423675537
[1, 2720] loss_train: 0.001767, loss_test: 0.005927
time: 0.2540559768676758
time: 2.227799415588379
[1, 2721] loss_train: 0.010683, loss_test: 0.005938
time: 0.2450542449951172
time: 2.2515029907226562
[1, 2722] loss_train: 0.007514, loss_test: 0.005945
time: 0.24805617332458496
time: 2.2039973735809326
[1, 2723] loss_train: 0.000582, loss_test: 0.005954
time: 0.24706029891967773
time: 2.2375004291534424
[1, 2724] loss_train: 0.006054, loss_test: 0.005949
time: 0.24205398559570312
time: 2.221496105194092
[1, 2725] loss_train: 0.003725, loss_test: 0.005946
time: 0.247053861618042
time: 2.2535040378570557
[1, 2726] loss_train: 0.004315, loss_test: 0.005932
time: 0.24505901336669922
time: 2.228023052215576
[1, 2727] loss_train: 0.008595, loss_test: 0.005921
time: 0.24405455589294434
time: 2.2555136680603027
[1, 2728] loss_train: 0.005297, loss_test: 0.005916
time: 0.2670595645904541
time: 2.3565266132354736
[1, 2729] loss_train: 0.006800, loss_test: 0.005914
time: 0.2760624885559082
time: 2.3165183067321777
[1, 2730] loss_train: 0.007449, loss_test: 0.005920
time: 0.29006409645080566
time: 2.28951096534729
[1, 2731] loss_train: 0.005592, loss_test: 0.005930
time: 0.24406838417053223
time: 2.2625372409820557
[1, 2732] loss_train: 0.016509, loss_test: 0.005934
time: 0.2490553855895996
time: 2.3025155067443848
[1, 2733] loss_train: 0.006949, loss_test: 0.005939
time: 0.25505685806274414
time: 2.3135175704956055
[1, 2734] loss_train: 0.007034, loss_test: 0.005947
time: 0.24305391311645508
time: 2.274904489517212
[1, 2735] loss_train: 0.004758, loss_test: 0.005951
time: 0.24605512619018555
time: 2.2575039863586426
[1, 2736] loss_train: 0.007471, loss_test: 0.005951
time: 0.2470548152923584
time: 2.3005151748657227
[1, 2737] loss_train: 0.006421, loss_test: 0.005948
time: 0.269059419631958
time: 2.2790443897247314
[1, 2738] loss_train: 0.005205, loss_test: 0.005947
time: 0.24905991554260254
time: 2.2709624767303467
[1, 2739] loss_train: 0.006742, loss_test: 0.005946
time: 0.24406719207763672
time: 2.262871742248535
[1, 2740] loss_train: 0.006632, loss_test: 0.005947
time: 0.2600584030151367
time: 2.304825782775879
[1, 2741] loss_train: 0.007031, loss_test: 0.005948
time: 0.2470555305480957
time: 2.319523811340332
[1, 2742] loss_train: 0.009839, loss_test: 0.005951
time: 0.24505352973937988
time: 2.2139980792999268
[1, 2743] loss_train: 0.002174, loss_test: 0.005954
time: 0.2470541000366211
time: 2.2890164852142334
[1, 2744] loss_train: 0.005277, loss_test: 0.005957
time: 0.24306654930114746
time: 2.2370049953460693
[1, 2745] loss_train: 0.006761, loss_test: 0.005956
time: 0.24805474281311035
time: 2.2552688121795654
[1, 2746] loss_train: 0.005007, loss_test: 0.005954
time: 0.24407386779785156
time: 2.263462781906128
[1, 2747] loss_train: 0.003990, loss_test: 0.005948
time: 0.24715518951416016
time: 2.3095638751983643
[1, 2748] loss_train: 0.005872, loss_test: 0.005948
time: 0.25505638122558594
time: 2.2575669288635254
[1, 2749] loss_train: 0.005424, loss_test: 0.005949
time: 0.2500581741333008
time: 2.260361671447754
[1, 2750] loss_train: 0.015495, loss_test: 0.005950
time: 0.26215100288391113
time: 2.231598138809204
[1, 2751] loss_train: 0.005017, loss_test: 0.005952
time: 0.25305604934692383
time: 2.2805097103118896
[1, 2752] loss_train: 0.001774, loss_test: 0.005960
time: 0.24364137649536133
time: 2.2664430141448975
[1, 2753] loss_train: 0.003619, loss_test: 0.005969
time: 0.25097012519836426
time: 2.290320634841919
[1, 2754] loss_train: 0.005538, loss_test: 0.005982
time: 0.24305391311645508
time: 2.2665090560913086
[1, 2755] loss_train: 0.002844, loss_test: 0.005993
time: 0.2510559558868408
time: 2.2815134525299072
[1, 2756] loss_train: 0.008450, loss_test: 0.005999
time: 0.24355602264404297
time: 2.253248453140259
[1, 2757] loss_train: 0.005666, loss_test: 0.006002
time: 0.25005555152893066
time: 2.2699429988861084
[1, 2758] loss_train: 0.003331, loss_test: 0.006009
time: 0.24355721473693848
time: 2.233768939971924
[1, 2759] loss_train: 0.001905, loss_test: 0.006017
time: 0.2509033679962158
time: 2.260021448135376
[1, 2760] loss_train: 0.018725, loss_test: 0.005993
time: 0.2545585632324219
time: 2.259505033493042
[1, 2761] loss_train: 0.008871, loss_test: 0.005966
time: 0.25205540657043457
time: 2.294090986251831
[1, 2762] loss_train: 0.002971, loss_test: 0.005955
time: 0.24205398559570312
time: 2.2785356044769287
[1, 2763] loss_train: 0.006339, loss_test: 0.005952
time: 0.2510559558868408
time: 2.245753765106201
[1, 2764] loss_train: 0.005784, loss_test: 0.005950
time: 0.24540305137634277
time: 2.259512186050415
[1, 2765] loss_train: 0.002956, loss_test: 0.005952
time: 0.2500576972961426
time: 2.2840049266815186
[1, 2766] loss_train: 0.009865, loss_test: 0.005957
time: 0.24405431747436523
time: 2.2355010509490967
[1, 2767] loss_train: 0.012837, loss_test: 0.005960
time: 0.25205492973327637
time: 2.2890336513519287
[1, 2768] loss_train: 0.003071, loss_test: 0.005968
time: 0.24457216262817383
time: 2.261504888534546
[1, 2769] loss_train: 0.004412, loss_test: 0.005979
time: 0.252056360244751
time: 2.2725489139556885
[1, 2770] loss_train: 0.008484, loss_test: 0.005991
time: 0.25556111335754395
time: 2.274040460586548
[1, 2771] loss_train: 0.013569, loss_test: 0.005971
time: 0.25905299186706543
time: 2.2461130619049072
[1, 2772] loss_train: 0.006764, loss_test: 0.005955
time: 0.24353265762329102
time: 2.264791965484619
[1, 2773] loss_train: 0.010336, loss_test: 0.005947
time: 0.25105834007263184
time: 2.2555418014526367
[1, 2774] loss_train: 0.003781, loss_test: 0.005933
time: 0.2450551986694336
time: 2.26051926612854
[1, 2775] loss_train: 0.005093, loss_test: 0.005926
time: 0.2490556240081787
time: 2.2755086421966553
[1, 2776] loss_train: 0.007453, loss_test: 0.005928
time: 0.2430555820465088
time: 2.2595083713531494
[1, 2777] loss_train: 0.011825, loss_test: 0.005936
time: 0.24605417251586914
time: 2.267082929611206
[1, 2778] loss_train: 0.008071, loss_test: 0.005947
time: 0.24308395385742188
time: 2.2300117015838623
[1, 2779] loss_train: 0.007786, loss_test: 0.005957
time: 0.2470545768737793
time: 2.2487235069274902
[1, 2780] loss_train: 0.010300, loss_test: 0.005946
time: 0.25904178619384766
time: 2.244950771331787
[1, 2781] loss_train: 0.007712, loss_test: 0.005938
time: 0.2470567226409912
time: 2.2582778930664062
[1, 2782] loss_train: 0.004030, loss_test: 0.005937
time: 0.24805521965026855
time: 2.289520263671875
[1, 2783] loss_train: 0.002153, loss_test: 0.005940
time: 0.24355792999267578
time: 2.2435014247894287
[1, 2784] loss_train: 0.005359, loss_test: 0.005946
time: 0.2510557174682617
time: 2.2545065879821777
[1, 2785] loss_train: 0.014338, loss_test: 0.005950
time: 0.2420661449432373
time: 2.2395124435424805
[1, 2786] loss_train: 0.011438, loss_test: 0.005955
time: 0.25705742835998535
time: 2.2558562755584717
[1, 2787] loss_train: 0.004319, loss_test: 0.005961
time: 0.24405384063720703
time: 2.2651588916778564
[1, 2788] loss_train: 0.007161, loss_test: 0.005969
time: 0.2470543384552002
time: 2.2425012588500977
[1, 2789] loss_train: 0.007662, loss_test: 0.005974
time: 0.24405431747436523
time: 2.2678256034851074
[1, 2790] loss_train: 0.001401, loss_test: 0.005980
time: 0.26206016540527344
time: 2.2716498374938965
[1, 2791] loss_train: 0.007212, loss_test: 0.005986
time: 0.2440662384033203
time: 2.2485029697418213
[1, 2792] loss_train: 0.005188, loss_test: 0.005995
time: 0.2470557689666748
time: 2.2545061111450195
[1, 2793] loss_train: 0.008813, loss_test: 0.005989
time: 0.24405360221862793
time: 2.2625067234039307
[1, 2794] loss_train: 0.011456, loss_test: 0.005980
time: 0.25229620933532715
time: 2.2775092124938965
[1, 2795] loss_train: 0.005960, loss_test: 0.005959
time: 0.24305367469787598
time: 2.2790279388427734
[1, 2796] loss_train: 0.002314, loss_test: 0.005940
time: 0.24805521965026855
time: 2.2841930389404297
[1, 2797] loss_train: 0.007168, loss_test: 0.005932
time: 0.2450547218322754
time: 2.2606542110443115
[1, 2798] loss_train: 0.006917, loss_test: 0.005930
time: 0.24708080291748047
time: 2.2875399589538574
[1, 2799] loss_train: 0.006228, loss_test: 0.005933
time: 0.24506783485412598
time: 2.2559540271759033
[1, 2800] loss_train: 0.004688, loss_test: 0.005937
time: 0.2572314739227295
time: 2.2661778926849365
[1, 2801] loss_train: 0.007096, loss_test: 0.005941
time: 0.24405431747436523
time: 2.2785234451293945
[1, 2802] loss_train: 0.003181, loss_test: 0.005949
time: 0.2470545768737793
time: 2.245514392852783
[1, 2803] loss_train: 0.007531, loss_test: 0.005958
time: 0.24405384063720703
time: 2.234006881713867
[1, 2804] loss_train: 0.006017, loss_test: 0.005966
time: 0.2435598373413086
time: 2.266381025314331
[1, 2805] loss_train: 0.007319, loss_test: 0.005973
time: 0.26805949211120605
time: 2.299227714538574
[1, 2806] loss_train: 0.011281, loss_test: 0.005970
time: 0.2460331916809082
time: 2.268007755279541
[1, 2807] loss_train: 0.005813, loss_test: 0.005960
time: 0.24556398391723633
time: 2.2475028038024902
[1, 2808] loss_train: 0.004428, loss_test: 0.005950
time: 0.24305343627929688
time: 2.245506763458252
[1, 2809] loss_train: 0.002888, loss_test: 0.005946
time: 0.24255752563476562
time: 2.270508289337158
[1, 2810] loss_train: 0.003964, loss_test: 0.005946
time: 0.2660651206970215
time: 2.2467687129974365
[1, 2811] loss_train: 0.005004, loss_test: 0.005949
time: 0.24205398559570312
time: 2.285017728805542
[1, 2812] loss_train: 0.012218, loss_test: 0.005945
time: 0.2490551471710205
time: 2.244229793548584
[1, 2813] loss_train: 0.003056, loss_test: 0.005944
time: 0.24305462837219238
time: 2.2528533935546875
[1, 2814] loss_train: 0.002261, loss_test: 0.005944
time: 0.24905753135681152
time: 2.294044256210327
[1, 2815] loss_train: 0.004828, loss_test: 0.005950
time: 0.24505400657653809
time: 2.270785093307495
[1, 2816] loss_train: 0.006125, loss_test: 0.005948
time: 0.24805641174316406
time: 2.259052038192749
[1, 2817] loss_train: 0.011207, loss_test: 0.005935
time: 0.24305295944213867
time: 2.2114996910095215
[1, 2818] loss_train: 0.007231, loss_test: 0.005925
time: 0.24807238578796387
time: 2.2469756603240967
[1, 2819] loss_train: 0.008412, loss_test: 0.005918
time: 0.24305272102355957
time: 2.2305169105529785
[1, 2820] loss_train: 0.016529, loss_test: 0.005913
time: 0.26205921173095703
time: 2.2550079822540283
[1, 2821] loss_train: 0.015623, loss_test: 0.005936
time: 0.24205303192138672
time: 2.244502544403076
[1, 2822] loss_train: 0.013857, loss_test: 0.006003
time: 0.24656033515930176
time: 2.2515032291412354
[1, 2823] loss_train: 0.002456, loss_test: 0.006087
time: 0.24505615234375
time: 2.2455015182495117
[1, 2824] loss_train: 0.024368, loss_test: 0.006171
time: 0.24805450439453125
time: 2.218496561050415
[1, 2825] loss_train: 0.007443, loss_test: 0.006198
time: 0.24305391311645508
time: 2.3067376613616943
[1, 2826] loss_train: 0.005781, loss_test: 0.006115
time: 0.25005555152893066
time: 2.2206883430480957
[1, 2827] loss_train: 0.005432, loss_test: 0.006007
time: 0.24405646324157715
time: 2.214495897293091
[1, 2828] loss_train: 0.011088, loss_test: 0.005943
time: 0.2470550537109375
time: 2.2353787422180176
[1, 2829] loss_train: 0.007625, loss_test: 0.005916
time: 0.2450542449951172
time: 2.247584104537964
[1, 2830] loss_train: 0.004421, loss_test: 0.005918
time: 0.2610492706298828
time: 2.221787691116333
[1, 2831] loss_train: 0.009706, loss_test: 0.005937
time: 0.2850639820098877
time: 2.398939371109009
[1, 2832] loss_train: 0.003340, loss_test: 0.005969
time: 0.25981688499450684
time: 2.343524932861328
[1, 2833] loss_train: 0.003605, loss_test: 0.006012
time: 0.291064977645874
time: 2.3275198936462402
[1, 2834] loss_train: 0.004357, loss_test: 0.006045
time: 0.24306654930114746
time: 2.3275201320648193
[1, 2835] loss_train: 0.003088, loss_test: 0.006078
time: 0.24405384063720703
time: 2.267507553100586
[1, 2836] loss_train: 0.002208, loss_test: 0.006104
time: 0.24505400657653809
time: 2.2635068893432617
[1, 2837] loss_train: 0.009942, loss_test: 0.006104
time: 0.242051362991333
time: 2.2655062675476074
[1, 2838] loss_train: 0.000708, loss_test: 0.006105
time: 0.24305510520935059
time: 2.250502824783325
[1, 2839] loss_train: 0.004363, loss_test: 0.006088
time: 0.24405407905578613
time: 2.3352253437042236
[1, 2840] loss_train: 0.003879, loss_test: 0.006052
time: 0.25813984870910645
time: 2.258788824081421
[1, 2841] loss_train: 0.003739, loss_test: 0.006026
time: 0.2800612449645996
time: 2.2805964946746826
[1, 2842] loss_train: 0.008151, loss_test: 0.005999
time: 0.26755404472351074
time: 2.2515838146209717
[1, 2843] loss_train: 0.008898, loss_test: 0.005976
time: 0.24805569648742676
time: 2.2535040378570557
[1, 2844] loss_train: 0.003611, loss_test: 0.005964
time: 0.2490553855895996
time: 2.259505271911621
[1, 2845] loss_train: 0.004051, loss_test: 0.005958
time: 0.24805521965026855
time: 2.2793569564819336
[1, 2846] loss_train: 0.003162, loss_test: 0.005956
time: 0.24758601188659668
time: 2.268507480621338
[1, 2847] loss_train: 0.005679, loss_test: 0.005956
time: 0.24365663528442383
time: 2.2833099365234375
[1, 2848] loss_train: 0.012621, loss_test: 0.005957
time: 0.24805498123168945
time: 2.2459208965301514
[1, 2849] loss_train: 0.007119, loss_test: 0.005956
time: 0.24506902694702148
time: 2.2778234481811523
[1, 2850] loss_train: 0.006557, loss_test: 0.005954
time: 0.2592911720275879
time: 2.281118154525757
[1, 2851] loss_train: 0.001343, loss_test: 0.005952
time: 0.24205374717712402
time: 2.2539141178131104
[1, 2852] loss_train: 0.005972, loss_test: 0.005947
time: 0.24800729751586914
time: 2.268803119659424
[1, 2853] loss_train: 0.004569, loss_test: 0.005945
time: 0.24305367469787598
time: 2.253504753112793
[1, 2854] loss_train: 0.002431, loss_test: 0.005949
time: 0.2470545768737793
time: 2.254504442214966
[1, 2855] loss_train: 0.003377, loss_test: 0.005957
time: 0.24605417251586914
time: 2.2594430446624756
[1, 2856] loss_train: 0.009027, loss_test: 0.005957
time: 0.2470552921295166
time: 2.229498863220215
[1, 2857] loss_train: 0.004966, loss_test: 0.005953
time: 0.24405431747436523
time: 2.2465028762817383
[1, 2858] loss_train: 0.004538, loss_test: 0.005947
time: 0.2510559558868408
time: 2.2807281017303467
[1, 2859] loss_train: 0.002589, loss_test: 0.005947
time: 0.2429344654083252
time: 2.249547004699707
[1, 2860] loss_train: 0.006373, loss_test: 0.005947
time: 0.2615647315979004
time: 2.287541389465332
[1, 2861] loss_train: 0.004283, loss_test: 0.005950
time: 0.24904680252075195
time: 2.2699947357177734
[1, 2862] loss_train: 0.000760, loss_test: 0.005958
time: 0.24898815155029297
time: 2.255608320236206
[1, 2863] loss_train: 0.010178, loss_test: 0.005964
time: 0.24205350875854492
time: 2.2585055828094482
[1, 2864] loss_train: 0.008604, loss_test: 0.005959
time: 0.2490551471710205
time: 2.270508289337158
[1, 2865] loss_train: 0.010449, loss_test: 0.005948
time: 0.24405431747436523
time: 2.263033866882324
[1, 2866] loss_train: 0.010186, loss_test: 0.005937
time: 0.2470545768737793
time: 2.256505012512207
[1, 2867] loss_train: 0.008370, loss_test: 0.005931
time: 0.24405431747436523
time: 2.2375009059906006
[1, 2868] loss_train: 0.010957, loss_test: 0.005929
time: 0.2530553340911865
time: 2.316520929336548
[1, 2869] loss_train: 0.005997, loss_test: 0.005933
time: 0.24406647682189941
time: 2.2407398223876953
[1, 2870] loss_train: 0.010917, loss_test: 0.005942
time: 0.26105833053588867
time: 2.3092644214630127
[1, 2871] loss_train: 0.004619, loss_test: 0.005956
time: 0.24706649780273438
time: 2.285310745239258
[1, 2872] loss_train: 0.003609, loss_test: 0.005961
time: 0.2510559558868408
time: 2.2809438705444336
[1, 2873] loss_train: 0.004726, loss_test: 0.005960
time: 0.2440950870513916
time: 2.221510171890259
[1, 2874] loss_train: 0.021276, loss_test: 0.005956
time: 0.25505685806274414
time: 2.2505033016204834
[1, 2875] loss_train: 0.012072, loss_test: 0.005953
time: 0.2430887222290039
time: 2.2825100421905518
[1, 2876] loss_train: 0.004330, loss_test: 0.005940
time: 0.2520577907562256
time: 2.280510187149048
[1, 2877] loss_train: 0.006184, loss_test: 0.005924
time: 0.24405384063720703
time: 2.2705636024475098
[1, 2878] loss_train: 0.005329, loss_test: 0.005909
time: 0.25505661964416504
time: 2.2595057487487793
[1, 2879] loss_train: 0.003500, loss_test: 0.005899
time: 0.24405384063720703
time: 2.2909181118011475
[1, 2880] loss_train: 0.001554, loss_test: 0.005897
time: 0.2630600929260254
time: 2.2690584659576416
[1, 2881] loss_train: 0.004680, loss_test: 0.005902
time: 0.24205350875854492
time: 2.2625081539154053
[1, 2882] loss_train: 0.005092, loss_test: 0.005915
time: 0.24709010124206543
time: 2.2474334239959717
[1, 2883] loss_train: 0.005299, loss_test: 0.005934
time: 0.24405407905578613
time: 2.293027639389038
[1, 2884] loss_train: 0.007100, loss_test: 0.005937
time: 0.2470552921295166
time: 2.271507740020752
[1, 2885] loss_train: 0.002049, loss_test: 0.005941
time: 0.24405384063720703
time: 2.2140016555786133
[1, 2886] loss_train: 0.010050, loss_test: 0.005950
time: 0.24605584144592285
time: 2.2385010719299316
[1, 2887] loss_train: 0.001723, loss_test: 0.005965
time: 0.24605560302734375
time: 2.252502918243408
[1, 2888] loss_train: 0.007462, loss_test: 0.005967
time: 0.249833345413208
time: 2.288372039794922
[1, 2889] loss_train: 0.009068, loss_test: 0.005961
time: 0.24605464935302734
time: 2.2657015323638916
[1, 2890] loss_train: 0.002205, loss_test: 0.005967
time: 0.26105809211730957
time: 2.2595067024230957
[1, 2891] loss_train: 0.024497, loss_test: 0.005930
time: 0.24505305290222168
time: 2.2741665840148926
[1, 2892] loss_train: 0.005026, loss_test: 0.005931
time: 0.24490118026733398
time: 2.255504846572876
[1, 2893] loss_train: 0.001935, loss_test: 0.005949
time: 0.24605488777160645
time: 2.258514881134033
[1, 2894] loss_train: 0.007682, loss_test: 0.005988
time: 0.2450544834136963
time: 2.2842376232147217
[1, 2895] loss_train: 0.007770, loss_test: 0.006031
time: 0.24405479431152344
time: 2.2663421630859375
[1, 2896] loss_train: 0.017025, loss_test: 0.006093
time: 0.24405336380004883
time: 2.26084303855896
[1, 2897] loss_train: 0.006733, loss_test: 0.006144
time: 0.24960780143737793
time: 2.241278648376465
[1, 2898] loss_train: 0.014356, loss_test: 0.006166
time: 0.24405360221862793
time: 2.257505416870117
[1, 2899] loss_train: 0.001313, loss_test: 0.006172
time: 0.24809026718139648
time: 2.240501642227173
[1, 2900] loss_train: 0.003989, loss_test: 0.006181
time: 0.25705718994140625
time: 2.307516098022461
[1, 2901] loss_train: 0.008903, loss_test: 0.006191
time: 0.24605369567871094
time: 2.257709503173828
[1, 2902] loss_train: 0.001893, loss_test: 0.006204
time: 0.24305367469787598
time: 2.257507801055908
[1, 2903] loss_train: 0.005010, loss_test: 0.006211
time: 0.24605417251586914
time: 2.2919483184814453
[1, 2904] loss_train: 0.011313, loss_test: 0.006222
time: 0.24199247360229492
time: 2.2963309288024902
[1, 2905] loss_train: 0.004980, loss_test: 0.006233
time: 0.24505352973937988
time: 2.2558717727661133
[1, 2906] loss_train: 0.007263, loss_test: 0.006100
time: 0.2450544834136963
time: 2.267507314682007
[1, 2907] loss_train: 0.015103, loss_test: 0.006005
time: 0.2470552921295166
time: 2.2615907192230225
[1, 2908] loss_train: 0.012336, loss_test: 0.005973
time: 0.24405407905578613
time: 2.233004570007324
[1, 2909] loss_train: 0.004474, loss_test: 0.005984
time: 0.24605393409729004
time: 2.2600085735321045
[1, 2910] loss_train: 0.002697, loss_test: 0.006013
time: 0.25505661964416504
time: 2.2860231399536133
[1, 2911] loss_train: 0.007393, loss_test: 0.006043
time: 0.25505924224853516
time: 2.270948648452759
[1, 2912] loss_train: 0.024727, loss_test: 0.005997
time: 0.24305319786071777
time: 2.272508382797241
[1, 2913] loss_train: 0.004741, loss_test: 0.005959
time: 0.2571699619293213
time: 2.27104115486145
[1, 2914] loss_train: 0.002370, loss_test: 0.005933
time: 0.24405479431152344
time: 2.2575061321258545
[1, 2915] loss_train: 0.001909, loss_test: 0.005919
time: 0.25005483627319336
time: 2.252485752105713
[1, 2916] loss_train: 0.004388, loss_test: 0.005909
time: 0.24805498123168945
time: 2.2530553340911865
[1, 2917] loss_train: 0.011641, loss_test: 0.005906
time: 0.2540559768676758
time: 2.264376163482666
[1, 2918] loss_train: 0.014335, loss_test: 0.005918
time: 0.24405455589294434
time: 2.2718112468719482
[1, 2919] loss_train: 0.013168, loss_test: 0.005950
time: 0.253894567489624
time: 2.266069173812866
[1, 2920] loss_train: 0.016002, loss_test: 0.005988
time: 0.25449585914611816
time: 2.2615067958831787
[1, 2921] loss_train: 0.011891, loss_test: 0.006033
time: 0.2490553855895996
time: 2.223503828048706
[1, 2922] loss_train: 0.004716, loss_test: 0.006062
time: 0.24405431747436523
time: 2.2957494258880615
[1, 2923] loss_train: 0.003548, loss_test: 0.006089
time: 0.25005555152893066
time: 2.2495172023773193
[1, 2924] loss_train: 0.003387, loss_test: 0.006097
time: 0.24305462837219238
time: 2.234499216079712
[1, 2925] loss_train: 0.007281, loss_test: 0.006066
time: 0.25205564498901367
time: 2.253110647201538
[1, 2926] loss_train: 0.012441, loss_test: 0.006021
time: 0.24405407905578613
time: 2.260871171951294
[1, 2927] loss_train: 0.006242, loss_test: 0.005979
time: 0.2490551471710205
time: 2.23349928855896
[1, 2928] loss_train: 0.007389, loss_test: 0.005950
time: 0.2450571060180664
time: 2.258999824523926
[1, 2929] loss_train: 0.003555, loss_test: 0.005941
time: 0.24805784225463867
time: 2.257546901702881
[1, 2930] loss_train: 0.004656, loss_test: 0.005942
time: 0.2565608024597168
time: 2.2465109825134277
[1, 2931] loss_train: 0.005818, loss_test: 0.005952
time: 0.2450547218322754
time: 2.2479825019836426
[1, 2932] loss_train: 0.006571, loss_test: 0.005967
time: 0.24305415153503418
time: 2.2395033836364746
[1, 2933] loss_train: 0.006107, loss_test: 0.005995
time: 0.2510557174682617
time: 2.221083164215088
[1, 2934] loss_train: 0.007990, loss_test: 0.006011
time: 0.24305248260498047
time: 2.2058167457580566
[1, 2935] loss_train: 0.007102, loss_test: 0.006016
time: 0.24688267707824707
time: 2.218496322631836
[1, 2936] loss_train: 0.005700, loss_test: 0.006016
time: 0.24305367469787598
time: 2.2435011863708496
[1, 2937] loss_train: 0.003484, loss_test: 0.006011
time: 0.2560560703277588
time: 2.242016553878784
[1, 2938] loss_train: 0.008061, loss_test: 0.006000
time: 0.24405908584594727
time: 2.2662601470947266
[1, 2939] loss_train: 0.008688, loss_test: 0.005979
time: 0.2466273307800293
time: 2.248450756072998
[1, 2940] loss_train: 0.009634, loss_test: 0.005957
time: 0.26004457473754883
time: 2.242035388946533
[1, 2941] loss_train: 0.014257, loss_test: 0.005935
time: 0.2459115982055664
time: 2.210636854171753
[1, 2942] loss_train: 0.001829, loss_test: 0.005926
time: 0.24605464935302734
time: 2.256516218185425
[1, 2943] loss_train: 0.008649, loss_test: 0.005921
time: 0.24405407905578613
time: 2.2315421104431152
[1, 2944] loss_train: 0.006490, loss_test: 0.005935
time: 0.2450547218322754
time: 2.224604845046997
[1, 2945] loss_train: 0.005473, loss_test: 0.005958
time: 0.2440013885498047
time: 2.2082040309906006
[1, 2946] loss_train: 0.001930, loss_test: 0.005974
time: 0.2439112663269043
time: 2.243502140045166
[1, 2947] loss_train: 0.003797, loss_test: 0.005985
time: 0.24405431747436523
time: 2.242501735687256
[1, 2948] loss_train: 0.002640, loss_test: 0.005991
time: 0.24306368827819824
time: 2.232499599456787
[1, 2949] loss_train: 0.006744, loss_test: 0.005988
time: 0.24305367469787598
time: 2.264540433883667
[1, 2950] loss_train: 0.014601, loss_test: 0.005985
time: 0.25506162643432617
time: 2.2385001182556152
[1, 2951] loss_train: 0.009712, loss_test: 0.005970
time: 0.2450547218322754
time: 2.2274978160858154
[1, 2952] loss_train: 0.003850, loss_test: 0.005955
time: 0.24205303192138672
time: 2.2284984588623047
[1, 2953] loss_train: 0.007467, loss_test: 0.005950
time: 0.24405431747436523
time: 2.234499931335449
[1, 2954] loss_train: 0.000894, loss_test: 0.005942
time: 0.2450542449951172
time: 2.2915122509002686
[1, 2955] loss_train: 0.011463, loss_test: 0.005937
time: 0.2450542449951172
time: 2.223512649536133
[1, 2956] loss_train: 0.005887, loss_test: 0.005939
time: 0.24405908584594727
time: 2.220515727996826
[1, 2957] loss_train: 0.008568, loss_test: 0.005934
time: 0.24405336380004883
time: 2.2376489639282227
[1, 2958] loss_train: 0.012781, loss_test: 0.005928
time: 0.2495269775390625
time: 2.229926347732544
[1, 2959] loss_train: 0.004424, loss_test: 0.005926
time: 0.24305391311645508
time: 2.2105085849761963
[1, 2960] loss_train: 0.003772, loss_test: 0.005928
time: 0.2570619583129883
time: 2.2274997234344482
[1, 2961] loss_train: 0.009529, loss_test: 0.005927
time: 0.24305438995361328
time: 2.238510847091675
[1, 2962] loss_train: 0.006018, loss_test: 0.005924
time: 0.24906706809997559
time: 2.2224974632263184
[1, 2963] loss_train: 0.012054, loss_test: 0.005919
time: 0.2450554370880127
time: 2.272510290145874
[1, 2964] loss_train: 0.001177, loss_test: 0.005917
time: 0.25705623626708984
time: 2.23431658744812
[1, 2965] loss_train: 0.007917, loss_test: 0.005915
time: 0.24706721305847168
time: 2.2390670776367188
[1, 2966] loss_train: 0.009274, loss_test: 0.005911
time: 0.2470560073852539
time: 2.2625069618225098
[1, 2967] loss_train: 0.001733, loss_test: 0.005910
time: 0.24409246444702148
time: 2.248502731323242
[1, 2968] loss_train: 0.008052, loss_test: 0.005910
time: 0.2470555305480957
time: 2.218496084213257
[1, 2969] loss_train: 0.010476, loss_test: 0.005911
time: 0.24305415153503418
time: 2.2425014972686768
[1, 2970] loss_train: 0.005335, loss_test: 0.005912
time: 0.2600581645965576
time: 2.2425105571746826
[1, 2971] loss_train: 0.005722, loss_test: 0.005913
time: 0.24305367469787598
time: 2.22800350189209
[1, 2972] loss_train: 0.011139, loss_test: 0.005910
time: 0.2470552921295166
time: 2.227015256881714
[1, 2973] loss_train: 0.005873, loss_test: 0.005909
time: 0.2470543384552002
time: 2.216531991958618
[1, 2974] loss_train: 0.007968, loss_test: 0.005906
time: 0.24205350875854492
time: 2.2124786376953125
[1, 2975] loss_train: 0.007971, loss_test: 0.005904
time: 0.24305391311645508
time: 2.2515037059783936
[1, 2976] loss_train: 0.001279, loss_test: 0.005900
time: 0.24608063697814941
time: 2.3044755458831787
[1, 2977] loss_train: 0.012043, loss_test: 0.005901
time: 0.24305415153503418
time: 2.308212995529175
[1, 2978] loss_train: 0.005590, loss_test: 0.005906
time: 0.2436072826385498
time: 2.230499267578125
[1, 2979] loss_train: 0.008437, loss_test: 0.005911
time: 0.2470552921295166
time: 2.2240002155303955
[1, 2980] loss_train: 0.008855, loss_test: 0.005912
time: 0.2555501461029053
time: 2.2515037059783936
[1, 2981] loss_train: 0.006777, loss_test: 0.005911
time: 0.24305391311645508
time: 2.2635090351104736
[1, 2982] loss_train: 0.011789, loss_test: 0.005910
time: 0.24605393409729004
time: 2.235483169555664
[1, 2983] loss_train: 0.004913, loss_test: 0.005910
time: 0.24305438995361328
time: 2.231886386871338
[1, 2984] loss_train: 0.012804, loss_test: 0.005904
time: 0.24405384063720703
time: 2.206496000289917
[1, 2985] loss_train: 0.004833, loss_test: 0.005903
time: 0.2430591583251953
time: 2.218508720397949
[1, 2986] loss_train: 0.012852, loss_test: 0.005910
time: 0.2470548152923584
time: 2.2284979820251465
[1, 2987] loss_train: 0.005084, loss_test: 0.005925
time: 0.24305462837219238
time: 2.213494062423706
[1, 2988] loss_train: 0.012796, loss_test: 0.005940
time: 0.24305438995361328
time: 2.2535033226013184
[1, 2989] loss_train: 0.009881, loss_test: 0.005954
time: 0.2470552921295166
time: 2.216506004333496
[1, 2990] loss_train: 0.002094, loss_test: 0.005967
time: 0.25905680656433105
time: 2.2374515533447266
[1, 2991] loss_train: 0.016054, loss_test: 0.005983
time: 0.24405384063720703
time: 2.2415003776550293
[1, 2992] loss_train: 0.002531, loss_test: 0.005994
time: 0.2450547218322754
time: 2.2455027103424072
[1, 2993] loss_train: 0.007140, loss_test: 0.005998
time: 0.24605464935302734
time: 2.2094943523406982
[1, 2994] loss_train: 0.005089, loss_test: 0.005998
time: 0.24405431747436523
time: 2.1994917392730713
[1, 2995] loss_train: 0.004188, loss_test: 0.005994
time: 0.24605488777160645
time: 2.211494207382202
[1, 2996] loss_train: 0.006392, loss_test: 0.005988
time: 0.24405455589294434
time: 2.2129037380218506
[1, 2997] loss_train: 0.003434, loss_test: 0.005977
time: 0.2470545768737793
time: 2.212495803833008
[1, 2998] loss_train: 0.004935, loss_test: 0.005976
time: 0.24305367469787598
time: 2.195024013519287
[1, 2999] loss_train: 0.007004, loss_test: 0.005979
time: 0.24305367469787598
time: 2.251512050628662
[1, 3000] loss_train: 0.002617, loss_test: 0.005989
time: 0.2560572624206543
time: 2.26047682762146
[1, 3001] loss_train: 0.007212, loss_test: 0.005989
time: 0.24405384063720703
time: 2.255209445953369
[1, 3002] loss_train: 0.001880, loss_test: 0.005992
time: 0.2450544834136963
time: 2.217980146408081
[1, 3003] loss_train: 0.012300, loss_test: 0.005973
time: 0.24342870712280273
time: 2.236029863357544
[1, 3004] loss_train: 0.013191, loss_test: 0.005946
time: 0.24571609497070312
time: 2.2514448165893555
[1, 3005] loss_train: 0.006088, loss_test: 0.005922
time: 0.24305367469787598
time: 2.234499931335449
[1, 3006] loss_train: 0.001525, loss_test: 0.005915
time: 0.2450542449951172
time: 2.2304985523223877
[1, 3007] loss_train: 0.023190, loss_test: 0.005913
time: 0.24405455589294434
time: 2.2200005054473877
[1, 3008] loss_train: 0.003477, loss_test: 0.005933
time: 0.24605417251586914
time: 2.241004228591919
[1, 3009] loss_train: 0.002496, loss_test: 0.005963
time: 0.24305462837219238
time: 2.232023000717163
[1, 3010] loss_train: 0.007659, loss_test: 0.005985
time: 0.254056453704834
time: 2.184009075164795
[1, 3011] loss_train: 0.001687, loss_test: 0.005996
time: 0.24305367469787598
time: 2.2405006885528564
[1, 3012] loss_train: 0.003279, loss_test: 0.005999
time: 0.24405431747436523
time: 2.2750277519226074
[1, 3013] loss_train: 0.009433, loss_test: 0.005997
time: 0.24405360221862793
time: 2.281510353088379
[1, 3014] loss_train: 0.007840, loss_test: 0.005991
time: 0.24205517768859863
time: 2.2324986457824707
[1, 3015] loss_train: 0.006205, loss_test: 0.005984
time: 0.24406790733337402
time: 2.2525036334991455
[1, 3016] loss_train: 0.007630, loss_test: 0.005974
time: 0.2531871795654297
time: 2.2465453147888184
[1, 3017] loss_train: 0.005264, loss_test: 0.005970
time: 0.2428290843963623
time: 2.2324578762054443
[1, 3018] loss_train: 0.007438, loss_test: 0.005971
time: 0.24625587463378906
time: 2.261507749557495
[1, 3019] loss_train: 0.009235, loss_test: 0.005968
time: 0.24356985092163086
time: 2.227015256881714
[1, 3020] loss_train: 0.005942, loss_test: 0.005976
time: 0.25705671310424805
time: 2.2530078887939453
[1, 3021] loss_train: 0.012967, loss_test: 0.005980
time: 0.24508142471313477
time: 2.236513137817383
[1, 3022] loss_train: 0.008989, loss_test: 0.005981
time: 0.2470545768737793
time: 2.243504047393799
[1, 3023] loss_train: 0.009926, loss_test: 0.005983
time: 0.24305367469787598
time: 2.243502378463745
[1, 3024] loss_train: 0.013955, loss_test: 0.005985
time: 0.24805450439453125
time: 2.2605061531066895
[1, 3025] loss_train: 0.001931, loss_test: 0.005984
time: 0.24605441093444824
time: 2.254505157470703
[1, 3026] loss_train: 0.005789, loss_test: 0.005979
time: 0.25005531311035156
time: 2.257504940032959
[1, 3027] loss_train: 0.003896, loss_test: 0.005976
time: 0.24405360221862793
time: 2.263698101043701
[1, 3028] loss_train: 0.010551, loss_test: 0.005968
time: 0.2540569305419922
time: 2.235499858856201
[1, 3029] loss_train: 0.005780, loss_test: 0.005962
time: 0.24306726455688477
time: 2.2575042247772217
[1, 3030] loss_train: 0.005519, loss_test: 0.005950
time: 0.2600576877593994
time: 2.229499101638794
[1, 3031] loss_train: 0.009352, loss_test: 0.005940
time: 0.24105358123779297
time: 2.219496726989746
[1, 3032] loss_train: 0.011016, loss_test: 0.005919
time: 0.2490549087524414
time: 2.268508195877075
[1, 3033] loss_train: 0.005066, loss_test: 0.005913
time: 0.2420666217803955
time: 2.218496799468994
[1, 3034] loss_train: 0.011863, loss_test: 0.005911
time: 0.2490675449371338
time: 2.2260072231292725
[1, 3035] loss_train: 0.007192, loss_test: 0.005916
time: 0.24205350875854492
time: 2.2555043697357178
[1, 3036] loss_train: 0.008277, loss_test: 0.005932
time: 0.2470545768737793
time: 2.241513967514038
[1, 3037] loss_train: 0.002352, loss_test: 0.005946
time: 0.24205374717712402
time: 2.3145179748535156
[1, 3038] loss_train: 0.002092, loss_test: 0.005954
time: 0.2560567855834961
time: 2.3403468132019043
[1, 3039] loss_train: 0.013346, loss_test: 0.005954
time: 0.2450544834136963
time: 2.2404675483703613
[1, 3040] loss_train: 0.005022, loss_test: 0.005946
time: 0.25566601753234863
time: 2.237499952316284
[1, 3041] loss_train: 0.001175, loss_test: 0.005943
time: 0.24305415153503418
time: 2.2907440662384033
[1, 3042] loss_train: 0.011975, loss_test: 0.005952
time: 0.25505709648132324
time: 2.2535078525543213
[1, 3043] loss_train: 0.002905, loss_test: 0.005960
time: 0.24205327033996582
time: 2.2270455360412598
[1, 3044] loss_train: 0.009178, loss_test: 0.005961
time: 0.24306631088256836
time: 2.253002643585205
[1, 3045] loss_train: 0.007787, loss_test: 0.005954
time: 0.2450542449951172
time: 2.2263474464416504
[1, 3046] loss_train: 0.007891, loss_test: 0.005952
time: 0.2490558624267578
time: 2.2284982204437256
[1, 3047] loss_train: 0.008563, loss_test: 0.005957
time: 0.24906635284423828
time: 2.2505037784576416
[1, 3048] loss_train: 0.019000, loss_test: 0.005947
time: 0.2470550537109375
time: 2.244502067565918
[1, 3049] loss_train: 0.009657, loss_test: 0.005935
time: 0.24205374717712402
time: 2.2605056762695312
[1, 3050] loss_train: 0.005461, loss_test: 0.005931
time: 0.2630579471588135
time: 2.217270612716675
[1, 3051] loss_train: 0.012364, loss_test: 0.005933
time: 0.24105405807495117
time: 2.2314987182617188
[1, 3052] loss_train: 0.002845, loss_test: 0.005950
time: 0.25005578994750977
time: 2.240039348602295
[1, 3053] loss_train: 0.007680, loss_test: 0.005974
time: 0.2420978546142578
time: 2.2255074977874756
[1, 3054] loss_train: 0.015082, loss_test: 0.005977
time: 0.24606704711914062
time: 2.267510414123535
[1, 3055] loss_train: 0.002269, loss_test: 0.005990
time: 0.24205374717712402
time: 2.258504867553711
[1, 3056] loss_train: 0.003562, loss_test: 0.005997
time: 0.2580571174621582
time: 2.2649476528167725
[1, 3057] loss_train: 0.005691, loss_test: 0.005996
time: 0.24305462837219238
time: 2.2735073566436768
[1, 3058] loss_train: 0.007050, loss_test: 0.005998
time: 0.24605488777160645
time: 2.2625465393066406
[1, 3059] loss_train: 0.003790, loss_test: 0.005997
time: 0.24405384063720703
time: 2.2495031356811523
[1, 3060] loss_train: 0.007656, loss_test: 0.005961
time: 0.26656532287597656
time: 2.2485032081604004
[1, 3061] loss_train: 0.008174, loss_test: 0.005936
time: 0.24405407905578613
time: 2.263505697250366
[1, 3062] loss_train: 0.007287, loss_test: 0.005916
time: 0.2540569305419922
time: 2.2545039653778076
[1, 3063] loss_train: 0.007643, loss_test: 0.005901
time: 0.24305367469787598
time: 2.226003885269165
[1, 3064] loss_train: 0.005198, loss_test: 0.005895
time: 0.2520570755004883
time: 2.2465014457702637
[1, 3065] loss_train: 0.003824, loss_test: 0.005892
time: 0.24205303192138672
time: 2.2390048503875732
[1, 3066] loss_train: 0.001979, loss_test: 0.005894
time: 0.2490558624267578
time: 2.2550175189971924
[1, 3067] loss_train: 0.007990, loss_test: 0.005905
time: 0.2450544834136963
time: 2.23449969291687
[1, 3068] loss_train: 0.004057, loss_test: 0.005922
time: 0.24605512619018555
time: 2.1984915733337402
[1, 3069] loss_train: 0.007747, loss_test: 0.005936
time: 0.24805450439453125
time: 2.23101544380188
[1, 3070] loss_train: 0.001895, loss_test: 0.005957
time: 0.2540559768676758
time: 2.2385013103485107
[1, 3071] loss_train: 0.007136, loss_test: 0.005969
time: 0.24305319786071777
time: 2.2760236263275146
[1, 3072] loss_train: 0.003982, loss_test: 0.005978
time: 0.2540585994720459
time: 2.219978094100952
[1, 3073] loss_train: 0.005915, loss_test: 0.005983
time: 0.2450568675994873
time: 2.3082644939422607
[1, 3074] loss_train: 0.010424, loss_test: 0.005966
time: 0.24300360679626465
time: 2.2668936252593994
[1, 3075] loss_train: 0.004009, loss_test: 0.005956
time: 0.24106693267822266
time: 2.2450146675109863
[1, 3076] loss_train: 0.011795, loss_test: 0.005941
time: 0.2470550537109375
time: 2.262021780014038
[1, 3077] loss_train: 0.004918, loss_test: 0.005941
time: 0.24305295944213867
time: 2.2280025482177734
[1, 3078] loss_train: 0.008931, loss_test: 0.005937
time: 0.24305391311645508
time: 2.2395031452178955
[1, 3079] loss_train: 0.006407, loss_test: 0.005946
time: 0.24405384063720703
time: 2.2295355796813965
[1, 3080] loss_train: 0.000594, loss_test: 0.005968
time: 0.254056453704834
time: 2.217496156692505
[1, 3081] loss_train: 0.000912, loss_test: 0.005968
time: 0.24305486679077148
time: 2.262516736984253
[1, 3082] loss_train: 0.010945, loss_test: 0.005974
time: 0.24405384063720703
time: 2.251521110534668
[1, 3083] loss_train: 0.003846, loss_test: 0.005955
time: 0.2450544834136963
time: 2.233502149581909
[1, 3084] loss_train: 0.004562, loss_test: 0.005929
time: 0.24305486679077148
time: 2.221497058868408
[1, 3085] loss_train: 0.008398, loss_test: 0.005910
time: 0.24305343627929688
time: 2.235499858856201
[1, 3086] loss_train: 0.001774, loss_test: 0.005909
time: 0.24205374717712402
time: 2.2855112552642822
[1, 3087] loss_train: 0.013612, loss_test: 0.005918
time: 0.24305319786071777
time: 2.290391445159912
[1, 3088] loss_train: 0.006481, loss_test: 0.005932
time: 0.2621161937713623
time: 2.3340682983398438
[1, 3089] loss_train: 0.008022, loss_test: 0.005946
time: 0.2490558624267578
time: 2.2579193115234375
[1, 3090] loss_train: 0.015628, loss_test: 0.005962
time: 0.2606847286224365
time: 2.270508289337158
[1, 3091] loss_train: 0.006349, loss_test: 0.005979
time: 0.24312281608581543
time: 2.221513032913208
[1, 3092] loss_train: 0.001779, loss_test: 0.005999
time: 0.24505400657653809
time: 2.230013132095337
[1, 3093] loss_train: 0.017312, loss_test: 0.005997
time: 0.24306011199951172
time: 2.255504846572876
[1, 3094] loss_train: 0.002040, loss_test: 0.005998
time: 0.24305343627929688
time: 2.2094943523406982
[1, 3095] loss_train: 0.004915, loss_test: 0.005986
time: 0.24305462837219238
time: 2.2475016117095947
[1, 3096] loss_train: 0.008983, loss_test: 0.005948
time: 0.2450547218322754
time: 2.266507387161255
[1, 3097] loss_train: 0.007585, loss_test: 0.005922
time: 0.24405384063720703
time: 2.2505037784576416
[1, 3098] loss_train: 0.001258, loss_test: 0.005911
time: 0.24305415153503418
time: 2.230501413345337
[1, 3099] loss_train: 0.004575, loss_test: 0.005908
time: 0.2470548152923584
time: 2.257510185241699
[1, 3100] loss_train: 0.003698, loss_test: 0.005908
time: 0.26105737686157227
time: 2.3553922176361084
[1, 3101] loss_train: 0.003480, loss_test: 0.005909
time: 0.2560567855834961
time: 2.2895874977111816
[1, 3102] loss_train: 0.009027, loss_test: 0.005910
time: 0.247053861618042
time: 2.2421045303344727
[1, 3103] loss_train: 0.002118, loss_test: 0.005908
time: 0.24405503273010254
time: 2.240004777908325
[1, 3104] loss_train: 0.005501, loss_test: 0.005907
time: 0.2650589942932129
time: 2.3225209712982178
[1, 3105] loss_train: 0.006024, loss_test: 0.005902
time: 0.2450544834136963
time: 2.268024206161499
[1, 3106] loss_train: 0.004961, loss_test: 0.005901
time: 0.256056547164917
time: 2.2875115871429443
[1, 3107] loss_train: 0.002002, loss_test: 0.005905
time: 0.2520568370819092
time: 2.3195292949676514
[1, 3108] loss_train: 0.005145, loss_test: 0.005915
time: 0.25005555152893066
time: 2.320518732070923
[1, 3109] loss_train: 0.004239, loss_test: 0.005931
time: 0.25705718994140625
time: 2.289189338684082
[1, 3110] loss_train: 0.003942, loss_test: 0.005950
time: 0.2710602283477783
time: 2.3390440940856934
[1, 3111] loss_train: 0.007635, loss_test: 0.005965
time: 0.25305676460266113
time: 2.3080344200134277
[1, 3112] loss_train: 0.006481, loss_test: 0.005977
time: 0.25706052780151367
time: 2.2654318809509277
[1, 3113] loss_train: 0.005141, loss_test: 0.005974
time: 0.25505638122558594
time: 2.271507978439331
[1, 3114] loss_train: 0.010739, loss_test: 0.005956
time: 0.25005459785461426
time: 2.2735087871551514
[1, 3115] loss_train: 0.007360, loss_test: 0.005933
time: 0.2560570240020752
time: 2.2838282585144043
[1, 3116] loss_train: 0.001132, loss_test: 0.005926
time: 0.25005578994750977
time: 2.2638347148895264
[1, 3117] loss_train: 0.005637, loss_test: 0.005928
time: 0.25005578994750977
time: 2.261521339416504
[1, 3118] loss_train: 0.004163, loss_test: 0.005933
time: 0.24902820587158203
time: 2.2865853309631348
[1, 3119] loss_train: 0.005718, loss_test: 0.005938
time: 0.2510552406311035
time: 2.289945125579834
[1, 3120] loss_train: 0.003661, loss_test: 0.005941
time: 0.2630586624145508
time: 2.296513557434082
[1, 3121] loss_train: 0.006166, loss_test: 0.005935
time: 0.2625441551208496
time: 2.3245327472686768
[1, 3122] loss_train: 0.008217, loss_test: 0.005927
time: 0.2560560703277588
time: 2.3060202598571777
[1, 3123] loss_train: 0.006837, loss_test: 0.005920
time: 0.2490553855895996
time: 2.2965404987335205
[1, 3124] loss_train: 0.008711, loss_test: 0.005915
time: 0.2540628910064697
time: 2.2905120849609375
[1, 3125] loss_train: 0.002333, loss_test: 0.005913
time: 0.25505614280700684
time: 2.3229377269744873
[1, 3126] loss_train: 0.011934, loss_test: 0.005908
time: 0.25205492973327637
time: 2.28351092338562
[1, 3127] loss_train: 0.005645, loss_test: 0.005905
time: 0.25008511543273926
time: 2.2544755935668945
[1, 3128] loss_train: 0.003826, loss_test: 0.005904
time: 0.2520568370819092
time: 2.2474100589752197
[1, 3129] loss_train: 0.007658, loss_test: 0.005904
time: 0.2490553855895996
time: 2.2590179443359375
[1, 3130] loss_train: 0.014421, loss_test: 0.005901
time: 0.26605963706970215
time: 2.3305206298828125
[1, 3131] loss_train: 0.001708, loss_test: 0.005906
time: 0.2530558109283447
time: 2.306706428527832
[1, 3132] loss_train: 0.006278, loss_test: 0.005918
time: 0.2510552406311035
time: 2.3179874420166016
[1, 3133] loss_train: 0.009230, loss_test: 0.005932
time: 0.2510561943054199
time: 2.3320436477661133
[1, 3134] loss_train: 0.003386, loss_test: 0.005951
time: 0.25005483627319336
time: 2.284147262573242
[1, 3135] loss_train: 0.006656, loss_test: 0.005966
time: 0.30501627922058105
time: 2.4135611057281494
[1, 3136] loss_train: 0.002306, loss_test: 0.005987
time: 0.26205897331237793
time: 2.258007764816284
[1, 3137] loss_train: 0.007507, loss_test: 0.005998
time: 0.2470550537109375
time: 2.2390050888061523
[1, 3138] loss_train: 0.007959, loss_test: 0.006005
time: 0.24405455589294434
time: 2.2480223178863525
[1, 3139] loss_train: 0.004741, loss_test: 0.006012
time: 0.24304747581481934
time: 2.28452205657959
[1, 3140] loss_train: 0.005917, loss_test: 0.006013
time: 0.2705850601196289
time: 2.317042589187622
[1, 3141] loss_train: 0.002264, loss_test: 0.006006
time: 0.2450575828552246
time: 2.239302635192871
[1, 3142] loss_train: 0.007796, loss_test: 0.006000
time: 0.2520558834075928
time: 2.2549984455108643
[1, 3143] loss_train: 0.011467, loss_test: 0.005991
time: 0.24302196502685547
time: 2.2729151248931885
[1, 3144] loss_train: 0.013663, loss_test: 0.005964
time: 0.2490558624267578
time: 2.2515017986297607
[1, 3145] loss_train: 0.008827, loss_test: 0.005928
time: 0.24305367469787598
time: 2.2335193157196045
[1, 3146] loss_train: 0.010089, loss_test: 0.005905
time: 0.24594640731811523
time: 2.250279188156128
[1, 3147] loss_train: 0.008295, loss_test: 0.005897
time: 0.24605512619018555
time: 2.2480063438415527
[1, 3148] loss_train: 0.002926, loss_test: 0.005909
time: 0.24605393409729004
time: 2.2572832107543945
[1, 3149] loss_train: 0.014574, loss_test: 0.005938
time: 0.2650594711303711
time: 2.351870059967041
[1, 3150] loss_train: 0.010424, loss_test: 0.005979
time: 0.265277624130249
time: 2.275087833404541
[1, 3151] loss_train: 0.008177, loss_test: 0.005996
time: 0.24605774879455566
time: 2.2538902759552
[1, 3152] loss_train: 0.005066, loss_test: 0.005982
time: 0.24782156944274902
time: 2.2278566360473633
[1, 3153] loss_train: 0.003653, loss_test: 0.005960
time: 0.24405479431152344
time: 2.229499101638794
[1, 3154] loss_train: 0.005486, loss_test: 0.005929
time: 0.2490553855895996
time: 2.2685070037841797
[1, 3155] loss_train: 0.007640, loss_test: 0.005902
time: 0.2455606460571289
time: 2.2535033226013184
[1, 3156] loss_train: 0.005203, loss_test: 0.005880
time: 0.254056453704834
time: 2.335531711578369
[1, 3157] loss_train: 0.006616, loss_test: 0.005876
time: 0.26105713844299316
time: 2.302517890930176
[1, 3158] loss_train: 0.004031, loss_test: 0.005889
time: 0.26405882835388184
time: 2.303515672683716
[1, 3159] loss_train: 0.003695, loss_test: 0.005916
time: 0.27005910873413086
time: 2.384533405303955
[1, 3160] loss_train: 0.003352, loss_test: 0.005950
time: 0.27506041526794434
time: 2.3514060974121094
[1, 3161] loss_train: 0.011281, loss_test: 0.005965
time: 0.2510559558868408
time: 2.3821773529052734
[1, 3162] loss_train: 0.013497, loss_test: 0.005975
time: 0.2774965763092041
time: 2.2637939453125
[1, 3163] loss_train: 0.001079, loss_test: 0.005988
time: 0.24706792831420898
time: 2.2810423374176025
[1, 3164] loss_train: 0.006197, loss_test: 0.005994
time: 0.24305343627929688
time: 2.339698553085327
[1, 3165] loss_train: 0.007447, loss_test: 0.005994
time: 0.2670588493347168
time: 2.2725090980529785
[1, 3166] loss_train: 0.007014, loss_test: 0.005974
time: 0.2510554790496826
time: 2.244006395339966
[1, 3167] loss_train: 0.001276, loss_test: 0.005962
time: 0.25305604934692383
time: 2.368743658065796
[1, 3168] loss_train: 0.003409, loss_test: 0.005951
time: 0.2720611095428467
time: 2.3868510723114014
[1, 3169] loss_train: 0.009661, loss_test: 0.005942
time: 0.2470552921295166
time: 2.2815101146698
[1, 3170] loss_train: 0.010697, loss_test: 0.005930
time: 0.2630586624145508
time: 2.4123375415802
[1, 3171] loss_train: 0.007030, loss_test: 0.005920
time: 0.29006314277648926
time: 2.3425376415252686
[1, 3172] loss_train: 0.008602, loss_test: 0.005912
time: 0.2440643310546875
time: 2.243502378463745
[1, 3173] loss_train: 0.011836, loss_test: 0.005906
time: 0.25136613845825195
time: 2.4075381755828857
[1, 3174] loss_train: 0.010519, loss_test: 0.005900
time: 0.2710609436035156
time: 2.301515579223633
[1, 3175] loss_train: 0.004809, loss_test: 0.005899
time: 0.2490551471710205
time: 2.279510021209717
[1, 3176] loss_train: 0.003630, loss_test: 0.005901
time: 0.24405479431152344
time: 2.266998291015625
[1, 3177] loss_train: 0.002102, loss_test: 0.005904
time: 0.26105690002441406
time: 2.2562313079833984
[1, 3178] loss_train: 0.015814, loss_test: 0.005907
time: 0.24105429649353027
time: 2.2682342529296875
[1, 3179] loss_train: 0.003673, loss_test: 0.005912
time: 0.30092644691467285
time: 2.379439353942871
[1, 3180] loss_train: 0.002844, loss_test: 0.005921
time: 0.26805901527404785
time: 2.2908895015716553
[1, 3181] loss_train: 0.003726, loss_test: 0.005933
time: 0.25105714797973633
time: 2.3165977001190186
[1, 3182] loss_train: 0.013052, loss_test: 0.005939
time: 0.2548508644104004
time: 2.3035147190093994
[1, 3183] loss_train: 0.004981, loss_test: 0.005948
time: 0.25005626678466797
time: 2.305516004562378
[1, 3184] loss_train: 0.001939, loss_test: 0.005961
time: 0.2510552406311035
time: 2.288517951965332
[1, 3185] loss_train: 0.002976, loss_test: 0.005977
time: 0.25005388259887695
time: 2.2995152473449707
[1, 3186] loss_train: 0.003665, loss_test: 0.005993
time: 0.25005483627319336
time: 2.292020320892334
[1, 3187] loss_train: 0.004163, loss_test: 0.006002
time: 0.2530558109283447
time: 2.298584461212158
[1, 3188] loss_train: 0.002832, loss_test: 0.006007
time: 0.2510552406311035
time: 2.297987461090088
[1, 3189] loss_train: 0.010383, loss_test: 0.006001
time: 0.2510554790496826
time: 2.3045151233673096
[1, 3190] loss_train: 0.012906, loss_test: 0.005987
time: 0.26805949211120605
time: 2.3274002075195312
[1, 3191] loss_train: 0.013066, loss_test: 0.005940
time: 0.25905728340148926
time: 2.330869674682617
[1, 3192] loss_train: 0.007790, loss_test: 0.005917
time: 0.25005531311035156
time: 2.31951904296875
[1, 3193] loss_train: 0.004275, loss_test: 0.005918
time: 0.2530558109283447
time: 2.3091955184936523
[1, 3194] loss_train: 0.004378, loss_test: 0.005937
time: 0.25305628776550293
time: 2.3043222427368164
[1, 3195] loss_train: 0.005312, loss_test: 0.005961
time: 0.25205540657043457
time: 2.304011583328247
[1, 3196] loss_train: 0.014186, loss_test: 0.005988
time: 0.2580573558807373
time: 2.32295298576355
[1, 3197] loss_train: 0.002949, loss_test: 0.005986
time: 0.25205540657043457
time: 2.296708345413208
[1, 3198] loss_train: 0.008076, loss_test: 0.005960
time: 0.25756263732910156
time: 2.2871880531311035
[1, 3199] loss_train: 0.007934, loss_test: 0.005927
time: 0.2600579261779785
time: 2.283419132232666
[1, 3200] loss_train: 0.005814, loss_test: 0.005904
time: 0.27454662322998047
time: 2.284510612487793
[1, 3201] loss_train: 0.012045, loss_test: 0.005889
time: 0.2510552406311035
time: 2.2897984981536865
[1, 3202] loss_train: 0.004176, loss_test: 0.005884
time: 0.25705647468566895
time: 2.315164804458618
[1, 3203] loss_train: 0.004239, loss_test: 0.005892
time: 0.2510557174682617
time: 2.3018980026245117
[1, 3204] loss_train: 0.012449, loss_test: 0.005902
time: 0.25005555152893066
time: 2.331186532974243
[1, 3205] loss_train: 0.013021, loss_test: 0.005913
time: 0.2550172805786133
time: 2.33850359916687
[1, 3206] loss_train: 0.006603, loss_test: 0.005926
time: 0.2580564022064209
time: 2.3144989013671875
[1, 3207] loss_train: 0.006664, loss_test: 0.005938
time: 0.2630579471588135
time: 2.2755095958709717
[1, 3208] loss_train: 0.009639, loss_test: 0.005943
time: 0.2510550022125244
time: 2.321025848388672
[1, 3209] loss_train: 0.009659, loss_test: 0.005950
time: 0.2490551471710205
time: 2.3360276222229004
[1, 3210] loss_train: 0.006206, loss_test: 0.005954
time: 0.2650582790374756
time: 2.308821439743042
[1, 3211] loss_train: 0.005476, loss_test: 0.005956
time: 0.25005459785461426
time: 2.3004720211029053
[1, 3212] loss_train: 0.002274, loss_test: 0.005962
time: 0.25005602836608887
time: 2.292694330215454
[1, 3213] loss_train: 0.006383, loss_test: 0.005959
time: 0.24901151657104492
time: 2.316981792449951
[1, 3214] loss_train: 0.008446, loss_test: 0.005954
time: 0.2550356388092041
time: 2.332641363143921
[1, 3215] loss_train: 0.012018, loss_test: 0.005938
time: 0.252056360244751
time: 2.285511016845703
[1, 3216] loss_train: 0.006409, loss_test: 0.005918
time: 0.25205540657043457
time: 2.296518564224243
[1, 3217] loss_train: 0.009989, loss_test: 0.005905
time: 0.24905657768249512
time: 2.284512519836426
[1, 3218] loss_train: 0.002514, loss_test: 0.005900
time: 0.2580568790435791
time: 2.3035225868225098
[1, 3219] loss_train: 0.003159, loss_test: 0.005908
time: 0.25005483627319336
time: 2.298513889312744
[1, 3220] loss_train: 0.005253, loss_test: 0.005925
time: 0.27006077766418457
time: 2.3060617446899414
[1, 3221] loss_train: 0.009894, loss_test: 0.005941
time: 0.2570154666900635
time: 2.3081283569335938
[1, 3222] loss_train: 0.006397, loss_test: 0.005957
time: 0.26605892181396484
time: 2.3544371128082275
[1, 3223] loss_train: 0.005035, loss_test: 0.005956
time: 0.25699758529663086
time: 2.3426599502563477
[1, 3224] loss_train: 0.004957, loss_test: 0.005928
time: 0.25803065299987793
time: 2.316012382507324
[1, 3225] loss_train: 0.009778, loss_test: 0.005905
time: 0.2529439926147461
time: 2.3150134086608887
[1, 3226] loss_train: 0.011873, loss_test: 0.005894
time: 0.2500112056732178
time: 2.308671236038208
[1, 3227] loss_train: 0.012437, loss_test: 0.005897
time: 0.25905847549438477
time: 2.315704345703125
[1, 3228] loss_train: 0.005677, loss_test: 0.005914
time: 0.25204920768737793
time: 2.320530414581299
[1, 3229] loss_train: 0.006345, loss_test: 0.005936
time: 0.2520558834075928
time: 2.2993862628936768
[1, 3230] loss_train: 0.007071, loss_test: 0.005960
time: 0.27304601669311523
time: 2.2932088375091553
[1, 3231] loss_train: 0.001774, loss_test: 0.005985
time: 0.25205516815185547
time: 2.2800674438476562
[1, 3232] loss_train: 0.009756, loss_test: 0.005992
time: 0.2520561218261719
time: 2.295029401779175
[1, 3233] loss_train: 0.007754, loss_test: 0.005980
time: 0.2540245056152344
time: 2.3050191402435303
[1, 3234] loss_train: 0.005216, loss_test: 0.005967
time: 0.2490551471710205
time: 2.2905218601226807
[1, 3235] loss_train: 0.004638, loss_test: 0.005957
time: 0.25705623626708984
time: 2.3365249633789062
[1, 3236] loss_train: 0.008716, loss_test: 0.005950
time: 0.25305652618408203
time: 2.369555711746216
[1, 3237] loss_train: 0.004024, loss_test: 0.005951
time: 0.2675633430480957
time: 2.327638864517212
[1, 3238] loss_train: 0.007156, loss_test: 0.005956
time: 0.2510550022125244
time: 2.292442798614502
[1, 3239] loss_train: 0.011003, loss_test: 0.005973
time: 0.2530558109283447
time: 2.3190221786499023
[1, 3240] loss_train: 0.002399, loss_test: 0.005988
time: 0.265059232711792
time: 2.31851863861084
[1, 3241] loss_train: 0.008342, loss_test: 0.006006
time: 0.25005483627319336
time: 2.3075168132781982
[1, 3242] loss_train: 0.011617, loss_test: 0.006002
time: 0.25005483627319336
time: 2.2925148010253906
[1, 3243] loss_train: 0.006848, loss_test: 0.005968
time: 0.25005483627319336
time: 2.3017141819000244
[1, 3244] loss_train: 0.007797, loss_test: 0.005934
time: 0.2540566921234131
time: 2.3115432262420654
[1, 3245] loss_train: 0.005541, loss_test: 0.005909
time: 0.2510554790496826
time: 2.304964065551758
[1, 3246] loss_train: 0.010780, loss_test: 0.005899
time: 0.26105761528015137
time: 2.2961738109588623
[1, 3247] loss_train: 0.000997, loss_test: 0.005897
time: 0.251035213470459
time: 2.2959694862365723
[1, 3248] loss_train: 0.003266, loss_test: 0.005908
time: 0.25005054473876953
time: 2.2956390380859375
[1, 3249] loss_train: 0.007365, loss_test: 0.005929
time: 0.25305628776550293
time: 2.3288967609405518
[1, 3250] loss_train: 0.011830, loss_test: 0.005950
time: 0.2760615348815918
time: 2.308518409729004
[1, 3251] loss_train: 0.001966, loss_test: 0.005967
time: 0.2547781467437744
time: 2.3185205459594727
[1, 3252] loss_train: 0.004882, loss_test: 0.005980
time: 0.25905799865722656
time: 2.3370256423950195
[1, 3253] loss_train: 0.010555, loss_test: 0.005991
time: 0.2540562152862549
time: 2.303889036178589
[1, 3254] loss_train: 0.009572, loss_test: 0.005971
time: 0.2520561218261719
time: 2.3069682121276855
[1, 3255] loss_train: 0.001168, loss_test: 0.005949
time: 0.25705647468566895
time: 2.303515672683716
[1, 3256] loss_train: 0.006272, loss_test: 0.005915
time: 0.25005483627319336
time: 2.288323402404785
[1, 3257] loss_train: 0.012053, loss_test: 0.005891
time: 0.250258207321167
time: 2.308481454849243
[1, 3258] loss_train: 0.009381, loss_test: 0.005894
time: 0.25505638122558594
time: 2.326521158218384
[1, 3259] loss_train: 0.007053, loss_test: 0.005916
time: 0.252056360244751
time: 2.2905120849609375
[1, 3260] loss_train: 0.003852, loss_test: 0.005948
time: 0.2650589942932129
time: 2.3155181407928467
[1, 3261] loss_train: 0.011657, loss_test: 0.005984
time: 0.2560570240020752
time: 2.333521604537964
[1, 3262] loss_train: 0.003336, loss_test: 0.005998
time: 0.2530558109283447
time: 2.301628589630127
[1, 3263] loss_train: 0.006138, loss_test: 0.005980
time: 0.2520565986633301
time: 2.311131000518799
[1, 3264] loss_train: 0.012103, loss_test: 0.005961
time: 0.258056640625
time: 2.299283266067505
[1, 3265] loss_train: 0.008699, loss_test: 0.005939
time: 0.25005602836608887
time: 2.316277503967285
[1, 3266] loss_train: 0.001740, loss_test: 0.005921
time: 0.2510566711425781
time: 2.309720993041992
[1, 3267] loss_train: 0.005860, loss_test: 0.005908
time: 0.26287150382995605
time: 2.2861366271972656
[1, 3268] loss_train: 0.016527, loss_test: 0.005906
time: 0.2510256767272949
time: 2.2819650173187256
[1, 3269] loss_train: 0.006912, loss_test: 0.005904
time: 0.25704383850097656
time: 2.2999038696289062
[1, 3270] loss_train: 0.011632, loss_test: 0.005904
time: 0.2630584239959717
time: 2.3394551277160645
[1, 3271] loss_train: 0.003037, loss_test: 0.005906
time: 0.2490551471710205
time: 2.2867202758789062
[1, 3272] loss_train: 0.007733, loss_test: 0.005904
time: 0.25205540657043457
time: 2.317039728164673
[1, 3273] loss_train: 0.004631, loss_test: 0.005904
time: 0.25005626678466797
time: 2.353314161300659
[1, 3274] loss_train: 0.005968, loss_test: 0.005902
time: 0.25305676460266113
time: 2.3209705352783203
[1, 3275] loss_train: 0.002631, loss_test: 0.005901
time: 0.25205540657043457
time: 2.3185181617736816
[1, 3276] loss_train: 0.005524, loss_test: 0.005899
time: 0.25569677352905273
time: 2.292213201522827
[1, 3277] loss_train: 0.012778, loss_test: 0.005895
time: 0.25005459785461426
time: 2.2995150089263916
[1, 3278] loss_train: 0.010154, loss_test: 0.005891
time: 0.25005483627319336
time: 2.31601619720459
[1, 3279] loss_train: 0.003826, loss_test: 0.005888
time: 0.25905919075012207
time: 2.310516595840454
[1, 3280] loss_train: 0.004819, loss_test: 0.005886
time: 0.2650589942932129
time: 2.320091485977173
[1, 3281] loss_train: 0.005836, loss_test: 0.005886
time: 0.250934362411499
time: 2.3427393436431885
[1, 3282] loss_train: 0.007207, loss_test: 0.005885
time: 0.2610623836517334
time: 2.321382999420166
[1, 3283] loss_train: 0.007096, loss_test: 0.005886
time: 0.2580568790435791
time: 2.2825112342834473
[1, 3284] loss_train: 0.012882, loss_test: 0.005885
time: 0.2510557174682617
time: 2.33223557472229
[1, 3285] loss_train: 0.000754, loss_test: 0.005885
time: 0.2540566921234131
time: 2.297525405883789
[1, 3286] loss_train: 0.002569, loss_test: 0.005886
time: 0.25069332122802734
time: 2.303513765335083
[1, 3287] loss_train: 0.003664, loss_test: 0.005887
time: 0.25705742835998535
time: 2.301248073577881
[1, 3288] loss_train: 0.002032, loss_test: 0.005890
time: 0.2588984966278076
time: 2.321259021759033
[1, 3289] loss_train: 0.000963, loss_test: 0.005897
time: 0.25005507469177246
time: 2.3020529747009277
[1, 3290] loss_train: 0.002968, loss_test: 0.005907
time: 0.2670142650604248
time: 2.3237249851226807
[1, 3291] loss_train: 0.012172, loss_test: 0.005920
time: 0.2540562152862549
time: 2.304781198501587
[1, 3292] loss_train: 0.011098, loss_test: 0.005931
time: 0.2530555725097656
time: 2.2890164852142334
[1, 3293] loss_train: 0.001910, loss_test: 0.005939
time: 0.25505685806274414
time: 2.2935149669647217
[1, 3294] loss_train: 0.005522, loss_test: 0.005949
time: 0.25305604934692383
time: 2.315819501876831
[1, 3295] loss_train: 0.009649, loss_test: 0.005952
time: 0.25305652618408203
time: 2.317349672317505
[1, 3296] loss_train: 0.005741, loss_test: 0.005954
time: 0.2520558834075928
time: 2.330183982849121
[1, 3297] loss_train: 0.011176, loss_test: 0.005950
time: 0.2560577392578125
time: 2.2955384254455566
[1, 3298] loss_train: 0.021943, loss_test: 0.005940
time: 0.25305795669555664
time: 2.316495418548584
[1, 3299] loss_train: 0.006056, loss_test: 0.005925
time: 0.25710320472717285
time: 2.320369243621826
[1, 3300] loss_train: 0.006085, loss_test: 0.005914
time: 0.2670590877532959
time: 2.3135178089141846
[1, 3301] loss_train: 0.003774, loss_test: 0.005906
time: 0.256056547164917
time: 2.346524477005005
[1, 3302] loss_train: 0.003951, loss_test: 0.005901
time: 0.25905728340148926
time: 2.3735432624816895
[1, 3303] loss_train: 0.005692, loss_test: 0.005893
time: 0.2710602283477783
time: 2.382534980773926
[1, 3304] loss_train: 0.011601, loss_test: 0.005894
time: 0.2670602798461914
time: 2.3555264472961426
[1, 3305] loss_train: 0.008776, loss_test: 0.005897
time: 0.2710697650909424
time: 2.3140578269958496
[1, 3306] loss_train: 0.008193, loss_test: 0.005913
time: 0.24405455589294434
time: 2.30352783203125
[1, 3307] loss_train: 0.005381, loss_test: 0.005937
time: 0.24505352973937988
time: 2.272412061691284
[1, 3308] loss_train: 0.007753, loss_test: 0.005964
time: 0.24605464935302734
time: 2.2530088424682617
[1, 3309] loss_train: 0.008128, loss_test: 0.005969
time: 0.2450551986694336
time: 2.2535061836242676
[1, 3310] loss_train: 0.001893, loss_test: 0.005954
time: 0.25505638122558594
time: 2.3015151023864746
[1, 3311] loss_train: 0.006735, loss_test: 0.005934
time: 0.2735927104949951
time: 2.232499122619629
[1, 3312] loss_train: 0.008751, loss_test: 0.005911
time: 0.24750232696533203
time: 2.282088279724121
[1, 3313] loss_train: 0.002571, loss_test: 0.005891
time: 0.25005507469177246
time: 2.252004384994507
[1, 3314] loss_train: 0.005710, loss_test: 0.005885
time: 0.24605441093444824
time: 2.242501735687256
[1, 3315] loss_train: 0.005313, loss_test: 0.005889
time: 0.2490551471710205
time: 2.241563558578491
[1, 3316] loss_train: 0.007265, loss_test: 0.005900
time: 0.2450544834136963
time: 2.2415010929107666
[1, 3317] loss_train: 0.011656, loss_test: 0.005906
time: 0.2470536231994629
time: 2.2727653980255127
[1, 3318] loss_train: 0.010297, loss_test: 0.005911
time: 0.2470548152923584
time: 2.2362515926361084
[1, 3319] loss_train: 0.009206, loss_test: 0.005913
time: 0.2490551471710205
time: 2.3035144805908203
[1, 3320] loss_train: 0.002430, loss_test: 0.005918
time: 0.25505685806274414
time: 2.222947359085083
[1, 3321] loss_train: 0.004497, loss_test: 0.005923
time: 0.24602103233337402
time: 2.2329931259155273
[1, 3322] loss_train: 0.008517, loss_test: 0.005923
time: 0.2530045509338379
time: 2.241739511489868
[1, 3323] loss_train: 0.016627, loss_test: 0.005906
time: 0.2470543384552002
time: 2.256507635116577
[1, 3324] loss_train: 0.008410, loss_test: 0.005896
time: 0.2490551471710205
time: 2.2596616744995117
[1, 3325] loss_train: 0.009237, loss_test: 0.005898
time: 0.24706745147705078
time: 2.231499433517456
[1, 3326] loss_train: 0.012420, loss_test: 0.005910
time: 0.2450547218322754
time: 2.2360024452209473
[1, 3327] loss_train: 0.006861, loss_test: 0.005931
time: 0.2470552921295166
time: 2.22400164604187
[1, 3328] loss_train: 0.003803, loss_test: 0.005944
time: 0.2450549602508545
time: 2.3021557331085205
[1, 3329] loss_train: 0.005052, loss_test: 0.005941
time: 0.2490556240081787
time: 2.234431743621826
[1, 3330] loss_train: 0.005561, loss_test: 0.005941
time: 0.2620582580566406
time: 2.271507740020752
[1, 3331] loss_train: 0.003320, loss_test: 0.005928
time: 0.2490556240081787
time: 2.340543031692505
[1, 3332] loss_train: 0.005666, loss_test: 0.005905
time: 0.26805973052978516
time: 2.3440299034118652
[1, 3333] loss_train: 0.005513, loss_test: 0.005891
time: 0.27706122398376465
time: 2.2905123233795166
[1, 3334] loss_train: 0.008382, loss_test: 0.005894
time: 0.2510561943054199
time: 2.2925124168395996
[1, 3335] loss_train: 0.008581, loss_test: 0.005913
time: 0.2580575942993164
time: 2.284510612487793
[1, 3336] loss_train: 0.007793, loss_test: 0.005943
time: 0.2580573558807373
time: 2.4165406227111816
[1, 3337] loss_train: 0.006769, loss_test: 0.005977
time: 0.2580568790435791
time: 2.3245205879211426
[1, 3338] loss_train: 0.005804, loss_test: 0.006002
time: 0.2740602493286133
time: 2.2559592723846436
[1, 3339] loss_train: 0.006191, loss_test: 0.006010
time: 0.24795293807983398
time: 2.251857042312622
[1, 3340] loss_train: 0.007117, loss_test: 0.006011
time: 0.25705695152282715
time: 2.245501756668091
[1, 3341] loss_train: 0.011472, loss_test: 0.006004
time: 0.24805521965026855
time: 2.250429630279541
[1, 3342] loss_train: 0.008260, loss_test: 0.005988
time: 0.24405407905578613
time: 2.2930245399475098
[1, 3343] loss_train: 0.003686, loss_test: 0.005975
time: 0.24605512619018555
time: 2.2350172996520996
[1, 3344] loss_train: 0.011443, loss_test: 0.005960
time: 0.2450549602508545
time: 2.2945148944854736
[1, 3345] loss_train: 0.006119, loss_test: 0.005950
time: 0.2450544834136963
time: 2.271013021469116
[1, 3346] loss_train: 0.002758, loss_test: 0.005942
time: 0.24605441093444824
time: 2.3960204124450684
[1, 3347] loss_train: 0.003394, loss_test: 0.005936
time: 0.2560610771179199
time: 2.38132381439209
[1, 3348] loss_train: 0.002597, loss_test: 0.005925
time: 0.24505400657653809
time: 2.238731861114502
[1, 3349] loss_train: 0.010696, loss_test: 0.005914
time: 0.2530555725097656
time: 2.2953884601593018
[1, 3350] loss_train: 0.001752, loss_test: 0.005910
time: 0.25905632972717285
time: 2.298905372619629
[1, 3351] loss_train: 0.003747, loss_test: 0.005907
time: 0.2498633861541748
time: 2.296299457550049
[1, 3352] loss_train: 0.009908, loss_test: 0.005907
time: 0.24805474281311035
time: 2.3085319995880127
[1, 3353] loss_train: 0.008992, loss_test: 0.005904
time: 0.2530558109283447
time: 2.3265345096588135
[1, 3354] loss_train: 0.003419, loss_test: 0.005901
time: 0.24502944946289062
time: 2.281644105911255
[1, 3355] loss_train: 0.006830, loss_test: 0.005901
time: 0.24410057067871094
time: 2.266892671585083
[1, 3356] loss_train: 0.003257, loss_test: 0.005902
time: 0.24882173538208008
time: 2.2724575996398926
[1, 3357] loss_train: 0.009256, loss_test: 0.005906
time: 0.24405455589294434
time: 2.3125171661376953
[1, 3358] loss_train: 0.007961, loss_test: 0.005907
time: 0.24205398559570312
time: 2.2704761028289795
[1, 3359] loss_train: 0.003623, loss_test: 0.005909
time: 0.24305391311645508
time: 2.2823972702026367
[1, 3360] loss_train: 0.003252, loss_test: 0.005904
time: 0.2585618495941162
time: 2.241501569747925
[1, 3361] loss_train: 0.001872, loss_test: 0.005904
time: 0.24405360221862793
time: 2.273020029067993
[1, 3362] loss_train: 0.002358, loss_test: 0.005904
time: 0.24501371383666992
time: 2.2643861770629883
[1, 3363] loss_train: 0.005620, loss_test: 0.005905
time: 0.2470550537109375
time: 2.2850232124328613
[1, 3364] loss_train: 0.011598, loss_test: 0.005900
time: 0.25005531311035156
time: 2.3210387229919434
[1, 3365] loss_train: 0.019286, loss_test: 0.005894
time: 0.25505805015563965
time: 2.3272805213928223
[1, 3366] loss_train: 0.002872, loss_test: 0.005895
time: 0.2540566921234131
time: 2.388418674468994
[1, 3367] loss_train: 0.002732, loss_test: 0.005895
time: 0.2740612030029297
time: 2.3745312690734863
[1, 3368] loss_train: 0.007827, loss_test: 0.005897
time: 0.2760622501373291
time: 2.35052490234375
[1, 3369] loss_train: 0.002736, loss_test: 0.005898
time: 0.2560563087463379
time: 2.352526903152466
[1, 3370] loss_train: 0.004893, loss_test: 0.005897
time: 0.2760617733001709
time: 2.288511276245117
[1, 3371] loss_train: 0.012773, loss_test: 0.005894
time: 0.27006030082702637
time: 2.392547130584717
[1, 3372] loss_train: 0.003577, loss_test: 0.005887
time: 0.2530558109283447
time: 2.362032651901245
[1, 3373] loss_train: 0.012128, loss_test: 0.005882
time: 0.24305343627929688
time: 2.3475277423858643
[1, 3374] loss_train: 0.013927, loss_test: 0.005881
time: 0.24405360221862793
time: 2.3265373706817627
[1, 3375] loss_train: 0.007027, loss_test: 0.005887
time: 0.26805925369262695
time: 2.2645070552825928
[1, 3376] loss_train: 0.004233, loss_test: 0.005902
time: 0.24405407905578613
time: 2.2625060081481934
[1, 3377] loss_train: 0.003577, loss_test: 0.005922
time: 0.2480604648590088
time: 2.2995147705078125
[1, 3378] loss_train: 0.008268, loss_test: 0.005945
time: 0.2540559768676758
time: 2.3175182342529297
[1, 3379] loss_train: 0.005501, loss_test: 0.005967
time: 0.28406381607055664
time: 2.3715293407440186
[1, 3380] loss_train: 0.006864, loss_test: 0.005975
time: 0.269061803817749
time: 2.2385010719299316
[1, 3381] loss_train: 0.004693, loss_test: 0.005980
time: 0.25305652618408203
time: 2.335524320602417
[1, 3382] loss_train: 0.009971, loss_test: 0.005954
time: 0.25505685806274414
time: 2.2825093269348145
[1, 3383] loss_train: 0.003807, loss_test: 0.005935
time: 0.28406357765197754
time: 2.399536609649658
[1, 3384] loss_train: 0.003301, loss_test: 0.005921
time: 0.29410886764526367
time: 2.5049796104431152
[1, 3385] loss_train: 0.008656, loss_test: 0.005909
time: 0.26805615425109863
time: 2.382476568222046
[1, 3386] loss_train: 0.006407, loss_test: 0.005900
time: 0.2780625820159912
time: 2.4720561504364014
[1, 3387] loss_train: 0.001860, loss_test: 0.005898
time: 0.261061429977417
time: 2.7633376121520996
[1, 3388] loss_train: 0.007102, loss_test: 0.005901
time: 0.2706315517425537
time: 2.4605422019958496
[1, 3389] loss_train: 0.004511, loss_test: 0.005905
time: 0.24906206130981445
time: 2.6495964527130127
[1, 3390] loss_train: 0.006701, loss_test: 0.005909
time: 0.30206751823425293
time: 2.5686726570129395
[1, 3391] loss_train: 0.004444, loss_test: 0.005912
time: 0.3090684413909912
time: 2.4397740364074707
[1, 3392] loss_train: 0.010158, loss_test: 0.005911
time: 0.2560575008392334
time: 2.3678576946258545
[1, 3393] loss_train: 0.002626, loss_test: 0.005908
time: 0.2760612964630127
time: 2.4855544567108154
[1, 3394] loss_train: 0.006179, loss_test: 0.005906
time: 0.254056453704834
time: 2.2960283756256104
[1, 3395] loss_train: 0.008349, loss_test: 0.005904
time: 0.2580575942993164
time: 2.5043773651123047
[1, 3396] loss_train: 0.006376, loss_test: 0.005902
time: 0.25582098960876465
time: 2.4425454139709473
[1, 3397] loss_train: 0.009154, loss_test: 0.005900
time: 0.25505614280700684
time: 2.5502278804779053
[1, 3398] loss_train: 0.006020, loss_test: 0.005896
time: 0.2650585174560547
time: 2.481243371963501
[1, 3399] loss_train: 0.009043, loss_test: 0.005894
time: 0.25905752182006836
time: 2.591313600540161
[1, 3400] loss_train: 0.001495, loss_test: 0.005892
time: 0.2670578956604004
time: 2.5150222778320312
[1, 3401] loss_train: 0.008406, loss_test: 0.005891
time: 0.25588321685791016
time: 2.5136024951934814
[1, 3402] loss_train: 0.005828, loss_test: 0.005892
time: 0.2710604667663574
time: 2.407541036605835
[1, 3403] loss_train: 0.006662, loss_test: 0.005901
time: 0.2620584964752197
time: 2.6095850467681885
[1, 3404] loss_train: 0.005721, loss_test: 0.005916
time: 0.26105833053588867
time: 2.522594451904297
[1, 3405] loss_train: 0.002809, loss_test: 0.005936
time: 0.2580573558807373
time: 2.375328302383423
[1, 3406] loss_train: 0.012583, loss_test: 0.005933
time: 0.2727980613708496
time: 2.576282501220703
[1, 3407] loss_train: 0.006225, loss_test: 0.005922
time: 0.2560563087463379
time: 2.40653920173645
[1, 3408] loss_train: 0.006449, loss_test: 0.005915
time: 0.2520558834075928
time: 2.510246515274048
[1, 3409] loss_train: 0.008450, loss_test: 0.005909
time: 0.28606319427490234
time: 2.437540292739868
[1, 3410] loss_train: 0.004537, loss_test: 0.005908
time: 0.26851344108581543
time: 2.7003822326660156
[1, 3411] loss_train: 0.005290, loss_test: 0.005907
time: 0.28806447982788086
time: 2.597580671310425
[1, 3412] loss_train: 0.007442, loss_test: 0.005906
time: 0.2550618648529053
time: 2.4069037437438965
[1, 3413] loss_train: 0.001702, loss_test: 0.005907
time: 0.2546875476837158
time: 2.3719229698181152
[1, 3414] loss_train: 0.000971, loss_test: 0.005909
time: 0.2577071189880371
time: 2.4674072265625
[1, 3415] loss_train: 0.004453, loss_test: 0.005916
time: 0.8352103233337402
time: 2.569578170776367
[1, 3416] loss_train: 0.013903, loss_test: 0.005917
time: 0.27205920219421387
time: 2.756068706512451
[1, 3417] loss_train: 0.003152, loss_test: 0.005918
time: 0.28406238555908203
time: 2.481001615524292
[1, 3418] loss_train: 0.008576, loss_test: 0.005919
time: 0.3190124034881592
time: 2.612602949142456
[1, 3419] loss_train: 0.004795, loss_test: 0.005919
time: 0.2730598449707031
time: 2.485583782196045
[1, 3420] loss_train: 0.002777, loss_test: 0.005919
time: 0.2841801643371582
time: 2.642420768737793
[1, 3421] loss_train: 0.009512, loss_test: 0.005916
time: 0.27306199073791504
time: 2.5710790157318115
[1, 3422] loss_train: 0.006435, loss_test: 0.005914
time: 0.28406262397766113
time: 3.212606430053711
[1, 3423] loss_train: 0.007066, loss_test: 0.005910
time: 0.280062198638916
time: 2.5555038452148438
[1, 3424] loss_train: 0.007945, loss_test: 0.005909
time: 0.2775282859802246
time: 2.6112923622131348
[1, 3425] loss_train: 0.009744, loss_test: 0.005905
time: 0.2740604877471924
time: 2.510925054550171
[1, 3426] loss_train: 0.002231, loss_test: 0.005903
time: 0.3661313056945801
time: 2.4950809478759766
[1, 3427] loss_train: 0.004474, loss_test: 0.005901
time: 0.27376818656921387
time: 2.460550308227539
[1, 3428] loss_train: 0.007561, loss_test: 0.005899
time: 0.28406357765197754
time: 2.474553346633911
[1, 3429] loss_train: 0.010230, loss_test: 0.005901
time: 0.2760610580444336
time: 2.497558355331421
[1, 3430] loss_train: 0.003031, loss_test: 0.005903
time: 0.29306530952453613
time: 2.725731611251831
[1, 3431] loss_train: 0.003858, loss_test: 0.005909
time: 0.27292299270629883
time: 2.5383949279785156
[1, 3432] loss_train: 0.006041, loss_test: 0.005915
time: 0.2720632553100586
time: 2.5095608234405518
[1, 3433] loss_train: 0.003853, loss_test: 0.005923
time: 0.27506208419799805
time: 2.4135642051696777
[1, 3434] loss_train: 0.004918, loss_test: 0.005932
time: 0.28406405448913574
time: 2.456549644470215
[1, 3435] loss_train: 0.003791, loss_test: 0.005944
time: 0.2725858688354492
time: 2.473660945892334
[1, 3436] loss_train: 0.002427, loss_test: 0.005957
time: 0.2737414836883545
time: 2.444516181945801
[1, 3437] loss_train: 0.011196, loss_test: 0.005956
time: 0.280062198638916
time: 2.5782511234283447
[1, 3438] loss_train: 0.012372, loss_test: 0.005940
time: 0.27916502952575684
time: 2.602071762084961
[1, 3439] loss_train: 0.008612, loss_test: 0.005930
time: 0.2690589427947998
time: 2.4455580711364746
[1, 3440] loss_train: 0.007966, loss_test: 0.005924
time: 0.303067684173584
time: 2.4805550575256348
[1, 3441] loss_train: 0.001793, loss_test: 0.005917
time: 0.2520561218261719
time: 2.5060648918151855
[1, 3442] loss_train: 0.007791, loss_test: 0.005913
time: 0.2475600242614746
time: 2.488919258117676
[1, 3443] loss_train: 0.004322, loss_test: 0.005910
time: 0.2720606327056885
time: 2.5032782554626465
[1, 3444] loss_train: 0.008544, loss_test: 0.005907
time: 0.2649524211883545
time: 2.4072954654693604
[1, 3445] loss_train: 0.012963, loss_test: 0.005904
time: 0.27208685874938965
time: 2.5465755462646484
[1, 3446] loss_train: 0.004598, loss_test: 0.005906
time: 0.2760610580444336
time: 2.5145628452301025
[1, 3447] loss_train: 0.004850, loss_test: 0.005908
time: 0.27205991744995117
time: 2.486078977584839
[1, 3448] loss_train: 0.006267, loss_test: 0.005911
time: 0.2710597515106201
time: 2.5951454639434814
[1, 3449] loss_train: 0.009632, loss_test: 0.005908
time: 0.31971001625061035
time: 2.4250922203063965
[1, 3450] loss_train: 0.005483, loss_test: 0.005906
time: 0.2870631217956543
time: 2.4445464611053467
[1, 3451] loss_train: 0.011341, loss_test: 0.005909
time: 0.2670600414276123
time: 2.4723997116088867
[1, 3452] loss_train: 0.006794, loss_test: 0.005908
time: 0.29706668853759766
time: 2.5891273021698
[1, 3453] loss_train: 0.013568, loss_test: 0.005902
time: 0.27556681632995605
time: 2.438251256942749
[1, 3454] loss_train: 0.019395, loss_test: 0.005872
time: 0.28406286239624023
time: 2.5162193775177
[1, 3455] loss_train: 0.009855, loss_test: 0.005870
time: 0.30645298957824707
time: 2.340122938156128
[1, 3456] loss_train: 0.002002, loss_test: 0.005889
time: 0.27906131744384766
time: 2.328531265258789
[1, 3457] loss_train: 0.005395, loss_test: 0.005921
time: 0.2678689956665039
time: 2.3635287284851074
[1, 3458] loss_train: 0.005021, loss_test: 0.005943
time: 0.2580561637878418
time: 2.378636121749878
[1, 3459] loss_train: 0.002538, loss_test: 0.005939
time: 0.25305604934692383
time: 2.3642618656158447
[1, 3460] loss_train: 0.007130, loss_test: 0.005922
time: 0.27106142044067383
time: 2.3403050899505615
[1, 3461] loss_train: 0.003715, loss_test: 0.005899
time: 0.2650589942932129
time: 2.3215179443359375
[1, 3462] loss_train: 0.004202, loss_test: 0.005885
time: 0.2560567855834961
time: 2.335721969604492
[1, 3463] loss_train: 0.001036, loss_test: 0.005886
time: 0.26105785369873047
time: 2.2840662002563477
[1, 3464] loss_train: 0.003305, loss_test: 0.005901
time: 0.2558753490447998
time: 2.4037516117095947
[1, 3465] loss_train: 0.008019, loss_test: 0.005925
time: 0.26205897331237793
time: 2.3422296047210693
[1, 3466] loss_train: 0.007032, loss_test: 0.005953
time: 0.27205991744995117
time: 2.3464858531951904
[1, 3467] loss_train: 0.005077, loss_test: 0.005975
time: 0.25305867195129395
time: 2.3155181407928467
[1, 3468] loss_train: 0.007930, loss_test: 0.005983
time: 0.2560567855834961
time: 2.3135247230529785
[1, 3469] loss_train: 0.007271, loss_test: 0.005981
time: 0.2540566921234131
time: 2.3209667205810547
[1, 3470] loss_train: 0.013438, loss_test: 0.005964
time: 0.2670588493347168
time: 2.3385989665985107
[1, 3471] loss_train: 0.010679, loss_test: 0.005953
time: 0.25452566146850586
time: 2.3218328952789307
[1, 3472] loss_train: 0.004033, loss_test: 0.005948
time: 0.2510557174682617
time: 2.330462694168091
[1, 3473] loss_train: 0.002228, loss_test: 0.005944
time: 0.2560563087463379
time: 2.351031541824341
[1, 3474] loss_train: 0.007709, loss_test: 0.005938
time: 0.2560563087463379
time: 2.4835190773010254
[1, 3475] loss_train: 0.006516, loss_test: 0.005921
time: 0.2540571689605713
time: 2.3410284519195557
[1, 3476] loss_train: 0.008055, loss_test: 0.005896
time: 0.2540555000305176
time: 2.304896593093872
[1, 3477] loss_train: 0.007253, loss_test: 0.005894
time: 0.2577364444732666
time: 2.344686985015869
[1, 3478] loss_train: 0.008077, loss_test: 0.005914
time: 0.26358890533447266
time: 2.3235535621643066
[1, 3479] loss_train: 0.016013, loss_test: 0.005942
time: 0.25377964973449707
time: 2.2900166511535645
[1, 3480] loss_train: 0.007320, loss_test: 0.005968
time: 0.2710609436035156
time: 2.3047680854797363
[1, 3481] loss_train: 0.008565, loss_test: 0.005993
time: 0.25305652618408203
time: 2.334036350250244
[1, 3482] loss_train: 0.006560, loss_test: 0.006004
time: 0.2610585689544678
time: 2.314023733139038
[1, 3483] loss_train: 0.007715, loss_test: 0.005991
time: 0.25205540657043457
time: 2.2735085487365723
[1, 3484] loss_train: 0.002090, loss_test: 0.005975
time: 0.2510557174682617
time: 2.2581658363342285
[1, 3485] loss_train: 0.008530, loss_test: 0.005955
time: 0.25505709648132324
time: 2.2630059719085693
[1, 3486] loss_train: 0.003125, loss_test: 0.005926
time: 0.2510557174682617
time: 2.2985141277313232
[1, 3487] loss_train: 0.005543, loss_test: 0.005905
time: 0.26606011390686035
time: 2.386535167694092
[1, 3488] loss_train: 0.007521, loss_test: 0.005892
time: 0.27006006240844727
time: 2.386701822280884
[1, 3489] loss_train: 0.006776, loss_test: 0.005890
time: 0.27205944061279297
time: 2.390784502029419
[1, 3490] loss_train: 0.014630, loss_test: 0.005891
time: 0.2835094928741455
time: 2.385040044784546
[1, 3491] loss_train: 0.005482, loss_test: 0.005898
time: 0.2720603942871094
time: 2.345630168914795
[1, 3492] loss_train: 0.004835, loss_test: 0.005911
time: 0.26105833053588867
time: 2.270507574081421
[1, 3493] loss_train: 0.005713, loss_test: 0.005926
time: 0.2600576877593994
time: 2.459406614303589
[1, 3494] loss_train: 0.001706, loss_test: 0.005946
time: 0.2510550022125244
time: 2.3278777599334717
[1, 3495] loss_train: 0.005783, loss_test: 0.005957
time: 0.2540566921234131
time: 2.274221658706665
[1, 3496] loss_train: 0.001100, loss_test: 0.005974
time: 0.26205897331237793
time: 2.3032937049865723
[1, 3497] loss_train: 0.011046, loss_test: 0.005971
time: 0.2565746307373047
time: 2.281558036804199
[1, 3498] loss_train: 0.005789, loss_test: 0.005966
time: 0.26105666160583496
time: 2.300017833709717
[1, 3499] loss_train: 0.008435, loss_test: 0.005953
time: 0.25505685806274414
time: 2.29451847076416
[1, 3500] loss_train: 0.006332, loss_test: 0.005945
time: 0.2630581855773926
time: 2.271507740020752
[1, 3501] loss_train: 0.002302, loss_test: 0.005939
time: 0.2520558834075928
time: 2.283609628677368
[1, 3502] loss_train: 0.007958, loss_test: 0.005927
time: 0.2510552406311035
time: 2.2755093574523926
[1, 3503] loss_train: 0.004190, loss_test: 0.005917
time: 0.25205564498901367
time: 2.2735090255737305
[1, 3504] loss_train: 0.002963, loss_test: 0.005914
time: 0.2490553855895996
time: 2.298513889312744
[1, 3505] loss_train: 0.011262, loss_test: 0.005907
time: 0.2510561943054199
time: 2.281510353088379
[1, 3506] loss_train: 0.003608, loss_test: 0.005906
time: 0.2490549087524414
time: 2.3075153827667236
[1, 3507] loss_train: 0.007705, loss_test: 0.005904
time: 0.2490556240081787
time: 2.2475028038024902
[1, 3508] loss_train: 0.004942, loss_test: 0.005901
time: 0.2510557174682617
time: 2.245943069458008
[1, 3509] loss_train: 0.010722, loss_test: 0.005897
time: 0.2510552406311035
time: 2.2645363807678223
[1, 3510] loss_train: 0.008047, loss_test: 0.005893
time: 0.2620580196380615
time: 2.3060343265533447
[1, 3511] loss_train: 0.002313, loss_test: 0.005889
time: 0.2490541934967041
time: 2.290524959564209
[1, 3512] loss_train: 0.006784, loss_test: 0.005887
time: 0.2500748634338379
time: 2.320518970489502
[1, 3513] loss_train: 0.007591, loss_test: 0.005887
time: 0.2510561943054199
time: 2.289510726928711
[1, 3514] loss_train: 0.006733, loss_test: 0.005885
time: 0.252056360244751
time: 2.266507625579834
[1, 3515] loss_train: 0.001882, loss_test: 0.005884
time: 0.25005555152893066
time: 2.289511203765869
[1, 3516] loss_train: 0.007080, loss_test: 0.005884
time: 0.24905633926391602
time: 2.2815098762512207
[1, 3517] loss_train: 0.007329, loss_test: 0.005885
time: 0.25005602836608887
time: 2.2640233039855957
[1, 3518] loss_train: 0.009074, loss_test: 0.005887
time: 0.25205564498901367
time: 2.308516263961792
[1, 3519] loss_train: 0.003329, loss_test: 0.005890
time: 0.25205492973327637
time: 2.284515380859375
[1, 3520] loss_train: 0.006832, loss_test: 0.005893
time: 0.26205873489379883
time: 2.287510871887207
[1, 3521] loss_train: 0.006452, loss_test: 0.005897
time: 0.2520570755004883
time: 2.283512830734253
[1, 3522] loss_train: 0.001998, loss_test: 0.005901
time: 0.2510552406311035
time: 2.2915127277374268
[1, 3523] loss_train: 0.003011, loss_test: 0.005908
time: 0.2510561943054199
time: 2.276508092880249
[1, 3524] loss_train: 0.010302, loss_test: 0.005912
time: 0.25005674362182617
time: 2.2925562858581543
[1, 3525] loss_train: 0.004245, loss_test: 0.005917
time: 0.2520570755004883
time: 2.284510612487793
[1, 3526] loss_train: 0.007361, loss_test: 0.005921
time: 0.25205540657043457
time: 2.2875771522521973
[1, 3527] loss_train: 0.011405, loss_test: 0.005914
time: 0.2510554790496826
time: 2.2665069103240967
[1, 3528] loss_train: 0.005722, loss_test: 0.005911
time: 0.2490549087524414
time: 2.241501808166504
[1, 3529] loss_train: 0.005536, loss_test: 0.005913
time: 0.25005555152893066
time: 2.24349308013916
[1, 3530] loss_train: 0.005100, loss_test: 0.005916
time: 0.2650582790374756
time: 2.2764031887054443
[1, 3531] loss_train: 0.016259, loss_test: 0.005915
time: 0.25005507469177246
time: 2.283510446548462
[1, 3532] loss_train: 0.003681, loss_test: 0.005917
time: 0.25005555152893066
time: 2.23349928855896
[1, 3533] loss_train: 0.004451, loss_test: 0.005922
time: 0.254056453704834
time: 2.2745089530944824
[1, 3534] loss_train: 0.013166, loss_test: 0.005926
time: 0.25005531311035156
time: 2.2935123443603516
[1, 3535] loss_train: 0.010694, loss_test: 0.005929
time: 0.2520558834075928
time: 2.280510425567627
[1, 3536] loss_train: 0.011450, loss_test: 0.005935
time: 0.2520568370819092
time: 2.2805092334747314
[1, 3537] loss_train: 0.009018, loss_test: 0.005937
time: 0.2508862018585205
time: 2.2995166778564453
[1, 3538] loss_train: 0.001519, loss_test: 0.005930
time: 0.254056453704834
time: 2.2855217456817627
[1, 3539] loss_train: 0.011393, loss_test: 0.005913
time: 0.2520561218261719
time: 2.279510259628296
[1, 3540] loss_train: 0.006721, loss_test: 0.005903
time: 0.2650618553161621
time: 2.2935125827789307
[1, 3541] loss_train: 0.012110, loss_test: 0.005900
time: 0.2510569095611572
time: 2.2445008754730225
[1, 3542] loss_train: 0.012045, loss_test: 0.005894
time: 0.2510561943054199
time: 2.313516855239868
[1, 3543] loss_train: 0.011424, loss_test: 0.005890
time: 0.2510561943054199
time: 2.240504026412964
[1, 3544] loss_train: 0.008988, loss_test: 0.005889
time: 0.2520561218261719
time: 2.2495036125183105
[1, 3545] loss_train: 0.009874, loss_test: 0.005888
time: 0.25005507469177246
time: 2.2785093784332275
[1, 3546] loss_train: 0.005379, loss_test: 0.005886
time: 0.2510557174682617
time: 2.2775259017944336
[1, 3547] loss_train: 0.002419, loss_test: 0.005885
time: 0.2580568790435791
time: 2.293513536453247
[1, 3548] loss_train: 0.014889, loss_test: 0.005885
time: 0.2510554790496826
time: 2.2711410522460938
[1, 3549] loss_train: 0.008074, loss_test: 0.005885
time: 0.25505709648132324
time: 2.28251051902771
[1, 3550] loss_train: 0.004556, loss_test: 0.005886
time: 0.2620582580566406
time: 2.2875115871429443
[1, 3551] loss_train: 0.012041, loss_test: 0.005885
time: 0.2510557174682617
time: 2.280513048171997
[1, 3552] loss_train: 0.006545, loss_test: 0.005887
time: 0.2540559768676758
time: 2.3045156002044678
[1, 3553] loss_train: 0.003822, loss_test: 0.005889
time: 0.28806376457214355
time: 2.7271416187286377
[1, 3554] loss_train: 0.016439, loss_test: 0.005890
time: 0.2560570240020752
time: 2.23500657081604
[1, 3555] loss_train: 0.004898, loss_test: 0.005894
time: 0.24605417251586914
time: 2.2485029697418213
[1, 3556] loss_train: 0.007816, loss_test: 0.005891
time: 0.2510557174682617
time: 2.2094948291778564
[1, 3557] loss_train: 0.009305, loss_test: 0.005884
time: 0.2470688819885254
time: 2.243504285812378
[1, 3558] loss_train: 0.009834, loss_test: 0.005878
time: 0.24806809425354004
time: 3.3815572261810303
[1, 3559] loss_train: 0.007179, loss_test: 0.005872
time: 0.38108253479003906
time: 3.5820295810699463
[1, 3560] loss_train: 0.007152, loss_test: 0.005869
time: 0.4120912551879883
time: 3.446135997772217
[1, 3561] loss_train: 0.007380, loss_test: 0.005870
time: 0.3710818290710449
time: 3.413551092147827
[1, 3562] loss_train: 0.003216, loss_test: 0.005872
time: 0.3898615837097168
time: 3.3759891986846924
[1, 3563] loss_train: 0.001714, loss_test: 0.005879
time: 0.38548946380615234
time: 3.8846323490142822
[1, 3564] loss_train: 0.013843, loss_test: 0.005884
time: 0.37186431884765625
time: 3.302603006362915
[1, 3565] loss_train: 0.007962, loss_test: 0.005891
time: 0.3821542263031006
time: 3.285804033279419
[1, 3566] loss_train: 0.002710, loss_test: 0.005901
time: 0.3751094341278076
time: 3.2922754287719727
[1, 3567] loss_train: 0.003512, loss_test: 0.005913
time: 0.3720662593841553
time: 3.284768581390381
[1, 3568] loss_train: 0.003580, loss_test: 0.005920
time: 0.37009596824645996
time: 3.258547067642212
[1, 3569] loss_train: 0.010459, loss_test: 0.005916
time: 0.38106703758239746
time: 3.247607946395874
[1, 3570] loss_train: 0.005942, loss_test: 0.005911
time: 0.40625
time: 3.2537477016448975
[1, 3571] loss_train: 0.003802, loss_test: 0.005903
time: 0.3720831871032715
time: 3.279157876968384
[1, 3572] loss_train: 0.011189, loss_test: 0.005894
time: 0.3711996078491211
time: 3.226391077041626
[1, 3573] loss_train: 0.005507, loss_test: 0.005886
time: 0.3746762275695801
time: 3.363370895385742
[1, 3574] loss_train: 0.006700, loss_test: 0.005876
time: 0.2790541648864746
time: 2.3020238876342773
[1, 3575] loss_train: 0.007412, loss_test: 0.005874
time: 0.24205255508422852
time: 2.2014925479888916
[1, 3576] loss_train: 0.000753, loss_test: 0.005872
time: 0.24405360221862793
time: 2.1974921226501465
[1, 3577] loss_train: 0.006858, loss_test: 0.005871
time: 0.24305367469787598
time: 2.2184956073760986
[1, 3578] loss_train: 0.007307, loss_test: 0.005867
time: 0.24305415153503418
time: 2.219496726989746
[1, 3579] loss_train: 0.003173, loss_test: 0.005865
time: 0.25005602836608887
time: 2.2115113735198975
[1, 3580] loss_train: 0.006934, loss_test: 0.005866
time: 0.25505685806274414
time: 2.2224974632263184
[1, 3581] loss_train: 0.007713, loss_test: 0.005870
time: 0.24806809425354004
time: 2.3285207748413086
[1, 3582] loss_train: 0.002941, loss_test: 0.005871
time: 0.2690589427947998
time: 2.3095176219940186
[1, 3583] loss_train: 0.005464, loss_test: 0.005874
time: 0.28806328773498535
time: 2.369940757751465
[1, 3584] loss_train: 0.004992, loss_test: 0.005874
time: 0.24405455589294434
time: 2.2234973907470703
[1, 3585] loss_train: 0.005371, loss_test: 0.005871
time: 0.2490551471710205
time: 2.2662854194641113
[1, 3586] loss_train: 0.004801, loss_test: 0.005870
time: 0.2940657138824463
time: 2.28251051902771
[1, 3587] loss_train: 0.004398, loss_test: 0.005870
time: 0.24406671524047852
time: 2.268507242202759
[1, 3588] loss_train: 0.011474, loss_test: 0.005874
time: 0.2540562152862549
time: 2.2655065059661865
[1, 3589] loss_train: 0.004723, loss_test: 0.005878
time: 0.24405455589294434
time: 2.2224977016448975
[1, 3590] loss_train: 0.008926, loss_test: 0.005886
time: 0.2540566921234131
time: 2.2635059356689453
[1, 3591] loss_train: 0.005031, loss_test: 0.005893
time: 0.2400531768798828
time: 2.2250025272369385
[1, 3592] loss_train: 0.002203, loss_test: 0.005902
time: 0.2450709342956543
time: 2.2365026473999023
[1, 3593] loss_train: 0.006350, loss_test: 0.005910
time: 0.24305391311645508
time: 2.2224972248077393
[1, 3594] loss_train: 0.012195, loss_test: 0.005901
time: 0.24405407905578613
time: 2.216496229171753
[1, 3595] loss_train: 0.003629, loss_test: 0.005897
time: 0.24606776237487793
time: 2.2295010089874268
[1, 3596] loss_train: 0.006919, loss_test: 0.005896
time: 0.2440791130065918
time: 2.2344985008239746
[1, 3597] loss_train: 0.002153, loss_test: 0.005896
time: 0.24305510520935059
time: 2.2194981575012207
[1, 3598] loss_train: 0.007489, loss_test: 0.005893
time: 0.24305391311645508
time: 2.228498697280884
[1, 3599] loss_train: 0.005173, loss_test: 0.005893
time: 0.24406814575195312
time: 2.2345099449157715
[1, 3600] loss_train: 0.002526, loss_test: 0.005894
time: 0.2560617923736572
time: 2.237499952316284
[1, 3601] loss_train: 0.004433, loss_test: 0.005896
time: 0.24605417251586914
time: 2.1974923610687256
[1, 3602] loss_train: 0.003140, loss_test: 0.005899
time: 0.2510554790496826
time: 2.20949387550354
[1, 3603] loss_train: 0.006119, loss_test: 0.005903
time: 0.2510559558868408
time: 2.2044930458068848
[1, 3604] loss_train: 0.007137, loss_test: 0.005894
time: 0.2450547218322754
time: 2.210496664047241
[1, 3605] loss_train: 0.002431, loss_test: 0.005886
time: 0.24805474281311035
time: 2.2274980545043945
[1, 3606] loss_train: 0.005636, loss_test: 0.005877
time: 0.24605512619018555
time: 2.23250150680542
[1, 3607] loss_train: 0.001570, loss_test: 0.005874
time: 0.24405431747436523
time: 2.2275009155273438
[1, 3608] loss_train: 0.003905, loss_test: 0.005870
time: 0.24505376815795898
time: 2.2244980335235596
[1, 3609] loss_train: 0.001321, loss_test: 0.005867
time: 0.2470545768737793
time: 2.242502212524414
[1, 3610] loss_train: 0.008668, loss_test: 0.005865
time: 0.2561013698577881
time: 2.232499122619629
[1, 3611] loss_train: 0.004155, loss_test: 0.005870
time: 0.24405384063720703
time: 2.256505012512207
[1, 3612] loss_train: 0.006077, loss_test: 0.005878
time: 0.2430553436279297
time: 2.2254984378814697
[1, 3613] loss_train: 0.015574, loss_test: 0.005874
time: 0.24405455589294434
time: 2.234499216079712
[1, 3614] loss_train: 0.007822, loss_test: 0.005873
time: 0.24405407905578613
time: 2.2405009269714355
[1, 3615] loss_train: 0.016443, loss_test: 0.005870
time: 0.24306654930114746
time: 2.2495028972625732
[1, 3616] loss_train: 0.011112, loss_test: 0.005873
time: 0.24605488777160645
time: 2.230703830718994
[1, 3617] loss_train: 0.005149, loss_test: 0.005880
time: 0.24406671524047852
time: 2.2324981689453125
[1, 3618] loss_train: 0.006098, loss_test: 0.005885
time: 0.2450547218322754
time: 2.223336935043335
[1, 3619] loss_train: 0.003808, loss_test: 0.005882
time: 0.2470552921295166
time: 2.193507671356201
[1, 3620] loss_train: 0.002984, loss_test: 0.005879
time: 0.25505614280700684
time: 2.243502378463745
[1, 3621] loss_train: 0.000912, loss_test: 0.005866
time: 0.24305510520935059
time: 2.2214975357055664
[1, 3622] loss_train: 0.009559, loss_test: 0.005864
time: 0.2450544834136963
time: 2.2244975566864014
[1, 3623] loss_train: 0.007950, loss_test: 0.005857
time: 0.24488592147827148
time: 2.2405006885528564
[1, 3624] loss_train: 0.005946, loss_test: 0.005852
time: 0.25005578994750977
time: 2.2285003662109375
[1, 3625] loss_train: 0.002156, loss_test: 0.005852
time: 0.24405455589294434
time: 2.217495918273926
[1, 3626] loss_train: 0.001738, loss_test: 0.005861
time: 0.25206780433654785
time: 2.253037691116333
[1, 3627] loss_train: 0.005566, loss_test: 0.005879
time: 0.24405431747436523
time: 2.208493947982788
[1, 3628] loss_train: 0.008079, loss_test: 0.005901
time: 0.24805474281311035
time: 2.256976366043091
[1, 3629] loss_train: 0.009908, loss_test: 0.005908
time: 0.24405384063720703
time: 2.2345187664031982
[1, 3630] loss_train: 0.003803, loss_test: 0.005912
time: 0.25905823707580566
time: 2.245502471923828
[1, 3631] loss_train: 0.006704, loss_test: 0.005906
time: 0.24405384063720703
time: 2.2084944248199463
[1, 3632] loss_train: 0.001376, loss_test: 0.005906
time: 0.24605417251586914
time: 2.2285094261169434
[1, 3633] loss_train: 0.003143, loss_test: 0.005903
time: 0.2470550537109375
time: 2.2445013523101807
[1, 3634] loss_train: 0.011621, loss_test: 0.005890
time: 0.2450551986694336
time: 2.235499620437622
[1, 3635] loss_train: 0.004142, loss_test: 0.005878
time: 0.24305415153503418
time: 2.23449969291687
[1, 3636] loss_train: 0.003097, loss_test: 0.005873
time: 0.24706649780273438
time: 2.2510182857513428
[1, 3637] loss_train: 0.007970, loss_test: 0.005872
time: 0.2450542449951172
time: 2.258504867553711
[1, 3638] loss_train: 0.008717, loss_test: 0.005873
time: 0.24205350875854492
time: 2.244501829147339
[1, 3639] loss_train: 0.003771, loss_test: 0.005879
time: 0.24405455589294434
time: 2.2034926414489746
[1, 3640] loss_train: 0.009782, loss_test: 0.005888
time: 0.25505638122558594
time: 2.2405245304107666
[1, 3641] loss_train: 0.002889, loss_test: 0.005894
time: 0.24505352973937988
time: 2.2180912494659424
[1, 3642] loss_train: 0.007685, loss_test: 0.005898
time: 0.24305343627929688
time: 2.224510431289673
[1, 3643] loss_train: 0.001744, loss_test: 0.005892
time: 0.2450547218322754
time: 2.190001964569092
[1, 3644] loss_train: 0.009683, loss_test: 0.005885
time: 0.24506783485412598
time: 2.2114944458007812
[1, 3645] loss_train: 0.008015, loss_test: 0.005880
time: 0.2470541000366211
time: 2.2094948291778564
[1, 3646] loss_train: 0.004472, loss_test: 0.005877
time: 0.24605488777160645
time: 2.205559015274048
[1, 3647] loss_train: 0.003835, loss_test: 0.005879
time: 0.24605488777160645
time: 2.2143661975860596
[1, 3648] loss_train: 0.008615, loss_test: 0.005887
time: 0.24406647682189941
time: 2.256505250930786
[1, 3649] loss_train: 0.007061, loss_test: 0.005894
time: 0.2450547218322754
time: 2.244501829147339
[1, 3650] loss_train: 0.006258, loss_test: 0.005898
time: 0.2540559768676758
time: 2.266528844833374
[1, 3651] loss_train: 0.010113, loss_test: 0.005898
time: 0.2470548152923584
time: 2.23449969291687
[1, 3652] loss_train: 0.008138, loss_test: 0.005899
time: 0.24405407905578613
time: 2.1969945430755615
[1, 3653] loss_train: 0.003655, loss_test: 0.005904
time: 0.2490551471710205
time: 2.2204973697662354
[1, 3654] loss_train: 0.002164, loss_test: 0.005913
time: 0.24305367469787598
time: 2.207494020462036
[1, 3655] loss_train: 0.004381, loss_test: 0.005921
time: 0.2440652847290039
time: 2.232499837875366
[1, 3656] loss_train: 0.003604, loss_test: 0.005929
time: 0.24305438995361328
time: 2.1990199089050293
[1, 3657] loss_train: 0.012851, loss_test: 0.005920
time: 0.24405479431152344
time: 2.2064931392669678
[1, 3658] loss_train: 0.006115, loss_test: 0.005912
time: 0.24506592750549316
time: 2.2430057525634766
[1, 3659] loss_train: 0.004433, loss_test: 0.005903
time: 0.24305343627929688
time: 2.242501735687256
[1, 3660] loss_train: 0.002437, loss_test: 0.005901
time: 0.2540569305419922
time: 2.2375118732452393
[1, 3661] loss_train: 0.003838, loss_test: 0.005899
time: 0.24405431747436523
time: 2.208495616912842
[1, 3662] loss_train: 0.005504, loss_test: 0.005894
time: 0.24606680870056152
time: 2.228515625
[1, 3663] loss_train: 0.011110, loss_test: 0.005887
time: 0.2470550537109375
time: 2.23449969291687
[1, 3664] loss_train: 0.007949, loss_test: 0.005884
time: 0.2490556240081787
time: 2.2234995365142822
[1, 3665] loss_train: 0.005447, loss_test: 0.005885
time: 0.24305391311645508
time: 2.195491313934326
[1, 3666] loss_train: 0.004790, loss_test: 0.005887
time: 0.2470564842224121
time: 2.213493585586548
[1, 3667] loss_train: 0.006411, loss_test: 0.005888
time: 0.24305319786071777
time: 2.2074942588806152
[1, 3668] loss_train: 0.003438, loss_test: 0.005891
time: 0.24405431747436523
time: 2.2294979095458984
[1, 3669] loss_train: 0.009797, loss_test: 0.005892
time: 0.2450547218322754
time: 2.22149658203125
[1, 3670] loss_train: 0.005101, loss_test: 0.005893
time: 0.25705838203430176
time: 2.247504472732544
[1, 3671] loss_train: 0.015735, loss_test: 0.005888
time: 0.24305343627929688
time: 2.2234978675842285
[1, 3672] loss_train: 0.008178, loss_test: 0.005880
time: 0.2450549602508545
time: 2.2284982204437256
[1, 3673] loss_train: 0.005103, loss_test: 0.005870
time: 0.24405455589294434
time: 2.222496747970581
[1, 3674] loss_train: 0.007271, loss_test: 0.005864
time: 0.24306631088256836
time: 2.220496892929077
[1, 3675] loss_train: 0.005067, loss_test: 0.005859
time: 0.24405431747436523
time: 2.1955108642578125
[1, 3676] loss_train: 0.008400, loss_test: 0.005857
time: 0.24605536460876465
time: 2.2030210494995117
[1, 3677] loss_train: 0.002725, loss_test: 0.005857
time: 0.2490549087524414
time: 2.1984925270080566
[1, 3678] loss_train: 0.007012, loss_test: 0.005858
time: 0.24605417251586914
time: 2.213554859161377
[1, 3679] loss_train: 0.006746, loss_test: 0.005859
time: 0.24805521965026855
time: 2.2165048122406006
[1, 3680] loss_train: 0.005227, loss_test: 0.005858
time: 0.2560567855834961
time: 2.2485034465789795
[1, 3681] loss_train: 0.007449, loss_test: 0.005862
time: 0.2490553855895996
time: 2.205995798110962
[1, 3682] loss_train: 0.006567, loss_test: 0.005865
time: 0.24456000328063965
time: 2.260505199432373
[1, 3683] loss_train: 0.008856, loss_test: 0.005869
time: 0.24205398559570312
time: 2.2795116901397705
[1, 3684] loss_train: 0.007260, loss_test: 0.005876
time: 0.2560570240020752
time: 2.2735085487365723
[1, 3685] loss_train: 0.004362, loss_test: 0.005879
time: 0.24805498123168945
time: 2.242518901824951
[1, 3686] loss_train: 0.005754, loss_test: 0.005879
time: 0.24406695365905762
time: 2.243502140045166
[1, 3687] loss_train: 0.005584, loss_test: 0.005875
time: 0.2450554370880127
time: 2.2245094776153564
[1, 3688] loss_train: 0.003363, loss_test: 0.005876
time: 0.2450544834136963
time: 2.2625255584716797
[1, 3689] loss_train: 0.001126, loss_test: 0.005877
time: 0.2450547218322754
time: 2.2225067615509033
[1, 3690] loss_train: 0.012403, loss_test: 0.005880
time: 0.25705647468566895
time: 2.267507553100586
[1, 3691] loss_train: 0.000844, loss_test: 0.005890
time: 0.24405384063720703
time: 2.2265331745147705
[1, 3692] loss_train: 0.007232, loss_test: 0.005905
time: 0.24405384063720703
time: 2.235508680343628
[1, 3693] loss_train: 0.006703, loss_test: 0.005915
time: 0.24405384063720703
time: 2.2254981994628906
[1, 3694] loss_train: 0.003640, loss_test: 0.005926
time: 0.24405503273010254
time: 2.230151414871216
[1, 3695] loss_train: 0.004063, loss_test: 0.005929
time: 0.24605441093444824
time: 2.232499599456787
[1, 3696] loss_train: 0.010578, loss_test: 0.005932
time: 0.24305438995361328
time: 2.210520029067993
[1, 3697] loss_train: 0.003834, loss_test: 0.005934
time: 0.24608993530273438
time: 2.235499620437622
[1, 3698] loss_train: 0.007030, loss_test: 0.005937
time: 0.24405431747436523
time: 2.2144954204559326
[1, 3699] loss_train: 0.013774, loss_test: 0.005933
time: 0.24305319786071777
time: 2.2290027141571045
[1, 3700] loss_train: 0.003913, loss_test: 0.005926
time: 0.2560570240020752
time: 2.271507740020752
[1, 3701] loss_train: 0.008737, loss_test: 0.005910
time: 0.24505400657653809
time: 2.1884922981262207
[1, 3702] loss_train: 0.010924, loss_test: 0.005897
time: 0.24505376815795898
time: 2.207493543624878
[1, 3703] loss_train: 0.006953, loss_test: 0.005886
time: 0.2450551986694336
time: 2.208495855331421
[1, 3704] loss_train: 0.004320, loss_test: 0.005881
time: 0.2510688304901123
time: 2.20949649810791
[1, 3705] loss_train: 0.003429, loss_test: 0.005881
time: 0.24505305290222168
time: 2.2254996299743652
[1, 3706] loss_train: 0.001395, loss_test: 0.005883
time: 0.2490549087524414
time: 2.206493616104126
[1, 3707] loss_train: 0.004365, loss_test: 0.005886
time: 0.24305391311645508
time: 2.2050163745880127
[1, 3708] loss_train: 0.008099, loss_test: 0.005885
time: 0.24605512619018555
time: 2.248502492904663
[1, 3709] loss_train: 0.012887, loss_test: 0.005887
time: 0.2450544834136963
time: 2.263026714324951
[1, 3710] loss_train: 0.007573, loss_test: 0.005889
time: 0.2560563087463379
time: 2.2595057487487793
[1, 3711] loss_train: 0.003042, loss_test: 0.005884
time: 0.24305367469787598
time: 2.2264983654022217
[1, 3712] loss_train: 0.003357, loss_test: 0.005881
time: 0.24305367469787598
time: 2.2454309463500977
[1, 3713] loss_train: 0.004354, loss_test: 0.005883
time: 0.24405407905578613
time: 2.243501663208008
[1, 3714] loss_train: 0.010222, loss_test: 0.005881
time: 0.24606704711914062
time: 2.219496726989746
[1, 3715] loss_train: 0.009042, loss_test: 0.005877
time: 0.24405479431152344
time: 2.2155139446258545
[1, 3716] loss_train: 0.008591, loss_test: 0.005872
time: 0.2450542449951172
time: 2.2004923820495605
[1, 3717] loss_train: 0.006218, loss_test: 0.005869
time: 0.24305319786071777
time: 2.199995994567871
[1, 3718] loss_train: 0.014075, loss_test: 0.005859
time: 0.24605607986450195
time: 2.1924970149993896
[1, 3719] loss_train: 0.014898, loss_test: 0.005882
time: 0.2450547218322754
time: 2.230501174926758
[1, 3720] loss_train: 0.010517, loss_test: 0.005927
time: 0.25505638122558594
time: 2.2365007400512695
[1, 3721] loss_train: 0.008977, loss_test: 0.005969
time: 0.25505685806274414
time: 2.220496416091919
[1, 3722] loss_train: 0.005581, loss_test: 0.005990
time: 0.2450549602508545
time: 2.224497079849243
[1, 3723] loss_train: 0.013293, loss_test: 0.005962
time: 0.25005531311035156
time: 2.2345006465911865
[1, 3724] loss_train: 0.003487, loss_test: 0.005917
time: 0.24605727195739746
time: 2.2244985103607178
[1, 3725] loss_train: 0.003883, loss_test: 0.005888
time: 0.2490553855895996
time: 2.2274975776672363
[1, 3726] loss_train: 0.011582, loss_test: 0.005871
time: 0.2450547218322754
time: 2.2034928798675537
[1, 3727] loss_train: 0.009248, loss_test: 0.005867
time: 0.24505352973937988
time: 2.2335002422332764
[1, 3728] loss_train: 0.006566, loss_test: 0.005870
time: 0.2445659637451172
time: 2.2224979400634766
[1, 3729] loss_train: 0.004746, loss_test: 0.005877
time: 0.24305367469787598
time: 2.2259013652801514
[1, 3730] loss_train: 0.006154, loss_test: 0.005891
time: 0.2580573558807373
time: 2.255507469177246
[1, 3731] loss_train: 0.010657, loss_test: 0.005888
time: 0.24905776977539062
time: 2.2535040378570557
[1, 3732] loss_train: 0.013782, loss_test: 0.005884
time: 0.24505352973937988
time: 2.2355034351348877
[1, 3733] loss_train: 0.003290, loss_test: 0.005883
time: 0.2470536231994629
time: 2.252504587173462
[1, 3734] loss_train: 0.010040, loss_test: 0.005880
time: 0.2450544834136963
time: 2.228503704071045
[1, 3735] loss_train: 0.007453, loss_test: 0.005875
time: 0.24506640434265137
time: 2.255507469177246
[1, 3736] loss_train: 0.014300, loss_test: 0.005873
time: 0.24406671524047852
time: 2.2314987182617188
[1, 3737] loss_train: 0.009234, loss_test: 0.005873
time: 0.24605584144592285
time: 2.213006019592285
[1, 3738] loss_train: 0.001394, loss_test: 0.005871
time: 0.2470550537109375
time: 2.224496841430664
[1, 3739] loss_train: 0.008548, loss_test: 0.005872
time: 0.24306917190551758
time: 2.1934893131256104
[1, 3740] loss_train: 0.010051, loss_test: 0.005871
time: 0.2560579776763916
time: 2.258514165878296
[1, 3741] loss_train: 0.008321, loss_test: 0.005863
time: 0.24605464935302734
time: 2.2255072593688965
[1, 3742] loss_train: 0.010663, loss_test: 0.005854
time: 0.24205470085144043
time: 2.207493305206299
[1, 3743] loss_train: 0.004182, loss_test: 0.005849
time: 0.24505400657653809
time: 2.2114951610565186
[1, 3744] loss_train: 0.000916, loss_test: 0.005851
time: 0.2470550537109375
time: 2.234501600265503
[1, 3745] loss_train: 0.008330, loss_test: 0.005863
time: 0.24405479431152344
time: 2.235499858856201
[1, 3746] loss_train: 0.003675, loss_test: 0.005886
time: 0.24805498123168945
time: 2.2365007400512695
[1, 3747] loss_train: 0.007386, loss_test: 0.005914
time: 0.24405407905578613
time: 2.2134950160980225
[1, 3748] loss_train: 0.001877, loss_test: 0.005946
time: 0.24805569648742676
time: 2.2164952754974365
[1, 3749] loss_train: 0.003035, loss_test: 0.005976
time: 0.24605441093444824
time: 2.2244980335235596
[1, 3750] loss_train: 0.005061, loss_test: 0.006004
time: 0.25705623626708984
time: 2.249042510986328
[1, 3751] loss_train: 0.002688, loss_test: 0.006031
time: 0.24405407905578613
time: 2.2014951705932617
[1, 3752] loss_train: 0.008439, loss_test: 0.006036
time: 0.24305415153503418
time: 2.2385003566741943
[1, 3753] loss_train: 0.002604, loss_test: 0.006036
time: 0.2450544834136963
time: 2.212496042251587
[1, 3754] loss_train: 0.006437, loss_test: 0.006026
time: 0.24405455589294434
time: 2.231499433517456
[1, 3755] loss_train: 0.006091, loss_test: 0.006005
time: 0.24405431747436523
time: 2.2405035495758057
[1, 3756] loss_train: 0.001960, loss_test: 0.005987
time: 0.24305367469787598
time: 2.217496395111084
[1, 3757] loss_train: 0.010566, loss_test: 0.005962
time: 0.24405384063720703
time: 2.2124948501586914
[1, 3758] loss_train: 0.010874, loss_test: 0.005922
time: 0.24405431747436523
time: 2.2214972972869873
[1, 3759] loss_train: 0.006127, loss_test: 0.005893
time: 0.2450547218322754
time: 2.207496166229248
[1, 3760] loss_train: 0.001732, loss_test: 0.005881
time: 0.25505614280700684
time: 2.2435178756713867
[1, 3761] loss_train: 0.001112, loss_test: 0.005878
time: 0.2600581645965576
time: 2.2304985523223877
[1, 3762] loss_train: 0.012654, loss_test: 0.005879
time: 0.24405455589294434
time: 2.2244975566864014
[1, 3763] loss_train: 0.015925, loss_test: 0.005889
time: 0.273068904876709
time: 2.2365012168884277
[1, 3764] loss_train: 0.004768, loss_test: 0.005900
time: 0.24405384063720703
time: 2.2375011444091797
[1, 3765] loss_train: 0.007507, loss_test: 0.005901
time: 0.24805521965026855
time: 2.260007381439209
[1, 3766] loss_train: 0.009527, loss_test: 0.005906
time: 0.24505329132080078
time: 2.193490982055664
[1, 3767] loss_train: 0.015219, loss_test: 0.005905
time: 0.24805545806884766
time: 2.232499361038208
[1, 3768] loss_train: 0.003319, loss_test: 0.005890
time: 0.2470550537109375
time: 2.235499382019043
[1, 3769] loss_train: 0.012858, loss_test: 0.005872
time: 0.24305391311645508
time: 2.243502140045166
[1, 3770] loss_train: 0.003230, loss_test: 0.005853
time: 0.2540566921234131
time: 2.23500919342041
[1, 3771] loss_train: 0.002258, loss_test: 0.005836
time: 0.24305438995361328
time: 2.2294983863830566
[1, 3772] loss_train: 0.007316, loss_test: 0.005832
time: 0.2450549602508545
time: 2.221508502960205
[1, 3773] loss_train: 0.003005, loss_test: 0.005840
time: 0.24505352973937988
time: 2.2314999103546143
[1, 3774] loss_train: 0.009395, loss_test: 0.005856
time: 0.24305510520935059
time: 2.2221882343292236
[1, 3775] loss_train: 0.001548, loss_test: 0.005878
time: 0.24806809425354004
time: 2.212494134902954
[1, 3776] loss_train: 0.008388, loss_test: 0.005879
time: 0.2450568675994873
time: 2.216496706008911
[1, 3777] loss_train: 0.004863, loss_test: 0.005880
time: 0.24405407905578613
time: 2.233006715774536
[1, 3778] loss_train: 0.010093, loss_test: 0.005875
time: 0.24305391311645508
time: 2.2114944458007812
[1, 3779] loss_train: 0.010358, loss_test: 0.005870
time: 0.24407100677490234
time: 2.207493305206299
[1, 3780] loss_train: 0.011267, loss_test: 0.005857
time: 0.2560563087463379
time: 2.226500988006592
[1, 3781] loss_train: 0.004859, loss_test: 0.005851
time: 0.2450549602508545
time: 2.222498893737793
[1, 3782] loss_train: 0.006452, loss_test: 0.005850
time: 0.2530558109283447
time: 2.219499349594116
[1, 3783] loss_train: 0.010720, loss_test: 0.005851
time: 0.24605441093444824
time: 2.243501663208008
[1, 3784] loss_train: 0.006922, loss_test: 0.005855
time: 0.24805450439453125
time: 2.2345004081726074
[1, 3785] loss_train: 0.007606, loss_test: 0.005862
time: 0.24637770652770996
time: 2.20749568939209
[1, 3786] loss_train: 0.003443, loss_test: 0.005871
time: 0.2450547218322754
time: 2.2265145778656006
[1, 3787] loss_train: 0.004596, loss_test: 0.005880
time: 0.24405479431152344
time: 2.2355000972747803
[1, 3788] loss_train: 0.003506, loss_test: 0.005888
time: 0.24655604362487793
time: 2.234013319015503
[1, 3789] loss_train: 0.004458, loss_test: 0.005890
time: 0.2450542449951172
time: 2.194500207901001
[1, 3790] loss_train: 0.001979, loss_test: 0.005889
time: 0.25905704498291016
time: 2.2685070037841797
[1, 3791] loss_train: 0.010406, loss_test: 0.005888
time: 0.2450547218322754
time: 2.2485032081604004
[1, 3792] loss_train: 0.004757, loss_test: 0.005891
time: 0.24605488777160645
time: 2.2194972038269043
[1, 3793] loss_train: 0.013603, loss_test: 0.005892
time: 0.24405312538146973
time: 2.2285006046295166
[1, 3794] loss_train: 0.002961, loss_test: 0.005885
time: 0.2450547218322754
time: 2.2395009994506836
[1, 3795] loss_train: 0.014519, loss_test: 0.005873
time: 0.24305391311645508
time: 2.25750470161438
[1, 3796] loss_train: 0.001944, loss_test: 0.005868
time: 0.24405407905578613
time: 2.2230148315429688
[1, 3797] loss_train: 0.011204, loss_test: 0.005865
time: 0.24405479431152344
time: 2.212494373321533
[1, 3798] loss_train: 0.003389, loss_test: 0.005864
time: 0.24405431747436523
time: 2.247502088546753
[1, 3799] loss_train: 0.019258, loss_test: 0.005868
time: 0.24506878852844238
time: 2.1855008602142334
[1, 3800] loss_train: 0.002902, loss_test: 0.005876
time: 0.2580575942993164
time: 2.23349928855896
[1, 3801] loss_train: 0.007490, loss_test: 0.005879
time: 0.2470550537109375
time: 2.223497152328491
[1, 3802] loss_train: 0.005701, loss_test: 0.005876
time: 0.2470550537109375
time: 2.2024929523468018
[1, 3803] loss_train: 0.014014, loss_test: 0.005880
time: 0.25005459785461426
time: 2.2264983654022217
[1, 3804] loss_train: 0.009123, loss_test: 0.005869
time: 0.24405479431152344
time: 2.217495918273926
[1, 3805] loss_train: 0.004299, loss_test: 0.005860
time: 0.2450547218322754
time: 2.226497173309326
[1, 3806] loss_train: 0.010019, loss_test: 0.005855
time: 0.2540559768676758
time: 2.2865118980407715
[1, 3807] loss_train: 0.010398, loss_test: 0.005848
time: 0.24805450439453125
time: 2.240501880645752
[1, 3808] loss_train: 0.003571, loss_test: 0.005846
time: 0.24405479431152344
time: 2.249502658843994
[1, 3809] loss_train: 0.002953, loss_test: 0.005851
time: 0.2470550537109375
time: 2.222515821456909
[1, 3810] loss_train: 0.007386, loss_test: 0.005862
time: 0.258056640625
time: 2.2595055103302
[1, 3811] loss_train: 0.005992, loss_test: 0.005876
time: 0.25005602836608887
time: 2.2164955139160156
[1, 3812] loss_train: 0.008593, loss_test: 0.005880
time: 0.24305319786071777
time: 2.2204973697662354
[1, 3813] loss_train: 0.007828, loss_test: 0.005879
time: 0.24405455589294434
time: 2.237499237060547
[1, 3814] loss_train: 0.002038, loss_test: 0.005879
time: 0.2450556755065918
time: 2.248007297515869
[1, 3815] loss_train: 0.003849, loss_test: 0.005879
time: 0.24305367469787598
time: 2.22249698638916
[1, 3816] loss_train: 0.002058, loss_test: 0.005881
time: 0.2450542449951172
time: 2.2390217781066895
[1, 3817] loss_train: 0.000865, loss_test: 0.005890
time: 0.24305415153503418
time: 2.2345001697540283
[1, 3818] loss_train: 0.010436, loss_test: 0.005895
time: 0.2510550022125244
time: 2.245234966278076
[1, 3819] loss_train: 0.002614, loss_test: 0.005902
time: 0.2490549087524414
time: 2.2214972972869873
[1, 3820] loss_train: 0.010596, loss_test: 0.005892
time: 0.25306153297424316
time: 2.2675089836120605
[1, 3821] loss_train: 0.007360, loss_test: 0.005862
time: 0.24405431747436523
time: 2.210493564605713
[1, 3822] loss_train: 0.009658, loss_test: 0.005842
time: 0.24405479431152344
time: 2.2405011653900146
[1, 3823] loss_train: 0.008555, loss_test: 0.005833
time: 0.24405384063720703
time: 2.2134957313537598
[1, 3824] loss_train: 0.015788, loss_test: 0.005843
time: 0.24307751655578613
time: 2.2294983863830566
[1, 3825] loss_train: 0.001952, loss_test: 0.005873
time: 0.24405384063720703
time: 2.242501974105835
[1, 3826] loss_train: 0.008219, loss_test: 0.005903
time: 0.2480754852294922
time: 2.2124953269958496
[1, 3827] loss_train: 0.002279, loss_test: 0.005918
time: 0.24505281448364258
time: 2.220496654510498
[1, 3828] loss_train: 0.013101, loss_test: 0.005896
time: 0.2600586414337158
time: 2.252011775970459
[1, 3829] loss_train: 0.003172, loss_test: 0.005874
time: 0.2450547218322754
time: 2.231498956680298
[1, 3830] loss_train: 0.004741, loss_test: 0.005850
time: 0.26105737686157227
time: 2.225001811981201
[1, 3831] loss_train: 0.004659, loss_test: 0.005837
time: 0.24405479431152344
time: 2.2244973182678223
[1, 3832] loss_train: 0.005573, loss_test: 0.005843
time: 0.2520565986633301
time: 2.246502161026001
[1, 3833] loss_train: 0.004328, loss_test: 0.005861
time: 0.24506735801696777
time: 2.229498863220215
[1, 3834] loss_train: 0.006350, loss_test: 0.005886
time: 0.2470545768737793
time: 2.2104949951171875
[1, 3835] loss_train: 0.009638, loss_test: 0.005901
time: 0.2450559139251709
time: 2.194490909576416
[1, 3836] loss_train: 0.002941, loss_test: 0.005917
time: 0.24305367469787598
time: 2.2044930458068848
[1, 3837] loss_train: 0.002196, loss_test: 0.005935
time: 0.24505376815795898
time: 2.2040510177612305
[1, 3838] loss_train: 0.019031, loss_test: 0.005937
time: 0.24306225776672363
time: 2.208493232727051
[1, 3839] loss_train: 0.010662, loss_test: 0.005936
time: 0.24305367469787598
time: 2.216496229171753
[1, 3840] loss_train: 0.008678, loss_test: 0.005936
time: 0.25707054138183594
time: 2.248501777648926
[1, 3841] loss_train: 0.014299, loss_test: 0.005923
time: 0.24506878852844238
time: 2.2415194511413574
[1, 3842] loss_train: 0.010197, loss_test: 0.005906
time: 0.24305391311645508
time: 2.2345011234283447
[1, 3843] loss_train: 0.009585, loss_test: 0.005893
time: 0.24605488777160645
time: 2.2024922370910645
[1, 3844] loss_train: 0.012998, loss_test: 0.005884
time: 0.24405384063720703
time: 2.20149302482605
[1, 3845] loss_train: 0.002730, loss_test: 0.005892
time: 0.2490553855895996
time: 2.22249698638916
[1, 3846] loss_train: 0.004673, loss_test: 0.005908
time: 0.24405431747436523
time: 2.2134950160980225
[1, 3847] loss_train: 0.001032, loss_test: 0.005922
time: 0.2470548152923584
time: 2.175487756729126
[1, 3848] loss_train: 0.003359, loss_test: 0.005930
time: 0.24505352973937988
time: 2.2175133228302
[1, 3849] loss_train: 0.005696, loss_test: 0.005927
time: 0.24305438995361328
time: 2.2455132007598877
[1, 3850] loss_train: 0.015683, loss_test: 0.005931
time: 0.26105809211730957
time: 2.2635059356689453
[1, 3851] loss_train: 0.011234, loss_test: 0.005927
time: 0.24405479431152344
time: 2.23409104347229
[1, 3852] loss_train: 0.006742, loss_test: 0.005916
time: 0.2450547218322754
time: 2.208493947982788
[1, 3853] loss_train: 0.003768, loss_test: 0.005896
time: 0.24405431747436523
time: 2.2244977951049805
[1, 3854] loss_train: 0.007563, loss_test: 0.005881
time: 0.24305367469787598
time: 2.2175040245056152
[1, 3855] loss_train: 0.007950, loss_test: 0.005871
time: 0.24405431747436523
time: 2.2535035610198975
[1, 3856] loss_train: 0.002187, loss_test: 0.005859
time: 0.24205350875854492
time: 2.210494041442871
[1, 3857] loss_train: 0.012333, loss_test: 0.005850
time: 0.2470550537109375
time: 2.217495918273926
[1, 3858] loss_train: 0.005800, loss_test: 0.005849
time: 0.24305391311645508
time: 2.220506191253662
[1, 3859] loss_train: 0.001825, loss_test: 0.005856
time: 0.24405384063720703
time: 2.243502140045166
[1, 3860] loss_train: 0.013421, loss_test: 0.005876
time: 0.25505614280700684
time: 2.269517183303833
[1, 3861] loss_train: 0.004059, loss_test: 0.005902
time: 0.24505400657653809
time: 2.2346293926239014
[1, 3862] loss_train: 0.001177, loss_test: 0.005941
time: 0.24406766891479492
time: 2.2294981479644775
[1, 3863] loss_train: 0.006985, loss_test: 0.005975
time: 0.2450549602508545
time: 2.208493709564209
[1, 3864] loss_train: 0.004402, loss_test: 0.006005
time: 0.2490549087524414
time: 2.235018253326416
[1, 3865] loss_train: 0.004015, loss_test: 0.006020
time: 0.24605512619018555
time: 2.2264983654022217
[1, 3866] loss_train: 0.004181, loss_test: 0.006034
time: 0.24805498123168945
time: 2.2180113792419434
[1, 3867] loss_train: 0.006768, loss_test: 0.006040
time: 0.2470555305480957
time: 2.2105095386505127
[1, 3868] loss_train: 0.012840, loss_test: 0.006004
time: 0.24305367469787598
time: 2.2390048503875732
[1, 3869] loss_train: 0.004694, loss_test: 0.005964
time: 0.24307894706726074
time: 2.219496965408325
[1, 3870] loss_train: 0.002245, loss_test: 0.005935
time: 0.2540557384490967
time: 2.2330682277679443
[1, 3871] loss_train: 0.008568, loss_test: 0.005902
time: 0.2490549087524414
time: 2.2395012378692627
[1, 3872] loss_train: 0.014497, loss_test: 0.005883
time: 0.24307847023010254
time: 2.2011053562164307
[1, 3873] loss_train: 0.004837, loss_test: 0.005889
time: 0.2450542449951172
time: 2.22149658203125
[1, 3874] loss_train: 0.002667, loss_test: 0.005909
time: 0.24505877494812012
time: 2.2070088386535645
[1, 3875] loss_train: 0.004204, loss_test: 0.005927
time: 0.24405479431152344
time: 2.2014946937561035
[1, 3876] loss_train: 0.005365, loss_test: 0.005927
time: 0.24405407905578613
time: 2.19649338722229
[1, 3877] loss_train: 0.006911, loss_test: 0.005923
time: 0.24605393409729004
time: 2.2224972248077393
[1, 3878] loss_train: 0.007991, loss_test: 0.005910
time: 0.2470693588256836
time: 2.1924893856048584
[1, 3879] loss_train: 0.005869, loss_test: 0.005886
time: 0.25005674362182617
time: 2.222506523132324
[1, 3880] loss_train: 0.006485, loss_test: 0.005874
time: 0.256056547164917
time: 2.2515225410461426
[1, 3881] loss_train: 0.003343, loss_test: 0.005871
time: 0.252061128616333
time: 2.231498956680298
[1, 3882] loss_train: 0.014573, loss_test: 0.005870
time: 0.24405407905578613
time: 2.231499195098877
[1, 3883] loss_train: 0.008541, loss_test: 0.005872
time: 0.24605393409729004
time: 2.2635066509246826
[1, 3884] loss_train: 0.009486, loss_test: 0.005872
time: 0.24605488777160645
time: 2.2134950160980225
[1, 3885] loss_train: 0.009163, loss_test: 0.005872
time: 0.24205374717712402
time: 2.223499298095703
[1, 3886] loss_train: 0.009165, loss_test: 0.005870
time: 0.24405455589294434
time: 2.235499620437622
[1, 3887] loss_train: 0.006552, loss_test: 0.005871
time: 0.24305438995361328
time: 2.2044925689697266
[1, 3888] loss_train: 0.007119, loss_test: 0.005870
time: 0.2450556755065918
time: 2.2254984378814697
[1, 3889] loss_train: 0.013787, loss_test: 0.005865
time: 0.24105334281921387
time: 2.2074942588806152
[1, 3890] loss_train: 0.012837, loss_test: 0.005859
time: 0.2550837993621826
time: 2.2555127143859863
[1, 3891] loss_train: 0.008970, loss_test: 0.005860
time: 0.24607062339782715
time: 2.238525867462158
[1, 3892] loss_train: 0.007781, loss_test: 0.005869
time: 0.24305391311645508
time: 2.2590267658233643
[1, 3893] loss_train: 0.001139, loss_test: 0.005880
time: 0.24305343627929688
time: 2.2465028762817383
[1, 3894] loss_train: 0.001793, loss_test: 0.005886
time: 0.24805521965026855
time: 2.1855077743530273
[1, 3895] loss_train: 0.011013, loss_test: 0.005892
time: 0.24405550956726074
time: 2.2004926204681396
[1, 3896] loss_train: 0.010317, loss_test: 0.005888
time: 0.2450542449951172
time: 2.250502824783325
[1, 3897] loss_train: 0.008151, loss_test: 0.005889
time: 0.24405503273010254
time: 2.205493688583374
[1, 3898] loss_train: 0.001827, loss_test: 0.005891
time: 0.25005555152893066
time: 2.2425010204315186
[1, 3899] loss_train: 0.011258, loss_test: 0.005888
time: 0.24475383758544922
time: 2.231499433517456
[1, 3900] loss_train: 0.004326, loss_test: 0.005893
time: 0.2600574493408203
time: 2.255504846572876
[1, 3901] loss_train: 0.004062, loss_test: 0.005903
time: 0.24606585502624512
time: 2.2165043354034424
[1, 3902] loss_train: 0.004486, loss_test: 0.005915
time: 0.24805474281311035
time: 2.2194972038269043
[1, 3903] loss_train: 0.001768, loss_test: 0.005921
time: 0.2450549602508545
time: 2.222496747970581
[1, 3904] loss_train: 0.005555, loss_test: 0.005928
time: 0.24605512619018555
time: 2.2355000972747803
[1, 3905] loss_train: 0.004099, loss_test: 0.005935
time: 0.24405407905578613
time: 2.230498790740967
[1, 3906] loss_train: 0.012104, loss_test: 0.005901
time: 0.2450544834136963
time: 2.230498790740967
[1, 3907] loss_train: 0.005749, loss_test: 0.005875
time: 0.24405384063720703
time: 2.2155003547668457
[1, 3908] loss_train: 0.006286, loss_test: 0.005864
time: 0.24405384063720703
time: 2.2355003356933594
[1, 3909] loss_train: 0.008999, loss_test: 0.005867
time: 0.24305367469787598
time: 2.2275214195251465
[1, 3910] loss_train: 0.009565, loss_test: 0.005878
time: 0.2560563087463379
time: 2.217010259628296
[1, 3911] loss_train: 0.005228, loss_test: 0.005891
time: 0.24605417251586914
time: 2.242502212524414
[1, 3912] loss_train: 0.003150, loss_test: 0.005897
time: 0.24405384063720703
time: 2.2445931434631348
[1, 3913] loss_train: 0.004348, loss_test: 0.005885
time: 0.24406790733337402
time: 2.2084929943084717
[1, 3914] loss_train: 0.002892, loss_test: 0.005872
time: 0.24305391311645508
time: 2.269526958465576
[1, 3915] loss_train: 0.015130, loss_test: 0.005864
time: 0.24505376815795898
time: 2.200502634048462
[1, 3916] loss_train: 0.005100, loss_test: 0.005861
time: 0.24405479431152344
time: 2.259504556655884
[1, 3917] loss_train: 0.003140, loss_test: 0.005862
time: 0.2450551986694336
time: 2.2245399951934814
[1, 3918] loss_train: 0.015696, loss_test: 0.005856
time: 0.24605417251586914
time: 2.233502149581909
[1, 3919] loss_train: 0.012011, loss_test: 0.005851
time: 0.24606657028198242
time: 2.2290148735046387
[1, 3920] loss_train: 0.007544, loss_test: 0.005849
time: 0.256056547164917
time: 2.204493284225464
[1, 3921] loss_train: 0.010408, loss_test: 0.005848
time: 0.25458717346191406
time: 2.20949387550354
[1, 3922] loss_train: 0.007454, loss_test: 0.005847
time: 0.24605417251586914
time: 2.225497245788574
[1, 3923] loss_train: 0.004242, loss_test: 0.005849
time: 0.24805545806884766
time: 2.2034924030303955
[1, 3924] loss_train: 0.002311, loss_test: 0.005852
time: 0.24505400657653809
time: 2.232499361038208
[1, 3925] loss_train: 0.015402, loss_test: 0.005853
time: 0.2450547218322754
time: 2.2570250034332275
[1, 3926] loss_train: 0.008799, loss_test: 0.005857
time: 0.24305343627929688
time: 2.2345004081726074
[1, 3927] loss_train: 0.011018, loss_test: 0.005861
time: 0.24405407905578613
time: 2.1924986839294434
[1, 3928] loss_train: 0.004124, loss_test: 0.005865
time: 0.24405455589294434
time: 2.2365007400512695
[1, 3929] loss_train: 0.008002, loss_test: 0.005869
time: 0.24305367469787598
time: 2.1994922161102295
[1, 3930] loss_train: 0.006694, loss_test: 0.005872
time: 0.254056453704834
time: 2.239514112472534
[1, 3931] loss_train: 0.006715, loss_test: 0.005864
time: 0.24305367469787598
time: 2.22251296043396
[1, 3932] loss_train: 0.003297, loss_test: 0.005860
time: 0.2420663833618164
time: 2.244502544403076
[1, 3933] loss_train: 0.006800, loss_test: 0.005853
time: 0.2450547218322754
time: 2.208514928817749
[1, 3934] loss_train: 0.005089, loss_test: 0.005848
time: 0.24605584144592285
time: 2.2014923095703125
[1, 3935] loss_train: 0.005253, loss_test: 0.005846
time: 0.24506664276123047
time: 2.2144954204559326
[1, 3936] loss_train: 0.006316, loss_test: 0.005843
time: 0.2490708827972412
time: 2.223497152328491
[1, 3937] loss_train: 0.005371, loss_test: 0.005842
time: 0.24405384063720703
time: 2.2068777084350586
[1, 3938] loss_train: 0.007421, loss_test: 0.005841
time: 0.24567294120788574
time: 2.230498790740967
[1, 3939] loss_train: 0.006988, loss_test: 0.005842
time: 0.24405336380004883
time: 2.2275142669677734
[1, 3940] loss_train: 0.016532, loss_test: 0.005842
time: 0.256056547164917
time: 2.2855114936828613
[1, 3941] loss_train: 0.004056, loss_test: 0.005844
time: 0.24105381965637207
time: 2.248502254486084
[1, 3942] loss_train: 0.005706, loss_test: 0.005845
time: 0.2470545768737793
time: 2.231499433517456
[1, 3943] loss_train: 0.008581, loss_test: 0.005853
time: 0.24605512619018555
time: 2.2184956073760986
[1, 3944] loss_train: 0.005939, loss_test: 0.005864
time: 0.24405384063720703
time: 2.2064943313598633
[1, 3945] loss_train: 0.001271, loss_test: 0.005876
time: 0.2470550537109375
time: 2.238499641418457
[1, 3946] loss_train: 0.006293, loss_test: 0.005886
time: 0.24406909942626953
time: 2.2114946842193604
[1, 3947] loss_train: 0.005064, loss_test: 0.005888
time: 0.24306535720825195
time: 2.1974997520446777
[1, 3948] loss_train: 0.004489, loss_test: 0.005885
time: 0.24405479431152344
time: 2.231498956680298
[1, 3949] loss_train: 0.005508, loss_test: 0.005886
time: 0.24205327033996582
time: 2.2375011444091797
[1, 3950] loss_train: 0.002764, loss_test: 0.005891
time: 0.25505733489990234
time: 2.2678942680358887
[1, 3951] loss_train: 0.012804, loss_test: 0.005891
time: 0.24305343627929688
time: 2.2164957523345947
[1, 3952] loss_train: 0.003377, loss_test: 0.005892
time: 0.2460799217224121
time: 2.2355000972747803
[1, 3953] loss_train: 0.005417, loss_test: 0.005893
time: 0.24405431747436523
time: 2.2034928798675537
[1, 3954] loss_train: 0.008732, loss_test: 0.005892
time: 0.24507975578308105
time: 2.2294976711273193
[1, 3955] loss_train: 0.026966, loss_test: 0.005865
time: 0.2470552921295166
time: 2.212494373321533
[1, 3956] loss_train: 0.006953, loss_test: 0.005857
time: 0.24605441093444824
time: 2.2255094051361084
[1, 3957] loss_train: 0.011914, loss_test: 0.005863
time: 0.2470543384552002
time: 2.2244980335235596
[1, 3958] loss_train: 0.011074, loss_test: 0.005879
time: 0.24603629112243652
time: 2.197491407394409
[1, 3959] loss_train: 0.004306, loss_test: 0.005903
time: 0.24506688117980957
time: 2.2144949436187744
[1, 3960] loss_train: 0.003344, loss_test: 0.005931
time: 0.2560572624206543
time: 2.232036828994751
[1, 3961] loss_train: 0.005470, loss_test: 0.005958
time: 0.25005459785461426
time: 2.241501569747925
[1, 3962] loss_train: 0.005874, loss_test: 0.005983
time: 0.2450542449951172
time: 2.2284984588623047
[1, 3963] loss_train: 0.008881, loss_test: 0.005998
time: 0.24305510520935059
time: 2.2355003356933594
[1, 3964] loss_train: 0.002506, loss_test: 0.006009
time: 0.24305486679077148
time: 2.213496685028076
[1, 3965] loss_train: 0.005252, loss_test: 0.005975
time: 0.24305415153503418
time: 2.233508348464966
[1, 3966] loss_train: 0.005225, loss_test: 0.005942
time: 0.24406695365905762
time: 2.2405242919921875
[1, 3967] loss_train: 0.017615, loss_test: 0.005903
time: 0.24305391311645508
time: 2.2037711143493652
[1, 3968] loss_train: 0.003317, loss_test: 0.005874
time: 0.24305391311645508
time: 2.208494186401367
[1, 3969] loss_train: 0.008636, loss_test: 0.005856
time: 0.2490549087524414
time: 2.2345001697540283
[1, 3970] loss_train: 0.007550, loss_test: 0.005848
time: 0.25505614280700684
time: 2.233751058578491
[1, 3971] loss_train: 0.002253, loss_test: 0.005848
time: 0.24505400657653809
time: 2.2375099658966064
[1, 3972] loss_train: 0.005864, loss_test: 0.005853
time: 0.24405431747436523
time: 2.217494249343872
[1, 3973] loss_train: 0.004918, loss_test: 0.005863
time: 0.24405455589294434
time: 2.209494113922119
[1, 3974] loss_train: 0.002875, loss_test: 0.005877
time: 0.25005578994750977
time: 2.23349928855896
[1, 3975] loss_train: 0.008993, loss_test: 0.005893
time: 0.24505376815795898
time: 2.2485032081604004
[1, 3976] loss_train: 0.002043, loss_test: 0.005913
time: 0.2470552921295166
time: 2.254378080368042
[1, 3977] loss_train: 0.003448, loss_test: 0.005936
time: 0.2450544834136963
time: 2.2385003566741943
[1, 3978] loss_train: 0.015399, loss_test: 0.005934
time: 0.24805474281311035
time: 2.234243154525757
[1, 3979] loss_train: 0.009506, loss_test: 0.005919
time: 0.24905610084533691
time: 2.2445015907287598
[1, 3980] loss_train: 0.010510, loss_test: 0.005904
time: 0.25905752182006836
time: 2.2707056999206543
[1, 3981] loss_train: 0.008166, loss_test: 0.005902
time: 0.24605488777160645
time: 2.2304985523223877
[1, 3982] loss_train: 0.012091, loss_test: 0.005938
time: 0.24805498123168945
time: 2.208495616912842
[1, 3983] loss_train: 0.006148, loss_test: 0.006005
time: 0.2450542449951172
time: 2.2244975566864014
[1, 3984] loss_train: 0.003016, loss_test: 0.006072
time: 0.2450542449951172
time: 2.208505392074585
[1, 3985] loss_train: 0.002924, loss_test: 0.006057
time: 0.24405407905578613
time: 2.230499029159546
[1, 3986] loss_train: 0.005431, loss_test: 0.005985
time: 0.24205350875854492
time: 2.235515832901001
[1, 3987] loss_train: 0.006453, loss_test: 0.005932
time: 0.24405360221862793
time: 2.2034952640533447
[1, 3988] loss_train: 0.007688, loss_test: 0.005897
time: 0.24306654930114746
time: 2.2094945907592773
[1, 3989] loss_train: 0.007601, loss_test: 0.005893
time: 0.24487829208374023
time: 2.2355000972747803
[1, 3990] loss_train: 0.005306, loss_test: 0.005907
time: 0.25608253479003906
time: 2.232517719268799
[1, 3991] loss_train: 0.005345, loss_test: 0.005927
time: 0.24408340454101562
time: 2.2004921436309814
[1, 3992] loss_train: 0.008441, loss_test: 0.005945
time: 0.24305438995361328
time: 2.234027624130249
[1, 3993] loss_train: 0.011461, loss_test: 0.005958
time: 0.24606823921203613
time: 2.216496229171753
[1, 3994] loss_train: 0.001599, loss_test: 0.005977
time: 0.24405455589294434
time: 2.2174949645996094
[1, 3995] loss_train: 0.011235, loss_test: 0.005980
time: 0.24805593490600586
time: 2.2094943523406982
[1, 3996] loss_train: 0.009522, loss_test: 0.005972
time: 0.24405384063720703
time: 2.2094948291778564
[1, 3997] loss_train: 0.001677, loss_test: 0.005970
time: 0.2450544834136963
time: 2.2174956798553467
[1, 3998] loss_train: 0.011555, loss_test: 0.005947
time: 0.24305367469787598
time: 2.220496654510498
[1, 3999] loss_train: 0.008897, loss_test: 0.005921
time: 0.2470550537109375
time: 2.2505040168762207
[1, 4000] loss_train: 0.004599, loss_test: 0.005905
time: 0.2540559768676758
time: 2.266507387161255
[1, 4001] loss_train: 0.014574, loss_test: 0.005887
time: 0.24405384063720703
time: 2.2520785331726074
[1, 4002] loss_train: 0.006966, loss_test: 0.005878
time: 0.2470548152923584
time: 2.231498956680298
[1, 4003] loss_train: 0.007840, loss_test: 0.005874
time: 0.2448265552520752
time: 2.2385005950927734
[1, 4004] loss_train: 0.001433, loss_test: 0.005874
time: 0.24505352973937988
time: 2.229499340057373
[1, 4005] loss_train: 0.010828, loss_test: 0.005875
time: 0.24405479431152344
time: 2.230726718902588
[1, 4006] loss_train: 0.004071, loss_test: 0.005871
time: 0.24405384063720703
time: 2.2525110244750977
[1, 4007] loss_train: 0.004284, loss_test: 0.005861
time: 0.24358558654785156
time: 2.2123382091522217
[1, 4008] loss_train: 0.007911, loss_test: 0.005854
time: 0.24609827995300293
time: 2.2335007190704346
[1, 4009] loss_train: 0.011001, loss_test: 0.005850
time: 0.24405288696289062
time: 2.2204959392547607
[1, 4010] loss_train: 0.007361, loss_test: 0.005849
time: 0.25205564498901367
time: 2.235499382019043
[1, 4011] loss_train: 0.004670, loss_test: 0.005848
time: 0.24405407905578613
time: 2.23750901222229
[1, 4012] loss_train: 0.003324, loss_test: 0.005851
time: 0.24605607986450195
time: 2.2665061950683594
[1, 4013] loss_train: 0.016956, loss_test: 0.005858
time: 0.24190187454223633
time: 2.218496084213257
[1, 4014] loss_train: 0.009897, loss_test: 0.005866
time: 0.24405431747436523
time: 2.2385005950927734
[1, 4015] loss_train: 0.005430, loss_test: 0.005873
time: 0.24405455589294434
time: 2.2184958457946777
[1, 4016] loss_train: 0.004800, loss_test: 0.005882
time: 0.24605417251586914
time: 2.2124972343444824
[1, 4017] loss_train: 0.010084, loss_test: 0.005889
time: 0.24506688117980957
time: 2.208012580871582
[1, 4018] loss_train: 0.003739, loss_test: 0.005897
time: 0.2490556240081787
time: 2.185488700866699
[1, 4019] loss_train: 0.009222, loss_test: 0.005897
time: 0.2470545768737793
time: 2.240370273590088
[1, 4020] loss_train: 0.015487, loss_test: 0.005895
time: 0.25505590438842773
time: 2.277509927749634
[1, 4021] loss_train: 0.006575, loss_test: 0.005892
time: 0.24405384063720703
time: 2.246501922607422
[1, 4022] loss_train: 0.005254, loss_test: 0.005887
time: 0.25005555152893066
time: 2.2475030422210693
[1, 4023] loss_train: 0.003385, loss_test: 0.005882
time: 0.24405407905578613
time: 2.2515037059783936
[1, 4024] loss_train: 0.004877, loss_test: 0.005879
time: 0.24505376815795898
time: 2.2625091075897217
[1, 4025] loss_train: 0.001246, loss_test: 0.005879
time: 0.24805521965026855
time: 2.2415056228637695
[1, 4026] loss_train: 0.005995, loss_test: 0.005885
time: 0.24605488777160645
time: 2.21049427986145
[1, 4027] loss_train: 0.005083, loss_test: 0.005889
time: 0.24405407905578613
time: 2.2485029697418213
[1, 4028] loss_train: 0.004883, loss_test: 0.005895
time: 0.24405384063720703
time: 2.224393129348755
[1, 4029] loss_train: 0.003563, loss_test: 0.005900
time: 0.2450554370880127
time: 2.2004923820495605
[1, 4030] loss_train: 0.009866, loss_test: 0.005903
time: 0.25705718994140625
time: 2.2555043697357178
[1, 4031] loss_train: 0.007282, loss_test: 0.005901
time: 0.2490551471710205
time: 2.196491003036499
[1, 4032] loss_train: 0.007468, loss_test: 0.005892
time: 0.24305343627929688
time: 2.228497266769409
[1, 4033] loss_train: 0.007261, loss_test: 0.005885
time: 0.24406647682189941
time: 2.208493709564209
[1, 4034] loss_train: 0.017688, loss_test: 0.005873
time: 0.2450544834136963
time: 2.235499382019043
[1, 4035] loss_train: 0.011305, loss_test: 0.005883
time: 0.24305391311645508
time: 2.2159998416900635
[1, 4036] loss_train: 0.003450, loss_test: 0.005914
time: 0.2470550537109375
time: 2.232499122619629
[1, 4037] loss_train: 0.013193, loss_test: 0.005954
time: 0.24305343627929688
time: 2.2399752140045166
[1, 4038] loss_train: 0.002546, loss_test: 0.005985
time: 0.2450547218322754
time: 2.2365000247955322
[1, 4039] loss_train: 0.012302, loss_test: 0.006011
time: 0.2510554790496826
time: 2.241058349609375
[1, 4040] loss_train: 0.007443, loss_test: 0.005990
time: 0.2554440498352051
time: 2.2366182804107666
[1, 4041] loss_train: 0.008911, loss_test: 0.005959
time: 0.2510561943054199
time: 2.2154951095581055
[1, 4042] loss_train: 0.004124, loss_test: 0.005930
time: 0.2450542449951172
time: 2.2325079441070557
[1, 4043] loss_train: 0.000965, loss_test: 0.005899
time: 0.24805498123168945
time: 2.218496561050415
[1, 4044] loss_train: 0.004328, loss_test: 0.005872
time: 0.2450547218322754
time: 2.2304983139038086
[1, 4045] loss_train: 0.002744, loss_test: 0.005853
time: 0.24405384063720703
time: 2.238180637359619
[1, 4046] loss_train: 0.009484, loss_test: 0.005853
time: 0.24505376815795898
time: 2.255504846572876
[1, 4047] loss_train: 0.014086, loss_test: 0.005865
time: 0.2420787811279297
time: 2.2465031147003174
[1, 4048] loss_train: 0.009131, loss_test: 0.005879
time: 0.24405360221862793
time: 2.2840402126312256
[1, 4049] loss_train: 0.004799, loss_test: 0.005890
time: 0.25005507469177246
time: 2.2335002422332764
[1, 4050] loss_train: 0.002283, loss_test: 0.005900
time: 0.256061315536499
time: 2.2134971618652344
[1, 4051] loss_train: 0.008379, loss_test: 0.005905
time: 0.24805569648742676
time: 2.260505199432373
[1, 4052] loss_train: 0.008530, loss_test: 0.005903
time: 0.24605393409729004
time: 2.244502305984497
[1, 4053] loss_train: 0.005361, loss_test: 0.005900
time: 0.24505400657653809
time: 2.247037172317505
[1, 4054] loss_train: 0.001213, loss_test: 0.005899
time: 0.24407243728637695
time: 2.24550461769104
[1, 4055] loss_train: 0.001245, loss_test: 0.005900
time: 0.2450542449951172
time: 2.2138917446136475
[1, 4056] loss_train: 0.008537, loss_test: 0.005898
time: 0.24306821823120117
time: 2.2064931392669678
[1, 4057] loss_train: 0.003269, loss_test: 0.005894
time: 0.24305462837219238
time: 2.22249698638916
[1, 4058] loss_train: 0.006304, loss_test: 0.005884
time: 0.24505400657653809
time: 2.243502378463745
[1, 4059] loss_train: 0.005205, loss_test: 0.005871
time: 0.24505400657653809
time: 2.2185115814208984
[1, 4060] loss_train: 0.004914, loss_test: 0.005857
time: 0.2540566921234131
time: 2.275508403778076
[1, 4061] loss_train: 0.006804, loss_test: 0.005847
time: 0.24405455589294434
time: 2.2355000972747803
[1, 4062] loss_train: 0.003115, loss_test: 0.005843
time: 0.24605393409729004
time: 2.229499340057373
[1, 4063] loss_train: 0.003746, loss_test: 0.005843
time: 0.24305438995361328
time: 2.246502161026001
[1, 4064] loss_train: 0.005676, loss_test: 0.005844
time: 0.24305319786071777
time: 2.2064967155456543
[1, 4065] loss_train: 0.006095, loss_test: 0.005846
time: 0.24305367469787598
time: 2.180497646331787
[1, 4066] loss_train: 0.010164, loss_test: 0.005844
time: 0.24955987930297852
time: 2.2024927139282227
[1, 4067] loss_train: 0.005353, loss_test: 0.005845
time: 0.24405431747436523
time: 2.2124948501586914
[1, 4068] loss_train: 0.011476, loss_test: 0.005846
time: 0.24605512619018555
time: 2.1914494037628174
[1, 4069] loss_train: 0.001608, loss_test: 0.005849
time: 0.24305415153503418
time: 2.193995475769043
[1, 4070] loss_train: 0.002958, loss_test: 0.005851
time: 0.2560570240020752
time: 2.2750139236450195
[1, 4071] loss_train: 0.007579, loss_test: 0.005857
time: 0.24405384063720703
time: 2.2515196800231934
[1, 4072] loss_train: 0.010004, loss_test: 0.005864
time: 0.24506902694702148
time: 2.2274980545043945
[1, 4073] loss_train: 0.010335, loss_test: 0.005871
time: 0.2450547218322754
time: 2.244502305984497
[1, 4074] loss_train: 0.004830, loss_test: 0.005876
time: 0.24405360221862793
time: 2.2254984378814697
[1, 4075] loss_train: 0.005109, loss_test: 0.005883
time: 0.24305367469787598
time: 2.249502658843994
[1, 4076] loss_train: 0.003406, loss_test: 0.005891
time: 0.2460615634918213
time: 2.251506805419922
[1, 4077] loss_train: 0.002670, loss_test: 0.005902
time: 0.24405336380004883
time: 2.238013982772827
[1, 4078] loss_train: 0.009053, loss_test: 0.005889
time: 0.2450547218322754
time: 2.237499713897705
[1, 4079] loss_train: 0.011010, loss_test: 0.005875
time: 0.24605441093444824
time: 2.202510118484497
[1, 4080] loss_train: 0.010412, loss_test: 0.005864
time: 0.2560570240020752
time: 2.2605130672454834
[1, 4081] loss_train: 0.015006, loss_test: 0.005854
time: 0.24605512619018555
time: 2.1839914321899414
[1, 4082] loss_train: 0.008433, loss_test: 0.005853
time: 0.24405384063720703
time: 2.22049880027771
[1, 4083] loss_train: 0.013677, loss_test: 0.005860
time: 0.24405384063720703
time: 2.243502140045166
[1, 4084] loss_train: 0.008343, loss_test: 0.005876
time: 0.2450544834136963
time: 2.2164957523345947
[1, 4085] loss_train: 0.006622, loss_test: 0.005898
time: 0.24805474281311035
time: 2.2365567684173584
[1, 4086] loss_train: 0.017542, loss_test: 0.005917
time: 0.24706649780273438
time: 2.2134954929351807
[1, 4087] loss_train: 0.003382, loss_test: 0.005917
time: 0.25005602836608887
time: 2.2365000247955322
[1, 4088] loss_train: 0.004922, loss_test: 0.005898
time: 0.24506759643554688
time: 2.2520668506622314
[1, 4089] loss_train: 0.005910, loss_test: 0.005883
time: 0.2470555305480957
time: 2.236499071121216
[1, 4090] loss_train: 0.006284, loss_test: 0.005871
time: 0.25705766677856445
time: 2.2495272159576416
[1, 4091] loss_train: 0.004599, loss_test: 0.005865
time: 0.2470543384552002
time: 2.2235107421875
[1, 4092] loss_train: 0.008161, loss_test: 0.005866
time: 0.24805545806884766
time: 2.2324986457824707
[1, 4093] loss_train: 0.008146, loss_test: 0.005881
time: 0.24605488777160645
time: 2.230499267578125
[1, 4094] loss_train: 0.007712, loss_test: 0.005899
time: 0.2450547218322754
time: 2.2064931392669678
[1, 4095] loss_train: 0.002664, loss_test: 0.005921
time: 0.24605417251586914
time: 2.2144956588745117
[1, 4096] loss_train: 0.016842, loss_test: 0.005919
time: 0.24505400657653809
time: 2.230499267578125
[1, 4097] loss_train: 0.002474, loss_test: 0.005920
time: 0.24305391311645508
time: 2.207495927810669
[1, 4098] loss_train: 0.005276, loss_test: 0.005920
time: 0.24405384063720703
time: 2.2214975357055664
[1, 4099] loss_train: 0.012819, loss_test: 0.005914
time: 0.24305343627929688
time: 2.2355005741119385
[1, 4100] loss_train: 0.005098, loss_test: 0.005910
time: 0.256056547164917
time: 2.269510269165039
[1, 4101] loss_train: 0.004932, loss_test: 0.005908
time: 0.2450544834136963
time: 2.222506284713745
[1, 4102] loss_train: 0.008802, loss_test: 0.005896
time: 0.24405384063720703
time: 2.2285332679748535
[1, 4103] loss_train: 0.004410, loss_test: 0.005884
time: 0.2470545768737793
time: 2.2560415267944336
[1, 4104] loss_train: 0.013393, loss_test: 0.005874
time: 0.24305343627929688
time: 2.1964919567108154
[1, 4105] loss_train: 0.014721, loss_test: 0.005875
time: 0.24305367469787598
time: 2.1955041885375977
[1, 4106] loss_train: 0.006232, loss_test: 0.005878
time: 0.25005507469177246
time: 2.219496488571167
[1, 4107] loss_train: 0.004757, loss_test: 0.005880
time: 0.2470545768737793
time: 2.2465031147003174
[1, 4108] loss_train: 0.006720, loss_test: 0.005876
time: 0.24806833267211914
time: 2.2396812438964844
[1, 4109] loss_train: 0.010042, loss_test: 0.005871
time: 0.2450544834136963
time: 2.2133448123931885
[1, 4110] loss_train: 0.007378, loss_test: 0.005868
time: 0.2600579261779785
time: 2.25956130027771
[1, 4111] loss_train: 0.004047, loss_test: 0.005860
time: 0.2450544834136963
time: 2.234499931335449
[1, 4112] loss_train: 0.009277, loss_test: 0.005856
time: 0.2450549602508545
time: 2.24550199508667
[1, 4113] loss_train: 0.006442, loss_test: 0.005850
time: 0.25505685806274414
time: 2.2389633655548096
[1, 4114] loss_train: 0.019486, loss_test: 0.005852
time: 0.24805450439453125
time: 2.2094945907592773
[1, 4115] loss_train: 0.014209, loss_test: 0.005860
time: 0.24605488777160645
time: 2.2294981479644775
[1, 4116] loss_train: 0.001329, loss_test: 0.005867
time: 0.2470552921295166
time: 2.2165207862854004
[1, 4117] loss_train: 0.005722, loss_test: 0.005865
time: 0.2450554370880127
time: 2.2315218448638916
[1, 4118] loss_train: 0.004403, loss_test: 0.005863
time: 0.2450544834136963
time: 2.2420172691345215
[1, 4119] loss_train: 0.003478, loss_test: 0.005862
time: 0.2450571060180664
time: 2.24550199508667
[1, 4120] loss_train: 0.005995, loss_test: 0.005866
time: 0.25505685806274414
time: 2.2423715591430664
[1, 4121] loss_train: 0.005434, loss_test: 0.005873
time: 0.24405384063720703
time: 2.2365009784698486
[1, 4122] loss_train: 0.006693, loss_test: 0.005877
time: 0.24305319786071777
time: 2.241518020629883
[1, 4123] loss_train: 0.011936, loss_test: 0.005887
time: 0.24506783485412598
time: 2.244590997695923
[1, 4124] loss_train: 0.007234, loss_test: 0.005901
time: 0.24305343627929688
time: 2.2375009059906006
[1, 4125] loss_train: 0.002553, loss_test: 0.005911
time: 0.24205422401428223
time: 2.2092905044555664
[1, 4126] loss_train: 0.013107, loss_test: 0.005902
time: 0.24605488777160645
time: 2.2094931602478027
[1, 4127] loss_train: 0.001473, loss_test: 0.005898
time: 0.24409985542297363
time: 2.231501579284668
[1, 4128] loss_train: 0.002082, loss_test: 0.005902
time: 0.24405431747436523
time: 2.236499071121216
[1, 4129] loss_train: 0.008296, loss_test: 0.005892
time: 0.24407505989074707
time: 2.199491500854492
[1, 4130] loss_train: 0.006415, loss_test: 0.005877
time: 0.2580571174621582
time: 2.230499505996704
[1, 4131] loss_train: 0.001675, loss_test: 0.005874
time: 0.25005602836608887
time: 2.2525200843811035
[1, 4132] loss_train: 0.001381, loss_test: 0.005878
time: 0.24405431747436523
time: 2.218505382537842
[1, 4133] loss_train: 0.010292, loss_test: 0.005880
time: 0.251056432723999
time: 2.233499526977539
[1, 4134] loss_train: 0.007651, loss_test: 0.005884
time: 0.24605393409729004
time: 2.2485034465789795
[1, 4135] loss_train: 0.006935, loss_test: 0.005887
time: 0.24805521965026855
time: 2.228001356124878
[1, 4136] loss_train: 0.017401, loss_test: 0.005890
time: 0.2450544834136963
time: 2.2144954204559326
[1, 4137] loss_train: 0.009670, loss_test: 0.005903
time: 0.24405407905578613
time: 2.1974916458129883
[1, 4138] loss_train: 0.016067, loss_test: 0.005914
time: 0.24305367469787598
time: 2.2234976291656494
[1, 4139] loss_train: 0.002069, loss_test: 0.005902
time: 0.24405407905578613
time: 2.2065155506134033
[1, 4140] loss_train: 0.004934, loss_test: 0.005880
time: 0.25705671310424805
time: 2.244502544403076
[1, 4141] loss_train: 0.004377, loss_test: 0.005860
time: 0.24405384063720703
time: 2.2355010509490967
[1, 4142] loss_train: 0.003460, loss_test: 0.005851
time: 0.24205303192138672
time: 2.2224974632263184
[1, 4143] loss_train: 0.005516, loss_test: 0.005853
time: 0.24405455589294434
time: 2.216999053955078
[1, 4144] loss_train: 0.009068, loss_test: 0.005855
time: 0.24505376815795898
time: 2.254504680633545
[1, 4145] loss_train: 0.001357, loss_test: 0.005856
time: 0.24405455589294434
time: 2.2495205402374268
[1, 4146] loss_train: 0.003162, loss_test: 0.005860
time: 0.24405360221862793
time: 2.2254979610443115
[1, 4147] loss_train: 0.012141, loss_test: 0.005867
time: 0.24505400657653809
time: 2.198526620864868
[1, 4148] loss_train: 0.004983, loss_test: 0.005876
time: 0.24605464935302734
time: 2.2505033016204834
[1, 4149] loss_train: 0.005110, loss_test: 0.005885
time: 0.24406695365905762
time: 2.2105181217193604
[1, 4150] loss_train: 0.006200, loss_test: 0.005897
time: 0.26105833053588867
time: 2.254426956176758
[1, 4151] loss_train: 0.003673, loss_test: 0.005910
time: 0.24505376815795898
time: 2.2275233268737793
[1, 4152] loss_train: 0.010059, loss_test: 0.005919
time: 0.2490546703338623
time: 2.2124955654144287
[1, 4153] loss_train: 0.003220, loss_test: 0.005922
time: 0.24505376815795898
time: 2.2104947566986084
[1, 4154] loss_train: 0.012203, loss_test: 0.005916
time: 0.24706649780273438
time: 2.23449969291687
[1, 4155] loss_train: 0.005803, loss_test: 0.005907
time: 0.24405431747436523
time: 2.2385003566741943
[1, 4156] loss_train: 0.009242, loss_test: 0.005897
time: 0.24507951736450195
time: 2.2605061531066895
[1, 4157] loss_train: 0.002550, loss_test: 0.005897
time: 0.2430558204650879
time: 2.207528591156006
[1, 4158] loss_train: 0.004585, loss_test: 0.005888
time: 0.24405360221862793
time: 2.215496063232422
[1, 4159] loss_train: 0.008732, loss_test: 0.005873
time: 0.24505400657653809
time: 2.212512731552124
[1, 4160] loss_train: 0.004011, loss_test: 0.005865
time: 0.2560567855834961
time: 2.257507085800171
[1, 4161] loss_train: 0.007696, loss_test: 0.005862
time: 0.24305367469787598
time: 2.2180192470550537
[1, 4162] loss_train: 0.007318, loss_test: 0.005859
time: 0.24505400657653809
time: 2.2114946842193604
[1, 4163] loss_train: 0.005413, loss_test: 0.005857
time: 0.24405384063720703
time: 2.202833652496338
[1, 4164] loss_train: 0.006665, loss_test: 0.005855
time: 0.2450544834136963
time: 2.212495803833008
[1, 4165] loss_train: 0.009630, loss_test: 0.005855
time: 0.24405431747436523
time: 2.1975085735321045
[1, 4166] loss_train: 0.007021, loss_test: 0.005857
time: 0.24505376815795898
time: 2.2214977741241455
[1, 4167] loss_train: 0.001771, loss_test: 0.005852
time: 0.24906682968139648
time: 2.2264983654022217
[1, 4168] loss_train: 0.011123, loss_test: 0.005850
time: 0.24605512619018555
time: 2.23449969291687
[1, 4169] loss_train: 0.006685, loss_test: 0.005851
time: 0.24805545806884766
time: 2.2365176677703857
[1, 4170] loss_train: 0.009638, loss_test: 0.005853
time: 0.256056547164917
time: 2.275012493133545
[1, 4171] loss_train: 0.010318, loss_test: 0.005854
time: 0.25005578994750977
time: 2.2415034770965576
[1, 4172] loss_train: 0.003133, loss_test: 0.005855
time: 0.24543547630310059
time: 2.2284984588623047
[1, 4173] loss_train: 0.008419, loss_test: 0.005855
time: 0.2490549087524414
time: 2.2114951610565186
[1, 4174] loss_train: 0.004932, loss_test: 0.005856
time: 0.24805426597595215
time: 2.2305030822753906
[1, 4175] loss_train: 0.003822, loss_test: 0.005854
time: 0.24405264854431152
time: 2.2515041828155518
[1, 4176] loss_train: 0.008836, loss_test: 0.005849
time: 0.24305343627929688
time: 2.2104990482330322
[1, 4177] loss_train: 0.007882, loss_test: 0.005845
time: 0.24305415153503418
time: 2.2395007610321045
[1, 4178] loss_train: 0.001774, loss_test: 0.005842
time: 0.2450551986694336
time: 2.22049617767334
[1, 4179] loss_train: 0.001514, loss_test: 0.005836
time: 0.24405360221862793
time: 2.2204971313476562
[1, 4180] loss_train: 0.001632, loss_test: 0.005834
time: 0.2560575008392334
time: 2.2775087356567383
[1, 4181] loss_train: 0.005552, loss_test: 0.005838
time: 0.24305438995361328
time: 2.2405011653900146
[1, 4182] loss_train: 0.006402, loss_test: 0.005845
time: 0.2450544834136963
time: 2.2630090713500977
[1, 4183] loss_train: 0.000594, loss_test: 0.005854
time: 0.24405479431152344
time: 2.238499641418457
[1, 4184] loss_train: 0.011417, loss_test: 0.005855
time: 0.24305367469787598
time: 2.2605082988739014
[1, 4185] loss_train: 0.010454, loss_test: 0.005848
time: 0.24305438995361328
time: 2.23249888420105
[1, 4186] loss_train: 0.006438, loss_test: 0.005842
time: 0.24405360221862793
time: 2.216495990753174
[1, 4187] loss_train: 0.007042, loss_test: 0.005839
time: 0.2490556240081787
time: 2.2274973392486572
[1, 4188] loss_train: 0.012976, loss_test: 0.005832
time: 0.24405503273010254
time: 2.2395005226135254
[1, 4189] loss_train: 0.005499, loss_test: 0.005830
time: 0.24405407905578613
time: 2.230499267578125
[1, 4190] loss_train: 0.005370, loss_test: 0.005829
time: 0.256056547164917
time: 2.2625198364257812
[1, 4191] loss_train: 0.009231, loss_test: 0.005830
time: 0.24506807327270508
time: 2.2334988117218018
[1, 4192] loss_train: 0.003693, loss_test: 0.005831
time: 0.24305367469787598
time: 2.216495990753174
[1, 4193] loss_train: 0.009710, loss_test: 0.005833
time: 0.24605560302734375
time: 2.215507745742798
[1, 4194] loss_train: 0.010936, loss_test: 0.005837
time: 0.2430591583251953
time: 2.208496570587158
[1, 4195] loss_train: 0.011394, loss_test: 0.005839
time: 0.24405479431152344
time: 2.243504047393799
[1, 4196] loss_train: 0.014908, loss_test: 0.005852
time: 0.25006842613220215
time: 2.2520840167999268
[1, 4197] loss_train: 0.003679, loss_test: 0.005872
time: 0.24605512619018555
time: 2.225497245788574
[1, 4198] loss_train: 0.007406, loss_test: 0.005898
time: 0.2490549087524414
time: 2.2429239749908447
[1, 4199] loss_train: 0.006412, loss_test: 0.005926
time: 0.24405431747436523
time: 2.2234973907470703
[1, 4200] loss_train: 0.009078, loss_test: 0.005942
time: 0.2610771656036377
time: 2.2491254806518555
[1, 4201] loss_train: 0.009666, loss_test: 0.005967
time: 0.2470548152923584
time: 2.221496343612671
[1, 4202] loss_train: 0.004768, loss_test: 0.005990
time: 0.2490551471710205
time: 2.2124953269958496
[1, 4203] loss_train: 0.004613, loss_test: 0.006016
time: 0.24605536460876465
time: 2.2515032291412354
[1, 4204] loss_train: 0.009320, loss_test: 0.006024
time: 0.24305343627929688
time: 2.2435266971588135
[1, 4205] loss_train: 0.013770, loss_test: 0.005994
time: 0.24405360221862793
time: 2.259519100189209
[1, 4206] loss_train: 0.011113, loss_test: 0.005977
time: 0.2450549602508545
time: 2.2515029907226562
[1, 4207] loss_train: 0.007905, loss_test: 0.005928
time: 0.24306559562683105
time: 2.228498935699463
[1, 4208] loss_train: 0.004907, loss_test: 0.005893
time: 0.24305391311645508
time: 2.2495226860046387
[1, 4209] loss_train: 0.003112, loss_test: 0.005869
time: 0.24405455589294434
time: 2.2144951820373535
[1, 4210] loss_train: 0.015504, loss_test: 0.005862
time: 0.2560999393463135
time: 2.2004921436309814
[1, 4211] loss_train: 0.005796, loss_test: 0.005865
time: 0.24305462837219238
time: 2.23950457572937
[1, 4212] loss_train: 0.009522, loss_test: 0.005874
time: 0.2450547218322754
time: 2.2274978160858154
[1, 4213] loss_train: 0.000668, loss_test: 0.005882
time: 0.24606561660766602
time: 2.192491054534912
[1, 4214] loss_train: 0.006383, loss_test: 0.005878
time: 0.24605393409729004
time: 2.1954915523529053
[1, 4215] loss_train: 0.003197, loss_test: 0.005869
time: 0.247053861618042
time: 2.1864893436431885
[1, 4216] loss_train: 0.004129, loss_test: 0.005855
time: 0.24405479431152344
time: 2.2194952964782715
[1, 4217] loss_train: 0.007543, loss_test: 0.005846
time: 0.2520568370819092
time: 2.2475028038024902
[1, 4218] loss_train: 0.003424, loss_test: 0.005844
time: 0.2450549602508545
time: 2.2336044311523438
[1, 4219] loss_train: 0.008710, loss_test: 0.005844
time: 0.24905681610107422
time: 2.201502799987793
[1, 4220] loss_train: 0.003433, loss_test: 0.005845
time: 0.25605297088623047
time: 2.2505972385406494
[1, 4221] loss_train: 0.006235, loss_test: 0.005846
time: 0.2490556240081787
time: 2.2274980545043945
[1, 4222] loss_train: 0.006563, loss_test: 0.005848
time: 0.2470545768737793
time: 2.2024929523468018
[1, 4223] loss_train: 0.011245, loss_test: 0.005845
time: 0.24505400657653809
time: 2.246502637863159
[1, 4224] loss_train: 0.005973, loss_test: 0.005841
time: 0.24305367469787598
time: 2.208496570587158
[1, 4225] loss_train: 0.003360, loss_test: 0.005839
time: 0.24305367469787598
time: 2.2515041828155518
[1, 4226] loss_train: 0.006164, loss_test: 0.005842
time: 0.24405384063720703
time: 2.195500135421753
[1, 4227] loss_train: 0.001467, loss_test: 0.005845
time: 0.25005602836608887
time: 2.246502161026001
[1, 4228] loss_train: 0.006636, loss_test: 0.005845
time: 0.24305391311645508
time: 2.2305140495300293
[1, 4229] loss_train: 0.006076, loss_test: 0.005846
time: 0.24405384063720703
time: 2.252958297729492
[1, 4230] loss_train: 0.006099, loss_test: 0.005845
time: 0.25505661964416504
time: 2.2665069103240967
[1, 4231] loss_train: 0.002833, loss_test: 0.005846
time: 0.24405431747436523
time: 2.257504940032959
[1, 4232] loss_train: 0.006700, loss_test: 0.005845
time: 0.24305462837219238
time: 2.247512102127075
[1, 4233] loss_train: 0.010268, loss_test: 0.005843
time: 0.24405455589294434
time: 2.2144973278045654
[1, 4234] loss_train: 0.018984, loss_test: 0.005844
time: 0.24305343627929688
time: 2.20849347114563
[1, 4235] loss_train: 0.006464, loss_test: 0.005853
time: 0.24405407905578613
time: 2.2154958248138428
[1, 4236] loss_train: 0.007566, loss_test: 0.005861
time: 0.24507975578308105
time: 2.231037139892578
[1, 4237] loss_train: 0.008650, loss_test: 0.005874
time: 0.24605441093444824
time: 2.24650239944458
[1, 4238] loss_train: 0.008244, loss_test: 0.005885
time: 0.24305462837219238
time: 2.206023693084717
[1, 4239] loss_train: 0.001509, loss_test: 0.005883
time: 0.24405360221862793
time: 2.1994922161102295
[1, 4240] loss_train: 0.007287, loss_test: 0.005874
time: 0.2630584239959717
time: 2.273508071899414
[1, 4241] loss_train: 0.008954, loss_test: 0.005859
time: 0.2450542449951172
time: 2.245501756668091
[1, 4242] loss_train: 0.004375, loss_test: 0.005846
time: 0.24805545806884766
time: 2.241501569747925
[1, 4243] loss_train: 0.002509, loss_test: 0.005840
time: 0.25005626678466797
time: 2.2925198078155518
[1, 4244] loss_train: 0.001715, loss_test: 0.005844
time: 0.2490551471710205
time: 2.218000888824463
[1, 4245] loss_train: 0.007144, loss_test: 0.005856
time: 0.2470545768737793
time: 2.2134978771209717
[1, 4246] loss_train: 0.006513, loss_test: 0.005876
time: 0.2470543384552002
time: 2.2400193214416504
[1, 4247] loss_train: 0.014034, loss_test: 0.005877
time: 0.2450544834136963
time: 2.21049427986145
[1, 4248] loss_train: 0.005702, loss_test: 0.005868
time: 0.24605441093444824
time: 2.2235255241394043
[1, 4249] loss_train: 0.002873, loss_test: 0.005861
time: 0.24305367469787598
time: 2.223496913909912
[1, 4250] loss_train: 0.000588, loss_test: 0.005858
time: 0.25705742835998535
time: 2.207493305206299
[1, 4251] loss_train: 0.001908, loss_test: 0.005862
time: 0.24405384063720703
time: 2.216496467590332
[1, 4252] loss_train: 0.001846, loss_test: 0.005869
time: 0.24305319786071777
time: 2.2224979400634766
[1, 4253] loss_train: 0.002323, loss_test: 0.005880
time: 0.24405360221862793
time: 2.244501829147339
[1, 4254] loss_train: 0.004385, loss_test: 0.005891
time: 0.24505949020385742
time: 2.213000774383545
[1, 4255] loss_train: 0.003951, loss_test: 0.005900
time: 0.24305415153503418
time: 2.210494041442871
[1, 4256] loss_train: 0.008318, loss_test: 0.005913
time: 0.24305438995361328
time: 2.232499122619629
[1, 4257] loss_train: 0.005510, loss_test: 0.005909
time: 0.2470550537109375
time: 2.208495855331421
[1, 4258] loss_train: 0.000803, loss_test: 0.005907
time: 0.24805474281311035
time: 2.1854894161224365
[1, 4259] loss_train: 0.004731, loss_test: 0.005902
time: 0.25006747245788574
time: 2.244514226913452
[1, 4260] loss_train: 0.008928, loss_test: 0.005903
time: 0.2560563087463379
time: 2.255505084991455
[1, 4261] loss_train: 0.011158, loss_test: 0.005887
time: 0.25205469131469727
time: 2.264507532119751
[1, 4262] loss_train: 0.005102, loss_test: 0.005873
time: 0.24505400657653809
time: 2.2084972858428955
[1, 4263] loss_train: 0.011975, loss_test: 0.005850
time: 0.2490553855895996
time: 2.2375011444091797
[1, 4264] loss_train: 0.007929, loss_test: 0.005834
time: 0.24405336380004883
time: 2.2234978675842285
[1, 4265] loss_train: 0.022318, loss_test: 0.005838
time: 0.24605512619018555
time: 2.212494373321533
[1, 4266] loss_train: 0.003960, loss_test: 0.005866
time: 0.24407458305358887
time: 2.2385616302490234
[1, 4267] loss_train: 0.004939, loss_test: 0.005899
time: 0.2440657615661621
time: 2.2525041103363037
[1, 4268] loss_train: 0.010792, loss_test: 0.005896
time: 0.24305391311645508
time: 2.24351167678833
[1, 4269] loss_train: 0.004320, loss_test: 0.005884
time: 0.24405384063720703
time: 2.240501642227173
[1, 4270] loss_train: 0.007405, loss_test: 0.005869
time: 0.25705742835998535
time: 2.2425010204315186
[1, 4271] loss_train: 0.008517, loss_test: 0.005863
time: 0.2450544834136963
time: 2.220496892929077
[1, 4272] loss_train: 0.000973, loss_test: 0.005865
time: 0.2450544834136963
time: 2.2054998874664307
[1, 4273] loss_train: 0.008110, loss_test: 0.005870
time: 0.24405384063720703
time: 2.253504991531372
[1, 4274] loss_train: 0.006885, loss_test: 0.005876
time: 0.24405336380004883
time: 2.2365007400512695
[1, 4275] loss_train: 0.017544, loss_test: 0.005879
time: 0.24305343627929688
time: 2.215510368347168
[1, 4276] loss_train: 0.008897, loss_test: 0.005880
time: 0.24405384063720703
time: 2.2154958248138428
[1, 4277] loss_train: 0.002976, loss_test: 0.005884
time: 0.2450544834136963
time: 2.2335221767425537
[1, 4278] loss_train: 0.015935, loss_test: 0.005909
time: 0.24406814575195312
time: 2.2174952030181885
[1, 4279] loss_train: 0.008910, loss_test: 0.005944
time: 0.24505400657653809
time: 2.234529495239258
[1, 4280] loss_train: 0.009518, loss_test: 0.005975
time: 0.254058837890625
time: 2.2735085487365723
[1, 4281] loss_train: 0.008026, loss_test: 0.006009
time: 0.2450547218322754
time: 2.211496591567993
[1, 4282] loss_train: 0.008650, loss_test: 0.006014
time: 0.2450542449951172
time: 2.2495036125183105
[1, 4283] loss_train: 0.009165, loss_test: 0.005963
time: 0.24405407905578613
time: 2.2224972248077393
[1, 4284] loss_train: 0.002307, loss_test: 0.005908
time: 0.2490551471710205
time: 2.1852331161499023
[1, 4285] loss_train: 0.008110, loss_test: 0.005869
time: 0.24405503273010254
time: 2.2134950160980225
[1, 4286] loss_train: 0.013323, loss_test: 0.005851
time: 0.2470550537109375
time: 2.2264976501464844
[1, 4287] loss_train: 0.000884, loss_test: 0.005844
time: 0.2450542449951172
time: 2.2223896980285645
[1, 4288] loss_train: 0.003866, loss_test: 0.005853
time: 0.24405407905578613
time: 2.1994919776916504
[1, 4289] loss_train: 0.016694, loss_test: 0.005858
time: 0.24305415153503418
time: 2.220018148422241
[1, 4290] loss_train: 0.007898, loss_test: 0.005852
time: 0.256056547164917
time: 2.2625064849853516
[1, 4291] loss_train: 0.008782, loss_test: 0.005849
time: 0.2450542449951172
time: 2.2610106468200684
[1, 4292] loss_train: 0.003014, loss_test: 0.005845
time: 0.24305415153503418
time: 2.2345001697540283
[1, 4293] loss_train: 0.003269, loss_test: 0.005845
time: 0.24305438995361328
time: 2.230498790740967
[1, 4294] loss_train: 0.008633, loss_test: 0.005848
time: 0.24605488777160645
time: 2.271507740020752
[1, 4295] loss_train: 0.000591, loss_test: 0.005853
time: 0.24305319786071777
time: 2.2395007610321045
[1, 4296] loss_train: 0.005778, loss_test: 0.005848
time: 0.24405503273010254
time: 2.2014923095703125
[1, 4297] loss_train: 0.015182, loss_test: 0.005835
time: 0.24405384063720703
time: 2.2204971313476562
[1, 4298] loss_train: 0.012644, loss_test: 0.005829
time: 0.24405360221862793
time: 2.2304983139038086
[1, 4299] loss_train: 0.006965, loss_test: 0.005833
time: 0.24305415153503418
time: 2.24810791015625
[1, 4300] loss_train: 0.004429, loss_test: 0.005840
time: 0.25707054138183594
time: 2.274012327194214
[1, 4301] loss_train: 0.008835, loss_test: 0.005846
time: 0.24305343627929688
time: 2.230501413345337
[1, 4302] loss_train: 0.003973, loss_test: 0.005855
time: 0.24405479431152344
time: 2.2284984588623047
[1, 4303] loss_train: 0.005715, loss_test: 0.005846
time: 0.24405407905578613
time: 2.24650502204895
[1, 4304] loss_train: 0.011111, loss_test: 0.005840
time: 0.25005483627319336
time: 2.240501642227173
[1, 4305] loss_train: 0.004195, loss_test: 0.005831
time: 0.24405527114868164
time: 2.207024335861206
[1, 4306] loss_train: 0.002584, loss_test: 0.005823
time: 0.24405384063720703
time: 2.2405004501342773
[1, 4307] loss_train: 0.010894, loss_test: 0.005821
time: 0.2490549087524414
time: 2.1944916248321533
[1, 4308] loss_train: 0.011294, loss_test: 0.005826
time: 0.24405360221862793
time: 2.231499433517456
[1, 4309] loss_train: 0.008242, loss_test: 0.005833
time: 0.24806809425354004
time: 2.2225146293640137
[1, 4310] loss_train: 0.001877, loss_test: 0.005846
time: 0.2560575008392334
time: 2.2660112380981445
[1, 4311] loss_train: 0.003906, loss_test: 0.005863
time: 0.24805545806884766
time: 2.2284982204437256
[1, 4312] loss_train: 0.007233, loss_test: 0.005877
time: 0.24505352973937988
time: 2.2114951610565186
[1, 4313] loss_train: 0.004194, loss_test: 0.005892
time: 0.2430562973022461
time: 2.2264983654022217
[1, 4314] loss_train: 0.009632, loss_test: 0.005892
time: 0.2450547218322754
time: 2.214508533477783
[1, 4315] loss_train: 0.003896, loss_test: 0.005889
time: 0.24405431747436523
time: 2.2134950160980225
[1, 4316] loss_train: 0.007973, loss_test: 0.005881
time: 0.24405360221862793
time: 2.228498935699463
[1, 4317] loss_train: 0.004132, loss_test: 0.005875
time: 0.24405384063720703
time: 2.223457098007202
[1, 4318] loss_train: 0.011995, loss_test: 0.005862
time: 0.24506664276123047
time: 2.2435014247894287
[1, 4319] loss_train: 0.011025, loss_test: 0.005848
time: 0.24406695365905762
time: 2.208829879760742
[1, 4320] loss_train: 0.003365, loss_test: 0.005839
time: 0.25505661964416504
time: 2.2395145893096924
[1, 4321] loss_train: 0.006597, loss_test: 0.005837
time: 0.24605512619018555
time: 2.213494300842285
[1, 4322] loss_train: 0.003976, loss_test: 0.005837
time: 0.24305462837219238
time: 2.2446587085723877
[1, 4323] loss_train: 0.004748, loss_test: 0.005839
time: 0.2470548152923584
time: 2.205493450164795
[1, 4324] loss_train: 0.000694, loss_test: 0.005840
time: 0.24805474281311035
time: 2.219496965408325
[1, 4325] loss_train: 0.009526, loss_test: 0.005838
time: 0.24805474281311035
time: 2.2375011444091797
[1, 4326] loss_train: 0.001904, loss_test: 0.005834
time: 0.24806809425354004
time: 2.2265055179595947
[1, 4327] loss_train: 0.003982, loss_test: 0.005832
time: 0.24405312538146973
time: 2.206493854522705
[1, 4328] loss_train: 0.003720, loss_test: 0.005832
time: 0.25006914138793945
time: 2.2695071697235107
[1, 4329] loss_train: 0.008711, loss_test: 0.005835
time: 0.24405407905578613
time: 2.224076271057129
[1, 4330] loss_train: 0.002983, loss_test: 0.005842
time: 0.2580571174621582
time: 2.2455053329467773
[1, 4331] loss_train: 0.002611, loss_test: 0.005855
time: 0.2510552406311035
time: 2.2485110759735107
[1, 4332] loss_train: 0.007618, loss_test: 0.005867
time: 0.2470548152923584
time: 2.2244997024536133
[1, 4333] loss_train: 0.006303, loss_test: 0.005883
time: 0.24405455589294434
time: 2.2194957733154297
[1, 4334] loss_train: 0.004679, loss_test: 0.005902
time: 0.2450542449951172
time: 2.2500176429748535
[1, 4335] loss_train: 0.003833, loss_test: 0.005925
time: 0.2470543384552002
time: 2.2105188369750977
[1, 4336] loss_train: 0.006208, loss_test: 0.005943
time: 0.24305319786071777
time: 2.2365024089813232
[1, 4337] loss_train: 0.012720, loss_test: 0.005937
time: 0.2450542449951172
time: 2.2395005226135254
[1, 4338] loss_train: 0.003132, loss_test: 0.005935
time: 0.2470557689666748
time: 2.2435126304626465
[1, 4339] loss_train: 0.005108, loss_test: 0.005933
time: 0.24305415153503418
time: 2.241518259048462
[1, 4340] loss_train: 0.001645, loss_test: 0.005934
time: 0.25705647468566895
time: 2.2375993728637695
[1, 4341] loss_train: 0.007214, loss_test: 0.005929
time: 0.24405431747436523
time: 2.2324986457824707
[1, 4342] loss_train: 0.001459, loss_test: 0.005929
time: 0.24405455589294434
time: 2.226511240005493
[1, 4343] loss_train: 0.003165, loss_test: 0.005929
time: 0.24405360221862793
time: 2.227499008178711
[1, 4344] loss_train: 0.009830, loss_test: 0.005918
time: 0.24405360221862793
time: 2.231529712677002
[1, 4345] loss_train: 0.008846, loss_test: 0.005900
time: 0.24305343627929688
time: 2.2455027103424072
[1, 4346] loss_train: 0.008600, loss_test: 0.005885
time: 0.24405384063720703
time: 2.23050856590271
[1, 4347] loss_train: 0.005432, loss_test: 0.005874
time: 0.24405336380004883
time: 2.181488513946533
[1, 4348] loss_train: 0.005811, loss_test: 0.005865
time: 0.2470550537109375
time: 2.2264978885650635
[1, 4349] loss_train: 0.012037, loss_test: 0.005855
time: 0.25005531311035156
time: 2.22851824760437
[1, 4350] loss_train: 0.003856, loss_test: 0.005848
time: 0.25705742835998535
time: 2.2264978885650635
[1, 4351] loss_train: 0.011574, loss_test: 0.005842
time: 0.24906706809997559
time: 2.2615058422088623
[1, 4352] loss_train: 0.016635, loss_test: 0.005839
time: 0.24406719207763672
time: 2.2094945907592773
[1, 4353] loss_train: 0.006004, loss_test: 0.005839
time: 0.2450547218322754
time: 2.2274980545043945
[1, 4354] loss_train: 0.006894, loss_test: 0.005840
time: 0.244065523147583
time: 2.2345175743103027
[1, 4355] loss_train: 0.009920, loss_test: 0.005839
time: 0.24605393409729004
time: 2.214495897293091
[1, 4356] loss_train: 0.004355, loss_test: 0.005839
time: 0.24405360221862793
time: 2.2230100631713867
[1, 4357] loss_train: 0.011362, loss_test: 0.005844
time: 0.24405622482299805
time: 2.2024929523468018
[1, 4358] loss_train: 0.010481, loss_test: 0.005857
time: 0.24405479431152344
time: 2.211494207382202
[1, 4359] loss_train: 0.006136, loss_test: 0.005872
time: 0.24405574798583984
time: 2.2114951610565186
[1, 4360] loss_train: 0.003964, loss_test: 0.005879
time: 0.25505614280700684
time: 2.266509771347046
[1, 4361] loss_train: 0.001639, loss_test: 0.005871
time: 0.24405360221862793
time: 2.235004186630249
[1, 4362] loss_train: 0.004089, loss_test: 0.005849
time: 0.2450551986694336
time: 2.247502565383911
[1, 4363] loss_train: 0.009432, loss_test: 0.005833
time: 0.24605441093444824
time: 2.232499599456787
[1, 4364] loss_train: 0.012278, loss_test: 0.005823
time: 0.24305391311645508
time: 2.2337021827697754
[1, 4365] loss_train: 0.007249, loss_test: 0.005823
time: 0.24605417251586914
time: 2.240501880645752
[1, 4366] loss_train: 0.002501, loss_test: 0.005827
time: 0.24205398559570312
time: 2.2270140647888184
[1, 4367] loss_train: 0.006513, loss_test: 0.005837
time: 0.2440662384033203
time: 2.2104976177215576
[1, 4368] loss_train: 0.008390, loss_test: 0.005847
time: 0.2490553855895996
time: 2.2284982204437256
[1, 4369] loss_train: 0.007900, loss_test: 0.005854
time: 0.24556541442871094
time: 2.227498769760132
[1, 4370] loss_train: 0.005638, loss_test: 0.005856
time: 0.26105737686157227
time: 2.2725088596343994
[1, 4371] loss_train: 0.004145, loss_test: 0.005856
time: 0.2490553855895996
time: 2.230498790740967
[1, 4372] loss_train: 0.001934, loss_test: 0.005854
time: 0.2490549087524414
time: 2.2465031147003174
[1, 4373] loss_train: 0.003725, loss_test: 0.005847
time: 0.24405431747436523
time: 2.1924901008605957
[1, 4374] loss_train: 0.021634, loss_test: 0.005845
time: 0.2470543384552002
time: 2.241501808166504
[1, 4375] loss_train: 0.004797, loss_test: 0.005847
time: 0.24506807327270508
time: 2.248534679412842
[1, 4376] loss_train: 0.006256, loss_test: 0.005850
time: 0.24806714057922363
time: 2.222496747970581
[1, 4377] loss_train: 0.008264, loss_test: 0.005850
time: 0.24508118629455566
time: 2.2264976501464844
[1, 4378] loss_train: 0.002977, loss_test: 0.005849
time: 0.24205398559570312
time: 2.2294983863830566
[1, 4379] loss_train: 0.008252, loss_test: 0.005852
time: 0.24405455589294434
time: 2.2030105590820312
[1, 4380] loss_train: 0.000937, loss_test: 0.005850
time: 0.25705742835998535
time: 2.2805097103118896
[1, 4381] loss_train: 0.001155, loss_test: 0.005849
time: 0.2450547218322754
time: 2.2009971141815186
[1, 4382] loss_train: 0.005624, loss_test: 0.005848
time: 0.24505400657653809
time: 2.255504608154297
[1, 4383] loss_train: 0.014121, loss_test: 0.005850
time: 0.24405407905578613
time: 2.2355005741119385
[1, 4384] loss_train: 0.002443, loss_test: 0.005851
time: 0.24505400657653809
time: 2.224003553390503
[1, 4385] loss_train: 0.006019, loss_test: 0.005845
time: 0.24505400657653809
time: 2.2475407123565674
[1, 4386] loss_train: 0.007051, loss_test: 0.005845
time: 0.24506807327270508
time: 2.2289137840270996
[1, 4387] loss_train: 0.002610, loss_test: 0.005835
time: 0.24205398559570312
time: 2.232499122619629
[1, 4388] loss_train: 0.005284, loss_test: 0.005834
time: 0.24305415153503418
time: 2.221508741378784
[1, 4389] loss_train: 0.007550, loss_test: 0.005837
time: 0.24605512619018555
time: 2.2525031566619873
[1, 4390] loss_train: 0.008957, loss_test: 0.005835
time: 0.2560572624206543
time: 2.258040189743042
[1, 4391] loss_train: 0.010263, loss_test: 0.005829
time: 0.24307894706726074
time: 2.200502395629883
[1, 4392] loss_train: 0.015460, loss_test: 0.005818
time: 0.24506592750549316
time: 2.1905131340026855
[1, 4393] loss_train: 0.005529, loss_test: 0.005812
time: 0.2490553855895996
time: 2.230515956878662
[1, 4394] loss_train: 0.011982, loss_test: 0.005809
time: 0.24506783485412598
time: 2.2094945907592773
[1, 4395] loss_train: 0.003275, loss_test: 0.005809
time: 0.25005483627319336
time: 2.2100086212158203
[1, 4396] loss_train: 0.007032, loss_test: 0.005809
time: 0.24405384063720703
time: 2.2204973697662354
[1, 4397] loss_train: 0.008882, loss_test: 0.005809
time: 0.24305391311645508
time: 2.1984922885894775
[1, 4398] loss_train: 0.007439, loss_test: 0.005808
time: 0.24506711959838867
time: 2.2154958248138428
[1, 4399] loss_train: 0.018309, loss_test: 0.005808
time: 0.26605939865112305
time: 2.2405097484588623
[1, 4400] loss_train: 0.008870, loss_test: 0.005810
time: 0.25505661964416504
time: 2.243502140045166
[1, 4401] loss_train: 0.008834, loss_test: 0.005814
time: 0.2450547218322754
time: 2.216498374938965
[1, 4402] loss_train: 0.000878, loss_test: 0.005813
time: 0.24405431747436523
time: 2.2264981269836426
[1, 4403] loss_train: 0.007906, loss_test: 0.005814
time: 0.24405384063720703
time: 2.228498935699463
[1, 4404] loss_train: 0.006538, loss_test: 0.005812
time: 0.2450542449951172
time: 2.1964914798736572
[1, 4405] loss_train: 0.006294, loss_test: 0.005811
time: 0.24405384063720703
time: 2.211012363433838
[1, 4406] loss_train: 0.004165, loss_test: 0.005810
time: 0.2470541000366211
time: 2.20349383354187
[1, 4407] loss_train: 0.004561, loss_test: 0.005809
time: 0.24405336380004883
time: 2.205493688583374
[1, 4408] loss_train: 0.009493, loss_test: 0.005809
time: 0.25005531311035156
time: 2.206493854522705
[1, 4409] loss_train: 0.008174, loss_test: 0.005811
time: 0.24605441093444824
time: 2.244502067565918
[1, 4410] loss_train: 0.002717, loss_test: 0.005816
time: 0.25905680656433105
time: 2.2715089321136475
[1, 4411] loss_train: 0.003502, loss_test: 0.005822
time: 0.24406695365905762
time: 2.2135069370269775
[1, 4412] loss_train: 0.003640, loss_test: 0.005828
time: 0.2470552921295166
time: 2.2775092124938965
[1, 4413] loss_train: 0.003287, loss_test: 0.005835
time: 0.25305628776550293
time: 2.2475061416625977
[1, 4414] loss_train: 0.012624, loss_test: 0.005842
time: 0.24805521965026855
time: 2.219496250152588
[1, 4415] loss_train: 0.008462, loss_test: 0.005847
time: 0.24405384063720703
time: 2.2034969329833984
[1, 4416] loss_train: 0.010672, loss_test: 0.005853
time: 0.24605679512023926
time: 2.193493127822876
[1, 4417] loss_train: 0.005788, loss_test: 0.005855
time: 0.24305367469787598
time: 2.2054951190948486
[1, 4418] loss_train: 0.005629, loss_test: 0.005854
time: 0.24505209922790527
time: 2.249520778656006
[1, 4419] loss_train: 0.013508, loss_test: 0.005849
time: 0.2450547218322754
time: 2.1721229553222656
[1, 4420] loss_train: 0.008350, loss_test: 0.005843
time: 0.25705671310424805
time: 2.280014991760254
[1, 4421] loss_train: 0.009963, loss_test: 0.005839
time: 0.2440659999847412
time: 2.2665088176727295
[1, 4422] loss_train: 0.002000, loss_test: 0.005839
time: 0.2450544834136963
time: 2.2224972248077393
[1, 4423] loss_train: 0.003223, loss_test: 0.005843
time: 0.2450542449951172
time: 2.201493263244629
[1, 4424] loss_train: 0.010297, loss_test: 0.005848
time: 0.24605631828308105
time: 2.2530293464660645
[1, 4425] loss_train: 0.001294, loss_test: 0.005853
time: 0.2450544834136963
time: 2.2395198345184326
[1, 4426] loss_train: 0.002058, loss_test: 0.005851
time: 0.24805498123168945
time: 2.2290287017822266
[1, 4427] loss_train: 0.008145, loss_test: 0.005848
time: 0.24506640434265137
time: 2.2391021251678467
[1, 4428] loss_train: 0.006960, loss_test: 0.005847
time: 0.24605417251586914
time: 2.2114951610565186
[1, 4429] loss_train: 0.004633, loss_test: 0.005845
time: 0.24605393409729004
time: 2.2080001831054688
[1, 4430] loss_train: 0.000962, loss_test: 0.005843
time: 0.25705718994140625
time: 2.241361141204834
[1, 4431] loss_train: 0.001734, loss_test: 0.005845
time: 0.25005507469177246
time: 2.231499671936035
[1, 4432] loss_train: 0.003060, loss_test: 0.005855
time: 0.24405312538146973
time: 2.2365000247955322
[1, 4433] loss_train: 0.001778, loss_test: 0.005874
time: 0.25005483627319336
time: 2.245502471923828
[1, 4434] loss_train: 0.004128, loss_test: 0.005896
time: 0.2440662384033203
time: 2.2325000762939453
[1, 4435] loss_train: 0.006437, loss_test: 0.005915
time: 0.24606895446777344
time: 2.221497058868408
[1, 4436] loss_train: 0.001828, loss_test: 0.005939
time: 0.24356746673583984
time: 2.2405004501342773
[1, 4437] loss_train: 0.004998, loss_test: 0.005955
time: 0.24855947494506836
time: 2.2455050945281982
[1, 4438] loss_train: 0.006157, loss_test: 0.005964
time: 0.24406695365905762
time: 2.2154977321624756
[1, 4439] loss_train: 0.007020, loss_test: 0.005963
time: 0.24605393409729004
time: 2.2014918327331543
[1, 4440] loss_train: 0.010076, loss_test: 0.005955
time: 0.2580573558807373
time: 2.231499433517456
[1, 4441] loss_train: 0.008404, loss_test: 0.005941
time: 0.24405384063720703
time: 2.204784393310547
[1, 4442] loss_train: 0.004506, loss_test: 0.005922
time: 0.24305415153503418
time: 2.212494373321533
[1, 4443] loss_train: 0.008840, loss_test: 0.005901
time: 0.24605488777160645
time: 2.2234976291656494
[1, 4444] loss_train: 0.006319, loss_test: 0.005880
time: 0.24506688117980957
time: 2.20949387550354
[1, 4445] loss_train: 0.005305, loss_test: 0.005865
time: 0.243058443069458
time: 2.228499174118042
[1, 4446] loss_train: 0.012525, loss_test: 0.005858
time: 0.24505996704101562
time: 2.2234976291656494
[1, 4447] loss_train: 0.008510, loss_test: 0.005859
time: 0.24709820747375488
time: 2.218496799468994
[1, 4448] loss_train: 0.007071, loss_test: 0.005863
time: 0.2490551471710205
time: 2.238499879837036
[1, 4449] loss_train: 0.005927, loss_test: 0.005864
time: 0.24405431747436523
time: 2.211493968963623
[1, 4450] loss_train: 0.005437, loss_test: 0.005866
time: 0.2580568790435791
time: 2.2755086421966553
[1, 4451] loss_train: 0.009575, loss_test: 0.005867
time: 0.24605584144592285
time: 2.2254974842071533
[1, 4452] loss_train: 0.010461, loss_test: 0.005864
time: 0.2490551471710205
time: 2.2525038719177246
[1, 4453] loss_train: 0.013691, loss_test: 0.005862
time: 0.24405360221862793
time: 2.2014925479888916
[1, 4454] loss_train: 0.008022, loss_test: 0.005870
time: 0.2470545768737793
time: 2.233499050140381
[1, 4455] loss_train: 0.006577, loss_test: 0.005872
time: 0.24405503273010254
time: 2.2014923095703125
[1, 4456] loss_train: 0.006871, loss_test: 0.005871
time: 0.24405360221862793
time: 2.2200253009796143
[1, 4457] loss_train: 0.006004, loss_test: 0.005864
time: 0.24605345726013184
time: 2.2375009059906006
[1, 4458] loss_train: 0.014128, loss_test: 0.005856
time: 0.24405384063720703
time: 2.231003999710083
[1, 4459] loss_train: 0.002555, loss_test: 0.005847
time: 0.24405503273010254
time: 2.246022939682007
[1, 4460] loss_train: 0.004065, loss_test: 0.005844
time: 0.25756096839904785
time: 2.2855114936828613
[1, 4461] loss_train: 0.014443, loss_test: 0.005845
time: 0.2450547218322754
time: 2.2695069313049316
[1, 4462] loss_train: 0.003646, loss_test: 0.005846
time: 0.2450542449951172
time: 2.253007173538208
[1, 4463] loss_train: 0.004796, loss_test: 0.005844
time: 0.24405407905578613
time: 2.2185049057006836
[1, 4464] loss_train: 0.006613, loss_test: 0.005841
time: 0.2450547218322754
time: 2.2075071334838867
[1, 4465] loss_train: 0.006478, loss_test: 0.005838
time: 0.24505376815795898
time: 2.220496892929077
[1, 4466] loss_train: 0.006467, loss_test: 0.005836
time: 0.24505376815795898
time: 2.2085115909576416
[1, 4467] loss_train: 0.009510, loss_test: 0.005825
time: 0.24505400657653809
time: 2.188490390777588
[1, 4468] loss_train: 0.003484, loss_test: 0.005818
time: 0.2450542449951172
time: 2.2055091857910156
[1, 4469] loss_train: 0.012679, loss_test: 0.005813
time: 0.24605536460876465
time: 2.260504961013794
[1, 4470] loss_train: 0.002903, loss_test: 0.005810
time: 0.2560572624206543
time: 2.235734462738037
[1, 4471] loss_train: 0.006000, loss_test: 0.005809
time: 0.2540562152862549
time: 2.2204957008361816
[1, 4472] loss_train: 0.008396, loss_test: 0.005809
time: 0.24405288696289062
time: 2.2254981994628906
[1, 4473] loss_train: 0.004153, loss_test: 0.005810
time: 0.2501041889190674
time: 2.2455027103424072
[1, 4474] loss_train: 0.002104, loss_test: 0.005812
time: 0.2470545768737793
time: 2.2405149936676025
[1, 4475] loss_train: 0.007351, loss_test: 0.005814
time: 0.2490549087524414
time: 2.221506118774414
[1, 4476] loss_train: 0.003311, loss_test: 0.005816
time: 0.24406790733337402
time: 2.227498769760132
[1, 4477] loss_train: 0.008214, loss_test: 0.005814
time: 0.24606776237487793
time: 2.2224972248077393
[1, 4478] loss_train: 0.005966, loss_test: 0.005813
time: 0.24305319786071777
time: 2.216499090194702
[1, 4479] loss_train: 0.006594, loss_test: 0.005814
time: 0.24406838417053223
time: 2.2134954929351807
[1, 4480] loss_train: 0.008889, loss_test: 0.005817
time: 0.2560572624206543
time: 2.261505365371704
[1, 4481] loss_train: 0.012273, loss_test: 0.005820
time: 0.2500593662261963
time: 2.225999593734741
[1, 4482] loss_train: 0.006060, loss_test: 0.005827
time: 0.24405431747436523
time: 2.248504877090454
[1, 4483] loss_train: 0.007078, loss_test: 0.005834
time: 0.2450571060180664
time: 2.233499526977539
[1, 4484] loss_train: 0.005874, loss_test: 0.005833
time: 0.24305367469787598
time: 2.2275075912475586
[1, 4485] loss_train: 0.009206, loss_test: 0.005831
time: 0.2450542449951172
time: 2.2625062465667725
[1, 4486] loss_train: 0.004163, loss_test: 0.005833
time: 0.2450544834136963
time: 2.2244973182678223
[1, 4487] loss_train: 0.009652, loss_test: 0.005827
time: 0.24405360221862793
time: 2.223496913909912
[1, 4488] loss_train: 0.011901, loss_test: 0.005823
time: 0.24605560302734375
time: 2.2014920711517334
[1, 4489] loss_train: 0.003908, loss_test: 0.005822
time: 0.24506330490112305
time: 2.2445015907287598
[1, 4490] loss_train: 0.012747, loss_test: 0.005819
time: 0.25507044792175293
time: 2.23449969291687
[1, 4491] loss_train: 0.005838, loss_test: 0.005818
time: 0.24305367469787598
time: 2.206494092941284
[1, 4492] loss_train: 0.007051, loss_test: 0.005820
time: 0.2450544834136963
time: 2.257511854171753
[1, 4493] loss_train: 0.009185, loss_test: 0.005827
time: 0.2450542449951172
time: 2.2385013103485107
[1, 4494] loss_train: 0.005542, loss_test: 0.005836
time: 0.2470545768737793
time: 2.2274985313415527
[1, 4495] loss_train: 0.005800, loss_test: 0.005842
time: 0.24405407905578613
time: 2.211352825164795
[1, 4496] loss_train: 0.004261, loss_test: 0.005846
time: 0.24805521965026855
time: 2.23449969291687
[1, 4497] loss_train: 0.001444, loss_test: 0.005839
time: 0.24405455589294434
time: 2.229005813598633
[1, 4498] loss_train: 0.006248, loss_test: 0.005833
time: 0.24805450439453125
time: 2.216496467590332
[1, 4499] loss_train: 0.015680, loss_test: 0.005830
time: 0.2450547218322754
time: 2.214461326599121
[1, 4500] loss_train: 0.008602, loss_test: 0.005830
time: 0.2550821304321289
time: 2.248502492904663
[1, 4501] loss_train: 0.005556, loss_test: 0.005833
time: 0.2450547218322754
time: 2.2244975566864014
[1, 4502] loss_train: 0.006842, loss_test: 0.005839
time: 0.24406671524047852
time: 2.254504680633545
[1, 4503] loss_train: 0.001785, loss_test: 0.005836
time: 0.24405384063720703
time: 2.2114949226379395
[1, 4504] loss_train: 0.006983, loss_test: 0.005835
time: 0.2450549602508545
time: 2.2395005226135254
[1, 4505] loss_train: 0.011216, loss_test: 0.005836
time: 0.2490556240081787
time: 2.243525266647339
[1, 4506] loss_train: 0.007872, loss_test: 0.005834
time: 0.2490558624267578
time: 2.241511821746826
[1, 4507] loss_train: 0.007070, loss_test: 0.005832
time: 0.24305343627929688
time: 2.2314982414245605
[1, 4508] loss_train: 0.010508, loss_test: 0.005830
time: 0.24305462837219238
time: 2.232499122619629
[1, 4509] loss_train: 0.006927, loss_test: 0.005825
time: 0.24306750297546387
time: 2.241518259048462
[1, 4510] loss_train: 0.004364, loss_test: 0.005822
time: 0.25505614280700684
time: 2.2640111446380615
[1, 4511] loss_train: 0.000715, loss_test: 0.005821
time: 0.24411249160766602
time: 2.247502565383911
[1, 4512] loss_train: 0.005878, loss_test: 0.005819
time: 0.24405431747436523
time: 2.2165043354034424
[1, 4513] loss_train: 0.005147, loss_test: 0.005817
time: 0.24305367469787598
time: 2.2134954929351807
[1, 4514] loss_train: 0.013050, loss_test: 0.005810
time: 0.24505376815795898
time: 2.241502046585083
[1, 4515] loss_train: 0.010399, loss_test: 0.005814
time: 0.2450544834136963
time: 2.194490432739258
[1, 4516] loss_train: 0.014499, loss_test: 0.005832
time: 0.24505400657653809
time: 2.2004928588867188
[1, 4517] loss_train: 0.004535, loss_test: 0.005848
time: 0.25005507469177246
time: 2.1895251274108887
[1, 4518] loss_train: 0.015022, loss_test: 0.005859
time: 0.24405455589294434
time: 2.248504638671875
[1, 4519] loss_train: 0.007056, loss_test: 0.005857
time: 0.24605417251586914
time: 2.2185161113739014
[1, 4520] loss_train: 0.004429, loss_test: 0.005835
time: 0.25505685806274414
time: 2.305515766143799
[1, 4521] loss_train: 0.011030, loss_test: 0.005824
time: 0.24805545806884766
time: 2.248502492904663
[1, 4522] loss_train: 0.006178, loss_test: 0.005818
time: 0.2450547218322754
time: 2.2415006160736084
[1, 4523] loss_train: 0.007903, loss_test: 0.005816
time: 0.24706792831420898
time: 2.220496416091919
[1, 4524] loss_train: 0.007744, loss_test: 0.005817
time: 0.24305438995361328
time: 2.2465155124664307
[1, 4525] loss_train: 0.008904, loss_test: 0.005822
time: 0.25205540657043457
time: 2.2055184841156006
[1, 4526] loss_train: 0.004970, loss_test: 0.005831
time: 0.24405431747436523
time: 2.231491804122925
[1, 4527] loss_train: 0.005793, loss_test: 0.005842
time: 0.2450547218322754
time: 2.2045068740844727
[1, 4528] loss_train: 0.003047, loss_test: 0.005855
time: 0.2450544834136963
time: 2.219496488571167
[1, 4529] loss_train: 0.003843, loss_test: 0.005870
time: 0.2470550537109375
time: 2.2590250968933105
[1, 4530] loss_train: 0.014992, loss_test: 0.005871
time: 0.2560558319091797
time: 2.229499101638794
[1, 4531] loss_train: 0.002767, loss_test: 0.005871
time: 0.24605464935302734
time: 2.2465016841888428
[1, 4532] loss_train: 0.001401, loss_test: 0.005869
time: 0.24305415153503418
time: 2.223501682281494
[1, 4533] loss_train: 0.004378, loss_test: 0.005867
time: 0.24504971504211426
time: 2.2535037994384766
[1, 4534] loss_train: 0.008980, loss_test: 0.005861
time: 0.24405479431152344
time: 2.257505178451538
[1, 4535] loss_train: 0.004405, loss_test: 0.005858
time: 0.24305415153503418
time: 2.237518787384033
[1, 4536] loss_train: 0.005983, loss_test: 0.005852
time: 0.24506759643554688
time: 2.231499195098877
[1, 4537] loss_train: 0.006123, loss_test: 0.005846
time: 0.24405455589294434
time: 2.2065281867980957
[1, 4538] loss_train: 0.003916, loss_test: 0.005841
time: 0.24505400657653809
time: 2.229499101638794
[1, 4539] loss_train: 0.005152, loss_test: 0.005839
time: 0.24505400657653809
time: 2.215513229370117
[1, 4540] loss_train: 0.008121, loss_test: 0.005841
time: 0.2560563087463379
time: 2.2254984378814697
[1, 4541] loss_train: 0.008711, loss_test: 0.005845
time: 0.24505400657653809
time: 2.222612142562866
[1, 4542] loss_train: 0.006059, loss_test: 0.005849
time: 0.2510554790496826
time: 2.218496561050415
[1, 4543] loss_train: 0.010798, loss_test: 0.005851
time: 0.2450547218322754
time: 2.2274975776672363
[1, 4544] loss_train: 0.010166, loss_test: 0.005856
time: 0.24605488777160645
time: 2.2241711616516113
[1, 4545] loss_train: 0.005756, loss_test: 0.005862
time: 0.2540559768676758
time: 2.2375006675720215
[1, 4546] loss_train: 0.004205, loss_test: 0.005865
time: 0.24605488777160645
time: 2.258507490158081
[1, 4547] loss_train: 0.003877, loss_test: 0.005861
time: 0.24405384063720703
time: 2.1914925575256348
[1, 4548] loss_train: 0.005709, loss_test: 0.005848
time: 0.2450542449951172
time: 2.248502492904663
[1, 4549] loss_train: 0.007109, loss_test: 0.005836
time: 0.24305510520935059
time: 2.228508710861206
[1, 4550] loss_train: 0.004742, loss_test: 0.005827
time: 0.25705718994140625
time: 2.236499547958374
[1, 4551] loss_train: 0.009109, loss_test: 0.005821
time: 0.24506592750549316
time: 2.2205166816711426
[1, 4552] loss_train: 0.006038, loss_test: 0.005817
time: 0.24505400657653809
time: 2.236022710800171
[1, 4553] loss_train: 0.004387, loss_test: 0.005821
time: 0.24406790733337402
time: 2.2224972248077393
[1, 4554] loss_train: 0.005016, loss_test: 0.005832
time: 0.24505400657653809
time: 2.255506992340088
[1, 4555] loss_train: 0.006895, loss_test: 0.005844
time: 0.2540559768676758
time: 2.2785141468048096
[1, 4556] loss_train: 0.006426, loss_test: 0.005856
time: 0.24305343627929688
time: 2.245502471923828
[1, 4557] loss_train: 0.004049, loss_test: 0.005866
time: 0.24305367469787598
time: 2.228498697280884
[1, 4558] loss_train: 0.005959, loss_test: 0.005877
time: 0.24505352973937988
time: 2.23850154876709
[1, 4559] loss_train: 0.003080, loss_test: 0.005891
time: 0.24506640434265137
time: 2.2004926204681396
[1, 4560] loss_train: 0.009331, loss_test: 0.005895
time: 0.2560698986053467
time: 2.26052188873291
[1, 4561] loss_train: 0.015579, loss_test: 0.005873
time: 0.2450549602508545
time: 2.2165000438690186
[1, 4562] loss_train: 0.005369, loss_test: 0.005859
time: 0.2420666217803955
time: 2.2345001697540283
[1, 4563] loss_train: 0.009910, loss_test: 0.005853
time: 0.24305367469787598
time: 2.2335002422332764
[1, 4564] loss_train: 0.006514, loss_test: 0.005844
time: 0.24505400657653809
time: 2.224497079849243
[1, 4565] loss_train: 0.007790, loss_test: 0.005838
time: 0.2450723648071289
time: 2.2035906314849854
[1, 4566] loss_train: 0.006094, loss_test: 0.005833
time: 0.24405455589294434
time: 2.233501434326172
[1, 4567] loss_train: 0.001275, loss_test: 0.005831
time: 0.25005578994750977
time: 2.2154953479766846
[1, 4568] loss_train: 0.003973, loss_test: 0.005827
time: 0.24805474281311035
time: 2.2224974632263184
[1, 4569] loss_train: 0.008635, loss_test: 0.005827
time: 0.24605512619018555
time: 2.2415237426757812
[1, 4570] loss_train: 0.012382, loss_test: 0.005827
time: 0.2540562152862549
time: 2.263010025024414
[1, 4571] loss_train: 0.006259, loss_test: 0.005830
time: 0.2540562152862549
time: 2.2630438804626465
[1, 4572] loss_train: 0.002458, loss_test: 0.005830
time: 0.24405360221862793
time: 2.2095084190368652
[1, 4573] loss_train: 0.007644, loss_test: 0.005827
time: 0.24605464935302734
time: 2.2154958248138428
[1, 4574] loss_train: 0.012086, loss_test: 0.005825
time: 0.2440807819366455
time: 2.2255172729492188
[1, 4575] loss_train: 0.007758, loss_test: 0.005825
time: 0.2470548152923584
time: 2.236515522003174
[1, 4576] loss_train: 0.007785, loss_test: 0.005824
time: 0.24408221244812012
time: 2.2254977226257324
[1, 4577] loss_train: 0.011611, loss_test: 0.005826
time: 0.24405431747436523
time: 2.2264983654022217
[1, 4578] loss_train: 0.008731, loss_test: 0.005828
time: 0.24556517601013184
time: 2.2345004081726074
[1, 4579] loss_train: 0.009950, loss_test: 0.005831
time: 0.24505400657653809
time: 2.2285234928131104
[1, 4580] loss_train: 0.005807, loss_test: 0.005834
time: 0.2540559768676758
time: 2.271507740020752
[1, 4581] loss_train: 0.006797, loss_test: 0.005835
time: 0.24405121803283691
time: 2.2405009269714355
[1, 4582] loss_train: 0.004100, loss_test: 0.005832
time: 0.24405407905578613
time: 2.232499837875366
[1, 4583] loss_train: 0.007528, loss_test: 0.005831
time: 0.24505400657653809
time: 2.215496301651001
[1, 4584] loss_train: 0.009437, loss_test: 0.005833
time: 0.24305367469787598
time: 2.2535035610198975
[1, 4585] loss_train: 0.002041, loss_test: 0.005833
time: 0.24306011199951172
time: 2.219505548477173
[1, 4586] loss_train: 0.002926, loss_test: 0.005834
time: 0.24305319786071777
time: 2.2365009784698486
[1, 4587] loss_train: 0.004897, loss_test: 0.005837
time: 0.24405384063720703
time: 2.2355005741119385
[1, 4588] loss_train: 0.003504, loss_test: 0.005841
time: 0.24505352973937988
time: 2.240529775619507
[1, 4589] loss_train: 0.005341, loss_test: 0.005847
time: 0.2450547218322754
time: 2.2155489921569824
[1, 4590] loss_train: 0.005830, loss_test: 0.005852
time: 0.256056547164917
time: 2.24450421333313
[1, 4591] loss_train: 0.008951, loss_test: 0.005849
time: 0.24405431747436523
time: 2.2365002632141113
[1, 4592] loss_train: 0.004214, loss_test: 0.005848
time: 0.2490556240081787
time: 2.2154955863952637
[1, 4593] loss_train: 0.004858, loss_test: 0.005843
time: 0.24505400657653809
time: 2.2365007400512695
[1, 4594] loss_train: 0.007527, loss_test: 0.005829
time: 0.25005555152893066
time: 2.2525134086608887
[1, 4595] loss_train: 0.000848, loss_test: 0.005822
time: 0.2450547218322754
time: 2.2014920711517334
[1, 4596] loss_train: 0.004339, loss_test: 0.005818
time: 0.24605464935302734
time: 2.2525124549865723
[1, 4597] loss_train: 0.011589, loss_test: 0.005815
time: 0.24405646324157715
time: 2.2054929733276367
[1, 4598] loss_train: 0.008155, loss_test: 0.005816
time: 0.2450544834136963
time: 2.233499765396118
[1, 4599] loss_train: 0.014636, loss_test: 0.005819
time: 0.24605417251586914
time: 2.230499267578125
[1, 4600] loss_train: 0.008633, loss_test: 0.005830
time: 0.2560572624206543
time: 2.2555177211761475
[1, 4601] loss_train: 0.006705, loss_test: 0.005840
time: 0.24505376815795898
time: 2.229499101638794
[1, 4602] loss_train: 0.000984, loss_test: 0.005849
time: 0.24506783485412598
time: 2.2515034675598145
[1, 4603] loss_train: 0.003792, loss_test: 0.005843
time: 0.24405431747436523
time: 2.2355003356933594
[1, 4604] loss_train: 0.006787, loss_test: 0.005832
time: 0.24505376815795898
time: 2.2515037059783936
[1, 4605] loss_train: 0.001387, loss_test: 0.005813
time: 0.24305391311645508
time: 2.2515037059783936
[1, 4606] loss_train: 0.005222, loss_test: 0.005804
time: 0.24405503273010254
time: 2.2355165481567383
[1, 4607] loss_train: 0.006255, loss_test: 0.005805
time: 0.24405550956726074
time: 2.249502658843994
[1, 4608] loss_train: 0.001625, loss_test: 0.005817
time: 0.24605417251586914
time: 2.233555793762207
[1, 4609] loss_train: 0.005474, loss_test: 0.005829
time: 0.24405407905578613
time: 2.219007730484009
[1, 4610] loss_train: 0.003843, loss_test: 0.005842
time: 0.2560567855834961
time: 2.2510476112365723
[1, 4611] loss_train: 0.012922, loss_test: 0.005848
time: 0.2490549087524414
time: 2.2285072803497314
[1, 4612] loss_train: 0.003698, loss_test: 0.005856
time: 0.24405312538146973
time: 2.2255117893218994
[1, 4613] loss_train: 0.007099, loss_test: 0.005851
time: 0.24205422401428223
time: 2.2034928798675537
[1, 4614] loss_train: 0.013391, loss_test: 0.005843
time: 0.2450542449951172
time: 2.2300868034362793
[1, 4615] loss_train: 0.008613, loss_test: 0.005827
time: 0.24605512619018555
time: 2.233499050140381
[1, 4616] loss_train: 0.006695, loss_test: 0.005816
time: 0.24406719207763672
time: 2.2381701469421387
[1, 4617] loss_train: 0.010830, loss_test: 0.005812
time: 0.24805450439453125
time: 2.220496416091919
[1, 4618] loss_train: 0.005979, loss_test: 0.005817
time: 0.24805641174316406
time: 2.224006175994873
[1, 4619] loss_train: 0.009990, loss_test: 0.005829
time: 0.2490544319152832
time: 2.2435028553009033
[1, 4620] loss_train: 0.005503, loss_test: 0.005845
time: 0.25505638122558594
time: 2.2865114212036133
[1, 4621] loss_train: 0.001489, loss_test: 0.005860
time: 0.2530558109283447
time: 2.2465028762817383
[1, 4622] loss_train: 0.004030, loss_test: 0.005864
time: 0.24405360221862793
time: 2.205493688583374
[1, 4623] loss_train: 0.006550, loss_test: 0.005849
time: 0.24805569648742676
time: 2.2014927864074707
[1, 4624] loss_train: 0.001456, loss_test: 0.005837
time: 0.2440659999847412
time: 2.206493616104126
[1, 4625] loss_train: 0.009722, loss_test: 0.005828
time: 0.24405503273010254
time: 2.1974902153015137
[1, 4626] loss_train: 0.000870, loss_test: 0.005822
time: 0.2450547218322754
time: 2.2340192794799805
[1, 4627] loss_train: 0.007226, loss_test: 0.005823
time: 0.24305415153503418
time: 2.220496892929077
[1, 4628] loss_train: 0.011789, loss_test: 0.005833
time: 0.25005555152893066
time: 2.196491003036499
[1, 4629] loss_train: 0.006460, loss_test: 0.005848
time: 0.24405384063720703
time: 2.227498769760132
[1, 4630] loss_train: 0.003043, loss_test: 0.005869
time: 0.25505614280700684
time: 2.2475030422210693
[1, 4631] loss_train: 0.002090, loss_test: 0.005899
time: 0.2450542449951172
time: 2.258521556854248
[1, 4632] loss_train: 0.003088, loss_test: 0.005931
time: 0.24405431747436523
time: 2.2285001277923584
[1, 4633] loss_train: 0.012941, loss_test: 0.005934
time: 0.24405407905578613
time: 2.243502378463745
[1, 4634] loss_train: 0.008523, loss_test: 0.005923
time: 0.24405455589294434
time: 2.223085641860962
[1, 4635] loss_train: 0.002960, loss_test: 0.005912
time: 0.24505352973937988
time: 2.2234978675842285
[1, 4636] loss_train: 0.011934, loss_test: 0.005901
time: 0.24405479431152344
time: 2.2136178016662598
[1, 4637] loss_train: 0.009713, loss_test: 0.005890
time: 0.24305391311645508
time: 2.236513614654541
[1, 4638] loss_train: 0.006272, loss_test: 0.005887
time: 0.2490546703338623
time: 2.209547758102417
[1, 4639] loss_train: 0.011164, loss_test: 0.005891
time: 0.2450547218322754
time: 2.2365000247955322
[1, 4640] loss_train: 0.011508, loss_test: 0.005902
time: 0.25905704498291016
time: 2.2975196838378906
[1, 4641] loss_train: 0.007926, loss_test: 0.005928
time: 0.24605441093444824
time: 2.2339789867401123
[1, 4642] loss_train: 0.003974, loss_test: 0.005955
time: 0.24805450439453125
time: 2.2505197525024414
[1, 4643] loss_train: 0.004346, loss_test: 0.005979
time: 0.24405431747436523
time: 2.230065107345581
[1, 4644] loss_train: 0.008449, loss_test: 0.005958
time: 0.24706721305847168
time: 2.2405014038085938
[1, 4645] loss_train: 0.011930, loss_test: 0.005940
time: 0.24505376815795898
time: 2.2320451736450195
[1, 4646] loss_train: 0.008362, loss_test: 0.005903
time: 0.2490551471710205
time: 2.2125041484832764
[1, 4647] loss_train: 0.005908, loss_test: 0.005852
time: 0.24405360221862793
time: 2.194491386413574
[1, 4648] loss_train: 0.008151, loss_test: 0.005822
time: 0.24605488777160645
time: 2.211494207382202
[1, 4649] loss_train: 0.008464, loss_test: 0.005806
time: 0.24405407905578613
time: 2.2125065326690674
[1, 4650] loss_train: 0.012748, loss_test: 0.005800
time: 0.25705766677856445
time: 2.2785086631774902
[1, 4651] loss_train: 0.006339, loss_test: 0.005800
time: 0.24405503273010254
time: 2.260505199432373
[1, 4652] loss_train: 0.005534, loss_test: 0.005803
time: 0.2450542449951172
time: 2.229498863220215
[1, 4653] loss_train: 0.011669, loss_test: 0.005811
time: 0.24205398559570312
time: 2.2180023193359375
[1, 4654] loss_train: 0.015342, loss_test: 0.005807
time: 0.2470548152923584
time: 2.2345163822174072
[1, 4655] loss_train: 0.001503, loss_test: 0.005811
time: 0.24305438995361328
time: 2.23449969291687
[1, 4656] loss_train: 0.007881, loss_test: 0.005820
time: 0.24405384063720703
time: 2.218496561050415
[1, 4657] loss_train: 0.006440, loss_test: 0.005828
time: 0.24605417251586914
time: 2.241502046585083
[1, 4658] loss_train: 0.002701, loss_test: 0.005842
time: 0.24406671524047852
time: 2.218496799468994
[1, 4659] loss_train: 0.007644, loss_test: 0.005853
time: 0.24405384063720703
time: 2.2346315383911133
[1, 4660] loss_train: 0.014452, loss_test: 0.005859
time: 0.2560572624206543
time: 2.2755086421966553
[1, 4661] loss_train: 0.004453, loss_test: 0.005867
time: 0.24405384063720703
time: 2.227498769760132
[1, 4662] loss_train: 0.005307, loss_test: 0.005875
time: 0.24605441093444824
time: 2.1985042095184326
[1, 4663] loss_train: 0.005166, loss_test: 0.005881
time: 0.2490549087524414
time: 2.207001209259033
[1, 4664] loss_train: 0.004502, loss_test: 0.005873
time: 0.2450544834136963
time: 2.2224972248077393
[1, 4665] loss_train: 0.006661, loss_test: 0.005861
time: 0.2470550537109375
time: 2.222498893737793
[1, 4666] loss_train: 0.004046, loss_test: 0.005846
time: 0.2450547218322754
time: 2.2135121822357178
[1, 4667] loss_train: 0.013914, loss_test: 0.005819
time: 0.24356627464294434
time: 2.2375011444091797
[1, 4668] loss_train: 0.008649, loss_test: 0.005805
time: 0.24305462837219238
time: 2.218512773513794
[1, 4669] loss_train: 0.014196, loss_test: 0.005799
time: 0.24607014656066895
time: 2.2595105171203613
[1, 4670] loss_train: 0.008665, loss_test: 0.005796
time: 0.2540562152862549
time: 2.2425031661987305
[1, 4671] loss_train: 0.007594, loss_test: 0.005794
time: 0.24405527114868164
time: 2.2525055408477783
[1, 4672] loss_train: 0.006052, loss_test: 0.005794
time: 0.24608135223388672
time: 2.260505199432373
[1, 4673] loss_train: 0.006218, loss_test: 0.005795
time: 0.24406743049621582
time: 2.2254977226257324
[1, 4674] loss_train: 0.003389, loss_test: 0.005801
time: 0.24305391311645508
time: 2.1874897480010986
[1, 4675] loss_train: 0.007308, loss_test: 0.005808
time: 0.24305367469787598
time: 2.244502305984497
[1, 4676] loss_train: 0.012521, loss_test: 0.005811
time: 0.24205446243286133
time: 2.23249888420105
[1, 4677] loss_train: 0.005330, loss_test: 0.005814
time: 0.24406814575195312
time: 2.2314987182617188
[1, 4678] loss_train: 0.010521, loss_test: 0.005834
time: 0.24406838417053223
time: 2.238499402999878
[1, 4679] loss_train: 0.009600, loss_test: 0.005848
time: 0.2470099925994873
time: 2.2915124893188477
[1, 4680] loss_train: 0.008102, loss_test: 0.005858
time: 0.26405811309814453
time: 2.2880167961120605
[1, 4681] loss_train: 0.003256, loss_test: 0.005870
time: 0.24811172485351562
time: 2.2254433631896973
[1, 4682] loss_train: 0.009719, loss_test: 0.005873
time: 0.2490551471710205
time: 2.2024922370910645
[1, 4683] loss_train: 0.005647, loss_test: 0.005877
time: 0.2420659065246582
time: 2.2254979610443115
[1, 4684] loss_train: 0.005524, loss_test: 0.005884
time: 0.24405407905578613
time: 2.2485055923461914
[1, 4685] loss_train: 0.011798, loss_test: 0.005881
time: 0.24405407905578613
time: 2.240504026412964
[1, 4686] loss_train: 0.003383, loss_test: 0.005881
time: 0.24305415153503418
time: 2.2085063457489014
[1, 4687] loss_train: 0.011124, loss_test: 0.005884
time: 0.24506878852844238
time: 2.222496747970581
[1, 4688] loss_train: 0.008048, loss_test: 0.005889
time: 0.24805498123168945
time: 2.203493595123291
[1, 4689] loss_train: 0.002223, loss_test: 0.005890
time: 0.2470548152923584
time: 2.2385013103485107
[1, 4690] loss_train: 0.008776, loss_test: 0.005883
time: 0.26105761528015137
time: 2.2505035400390625
[1, 4691] loss_train: 0.007871, loss_test: 0.005869
time: 0.24605512619018555
time: 2.210494041442871
[1, 4692] loss_train: 0.010751, loss_test: 0.005854
time: 0.2470545768737793
time: 2.2214975357055664
[1, 4693] loss_train: 0.014791, loss_test: 0.005847
time: 0.25005578994750977
time: 2.2360031604766846
[1, 4694] loss_train: 0.004233, loss_test: 0.005838
time: 0.24606633186340332
time: 2.2199981212615967
[1, 4695] loss_train: 0.002782, loss_test: 0.005827
time: 0.24305415153503418
time: 2.228498935699463
[1, 4696] loss_train: 0.006286, loss_test: 0.005817
time: 0.2470707893371582
time: 2.230498790740967
[1, 4697] loss_train: 0.008279, loss_test: 0.005809
time: 0.24305367469787598
time: 2.2355003356933594
[1, 4698] loss_train: 0.004184, loss_test: 0.005804
time: 0.25505733489990234
time: 2.2445015907287598
[1, 4699] loss_train: 0.004449, loss_test: 0.005801
time: 0.24579143524169922
time: 2.2264981269836426
[1, 4700] loss_train: 0.005050, loss_test: 0.005801
time: 0.2560567855834961
time: 2.283510684967041
[1, 4701] loss_train: 0.004522, loss_test: 0.005804
time: 0.24305391311645508
time: 2.24550199508667
[1, 4702] loss_train: 0.011315, loss_test: 0.005803
time: 0.24405384063720703
time: 2.2455027103424072
[1, 4703] loss_train: 0.008113, loss_test: 0.005806
time: 0.24305391311645508
time: 2.2375001907348633
[1, 4704] loss_train: 0.005182, loss_test: 0.005809
time: 0.24305438995361328
time: 2.234499931335449
[1, 4705] loss_train: 0.005916, loss_test: 0.005814
time: 0.24305367469787598
time: 2.2355000972747803
[1, 4706] loss_train: 0.007753, loss_test: 0.005823
time: 0.24505400657653809
time: 2.2325000762939453
[1, 4707] loss_train: 0.003666, loss_test: 0.005835
time: 0.24405360221862793
time: 2.212130069732666
[1, 4708] loss_train: 0.004772, loss_test: 0.005841
time: 0.24405384063720703
time: 2.2094969749450684
[1, 4709] loss_train: 0.002573, loss_test: 0.005848
time: 0.24205398559570312
time: 2.197510242462158
[1, 4710] loss_train: 0.008104, loss_test: 0.005851
time: 0.25505638122558594
time: 2.2244975566864014
[1, 4711] loss_train: 0.003040, loss_test: 0.005852
time: 0.2470550537109375
time: 2.206493616104126
[1, 4712] loss_train: 0.003517, loss_test: 0.005853
time: 0.24405455589294434
time: 2.219998359680176
[1, 4713] loss_train: 0.001088, loss_test: 0.005859
time: 0.252056360244751
time: 2.214494466781616
[1, 4714] loss_train: 0.018228, loss_test: 0.005849
time: 0.24405431747436523
time: 2.2735114097595215
[1, 4715] loss_train: 0.011159, loss_test: 0.005831
time: 0.2470552921295166
time: 2.2277982234954834
[1, 4716] loss_train: 0.005983, loss_test: 0.005820
time: 0.24405360221862793
time: 2.242501974105835
[1, 4717] loss_train: 0.010179, loss_test: 0.005811
time: 0.24505376815795898
time: 2.2234973907470703
[1, 4718] loss_train: 0.007850, loss_test: 0.005804
time: 0.24305415153503418
time: 2.223001480102539
[1, 4719] loss_train: 0.017292, loss_test: 0.005817
time: 0.24405407905578613
time: 2.218496561050415
[1, 4720] loss_train: 0.003817, loss_test: 0.005851
time: 0.2540571689605713
time: 2.283522129058838
[1, 4721] loss_train: 0.001932, loss_test: 0.005886
time: 0.2450542449951172
time: 2.2234976291656494
[1, 4722] loss_train: 0.001607, loss_test: 0.005909
time: 0.24505400657653809
time: 2.2365005016326904
[1, 4723] loss_train: 0.004239, loss_test: 0.005912
time: 0.2450547218322754
time: 2.224499464035034
[1, 4724] loss_train: 0.010544, loss_test: 0.005899
time: 0.24305391311645508
time: 2.205493450164795
[1, 4725] loss_train: 0.013370, loss_test: 0.005852
time: 0.24405479431152344
time: 2.208493947982788
[1, 4726] loss_train: 0.007223, loss_test: 0.005816
time: 0.24305415153503418
time: 2.220496892929077
[1, 4727] loss_train: 0.006827, loss_test: 0.005795
time: 0.24305367469787598
time: 2.2230005264282227
[1, 4728] loss_train: 0.008706, loss_test: 0.005790
time: 0.24305438995361328
time: 2.210493326187134
[1, 4729] loss_train: 0.008397, loss_test: 0.005800
time: 0.24405455589294434
time: 2.215496063232422
[1, 4730] loss_train: 0.008665, loss_test: 0.005824
time: 0.2620577812194824
time: 2.212495803833008
[1, 4731] loss_train: 0.004365, loss_test: 0.005855
time: 0.24805474281311035
time: 2.203495502471924
[1, 4732] loss_train: 0.007771, loss_test: 0.005877
time: 0.2490556240081787
time: 2.2034926414489746
[1, 4733] loss_train: 0.002856, loss_test: 0.005899
time: 0.24405360221862793
time: 2.215505838394165
[1, 4734] loss_train: 0.018068, loss_test: 0.005891
time: 0.24205374717712402
time: 2.2370169162750244
[1, 4735] loss_train: 0.009561, loss_test: 0.005845
time: 0.24409151077270508
time: 2.199510097503662
[1, 4736] loss_train: 0.011241, loss_test: 0.005819
time: 0.24405407905578613
time: 2.2244975566864014
[1, 4737] loss_train: 0.004554, loss_test: 0.005829
time: 0.24605417251586914
time: 2.2345001697540283
[1, 4738] loss_train: 0.005254, loss_test: 0.005860
time: 0.24405407905578613
time: 2.2540090084075928
[1, 4739] loss_train: 0.004592, loss_test: 0.005889
time: 0.24405455589294434
time: 2.258523941040039
[1, 4740] loss_train: 0.016386, loss_test: 0.005919
time: 0.2560572624206543
time: 2.272507905960083
[1, 4741] loss_train: 0.003827, loss_test: 0.005922
time: 0.24305415153503418
time: 2.234499216079712
[1, 4742] loss_train: 0.003277, loss_test: 0.005883
time: 0.24205327033996582
time: 2.229003429412842
[1, 4743] loss_train: 0.013161, loss_test: 0.005853
time: 0.24305319786071777
time: 2.228498935699463
[1, 4744] loss_train: 0.004487, loss_test: 0.005825
time: 0.24406719207763672
time: 2.2061245441436768
[1, 4745] loss_train: 0.001947, loss_test: 0.005811
time: 0.24406647682189941
time: 2.1984920501708984
[1, 4746] loss_train: 0.003266, loss_test: 0.005812
time: 0.24405336380004883
time: 2.2059998512268066
[1, 4747] loss_train: 0.012993, loss_test: 0.005822
time: 0.25005483627319336
time: 2.212508201599121
[1, 4748] loss_train: 0.002840, loss_test: 0.005838
time: 0.24605488777160645
time: 2.2375121116638184
[1, 4749] loss_train: 0.011137, loss_test: 0.005844
time: 0.2510552406311035
time: 2.2254984378814697
[1, 4750] loss_train: 0.003960, loss_test: 0.005851
time: 0.2580568790435791
time: 2.253523111343384
[1, 4751] loss_train: 0.006517, loss_test: 0.005859
time: 0.25005531311035156
time: 2.228498935699463
[1, 4752] loss_train: 0.007787, loss_test: 0.005865
time: 0.24305438995361328
time: 2.2635059356689453
[1, 4753] loss_train: 0.009294, loss_test: 0.005869
time: 0.24805521965026855
time: 2.258505344390869
[1, 4754] loss_train: 0.003500, loss_test: 0.005855
time: 0.24605369567871094
time: 2.2225074768066406
[1, 4755] loss_train: 0.006360, loss_test: 0.005839
time: 0.25005412101745605
time: 2.216496229171753
[1, 4756] loss_train: 0.005660, loss_test: 0.005828
time: 0.24405384063720703
time: 2.220506429672241
[1, 4757] loss_train: 0.009995, loss_test: 0.005823
time: 0.24605441093444824
time: 2.203996419906616
[1, 4758] loss_train: 0.007331, loss_test: 0.005822
time: 0.2450542449951172
time: 2.2264983654022217
[1, 4759] loss_train: 0.003750, loss_test: 0.005822
time: 0.24305391311645508
time: 2.250659704208374
[1, 4760] loss_train: 0.004606, loss_test: 0.005820
time: 0.2540562152862549
time: 2.2485032081604004
[1, 4761] loss_train: 0.010049, loss_test: 0.005820
time: 0.24505376815795898
time: 2.2134978771209717
[1, 4762] loss_train: 0.008383, loss_test: 0.005819
time: 0.24405407905578613
time: 2.239501476287842
[1, 4763] loss_train: 0.004139, loss_test: 0.005815
time: 0.24305343627929688
time: 2.2645068168640137
[1, 4764] loss_train: 0.013121, loss_test: 0.005811
time: 0.24405431747436523
time: 2.2435033321380615
[1, 4765] loss_train: 0.004020, loss_test: 0.005806
time: 0.24405479431152344
time: 2.2355000972747803
[1, 4766] loss_train: 0.005388, loss_test: 0.005807
time: 0.24305367469787598
time: 2.245023488998413
[1, 4767] loss_train: 0.004769, loss_test: 0.005815
time: 0.24406647682189941
time: 2.1864981651306152
[1, 4768] loss_train: 0.011025, loss_test: 0.005824
time: 0.2450547218322754
time: 2.196491003036499
[1, 4769] loss_train: 0.003985, loss_test: 0.005835
time: 0.2450547218322754
time: 2.213043689727783
[1, 4770] loss_train: 0.001308, loss_test: 0.005847
time: 0.2600581645965576
time: 2.2284982204437256
[1, 4771] loss_train: 0.001544, loss_test: 0.005861
time: 0.2490546703338623
time: 2.210496425628662
[1, 4772] loss_train: 0.003195, loss_test: 0.005871
time: 0.24805498123168945
time: 2.243502616882324
[1, 4773] loss_train: 0.005838, loss_test: 0.005873
time: 0.24605417251586914
time: 2.242501974105835
[1, 4774] loss_train: 0.005222, loss_test: 0.005865
time: 0.2490558624267578
time: 2.2105259895324707
[1, 4775] loss_train: 0.002714, loss_test: 0.005858
time: 0.24305319786071777
time: 2.2265257835388184
[1, 4776] loss_train: 0.001308, loss_test: 0.005852
time: 0.24605488777160645
time: 2.2395074367523193
[1, 4777] loss_train: 0.003717, loss_test: 0.005847
time: 0.25205564498901367
time: 2.2425119876861572
[1, 4778] loss_train: 0.006079, loss_test: 0.005839
time: 0.24205446243286133
time: 2.25750470161438
[1, 4779] loss_train: 0.008701, loss_test: 0.005827
time: 0.2440659999847412
time: 2.2235267162323
[1, 4780] loss_train: 0.003500, loss_test: 0.005822
time: 0.25505614280700684
time: 2.2204976081848145
[1, 4781] loss_train: 0.009159, loss_test: 0.005817
time: 0.24305319786071777
time: 2.2495036125183105
[1, 4782] loss_train: 0.011037, loss_test: 0.005806
time: 0.24406671524047852
time: 2.195490837097168
[1, 4783] loss_train: 0.010512, loss_test: 0.005810
time: 0.24405479431152344
time: 2.2154948711395264
[1, 4784] loss_train: 0.017162, loss_test: 0.005842
time: 0.24606657028198242
time: 2.2114949226379395
[1, 4785] loss_train: 0.010707, loss_test: 0.005889
time: 0.24405384063720703
time: 2.2245066165924072
[1, 4786] loss_train: 0.006931, loss_test: 0.005943
time: 0.24205422401428223
time: 2.250009059906006
[1, 4787] loss_train: 0.009912, loss_test: 0.005970
time: 0.24305438995361328
time: 2.218496322631836
[1, 4788] loss_train: 0.011154, loss_test: 0.005994
time: 0.24506640434265137
time: 2.243501901626587
[1, 4789] loss_train: 0.005935, loss_test: 0.006022
time: 0.2435920238494873
time: 2.204998254776001
[1, 4790] loss_train: 0.006997, loss_test: 0.006032
time: 0.2560572624206543
time: 2.2635228633880615
[1, 4791] loss_train: 0.006842, loss_test: 0.006028
time: 0.25305604934692383
time: 2.2015135288238525
[1, 4792] loss_train: 0.002685, loss_test: 0.006030
time: 0.24405384063720703
time: 2.204493522644043
[1, 4793] loss_train: 0.003724, loss_test: 0.006019
time: 0.2490558624267578
time: 2.2405004501342773
[1, 4794] loss_train: 0.005746, loss_test: 0.005991
time: 0.24605512619018555
time: 2.2184958457946777
[1, 4795] loss_train: 0.008096, loss_test: 0.005973
time: 0.24405407905578613
time: 2.207522392272949
[1, 4796] loss_train: 0.006542, loss_test: 0.005947
time: 0.24305367469787598
time: 2.23250412940979
[1, 4797] loss_train: 0.014329, loss_test: 0.005928
time: 0.2470548152923584
time: 2.2525057792663574
[1, 4798] loss_train: 0.005212, loss_test: 0.005910
time: 0.24405384063720703
time: 2.2345030307769775
[1, 4799] loss_train: 0.009567, loss_test: 0.005884
time: 0.24205350875854492
time: 2.2355027198791504
[1, 4800] loss_train: 0.006527, loss_test: 0.005862
time: 0.25705671310424805
time: 2.2575056552886963
[1, 4801] loss_train: 0.007883, loss_test: 0.005848
time: 0.24505352973937988
time: 2.2425034046173096
[1, 4802] loss_train: 0.007433, loss_test: 0.005832
time: 0.24308466911315918
time: 2.284512996673584
[1, 4803] loss_train: 0.007809, loss_test: 0.005816
time: 0.24405503273010254
time: 2.2395002841949463
[1, 4804] loss_train: 0.009914, loss_test: 0.005812
time: 0.24805450439453125
time: 2.258509635925293
[1, 4805] loss_train: 0.005364, loss_test: 0.005831
time: 0.24406719207763672
time: 2.234358787536621
[1, 4806] loss_train: 0.005035, loss_test: 0.005866
time: 0.24305438995361328
time: 2.22149658203125
[1, 4807] loss_train: 0.004697, loss_test: 0.005903
time: 0.2450547218322754
time: 2.242037057876587
[1, 4808] loss_train: 0.005659, loss_test: 0.005928
time: 0.24205279350280762
time: 2.2114951610565186
[1, 4809] loss_train: 0.006005, loss_test: 0.005930
time: 0.24405384063720703
time: 2.2555577754974365
[1, 4810] loss_train: 0.003350, loss_test: 0.005920
time: 0.25305652618408203
time: 2.250502824783325
[1, 4811] loss_train: 0.006369, loss_test: 0.005893
time: 0.2450547218322754
time: 2.2535312175750732
[1, 4812] loss_train: 0.007859, loss_test: 0.005866
time: 0.24305486679077148
time: 2.2450058460235596
[1, 4813] loss_train: 0.008203, loss_test: 0.005836
time: 0.24505400657653809
time: 2.2395031452178955
[1, 4814] loss_train: 0.004993, loss_test: 0.005820
time: 0.24605536460876465
time: 2.2435126304626465
[1, 4815] loss_train: 0.003511, loss_test: 0.005819
time: 0.24605154991149902
time: 2.2144951820373535
[1, 4816] loss_train: 0.009090, loss_test: 0.005828
time: 0.24405360221862793
time: 2.2124955654144287
[1, 4817] loss_train: 0.008675, loss_test: 0.005835
time: 0.24445605278015137
time: 2.206493377685547
[1, 4818] loss_train: 0.009629, loss_test: 0.005844
time: 0.2470545768737793
time: 2.2114949226379395
[1, 4819] loss_train: 0.004912, loss_test: 0.005853
time: 0.24605441093444824
time: 2.2215211391448975
[1, 4820] loss_train: 0.007840, loss_test: 0.005856
time: 0.2620577812194824
time: 2.2620089054107666
[1, 4821] loss_train: 0.009015, loss_test: 0.005859
time: 0.2510559558868408
time: 2.2515037059783936
[1, 4822] loss_train: 0.001634, loss_test: 0.005866
time: 0.24906039237976074
time: 2.2555062770843506
[1, 4823] loss_train: 0.016639, loss_test: 0.005850
time: 0.24405455589294434
time: 2.2485198974609375
[1, 4824] loss_train: 0.000923, loss_test: 0.005842
time: 0.25206875801086426
time: 2.245006799697876
[1, 4825] loss_train: 0.010490, loss_test: 0.005836
time: 0.24605512619018555
time: 2.2362704277038574
[1, 4826] loss_train: 0.010702, loss_test: 0.005836
time: 0.24805498123168945
time: 2.2385001182556152
[1, 4827] loss_train: 0.007427, loss_test: 0.005846
time: 0.24405455589294434
time: 2.2174954414367676
[1, 4828] loss_train: 0.014692, loss_test: 0.005874
time: 0.2465801239013672
time: 2.250502586364746
[1, 4829] loss_train: 0.003534, loss_test: 0.005892
time: 0.24405479431152344
time: 2.224505662918091
[1, 4830] loss_train: 0.002980, loss_test: 0.005902
time: 0.25705647468566895
time: 2.260512351989746
[1, 4831] loss_train: 0.006828, loss_test: 0.005900
time: 0.24305438995361328
time: 2.207493543624878
[1, 4832] loss_train: 0.002701, loss_test: 0.005892
time: 0.2450547218322754
time: 2.233499050140381
[1, 4833] loss_train: 0.008497, loss_test: 0.005850
time: 0.24505615234375
time: 2.2335000038146973
[1, 4834] loss_train: 0.003816, loss_test: 0.005808
time: 0.24808144569396973
time: 2.2385013103485107
[1, 4835] loss_train: 0.006854, loss_test: 0.005792
time: 0.24405360221862793
time: 2.217496395111084
[1, 4836] loss_train: 0.007660, loss_test: 0.005802
time: 0.24306964874267578
time: 2.2490291595458984
[1, 4837] loss_train: 0.008307, loss_test: 0.005830
time: 0.24205446243286133
time: 2.2295165061950684
[1, 4838] loss_train: 0.003672, loss_test: 0.005872
time: 0.24305367469787598
time: 2.2144954204559326
[1, 4839] loss_train: 0.003927, loss_test: 0.005917
time: 0.2450547218322754
time: 2.2185051441192627
[1, 4840] loss_train: 0.013149, loss_test: 0.005933
time: 0.25507211685180664
time: 2.231497287750244
[1, 4841] loss_train: 0.011077, loss_test: 0.005913
time: 0.24605441093444824
time: 2.22649884223938
[1, 4842] loss_train: 0.002936, loss_test: 0.005891
time: 0.2450549602508545
time: 2.258504629135132
[1, 4843] loss_train: 0.003215, loss_test: 0.005870
time: 0.2450549602508545
time: 2.2034924030303955
[1, 4844] loss_train: 0.006490, loss_test: 0.005844
time: 0.2450542449951172
time: 2.216505765914917
[1, 4845] loss_train: 0.009835, loss_test: 0.005838
time: 0.24605393409729004
time: 2.217496395111084
[1, 4846] loss_train: 0.005318, loss_test: 0.005833
time: 0.2450542449951172
time: 2.221001625061035
[1, 4847] loss_train: 0.003701, loss_test: 0.005835
time: 0.24805498123168945
time: 2.2274982929229736
[1, 4848] loss_train: 0.005985, loss_test: 0.005841
time: 0.24405455589294434
time: 2.222020149230957
[1, 4849] loss_train: 0.008526, loss_test: 0.005844
time: 0.2450547218322754
time: 2.258505344390869
[1, 4850] loss_train: 0.002315, loss_test: 0.005841
time: 0.2560732364654541
time: 2.262507438659668
[1, 4851] loss_train: 0.008727, loss_test: 0.005835
time: 0.25005555152893066
time: 2.2365000247955322
[1, 4852] loss_train: 0.005183, loss_test: 0.005832
time: 0.24405431747436523
time: 2.2264981269836426
[1, 4853] loss_train: 0.012414, loss_test: 0.005829
time: 0.24305319786071777
time: 2.2274985313415527
[1, 4854] loss_train: 0.005542, loss_test: 0.005826
time: 0.2450542449951172
time: 2.2315151691436768
[1, 4855] loss_train: 0.010828, loss_test: 0.005822
time: 0.24405908584594727
time: 2.2755086421966553
[1, 4856] loss_train: 0.010639, loss_test: 0.005811
time: 0.24258136749267578
time: 2.2241787910461426
[1, 4857] loss_train: 0.004190, loss_test: 0.005803
time: 0.24505376815795898
time: 2.2865118980407715
[1, 4858] loss_train: 0.008799, loss_test: 0.005797
time: 0.24305438995361328
time: 2.2125048637390137
[1, 4859] loss_train: 0.000659, loss_test: 0.005796
time: 0.24405431747436523
time: 2.2375001907348633
[1, 4860] loss_train: 0.003703, loss_test: 0.005796
time: 0.2540559768676758
time: 2.2730209827423096
[1, 4861] loss_train: 0.002182, loss_test: 0.005799
time: 0.2450549602508545
time: 2.218496322631836
[1, 4862] loss_train: 0.000679, loss_test: 0.005802
time: 0.24406647682189941
time: 2.281510353088379
[1, 4863] loss_train: 0.004018, loss_test: 0.005810
time: 0.24305367469787598
time: 2.235499858856201
[1, 4864] loss_train: 0.015888, loss_test: 0.005802
time: 0.24605393409729004
time: 2.230499505996704
[1, 4865] loss_train: 0.002841, loss_test: 0.005799
time: 0.24305462837219238
time: 2.2225043773651123
[1, 4866] loss_train: 0.016129, loss_test: 0.005798
time: 0.24305462837219238
time: 2.2344985008239746
[1, 4867] loss_train: 0.007586, loss_test: 0.005797
time: 0.24605512619018555
time: 2.2465028762817383
[1, 4868] loss_train: 0.005071, loss_test: 0.005796
time: 0.24505400657653809
time: 2.2335000038146973
[1, 4869] loss_train: 0.008828, loss_test: 0.005795
time: 0.24409270286560059
time: 2.2124977111816406
[1, 4870] loss_train: 0.005930, loss_test: 0.005792
time: 0.25705671310424805
time: 2.2365007400512695
[1, 4871] loss_train: 0.012348, loss_test: 0.005795
time: 0.24505329132080078
time: 2.221497058868408
[1, 4872] loss_train: 0.006508, loss_test: 0.005795
time: 0.24405360221862793
time: 2.221497058868408
[1, 4873] loss_train: 0.004227, loss_test: 0.005796
time: 0.2450551986694336
time: 2.2034921646118164
[1, 4874] loss_train: 0.011238, loss_test: 0.005802
time: 0.2490556240081787
time: 2.2565042972564697
[1, 4875] loss_train: 0.014287, loss_test: 0.005808
time: 0.24406743049621582
time: 2.206493616104126
[1, 4876] loss_train: 0.002494, loss_test: 0.005815
time: 0.2510561943054199
time: 2.215519428253174
[1, 4877] loss_train: 0.002701, loss_test: 0.005819
time: 0.2450551986694336
time: 2.2244973182678223
[1, 4878] loss_train: 0.011625, loss_test: 0.005820
time: 0.24805426597595215
time: 2.192490816116333
[1, 4879] loss_train: 0.011813, loss_test: 0.005813
time: 0.24405360221862793
time: 2.2224974632263184
[1, 4880] loss_train: 0.006475, loss_test: 0.005810
time: 0.25705695152282715
time: 2.258523464202881
[1, 4881] loss_train: 0.004968, loss_test: 0.005813
time: 0.2450542449951172
time: 2.257520914077759
[1, 4882] loss_train: 0.004874, loss_test: 0.005823
time: 0.24506640434265137
time: 2.22153639793396
[1, 4883] loss_train: 0.008023, loss_test: 0.005841
time: 0.24405384063720703
time: 2.2615063190460205
[1, 4884] loss_train: 0.016984, loss_test: 0.005865
time: 0.24305367469787598
time: 2.2285006046295166
[1, 4885] loss_train: 0.001796, loss_test: 0.005896
time: 0.24305343627929688
time: 2.217000722885132
[1, 4886] loss_train: 0.005542, loss_test: 0.005924
time: 0.24405479431152344
time: 2.2465009689331055
[1, 4887] loss_train: 0.002865, loss_test: 0.005957
time: 0.24405503273010254
time: 2.2134952545166016
[1, 4888] loss_train: 0.000544, loss_test: 0.005994
time: 0.24605417251586914
time: 2.2250261306762695
[1, 4889] loss_train: 0.000496, loss_test: 0.006039
time: 0.24405384063720703
time: 2.220496892929077
[1, 4890] loss_train: 0.005490, loss_test: 0.006071
time: 0.25505685806274414
time: 2.2475028038024902
[1, 4891] loss_train: 0.007632, loss_test: 0.006086
time: 0.24405384063720703
time: 2.231499671936035
[1, 4892] loss_train: 0.014474, loss_test: 0.006101
time: 0.24405360221862793
time: 2.2124977111816406
[1, 4893] loss_train: 0.005255, loss_test: 0.006111
time: 0.2470557689666748
time: 2.2385008335113525
[1, 4894] loss_train: 0.015750, loss_test: 0.006103
time: 0.24405479431152344
time: 2.219026803970337
[1, 4895] loss_train: 0.004729, loss_test: 0.006101
time: 0.25105714797973633
time: 2.2405004501342773
[1, 4896] loss_train: 0.005355, loss_test: 0.006084
time: 0.24305343627929688
time: 2.223022937774658
[1, 4897] loss_train: 0.003715, loss_test: 0.005953
time: 0.2490551471710205
time: 2.2140052318573
[1, 4898] loss_train: 0.006436, loss_test: 0.005878
time: 0.25905752182006836
time: 2.299516201019287
[1, 4899] loss_train: 0.005607, loss_test: 0.005836
time: 0.2510554790496826
time: 2.2495033740997314
[1, 4900] loss_train: 0.008513, loss_test: 0.005816
time: 0.257080078125
time: 2.245499610900879
[1, 4901] loss_train: 0.011856, loss_test: 0.005809
time: 0.2540562152862549
time: 2.2144949436187744
[1, 4902] loss_train: 0.007528, loss_test: 0.005829
time: 0.24805474281311035
time: 2.228498935699463
[1, 4903] loss_train: 0.007582, loss_test: 0.005863
time: 0.2490553855895996
time: 2.235499858856201
[1, 4904] loss_train: 0.001729, loss_test: 0.005907
time: 0.24405455589294434
time: 2.2045083045959473
[1, 4905] loss_train: 0.007217, loss_test: 0.005942
time: 0.24605488777160645
time: 2.2024924755096436
[1, 4906] loss_train: 0.003240, loss_test: 0.005966
time: 0.24305319786071777
time: 2.2505040168762207
[1, 4907] loss_train: 0.010491, loss_test: 0.005978
time: 0.24406957626342773
time: 2.2094948291778564
[1, 4908] loss_train: 0.001850, loss_test: 0.005986
time: 0.2530553340911865
time: 2.2745091915130615
[1, 4909] loss_train: 0.003220, loss_test: 0.005997
time: 0.24405431747436523
time: 2.20949387550354
[1, 4910] loss_train: 0.001695, loss_test: 0.006004
time: 0.2560572624206543
time: 2.249502658843994
[1, 4911] loss_train: 0.002191, loss_test: 0.006019
time: 0.2450544834136963
time: 2.2505033016204834
[1, 4912] loss_train: 0.003309, loss_test: 0.006026
time: 0.24605488777160645
time: 2.204493284225464
[1, 4913] loss_train: 0.004910, loss_test: 0.006021
time: 0.24305486679077148
time: 2.233003616333008
[1, 4914] loss_train: 0.008524, loss_test: 0.005998
time: 0.24505400657653809
time: 2.221497058868408
[1, 4915] loss_train: 0.005714, loss_test: 0.005971
time: 0.24206972122192383
time: 2.2124953269958496
[1, 4916] loss_train: 0.004254, loss_test: 0.005947
time: 0.24405550956726074
time: 2.182488203048706
[1, 4917] loss_train: 0.004087, loss_test: 0.005927
time: 0.24605441093444824
time: 2.229499578475952
[1, 4918] loss_train: 0.001482, loss_test: 0.005913
time: 0.24805426597595215
time: 2.2425146102905273
[1, 4919] loss_train: 0.007167, loss_test: 0.005899
time: 0.24505400657653809
time: 2.2480149269104004
[1, 4920] loss_train: 0.005701, loss_test: 0.005885
time: 0.2600569725036621
time: 2.2715089321136475
[1, 4921] loss_train: 0.014464, loss_test: 0.005868
time: 0.24405479431152344
time: 2.2464351654052734
[1, 4922] loss_train: 0.011212, loss_test: 0.005849
time: 0.2490556240081787
time: 2.2345190048217773
[1, 4923] loss_train: 0.017717, loss_test: 0.005847
time: 0.24405312538146973
time: 2.220423460006714
[1, 4924] loss_train: 0.004571, loss_test: 0.005858
time: 0.2490553855895996
time: 2.2124969959259033
[1, 4925] loss_train: 0.006588, loss_test: 0.005866
time: 0.24405360221862793
time: 2.214495897293091
[1, 4926] loss_train: 0.010332, loss_test: 0.005882
time: 0.2470543384552002
time: 2.2385032176971436
[1, 4927] loss_train: 0.008306, loss_test: 0.005890
time: 0.24505376815795898
time: 2.2645070552825928
[1, 4928] loss_train: 0.004246, loss_test: 0.005888
time: 0.24806714057922363
time: 2.220496654510498
[1, 4929] loss_train: 0.005615, loss_test: 0.005874
time: 0.24507761001586914
time: 2.2375001907348633
[1, 4930] loss_train: 0.007765, loss_test: 0.005863
time: 0.25408172607421875
time: 2.2795114517211914
[1, 4931] loss_train: 0.004700, loss_test: 0.005854
time: 0.24405431747436523
time: 2.233499526977539
[1, 4932] loss_train: 0.007827, loss_test: 0.005851
time: 0.24305367469787598
time: 2.228499412536621
[1, 4933] loss_train: 0.006901, loss_test: 0.005849
time: 0.24306678771972656
time: 2.233499765396118
[1, 4934] loss_train: 0.005246, loss_test: 0.005854
time: 0.24205350875854492
time: 2.2345120906829834
[1, 4935] loss_train: 0.003749, loss_test: 0.005863
time: 0.24305462837219238
time: 2.2294981479644775
[1, 4936] loss_train: 0.008760, loss_test: 0.005875
time: 0.2450542449951172
time: 2.216495990753174
[1, 4937] loss_train: 0.003973, loss_test: 0.005893
time: 0.24305367469787598
time: 2.2045042514801025
[1, 4938] loss_train: 0.002782, loss_test: 0.005916
time: 0.24405455589294434
time: 2.2284982204437256
[1, 4939] loss_train: 0.003823, loss_test: 0.005936
time: 0.24605488777160645
time: 2.2200334072113037
[1, 4940] loss_train: 0.008261, loss_test: 0.005915
time: 0.2540559768676758
time: 2.2134957313537598
[1, 4941] loss_train: 0.005154, loss_test: 0.005887
time: 0.24805498123168945
time: 2.2375001907348633
[1, 4942] loss_train: 0.010631, loss_test: 0.005856
time: 0.24505400657653809
time: 2.2355003356933594
[1, 4943] loss_train: 0.005328, loss_test: 0.005830
time: 0.24405384063720703
time: 2.2585058212280273
[1, 4944] loss_train: 0.006695, loss_test: 0.005814
time: 0.24406671524047852
time: 2.217495918273926
[1, 4945] loss_train: 0.005693, loss_test: 0.005803
time: 0.2490551471710205
time: 2.211514949798584
[1, 4946] loss_train: 0.007505, loss_test: 0.005795
time: 0.24405455589294434
time: 2.2178874015808105
[1, 4947] loss_train: 0.003674, loss_test: 0.005792
time: 0.24805569648742676
time: 2.2455015182495117
[1, 4948] loss_train: 0.007803, loss_test: 0.005795
time: 0.24305105209350586
time: 2.235499858856201
[1, 4949] loss_train: 0.007906, loss_test: 0.005802
time: 0.24701809883117676
time: 2.218496561050415
[1, 4950] loss_train: 0.002200, loss_test: 0.005807
time: 0.25505685806274414
time: 2.2264978885650635
[1, 4951] loss_train: 0.007284, loss_test: 0.005810
time: 0.24305415153503418
time: 2.2134950160980225
[1, 4952] loss_train: 0.002847, loss_test: 0.005809
time: 0.24305391311645508
time: 2.1924901008605957
[1, 4953] loss_train: 0.007736, loss_test: 0.005809
time: 0.24305462837219238
time: 2.229499101638794
[1, 4954] loss_train: 0.010766, loss_test: 0.005811
time: 0.2450544834136963
time: 2.247502565383911
[1, 4955] loss_train: 0.002873, loss_test: 0.005814
time: 0.24405407905578613
time: 2.2175216674804688
[1, 4956] loss_train: 0.007848, loss_test: 0.005816
time: 0.24505376815795898
time: 2.192492723464966
[1, 4957] loss_train: 0.006117, loss_test: 0.005818
time: 0.24405455589294434
time: 2.229512929916382
[1, 4958] loss_train: 0.021101, loss_test: 0.005812
time: 0.24507832527160645
time: 2.2134954929351807
[1, 4959] loss_train: 0.007094, loss_test: 0.005808
time: 0.2470543384552002
time: 2.1892573833465576
[1, 4960] loss_train: 0.006917, loss_test: 0.005805
time: 0.2600574493408203
time: 2.2525041103363037
[1, 4961] loss_train: 0.010020, loss_test: 0.005806
time: 0.2450549602508545
time: 2.2445013523101807
[1, 4962] loss_train: 0.003722, loss_test: 0.005800
time: 0.25005507469177246
time: 2.2194998264312744
[1, 4963] loss_train: 0.008378, loss_test: 0.005795
time: 0.24405336380004883
time: 2.232499837875366
[1, 4964] loss_train: 0.019774, loss_test: 0.005794
time: 0.2470543384552002
time: 2.2465033531188965
[1, 4965] loss_train: 0.014973, loss_test: 0.005798
time: 0.24405336380004883
time: 2.219022750854492
[1, 4966] loss_train: 0.007375, loss_test: 0.005808
time: 0.24806785583496094
time: 2.2354989051818848
[1, 4967] loss_train: 0.014110, loss_test: 0.005808
time: 0.24506735801696777
time: 2.221008062362671
[1, 4968] loss_train: 0.006409, loss_test: 0.005804
time: 0.24305391311645508
time: 2.2144949436187744
[1, 4969] loss_train: 0.002616, loss_test: 0.005798
time: 0.24305438995361328
time: 2.2065141201019287
[1, 4970] loss_train: 0.003101, loss_test: 0.005792
time: 0.25408053398132324
time: 2.2505037784576416
[1, 4971] loss_train: 0.003546, loss_test: 0.005788
time: 0.24606752395629883
time: 2.226506471633911
[1, 4972] loss_train: 0.004791, loss_test: 0.005786
time: 0.2430555820465088
time: 2.249502182006836
[1, 4973] loss_train: 0.003104, loss_test: 0.005790
time: 0.24506735801696777
time: 2.208496332168579
[1, 4974] loss_train: 0.004856, loss_test: 0.005799
time: 0.24506926536560059
time: 2.2244973182678223
[1, 4975] loss_train: 0.009319, loss_test: 0.005805
time: 0.24305295944213867
time: 2.207493543624878
[1, 4976] loss_train: 0.007380, loss_test: 0.005801
time: 0.24805545806884766
time: 2.230499267578125
[1, 4977] loss_train: 0.008130, loss_test: 0.005799
time: 0.24506735801696777
time: 2.2215166091918945
[1, 4978] loss_train: 0.005413, loss_test: 0.005800
time: 0.24405455589294434
time: 2.1924898624420166
[1, 4979] loss_train: 0.010025, loss_test: 0.005797
time: 0.2490551471710205
time: 2.2242774963378906
[1, 4980] loss_train: 0.001468, loss_test: 0.005800
time: 0.25905799865722656
time: 2.266521692276001
[1, 4981] loss_train: 0.014460, loss_test: 0.005803
time: 0.25205564498901367
time: 2.2274982929229736
[1, 4982] loss_train: 0.002021, loss_test: 0.005807
time: 0.2450556755065918
time: 2.2314984798431396
[1, 4983] loss_train: 0.002632, loss_test: 0.005810
time: 0.2470545768737793
time: 2.2335000038146973
[1, 4984] loss_train: 0.010168, loss_test: 0.005811
time: 0.24305343627929688
time: 2.2345123291015625
[1, 4985] loss_train: 0.010030, loss_test: 0.005809
time: 0.2450544834136963
time: 2.252521514892578
[1, 4986] loss_train: 0.008326, loss_test: 0.005808
time: 0.24605512619018555
time: 2.2585043907165527
[1, 4987] loss_train: 0.008736, loss_test: 0.005812
time: 0.24505400657653809
time: 2.2275006771087646
[1, 4988] loss_train: 0.006418, loss_test: 0.005816
time: 0.24205803871154785
time: 2.2034924030303955
[1, 4989] loss_train: 0.004600, loss_test: 0.005815
time: 0.24506711959838867
time: 2.2220075130462646
[1, 4990] loss_train: 0.008132, loss_test: 0.005814
time: 0.2540559768676758
time: 2.2995147705078125
[1, 4991] loss_train: 0.011895, loss_test: 0.005811
time: 0.24305367469787598
time: 2.2535042762756348
[1, 4992] loss_train: 0.003615, loss_test: 0.005807
time: 0.24206948280334473
time: 2.2234978675842285
[1, 4993] loss_train: 0.004585, loss_test: 0.005799
time: 0.24405384063720703
time: 2.24650239944458
[1, 4994] loss_train: 0.007262, loss_test: 0.005793
time: 0.24405479431152344
time: 2.2274978160858154
[1, 4995] loss_train: 0.001142, loss_test: 0.005788
time: 0.24305415153503418
time: 2.2315104007720947
[1, 4996] loss_train: 0.006126, loss_test: 0.005789
time: 0.24805545806884766
time: 2.246520519256592
[1, 4997] loss_train: 0.007526, loss_test: 0.005788
time: 0.24305391311645508
time: 2.2154958248138428
[1, 4998] loss_train: 0.005848, loss_test: 0.005788
time: 0.24405360221862793
time: 2.2170162200927734
[1, 4999] loss_train: 0.005166, loss_test: 0.005787
time: 0.24405360221862793
time: 2.2085108757019043
[1, 5000] loss_train: 0.012986, loss_test: 0.005785
time: 0.25507020950317383
time: 2.2775096893310547
[1, 5001] loss_train: 0.008639, loss_test: 0.005785
time: 0.2450542449951172
time: 2.2234978675842285
[1, 5002] loss_train: 0.007432, loss_test: 0.005786
time: 0.25005555152893066
time: 2.236004114151001
[1, 5003] loss_train: 0.004574, loss_test: 0.005786
time: 0.24305486679077148
time: 2.2294981479644775
[1, 5004] loss_train: 0.010070, loss_test: 0.005788
time: 0.24505376815795898
time: 2.227498769760132
[1, 5005] loss_train: 0.003186, loss_test: 0.005792
time: 0.24305367469787598
time: 2.200507879257202
[1, 5006] loss_train: 0.015062, loss_test: 0.005793
time: 0.25005578994750977
time: 2.2154951095581055
[1, 5007] loss_train: 0.003419, loss_test: 0.005794
time: 0.2470552921295166
time: 2.224496603012085
[1, 5008] loss_train: 0.003855, loss_test: 0.005795
time: 0.24805617332458496
time: 2.2405178546905518
[1, 5009] loss_train: 0.005975, loss_test: 0.005796
time: 0.2450542449951172
time: 2.2025034427642822
[1, 5010] loss_train: 0.004982, loss_test: 0.005798
time: 0.2540562152862549
time: 2.2104949951171875
[1, 5011] loss_train: 0.000666, loss_test: 0.005804
time: 0.2450542449951172
time: 2.2215566635131836
[1, 5012] loss_train: 0.005825, loss_test: 0.005810
time: 0.24205327033996582
time: 2.2034926414489746
[1, 5013] loss_train: 0.017497, loss_test: 0.005812
time: 0.2450544834136963
time: 2.2204995155334473
[1, 5014] loss_train: 0.005350, loss_test: 0.005812
time: 0.24405360221862793
time: 2.2585055828094482
[1, 5015] loss_train: 0.003831, loss_test: 0.005812
time: 0.24305367469787598
time: 2.2234976291656494
[1, 5016] loss_train: 0.011396, loss_test: 0.005802
time: 0.2420656681060791
time: 2.239023208618164
[1, 5017] loss_train: 0.003549, loss_test: 0.005797
time: 0.24406766891479492
time: 2.247502326965332
[1, 5018] loss_train: 0.007141, loss_test: 0.005796
time: 0.24273896217346191
time: 2.1984918117523193
[1, 5019] loss_train: 0.001638, loss_test: 0.005796
time: 0.24405407905578613
time: 2.2310216426849365
[1, 5020] loss_train: 0.008565, loss_test: 0.005795
time: 0.2580568790435791
time: 2.2460105419158936
[1, 5021] loss_train: 0.016219, loss_test: 0.005793
time: 0.2450549602508545
time: 2.2154951095581055
[1, 5022] loss_train: 0.005952, loss_test: 0.005796
time: 0.24405360221862793
time: 2.2144978046417236
[1, 5023] loss_train: 0.002895, loss_test: 0.005799
time: 0.2490549087524414
time: 2.2004926204681396
[1, 5024] loss_train: 0.014643, loss_test: 0.005801
time: 0.24405384063720703
time: 2.215522289276123
[1, 5025] loss_train: 0.014519, loss_test: 0.005809
time: 0.24805474281311035
time: 2.204493522644043
[1, 5026] loss_train: 0.008846, loss_test: 0.005817
time: 0.24409842491149902
time: 2.190502166748047
[1, 5027] loss_train: 0.003587, loss_test: 0.005825
time: 0.24405527114868164
time: 2.223496913909912
[1, 5028] loss_train: 0.007292, loss_test: 0.005829
time: 0.24305415153503418
time: 2.2360174655914307
[1, 5029] loss_train: 0.010770, loss_test: 0.005821
time: 0.24305367469787598
time: 2.2224977016448975
[1, 5030] loss_train: 0.007132, loss_test: 0.005814
time: 0.25505661964416504
time: 2.258507490158081
[1, 5031] loss_train: 0.005249, loss_test: 0.005802
time: 0.24305415153503418
time: 2.251504421234131
[1, 5032] loss_train: 0.004198, loss_test: 0.005790
time: 0.2450544834136963
time: 2.2184958457946777
[1, 5033] loss_train: 0.006525, loss_test: 0.005784
time: 0.24405455589294434
time: 2.22049617767334
[1, 5034] loss_train: 0.005115, loss_test: 0.005783
time: 0.2450549602508545
time: 2.211503505706787
[1, 5035] loss_train: 0.007979, loss_test: 0.005781
time: 0.24205279350280762
time: 2.2054941654205322
[1, 5036] loss_train: 0.011634, loss_test: 0.005778
time: 0.24406743049621582
time: 2.2134947776794434
[1, 5037] loss_train: 0.008104, loss_test: 0.005774
time: 0.24405455589294434
time: 2.2044920921325684
[1, 5038] loss_train: 0.008163, loss_test: 0.005772
time: 0.24907445907592773
time: 2.246006727218628
[1, 5039] loss_train: 0.006490, loss_test: 0.005772
time: 0.2450547218322754
time: 2.2044930458068848
[1, 5040] loss_train: 0.007091, loss_test: 0.005774
time: 0.26105761528015137
time: 2.266507148742676
[1, 5041] loss_train: 0.006832, loss_test: 0.005777
time: 0.24505400657653809
time: 2.253504514694214
[1, 5042] loss_train: 0.016847, loss_test: 0.005780
time: 0.25005555152893066
time: 2.25850510597229
[1, 5043] loss_train: 0.014787, loss_test: 0.005782
time: 0.2450547218322754
time: 2.2545039653778076
[1, 5044] loss_train: 0.005843, loss_test: 0.005784
time: 0.2510557174682617
time: 2.2334988117218018
[1, 5045] loss_train: 0.004374, loss_test: 0.005788
time: 0.24405384063720703
time: 2.2225136756896973
[1, 5046] loss_train: 0.002105, loss_test: 0.005792
time: 0.24405407905578613
time: 2.2465028762817383
[1, 5047] loss_train: 0.012364, loss_test: 0.005787
time: 0.24605417251586914
time: 2.2104949951171875
[1, 5048] loss_train: 0.002267, loss_test: 0.005784
time: 0.24205422401428223
time: 2.2234978675842285
[1, 5049] loss_train: 0.006556, loss_test: 0.005782
time: 0.24258995056152344
time: 2.228498935699463
[1, 5050] loss_train: 0.006829, loss_test: 0.005780
time: 0.25505661964416504
time: 2.2645065784454346
[1, 5051] loss_train: 0.002820, loss_test: 0.005779
time: 0.24405431747436523
time: 2.255514621734619
[1, 5052] loss_train: 0.008137, loss_test: 0.005783
time: 0.24405384063720703
time: 2.2507336139678955
[1, 5053] loss_train: 0.005763, loss_test: 0.005789
time: 0.24305415153503418
time: 2.2224972248077393
[1, 5054] loss_train: 0.000888, loss_test: 0.005797
time: 0.24305415153503418
time: 2.260507822036743
[1, 5055] loss_train: 0.008949, loss_test: 0.005807
time: 0.24305295944213867
time: 2.2405014038085938
[1, 5056] loss_train: 0.011169, loss_test: 0.005817
time: 0.2440657615661621
time: 2.2345004081726074
[1, 5057] loss_train: 0.004765, loss_test: 0.005830
time: 0.2470550537109375
time: 2.24300479888916
[1, 5058] loss_train: 0.007529, loss_test: 0.005838
time: 0.24305462837219238
time: 2.2125134468078613
[1, 5059] loss_train: 0.002522, loss_test: 0.005848
time: 0.25005555152893066
time: 2.2154958248138428
[1, 5060] loss_train: 0.001072, loss_test: 0.005843
time: 0.256056547164917
time: 2.2535042762756348
[1, 5061] loss_train: 0.005579, loss_test: 0.005840
time: 0.2450547218322754
time: 2.222001791000366
[1, 5062] loss_train: 0.009721, loss_test: 0.005826
time: 0.24405431747436523
time: 2.219496250152588
[1, 5063] loss_train: 0.001640, loss_test: 0.005820
time: 0.2449326515197754
time: 2.2205123901367188
[1, 5064] loss_train: 0.008536, loss_test: 0.005816
time: 0.2450547218322754
time: 2.238499879837036
[1, 5065] loss_train: 0.004974, loss_test: 0.005815
time: 0.2430732250213623
time: 2.227656602859497
[1, 5066] loss_train: 0.011228, loss_test: 0.005816
time: 0.2450544834136963
time: 2.224499464035034
[1, 5067] loss_train: 0.006125, loss_test: 0.005819
time: 0.25305724143981934
time: 2.2385008335113525
[1, 5068] loss_train: 0.004757, loss_test: 0.005821
time: 0.24506807327270508
time: 2.2495028972625732
[1, 5069] loss_train: 0.007945, loss_test: 0.005821
time: 0.2510559558868408
time: 2.197507619857788
[1, 5070] loss_train: 0.005654, loss_test: 0.005821
time: 0.256056547164917
time: 2.233499765396118
[1, 5071] loss_train: 0.007454, loss_test: 0.005821
time: 0.25305604934692383
time: 2.1804893016815186
[1, 5072] loss_train: 0.005294, loss_test: 0.005821
time: 0.24405527114868164
time: 2.231498956680298
[1, 5073] loss_train: 0.006838, loss_test: 0.005820
time: 0.24206948280334473
time: 2.2375009059906006
[1, 5074] loss_train: 0.003144, loss_test: 0.005823
time: 0.24605417251586914
time: 2.233499526977539
[1, 5075] loss_train: 0.005181, loss_test: 0.005826
time: 0.24405431747436523
time: 2.2265114784240723
[1, 5076] loss_train: 0.005037, loss_test: 0.005832
time: 0.24505376815795898
time: 2.247504949569702
[1, 5077] loss_train: 0.012454, loss_test: 0.005834
time: 0.24205422401428223
time: 2.2202677726745605
[1, 5078] loss_train: 0.008546, loss_test: 0.005838
time: 0.24605441093444824
time: 2.2400214672088623
[1, 5079] loss_train: 0.007958, loss_test: 0.005837
time: 0.24305367469787598
time: 2.254506826400757
[1, 5080] loss_train: 0.005727, loss_test: 0.005834
time: 0.2540562152862549
time: 2.254504442214966
[1, 5081] loss_train: 0.002122, loss_test: 0.005829
time: 0.2450542449951172
time: 2.247502088546753
[1, 5082] loss_train: 0.012599, loss_test: 0.005819
time: 0.24405384063720703
time: 2.236501455307007
[1, 5083] loss_train: 0.003136, loss_test: 0.005812
time: 0.24405336380004883
time: 2.205493211746216
[1, 5084] loss_train: 0.006858, loss_test: 0.005810
time: 0.24805498123168945
time: 2.229499101638794
[1, 5085] loss_train: 0.003796, loss_test: 0.005809
time: 0.24405455589294434
time: 2.1915066242218018
[1, 5086] loss_train: 0.004831, loss_test: 0.005810
time: 0.24405384063720703
time: 2.207494020462036
[1, 5087] loss_train: 0.003874, loss_test: 0.005811
time: 0.24605417251586914
time: 2.237508773803711
[1, 5088] loss_train: 0.012876, loss_test: 0.005796
time: 0.24805569648742676
time: 2.2545039653778076
[1, 5089] loss_train: 0.012836, loss_test: 0.005784
time: 0.24405360221862793
time: 2.2625153064727783
[1, 5090] loss_train: 0.005056, loss_test: 0.005780
time: 0.26006031036376953
time: 2.2655093669891357
[1, 5091] loss_train: 0.009184, loss_test: 0.005779
time: 0.24605488777160645
time: 2.2284982204437256
[1, 5092] loss_train: 0.006718, loss_test: 0.005789
time: 0.25005507469177246
time: 2.23249888420105
[1, 5093] loss_train: 0.007925, loss_test: 0.005811
time: 0.2450559139251709
time: 2.212019920349121
[1, 5094] loss_train: 0.007723, loss_test: 0.005840
time: 0.25205516815185547
time: 2.2044928073883057
[1, 5095] loss_train: 0.005642, loss_test: 0.005866
time: 0.24305343627929688
time: 2.241530179977417
[1, 5096] loss_train: 0.008103, loss_test: 0.005872
time: 0.24405384063720703
time: 2.244502305984497
[1, 5097] loss_train: 0.004494, loss_test: 0.005868
time: 0.24413418769836426
time: 2.2345004081726074
[1, 5098] loss_train: 0.009487, loss_test: 0.005858
time: 0.24205374717712402
time: 2.2100110054016113
[1, 5099] loss_train: 0.002978, loss_test: 0.005828
time: 0.24205350875854492
time: 2.2385125160217285
[1, 5100] loss_train: 0.001361, loss_test: 0.005791
time: 0.25705671310424805
time: 2.2545042037963867
[1, 5101] loss_train: 0.010768, loss_test: 0.005784
time: 0.24605464935302734
time: 2.232499837875366
[1, 5102] loss_train: 0.010628, loss_test: 0.005790
time: 0.2450542449951172
time: 2.230008602142334
[1, 5103] loss_train: 0.010763, loss_test: 0.005804
time: 0.24405527114868164
time: 2.2365000247955322
[1, 5104] loss_train: 0.005257, loss_test: 0.005821
time: 0.2470545768737793
time: 2.203493118286133
[1, 5105] loss_train: 0.003070, loss_test: 0.005838
time: 0.24405384063720703
time: 2.1999948024749756
[1, 5106] loss_train: 0.004231, loss_test: 0.005852
time: 0.24505400657653809
time: 2.1974921226501465
[1, 5107] loss_train: 0.002304, loss_test: 0.005862
time: 0.24305391311645508
time: 2.2505035400390625
[1, 5108] loss_train: 0.007947, loss_test: 0.005867
time: 0.24405360221862793
time: 2.2154958248138428
[1, 5109] loss_train: 0.008488, loss_test: 0.005854
time: 0.24805474281311035
time: 2.220127582550049
[1, 5110] loss_train: 0.006167, loss_test: 0.005841
time: 0.25705671310424805
time: 2.2365007400512695
[1, 5111] loss_train: 0.005258, loss_test: 0.005830
time: 0.2560563087463379
time: 2.229499101638794
[1, 5112] loss_train: 0.011188, loss_test: 0.005811
time: 0.2440941333770752
time: 2.244502305984497
[1, 5113] loss_train: 0.004650, loss_test: 0.005799
time: 0.247053861618042
time: 2.2275149822235107
[1, 5114] loss_train: 0.010051, loss_test: 0.005791
time: 0.24605417251586914
time: 2.240513324737549
[1, 5115] loss_train: 0.014156, loss_test: 0.005785
time: 0.2490553855895996
time: 2.247502565383911
[1, 5116] loss_train: 0.004117, loss_test: 0.005793
time: 0.2450547218322754
time: 2.272592067718506
[1, 5117] loss_train: 0.006360, loss_test: 0.005811
time: 0.25205564498901367
time: 2.244502305984497
[1, 5118] loss_train: 0.006560, loss_test: 0.005827
time: 0.24505400657653809
time: 2.2385003566741943
[1, 5119] loss_train: 0.001717, loss_test: 0.005831
time: 0.24605512619018555
time: 2.2410314083099365
[1, 5120] loss_train: 0.004419, loss_test: 0.005831
time: 0.2560577392578125
time: 2.2654852867126465
[1, 5121] loss_train: 0.007396, loss_test: 0.005826
time: 0.25207018852233887
time: 2.2260234355926514
[1, 5122] loss_train: 0.003751, loss_test: 0.005817
time: 0.24405360221862793
time: 2.237501621246338
[1, 5123] loss_train: 0.010988, loss_test: 0.005801
time: 0.24405384063720703
time: 2.225003242492676
[1, 5124] loss_train: 0.005342, loss_test: 0.005793
time: 0.24806809425354004
time: 2.2335000038146973
[1, 5125] loss_train: 0.001250, loss_test: 0.005791
time: 0.24505853652954102
time: 2.2340290546417236
[1, 5126] loss_train: 0.008015, loss_test: 0.005795
time: 0.24305295944213867
time: 2.217496395111084
[1, 5127] loss_train: 0.005150, loss_test: 0.005800
time: 0.24506831169128418
time: 2.204493522644043
[1, 5128] loss_train: 0.006541, loss_test: 0.005799
time: 0.24606609344482422
time: 2.2595057487487793
[1, 5129] loss_train: 0.007440, loss_test: 0.005796
time: 0.24205446243286133
time: 2.226511240005493
[1, 5130] loss_train: 0.005108, loss_test: 0.005797
time: 0.25505566596984863
time: 2.2244980335235596
[1, 5131] loss_train: 0.007903, loss_test: 0.005791
time: 0.24605417251586914
time: 2.2254974842071533
[1, 5132] loss_train: 0.006896, loss_test: 0.005787
time: 0.24405455589294434
time: 2.213999032974243
[1, 5133] loss_train: 0.010525, loss_test: 0.005789
time: 0.24305415153503418
time: 2.2295000553131104
[1, 5134] loss_train: 0.005342, loss_test: 0.005795
time: 0.24405407905578613
time: 2.2200145721435547
[1, 5135] loss_train: 0.011498, loss_test: 0.005798
time: 0.24505400657653809
time: 2.2124950885772705
[1, 5136] loss_train: 0.005149, loss_test: 0.005803
time: 0.24805402755737305
time: 2.2491955757141113
[1, 5137] loss_train: 0.001832, loss_test: 0.005805
time: 0.24405455589294434
time: 2.2264978885650635
[1, 5138] loss_train: 0.006427, loss_test: 0.005801
time: 0.2540562152862549
time: 2.256505250930786
[1, 5139] loss_train: 0.004012, loss_test: 0.005795
time: 0.24505352973937988
time: 2.241501808166504
[1, 5140] loss_train: 0.003362, loss_test: 0.005789
time: 0.26107001304626465
time: 2.2935333251953125
[1, 5141] loss_train: 0.007115, loss_test: 0.005792
time: 0.2540562152862549
time: 2.2735087871551514
[1, 5142] loss_train: 0.003426, loss_test: 0.005805
time: 0.2450544834136963
time: 2.1925039291381836
[1, 5143] loss_train: 0.002980, loss_test: 0.005832
time: 0.24405360221862793
time: 2.2169995307922363
[1, 5144] loss_train: 0.009323, loss_test: 0.005840
time: 0.2490551471710205
time: 2.206494092941284
[1, 5145] loss_train: 0.007161, loss_test: 0.005841
time: 0.2450551986694336
time: 2.2475028038024902
[1, 5146] loss_train: 0.008209, loss_test: 0.005835
time: 0.2470543384552002
time: 2.2645087242126465
[1, 5147] loss_train: 0.002511, loss_test: 0.005834
time: 0.2450544834136963
time: 2.232501268386841
[1, 5148] loss_train: 0.007581, loss_test: 0.005832
time: 0.2490546703338623
time: 2.2235212326049805
[1, 5149] loss_train: 0.002633, loss_test: 0.005834
time: 0.2440662384033203
time: 2.2365193367004395
[1, 5150] loss_train: 0.005016, loss_test: 0.005838
time: 0.25505638122558594
time: 2.2635080814361572
[1, 5151] loss_train: 0.007218, loss_test: 0.005841
time: 0.24405455589294434
time: 2.2304985523223877
[1, 5152] loss_train: 0.006547, loss_test: 0.005838
time: 0.24305367469787598
time: 2.2375011444091797
[1, 5153] loss_train: 0.016005, loss_test: 0.005826
time: 0.24506807327270508
time: 2.2314987182617188
[1, 5154] loss_train: 0.007659, loss_test: 0.005821
time: 0.24506664276123047
time: 2.218737840652466
[1, 5155] loss_train: 0.006029, loss_test: 0.005822
time: 0.24805450439453125
time: 2.226162910461426
[1, 5156] loss_train: 0.003164, loss_test: 0.005821
time: 0.24505400657653809
time: 2.191492795944214
[1, 5157] loss_train: 0.004577, loss_test: 0.005821
time: 0.24405384063720703
time: 2.218496799468994
[1, 5158] loss_train: 0.006125, loss_test: 0.005820
time: 0.24205303192138672
time: 2.2234978675842285
[1, 5159] loss_train: 0.003266, loss_test: 0.005814
time: 0.2435770034790039
time: 2.230499029159546
[1, 5160] loss_train: 0.009487, loss_test: 0.005804
time: 0.2550830841064453
time: 2.24650239944458
[1, 5161] loss_train: 0.011015, loss_test: 0.005794
time: 0.24405336380004883
time: 2.2144980430603027
[1, 5162] loss_train: 0.010765, loss_test: 0.005788
time: 0.2470543384552002
time: 2.23249888420105
[1, 5163] loss_train: 0.004502, loss_test: 0.005787
time: 0.247056245803833
time: 2.2304985523223877
[1, 5164] loss_train: 0.005993, loss_test: 0.005791
time: 0.24405360221862793
time: 2.243502378463745
[1, 5165] loss_train: 0.007333, loss_test: 0.005797
time: 0.2510557174682617
time: 2.2215161323547363
[1, 5166] loss_train: 0.009531, loss_test: 0.005797
time: 0.2450547218322754
time: 2.239527702331543
[1, 5167] loss_train: 0.004450, loss_test: 0.005796
time: 0.24805474281311035
time: 2.266507387161255
[1, 5168] loss_train: 0.006668, loss_test: 0.005795
time: 0.24405360221862793
time: 2.2204973697662354
[1, 5169] loss_train: 0.003989, loss_test: 0.005794
time: 0.2490553855895996
time: 2.219496011734009
[1, 5170] loss_train: 0.008806, loss_test: 0.005793
time: 0.254056453704834
time: 2.250516653060913
[1, 5171] loss_train: 0.001971, loss_test: 0.005791
time: 0.24805521965026855
time: 2.207505464553833
[1, 5172] loss_train: 0.009100, loss_test: 0.005786
time: 0.2470541000366211
time: 2.2395036220550537
[1, 5173] loss_train: 0.003892, loss_test: 0.005782
time: 0.24305438995361328
time: 2.2555043697357178
[1, 5174] loss_train: 0.009931, loss_test: 0.005776
time: 0.24305438995361328
time: 2.2164950370788574
[1, 5175] loss_train: 0.007606, loss_test: 0.005773
time: 0.25005602836608887
time: 2.205493211746216
[1, 5176] loss_train: 0.006606, loss_test: 0.005773
time: 0.24406719207763672
time: 2.218496322631836
[1, 5177] loss_train: 0.004460, loss_test: 0.005774
time: 0.24405360221862793
time: 2.2485036849975586
[1, 5178] loss_train: 0.001339, loss_test: 0.005776
time: 0.24506640434265137
time: 2.2385032176971436
[1, 5179] loss_train: 0.003210, loss_test: 0.005778
time: 0.24305391311645508
time: 2.255537271499634
[1, 5180] loss_train: 0.004365, loss_test: 0.005780
time: 0.25505590438842773
time: 2.242502212524414
[1, 5181] loss_train: 0.002724, loss_test: 0.005784
time: 0.2470550537109375
time: 2.2139999866485596
[1, 5182] loss_train: 0.006824, loss_test: 0.005788
time: 0.24605417251586914
time: 2.217496156692505
[1, 5183] loss_train: 0.004959, loss_test: 0.005792
time: 0.24405384063720703
time: 2.218496561050415
[1, 5184] loss_train: 0.012202, loss_test: 0.005792
time: 0.2450559139251709
time: 2.229499340057373
[1, 5185] loss_train: 0.001708, loss_test: 0.005796
time: 0.24605464935302734
time: 2.223499298095703
[1, 5186] loss_train: 0.011031, loss_test: 0.005797
time: 0.24305391311645508
time: 2.2385003566741943
[1, 5187] loss_train: 0.004506, loss_test: 0.005801
time: 0.2440948486328125
time: 2.243316173553467
[1, 5188] loss_train: 0.006143, loss_test: 0.005806
time: 0.2470552921295166
time: 2.2164955139160156
[1, 5189] loss_train: 0.010833, loss_test: 0.005802
time: 0.24605464935302734
time: 2.2388036251068115
[1, 5190] loss_train: 0.004209, loss_test: 0.005800
time: 0.26105833053588867
time: 2.2264978885650635
[1, 5191] loss_train: 0.005086, loss_test: 0.005798
time: 0.24505400657653809
time: 2.2430362701416016
[1, 5192] loss_train: 0.003377, loss_test: 0.005795
time: 0.25005602836608887
time: 2.246019124984741
[1, 5193] loss_train: 0.006994, loss_test: 0.005787
time: 0.2450549602508545
time: 2.2525031566619873
[1, 5194] loss_train: 0.003614, loss_test: 0.005783
time: 0.2470545768737793
time: 2.242501974105835
[1, 5195] loss_train: 0.007336, loss_test: 0.005779
time: 0.2450542449951172
time: 2.204512119293213
[1, 5196] loss_train: 0.008099, loss_test: 0.005775
time: 0.24306702613830566
time: 2.2545042037963867
[1, 5197] loss_train: 0.001907, loss_test: 0.005774
time: 0.2450544834136963
time: 2.2285146713256836
[1, 5198] loss_train: 0.003045, loss_test: 0.005775
time: 0.24305462837219238
time: 2.2034921646118164
[1, 5199] loss_train: 0.005350, loss_test: 0.005775
time: 0.24305438995361328
time: 2.2205066680908203
[1, 5200] loss_train: 0.003862, loss_test: 0.005776
time: 0.2540562152862549
time: 2.22649884223938
[1, 5201] loss_train: 0.002942, loss_test: 0.005779
time: 0.24405431747436523
time: 2.207493543624878
[1, 5202] loss_train: 0.007334, loss_test: 0.005781
time: 0.24505376815795898
time: 2.2485034465789795
[1, 5203] loss_train: 0.003640, loss_test: 0.005784
time: 0.24305343627929688
time: 2.2515370845794678
[1, 5204] loss_train: 0.007467, loss_test: 0.005786
time: 0.2450549602508545
time: 2.237003803253174
[1, 5205] loss_train: 0.010205, loss_test: 0.005806
time: 0.24405360221862793
time: 2.2214977741241455
[1, 5206] loss_train: 0.004009, loss_test: 0.005833
time: 0.24405360221862793
time: 2.23349928855896
[1, 5207] loss_train: 0.005401, loss_test: 0.005868
time: 0.2450554370880127
time: 2.20949387550354
[1, 5208] loss_train: 0.001204, loss_test: 0.005910
time: 0.24405550956726074
time: 2.2294981479644775
[1, 5209] loss_train: 0.007235, loss_test: 0.005938
time: 0.2450547218322754
time: 2.249016761779785
[1, 5210] loss_train: 0.001130, loss_test: 0.005968
time: 0.2560594081878662
time: 2.2405011653900146
[1, 5211] loss_train: 0.020159, loss_test: 0.005908
time: 0.24405360221862793
time: 2.198129892349243
[1, 5212] loss_train: 0.012190, loss_test: 0.005846
time: 0.24806785583496094
time: 2.22149658203125
[1, 5213] loss_train: 0.006487, loss_test: 0.005807
time: 0.24709677696228027
time: 2.246501922607422
[1, 5214] loss_train: 0.002384, loss_test: 0.005795
time: 0.24305391311645508
time: 2.218496322631836
[1, 5215] loss_train: 0.007428, loss_test: 0.005802
time: 0.2490553855895996
time: 2.1914901733398438
[1, 5216] loss_train: 0.002740, loss_test: 0.005826
time: 0.24405360221862793
time: 2.1974918842315674
[1, 5217] loss_train: 0.009451, loss_test: 0.005847
time: 0.24305343627929688
time: 2.2224977016448975
[1, 5218] loss_train: 0.003974, loss_test: 0.005877
time: 0.2450549602508545
time: 2.2275166511535645
[1, 5219] loss_train: 0.011384, loss_test: 0.005918
time: 0.24405431747436523
time: 2.221527099609375
[1, 5220] loss_train: 0.005969, loss_test: 0.005962
time: 0.25505709648132324
time: 2.2555043697357178
[1, 5221] loss_train: 0.011085, loss_test: 0.005990
time: 0.2450547218322754
time: 2.248502731323242
[1, 5222] loss_train: 0.005095, loss_test: 0.006003
time: 0.2470557689666748
time: 2.2825100421905518
[1, 5223] loss_train: 0.009781, loss_test: 0.005968
time: 0.24405431747436523
time: 2.2395007610321045
[1, 5224] loss_train: 0.008672, loss_test: 0.005913
time: 0.24305391311645508
time: 2.2244975566864014
[1, 5225] loss_train: 0.006647, loss_test: 0.005858
time: 0.24205374717712402
time: 2.2675068378448486
[1, 5226] loss_train: 0.004658, loss_test: 0.005822
time: 0.24305438995361328
time: 2.2375004291534424
[1, 5227] loss_train: 0.006460, loss_test: 0.005801
time: 0.24405384063720703
time: 2.220496892929077
[1, 5228] loss_train: 0.003747, loss_test: 0.005794
time: 0.24405455589294434
time: 2.2225072383880615
[1, 5229] loss_train: 0.009589, loss_test: 0.005798
time: 0.24305343627929688
time: 2.2030062675476074
[1, 5230] loss_train: 0.009535, loss_test: 0.005796
time: 0.25707030296325684
time: 2.277512311935425
[1, 5231] loss_train: 0.008276, loss_test: 0.005796
time: 0.24505376815795898
time: 2.2475030422210693
[1, 5232] loss_train: 0.003655, loss_test: 0.005800
time: 0.24907636642456055
time: 2.2074942588806152
[1, 5233] loss_train: 0.007642, loss_test: 0.005799
time: 0.24405479431152344
time: 2.2124946117401123
[1, 5234] loss_train: 0.008935, loss_test: 0.005798
time: 0.2510678768157959
time: 2.2525057792663574
[1, 5235] loss_train: 0.001164, loss_test: 0.005801
time: 0.24605441093444824
time: 2.2135064601898193
[1, 5236] loss_train: 0.004791, loss_test: 0.005804
time: 0.2490551471710205
time: 2.2525041103363037
[1, 5237] loss_train: 0.002931, loss_test: 0.005807
time: 0.24506711959838867
time: 2.218496084213257
[1, 5238] loss_train: 0.005940, loss_test: 0.005806
time: 0.2470552921295166
time: 2.241023302078247
[1, 5239] loss_train: 0.002707, loss_test: 0.005806
time: 0.24405288696289062
time: 2.2320199012756348
[1, 5240] loss_train: 0.012143, loss_test: 0.005800
time: 0.2600584030151367
time: 2.2505147457122803
[1, 5241] loss_train: 0.009271, loss_test: 0.005793
time: 0.24305367469787598
time: 2.2294983863830566
[1, 5242] loss_train: 0.010787, loss_test: 0.005787
time: 0.24805521965026855
time: 2.2075035572052
[1, 5243] loss_train: 0.011205, loss_test: 0.005782
time: 0.24405384063720703
time: 2.255504846572876
[1, 5244] loss_train: 0.017023, loss_test: 0.005798
time: 0.24405384063720703
time: 2.2134954929351807
[1, 5245] loss_train: 0.005731, loss_test: 0.005828
time: 0.2470555305480957
time: 2.2174949645996094
[1, 5246] loss_train: 0.005114, loss_test: 0.005854
time: 0.2450544834136963
time: 2.233025312423706
[1, 5247] loss_train: 0.009745, loss_test: 0.005865
time: 0.2450542449951172
time: 2.203493356704712
[1, 5248] loss_train: 0.004006, loss_test: 0.005872
time: 0.24405336380004883
time: 2.231498956680298
[1, 5249] loss_train: 0.005022, loss_test: 0.005842
time: 0.24605607986450195
time: 2.215507745742798
[1, 5250] loss_train: 0.009691, loss_test: 0.005801
time: 0.25905799865722656
time: 2.2585132122039795
[1, 5251] loss_train: 0.006157, loss_test: 0.005778
time: 0.24305367469787598
time: 2.230499505996704
[1, 5252] loss_train: 0.004492, loss_test: 0.005773
time: 0.2470552921295166
time: 2.230499029159546
[1, 5253] loss_train: 0.005768, loss_test: 0.005785
time: 0.24405336380004883
time: 2.228498935699463
[1, 5254] loss_train: 0.004588, loss_test: 0.005814
time: 0.24408531188964844
time: 2.19749116897583
[1, 5255] loss_train: 0.003835, loss_test: 0.005850
time: 0.24905610084533691
time: 2.229038953781128
[1, 5256] loss_train: 0.007011, loss_test: 0.005886
time: 0.24707865715026855
time: 2.2234983444213867
[1, 5257] loss_train: 0.003172, loss_test: 0.005921
time: 0.24908185005187988
time: 2.2285001277923584
[1, 5258] loss_train: 0.006093, loss_test: 0.005954
time: 0.2450547218322754
time: 2.2134947776794434
[1, 5259] loss_train: 0.003674, loss_test: 0.005986
time: 0.2470552921295166
time: 2.238116502761841
[1, 5260] loss_train: 0.018581, loss_test: 0.005953
time: 0.25505733489990234
time: 2.270507335662842
[1, 5261] loss_train: 0.009439, loss_test: 0.005915
time: 0.2470543384552002
time: 2.2705085277557373
[1, 5262] loss_train: 0.006964, loss_test: 0.005879
time: 0.24305367469787598
time: 2.2290163040161133
[1, 5263] loss_train: 0.010554, loss_test: 0.005829
time: 0.24505352973937988
time: 2.226498603820801
[1, 5264] loss_train: 0.009799, loss_test: 0.005796
time: 0.2450547218322754
time: 2.218012809753418
[1, 5265] loss_train: 0.011634, loss_test: 0.005795
time: 0.2450544834136963
time: 2.2264978885650635
[1, 5266] loss_train: 0.014010, loss_test: 0.005864
time: 0.2470550537109375
time: 2.210517168045044
[1, 5267] loss_train: 0.009198, loss_test: 0.006018
time: 0.24405360221862793
time: 2.245502471923828
[1, 5268] loss_train: 0.006977, loss_test: 0.006130
time: 0.24305391311645508
time: 2.205493450164795
[1, 5269] loss_train: 0.001465, loss_test: 0.006234
time: 0.24305367469787598
time: 2.2375197410583496
[1, 5270] loss_train: 0.006464, loss_test: 0.006264
time: 0.2540559768676758
time: 2.255505084991455
[1, 5271] loss_train: 0.006398, loss_test: 0.006158
time: 0.2470541000366211
time: 2.229499101638794
[1, 5272] loss_train: 0.006822, loss_test: 0.005958
time: 0.24405384063720703
time: 2.242502212524414
[1, 5273] loss_train: 0.001502, loss_test: 0.005819
time: 0.24405431747436523
time: 2.2415013313293457
[1, 5274] loss_train: 0.011196, loss_test: 0.005785
time: 0.24305391311645508
time: 2.231499433517456
[1, 5275] loss_train: 0.009619, loss_test: 0.005829
time: 0.24305343627929688
time: 2.242501735687256
[1, 5276] loss_train: 0.004662, loss_test: 0.005908
time: 0.2450549602508545
time: 2.2315139770507812
[1, 5277] loss_train: 0.002821, loss_test: 0.006008
time: 0.24405789375305176
time: 2.24650239944458
[1, 5278] loss_train: 0.000519, loss_test: 0.006119
time: 0.24506735801696777
time: 2.2224974632263184
[1, 5279] loss_train: 0.006760, loss_test: 0.006196
time: 0.24605417251586914
time: 2.2074942588806152
[1, 5280] loss_train: 0.005349, loss_test: 0.006226
time: 0.26244306564331055
time: 2.241502285003662
[1, 5281] loss_train: 0.005768, loss_test: 0.006231
time: 0.24405336380004883
time: 2.229498863220215
[1, 5282] loss_train: 0.006308, loss_test: 0.006215
time: 0.2510550022125244
time: 2.2420058250427246
[1, 5283] loss_train: 0.006813, loss_test: 0.006160
time: 0.24430561065673828
time: 2.243501663208008
[1, 5284] loss_train: 0.010071, loss_test: 0.006069
time: 0.2510561943054199
time: 2.2194979190826416
[1, 5285] loss_train: 0.011223, loss_test: 0.005967
time: 0.24405479431152344
time: 2.2565042972564697
[1, 5286] loss_train: 0.002323, loss_test: 0.005890
time: 0.24805521965026855
time: 2.219263792037964
[1, 5287] loss_train: 0.001156, loss_test: 0.005840
time: 0.24405455589294434
time: 2.2244973182678223
[1, 5288] loss_train: 0.003289, loss_test: 0.005812
time: 0.24305438995361328
time: 2.218006134033203
[1, 5289] loss_train: 0.005597, loss_test: 0.005805
time: 0.24806928634643555
time: 2.2495028972625732
[1, 5290] loss_train: 0.003251, loss_test: 0.005814
time: 0.25505614280700684
time: 2.272508382797241
[1, 5291] loss_train: 0.002296, loss_test: 0.005833
time: 0.24505352973937988
time: 2.2149996757507324
[1, 5292] loss_train: 0.003373, loss_test: 0.005855
time: 0.24405360221862793
time: 2.2254984378814697
[1, 5293] loss_train: 0.005544, loss_test: 0.005872
time: 0.2420670986175537
time: 2.218498706817627
[1, 5294] loss_train: 0.011943, loss_test: 0.005893
time: 0.24306750297546387
time: 2.2685070037841797
[1, 5295] loss_train: 0.002506, loss_test: 0.005913
time: 0.24410700798034668
time: 2.2174956798553467
[1, 5296] loss_train: 0.005663, loss_test: 0.005911
time: 0.2450542449951172
time: 2.280069351196289
[1, 5297] loss_train: 0.004151, loss_test: 0.005892
time: 0.24605488777160645
time: 2.2395002841949463
[1, 5298] loss_train: 0.003027, loss_test: 0.005877
time: 0.2450549602508545
time: 2.2150158882141113
[1, 5299] loss_train: 0.009514, loss_test: 0.005859
time: 0.2450542449951172
time: 2.2395012378692627
[1, 5300] loss_train: 0.004527, loss_test: 0.005847
time: 0.25505614280700684
time: 2.2104947566986084
[1, 5301] loss_train: 0.004941, loss_test: 0.005833
time: 0.24907302856445312
time: 2.203493356704712
[1, 5302] loss_train: 0.004790, loss_test: 0.005825
time: 0.2450544834136963
time: 2.207514524459839
[1, 5303] loss_train: 0.013779, loss_test: 0.005819
time: 0.24405455589294434
time: 2.2074942588806152
[1, 5304] loss_train: 0.005940, loss_test: 0.005817
time: 0.24605441093444824
time: 2.2144951820373535
[1, 5305] loss_train: 0.004950, loss_test: 0.005810
time: 0.24805498123168945
time: 2.2164952754974365
[1, 5306] loss_train: 0.004632, loss_test: 0.005804
time: 0.24805474281311035
time: 2.230499505996704
[1, 5307] loss_train: 0.003706, loss_test: 0.005801
time: 0.24605464935302734
time: 2.2010140419006348
[1, 5308] loss_train: 0.008445, loss_test: 0.005798
time: 0.24606704711914062
time: 2.2695231437683105
[1, 5309] loss_train: 0.004757, loss_test: 0.005798
time: 0.24305343627929688
time: 2.2324986457824707
[1, 5310] loss_train: 0.008726, loss_test: 0.005800
time: 0.25505685806274414
time: 2.2645068168640137
[1, 5311] loss_train: 0.000954, loss_test: 0.005800
time: 0.2450547218322754
time: 2.218508243560791
[1, 5312] loss_train: 0.004575, loss_test: 0.005798
time: 0.24405431747436523
time: 2.208494186401367
[1, 5313] loss_train: 0.007542, loss_test: 0.005795
time: 0.24405455589294434
time: 2.215998411178589
[1, 5314] loss_train: 0.018154, loss_test: 0.005788
time: 0.24405503273010254
time: 2.2375001907348633
[1, 5315] loss_train: 0.006463, loss_test: 0.005784
time: 0.24205327033996582
time: 2.204496383666992
[1, 5316] loss_train: 0.004928, loss_test: 0.005783
time: 0.24505972862243652
time: 2.2114944458007812
[1, 5317] loss_train: 0.011678, loss_test: 0.005788
time: 0.24405407905578613
time: 2.2245004177093506
[1, 5318] loss_train: 0.008483, loss_test: 0.005792
time: 0.24509692192077637
time: 2.2174060344696045
[1, 5319] loss_train: 0.001818, loss_test: 0.005790
time: 0.24505376815795898
time: 2.232499837875366
[1, 5320] loss_train: 0.002687, loss_test: 0.005783
time: 0.2560570240020752
time: 2.248809337615967
[1, 5321] loss_train: 0.005503, loss_test: 0.005777
time: 0.24505949020385742
time: 2.2104947566986084
[1, 5322] loss_train: 0.008460, loss_test: 0.005772
time: 0.24805474281311035
time: 2.2233054637908936
[1, 5323] loss_train: 0.008494, loss_test: 0.005768
time: 0.24805593490600586
time: 2.219496488571167
[1, 5324] loss_train: 0.004699, loss_test: 0.005767
time: 0.2490549087524414
time: 2.1885039806365967
[1, 5325] loss_train: 0.001774, loss_test: 0.005769
time: 0.24606823921203613
time: 2.213508129119873
[1, 5326] loss_train: 0.001267, loss_test: 0.005773
time: 0.2440629005432129
time: 2.193490743637085
[1, 5327] loss_train: 0.014184, loss_test: 0.005780
time: 0.24506640434265137
time: 2.205493688583374
[1, 5328] loss_train: 0.008524, loss_test: 0.005785
time: 0.2450547218322754
time: 2.2285268306732178
[1, 5329] loss_train: 0.012167, loss_test: 0.005790
time: 0.2450542449951172
time: 2.2084949016571045
[1, 5330] loss_train: 0.003108, loss_test: 0.005796
time: 0.25907135009765625
time: 2.2770140171051025
[1, 5331] loss_train: 0.000688, loss_test: 0.005808
time: 0.2450544834136963
time: 2.2395009994506836
[1, 5332] loss_train: 0.008964, loss_test: 0.005813
time: 0.24305343627929688
time: 2.2495033740997314
[1, 5333] loss_train: 0.005677, loss_test: 0.005816
time: 0.24605488777160645
time: 2.2154958248138428
[1, 5334] loss_train: 0.008178, loss_test: 0.005811
time: 0.24405336380004883
time: 2.2370383739471436
[1, 5335] loss_train: 0.006357, loss_test: 0.005807
time: 0.2470545768737793
time: 2.2465016841888428
[1, 5336] loss_train: 0.001997, loss_test: 0.005806
time: 0.24305391311645508
time: 2.2385005950927734
[1, 5337] loss_train: 0.006145, loss_test: 0.005806
time: 0.24405455589294434
time: 2.195490837097168
[1, 5338] loss_train: 0.005318, loss_test: 0.005800
time: 0.2420806884765625
time: 2.206495523452759
[1, 5339] loss_train: 0.011676, loss_test: 0.005792
time: 0.24805474281311035
time: 2.2035024166107178
[1, 5340] loss_train: 0.004638, loss_test: 0.005785
time: 0.2600584030151367
time: 2.2480201721191406
[1, 5341] loss_train: 0.012102, loss_test: 0.005779
time: 0.24805450439453125
time: 2.225001811981201
[1, 5342] loss_train: 0.001194, loss_test: 0.005779
time: 0.24405407905578613
time: 2.239501714706421
[1, 5343] loss_train: 0.003481, loss_test: 0.005780
time: 0.2470545768737793
time: 2.258505344390869
[1, 5344] loss_train: 0.006348, loss_test: 0.005780
time: 0.24406671524047852
time: 2.2372260093688965
[1, 5345] loss_train: 0.006377, loss_test: 0.005781
time: 0.2450554370880127
time: 2.2144951820373535
[1, 5346] loss_train: 0.004730, loss_test: 0.005781
time: 0.2450542449951172
time: 2.232501745223999
[1, 5347] loss_train: 0.006616, loss_test: 0.005781
time: 0.24405455589294434
time: 2.21551251411438
[1, 5348] loss_train: 0.005233, loss_test: 0.005782
time: 0.24305415153503418
time: 2.208493709564209
[1, 5349] loss_train: 0.009343, loss_test: 0.005782
time: 0.2440786361694336
time: 2.223513603210449
[1, 5350] loss_train: 0.002246, loss_test: 0.005783
time: 0.2540559768676758
time: 2.2365052700042725
[1, 5351] loss_train: 0.001972, loss_test: 0.005786
time: 0.24305391311645508
time: 2.22049880027771
[1, 5352] loss_train: 0.006143, loss_test: 0.005789
time: 0.2450544834136963
time: 2.218496322631836
[1, 5353] loss_train: 0.012494, loss_test: 0.005789
time: 0.24506688117980957
time: 2.2365009784698486
[1, 5354] loss_train: 0.008674, loss_test: 0.005788
time: 0.24305343627929688
time: 2.227498769760132
[1, 5355] loss_train: 0.004744, loss_test: 0.005789
time: 0.24405384063720703
time: 2.2264981269836426
[1, 5356] loss_train: 0.011146, loss_test: 0.005791
time: 0.2450542449951172
time: 2.217496156692505
[1, 5357] loss_train: 0.014383, loss_test: 0.005796
time: 0.2510554790496826
time: 2.2144949436187744
[1, 5358] loss_train: 0.008899, loss_test: 0.005802
time: 0.25005674362182617
time: 2.2154951095581055
[1, 5359] loss_train: 0.008771, loss_test: 0.005807
time: 0.24509668350219727
time: 2.2304985523223877
[1, 5360] loss_train: 0.004129, loss_test: 0.005807
time: 0.25905704498291016
time: 2.219496726989746
[1, 5361] loss_train: 0.006372, loss_test: 0.005804
time: 0.2470545768737793
time: 2.2264976501464844
[1, 5362] loss_train: 0.003835, loss_test: 0.005800
time: 0.2450549602508545
time: 2.235503911972046
[1, 5363] loss_train: 0.009163, loss_test: 0.005797
time: 0.24305367469787598
time: 2.211495876312256
[1, 5364] loss_train: 0.004763, loss_test: 0.005794
time: 0.24505376815795898
time: 2.248504161834717
[1, 5365] loss_train: 0.012933, loss_test: 0.005791
time: 0.24382686614990234
time: 2.2224974632263184
[1, 5366] loss_train: 0.010724, loss_test: 0.005789
time: 0.24405431747436523
time: 2.239185333251953
[1, 5367] loss_train: 0.001616, loss_test: 0.005789
time: 0.2450544834136963
time: 2.2635064125061035
[1, 5368] loss_train: 0.006333, loss_test: 0.005789
time: 0.2490551471710205
time: 2.2240097522735596
[1, 5369] loss_train: 0.004095, loss_test: 0.005791
time: 0.24405407905578613
time: 2.26552414894104
[1, 5370] loss_train: 0.008559, loss_test: 0.005792
time: 0.2560703754425049
time: 2.2635135650634766
[1, 5371] loss_train: 0.005798, loss_test: 0.005794
time: 0.24805521965026855
time: 2.220496654510498
[1, 5372] loss_train: 0.009805, loss_test: 0.005794
time: 0.24405431747436523
time: 2.2024917602539062
[1, 5373] loss_train: 0.008671, loss_test: 0.005795
time: 0.24405360221862793
time: 2.2274980545043945
[1, 5374] loss_train: 0.004179, loss_test: 0.005797
time: 0.24605464935302734
time: 2.230520009994507
[1, 5375] loss_train: 0.001492, loss_test: 0.005800
time: 0.24305367469787598
time: 2.2600200176239014
[1, 5376] loss_train: 0.003315, loss_test: 0.005805
time: 0.24405407905578613
time: 2.228498697280884
[1, 5377] loss_train: 0.007523, loss_test: 0.005807
time: 0.2450547218322754
time: 2.223496913909912
[1, 5378] loss_train: 0.006277, loss_test: 0.005810
time: 0.24405360221862793
time: 2.233546018600464
[1, 5379] loss_train: 0.011112, loss_test: 0.005813
time: 0.24405360221862793
time: 2.23249888420105
[1, 5380] loss_train: 0.001752, loss_test: 0.005816
time: 0.2560575008392334
time: 2.218505859375
[1, 5381] loss_train: 0.006234, loss_test: 0.005816
time: 0.25005507469177246
time: 2.2385239601135254
[1, 5382] loss_train: 0.002639, loss_test: 0.005815
time: 0.24405407905578613
time: 2.236004114151001
[1, 5383] loss_train: 0.009031, loss_test: 0.005811
time: 0.2490558624267578
time: 2.228498697280884
[1, 5384] loss_train: 0.011094, loss_test: 0.005806
time: 0.2470543384552002
time: 2.2315022945404053
[1, 5385] loss_train: 0.002691, loss_test: 0.005802
time: 0.2490549087524414
time: 2.2264983654022217
[1, 5386] loss_train: 0.002515, loss_test: 0.005800
time: 0.24605441093444824
time: 2.2345004081726074
[1, 5387] loss_train: 0.015566, loss_test: 0.005794
time: 0.2470548152923584
time: 2.23449969291687
[1, 5388] loss_train: 0.003856, loss_test: 0.005790
time: 0.2450544834136963
time: 2.216520309448242
[1, 5389] loss_train: 0.003841, loss_test: 0.005787
time: 0.24405384063720703
time: 2.220496892929077
[1, 5390] loss_train: 0.013603, loss_test: 0.005783
time: 0.2540562152862549
time: 2.258516788482666
[1, 5391] loss_train: 0.007652, loss_test: 0.005781
time: 0.2470543384552002
time: 2.2154958248138428
[1, 5392] loss_train: 0.005329, loss_test: 0.005779
time: 0.24505376815795898
time: 2.2475032806396484
[1, 5393] loss_train: 0.006070, loss_test: 0.005776
time: 0.24505972862243652
time: 2.2645227909088135
[1, 5394] loss_train: 0.001756, loss_test: 0.005773
time: 0.2490684986114502
time: 2.23114013671875
[1, 5395] loss_train: 0.005765, loss_test: 0.005773
time: 0.2450547218322754
time: 2.2393884658813477
[1, 5396] loss_train: 0.009541, loss_test: 0.005778
time: 0.24305391311645508
time: 2.218430519104004
[1, 5397] loss_train: 0.004704, loss_test: 0.005790
time: 0.24405598640441895
time: 2.2244980335235596
[1, 5398] loss_train: 0.010519, loss_test: 0.005800
time: 0.24405431747436523
time: 2.220496416091919
[1, 5399] loss_train: 0.009325, loss_test: 0.005809
time: 0.24306631088256836
time: 2.1724863052368164
[1, 5400] loss_train: 0.009650, loss_test: 0.005812
time: 0.2560567855834961
time: 2.226497173309326
[1, 5401] loss_train: 0.008702, loss_test: 0.005809
time: 0.25005626678466797
time: 2.225497245788574
[1, 5402] loss_train: 0.005012, loss_test: 0.005802
time: 0.2470691204071045
time: 2.2265005111694336
[1, 5403] loss_train: 0.006642, loss_test: 0.005788
time: 0.2470550537109375
time: 2.225499391555786
[1, 5404] loss_train: 0.002284, loss_test: 0.005777
time: 0.2490549087524414
time: 2.217496633529663
[1, 5405] loss_train: 0.007617, loss_test: 0.005774
time: 0.24405384063720703
time: 2.2334988117218018
[1, 5406] loss_train: 0.007489, loss_test: 0.005775
time: 0.2470560073852539
time: 2.2353994846343994
[1, 5407] loss_train: 0.005462, loss_test: 0.005780
time: 0.24305367469787598
time: 2.221497058868408
[1, 5408] loss_train: 0.001518, loss_test: 0.005790
time: 0.24505400657653809
time: 2.2465221881866455
[1, 5409] loss_train: 0.009173, loss_test: 0.005794
time: 0.2450544834136963
time: 2.188488721847534
[1, 5410] loss_train: 0.003746, loss_test: 0.005799
time: 0.25705623626708984
time: 2.2535040378570557
[1, 5411] loss_train: 0.004325, loss_test: 0.005804
time: 0.24605536460876465
time: 2.23449969291687
[1, 5412] loss_train: 0.002786, loss_test: 0.005812
time: 0.24305415153503418
time: 2.235499858856201
[1, 5413] loss_train: 0.005359, loss_test: 0.005811
time: 0.24405431747436523
time: 2.210494041442871
[1, 5414] loss_train: 0.006496, loss_test: 0.005803
time: 0.24405431747436523
time: 2.233502149581909
[1, 5415] loss_train: 0.006220, loss_test: 0.005794
time: 0.24305343627929688
time: 2.2465031147003174
[1, 5416] loss_train: 0.002438, loss_test: 0.005791
time: 0.24305319786071777
time: 2.242501974105835
[1, 5417] loss_train: 0.010978, loss_test: 0.005786
time: 0.24305343627929688
time: 2.2365002632141113
[1, 5418] loss_train: 0.005735, loss_test: 0.005785
time: 0.24805474281311035
time: 2.218297004699707
[1, 5419] loss_train: 0.005465, loss_test: 0.005783
time: 0.24305391311645508
time: 2.2034926414489746
[1, 5420] loss_train: 0.000416, loss_test: 0.005783
time: 0.2560567855834961
time: 2.236516237258911
[1, 5421] loss_train: 0.005692, loss_test: 0.005783
time: 0.2520630359649658
time: 2.2014946937561035
[1, 5422] loss_train: 0.009418, loss_test: 0.005783
time: 0.24605417251586914
time: 2.2204971313476562
[1, 5423] loss_train: 0.014742, loss_test: 0.005780
time: 0.2480940818786621
time: 2.1984920501708984
[1, 5424] loss_train: 0.005036, loss_test: 0.005781
time: 0.24405384063720703
time: 2.248307228088379
[1, 5425] loss_train: 0.017532, loss_test: 0.005780
time: 0.254056453704834
time: 2.2355003356933594
[1, 5426] loss_train: 0.000812, loss_test: 0.005782
time: 0.24605441093444824
time: 2.2365024089813232
[1, 5427] loss_train: 0.009773, loss_test: 0.005785
time: 0.2470545768737793
time: 2.2264978885650635
[1, 5428] loss_train: 0.003589, loss_test: 0.005789
time: 0.24405455589294434
time: 2.2475016117095947
[1, 5429] loss_train: 0.008505, loss_test: 0.005788
time: 0.24607443809509277
time: 2.2304983139038086
[1, 5430] loss_train: 0.003951, loss_test: 0.005783
time: 0.25505709648132324
time: 2.257505178451538
[1, 5431] loss_train: 0.007366, loss_test: 0.005780
time: 0.24605464935302734
time: 2.2615065574645996
[1, 5432] loss_train: 0.004675, loss_test: 0.005781
time: 0.2450549602508545
time: 2.2244999408721924
[1, 5433] loss_train: 0.007525, loss_test: 0.005784
time: 0.24305367469787598
time: 2.2365012168884277
[1, 5434] loss_train: 0.011569, loss_test: 0.005788
time: 0.24405336380004883
time: 2.206494092941284
[1, 5435] loss_train: 0.004167, loss_test: 0.005796
time: 0.2450544834136963
time: 2.2380220890045166
[1, 5436] loss_train: 0.005352, loss_test: 0.005806
time: 0.24305367469787598
time: 2.222496747970581
[1, 5437] loss_train: 0.008746, loss_test: 0.005823
time: 0.24405455589294434
time: 2.1954996585845947
[1, 5438] loss_train: 0.006731, loss_test: 0.005841
time: 0.24605417251586914
time: 2.1944916248321533
[1, 5439] loss_train: 0.011439, loss_test: 0.005864
time: 0.24405407905578613
time: 2.2030136585235596
[1, 5440] loss_train: 0.004290, loss_test: 0.005881
time: 0.2560563087463379
time: 2.2370052337646484
[1, 5441] loss_train: 0.004621, loss_test: 0.005896
time: 0.24805569648742676
time: 2.248502492904663
[1, 5442] loss_train: 0.012241, loss_test: 0.005897
time: 0.2450549602508545
time: 2.2645068168640137
[1, 5443] loss_train: 0.003633, loss_test: 0.005901
time: 0.2450542449951172
time: 2.27150821685791
[1, 5444] loss_train: 0.009416, loss_test: 0.005889
time: 0.24605393409729004
time: 2.227498769760132
[1, 5445] loss_train: 0.009582, loss_test: 0.005874
time: 0.24605393409729004
time: 2.1975085735321045
[1, 5446] loss_train: 0.005563, loss_test: 0.005850
time: 0.24805450439453125
time: 2.2104949951171875
[1, 5447] loss_train: 0.002855, loss_test: 0.005831
time: 0.24505400657653809
time: 2.2014927864074707
[1, 5448] loss_train: 0.009386, loss_test: 0.005822
time: 0.24505400657653809
time: 2.1864895820617676
[1, 5449] loss_train: 0.010561, loss_test: 0.005809
time: 0.24405360221862793
time: 2.2304129600524902
[1, 5450] loss_train: 0.009120, loss_test: 0.005800
time: 0.26105737686157227
time: 2.240501642227173
[1, 5451] loss_train: 0.005869, loss_test: 0.005797
time: 0.24305510520935059
time: 2.240501880645752
[1, 5452] loss_train: 0.008431, loss_test: 0.005801
time: 0.24605393409729004
time: 2.246507167816162
[1, 5453] loss_train: 0.006061, loss_test: 0.005810
time: 0.24405384063720703
time: 2.2104949951171875
[1, 5454] loss_train: 0.004478, loss_test: 0.005816
time: 0.24305415153503418
time: 2.2495102882385254
[1, 5455] loss_train: 0.005137, loss_test: 0.005818
time: 0.2470550537109375
time: 2.239034414291382
[1, 5456] loss_train: 0.006155, loss_test: 0.005814
time: 0.2450547218322754
time: 2.235797882080078
[1, 5457] loss_train: 0.010794, loss_test: 0.005812
time: 0.24405431747436523
time: 2.2115163803100586
[1, 5458] loss_train: 0.002684, loss_test: 0.005808
time: 0.24305391311645508
time: 2.189502477645874
[1, 5459] loss_train: 0.018669, loss_test: 0.005806
time: 0.24405503273010254
time: 2.23103404045105
[1, 5460] loss_train: 0.009050, loss_test: 0.005802
time: 0.2560570240020752
time: 2.217503547668457
[1, 5461] loss_train: 0.004004, loss_test: 0.005800
time: 0.24605417251586914
time: 2.2114951610565186
[1, 5462] loss_train: 0.011242, loss_test: 0.005798
time: 0.24605417251586914
time: 2.2234973907470703
[1, 5463] loss_train: 0.009253, loss_test: 0.005793
time: 0.24905967712402344
time: 2.2254979610443115
[1, 5464] loss_train: 0.010015, loss_test: 0.005788
time: 0.2450551986694336
time: 2.2274975776672363
[1, 5465] loss_train: 0.008696, loss_test: 0.005784
time: 0.24706697463989258
time: 2.2258810997009277
[1, 5466] loss_train: 0.010538, loss_test: 0.005780
time: 0.24405431747436523
time: 2.2395026683807373
[1, 5467] loss_train: 0.010341, loss_test: 0.005776
time: 0.24307990074157715
time: 2.2655091285705566
[1, 5468] loss_train: 0.007769, loss_test: 0.005774
time: 0.2450542449951172
time: 2.207493782043457
[1, 5469] loss_train: 0.013552, loss_test: 0.005785
time: 0.24405407905578613
time: 2.209494113922119
[1, 5470] loss_train: 0.010925, loss_test: 0.005812
time: 0.25505685806274414
time: 2.260505437850952
[1, 5471] loss_train: 0.007289, loss_test: 0.005839
time: 0.24405455589294434
time: 2.234499454498291
[1, 5472] loss_train: 0.000822, loss_test: 0.005867
time: 0.2470548152923584
time: 2.220496892929077
[1, 5473] loss_train: 0.002316, loss_test: 0.005895
time: 0.24505400657653809
time: 2.216495990753174
[1, 5474] loss_train: 0.005007, loss_test: 0.005885
time: 0.24505400657653809
time: 2.228499174118042
[1, 5475] loss_train: 0.001853, loss_test: 0.005868
time: 0.24305343627929688
time: 2.235990285873413
[1, 5476] loss_train: 0.007131, loss_test: 0.005845
time: 0.24305415153503418
time: 2.2154953479766846
[1, 5477] loss_train: 0.004240, loss_test: 0.005833
time: 0.24305367469787598
time: 2.227837324142456
[1, 5478] loss_train: 0.005036, loss_test: 0.005836
time: 0.2450547218322754
time: 2.2545039653778076
[1, 5479] loss_train: 0.004333, loss_test: 0.005849
time: 0.2470552921295166
time: 2.2165133953094482
[1, 5480] loss_train: 0.003019, loss_test: 0.005868
time: 0.2570960521697998
time: 2.2855277061462402
[1, 5481] loss_train: 0.005620, loss_test: 0.005885
time: 0.24305391311645508
time: 2.2455153465270996
[1, 5482] loss_train: 0.004639, loss_test: 0.005900
time: 0.24605464935302734
time: 2.236004114151001
[1, 5483] loss_train: 0.003262, loss_test: 0.005913
time: 0.2450542449951172
time: 2.223004102706909
[1, 5484] loss_train: 0.005290, loss_test: 0.005916
time: 0.2450563907623291
time: 2.2244977951049805
[1, 5485] loss_train: 0.007135, loss_test: 0.005909
time: 0.24505400657653809
time: 2.196491241455078
[1, 5486] loss_train: 0.009449, loss_test: 0.005884
time: 0.2511458396911621
time: 2.221496820449829
[1, 5487] loss_train: 0.010506, loss_test: 0.005850
time: 0.24505400657653809
time: 2.2024929523468018
[1, 5488] loss_train: 0.007525, loss_test: 0.005827
time: 0.24305462837219238
time: 2.254503011703491
[1, 5489] loss_train: 0.009959, loss_test: 0.005803
time: 0.24805545806884766
time: 2.2155299186706543
[1, 5490] loss_train: 0.005150, loss_test: 0.005795
time: 0.2560567855834961
time: 2.2655069828033447
[1, 5491] loss_train: 0.005335, loss_test: 0.005803
time: 0.24405407905578613
time: 2.2515039443969727
[1, 5492] loss_train: 0.013356, loss_test: 0.005816
time: 0.24305367469787598
time: 2.2375030517578125
[1, 5493] loss_train: 0.009768, loss_test: 0.005830
time: 0.2450542449951172
time: 2.192490339279175
[1, 5494] loss_train: 0.025835, loss_test: 0.005844
time: 0.24305391311645508
time: 2.218496561050415
[1, 5495] loss_train: 0.005809, loss_test: 0.005858
time: 0.24405407905578613
time: 2.257507085800171
[1, 5496] loss_train: 0.010746, loss_test: 0.005873
time: 0.24505376815795898
time: 2.2124955654144287
[1, 5497] loss_train: 0.005314, loss_test: 0.005882
time: 0.24305343627929688
time: 2.192490816116333
[1, 5498] loss_train: 0.000709, loss_test: 0.005881
time: 0.24805521965026855
time: 2.25016188621521
[1, 5499] loss_train: 0.003907, loss_test: 0.005863
time: 0.24305367469787598
time: 2.218010663986206
[1, 5500] loss_train: 0.005583, loss_test: 0.005831
time: 0.2560570240020752
time: 2.260505199432373
[1, 5501] loss_train: 0.007913, loss_test: 0.005808
time: 0.24606823921203613
time: 2.2274978160858154
[1, 5502] loss_train: 0.006221, loss_test: 0.005789
time: 0.2450544834136963
time: 2.2154955863952637
[1, 5503] loss_train: 0.002534, loss_test: 0.005773
time: 0.24405360221862793
time: 2.219496965408325
[1, 5504] loss_train: 0.008629, loss_test: 0.005771
time: 0.24605417251586914
time: 2.230499505996704
[1, 5505] loss_train: 0.007990, loss_test: 0.005777
time: 0.2620580196380615
time: 2.2515034675598145
[1, 5506] loss_train: 0.009409, loss_test: 0.005787
time: 0.2470545768737793
time: 2.1875457763671875
[1, 5507] loss_train: 0.003993, loss_test: 0.005799
time: 0.2490551471710205
time: 2.2375004291534424
[1, 5508] loss_train: 0.008853, loss_test: 0.005807
time: 0.24305391311645508
time: 2.2405014038085938
[1, 5509] loss_train: 0.007772, loss_test: 0.005812
time: 0.24805474281311035
time: 2.207505226135254
[1, 5510] loss_train: 0.005390, loss_test: 0.005812
time: 0.2540557384490967
time: 2.263507127761841
[1, 5511] loss_train: 0.003165, loss_test: 0.005811
time: 0.24605488777160645
time: 2.232499837875366
[1, 5512] loss_train: 0.008850, loss_test: 0.005809
time: 0.24305367469787598
time: 2.2475028038024902
[1, 5513] loss_train: 0.010738, loss_test: 0.005802
time: 0.24305415153503418
time: 2.244502067565918
[1, 5514] loss_train: 0.005709, loss_test: 0.005797
time: 0.24505400657653809
time: 2.241502523422241
[1, 5515] loss_train: 0.016842, loss_test: 0.005801
time: 0.24505352973937988
time: 2.244502305984497
[1, 5516] loss_train: 0.007963, loss_test: 0.005805
time: 0.2490558624267578
time: 2.2365000247955322
[1, 5517] loss_train: 0.011801, loss_test: 0.005808
time: 0.24405455589294434
time: 2.225497245788574
[1, 5518] loss_train: 0.011679, loss_test: 0.005813
time: 0.24305391311645508
time: 2.198608160018921
[1, 5519] loss_train: 0.001835, loss_test: 0.005811
time: 0.24405407905578613
time: 2.2170310020446777
[1, 5520] loss_train: 0.003984, loss_test: 0.005809
time: 0.2560572624206543
time: 2.258504629135132
[1, 5521] loss_train: 0.005288, loss_test: 0.005806
time: 0.2490549087524414
time: 2.2365007400512695
[1, 5522] loss_train: 0.008432, loss_test: 0.005801
time: 0.24375653266906738
time: 2.219496726989746
[1, 5523] loss_train: 0.012666, loss_test: 0.005795
time: 0.2450547218322754
time: 2.2294986248016357
[1, 5524] loss_train: 0.010513, loss_test: 0.005792
time: 0.24305438995361328
time: 2.230001449584961
[1, 5525] loss_train: 0.005722, loss_test: 0.005788
time: 0.24506449699401855
time: 2.2264978885650635
[1, 5526] loss_train: 0.013739, loss_test: 0.005789
time: 0.24605441093444824
time: 2.2475030422210693
[1, 5527] loss_train: 0.011363, loss_test: 0.005792
time: 0.2450549602508545
time: 2.225497245788574
[1, 5528] loss_train: 0.005558, loss_test: 0.005797
time: 0.2450547218322754
time: 2.217495918273926
[1, 5529] loss_train: 0.007596, loss_test: 0.005796
time: 0.2450544834136963
time: 2.2130370140075684
[1, 5530] loss_train: 0.009982, loss_test: 0.005796
time: 0.26107168197631836
time: 2.261505126953125
[1, 5531] loss_train: 0.010248, loss_test: 0.005795
time: 0.2510561943054199
time: 2.223496913909912
[1, 5532] loss_train: 0.003754, loss_test: 0.005788
time: 0.2490549087524414
time: 2.2064943313598633
[1, 5533] loss_train: 0.008622, loss_test: 0.005784
time: 0.2490553855895996
time: 2.209494113922119
[1, 5534] loss_train: 0.005857, loss_test: 0.005778
time: 0.24306583404541016
time: 2.229498863220215
[1, 5535] loss_train: 0.000815, loss_test: 0.005769
time: 0.2450542449951172
time: 2.2214975357055664
[1, 5536] loss_train: 0.006091, loss_test: 0.005763
time: 0.24405360221862793
time: 2.2655231952667236
[1, 5537] loss_train: 0.007980, loss_test: 0.005758
time: 0.2450549602508545
time: 2.2284982204437256
[1, 5538] loss_train: 0.008626, loss_test: 0.005758
time: 0.24405455589294434
time: 2.2375118732452393
[1, 5539] loss_train: 0.001098, loss_test: 0.005761
time: 0.24405360221862793
time: 2.2265000343322754
[1, 5540] loss_train: 0.006810, loss_test: 0.005762
time: 0.25505757331848145
time: 2.301037073135376
[1, 5541] loss_train: 0.003719, loss_test: 0.005769
time: 0.24305391311645508
time: 2.2375025749206543
[1, 5542] loss_train: 0.008558, loss_test: 0.005770
time: 0.24405384063720703
time: 2.1964914798736572
[1, 5543] loss_train: 0.008102, loss_test: 0.005766
time: 0.24605417251586914
time: 2.23349928855896
[1, 5544] loss_train: 0.008944, loss_test: 0.005765
time: 0.24305367469787598
time: 2.2485032081604004
[1, 5545] loss_train: 0.004388, loss_test: 0.005769
time: 0.2440662384033203
time: 2.239504098892212
[1, 5546] loss_train: 0.002688, loss_test: 0.005773
time: 0.24405336380004883
time: 2.240501642227173
[1, 5547] loss_train: 0.003582, loss_test: 0.005774
time: 0.24306654930114746
time: 2.2354989051818848
[1, 5548] loss_train: 0.005151, loss_test: 0.005774
time: 0.2470552921295166
time: 2.2505109310150146
[1, 5549] loss_train: 0.004264, loss_test: 0.005773
time: 0.24405455589294434
time: 2.2034924030303955
[1, 5550] loss_train: 0.006883, loss_test: 0.005770
time: 0.25505709648132324
time: 2.2505550384521484
[1, 5551] loss_train: 0.005096, loss_test: 0.005767
time: 0.24806833267211914
time: 2.231498956680298
[1, 5552] loss_train: 0.012112, loss_test: 0.005765
time: 0.24405407905578613
time: 2.256518602371216
[1, 5553] loss_train: 0.005910, loss_test: 0.005762
time: 0.24805474281311035
time: 2.2775089740753174
[1, 5554] loss_train: 0.006372, loss_test: 0.005759
time: 0.2450549602508545
time: 2.218498945236206
[1, 5555] loss_train: 0.006081, loss_test: 0.005757
time: 0.24505376815795898
time: 2.1999013423919678
[1, 5556] loss_train: 0.005232, loss_test: 0.005753
time: 0.24605464935302734
time: 2.236513376235962
[1, 5557] loss_train: 0.010750, loss_test: 0.005751
time: 0.25005578994750977
time: 2.237393617630005
[1, 5558] loss_train: 0.007559, loss_test: 0.005750
time: 0.24505376815795898
time: 2.202010154724121
[1, 5559] loss_train: 0.002610, loss_test: 0.005751
time: 0.24958252906799316
time: 2.259504795074463
[1, 5560] loss_train: 0.019160, loss_test: 0.005749
time: 0.25505661964416504
time: 2.2284984588623047
[1, 5561] loss_train: 0.005342, loss_test: 0.005749
time: 0.2490551471710205
time: 2.2254974842071533
[1, 5562] loss_train: 0.002923, loss_test: 0.005751
time: 0.24305319786071777
time: 2.218496799468994
[1, 5563] loss_train: 0.007756, loss_test: 0.005751
time: 0.24405455589294434
time: 2.249518871307373
[1, 5564] loss_train: 0.005574, loss_test: 0.005754
time: 0.24305415153503418
time: 2.219496250152588
[1, 5565] loss_train: 0.008945, loss_test: 0.005753
time: 0.24306821823120117
time: 2.257505178451538
[1, 5566] loss_train: 0.001897, loss_test: 0.005753
time: 0.2450544834136963
time: 2.218496561050415
[1, 5567] loss_train: 0.010188, loss_test: 0.005753
time: 0.24505615234375
time: 2.2367305755615234
[1, 5568] loss_train: 0.017224, loss_test: 0.005747
time: 0.24405360221862793
time: 2.2355005741119385
[1, 5569] loss_train: 0.002795, loss_test: 0.005744
time: 0.24305343627929688
time: 2.1994943618774414
[1, 5570] loss_train: 0.013033, loss_test: 0.005744
time: 0.256056547164917
time: 2.278510093688965
[1, 5571] loss_train: 0.003938, loss_test: 0.005746
time: 0.25005507469177246
time: 2.2495036125183105
[1, 5572] loss_train: 0.010049, loss_test: 0.005749
time: 0.24305248260498047
time: 2.226496934890747
[1, 5573] loss_train: 0.006734, loss_test: 0.005753
time: 0.24506044387817383
time: 2.211494207382202
[1, 5574] loss_train: 0.007255, loss_test: 0.005759
time: 0.24305391311645508
time: 2.259505271911621
[1, 5575] loss_train: 0.003448, loss_test: 0.005766
time: 0.24521517753601074
time: 2.2224977016448975
[1, 5576] loss_train: 0.000798, loss_test: 0.005774
time: 0.2450542449951172
time: 2.21589732170105
[1, 5577] loss_train: 0.008832, loss_test: 0.005782
time: 0.24305343627929688
time: 2.228499174118042
[1, 5578] loss_train: 0.007935, loss_test: 0.005790
time: 0.24305438995361328
time: 2.2360188961029053
[1, 5579] loss_train: 0.005073, loss_test: 0.005798
time: 0.2450549602508545
time: 2.2405126094818115
[1, 5580] loss_train: 0.006820, loss_test: 0.005806
time: 0.25705718994140625
time: 2.2710120677948
[1, 5581] loss_train: 0.003073, loss_test: 0.005816
time: 0.24405384063720703
time: 2.2144956588745117
[1, 5582] loss_train: 0.001296, loss_test: 0.005828
time: 0.2470541000366211
time: 2.208494186401367
[1, 5583] loss_train: 0.006449, loss_test: 0.005833
time: 0.25005578994750977
time: 2.256504774093628
[1, 5584] loss_train: 0.004152, loss_test: 0.005834
time: 0.24805521965026855
time: 2.2314987182617188
[1, 5585] loss_train: 0.005093, loss_test: 0.005835
time: 0.24505400657653809
time: 2.2384467124938965
[1, 5586] loss_train: 0.000926, loss_test: 0.005837
time: 0.25005555152893066
time: 2.2244977951049805
[1, 5587] loss_train: 0.010587, loss_test: 0.005823
time: 0.2440633773803711
time: 2.2385027408599854
[1, 5588] loss_train: 0.004840, loss_test: 0.005810
time: 0.24605393409729004
time: 2.224000930786133
[1, 5589] loss_train: 0.012379, loss_test: 0.005793
time: 0.24405455589294434
time: 2.234520673751831
[1, 5590] loss_train: 0.016633, loss_test: 0.005771
time: 0.2550692558288574
time: 2.2495028972625732
[1, 5591] loss_train: 0.003252, loss_test: 0.005767
time: 0.24305438995361328
time: 2.2390341758728027
[1, 5592] loss_train: 0.009170, loss_test: 0.005777
time: 0.24405455589294434
time: 2.2495241165161133
[1, 5593] loss_train: 0.004326, loss_test: 0.005788
time: 0.24605488777160645
time: 2.1994917392730713
[1, 5594] loss_train: 0.008481, loss_test: 0.005801
time: 0.24412202835083008
time: 2.2505037784576416
[1, 5595] loss_train: 0.006644, loss_test: 0.005808
time: 0.24305343627929688
time: 2.2224974632263184
[1, 5596] loss_train: 0.007001, loss_test: 0.005809
time: 0.24205303192138672
time: 2.2274985313415527
[1, 5597] loss_train: 0.002786, loss_test: 0.005804
time: 0.24405455589294434
time: 2.2250242233276367
[1, 5598] loss_train: 0.011390, loss_test: 0.005787
time: 0.2450549602508545
time: 2.22054386138916
[1, 5599] loss_train: 0.007171, loss_test: 0.005777
time: 0.24406719207763672
time: 2.2195000648498535
[1, 5600] loss_train: 0.007057, loss_test: 0.005774
time: 0.25705623626708984
time: 2.242502450942993
[1, 5601] loss_train: 0.008791, loss_test: 0.005783
time: 0.24406671524047852
time: 2.247518539428711
[1, 5602] loss_train: 0.007844, loss_test: 0.005806
time: 0.2450542449951172
time: 2.221497058868408
[1, 5603] loss_train: 0.010155, loss_test: 0.005835
time: 0.24405455589294434
time: 2.202997922897339
[1, 5604] loss_train: 0.005012, loss_test: 0.005865
time: 0.2450542449951172
time: 2.2104945182800293
[1, 5605] loss_train: 0.005522, loss_test: 0.005900
time: 0.2490687370300293
time: 2.210493564605713
[1, 5606] loss_train: 0.008900, loss_test: 0.005917
time: 0.24305391311645508
time: 2.2224972248077393
[1, 5607] loss_train: 0.002533, loss_test: 0.005935
time: 0.25005555152893066
time: 2.2274982929229736
[1, 5608] loss_train: 0.011214, loss_test: 0.005944
time: 0.24405384063720703
time: 2.221497058868408
[1, 5609] loss_train: 0.006646, loss_test: 0.005943
time: 0.24405455589294434
time: 2.247502088546753
[1, 5610] loss_train: 0.002638, loss_test: 0.005942
time: 0.25705790519714355
time: 2.2775118350982666
[1, 5611] loss_train: 0.001355, loss_test: 0.005936
time: 0.24805521965026855
time: 2.220473051071167
[1, 5612] loss_train: 0.012905, loss_test: 0.005860
time: 0.24405360221862793
time: 2.243502616882324
[1, 5613] loss_train: 0.007276, loss_test: 0.005812
time: 0.24405336380004883
time: 2.2265021800994873
[1, 5614] loss_train: 0.007771, loss_test: 0.005811
time: 0.2450542449951172
time: 2.223496913909912
[1, 5615] loss_train: 0.004002, loss_test: 0.005850
time: 0.24605488777160645
time: 2.231522560119629
[1, 5616] loss_train: 0.006663, loss_test: 0.005909
time: 0.24605488777160645
time: 2.2144951820373535
[1, 5617] loss_train: 0.004840, loss_test: 0.005950
time: 0.2490549087524414
time: 2.2025246620178223
[1, 5618] loss_train: 0.008054, loss_test: 0.005966
time: 0.24305391311645508
time: 2.1995081901550293
[1, 5619] loss_train: 0.002791, loss_test: 0.005903
time: 0.24506759643554688
time: 2.204996109008789
[1, 5620] loss_train: 0.009571, loss_test: 0.005838
time: 0.25905823707580566
time: 2.249502420425415
[1, 5621] loss_train: 0.001631, loss_test: 0.005798
time: 0.24405431747436523
time: 2.2448325157165527
[1, 5622] loss_train: 0.002706, loss_test: 0.005782
time: 0.2450556755065918
time: 2.2274980545043945
[1, 5623] loss_train: 0.009358, loss_test: 0.005787
time: 0.24505400657653809
time: 2.2355003356933594
[1, 5624] loss_train: 0.006279, loss_test: 0.005793
time: 0.254056453704834
time: 2.2375001907348633
[1, 5625] loss_train: 0.009642, loss_test: 0.005801
time: 0.24605441093444824
time: 2.2113037109375
[1, 5626] loss_train: 0.006961, loss_test: 0.005811
time: 0.24805450439453125
time: 2.2134952545166016
[1, 5627] loss_train: 0.004732, loss_test: 0.005819
time: 0.24405479431152344
time: 2.203505516052246
[1, 5628] loss_train: 0.004943, loss_test: 0.005829
time: 0.2450544834136963
time: 2.2044930458068848
[1, 5629] loss_train: 0.011539, loss_test: 0.005839
time: 0.24405550956726074
time: 2.2110097408294678
[1, 5630] loss_train: 0.004989, loss_test: 0.005847
time: 0.25608110427856445
time: 2.2194955348968506
[1, 5631] loss_train: 0.002725, loss_test: 0.005851
time: 0.2450547218322754
time: 2.216495990753174
[1, 5632] loss_train: 0.004929, loss_test: 0.005845
time: 0.24505400657653809
time: 2.2355000972747803
[1, 5633] loss_train: 0.006660, loss_test: 0.005827
time: 0.24405455589294434
time: 2.2044930458068848
[1, 5634] loss_train: 0.007445, loss_test: 0.005811
time: 0.24405360221862793
time: 2.2270047664642334
[1, 5635] loss_train: 0.009613, loss_test: 0.005797
time: 0.24605441093444824
time: 2.2164955139160156
[1, 5636] loss_train: 0.006706, loss_test: 0.005787
time: 0.24505352973937988
time: 2.2255117893218994
[1, 5637] loss_train: 0.007272, loss_test: 0.005772
time: 0.24405431747436523
time: 2.2375001907348633
[1, 5638] loss_train: 0.007864, loss_test: 0.005761
time: 0.24405479431152344
time: 2.2304985523223877
[1, 5639] loss_train: 0.003488, loss_test: 0.005756
time: 0.2490549087524414
time: 2.2300186157226562
[1, 5640] loss_train: 0.008351, loss_test: 0.005752
time: 0.2580578327178955
time: 2.2715260982513428
[1, 5641] loss_train: 0.004115, loss_test: 0.005759
time: 0.2560696601867676
time: 2.2351183891296387
[1, 5642] loss_train: 0.006499, loss_test: 0.005780
time: 0.24505376815795898
time: 2.217498540878296
[1, 5643] loss_train: 0.009539, loss_test: 0.005798
time: 0.25005578994750977
time: 2.2174956798553467
[1, 5644] loss_train: 0.004273, loss_test: 0.005800
time: 0.24505400657653809
time: 2.2254981994628906
[1, 5645] loss_train: 0.003634, loss_test: 0.005792
time: 0.2470545768737793
time: 2.198021411895752
[1, 5646] loss_train: 0.005429, loss_test: 0.005783
time: 0.24405455589294434
time: 2.2264978885650635
[1, 5647] loss_train: 0.002838, loss_test: 0.005769
time: 0.24405479431152344
time: 2.2485177516937256
[1, 5648] loss_train: 0.005584, loss_test: 0.005762
time: 0.24305272102355957
time: 2.2224972248077393
[1, 5649] loss_train: 0.004338, loss_test: 0.005759
time: 0.24405336380004883
time: 2.2234981060028076
[1, 5650] loss_train: 0.002635, loss_test: 0.005765
time: 0.25505614280700684
time: 2.230513095855713
[1, 5651] loss_train: 0.003345, loss_test: 0.005781
time: 0.2450542449951172
time: 2.2412545680999756
[1, 5652] loss_train: 0.007054, loss_test: 0.005799
time: 0.2450544834136963
time: 2.207494020462036
[1, 5653] loss_train: 0.009359, loss_test: 0.005813
time: 0.24305367469787598
time: 2.1994919776916504
[1, 5654] loss_train: 0.003005, loss_test: 0.005829
time: 0.24305391311645508
time: 2.2034926414489746
[1, 5655] loss_train: 0.006288, loss_test: 0.005836
time: 0.24605560302734375
time: 2.2139999866485596
[1, 5656] loss_train: 0.007396, loss_test: 0.005842
time: 0.24305438995361328
time: 2.2144954204559326
[1, 5657] loss_train: 0.005563, loss_test: 0.005842
time: 0.24505376815795898
time: 2.2735085487365723
[1, 5658] loss_train: 0.007462, loss_test: 0.005841
time: 0.252056360244751
time: 2.2265243530273438
[1, 5659] loss_train: 0.009378, loss_test: 0.005831
time: 0.24505400657653809
time: 2.2391183376312256
[1, 5660] loss_train: 0.003566, loss_test: 0.005820
time: 0.26105785369873047
time: 2.251007556915283
[1, 5661] loss_train: 0.014736, loss_test: 0.005802
time: 0.2470555305480957
time: 2.2284977436065674
[1, 5662] loss_train: 0.006025, loss_test: 0.005788
time: 0.25005531311035156
time: 2.2134947776794434
[1, 5663] loss_train: 0.008247, loss_test: 0.005783
time: 0.24405574798583984
time: 2.223496913909912
[1, 5664] loss_train: 0.010346, loss_test: 0.005786
time: 0.2470543384552002
time: 2.243502140045166
[1, 5665] loss_train: 0.006250, loss_test: 0.005792
time: 0.2450547218322754
time: 2.2535042762756348
[1, 5666] loss_train: 0.001081, loss_test: 0.005794
time: 0.24505901336669922
time: 2.231499671936035
[1, 5667] loss_train: 0.002226, loss_test: 0.005796
time: 0.24505400657653809
time: 2.2185845375061035
[1, 5668] loss_train: 0.010686, loss_test: 0.005792
time: 0.24605512619018555
time: 2.2154955863952637
[1, 5669] loss_train: 0.004252, loss_test: 0.005785
time: 0.24605441093444824
time: 2.2373459339141846
[1, 5670] loss_train: 0.012816, loss_test: 0.005779
time: 0.25505661964416504
time: 2.246936082839966
[1, 5671] loss_train: 0.005047, loss_test: 0.005774
time: 0.24605417251586914
time: 2.2355005741119385
[1, 5672] loss_train: 0.013855, loss_test: 0.005770
time: 0.24605512619018555
time: 2.235499620437622
[1, 5673] loss_train: 0.005386, loss_test: 0.005766
time: 0.2450549602508545
time: 2.2074930667877197
[1, 5674] loss_train: 0.006777, loss_test: 0.005764
time: 0.24305415153503418
time: 2.2415013313293457
[1, 5675] loss_train: 0.004406, loss_test: 0.005765
time: 0.24305415153503418
time: 2.1884891986846924
[1, 5676] loss_train: 0.003732, loss_test: 0.005771
time: 0.24406671524047852
time: 2.227520704269409
[1, 5677] loss_train: 0.006147, loss_test: 0.005776
time: 0.24305343627929688
time: 2.2054941654205322
[1, 5678] loss_train: 0.008240, loss_test: 0.005773
time: 0.2470543384552002
time: 2.197514772415161
[1, 5679] loss_train: 0.007456, loss_test: 0.005766
time: 0.2490549087524414
time: 2.208026647567749
[1, 5680] loss_train: 0.004514, loss_test: 0.005762
time: 0.25492382049560547
time: 2.2385008335113525
[1, 5681] loss_train: 0.011177, loss_test: 0.005754
time: 0.24739503860473633
time: 2.217495918273926
[1, 5682] loss_train: 0.010405, loss_test: 0.005748
time: 0.2450709342956543
time: 2.2234973907470703
[1, 5683] loss_train: 0.005452, loss_test: 0.005744
time: 0.2470545768737793
time: 2.2435011863708496
[1, 5684] loss_train: 0.004125, loss_test: 0.005744
time: 0.24405956268310547
time: 2.215496301651001
[1, 5685] loss_train: 0.002303, loss_test: 0.005744
time: 0.2450542449951172
time: 2.2405033111572266
[1, 5686] loss_train: 0.002398, loss_test: 0.005745
time: 0.2450549602508545
time: 2.223497152328491
[1, 5687] loss_train: 0.008535, loss_test: 0.005746
time: 0.2450544834136963
time: 2.2051937580108643
[1, 5688] loss_train: 0.006668, loss_test: 0.005747
time: 0.24605464935302734
time: 2.218496561050415
[1, 5689] loss_train: 0.006592, loss_test: 0.005746
time: 0.24407958984375
time: 2.2045133113861084
[1, 5690] loss_train: 0.003079, loss_test: 0.005745
time: 0.25508642196655273
time: 2.2530462741851807
[1, 5691] loss_train: 0.015489, loss_test: 0.005745
time: 0.24405670166015625
time: 2.1904897689819336
[1, 5692] loss_train: 0.014892, loss_test: 0.005759
time: 0.24306678771972656
time: 2.208998203277588
[1, 5693] loss_train: 0.001324, loss_test: 0.005780
time: 0.24506711959838867
time: 2.2284984588623047
[1, 5694] loss_train: 0.001461, loss_test: 0.005788
time: 0.24805498123168945
time: 2.2225143909454346
[1, 5695] loss_train: 0.007925, loss_test: 0.005798
time: 0.2470684051513672
time: 2.219021797180176
[1, 5696] loss_train: 0.005799, loss_test: 0.005802
time: 0.2510561943054199
time: 2.2125120162963867
[1, 5697] loss_train: 0.004752, loss_test: 0.005807
time: 0.24405384063720703
time: 2.2505030632019043
[1, 5698] loss_train: 0.009573, loss_test: 0.005809
time: 0.2470557689666748
time: 2.2405004501342773
[1, 5699] loss_train: 0.007070, loss_test: 0.005808
time: 0.24305367469787598
time: 2.1919989585876465
[1, 5700] loss_train: 0.005620, loss_test: 0.005805
time: 0.2560572624206543
time: 2.2695071697235107
[1, 5701] loss_train: 0.006481, loss_test: 0.005805
time: 0.24405479431152344
time: 2.2235076427459717
[1, 5702] loss_train: 0.006548, loss_test: 0.005802
time: 0.24605441093444824
time: 2.2204959392547607
[1, 5703] loss_train: 0.012573, loss_test: 0.005799
time: 0.24405455589294434
time: 2.230516195297241
[1, 5704] loss_train: 0.009004, loss_test: 0.005797
time: 0.24405431747436523
time: 2.21150279045105
[1, 5705] loss_train: 0.009746, loss_test: 0.005799
time: 0.2440652847290039
time: 2.206493854522705
[1, 5706] loss_train: 0.007082, loss_test: 0.005801
time: 0.24406790733337402
time: 2.2019975185394287
[1, 5707] loss_train: 0.012948, loss_test: 0.005804
time: 0.24406790733337402
time: 2.247241497039795
[1, 5708] loss_train: 0.012856, loss_test: 0.005803
time: 0.24405407905578613
time: 2.2245163917541504
[1, 5709] loss_train: 0.003047, loss_test: 0.005803
time: 0.24405431747436523
time: 2.2065114974975586
[1, 5710] loss_train: 0.005046, loss_test: 0.005802
time: 0.2560570240020752
time: 2.238499641418457
[1, 5711] loss_train: 0.008012, loss_test: 0.005800
time: 0.24605607986450195
time: 2.2044928073883057
[1, 5712] loss_train: 0.006219, loss_test: 0.005798
time: 0.24405384063720703
time: 2.216495990753174
[1, 5713] loss_train: 0.003870, loss_test: 0.005791
time: 0.2470545768737793
time: 2.280510663986206
[1, 5714] loss_train: 0.000716, loss_test: 0.005785
time: 0.24605441093444824
time: 2.230499267578125
[1, 5715] loss_train: 0.005306, loss_test: 0.005781
time: 0.2540566921234131
time: 2.205014228820801
[1, 5716] loss_train: 0.006156, loss_test: 0.005784
time: 0.24305391311645508
time: 2.1964917182922363
[1, 5717] loss_train: 0.009437, loss_test: 0.005787
time: 0.24405455589294434
time: 2.236499786376953
[1, 5718] loss_train: 0.005432, loss_test: 0.005790
time: 0.24305343627929688
time: 2.2254981994628906
[1, 5719] loss_train: 0.004196, loss_test: 0.005797
time: 0.24306964874267578
time: 2.2144951820373535
[1, 5720] loss_train: 0.004134, loss_test: 0.005806
time: 0.2540562152862549
time: 2.2520079612731934
[1, 5721] loss_train: 0.003911, loss_test: 0.005817
time: 0.24405479431152344
time: 2.226321220397949
[1, 5722] loss_train: 0.006273, loss_test: 0.005823
time: 0.24909162521362305
time: 2.2935125827789307
[1, 5723] loss_train: 0.009918, loss_test: 0.005815
time: 0.24405431747436523
time: 2.221012830734253
[1, 5724] loss_train: 0.012638, loss_test: 0.005787
time: 0.24605417251586914
time: 2.233499765396118
[1, 5725] loss_train: 0.013184, loss_test: 0.005771
time: 0.24405384063720703
time: 2.1999950408935547
[1, 5726] loss_train: 0.013259, loss_test: 0.005779
time: 0.24405455589294434
time: 2.221499443054199
[1, 5727] loss_train: 0.008722, loss_test: 0.005792
time: 0.24405455589294434
time: 2.206005573272705
[1, 5728] loss_train: 0.008390, loss_test: 0.005815
time: 0.24405479431152344
time: 2.2605042457580566
[1, 5729] loss_train: 0.001784, loss_test: 0.005828
time: 0.24506688117980957
time: 2.2000129222869873
[1, 5730] loss_train: 0.006801, loss_test: 0.005821
time: 0.2560553550720215
time: 2.279510259628296
[1, 5731] loss_train: 0.011755, loss_test: 0.005812
time: 0.24405455589294434
time: 2.2535035610198975
[1, 5732] loss_train: 0.007244, loss_test: 0.005811
time: 0.25305604934692383
time: 2.2224972248077393
[1, 5733] loss_train: 0.013236, loss_test: 0.005804
time: 0.2450547218322754
time: 2.219496726989746
[1, 5734] loss_train: 0.003032, loss_test: 0.005797
time: 0.24806857109069824
time: 2.2415013313293457
[1, 5735] loss_train: 0.001063, loss_test: 0.005776
time: 0.24305462837219238
time: 2.2144951820373535
[1, 5736] loss_train: 0.001405, loss_test: 0.005759
time: 0.24926972389221191
time: 2.235326051712036
[1, 5737] loss_train: 0.007798, loss_test: 0.005750
time: 0.2450547218322754
time: 2.214493751525879
[1, 5738] loss_train: 0.001049, loss_test: 0.005751
time: 0.24805474281311035
time: 2.239501953125
[1, 5739] loss_train: 0.011632, loss_test: 0.005759
time: 0.24605393409729004
time: 2.2024924755096436
[1, 5740] loss_train: 0.010850, loss_test: 0.005767
time: 0.2550640106201172
time: 2.255504608154297
[1, 5741] loss_train: 0.008261, loss_test: 0.005768
time: 0.24305438995361328
time: 2.2264978885650635
[1, 5742] loss_train: 0.004313, loss_test: 0.005767
time: 0.24605512619018555
time: 2.2045023441314697
[1, 5743] loss_train: 0.010631, loss_test: 0.005760
time: 0.24305510520935059
time: 2.2204959392547607
[1, 5744] loss_train: 0.003515, loss_test: 0.005752
time: 0.24405479431152344
time: 2.241501569747925
[1, 5745] loss_train: 0.003964, loss_test: 0.005748
time: 0.24405384063720703
time: 2.244502305984497
[1, 5746] loss_train: 0.005629, loss_test: 0.005745
time: 0.24405455589294434
time: 2.24550199508667
[1, 5747] loss_train: 0.000857, loss_test: 0.005743
time: 0.24205398559570312
time: 2.238520383834839
[1, 5748] loss_train: 0.005364, loss_test: 0.005742
time: 0.24405431747436523
time: 2.21750545501709
[1, 5749] loss_train: 0.007379, loss_test: 0.005741
time: 0.24505352973937988
time: 2.2110209465026855
[1, 5750] loss_train: 0.005043, loss_test: 0.005740
time: 0.25505852699279785
time: 2.25750470161438
[1, 5751] loss_train: 0.008074, loss_test: 0.005740
time: 0.2450547218322754
time: 2.19749116897583
[1, 5752] loss_train: 0.006138, loss_test: 0.005742
time: 0.24306607246398926
time: 2.2605068683624268
[1, 5753] loss_train: 0.006136, loss_test: 0.005743
time: 0.2450544834136963
time: 2.1994926929473877
[1, 5754] loss_train: 0.000996, loss_test: 0.005744
time: 0.24505376815795898
time: 2.221513271331787
[1, 5755] loss_train: 0.008008, loss_test: 0.005746
time: 0.24805450439453125
time: 2.2099978923797607
[1, 5756] loss_train: 0.005870, loss_test: 0.005746
time: 0.24605512619018555
time: 2.252017021179199
[1, 5757] loss_train: 0.004472, loss_test: 0.005747
time: 0.24805760383605957
time: 2.2264976501464844
[1, 5758] loss_train: 0.003796, loss_test: 0.005751
time: 0.24405431747436523
time: 2.2620434761047363
[1, 5759] loss_train: 0.006343, loss_test: 0.005755
time: 0.24805545806884766
time: 2.2255187034606934
[1, 5760] loss_train: 0.004323, loss_test: 0.005761
time: 0.25505685806274414
time: 2.22249698638916
[1, 5761] loss_train: 0.008298, loss_test: 0.005766
time: 0.24205613136291504
time: 2.2024922370910645
[1, 5762] loss_train: 0.005911, loss_test: 0.005769
time: 0.24405479431152344
time: 2.236499547958374
[1, 5763] loss_train: 0.003879, loss_test: 0.005773
time: 0.24405455589294434
time: 2.2325010299682617
[1, 5764] loss_train: 0.002770, loss_test: 0.005779
time: 0.24406719207763672
time: 2.2159993648529053
[1, 5765] loss_train: 0.001915, loss_test: 0.005786
time: 0.24305367469787598
time: 2.2094945907592773
[1, 5766] loss_train: 0.006861, loss_test: 0.005787
time: 0.24805474281311035
time: 2.2500252723693848
[1, 5767] loss_train: 0.002584, loss_test: 0.005790
time: 0.24305415153503418
time: 2.20849347114563
[1, 5768] loss_train: 0.008210, loss_test: 0.005786
time: 0.24305486679077148
time: 2.227029800415039
[1, 5769] loss_train: 0.013473, loss_test: 0.005777
time: 0.24505400657653809
time: 2.1974921226501465
[1, 5770] loss_train: 0.004624, loss_test: 0.005767
time: 0.254056453704834
time: 2.2735092639923096
[1, 5771] loss_train: 0.008084, loss_test: 0.005758
time: 0.24305438995361328
time: 2.2334988117218018
[1, 5772] loss_train: 0.000559, loss_test: 0.005754
time: 0.24605441093444824
time: 2.2244980335235596
[1, 5773] loss_train: 0.006317, loss_test: 0.005754
time: 0.2530558109283447
time: 2.2094945907592773
[1, 5774] loss_train: 0.008549, loss_test: 0.005751
time: 0.25005578994750977
time: 2.1894898414611816
[1, 5775] loss_train: 0.005020, loss_test: 0.005749
time: 0.24505376815795898
time: 2.221001386642456
[1, 5776] loss_train: 0.004731, loss_test: 0.005748
time: 0.2470548152923584
time: 2.2144951820373535
[1, 5777] loss_train: 0.010575, loss_test: 0.005747
time: 0.24405360221862793
time: 2.2234981060028076
[1, 5778] loss_train: 0.006478, loss_test: 0.005748
time: 0.2470545768737793
time: 2.222003936767578
[1, 5779] loss_train: 0.011604, loss_test: 0.005749
time: 0.24805498123168945
time: 2.2085041999816895
[1, 5780] loss_train: 0.013509, loss_test: 0.005747
time: 0.2560563087463379
time: 2.2845115661621094
[1, 5781] loss_train: 0.008723, loss_test: 0.005745
time: 0.24605464935302734
time: 2.260505437850952
[1, 5782] loss_train: 0.011467, loss_test: 0.005750
time: 0.24506807327270508
time: 2.218496084213257
[1, 5783] loss_train: 0.007400, loss_test: 0.005763
time: 0.24405336380004883
time: 2.207493782043457
[1, 5784] loss_train: 0.008745, loss_test: 0.005779
time: 0.24405360221862793
time: 2.2265145778656006
[1, 5785] loss_train: 0.003612, loss_test: 0.005799
time: 0.24505400657653809
time: 2.2104949951171875
[1, 5786] loss_train: 0.008916, loss_test: 0.005811
time: 0.24405837059020996
time: 2.2279508113861084
[1, 5787] loss_train: 0.012629, loss_test: 0.005813
time: 0.24805450439453125
time: 2.204493522644043
[1, 5788] loss_train: 0.009038, loss_test: 0.005804
time: 0.24305367469787598
time: 2.2274985313415527
[1, 5789] loss_train: 0.006307, loss_test: 0.005798
time: 0.24409151077270508
time: 2.236250400543213
[1, 5790] loss_train: 0.007398, loss_test: 0.005789
time: 0.25705695152282715
time: 2.243501901626587
[1, 5791] loss_train: 0.006944, loss_test: 0.005783
time: 0.24805521965026855
time: 2.2373406887054443
[1, 5792] loss_train: 0.001742, loss_test: 0.005782
time: 0.24405336380004883
time: 2.2109994888305664
[1, 5793] loss_train: 0.002424, loss_test: 0.005794
time: 0.25005316734313965
time: 2.2124946117401123
[1, 5794] loss_train: 0.006412, loss_test: 0.005812
time: 0.2470550537109375
time: 2.244501829147339
[1, 5795] loss_train: 0.006776, loss_test: 0.005831
time: 0.2470548152923584
time: 2.237525701522827
[1, 5796] loss_train: 0.008470, loss_test: 0.005841
time: 0.24605488777160645
time: 2.1914899349212646
[1, 5797] loss_train: 0.003851, loss_test: 0.005858
time: 0.2450544834136963
time: 2.232501745223999
[1, 5798] loss_train: 0.008765, loss_test: 0.005862
time: 0.24506688117980957
time: 2.2134954929351807
[1, 5799] loss_train: 0.002649, loss_test: 0.005862
time: 0.24605488777160645
time: 2.2284979820251465
[1, 5800] loss_train: 0.007261, loss_test: 0.005854
time: 0.25406908988952637
time: 2.2455034255981445
[1, 5801] loss_train: 0.007095, loss_test: 0.005844
time: 0.24505376815795898
time: 2.2224974632263184
[1, 5802] loss_train: 0.006636, loss_test: 0.005833
time: 0.24405455589294434
time: 2.233499526977539
[1, 5803] loss_train: 0.003431, loss_test: 0.005825
time: 0.24305486679077148
time: 2.2324984073638916
[1, 5804] loss_train: 0.003405, loss_test: 0.005818
time: 0.24405431747436523
time: 2.2415013313293457
[1, 5805] loss_train: 0.006654, loss_test: 0.005808
time: 0.24407029151916504
time: 2.2700142860412598
[1, 5806] loss_train: 0.005704, loss_test: 0.005799
time: 0.24305367469787598
time: 2.2074942588806152
[1, 5807] loss_train: 0.015938, loss_test: 0.005775
time: 0.24205327033996582
time: 2.2505030632019043
[1, 5808] loss_train: 0.003412, loss_test: 0.005781
time: 0.24405479431152344
time: 2.195491075515747
[1, 5809] loss_train: 0.008676, loss_test: 0.005817
time: 0.24307894706726074
time: 2.2460384368896484
[1, 5810] loss_train: 0.005838, loss_test: 0.005853
time: 0.25505661964416504
time: 2.2044923305511475
[1, 5811] loss_train: 0.007622, loss_test: 0.005882
time: 0.2450551986694336
time: 2.207493782043457
[1, 5812] loss_train: 0.005385, loss_test: 0.005904
time: 0.25005626678466797
time: 2.2455055713653564
[1, 5813] loss_train: 0.004727, loss_test: 0.005853
time: 0.2450544834136963
time: 2.222499370574951
[1, 5814] loss_train: 0.004544, loss_test: 0.005817
time: 0.2490544319152832
time: 2.231499195098877
[1, 5815] loss_train: 0.001797, loss_test: 0.005784
time: 0.24405431747436523
time: 2.2365193367004395
[1, 5816] loss_train: 0.007128, loss_test: 0.005763
time: 0.2470548152923584
time: 2.219496488571167
[1, 5817] loss_train: 0.003473, loss_test: 0.005764
time: 0.24405384063720703
time: 2.2094948291778564
[1, 5818] loss_train: 0.001834, loss_test: 0.005778
time: 0.2450549602508545
time: 2.2264976501464844
[1, 5819] loss_train: 0.004256, loss_test: 0.005803
time: 0.24405384063720703
time: 2.2390170097351074
[1, 5820] loss_train: 0.001961, loss_test: 0.005836
time: 0.2540566921234131
time: 2.2254979610443115
[1, 5821] loss_train: 0.008104, loss_test: 0.005852
time: 0.2420661449432373
time: 2.241516590118408
[1, 5822] loss_train: 0.003681, loss_test: 0.005868
time: 0.24305367469787598
time: 2.203493118286133
[1, 5823] loss_train: 0.005645, loss_test: 0.005879
time: 0.24406671524047852
time: 2.2164969444274902
[1, 5824] loss_train: 0.004465, loss_test: 0.005889
time: 0.24405312538146973
time: 2.2134957313537598
[1, 5825] loss_train: 0.008958, loss_test: 0.005885
time: 0.24305391311645508
time: 2.2294983863830566
[1, 5826] loss_train: 0.010745, loss_test: 0.005868
time: 0.24406838417053223
time: 2.182487964630127
[1, 5827] loss_train: 0.009772, loss_test: 0.005844
time: 0.24805426597595215
time: 2.207986354827881
[1, 5828] loss_train: 0.006588, loss_test: 0.005822
time: 0.24405384063720703
time: 2.228498935699463
[1, 5829] loss_train: 0.003063, loss_test: 0.005810
time: 0.2510561943054199
time: 2.2345075607299805
[1, 5830] loss_train: 0.001176, loss_test: 0.005810
time: 0.25505614280700684
time: 2.282510995864868
[1, 5831] loss_train: 0.009203, loss_test: 0.005813
time: 0.25005602836608887
time: 2.2294983863830566
[1, 5832] loss_train: 0.005793, loss_test: 0.005810
time: 0.2510557174682617
time: 2.2365007400512695
[1, 5833] loss_train: 0.005471, loss_test: 0.005809
time: 0.2470543384552002
time: 2.2395009994506836
[1, 5834] loss_train: 0.003008, loss_test: 0.005810
time: 0.24305343627929688
time: 2.2110044956207275
[1, 5835] loss_train: 0.002474, loss_test: 0.005803
time: 0.24405360221862793
time: 2.2214975357055664
[1, 5836] loss_train: 0.005993, loss_test: 0.005791
time: 0.25008130073547363
time: 2.2385005950927734
[1, 5837] loss_train: 0.003999, loss_test: 0.005782
time: 0.24505400657653809
time: 2.249591588973999
[1, 5838] loss_train: 0.009279, loss_test: 0.005775
time: 0.24505400657653809
time: 2.2635064125061035
[1, 5839] loss_train: 0.005734, loss_test: 0.005764
time: 0.24405479431152344
time: 2.244518280029297
[1, 5840] loss_train: 0.007439, loss_test: 0.005759
time: 0.2560572624206543
time: 2.2855136394500732
[1, 5841] loss_train: 0.002148, loss_test: 0.005757
time: 0.24305367469787598
time: 2.233499765396118
[1, 5842] loss_train: 0.006304, loss_test: 0.005756
time: 0.24205470085144043
time: 2.2425014972686768
[1, 5843] loss_train: 0.002544, loss_test: 0.005759
time: 0.24405407905578613
time: 2.2375004291534424
[1, 5844] loss_train: 0.009190, loss_test: 0.005765
time: 0.24305391311645508
time: 2.2495031356811523
[1, 5845] loss_train: 0.002316, loss_test: 0.005774
time: 0.24805474281311035
time: 2.2094945907592773
[1, 5846] loss_train: 0.001326, loss_test: 0.005788
time: 0.24305343627929688
time: 2.209016799926758
[1, 5847] loss_train: 0.015088, loss_test: 0.005787
time: 0.24305367469787598
time: 2.221000909805298
[1, 5848] loss_train: 0.011742, loss_test: 0.005782
time: 0.24605441093444824
time: 2.231508493423462
[1, 5849] loss_train: 0.008234, loss_test: 0.005771
time: 0.24305343627929688
time: 2.2190067768096924
[1, 5850] loss_train: 0.003987, loss_test: 0.005765
time: 0.25505661964416504
time: 2.2415013313293457
[1, 5851] loss_train: 0.005744, loss_test: 0.005759
time: 0.24405360221862793
time: 2.2024929523468018
[1, 5852] loss_train: 0.007052, loss_test: 0.005757
time: 0.24905610084533691
time: 2.237499952316284
[1, 5853] loss_train: 0.002689, loss_test: 0.005758
time: 0.2450542449951172
time: 2.2395009994506836
[1, 5854] loss_train: 0.005307, loss_test: 0.005760
time: 0.24605417251586914
time: 2.2114951610565186
[1, 5855] loss_train: 0.009404, loss_test: 0.005762
time: 0.24405455589294434
time: 2.20849347114563
[1, 5856] loss_train: 0.002236, loss_test: 0.005760
time: 0.25005626678466797
time: 2.230516195297241
[1, 5857] loss_train: 0.002978, loss_test: 0.005756
time: 0.24305462837219238
time: 2.208493232727051
[1, 5858] loss_train: 0.005171, loss_test: 0.005753
time: 0.2450547218322754
time: 2.207493782043457
[1, 5859] loss_train: 0.002753, loss_test: 0.005755
time: 0.24505376815795898
time: 2.219017267227173
[1, 5860] loss_train: 0.003295, loss_test: 0.005766
time: 0.2580571174621582
time: 2.268510103225708
[1, 5861] loss_train: 0.006930, loss_test: 0.005782
time: 0.2450544834136963
time: 2.2114944458007812
[1, 5862] loss_train: 0.004770, loss_test: 0.005799
time: 0.24706244468688965
time: 2.231001853942871
[1, 5863] loss_train: 0.004119, loss_test: 0.005815
time: 0.24505400657653809
time: 2.2124955654144287
[1, 5864] loss_train: 0.007447, loss_test: 0.005814
time: 0.24405431747436523
time: 2.2154970169067383
[1, 5865] loss_train: 0.006724, loss_test: 0.005812
time: 0.24405360221862793
time: 2.2314999103546143
[1, 5866] loss_train: 0.011830, loss_test: 0.005799
time: 0.24510979652404785
time: 2.2144837379455566
[1, 5867] loss_train: 0.008244, loss_test: 0.005781
time: 0.24305343627929688
time: 2.2244980335235596
[1, 5868] loss_train: 0.005631, loss_test: 0.005768
time: 0.24607253074645996
time: 2.231515645980835
[1, 5869] loss_train: 0.002155, loss_test: 0.005761
time: 0.24805474281311035
time: 2.2495036125183105
[1, 5870] loss_train: 0.002195, loss_test: 0.005759
time: 0.2560567855834961
time: 2.2355000972747803
[1, 5871] loss_train: 0.015986, loss_test: 0.005753
time: 0.24405121803283691
time: 2.219496250152588
[1, 5872] loss_train: 0.004799, loss_test: 0.005757
time: 0.24605512619018555
time: 2.187490701675415
[1, 5873] loss_train: 0.000936, loss_test: 0.005766
time: 0.25005531311035156
time: 2.198491334915161
[1, 5874] loss_train: 0.013006, loss_test: 0.005775
time: 0.24305462837219238
time: 2.243502378463745
[1, 5875] loss_train: 0.007736, loss_test: 0.005788
time: 0.24807000160217285
time: 2.2385001182556152
[1, 5876] loss_train: 0.005536, loss_test: 0.005799
time: 0.2470555305480957
time: 2.235499620437622
[1, 5877] loss_train: 0.006037, loss_test: 0.005805
time: 0.24306893348693848
time: 2.2234978675842285
[1, 5878] loss_train: 0.012326, loss_test: 0.005802
time: 0.24105310440063477
time: 2.2254979610443115
[1, 5879] loss_train: 0.006281, loss_test: 0.005800
time: 0.24405479431152344
time: 2.2105162143707275
[1, 5880] loss_train: 0.007352, loss_test: 0.005794
time: 0.25305652618408203
time: 2.236499786376953
[1, 5881] loss_train: 0.015795, loss_test: 0.005794
time: 0.2450544834136963
time: 2.2150018215179443
[1, 5882] loss_train: 0.016553, loss_test: 0.005792
time: 0.24405407905578613
time: 2.2114977836608887
[1, 5883] loss_train: 0.005981, loss_test: 0.005780
time: 0.2450542449951172
time: 2.2284982204437256
[1, 5884] loss_train: 0.002869, loss_test: 0.005768
time: 0.24505376815795898
time: 2.224146842956543
[1, 5885] loss_train: 0.004113, loss_test: 0.005756
time: 0.24305295944213867
time: 2.202510356903076
[1, 5886] loss_train: 0.002552, loss_test: 0.005750
time: 0.24605488777160645
time: 2.2144949436187744
[1, 5887] loss_train: 0.007534, loss_test: 0.005753
time: 0.24405455589294434
time: 2.235499143600464
[1, 5888] loss_train: 0.003136, loss_test: 0.005767
time: 0.24905610084533691
time: 2.2605063915252686
[1, 5889] loss_train: 0.013721, loss_test: 0.005779
time: 0.2490551471710205
time: 2.2054927349090576
[1, 5890] loss_train: 0.004460, loss_test: 0.005792
time: 0.2620582580566406
time: 2.2565062046051025
[1, 5891] loss_train: 0.006917, loss_test: 0.005804
time: 0.24605536460876465
time: 2.2345168590545654
[1, 5892] loss_train: 0.001813, loss_test: 0.005816
time: 0.2490544319152832
time: 2.2064943313598633
[1, 5893] loss_train: 0.005228, loss_test: 0.005829
time: 0.2490556240081787
time: 2.2375004291534424
[1, 5894] loss_train: 0.001846, loss_test: 0.005844
time: 0.24905157089233398
time: 2.2124948501586914
[1, 5895] loss_train: 0.014150, loss_test: 0.005822
time: 0.24405407905578613
time: 2.229527711868286
[1, 5896] loss_train: 0.009252, loss_test: 0.005787
time: 0.24605512619018555
time: 2.220017194747925
[1, 5897] loss_train: 0.000533, loss_test: 0.005763
time: 0.24405360221862793
time: 2.2154958248138428
[1, 5898] loss_train: 0.006004, loss_test: 0.005748
time: 0.24305319786071777
time: 2.2390060424804688
[1, 5899] loss_train: 0.002625, loss_test: 0.005743
time: 0.24405384063720703
time: 2.260507583618164
[1, 5900] loss_train: 0.006612, loss_test: 0.005742
time: 0.2560572624206543
time: 2.2545042037963867
[1, 5901] loss_train: 0.003681, loss_test: 0.005745
time: 0.24805498123168945
time: 2.2585067749023438
[1, 5902] loss_train: 0.007178, loss_test: 0.005751
time: 0.24405407905578613
time: 2.235499858856201
[1, 5903] loss_train: 0.014491, loss_test: 0.005758
time: 0.24605417251586914
time: 2.233499765396118
[1, 5904] loss_train: 0.004043, loss_test: 0.005761
time: 0.24305391311645508
time: 2.2385005950927734
[1, 5905] loss_train: 0.002825, loss_test: 0.005759
time: 0.2450544834136963
time: 2.207493782043457
[1, 5906] loss_train: 0.004082, loss_test: 0.005756
time: 0.2440786361694336
time: 2.245502471923828
[1, 5907] loss_train: 0.002181, loss_test: 0.005757
time: 0.24305367469787598
time: 2.214236259460449
[1, 5908] loss_train: 0.004628, loss_test: 0.005761
time: 0.24305438995361328
time: 2.2134950160980225
[1, 5909] loss_train: 0.005435, loss_test: 0.005767
time: 0.24405360221862793
time: 2.2045204639434814
[1, 5910] loss_train: 0.007731, loss_test: 0.005771
time: 0.2580583095550537
time: 2.2645151615142822
[1, 5911] loss_train: 0.013496, loss_test: 0.005764
time: 0.2470545768737793
time: 2.2124953269958496
[1, 5912] loss_train: 0.009210, loss_test: 0.005759
time: 0.2490546703338623
time: 2.219001531600952
[1, 5913] loss_train: 0.003925, loss_test: 0.005764
time: 0.24805474281311035
time: 2.2465028762817383
[1, 5914] loss_train: 0.005490, loss_test: 0.005774
time: 0.24405503273010254
time: 2.2034921646118164
[1, 5915] loss_train: 0.005107, loss_test: 0.005784
time: 0.24605464935302734
time: 2.246514320373535
[1, 5916] loss_train: 0.002699, loss_test: 0.005800
time: 0.24305415153503418
time: 2.2518973350524902
[1, 5917] loss_train: 0.004805, loss_test: 0.005813
time: 0.24805521965026855
time: 2.2014920711517334
[1, 5918] loss_train: 0.003094, loss_test: 0.005825
time: 0.24405336380004883
time: 2.2084944248199463
[1, 5919] loss_train: 0.012757, loss_test: 0.005825
time: 0.24405479431152344
time: 2.209007740020752
[1, 5920] loss_train: 0.001666, loss_test: 0.005822
time: 0.2600574493408203
time: 2.2515034675598145
[1, 5921] loss_train: 0.004985, loss_test: 0.005811
time: 0.2450544834136963
time: 2.220496654510498
[1, 5922] loss_train: 0.006307, loss_test: 0.005799
time: 0.24405360221862793
time: 2.2124953269958496
[1, 5923] loss_train: 0.010508, loss_test: 0.005791
time: 0.24505376815795898
time: 2.239501476287842
[1, 5924] loss_train: 0.011154, loss_test: 0.005782
time: 0.24405431747436523
time: 2.210496425628662
[1, 5925] loss_train: 0.008073, loss_test: 0.005773
time: 0.24406814575195312
time: 2.22149658203125
[1, 5926] loss_train: 0.007125, loss_test: 0.005770
time: 0.24405431747436523
time: 2.219496011734009
[1, 5927] loss_train: 0.001664, loss_test: 0.005766
time: 0.24605488777160645
time: 2.2174956798553467
[1, 5928] loss_train: 0.009958, loss_test: 0.005763
time: 0.24605321884155273
time: 2.1890201568603516
[1, 5929] loss_train: 0.009878, loss_test: 0.005763
time: 0.244065523147583
time: 2.2370245456695557
[1, 5930] loss_train: 0.007626, loss_test: 0.005762
time: 0.261059045791626
time: 2.267505407333374
[1, 5931] loss_train: 0.010459, loss_test: 0.005762
time: 0.24506807327270508
time: 2.2134947776794434
[1, 5932] loss_train: 0.001382, loss_test: 0.005761
time: 0.2470550537109375
time: 2.24200701713562
[1, 5933] loss_train: 0.005710, loss_test: 0.005761
time: 0.24405336380004883
time: 2.205496072769165
[1, 5934] loss_train: 0.004646, loss_test: 0.005765
time: 0.24305367469787598
time: 2.248873233795166
[1, 5935] loss_train: 0.007759, loss_test: 0.005771
time: 0.24405360221862793
time: 2.253504514694214
[1, 5936] loss_train: 0.013514, loss_test: 0.005771
time: 0.24405384063720703
time: 2.230499505996704
[1, 5937] loss_train: 0.016268, loss_test: 0.005768
time: 0.24305415153503418
time: 2.203490734100342
[1, 5938] loss_train: 0.008146, loss_test: 0.005765
time: 0.24305415153503418
time: 2.252504348754883
[1, 5939] loss_train: 0.004349, loss_test: 0.005762
time: 0.24305367469787598
time: 2.2395131587982178
[1, 5940] loss_train: 0.000607, loss_test: 0.005760
time: 0.2580842971801758
time: 2.261505603790283
[1, 5941] loss_train: 0.004871, loss_test: 0.005756
time: 0.24406647682189941
time: 2.2565038204193115
[1, 5942] loss_train: 0.003260, loss_test: 0.005752
time: 0.24405360221862793
time: 2.231499195098877
[1, 5943] loss_train: 0.005563, loss_test: 0.005750
time: 0.2450544834136963
time: 2.2024922370910645
[1, 5944] loss_train: 0.009275, loss_test: 0.005749
time: 0.24306702613830566
time: 2.229505777359009
[1, 5945] loss_train: 0.003841, loss_test: 0.005748
time: 0.24405431747436523
time: 2.2004923820495605
[1, 5946] loss_train: 0.005001, loss_test: 0.005749
time: 0.24305391311645508
time: 2.191523313522339
[1, 5947] loss_train: 0.006533, loss_test: 0.005749
time: 0.24405431747436523
time: 2.220496654510498
[1, 5948] loss_train: 0.003789, loss_test: 0.005750
time: 0.2450544834136963
time: 2.2215070724487305
[1, 5949] loss_train: 0.005021, loss_test: 0.005751
time: 0.24805474281311035
time: 2.2295150756835938
[1, 5950] loss_train: 0.005353, loss_test: 0.005753
time: 0.26105785369873047
time: 2.2585055828094482
[1, 5951] loss_train: 0.008287, loss_test: 0.005752
time: 0.25005578994750977
time: 2.246502161026001
[1, 5952] loss_train: 0.009149, loss_test: 0.005750
time: 0.24405479431152344
time: 2.2505030632019043
[1, 5953] loss_train: 0.001885, loss_test: 0.005749
time: 0.2510561943054199
time: 2.2254977226257324
[1, 5954] loss_train: 0.007818, loss_test: 0.005748
time: 0.24405455589294434
time: 2.215503454208374
[1, 5955] loss_train: 0.001956, loss_test: 0.005750
time: 0.24605393409729004
time: 2.20149302482605
[1, 5956] loss_train: 0.005842, loss_test: 0.005752
time: 0.24505400657653809
time: 2.2400505542755127
[1, 5957] loss_train: 0.003064, loss_test: 0.005756
time: 0.24605417251586914
time: 2.208493947982788
[1, 5958] loss_train: 0.002572, loss_test: 0.005761
time: 0.24405384063720703
time: 2.200511932373047
[1, 5959] loss_train: 0.011207, loss_test: 0.005767
time: 0.24405407905578613
time: 2.2204971313476562
[1, 5960] loss_train: 0.001850, loss_test: 0.005778
time: 0.25905704498291016
time: 2.2745609283447266
[1, 5961] loss_train: 0.002970, loss_test: 0.005791
time: 0.2450542449951172
time: 2.246501922607422
[1, 5962] loss_train: 0.005931, loss_test: 0.005802
time: 0.24305438995361328
time: 2.2295007705688477
[1, 5963] loss_train: 0.000634, loss_test: 0.005815
time: 0.24805569648742676
time: 2.222499370574951
[1, 5964] loss_train: 0.014189, loss_test: 0.005808
time: 0.24405431747436523
time: 2.205493450164795
[1, 5965] loss_train: 0.003289, loss_test: 0.005801
time: 0.24205398559570312
time: 2.2144949436187744
[1, 5966] loss_train: 0.005940, loss_test: 0.005793
time: 0.24205398559570312
time: 2.2375504970550537
[1, 5967] loss_train: 0.009708, loss_test: 0.005781
time: 0.2450547218322754
time: 2.2094948291778564
[1, 5968] loss_train: 0.005706, loss_test: 0.005774
time: 0.24406766891479492
time: 2.2322049140930176
[1, 5969] loss_train: 0.008438, loss_test: 0.005772
time: 0.2450542449951172
time: 2.2224974632263184
[1, 5970] loss_train: 0.010586, loss_test: 0.005772
time: 0.2620575428009033
time: 2.2495033740997314
[1, 5971] loss_train: 0.006777, loss_test: 0.005775
time: 0.24505400657653809
time: 2.2004950046539307
[1, 5972] loss_train: 0.003545, loss_test: 0.005775
time: 0.2490556240081787
time: 2.2284979820251465
[1, 5973] loss_train: 0.008040, loss_test: 0.005775
time: 0.24405407905578613
time: 2.2114951610565186
[1, 5974] loss_train: 0.005841, loss_test: 0.005772
time: 0.24405360221862793
time: 2.217317819595337
[1, 5975] loss_train: 0.007602, loss_test: 0.005766
time: 0.24405407905578613
time: 2.23449969291687
[1, 5976] loss_train: 0.009021, loss_test: 0.005759
time: 0.24405384063720703
time: 2.2114977836608887
[1, 5977] loss_train: 0.009626, loss_test: 0.005756
time: 0.24505615234375
time: 2.217496395111084
[1, 5978] loss_train: 0.013605, loss_test: 0.005761
time: 0.24305462837219238
time: 2.2092323303222656
[1, 5979] loss_train: 0.008005, loss_test: 0.005775
time: 0.24405431747436523
time: 2.1984915733337402
[1, 5980] loss_train: 0.005291, loss_test: 0.005798
time: 0.25705695152282715
time: 2.266507387161255
[1, 5981] loss_train: 0.007710, loss_test: 0.005821
time: 0.24405407905578613
time: 2.206494092941284
[1, 5982] loss_train: 0.009159, loss_test: 0.005837
time: 0.24205470085144043
time: 2.2174956798553467
[1, 5983] loss_train: 0.001004, loss_test: 0.005858
time: 0.24605345726013184
time: 2.2405014038085938
[1, 5984] loss_train: 0.013168, loss_test: 0.005878
time: 0.2470545768737793
time: 2.2375004291534424
[1, 5985] loss_train: 0.006426, loss_test: 0.005878
time: 0.2450544834136963
time: 2.2455015182495117
[1, 5986] loss_train: 0.001785, loss_test: 0.005874
time: 0.24406743049621582
time: 2.221510410308838
[1, 5987] loss_train: 0.006273, loss_test: 0.005876
time: 0.25005602836608887
time: 2.223496913909912
[1, 5988] loss_train: 0.007524, loss_test: 0.005878
time: 0.24405384063720703
time: 2.2294983863830566
[1, 5989] loss_train: 0.012868, loss_test: 0.005865
time: 0.2490544319152832
time: 2.2255859375
[1, 5990] loss_train: 0.006906, loss_test: 0.005838
time: 0.2550694942474365
time: 2.2985146045684814
[1, 5991] loss_train: 0.005544, loss_test: 0.005817
time: 0.2630593776702881
time: 2.2200241088867188
[1, 5992] loss_train: 0.005367, loss_test: 0.005795
time: 0.24405384063720703
time: 2.2099995613098145
[1, 5993] loss_train: 0.007264, loss_test: 0.005782
time: 0.2470545768737793
time: 2.2254977226257324
[1, 5994] loss_train: 0.005313, loss_test: 0.005777
time: 0.2450542449951172
time: 2.191490650177002
[1, 5995] loss_train: 0.005876, loss_test: 0.005776
time: 0.2450547218322754
time: 2.192490339279175
[1, 5996] loss_train: 0.009057, loss_test: 0.005774
time: 0.24305367469787598
time: 2.242119312286377
[1, 5997] loss_train: 0.012807, loss_test: 0.005771
time: 0.24307799339294434
time: 2.228498697280884
[1, 5998] loss_train: 0.001713, loss_test: 0.005775
time: 0.2450549602508545
time: 2.2549149990081787
[1, 5999] loss_train: 0.004630, loss_test: 0.005782
time: 0.24305367469787598
time: 2.267507553100586
[1, 6000] loss_train: 0.006356, loss_test: 0.005784
time: 0.2550685405731201
time: 2.240504026412964
[1, 6001] loss_train: 0.003466, loss_test: 0.005783
time: 0.24605369567871094
time: 2.261505365371704
[1, 6002] loss_train: 0.006379, loss_test: 0.005784
time: 0.24305438995361328
time: 2.2405025959014893
[1, 6003] loss_train: 0.007901, loss_test: 0.005781
time: 0.24405455589294434
time: 2.206495761871338
[1, 6004] loss_train: 0.005683, loss_test: 0.005775
time: 0.2450547218322754
time: 2.2244973182678223
[1, 6005] loss_train: 0.006812, loss_test: 0.005767
time: 0.24405431747436523
time: 2.2154958248138428
[1, 6006] loss_train: 0.006460, loss_test: 0.005760
time: 0.24405312538146973
time: 2.218496322631836
[1, 6007] loss_train: 0.004399, loss_test: 0.005760
time: 0.2450551986694336
time: 2.2318551540374756
[1, 6008] loss_train: 0.006223, loss_test: 0.005766
time: 0.2490549087524414
time: 2.2515156269073486
[1, 6009] loss_train: 0.005590, loss_test: 0.005772
time: 0.2450547218322754
time: 2.2284984588623047
[1, 6010] loss_train: 0.010046, loss_test: 0.005779
time: 0.25905823707580566
time: 2.2645058631896973
[1, 6011] loss_train: 0.004020, loss_test: 0.005792
time: 0.2490673065185547
time: 2.2535042762756348
[1, 6012] loss_train: 0.005032, loss_test: 0.005809
time: 0.25005507469177246
time: 2.229004144668579
[1, 6013] loss_train: 0.009905, loss_test: 0.005809
time: 0.24405384063720703
time: 2.2385010719299316
[1, 6014] loss_train: 0.005023, loss_test: 0.005808
time: 0.2490677833557129
time: 2.209493637084961
[1, 6015] loss_train: 0.011866, loss_test: 0.005809
time: 0.24405455589294434
time: 2.225499153137207
[1, 6016] loss_train: 0.007810, loss_test: 0.005808
time: 0.2490546703338623
time: 2.229499101638794
[1, 6017] loss_train: 0.006774, loss_test: 0.005809
time: 0.24405574798583984
time: 2.221010684967041
[1, 6018] loss_train: 0.007355, loss_test: 0.005799
time: 0.2490556240081787
time: 2.2244999408721924
[1, 6019] loss_train: 0.001832, loss_test: 0.005790
time: 0.24305343627929688
time: 2.214517593383789
[1, 6020] loss_train: 0.001469, loss_test: 0.005790
time: 0.25505638122558594
time: 2.2385010719299316
[1, 6021] loss_train: 0.004719, loss_test: 0.005792
time: 0.24405384063720703
time: 2.2457828521728516
[1, 6022] loss_train: 0.003167, loss_test: 0.005799
time: 0.24405407905578613
time: 2.2385096549987793
[1, 6023] loss_train: 0.004215, loss_test: 0.005807
time: 0.24305343627929688
time: 2.244504928588867
[1, 6024] loss_train: 0.008091, loss_test: 0.005808
time: 0.2450542449951172
time: 2.2515034675598145
[1, 6025] loss_train: 0.007454, loss_test: 0.005798
time: 0.24305438995361328
time: 2.2244973182678223
[1, 6026] loss_train: 0.010753, loss_test: 0.005787
time: 0.24505400657653809
time: 2.205493688583374
[1, 6027] loss_train: 0.007865, loss_test: 0.005771
time: 0.24305367469787598
time: 2.2105071544647217
[1, 6028] loss_train: 0.007885, loss_test: 0.005765
time: 0.24505329132080078
time: 2.21049427986145
[1, 6029] loss_train: 0.007973, loss_test: 0.005768
time: 0.24305462837219238
time: 2.192016363143921
[1, 6030] loss_train: 0.010115, loss_test: 0.005775
time: 0.25505590438842773
time: 2.217496633529663
[1, 6031] loss_train: 0.010731, loss_test: 0.005782
time: 0.2530553340911865
time: 2.241501808166504
[1, 6032] loss_train: 0.002982, loss_test: 0.005781
time: 0.2450544834136963
time: 2.2184972763061523
[1, 6033] loss_train: 0.007252, loss_test: 0.005777
time: 0.2490556240081787
time: 2.234499216079712
[1, 6034] loss_train: 0.006046, loss_test: 0.005769
time: 0.24405479431152344
time: 2.248502492904663
[1, 6035] loss_train: 0.005883, loss_test: 0.005758
time: 0.25005578994750977
time: 2.2435014247894287
[1, 6036] loss_train: 0.000714, loss_test: 0.005750
time: 0.2450551986694336
time: 2.2304985523223877
[1, 6037] loss_train: 0.001653, loss_test: 0.005745
time: 0.2470545768737793
time: 2.2335314750671387
[1, 6038] loss_train: 0.004535, loss_test: 0.005745
time: 0.24405360221862793
time: 2.2134971618652344
[1, 6039] loss_train: 0.007346, loss_test: 0.005749
time: 0.24456429481506348
time: 2.2615063190460205
[1, 6040] loss_train: 0.007414, loss_test: 0.005752
time: 0.25705718994140625
time: 2.270517587661743
[1, 6041] loss_train: 0.005830, loss_test: 0.005754
time: 0.24605488777160645
time: 2.2375004291534424
[1, 6042] loss_train: 0.006404, loss_test: 0.005753
time: 0.24405360221862793
time: 2.243501901626587
[1, 6043] loss_train: 0.012126, loss_test: 0.005747
time: 0.24305438995361328
time: 2.2124946117401123
[1, 6044] loss_train: 0.013249, loss_test: 0.005738
time: 0.24305343627929688
time: 2.241502046585083
[1, 6045] loss_train: 0.006502, loss_test: 0.005734
time: 0.24605512619018555
time: 2.22249698638916
[1, 6046] loss_train: 0.010678, loss_test: 0.005740
time: 0.24355840682983398
time: 2.2264983654022217
[1, 6047] loss_train: 0.014372, loss_test: 0.005756
time: 0.24305319786071777
time: 2.232516288757324
[1, 6048] loss_train: 0.005006, loss_test: 0.005773
time: 0.24505376815795898
time: 2.2244980335235596
[1, 6049] loss_train: 0.005812, loss_test: 0.005784
time: 0.24205327033996582
time: 2.2455132007598877
[1, 6050] loss_train: 0.015847, loss_test: 0.005801
time: 0.2560575008392334
time: 2.231498956680298
[1, 6051] loss_train: 0.008838, loss_test: 0.005797
time: 0.24606585502624512
time: 2.214495897293091
[1, 6052] loss_train: 0.003973, loss_test: 0.005785
time: 0.24405360221862793
time: 2.219496726989746
[1, 6053] loss_train: 0.005834, loss_test: 0.005772
time: 0.24405336380004883
time: 2.2325003147125244
[1, 6054] loss_train: 0.003332, loss_test: 0.005768
time: 0.24405407905578613
time: 2.2275266647338867
[1, 6055] loss_train: 0.007103, loss_test: 0.005768
time: 0.2450542449951172
time: 2.211515188217163
[1, 6056] loss_train: 0.001667, loss_test: 0.005769
time: 0.2520558834075928
time: 2.2144949436187744
[1, 6057] loss_train: 0.006834, loss_test: 0.005769
time: 0.2470550537109375
time: 2.2330121994018555
[1, 6058] loss_train: 0.011725, loss_test: 0.005768
time: 0.25005507469177246
time: 2.2370052337646484
[1, 6059] loss_train: 0.005856, loss_test: 0.005765
time: 0.24505376815795898
time: 2.250521183013916
[1, 6060] loss_train: 0.008092, loss_test: 0.005765
time: 0.26206135749816895
time: 2.2545042037963867
[1, 6061] loss_train: 0.002288, loss_test: 0.005768
time: 0.24405455589294434
time: 2.2365009784698486
[1, 6062] loss_train: 0.007827, loss_test: 0.005770
time: 0.2470545768737793
time: 2.2264983654022217
[1, 6063] loss_train: 0.008685, loss_test: 0.005769
time: 0.243056058883667
time: 2.2024927139282227
[1, 6064] loss_train: 0.006510, loss_test: 0.005765
time: 0.24605393409729004
time: 2.231501579284668
[1, 6065] loss_train: 0.006592, loss_test: 0.005763
time: 0.24505352973937988
time: 2.228498935699463
[1, 6066] loss_train: 0.004415, loss_test: 0.005761
time: 0.24305343627929688
time: 2.1985015869140625
[1, 6067] loss_train: 0.006489, loss_test: 0.005761
time: 0.24305367469787598
time: 2.1925885677337646
[1, 6068] loss_train: 0.006234, loss_test: 0.005762
time: 0.24805450439453125
time: 2.231499433517456
[1, 6069] loss_train: 0.006903, loss_test: 0.005766
time: 0.24305415153503418
time: 2.243025541305542
[1, 6070] loss_train: 0.000840, loss_test: 0.005769
time: 0.25505709648132324
time: 2.2795095443725586
[1, 6071] loss_train: 0.004559, loss_test: 0.005770
time: 0.25005483627319336
time: 2.203493356704712
[1, 6072] loss_train: 0.008232, loss_test: 0.005769
time: 0.24605464935302734
time: 2.2244975566864014
[1, 6073] loss_train: 0.009296, loss_test: 0.005770
time: 0.24405455589294434
time: 2.258505344390869
[1, 6074] loss_train: 0.010461, loss_test: 0.005771
time: 0.24505376815795898
time: 2.210502862930298
[1, 6075] loss_train: 0.000642, loss_test: 0.005773
time: 0.24305438995361328
time: 2.223497152328491
[1, 6076] loss_train: 0.008898, loss_test: 0.005777
time: 0.24505376815795898
time: 2.232945203781128
[1, 6077] loss_train: 0.003800, loss_test: 0.005783
time: 0.24805498123168945
time: 2.232743263244629
[1, 6078] loss_train: 0.002975, loss_test: 0.005793
time: 0.24405407905578613
time: 2.2235066890716553
[1, 6079] loss_train: 0.012568, loss_test: 0.005796
time: 0.2490546703338623
time: 2.2094945907592773
[1, 6080] loss_train: 0.010287, loss_test: 0.005805
time: 0.255617618560791
time: 2.2555041313171387
[1, 6081] loss_train: 0.002664, loss_test: 0.005820
time: 0.2510554790496826
time: 2.1974923610687256
[1, 6082] loss_train: 0.007843, loss_test: 0.005817
time: 0.2470541000366211
time: 2.246208906173706
[1, 6083] loss_train: 0.007993, loss_test: 0.005810
time: 0.24405431747436523
time: 2.2284998893737793
[1, 6084] loss_train: 0.007749, loss_test: 0.005794
time: 0.24405407905578613
time: 2.246380090713501
[1, 6085] loss_train: 0.007451, loss_test: 0.005775
time: 0.24405384063720703
time: 2.2535042762756348
[1, 6086] loss_train: 0.003576, loss_test: 0.005759
time: 0.24305415153503418
time: 2.2304348945617676
[1, 6087] loss_train: 0.005827, loss_test: 0.005749
time: 0.24405455589294434
time: 2.2102935314178467
[1, 6088] loss_train: 0.002143, loss_test: 0.005743
time: 0.2450549602508545
time: 2.233785629272461
[1, 6089] loss_train: 0.003844, loss_test: 0.005740
time: 0.24508023262023926
time: 2.204493999481201
[1, 6090] loss_train: 0.003767, loss_test: 0.005741
time: 0.2530689239501953
time: 2.232018232345581
[1, 6091] loss_train: 0.002844, loss_test: 0.005747
time: 0.24677014350891113
time: 2.1874899864196777
[1, 6092] loss_train: 0.006341, loss_test: 0.005751
time: 0.24905610084533691
time: 2.247502088546753
[1, 6093] loss_train: 0.002735, loss_test: 0.005757
time: 0.24305462837219238
time: 2.2294983863830566
[1, 6094] loss_train: 0.003893, loss_test: 0.005764
time: 0.2450544834136963
time: 2.221496343612671
[1, 6095] loss_train: 0.005473, loss_test: 0.005770
time: 0.2450697422027588
time: 2.2134954929351807
[1, 6096] loss_train: 0.008322, loss_test: 0.005775
time: 0.2511579990386963
time: 2.2355003356933594
[1, 6097] loss_train: 0.013373, loss_test: 0.005764
time: 0.24605464935302734
time: 2.2385005950927734
[1, 6098] loss_train: 0.002827, loss_test: 0.005760
time: 0.2510554790496826
time: 2.2355000972747803
[1, 6099] loss_train: 0.007291, loss_test: 0.005754
time: 0.2450547218322754
time: 2.22049617767334
[1, 6100] loss_train: 0.018094, loss_test: 0.005759
time: 0.25905680656433105
time: 2.2284984588623047
[1, 6101] loss_train: 0.006152, loss_test: 0.005784
time: 0.2450547218322754
time: 2.249504804611206
[1, 6102] loss_train: 0.005334, loss_test: 0.005807
time: 0.2470548152923584
time: 2.204014778137207
[1, 6103] loss_train: 0.004595, loss_test: 0.005809
time: 0.24405431747436523
time: 2.227001428604126
[1, 6104] loss_train: 0.001526, loss_test: 0.005797
time: 0.24205350875854492
time: 2.2163007259368896
[1, 6105] loss_train: 0.004838, loss_test: 0.005784
time: 0.24405384063720703
time: 2.235508441925049
[1, 6106] loss_train: 0.010214, loss_test: 0.005769
time: 0.2450544834136963
time: 2.232499837875366
[1, 6107] loss_train: 0.009612, loss_test: 0.005751
time: 0.24506855010986328
time: 2.238020658493042
[1, 6108] loss_train: 0.009849, loss_test: 0.005744
time: 0.24305367469787598
time: 2.261519193649292
[1, 6109] loss_train: 0.010416, loss_test: 0.005754
time: 0.24805450439453125
time: 2.242006540298462
[1, 6110] loss_train: 0.012731, loss_test: 0.005765
time: 0.2530956268310547
time: 2.3045153617858887
[1, 6111] loss_train: 0.006428, loss_test: 0.005775
time: 0.24605321884155273
time: 2.2264997959136963
[1, 6112] loss_train: 0.001254, loss_test: 0.005788
time: 0.2450542449951172
time: 2.2365005016326904
[1, 6113] loss_train: 0.006350, loss_test: 0.005798
time: 0.2450542449951172
time: 2.2274985313415527
[1, 6114] loss_train: 0.011728, loss_test: 0.005791
time: 0.24305391311645508
time: 2.2264978885650635
[1, 6115] loss_train: 0.006499, loss_test: 0.005782
time: 0.24305343627929688
time: 2.2385191917419434
[1, 6116] loss_train: 0.013929, loss_test: 0.005765
time: 0.24605441093444824
time: 2.2355144023895264
[1, 6117] loss_train: 0.007114, loss_test: 0.005755
time: 0.24405455589294434
time: 2.2095155715942383
[1, 6118] loss_train: 0.006628, loss_test: 0.005752
time: 0.24305343627929688
time: 2.2395009994506836
[1, 6119] loss_train: 0.005951, loss_test: 0.005755
time: 0.24605536460876465
time: 2.182514190673828
[1, 6120] loss_train: 0.004833, loss_test: 0.005760
time: 0.2540559768676758
time: 2.2785873413085938
[1, 6121] loss_train: 0.007771, loss_test: 0.005769
time: 0.25006771087646484
time: 2.244502067565918
[1, 6122] loss_train: 0.006350, loss_test: 0.005773
time: 0.2510561943054199
time: 2.2204957008361816
[1, 6123] loss_train: 0.010455, loss_test: 0.005778
time: 0.2450547218322754
time: 2.2104945182800293
[1, 6124] loss_train: 0.005944, loss_test: 0.005774
time: 0.24405455589294434
time: 2.2185075283050537
[1, 6125] loss_train: 0.005738, loss_test: 0.005768
time: 0.2470545768737793
time: 2.202486515045166
[1, 6126] loss_train: 0.003709, loss_test: 0.005763
time: 0.24505400657653809
time: 2.218496799468994
[1, 6127] loss_train: 0.007621, loss_test: 0.005760
time: 0.24305367469787598
time: 2.207505226135254
[1, 6128] loss_train: 0.005929, loss_test: 0.005759
time: 0.24405431747436523
time: 2.218510627746582
[1, 6129] loss_train: 0.004088, loss_test: 0.005764
time: 0.25005650520324707
time: 2.1985273361206055
[1, 6130] loss_train: 0.005697, loss_test: 0.005764
time: 0.2540557384490967
time: 2.255505084991455
[1, 6131] loss_train: 0.001115, loss_test: 0.005774
time: 0.24305319786071777
time: 2.217496633529663
[1, 6132] loss_train: 0.012854, loss_test: 0.005774
time: 0.24405431747436523
time: 2.223497152328491
[1, 6133] loss_train: 0.009218, loss_test: 0.005774
time: 0.24605464935302734
time: 2.2154953479766846
[1, 6134] loss_train: 0.011830, loss_test: 0.005771
time: 0.24405479431152344
time: 2.2174956798553467
[1, 6135] loss_train: 0.005044, loss_test: 0.005768
time: 0.24405431747436523
time: 2.1944899559020996
[1, 6136] loss_train: 0.010793, loss_test: 0.005757
time: 0.24505376815795898
time: 2.2214972972869873
[1, 6137] loss_train: 0.000914, loss_test: 0.005753
time: 0.24505400657653809
time: 2.2174980640411377
[1, 6138] loss_train: 0.002056, loss_test: 0.005754
time: 0.24805474281311035
time: 2.2365007400512695
[1, 6139] loss_train: 0.005366, loss_test: 0.005757
time: 0.24556779861450195
time: 2.225497245788574
[1, 6140] loss_train: 0.006973, loss_test: 0.005762
time: 0.2620584964752197
time: 2.2435150146484375
[1, 6141] loss_train: 0.013335, loss_test: 0.005766
time: 0.24205422401428223
time: 2.22149658203125
[1, 6142] loss_train: 0.000661, loss_test: 0.005767
time: 0.24606657028198242
time: 2.230499029159546
[1, 6143] loss_train: 0.006130, loss_test: 0.005770
time: 0.24405407905578613
time: 2.2385013103485107
[1, 6144] loss_train: 0.012776, loss_test: 0.005767
time: 0.24305415153503418
time: 2.2384519577026367
[1, 6145] loss_train: 0.003409, loss_test: 0.005766
time: 0.24605512619018555
time: 2.2305006980895996
[1, 6146] loss_train: 0.002633, loss_test: 0.005765
time: 0.24405360221862793
time: 2.212495803833008
[1, 6147] loss_train: 0.004346, loss_test: 0.005765
time: 0.24405384063720703
time: 2.224353075027466
[1, 6148] loss_train: 0.000635, loss_test: 0.005766
time: 0.24405407905578613
time: 2.219496726989746
[1, 6149] loss_train: 0.005917, loss_test: 0.005767
time: 0.24405384063720703
time: 2.2075042724609375
[1, 6150] loss_train: 0.005778, loss_test: 0.005768
time: 0.25705671310424805
time: 2.2825112342834473
[1, 6151] loss_train: 0.006653, loss_test: 0.005768
time: 0.24205374717712402
time: 2.246502161026001
[1, 6152] loss_train: 0.003140, loss_test: 0.005770
time: 0.2450547218322754
time: 2.21049427986145
[1, 6153] loss_train: 0.003552, loss_test: 0.005769
time: 0.24305415153503418
time: 2.230498790740967
[1, 6154] loss_train: 0.005712, loss_test: 0.005766
time: 0.24405360221862793
time: 2.245515823364258
[1, 6155] loss_train: 0.006238, loss_test: 0.005763
time: 0.24405384063720703
time: 2.1974921226501465
[1, 6156] loss_train: 0.005690, loss_test: 0.005758
time: 0.24505352973937988
time: 2.243501663208008
[1, 6157] loss_train: 0.014493, loss_test: 0.005763
time: 0.2450544834136963
time: 2.2085065841674805
[1, 6158] loss_train: 0.001961, loss_test: 0.005771
time: 0.24508047103881836
time: 2.2264974117279053
[1, 6159] loss_train: 0.006921, loss_test: 0.005775
time: 0.24805521965026855
time: 2.2195136547088623
[1, 6160] loss_train: 0.013416, loss_test: 0.005760
time: 0.25505590438842773
time: 2.2335116863250732
[1, 6161] loss_train: 0.009382, loss_test: 0.005746
time: 0.24805521965026855
time: 2.232499122619629
[1, 6162] loss_train: 0.006404, loss_test: 0.005747
time: 0.24305438995361328
time: 2.194490671157837
[1, 6163] loss_train: 0.001671, loss_test: 0.005763
time: 0.2450542449951172
time: 2.2355003356933594
[1, 6164] loss_train: 0.000997, loss_test: 0.005769
time: 0.24405384063720703
time: 2.1894900798797607
[1, 6165] loss_train: 0.007463, loss_test: 0.005773
time: 0.24205398559570312
time: 2.2615058422088623
[1, 6166] loss_train: 0.007848, loss_test: 0.005769
time: 0.24405407905578613
time: 2.2305002212524414
[1, 6167] loss_train: 0.007638, loss_test: 0.005762
time: 0.24495840072631836
time: 2.2435033321380615
[1, 6168] loss_train: 0.003789, loss_test: 0.005755
time: 0.24205350875854492
time: 2.241501569747925
[1, 6169] loss_train: 0.001165, loss_test: 0.005745
time: 0.24405455589294434
time: 2.2134947776794434
[1, 6170] loss_train: 0.006218, loss_test: 0.005738
time: 0.2560567855834961
time: 2.2635068893432617
[1, 6171] loss_train: 0.002691, loss_test: 0.005738
time: 0.2430562973022461
time: 2.2134947776794434
[1, 6172] loss_train: 0.008172, loss_test: 0.005741
time: 0.24305367469787598
time: 2.204493284225464
[1, 6173] loss_train: 0.015145, loss_test: 0.005741
time: 0.24405407905578613
time: 2.202493667602539
[1, 6174] loss_train: 0.007111, loss_test: 0.005742
time: 0.24406671524047852
time: 2.229501247406006
[1, 6175] loss_train: 0.007269, loss_test: 0.005741
time: 0.24405407905578613
time: 2.2254979610443115
[1, 6176] loss_train: 0.004463, loss_test: 0.005743
time: 0.24805545806884766
time: 2.2149276733398438
[1, 6177] loss_train: 0.002984, loss_test: 0.005747
time: 0.24605417251586914
time: 2.2244980335235596
[1, 6178] loss_train: 0.007872, loss_test: 0.005747
time: 0.24605417251586914
time: 2.2395012378692627
[1, 6179] loss_train: 0.002672, loss_test: 0.005747
time: 0.24305438995361328
time: 2.2274978160858154
[1, 6180] loss_train: 0.005797, loss_test: 0.005749
time: 0.25505685806274414
time: 2.2510571479797363
[1, 6181] loss_train: 0.001522, loss_test: 0.005755
time: 0.24507856369018555
time: 2.2184972763061523
[1, 6182] loss_train: 0.010797, loss_test: 0.005757
time: 0.24305367469787598
time: 2.196491241455078
[1, 6183] loss_train: 0.008185, loss_test: 0.005757
time: 0.24505400657653809
time: 2.21549654006958
[1, 6184] loss_train: 0.006286, loss_test: 0.005754
time: 0.24605441093444824
time: 2.1985223293304443
[1, 6185] loss_train: 0.015928, loss_test: 0.005747
time: 0.24605488777160645
time: 2.2144951820373535
[1, 6186] loss_train: 0.005785, loss_test: 0.005744
time: 0.24405384063720703
time: 2.243511915206909
[1, 6187] loss_train: 0.008135, loss_test: 0.005739
time: 0.2470569610595703
time: 2.204493522644043
[1, 6188] loss_train: 0.005611, loss_test: 0.005739
time: 0.24505400657653809
time: 2.1994924545288086
[1, 6189] loss_train: 0.001822, loss_test: 0.005739
time: 0.2450549602508545
time: 2.211493730545044
[1, 6190] loss_train: 0.008158, loss_test: 0.005738
time: 0.2560567855834961
time: 2.2345001697540283
[1, 6191] loss_train: 0.008804, loss_test: 0.005737
time: 0.2510554790496826
time: 2.2274985313415527
[1, 6192] loss_train: 0.008845, loss_test: 0.005735
time: 0.2520575523376465
time: 2.2254981994628906
[1, 6193] loss_train: 0.006262, loss_test: 0.005733
time: 0.24706602096557617
time: 2.2235007286071777
[1, 6194] loss_train: 0.002963, loss_test: 0.005731
time: 0.24805521965026855
time: 2.216495990753174
[1, 6195] loss_train: 0.004483, loss_test: 0.005729
time: 0.24506831169128418
time: 2.2415010929107666
[1, 6196] loss_train: 0.004732, loss_test: 0.005730
time: 0.24405455589294434
time: 2.2030816078186035
[1, 6197] loss_train: 0.014617, loss_test: 0.005730
time: 0.24405407905578613
time: 2.208493947982788
[1, 6198] loss_train: 0.003739, loss_test: 0.005733
time: 0.24405431747436523
time: 2.229511022567749
[1, 6199] loss_train: 0.003470, loss_test: 0.005740
time: 0.24305438995361328
time: 2.2254974842071533
[1, 6200] loss_train: 0.007814, loss_test: 0.005744
time: 0.2540557384490967
time: 2.2375142574310303
[1, 6201] loss_train: 0.005828, loss_test: 0.005749
time: 0.24802303314208984
time: 2.217496156692505
[1, 6202] loss_train: 0.005002, loss_test: 0.005743
time: 0.24305391311645508
time: 2.22249698638916
[1, 6203] loss_train: 0.003148, loss_test: 0.005739
time: 0.24305391311645508
time: 2.2114951610565186
[1, 6204] loss_train: 0.002780, loss_test: 0.005740
time: 0.2440662384033203
time: 2.2415013313293457
[1, 6205] loss_train: 0.004086, loss_test: 0.005743
time: 0.24405384063720703
time: 2.2264981269836426
[1, 6206] loss_train: 0.010175, loss_test: 0.005740
time: 0.24306726455688477
time: 2.226287364959717
[1, 6207] loss_train: 0.007699, loss_test: 0.005738
time: 0.24405360221862793
time: 2.2244980335235596
[1, 6208] loss_train: 0.009572, loss_test: 0.005735
time: 0.25305652618408203
time: 2.2330288887023926
[1, 6209] loss_train: 0.012918, loss_test: 0.005735
time: 0.2470545768737793
time: 2.2535033226013184
[1, 6210] loss_train: 0.013688, loss_test: 0.005737
time: 0.26105833053588867
time: 2.2755253314971924
[1, 6211] loss_train: 0.011968, loss_test: 0.005743
time: 0.2510695457458496
time: 2.2069995403289795
[1, 6212] loss_train: 0.004115, loss_test: 0.005750
time: 0.2490556240081787
time: 2.2034926414489746
[1, 6213] loss_train: 0.003830, loss_test: 0.005758
time: 0.24305438995361328
time: 2.2405011653900146
[1, 6214] loss_train: 0.001194, loss_test: 0.005768
time: 0.2470569610595703
time: 2.245504856109619
[1, 6215] loss_train: 0.011290, loss_test: 0.005778
time: 0.24405360221862793
time: 2.2204976081848145
[1, 6216] loss_train: 0.004037, loss_test: 0.005779
time: 0.24505352973937988
time: 2.2305188179016113
[1, 6217] loss_train: 0.005444, loss_test: 0.005782
time: 0.2450542449951172
time: 2.205493688583374
[1, 6218] loss_train: 0.007024, loss_test: 0.005776
time: 0.2450547218322754
time: 2.2234973907470703
[1, 6219] loss_train: 0.012181, loss_test: 0.005764
time: 0.24407219886779785
time: 2.267608642578125
[1, 6220] loss_train: 0.006735, loss_test: 0.005747
time: 0.25705766677856445
time: 2.244501829147339
[1, 6221] loss_train: 0.008129, loss_test: 0.005739
time: 0.24505400657653809
time: 2.2505037784576416
[1, 6222] loss_train: 0.004384, loss_test: 0.005740
time: 0.24405479431152344
time: 2.2154948711395264
[1, 6223] loss_train: 0.006160, loss_test: 0.005747
time: 0.24305343627929688
time: 2.227499008178711
[1, 6224] loss_train: 0.005175, loss_test: 0.005759
time: 0.24307894706726074
time: 2.2189996242523193
[1, 6225] loss_train: 0.006276, loss_test: 0.005770
time: 0.24606847763061523
time: 2.1954903602600098
[1, 6226] loss_train: 0.002385, loss_test: 0.005786
time: 0.24405217170715332
time: 2.2185800075531006
[1, 6227] loss_train: 0.004307, loss_test: 0.005802
time: 0.24406719207763672
time: 2.22249698638916
[1, 6228] loss_train: 0.005325, loss_test: 0.005819
time: 0.24305343627929688
time: 2.244502305984497
[1, 6229] loss_train: 0.003947, loss_test: 0.005834
time: 0.24505400657653809
time: 2.2300405502319336
[1, 6230] loss_train: 0.003645, loss_test: 0.005845
time: 0.25505590438842773
time: 2.255504846572876
[1, 6231] loss_train: 0.012504, loss_test: 0.005827
time: 0.24805474281311035
time: 2.2595055103302
[1, 6232] loss_train: 0.006539, loss_test: 0.005805
time: 0.24605536460876465
time: 2.224497079849243
[1, 6233] loss_train: 0.006967, loss_test: 0.005785
time: 0.24805450439453125
time: 2.239501476287842
[1, 6234] loss_train: 0.007888, loss_test: 0.005774
time: 0.2530558109283447
time: 2.240504026412964
[1, 6235] loss_train: 0.002836, loss_test: 0.005766
time: 0.25208520889282227
time: 2.224497079849243
[1, 6236] loss_train: 0.006700, loss_test: 0.005763
time: 0.24605488777160645
time: 2.2180378437042236
[1, 6237] loss_train: 0.008492, loss_test: 0.005764
time: 0.2470560073852539
time: 2.2285096645355225
[1, 6238] loss_train: 0.004525, loss_test: 0.005770
time: 0.24305415153503418
time: 2.2134947776794434
[1, 6239] loss_train: 0.007950, loss_test: 0.005776
time: 0.24305367469787598
time: 2.236511707305908
[1, 6240] loss_train: 0.007775, loss_test: 0.005780
time: 0.25505614280700684
time: 2.2495038509368896
[1, 6241] loss_train: 0.006740, loss_test: 0.005775
time: 0.25305628776550293
time: 2.245513677597046
[1, 6242] loss_train: 0.006106, loss_test: 0.005768
time: 0.2450547218322754
time: 2.2425007820129395
[1, 6243] loss_train: 0.001224, loss_test: 0.005760
time: 0.24605464935302734
time: 2.2164952754974365
[1, 6244] loss_train: 0.017563, loss_test: 0.005755
time: 0.24405479431152344
time: 2.2164947986602783
[1, 6245] loss_train: 0.014104, loss_test: 0.005751
time: 0.2450544834136963
time: 2.225508451461792
[1, 6246] loss_train: 0.006146, loss_test: 0.005747
time: 0.24405384063720703
time: 2.200493097305298
[1, 6247] loss_train: 0.005775, loss_test: 0.005744
time: 0.24305367469787598
time: 2.2114946842193604
[1, 6248] loss_train: 0.002678, loss_test: 0.005742
time: 0.24405384063720703
time: 2.1954989433288574
[1, 6249] loss_train: 0.009478, loss_test: 0.005740
time: 0.2450547218322754
time: 2.209494113922119
[1, 6250] loss_train: 0.005980, loss_test: 0.005738
time: 0.2580573558807373
time: 2.24851655960083
[1, 6251] loss_train: 0.009798, loss_test: 0.005735
time: 0.24405455589294434
time: 2.2154955863952637
[1, 6252] loss_train: 0.012505, loss_test: 0.005734
time: 0.25305628776550293
time: 2.2264978885650635
[1, 6253] loss_train: 0.006179, loss_test: 0.005732
time: 0.24405360221862793
time: 2.253504991531372
[1, 6254] loss_train: 0.011540, loss_test: 0.005728
time: 0.24905705451965332
time: 2.247518539428711
[1, 6255] loss_train: 0.015230, loss_test: 0.005726
time: 0.24405407905578613
time: 2.244016647338867
[1, 6256] loss_train: 0.002938, loss_test: 0.005724
time: 0.2490549087524414
time: 2.2465031147003174
[1, 6257] loss_train: 0.002293, loss_test: 0.005723
time: 0.24506783485412598
time: 2.2065021991729736
[1, 6258] loss_train: 0.005296, loss_test: 0.005722
time: 0.2470552921295166
time: 2.2024927139282227
[1, 6259] loss_train: 0.012787, loss_test: 0.005719
time: 0.24307870864868164
time: 2.257051944732666
[1, 6260] loss_train: 0.014999, loss_test: 0.005715
time: 0.2560570240020752
time: 2.258505344390869
[1, 6261] loss_train: 0.006509, loss_test: 0.005716
time: 0.24505400657653809
time: 2.257504940032959
[1, 6262] loss_train: 0.011265, loss_test: 0.005721
time: 0.24605464935302734
time: 2.239501476287842
[1, 6263] loss_train: 0.002823, loss_test: 0.005725
time: 0.24405360221862793
time: 2.240501642227173
[1, 6264] loss_train: 0.007803, loss_test: 0.005729
time: 0.24205422401428223
time: 2.207493305206299
[1, 6265] loss_train: 0.006329, loss_test: 0.005732
time: 0.2450544834136963
time: 2.250502347946167
[1, 6266] loss_train: 0.001902, loss_test: 0.005734
time: 0.24507999420166016
time: 2.2295331954956055
[1, 6267] loss_train: 0.001439, loss_test: 0.005741
time: 0.24305415153503418
time: 2.244502305984497
[1, 6268] loss_train: 0.005651, loss_test: 0.005749
time: 0.24305462837219238
time: 2.2565042972564697
[1, 6269] loss_train: 0.005195, loss_test: 0.005758
time: 0.24305415153503418
time: 2.2015841007232666
[1, 6270] loss_train: 0.008624, loss_test: 0.005771
time: 0.25505614280700684
time: 2.2465028762817383
[1, 6271] loss_train: 0.008799, loss_test: 0.005775
time: 0.24305462837219238
time: 2.2290022373199463
[1, 6272] loss_train: 0.005813, loss_test: 0.005781
time: 0.2450547218322754
time: 2.2140181064605713
[1, 6273] loss_train: 0.011384, loss_test: 0.005760
time: 0.2450547218322754
time: 2.2194957733154297
[1, 6274] loss_train: 0.006259, loss_test: 0.005748
time: 0.24305367469787598
time: 2.1829917430877686
[1, 6275] loss_train: 0.012889, loss_test: 0.005739
time: 0.2450544834136963
time: 2.2164957523345947
[1, 6276] loss_train: 0.009331, loss_test: 0.005736
time: 0.2450549602508545
time: 2.219522476196289
[1, 6277] loss_train: 0.013898, loss_test: 0.005746
time: 0.2490556240081787
time: 2.2244973182678223
[1, 6278] loss_train: 0.001471, loss_test: 0.005759
time: 0.24405407905578613
time: 2.2385003566741943
[1, 6279] loss_train: 0.004552, loss_test: 0.005763
time: 0.25005626678466797
time: 2.284548759460449
[1, 6280] loss_train: 0.008213, loss_test: 0.005759
time: 0.25705671310424805
time: 2.2475132942199707
[1, 6281] loss_train: 0.010624, loss_test: 0.005751
time: 0.24908113479614258
time: 2.2234973907470703
[1, 6282] loss_train: 0.005591, loss_test: 0.005740
time: 0.24806857109069824
time: 2.206009864807129
[1, 6283] loss_train: 0.012111, loss_test: 0.005734
time: 0.247056245803833
time: 2.237499713897705
[1, 6284] loss_train: 0.010327, loss_test: 0.005733
time: 0.24405384063720703
time: 2.2004928588867188
[1, 6285] loss_train: 0.002967, loss_test: 0.005737
time: 0.24405384063720703
time: 2.2084944248199463
[1, 6286] loss_train: 0.003076, loss_test: 0.005749
time: 0.24405479431152344
time: 2.1924889087677
[1, 6287] loss_train: 0.008901, loss_test: 0.005767
time: 0.24305248260498047
time: 2.2375011444091797
[1, 6288] loss_train: 0.007736, loss_test: 0.005788
time: 0.24505400657653809
time: 2.2380197048187256
[1, 6289] loss_train: 0.007104, loss_test: 0.005807
time: 0.24505329132080078
time: 2.20451283454895
[1, 6290] loss_train: 0.009380, loss_test: 0.005823
time: 0.25705575942993164
time: 2.2885124683380127
[1, 6291] loss_train: 0.003780, loss_test: 0.005832
time: 0.24405384063720703
time: 2.23249888420105
[1, 6292] loss_train: 0.008151, loss_test: 0.005829
time: 0.2450549602508545
time: 2.2315168380737305
[1, 6293] loss_train: 0.001484, loss_test: 0.005829
time: 0.24205303192138672
time: 2.223499059677124
[1, 6294] loss_train: 0.001274, loss_test: 0.005835
time: 0.24405264854431152
time: 2.211498260498047
[1, 6295] loss_train: 0.004241, loss_test: 0.005832
time: 0.24405121803283691
time: 2.2274975776672363
[1, 6296] loss_train: 0.014657, loss_test: 0.005813
time: 0.2470548152923584
time: 2.243501901626587
[1, 6297] loss_train: 0.005891, loss_test: 0.005799
time: 0.2450547218322754
time: 2.194490671157837
[1, 6298] loss_train: 0.005794, loss_test: 0.005790
time: 0.24805474281311035
time: 2.1959943771362305
[1, 6299] loss_train: 0.000508, loss_test: 0.005788
time: 0.24605441093444824
time: 2.2655069828033447
[1, 6300] loss_train: 0.003000, loss_test: 0.005790
time: 0.26105833053588867
time: 2.242609977722168
[1, 6301] loss_train: 0.006307, loss_test: 0.005796
time: 0.24405407905578613
time: 2.2465028762817383
[1, 6302] loss_train: 0.012992, loss_test: 0.005808
time: 0.2470548152923584
time: 2.2205069065093994
[1, 6303] loss_train: 0.002946, loss_test: 0.005824
time: 0.24405455589294434
time: 2.2395005226135254
[1, 6304] loss_train: 0.006774, loss_test: 0.005837
time: 0.24305438995361328
time: 2.2124946117401123
[1, 6305] loss_train: 0.004446, loss_test: 0.005828
time: 0.24505400657653809
time: 2.2175047397613525
[1, 6306] loss_train: 0.005515, loss_test: 0.005816
time: 0.2450547218322754
time: 2.24650239944458
[1, 6307] loss_train: 0.003296, loss_test: 0.005803
time: 0.24405360221862793
time: 2.243502378463745
[1, 6308] loss_train: 0.006854, loss_test: 0.005793
time: 0.24405384063720703
time: 2.228513717651367
[1, 6309] loss_train: 0.001741, loss_test: 0.005796
time: 0.24805545806884766
time: 2.235003709793091
[1, 6310] loss_train: 0.004449, loss_test: 0.005804
time: 0.2560703754425049
time: 2.2745094299316406
[1, 6311] loss_train: 0.007085, loss_test: 0.005807
time: 0.24306726455688477
time: 2.2224998474121094
[1, 6312] loss_train: 0.002659, loss_test: 0.005808
time: 0.24605441093444824
time: 2.2625062465667725
[1, 6313] loss_train: 0.011753, loss_test: 0.005793
time: 0.24305367469787598
time: 2.232499837875366
[1, 6314] loss_train: 0.004605, loss_test: 0.005801
time: 0.24308037757873535
time: 2.2284984588623047
[1, 6315] loss_train: 0.003971, loss_test: 0.005827
time: 0.24305438995361328
time: 2.2134947776794434
[1, 6316] loss_train: 0.013229, loss_test: 0.005850
time: 0.24305343627929688
time: 2.2134957313537598
[1, 6317] loss_train: 0.003652, loss_test: 0.005886
time: 0.24305319786071777
time: 2.2084944248199463
[1, 6318] loss_train: 0.005952, loss_test: 0.005941
time: 0.24505400657653809
time: 2.218496084213257
[1, 6319] loss_train: 0.007883, loss_test: 0.006011
time: 0.2535684108734131
time: 2.205493688583374
[1, 6320] loss_train: 0.005522, loss_test: 0.006055
time: 0.26105833053588867
time: 2.219496011734009
[1, 6321] loss_train: 0.007506, loss_test: 0.006075
time: 0.2470552921295166
time: 2.2405126094818115
[1, 6322] loss_train: 0.004029, loss_test: 0.006095
time: 0.24405360221862793
time: 2.2224977016448975
[1, 6323] loss_train: 0.008644, loss_test: 0.006100
time: 0.24405360221862793
time: 2.235499858856201
[1, 6324] loss_train: 0.005909, loss_test: 0.006079
time: 0.2450551986694336
time: 2.2315011024475098
[1, 6325] loss_train: 0.017670, loss_test: 0.006053
time: 0.24405455589294434
time: 2.2415008544921875
[1, 6326] loss_train: 0.012215, loss_test: 0.006035
time: 0.24405455589294434
time: 2.225003957748413
[1, 6327] loss_train: 0.009280, loss_test: 0.005989
time: 0.24405384063720703
time: 2.209496259689331
[1, 6328] loss_train: 0.004374, loss_test: 0.005910
time: 0.24305319786071777
time: 2.228013753890991
[1, 6329] loss_train: 0.006241, loss_test: 0.005858
time: 0.2490558624267578
time: 2.2335150241851807
[1, 6330] loss_train: 0.004465, loss_test: 0.005811
time: 0.2560575008392334
time: 2.2275021076202393
[1, 6331] loss_train: 0.006635, loss_test: 0.005808
time: 0.2490556240081787
time: 2.235499382019043
[1, 6332] loss_train: 0.008044, loss_test: 0.005821
time: 0.2450542449951172
time: 2.2475030422210693
[1, 6333] loss_train: 0.015077, loss_test: 0.005847
time: 0.24305343627929688
time: 2.2485036849975586
[1, 6334] loss_train: 0.008155, loss_test: 0.005882
time: 0.24405384063720703
time: 2.2244889736175537
[1, 6335] loss_train: 0.023696, loss_test: 0.005883
time: 0.24405384063720703
time: 2.214495897293091
[1, 6336] loss_train: 0.012970, loss_test: 0.005897
time: 0.2450549602508545
time: 2.227511167526245
[1, 6337] loss_train: 0.006266, loss_test: 0.005909
time: 0.24405384063720703
time: 2.2605056762695312
[1, 6338] loss_train: 0.007285, loss_test: 0.005919
time: 0.24405384063720703
time: 2.1965036392211914
[1, 6339] loss_train: 0.003047, loss_test: 0.005926
time: 0.24605417251586914
time: 2.2155003547668457
[1, 6340] loss_train: 0.007519, loss_test: 0.005912
time: 0.25905776023864746
time: 2.2605056762695312
[1, 6341] loss_train: 0.006856, loss_test: 0.005869
time: 0.24405360221862793
time: 2.2084944248199463
[1, 6342] loss_train: 0.005686, loss_test: 0.005815
time: 0.2490549087524414
time: 2.2244980335235596
[1, 6343] loss_train: 0.009362, loss_test: 0.005755
time: 0.24405407905578613
time: 2.2124950885772705
[1, 6344] loss_train: 0.000707, loss_test: 0.005733
time: 0.24405360221862793
time: 2.2224977016448975
[1, 6345] loss_train: 0.012815, loss_test: 0.005741
time: 0.24405479431152344
time: 2.2140326499938965
[1, 6346] loss_train: 0.014064, loss_test: 0.005766
time: 0.24405360221862793
time: 2.216495990753174
[1, 6347] loss_train: 0.001940, loss_test: 0.005803
time: 0.24305415153503418
time: 2.223498582839966
[1, 6348] loss_train: 0.006558, loss_test: 0.005839
time: 0.24305415153503418
time: 2.2274985313415527
[1, 6349] loss_train: 0.010191, loss_test: 0.005859
time: 0.24406671524047852
time: 2.1935055255889893
[1, 6350] loss_train: 0.007281, loss_test: 0.005871
time: 0.2560567855834961
time: 2.2535042762756348
[1, 6351] loss_train: 0.005757, loss_test: 0.005864
time: 0.24405384063720703
time: 2.227499008178711
[1, 6352] loss_train: 0.008122, loss_test: 0.005820
time: 0.24405407905578613
time: 2.219499111175537
[1, 6353] loss_train: 0.006267, loss_test: 0.005779
time: 0.2470552921295166
time: 2.2024919986724854
[1, 6354] loss_train: 0.009946, loss_test: 0.005749
time: 0.2450542449951172
time: 2.2050206661224365
[1, 6355] loss_train: 0.008206, loss_test: 0.005729
time: 0.2490546703338623
time: 2.20149302482605
[1, 6356] loss_train: 0.005685, loss_test: 0.005725
time: 0.24505400657653809
time: 2.225497007369995
[1, 6357] loss_train: 0.005109, loss_test: 0.005734
time: 0.25005626678466797
time: 2.2214972972869873
[1, 6358] loss_train: 0.005816, loss_test: 0.005757
time: 0.24405431747436523
time: 2.200528621673584
[1, 6359] loss_train: 0.002372, loss_test: 0.005771
time: 0.24405407905578613
time: 2.2044928073883057
[1, 6360] loss_train: 0.010249, loss_test: 0.005771
time: 0.25776052474975586
time: 2.2425005435943604
[1, 6361] loss_train: 0.001974, loss_test: 0.005769
time: 0.24405455589294434
time: 2.24550199508667
[1, 6362] loss_train: 0.006450, loss_test: 0.005759
time: 0.25305604934692383
time: 2.2595057487487793
[1, 6363] loss_train: 0.005493, loss_test: 0.005745
time: 0.24605464935302734
time: 2.238513231277466
[1, 6364] loss_train: 0.006019, loss_test: 0.005737
time: 0.24684691429138184
time: 2.224838972091675
[1, 6365] loss_train: 0.001810, loss_test: 0.005732
time: 0.24405479431152344
time: 2.233499526977539
[1, 6366] loss_train: 0.005757, loss_test: 0.005733
time: 0.24405455589294434
time: 2.219496726989746
[1, 6367] loss_train: 0.002794, loss_test: 0.005744
time: 0.24505376815795898
time: 2.2134957313537598
[1, 6368] loss_train: 0.005270, loss_test: 0.005759
time: 0.24305391311645508
time: 2.2264978885650635
[1, 6369] loss_train: 0.005055, loss_test: 0.005779
time: 0.24505400657653809
time: 2.242527484893799
[1, 6370] loss_train: 0.007269, loss_test: 0.005798
time: 0.25505685806274414
time: 2.204495668411255
[1, 6371] loss_train: 0.010206, loss_test: 0.005816
time: 0.24405336380004883
time: 2.216496467590332
[1, 6372] loss_train: 0.008142, loss_test: 0.005836
time: 0.25005483627319336
time: 2.225497007369995
[1, 6373] loss_train: 0.002058, loss_test: 0.005862
time: 0.2450547218322754
time: 2.2405011653900146
[1, 6374] loss_train: 0.005243, loss_test: 0.005881
time: 0.24605512619018555
time: 2.231498956680298
[1, 6375] loss_train: 0.003239, loss_test: 0.005900
time: 0.2450544834136963
time: 2.2215137481689453
[1, 6376] loss_train: 0.010905, loss_test: 0.005899
time: 0.24605488777160645
time: 2.2625067234039307
[1, 6377] loss_train: 0.003734, loss_test: 0.005901
time: 0.25510072708129883
time: 2.2295007705688477
[1, 6378] loss_train: 0.003364, loss_test: 0.005895
time: 0.24805474281311035
time: 2.219496726989746
[1, 6379] loss_train: 0.003748, loss_test: 0.005892
time: 0.24405336380004883
time: 2.2074944972991943
[1, 6380] loss_train: 0.006527, loss_test: 0.005849
time: 0.255568265914917
time: 2.2264981269836426
[1, 6381] loss_train: 0.002726, loss_test: 0.005803
time: 0.24605417251586914
time: 2.2094943523406982
[1, 6382] loss_train: 0.005096, loss_test: 0.005772
time: 0.2440657615661621
time: 2.266507387161255
[1, 6383] loss_train: 0.007356, loss_test: 0.005752
time: 0.24456548690795898
time: 2.2705085277557373
[1, 6384] loss_train: 0.003920, loss_test: 0.005744
time: 0.24505400657653809
time: 2.262521982192993
[1, 6385] loss_train: 0.001040, loss_test: 0.005743
time: 0.2450542449951172
time: 2.2194983959198
[1, 6386] loss_train: 0.016423, loss_test: 0.005747
time: 0.24306774139404297
time: 2.2665059566497803
[1, 6387] loss_train: 0.003286, loss_test: 0.005752
time: 0.24606943130493164
time: 2.2225029468536377
[1, 6388] loss_train: 0.004504, loss_test: 0.005754
time: 0.24405360221862793
time: 2.2244980335235596
[1, 6389] loss_train: 0.008834, loss_test: 0.005761
time: 0.24506664276123047
time: 2.2114953994750977
[1, 6390] loss_train: 0.007851, loss_test: 0.005765
time: 0.256056547164917
time: 2.251523494720459
[1, 6391] loss_train: 0.005629, loss_test: 0.005768
time: 0.2450551986694336
time: 2.224497079849243
[1, 6392] loss_train: 0.010861, loss_test: 0.005767
time: 0.24307847023010254
time: 2.2215049266815186
[1, 6393] loss_train: 0.005554, loss_test: 0.005764
time: 0.2430555820465088
time: 2.1904895305633545
[1, 6394] loss_train: 0.008220, loss_test: 0.005757
time: 0.24405455589294434
time: 2.2024929523468018
[1, 6395] loss_train: 0.003506, loss_test: 0.005753
time: 0.24808096885681152
time: 2.212494373321533
[1, 6396] loss_train: 0.006963, loss_test: 0.005753
time: 0.24505400657653809
time: 2.194026470184326
[1, 6397] loss_train: 0.011662, loss_test: 0.005756
time: 0.25005531311035156
time: 2.220496654510498
[1, 6398] loss_train: 0.015574, loss_test: 0.005754
time: 0.2450542449951172
time: 2.219496726989746
[1, 6399] loss_train: 0.008168, loss_test: 0.005752
time: 0.24405479431152344
time: 2.250502824783325
[1, 6400] loss_train: 0.010080, loss_test: 0.005746
time: 0.2540562152862549
time: 2.214010715484619
[1, 6401] loss_train: 0.002281, loss_test: 0.005741
time: 0.24605417251586914
time: 2.2244980335235596
[1, 6402] loss_train: 0.003590, loss_test: 0.005739
time: 0.24305415153503418
time: 2.228012800216675
[1, 6403] loss_train: 0.004178, loss_test: 0.005736
time: 0.2450549602508545
time: 2.2410223484039307
[1, 6404] loss_train: 0.001449, loss_test: 0.005736
time: 0.2470543384552002
time: 2.2304999828338623
[1, 6405] loss_train: 0.003764, loss_test: 0.005738
time: 0.24405431747436523
time: 2.2254981994628906
[1, 6406] loss_train: 0.003064, loss_test: 0.005742
time: 0.24405407905578613
time: 2.23403000831604
[1, 6407] loss_train: 0.006785, loss_test: 0.005748
time: 0.24505376815795898
time: 2.2455027103424072
[1, 6408] loss_train: 0.004119, loss_test: 0.005758
time: 0.2450544834136963
time: 2.213014602661133
[1, 6409] loss_train: 0.004218, loss_test: 0.005770
time: 0.2440793514251709
time: 2.2264983654022217
[1, 6410] loss_train: 0.009166, loss_test: 0.005764
time: 0.25457310676574707
time: 2.2675094604492188
[1, 6411] loss_train: 0.005510, loss_test: 0.005750
time: 0.24805450439453125
time: 2.23350191116333
[1, 6412] loss_train: 0.002335, loss_test: 0.005740
time: 0.24405503273010254
time: 2.237499952316284
[1, 6413] loss_train: 0.006001, loss_test: 0.005735
time: 0.24305343627929688
time: 2.2515041828155518
[1, 6414] loss_train: 0.007267, loss_test: 0.005731
time: 0.2450547218322754
time: 2.2054927349090576
[1, 6415] loss_train: 0.011948, loss_test: 0.005725
time: 0.2450542449951172
time: 2.2084944248199463
[1, 6416] loss_train: 0.012745, loss_test: 0.005726
time: 0.24805450439453125
time: 2.2175073623657227
[1, 6417] loss_train: 0.007792, loss_test: 0.005731
time: 0.24805474281311035
time: 2.203493118286133
[1, 6418] loss_train: 0.002670, loss_test: 0.005735
time: 0.24605488777160645
time: 2.2090277671813965
[1, 6419] loss_train: 0.004261, loss_test: 0.005737
time: 0.24205303192138672
time: 2.238006114959717
[1, 6420] loss_train: 0.010931, loss_test: 0.005734
time: 0.25705671310424805
time: 2.254528284072876
[1, 6421] loss_train: 0.007266, loss_test: 0.005731
time: 0.24405360221862793
time: 2.232499837875366
[1, 6422] loss_train: 0.010165, loss_test: 0.005726
time: 0.24305343627929688
time: 2.265514850616455
[1, 6423] loss_train: 0.013438, loss_test: 0.005727
time: 0.24305391311645508
time: 2.2585055828094482
[1, 6424] loss_train: 0.008681, loss_test: 0.005737
time: 0.2450542449951172
time: 2.2275004386901855
[1, 6425] loss_train: 0.008194, loss_test: 0.005745
time: 0.24405336380004883
time: 2.243502378463745
[1, 6426] loss_train: 0.005154, loss_test: 0.005742
time: 0.24406695365905762
time: 2.2044930458068848
[1, 6427] loss_train: 0.015076, loss_test: 0.005743
time: 0.2470543384552002
time: 2.2525041103363037
[1, 6428] loss_train: 0.004280, loss_test: 0.005747
time: 0.24905657768249512
time: 2.2435007095336914
[1, 6429] loss_train: 0.003247, loss_test: 0.005746
time: 0.24405431747436523
time: 2.227498769760132
[1, 6430] loss_train: 0.008299, loss_test: 0.005746
time: 0.25705647468566895
time: 2.2335000038146973
[1, 6431] loss_train: 0.012178, loss_test: 0.005743
time: 0.2440798282623291
time: 2.2395007610321045
[1, 6432] loss_train: 0.012119, loss_test: 0.005744
time: 0.24305319786071777
time: 2.2264983654022217
[1, 6433] loss_train: 0.003677, loss_test: 0.005744
time: 0.24405407905578613
time: 2.231499433517456
[1, 6434] loss_train: 0.009498, loss_test: 0.005742
time: 0.24605441093444824
time: 2.2074942588806152
[1, 6435] loss_train: 0.005315, loss_test: 0.005738
time: 0.24405336380004883
time: 2.231508731842041
[1, 6436] loss_train: 0.005302, loss_test: 0.005732
time: 0.24605512619018555
time: 2.2360031604766846
[1, 6437] loss_train: 0.002548, loss_test: 0.005727
time: 0.24606657028198242
time: 2.2345004081726074
[1, 6438] loss_train: 0.007859, loss_test: 0.005725
time: 0.24605417251586914
time: 2.2214972972869873
[1, 6439] loss_train: 0.005278, loss_test: 0.005729
time: 0.25005483627319336
time: 2.1975324153900146
[1, 6440] loss_train: 0.003955, loss_test: 0.005736
time: 0.25505638122558594
time: 2.241502046585083
[1, 6441] loss_train: 0.001387, loss_test: 0.005751
time: 0.25205540657043457
time: 2.2385010719299316
[1, 6442] loss_train: 0.001796, loss_test: 0.005772
time: 0.24405360221862793
time: 2.2114949226379395
[1, 6443] loss_train: 0.005794, loss_test: 0.005796
time: 0.2450549602508545
time: 2.208493709564209
[1, 6444] loss_train: 0.001086, loss_test: 0.005824
time: 0.24305343627929688
time: 2.241502046585083
[1, 6445] loss_train: 0.001893, loss_test: 0.005854
time: 0.24405407905578613
time: 2.2429561614990234
[1, 6446] loss_train: 0.008086, loss_test: 0.005861
time: 0.24305391311645508
time: 2.2320220470428467
[1, 6447] loss_train: 0.012619, loss_test: 0.005828
time: 0.24205279350280762
time: 2.2004928588867188
[1, 6448] loss_train: 0.008013, loss_test: 0.005789
time: 0.2510693073272705
time: 2.231499433517456
[1, 6449] loss_train: 0.004315, loss_test: 0.005763
time: 0.24305438995361328
time: 2.242509365081787
[1, 6450] loss_train: 0.002676, loss_test: 0.005750
time: 0.254056453704834
time: 2.2445011138916016
[1, 6451] loss_train: 0.005031, loss_test: 0.005746
time: 0.24306702613830566
time: 2.2064931392669678
[1, 6452] loss_train: 0.007578, loss_test: 0.005750
time: 0.24405407905578613
time: 2.2024929523468018
[1, 6453] loss_train: 0.001291, loss_test: 0.005761
time: 0.2450547218322754
time: 2.2184979915618896
[1, 6454] loss_train: 0.002311, loss_test: 0.005764
time: 0.24506783485412598
time: 2.2164952754974365
[1, 6455] loss_train: 0.009045, loss_test: 0.005763
time: 0.24505376815795898
time: 2.209287166595459
[1, 6456] loss_train: 0.003171, loss_test: 0.005758
time: 0.2490549087524414
time: 2.244511604309082
[1, 6457] loss_train: 0.010337, loss_test: 0.005750
time: 0.24306631088256836
time: 2.220496416091919
[1, 6458] loss_train: 0.008841, loss_test: 0.005747
time: 0.24805545806884766
time: 2.2294981479644775
[1, 6459] loss_train: 0.023221, loss_test: 0.005743
time: 0.24305391311645508
time: 2.2215051651000977
[1, 6460] loss_train: 0.005727, loss_test: 0.005744
time: 0.25628185272216797
time: 2.2555038928985596
[1, 6461] loss_train: 0.006180, loss_test: 0.005747
time: 0.24405455589294434
time: 2.2094945907592773
[1, 6462] loss_train: 0.008914, loss_test: 0.005750
time: 0.24506616592407227
time: 2.2385003566741943
[1, 6463] loss_train: 0.006226, loss_test: 0.005750
time: 0.24405384063720703
time: 2.20149302482605
[1, 6464] loss_train: 0.007086, loss_test: 0.005748
time: 0.24405384063720703
time: 2.181488037109375
[1, 6465] loss_train: 0.008562, loss_test: 0.005749
time: 0.2450542449951172
time: 2.216524124145508
[1, 6466] loss_train: 0.005021, loss_test: 0.005751
time: 0.24405360221862793
time: 2.225008726119995
[1, 6467] loss_train: 0.008774, loss_test: 0.005750
time: 0.24405479431152344
time: 2.2134947776794434
[1, 6468] loss_train: 0.010856, loss_test: 0.005749
time: 0.2450542449951172
time: 2.2605056762695312
[1, 6469] loss_train: 0.004507, loss_test: 0.005750
time: 0.24305367469787598
time: 2.2206623554229736
[1, 6470] loss_train: 0.003528, loss_test: 0.005756
time: 0.2580575942993164
time: 2.224497079849243
[1, 6471] loss_train: 0.005861, loss_test: 0.005762
time: 0.24805569648742676
time: 2.2294981479644775
[1, 6472] loss_train: 0.003662, loss_test: 0.005763
time: 0.24805545806884766
time: 2.2144954204559326
[1, 6473] loss_train: 0.003975, loss_test: 0.005762
time: 0.2490544319152832
time: 2.2254981994628906
[1, 6474] loss_train: 0.008497, loss_test: 0.005763
time: 0.24405455589294434
time: 2.236499786376953
[1, 6475] loss_train: 0.002864, loss_test: 0.005766
time: 0.24805474281311035
time: 2.1945154666900635
[1, 6476] loss_train: 0.008887, loss_test: 0.005764
time: 0.24505376815795898
time: 2.2244980335235596
[1, 6477] loss_train: 0.003657, loss_test: 0.005766
time: 0.24405360221862793
time: 2.219496726989746
[1, 6478] loss_train: 0.010573, loss_test: 0.005759
time: 0.24405407905578613
time: 2.2214975357055664
[1, 6479] loss_train: 0.007679, loss_test: 0.005755
time: 0.2470543384552002
time: 2.221038341522217
[1, 6480] loss_train: 0.007838, loss_test: 0.005756
time: 0.25505638122558594
time: 2.2475030422210693
[1, 6481] loss_train: 0.008217, loss_test: 0.005764
time: 0.24305391311645508
time: 2.2244975566864014
[1, 6482] loss_train: 0.008404, loss_test: 0.005778
time: 0.24605464935302734
time: 2.241504192352295
[1, 6483] loss_train: 0.007110, loss_test: 0.005791
time: 0.24405360221862793
time: 2.241501808166504
[1, 6484] loss_train: 0.005729, loss_test: 0.005798
time: 0.2450549602508545
time: 2.2445015907287598
[1, 6485] loss_train: 0.015658, loss_test: 0.005807
time: 0.2450544834136963
time: 2.2405128479003906
[1, 6486] loss_train: 0.007535, loss_test: 0.005798
time: 0.24405312538146973
time: 2.265507221221924
[1, 6487] loss_train: 0.009704, loss_test: 0.005783
time: 0.24505400657653809
time: 2.2004926204681396
[1, 6488] loss_train: 0.014049, loss_test: 0.005765
time: 0.24405431747436523
time: 2.206493377685547
[1, 6489] loss_train: 0.001103, loss_test: 0.005753
time: 0.2470545768737793
time: 2.253025531768799
[1, 6490] loss_train: 0.011249, loss_test: 0.005744
time: 0.2560563087463379
time: 2.258504867553711
[1, 6491] loss_train: 0.008337, loss_test: 0.005738
time: 0.24405455589294434
time: 2.197500228881836
[1, 6492] loss_train: 0.009338, loss_test: 0.005737
time: 0.2490549087524414
time: 2.1994919776916504
[1, 6493] loss_train: 0.015746, loss_test: 0.005732
time: 0.24605464935302734
time: 2.218496322631836
[1, 6494] loss_train: 0.009889, loss_test: 0.005731
time: 0.24805545806884766
time: 2.2705078125
[1, 6495] loss_train: 0.005926, loss_test: 0.005729
time: 0.24505400657653809
time: 2.211494207382202
[1, 6496] loss_train: 0.011215, loss_test: 0.005730
time: 0.2470550537109375
time: 2.2380237579345703
[1, 6497] loss_train: 0.001706, loss_test: 0.005727
time: 0.24505376815795898
time: 2.231545925140381
[1, 6498] loss_train: 0.002055, loss_test: 0.005724
time: 0.24305391311645508
time: 2.2085041999816895
[1, 6499] loss_train: 0.005332, loss_test: 0.005724
time: 0.25005578994750977
time: 2.2665302753448486
[1, 6500] loss_train: 0.003578, loss_test: 0.005726
time: 0.2530689239501953
time: 2.2575037479400635
[1, 6501] loss_train: 0.005458, loss_test: 0.005730
time: 0.24405455589294434
time: 2.238499879837036
[1, 6502] loss_train: 0.004233, loss_test: 0.005735
time: 0.24305367469787598
time: 2.2244980335235596
[1, 6503] loss_train: 0.003308, loss_test: 0.005742
time: 0.24405360221862793
time: 2.252504587173462
[1, 6504] loss_train: 0.008771, loss_test: 0.005753
time: 0.24305367469787598
time: 2.232012987136841
[1, 6505] loss_train: 0.002048, loss_test: 0.005768
time: 0.24405360221862793
time: 2.215496778488159
[1, 6506] loss_train: 0.006646, loss_test: 0.005783
time: 0.24605417251586914
time: 2.2555198669433594
[1, 6507] loss_train: 0.006716, loss_test: 0.005794
time: 0.24405360221862793
time: 2.204493999481201
[1, 6508] loss_train: 0.005374, loss_test: 0.005805
time: 0.2440657615661621
time: 2.2175068855285645
[1, 6509] loss_train: 0.006637, loss_test: 0.005817
time: 0.24605464935302734
time: 2.2225234508514404
[1, 6510] loss_train: 0.012054, loss_test: 0.005827
time: 0.2540566921234131
time: 2.268507242202759
[1, 6511] loss_train: 0.002257, loss_test: 0.005841
time: 0.24305319786071777
time: 2.224510908126831
[1, 6512] loss_train: 0.014853, loss_test: 0.005820
time: 0.2450549602508545
time: 2.210493803024292
[1, 6513] loss_train: 0.007635, loss_test: 0.005795
time: 0.24405455589294434
time: 2.2104947566986084
[1, 6514] loss_train: 0.006708, loss_test: 0.005776
time: 0.24405384063720703
time: 2.2234981060028076
[1, 6515] loss_train: 0.002441, loss_test: 0.005755
time: 0.24906659126281738
time: 2.1894900798797607
[1, 6516] loss_train: 0.002930, loss_test: 0.005740
time: 0.24805498123168945
time: 2.2185356616973877
[1, 6517] loss_train: 0.009852, loss_test: 0.005731
time: 0.2470545768737793
time: 2.218496799468994
[1, 6518] loss_train: 0.002954, loss_test: 0.005728
time: 0.24305319786071777
time: 2.261061906814575
[1, 6519] loss_train: 0.006334, loss_test: 0.005726
time: 0.24305462837219238
time: 2.257504463195801
[1, 6520] loss_train: 0.009199, loss_test: 0.005726
time: 0.2560553550720215
time: 2.2635080814361572
[1, 6521] loss_train: 0.009530, loss_test: 0.005727
time: 0.252056360244751
time: 2.2405014038085938
[1, 6522] loss_train: 0.006249, loss_test: 0.005727
time: 0.24305343627929688
time: 2.2470057010650635
[1, 6523] loss_train: 0.000619, loss_test: 0.005724
time: 0.24305319786071777
time: 2.2505040168762207
[1, 6524] loss_train: 0.004014, loss_test: 0.005720
time: 0.24405336380004883
time: 2.2044925689697266
[1, 6525] loss_train: 0.004169, loss_test: 0.005719
time: 0.24405312538146973
time: 2.2014927864074707
[1, 6526] loss_train: 0.001768, loss_test: 0.005719
time: 0.2470557689666748
time: 2.244295358657837
[1, 6527] loss_train: 0.008766, loss_test: 0.005721
time: 0.24405384063720703
time: 2.224499225616455
[1, 6528] loss_train: 0.010591, loss_test: 0.005719
time: 0.24305438995361328
time: 2.2490341663360596
[1, 6529] loss_train: 0.004466, loss_test: 0.005718
time: 0.24405384063720703
time: 2.2695083618164062
[1, 6530] loss_train: 0.004482, loss_test: 0.005720
time: 0.2570686340332031
time: 2.256504535675049
[1, 6531] loss_train: 0.001424, loss_test: 0.005723
time: 0.24405455589294434
time: 2.2465038299560547
[1, 6532] loss_train: 0.004645, loss_test: 0.005730
time: 0.24505305290222168
time: 2.2505042552948
[1, 6533] loss_train: 0.007293, loss_test: 0.005733
time: 0.24308180809020996
time: 2.2485029697418213
[1, 6534] loss_train: 0.004934, loss_test: 0.005737
time: 0.24405360221862793
time: 2.2175230979919434
[1, 6535] loss_train: 0.005941, loss_test: 0.005742
time: 0.24405384063720703
time: 2.2234976291656494
[1, 6536] loss_train: 0.002763, loss_test: 0.005747
time: 0.24478435516357422
time: 2.2184953689575195
[1, 6537] loss_train: 0.005248, loss_test: 0.005754
time: 0.24405431747436523
time: 2.193490982055664
[1, 6538] loss_train: 0.007813, loss_test: 0.005753
time: 0.24406218528747559
time: 2.2401843070983887
[1, 6539] loss_train: 0.013875, loss_test: 0.005745
time: 0.2450566291809082
time: 2.195718765258789
[1, 6540] loss_train: 0.010265, loss_test: 0.005735
time: 0.2600574493408203
time: 2.239023208618164
[1, 6541] loss_train: 0.006097, loss_test: 0.005728
time: 0.24505400657653809
time: 2.217496633529663
[1, 6542] loss_train: 0.007626, loss_test: 0.005725
time: 0.25005578994750977
time: 2.2335100173950195
[1, 6543] loss_train: 0.008223, loss_test: 0.005727
time: 0.2450547218322754
time: 2.24300479888916
[1, 6544] loss_train: 0.022257, loss_test: 0.005735
time: 0.24706768989562988
time: 2.2355005741119385
[1, 6545] loss_train: 0.002403, loss_test: 0.005740
time: 0.24405384063720703
time: 2.1894900798797607
[1, 6546] loss_train: 0.007587, loss_test: 0.005748
time: 0.24505400657653809
time: 2.208493947982788
[1, 6547] loss_train: 0.006867, loss_test: 0.005756
time: 0.24499726295471191
time: 2.223496198654175
[1, 6548] loss_train: 0.006002, loss_test: 0.005761
time: 0.24305462837219238
time: 2.229499101638794
[1, 6549] loss_train: 0.004483, loss_test: 0.005763
time: 0.24305415153503418
time: 2.2245166301727295
[1, 6550] loss_train: 0.003709, loss_test: 0.005761
time: 0.2560691833496094
time: 2.2535059452056885
[1, 6551] loss_train: 0.008051, loss_test: 0.005750
time: 0.24405360221862793
time: 2.257505178451538
[1, 6552] loss_train: 0.006650, loss_test: 0.005732
time: 0.24305367469787598
time: 2.2244982719421387
[1, 6553] loss_train: 0.006298, loss_test: 0.005721
time: 0.24405407905578613
time: 2.2204971313476562
[1, 6554] loss_train: 0.010190, loss_test: 0.005716
time: 0.24305319786071777
time: 2.231499433517456
[1, 6555] loss_train: 0.003149, loss_test: 0.005713
time: 0.24405360221862793
time: 2.2230184078216553
[1, 6556] loss_train: 0.006792, loss_test: 0.005713
time: 0.24405360221862793
time: 2.253504514694214
[1, 6557] loss_train: 0.012401, loss_test: 0.005714
time: 0.24305343627929688
time: 2.230499505996704
[1, 6558] loss_train: 0.012439, loss_test: 0.005716
time: 0.24405431747436523
time: 2.2435038089752197
[1, 6559] loss_train: 0.006012, loss_test: 0.005718
time: 0.24506711959838867
time: 2.2355144023895264
[1, 6560] loss_train: 0.007184, loss_test: 0.005720
time: 0.2540557384490967
time: 2.2405011653900146
[1, 6561] loss_train: 0.002637, loss_test: 0.005721
time: 0.25505614280700684
time: 2.199500322341919
[1, 6562] loss_train: 0.012566, loss_test: 0.005721
time: 0.2442793846130371
time: 2.23449969291687
[1, 6563] loss_train: 0.005794, loss_test: 0.005719
time: 0.2490553855895996
time: 2.190424680709839
[1, 6564] loss_train: 0.004453, loss_test: 0.005716
time: 0.24505352973937988
time: 2.1985175609588623
[1, 6565] loss_train: 0.006145, loss_test: 0.005715
time: 0.24305438995361328
time: 2.2278223037719727
[1, 6566] loss_train: 0.007541, loss_test: 0.005715
time: 0.24205374717712402
time: 2.239513397216797
[1, 6567] loss_train: 0.007608, loss_test: 0.005715
time: 0.24305438995361328
time: 2.2385170459747314
[1, 6568] loss_train: 0.018695, loss_test: 0.005714
time: 0.2450547218322754
time: 2.223496913909912
[1, 6569] loss_train: 0.003860, loss_test: 0.005718
time: 0.24408340454101562
time: 2.2445013523101807
[1, 6570] loss_train: 0.002840, loss_test: 0.005722
time: 0.2560567855834961
time: 2.2915263175964355
[1, 6571] loss_train: 0.015795, loss_test: 0.005729
time: 0.2430586814880371
time: 2.197492837905884
[1, 6572] loss_train: 0.006829, loss_test: 0.005727
time: 0.24505400657653809
time: 2.256505250930786
[1, 6573] loss_train: 0.004489, loss_test: 0.005727
time: 0.2470543384552002
time: 2.240501642227173
[1, 6574] loss_train: 0.001842, loss_test: 0.005724
time: 0.24405407905578613
time: 2.1924898624420166
[1, 6575] loss_train: 0.006535, loss_test: 0.005724
time: 0.24406743049621582
time: 2.2164952754974365
[1, 6576] loss_train: 0.001500, loss_test: 0.005725
time: 0.24305438995361328
time: 2.230030059814453
[1, 6577] loss_train: 0.008085, loss_test: 0.005730
time: 0.24305391311645508
time: 2.211013078689575
[1, 6578] loss_train: 0.007164, loss_test: 0.005729
time: 0.244584321975708
time: 2.1994922161102295
[1, 6579] loss_train: 0.009481, loss_test: 0.005734
time: 0.24605488777160645
time: 2.2044930458068848
[1, 6580] loss_train: 0.008418, loss_test: 0.005737
time: 0.2630579471588135
time: 2.255504846572876
[1, 6581] loss_train: 0.003088, loss_test: 0.005738
time: 0.24505400657653809
time: 2.2590177059173584
[1, 6582] loss_train: 0.001294, loss_test: 0.005736
time: 0.2490556240081787
time: 2.2244973182678223
[1, 6583] loss_train: 0.003695, loss_test: 0.005736
time: 0.24605464935302734
time: 2.2435123920440674
[1, 6584] loss_train: 0.005521, loss_test: 0.005739
time: 0.24605417251586914
time: 2.219496965408325
[1, 6585] loss_train: 0.007720, loss_test: 0.005739
time: 0.24605488777160645
time: 2.2105114459991455
[1, 6586] loss_train: 0.010866, loss_test: 0.005743
time: 0.24205350875854492
time: 2.220496416091919
[1, 6587] loss_train: 0.006593, loss_test: 0.005751
time: 0.24405407905578613
time: 2.227498769760132
[1, 6588] loss_train: 0.002319, loss_test: 0.005762
time: 0.24405384063720703
time: 2.202493667602539
[1, 6589] loss_train: 0.005888, loss_test: 0.005771
time: 0.2440803050994873
time: 2.2105283737182617
[1, 6590] loss_train: 0.010423, loss_test: 0.005774
time: 0.2560563087463379
time: 2.2715084552764893
[1, 6591] loss_train: 0.010613, loss_test: 0.005763
time: 0.2450542449951172
time: 2.2495248317718506
[1, 6592] loss_train: 0.005145, loss_test: 0.005755
time: 0.24506640434265137
time: 2.2405009269714355
[1, 6593] loss_train: 0.003963, loss_test: 0.005753
time: 0.25305604934692383
time: 2.2480084896087646
[1, 6594] loss_train: 0.005242, loss_test: 0.005750
time: 0.2440805435180664
time: 2.204496145248413
[1, 6595] loss_train: 0.003031, loss_test: 0.005748
time: 0.24405384063720703
time: 2.256349802017212
[1, 6596] loss_train: 0.016727, loss_test: 0.005752
time: 0.24305391311645508
time: 2.1894917488098145
[1, 6597] loss_train: 0.003183, loss_test: 0.005761
time: 0.24505400657653809
time: 2.203493356704712
[1, 6598] loss_train: 0.007206, loss_test: 0.005768
time: 0.24405455589294434
time: 2.259505033493042
[1, 6599] loss_train: 0.003414, loss_test: 0.005778
time: 0.2490558624267578
time: 2.22200345993042
[1, 6600] loss_train: 0.004300, loss_test: 0.005790
time: 0.25705647468566895
time: 2.2244977951049805
[1, 6601] loss_train: 0.007513, loss_test: 0.005793
time: 0.25205564498901367
time: 2.196016311645508
[1, 6602] loss_train: 0.004680, loss_test: 0.005795
time: 0.24405384063720703
time: 2.2144956588745117
[1, 6603] loss_train: 0.001594, loss_test: 0.005785
time: 0.24605464935302734
time: 2.2264981269836426
[1, 6604] loss_train: 0.005996, loss_test: 0.005776
time: 0.2450566291809082
time: 2.210996627807617
[1, 6605] loss_train: 0.006693, loss_test: 0.005769
time: 0.24406886100769043
time: 2.2324984073638916
[1, 6606] loss_train: 0.011415, loss_test: 0.005764
time: 0.24607133865356445
time: 2.1974916458129883
[1, 6607] loss_train: 0.008047, loss_test: 0.005760
time: 0.24405384063720703
time: 2.2184958457946777
[1, 6608] loss_train: 0.006751, loss_test: 0.005758
time: 0.24306631088256836
time: 2.205493450164795
[1, 6609] loss_train: 0.011561, loss_test: 0.005761
time: 0.24405336380004883
time: 2.205503225326538
[1, 6610] loss_train: 0.007063, loss_test: 0.005769
time: 0.25505661964416504
time: 2.243502140045166
[1, 6611] loss_train: 0.007540, loss_test: 0.005779
time: 0.24205350875854492
time: 2.2405035495758057
[1, 6612] loss_train: 0.000712, loss_test: 0.005783
time: 0.24405384063720703
time: 2.208494186401367
[1, 6613] loss_train: 0.009217, loss_test: 0.005786
time: 0.24405384063720703
time: 2.2224974632263184
[1, 6614] loss_train: 0.011153, loss_test: 0.005793
time: 0.2530558109283447
time: 2.222017765045166
[1, 6615] loss_train: 0.003177, loss_test: 0.005774
time: 0.2460641860961914
time: 2.237515687942505
[1, 6616] loss_train: 0.003504, loss_test: 0.005736
time: 0.24905610084533691
time: 2.2244973182678223
[1, 6617] loss_train: 0.008995, loss_test: 0.005715
time: 0.24606037139892578
time: 2.2395005226135254
[1, 6618] loss_train: 0.007168, loss_test: 0.005707
time: 0.2490558624267578
time: 2.237499475479126
[1, 6619] loss_train: 0.003662, loss_test: 0.005715
time: 0.24505376815795898
time: 2.227057933807373
[1, 6620] loss_train: 0.014105, loss_test: 0.005725
time: 0.25705671310424805
time: 2.2655069828033447
[1, 6621] loss_train: 0.007471, loss_test: 0.005727
time: 0.24908161163330078
time: 2.2264974117279053
[1, 6622] loss_train: 0.005320, loss_test: 0.005728
time: 0.2450542449951172
time: 2.2204973697662354
[1, 6623] loss_train: 0.019689, loss_test: 0.005709
time: 0.24405431747436523
time: 2.250502824783325
[1, 6624] loss_train: 0.004506, loss_test: 0.005700
time: 0.24505400657653809
time: 2.234499931335449
[1, 6625] loss_train: 0.001720, loss_test: 0.005698
time: 0.2450542449951172
time: 2.2258877754211426
[1, 6626] loss_train: 0.005225, loss_test: 0.005699
time: 0.24405431747436523
time: 2.231523275375366
[1, 6627] loss_train: 0.000911, loss_test: 0.005701
time: 0.24606800079345703
time: 2.2144956588745117
[1, 6628] loss_train: 0.011536, loss_test: 0.005704
time: 0.24405837059020996
time: 2.2254979610443115
[1, 6629] loss_train: 0.005653, loss_test: 0.005709
time: 0.24408769607543945
time: 2.235537052154541
[1, 6630] loss_train: 0.012222, loss_test: 0.005714
time: 0.25705766677856445
time: 2.2525057792663574
[1, 6631] loss_train: 0.010182, loss_test: 0.005714
time: 0.2470543384552002
time: 2.2224977016448975
[1, 6632] loss_train: 0.010340, loss_test: 0.005715
time: 0.24405479431152344
time: 2.2034921646118164
[1, 6633] loss_train: 0.007012, loss_test: 0.005714
time: 0.24405384063720703
time: 2.21049427986145
[1, 6634] loss_train: 0.004469, loss_test: 0.005711
time: 0.24405360221862793
time: 2.2104969024658203
[1, 6635] loss_train: 0.003581, loss_test: 0.005711
time: 0.24405407905578613
time: 2.241502046585083
[1, 6636] loss_train: 0.006710, loss_test: 0.005718
time: 0.2450544834136963
time: 2.1985034942626953
[1, 6637] loss_train: 0.002059, loss_test: 0.005735
time: 0.24805474281311035
time: 2.221195697784424
[1, 6638] loss_train: 0.001577, loss_test: 0.005756
time: 0.25005578994750977
time: 2.2415316104888916
[1, 6639] loss_train: 0.007635, loss_test: 0.005770
time: 0.2470557689666748
time: 2.233499526977539
[1, 6640] loss_train: 0.003236, loss_test: 0.005790
time: 0.25505685806274414
time: 2.2465028762817383
[1, 6641] loss_train: 0.004575, loss_test: 0.005813
time: 0.25005578994750977
time: 2.233499526977539
[1, 6642] loss_train: 0.008431, loss_test: 0.005829
time: 0.24405407905578613
time: 2.221496820449829
[1, 6643] loss_train: 0.016408, loss_test: 0.005777
time: 0.24405455589294434
time: 2.23349928855896
[1, 6644] loss_train: 0.006501, loss_test: 0.005741
time: 0.24405384063720703
time: 2.2234978675842285
[1, 6645] loss_train: 0.010795, loss_test: 0.005723
time: 0.24605417251586914
time: 2.21650767326355
[1, 6646] loss_train: 0.005862, loss_test: 0.005721
time: 0.2530550956726074
time: 2.2955129146575928
[1, 6647] loss_train: 0.003491, loss_test: 0.005730
time: 0.24505352973937988
time: 2.2165112495422363
[1, 6648] loss_train: 0.002332, loss_test: 0.005742
time: 0.2490549087524414
time: 2.223505735397339
[1, 6649] loss_train: 0.008877, loss_test: 0.005744
time: 0.24405360221862793
time: 2.208509683609009
[1, 6650] loss_train: 0.005167, loss_test: 0.005744
time: 0.2580857276916504
time: 2.243502378463745
[1, 6651] loss_train: 0.007020, loss_test: 0.005738
time: 0.24405431747436523
time: 2.256504535675049
[1, 6652] loss_train: 0.009356, loss_test: 0.005733
time: 0.2450549602508545
time: 2.2094943523406982
[1, 6653] loss_train: 0.007203, loss_test: 0.005732
time: 0.243058443069458
time: 2.232499837875366
[1, 6654] loss_train: 0.001935, loss_test: 0.005726
time: 0.24505352973937988
time: 2.228498935699463
[1, 6655] loss_train: 0.002535, loss_test: 0.005726
time: 0.24506783485412598
time: 2.23349928855896
[1, 6656] loss_train: 0.003256, loss_test: 0.005731
time: 0.2450547218322754
time: 2.247502088546753
[1, 6657] loss_train: 0.006319, loss_test: 0.005742
time: 0.24305367469787598
time: 2.2355003356933594
[1, 6658] loss_train: 0.005003, loss_test: 0.005759
time: 0.24605417251586914
time: 2.255946636199951
[1, 6659] loss_train: 0.012750, loss_test: 0.005774
time: 0.24405527114868164
time: 2.2184956073760986
[1, 6660] loss_train: 0.005485, loss_test: 0.005784
time: 0.2560567855834961
time: 2.2865138053894043
[1, 6661] loss_train: 0.006277, loss_test: 0.005793
time: 0.2450544834136963
time: 2.221496820449829
[1, 6662] loss_train: 0.008369, loss_test: 0.005800
time: 0.2490558624267578
time: 2.2405006885528564
[1, 6663] loss_train: 0.005615, loss_test: 0.005804
time: 0.2450563907623291
time: 2.209494113922119
[1, 6664] loss_train: 0.003817, loss_test: 0.005807
time: 0.2490558624267578
time: 2.2284977436065674
[1, 6665] loss_train: 0.007518, loss_test: 0.005807
time: 0.24606823921203613
time: 2.2335145473480225
[1, 6666] loss_train: 0.008476, loss_test: 0.005787
time: 0.2490558624267578
time: 2.2324986457824707
[1, 6667] loss_train: 0.009485, loss_test: 0.005759
time: 0.24520206451416016
time: 2.231499433517456
[1, 6668] loss_train: 0.006912, loss_test: 0.005747
time: 0.25005531311035156
time: 2.2405011653900146
[1, 6669] loss_train: 0.006145, loss_test: 0.005745
time: 0.2440791130065918
time: 2.1984918117523193
[1, 6670] loss_train: 0.005751, loss_test: 0.005750
time: 0.2560567855834961
time: 2.275022029876709
[1, 6671] loss_train: 0.008575, loss_test: 0.005752
time: 0.2450542449951172
time: 2.2405014038085938
[1, 6672] loss_train: 0.011740, loss_test: 0.005753
time: 0.24305462837219238
time: 2.2490053176879883
[1, 6673] loss_train: 0.006059, loss_test: 0.005747
time: 0.2450542449951172
time: 2.2110142707824707
[1, 6674] loss_train: 0.003865, loss_test: 0.005737
time: 0.24405431747436523
time: 2.2532527446746826
[1, 6675] loss_train: 0.005113, loss_test: 0.005731
time: 0.24405384063720703
time: 2.2525038719177246
[1, 6676] loss_train: 0.003106, loss_test: 0.005733
time: 0.24405407905578613
time: 2.2264983654022217
[1, 6677] loss_train: 0.004831, loss_test: 0.005738
time: 0.2450542449951172
time: 2.223013401031494
[1, 6678] loss_train: 0.010934, loss_test: 0.005741
time: 0.25005507469177246
time: 2.2355003356933594
[1, 6679] loss_train: 0.001898, loss_test: 0.005745
time: 0.24414610862731934
time: 2.238609552383423
[1, 6680] loss_train: 0.003052, loss_test: 0.005751
time: 0.25705671310424805
time: 2.282510757446289
[1, 6681] loss_train: 0.010417, loss_test: 0.005750
time: 0.24605488777160645
time: 2.2250137329101562
[1, 6682] loss_train: 0.006831, loss_test: 0.005747
time: 0.24406790733337402
time: 2.2365007400512695
[1, 6683] loss_train: 0.002190, loss_test: 0.005744
time: 0.25005483627319336
time: 2.2244999408721924
[1, 6684] loss_train: 0.009159, loss_test: 0.005742
time: 0.24405455589294434
time: 2.2174956798553467
[1, 6685] loss_train: 0.004588, loss_test: 0.005739
time: 0.24405360221862793
time: 2.2195117473602295
[1, 6686] loss_train: 0.001382, loss_test: 0.005739
time: 0.24505615234375
time: 2.243518114089966
[1, 6687] loss_train: 0.007390, loss_test: 0.005739
time: 0.24306678771972656
time: 2.2134947776794434
[1, 6688] loss_train: 0.004490, loss_test: 0.005738
time: 0.24605512619018555
time: 2.2525036334991455
[1, 6689] loss_train: 0.018001, loss_test: 0.005728
time: 0.24205470085144043
time: 2.212466239929199
[1, 6690] loss_train: 0.003859, loss_test: 0.005724
time: 0.2580571174621582
time: 2.2495017051696777
[1, 6691] loss_train: 0.004256, loss_test: 0.005723
time: 0.24805545806884766
time: 2.2185146808624268
[1, 6692] loss_train: 0.011023, loss_test: 0.005719
time: 0.2450547218322754
time: 2.2415013313293457
[1, 6693] loss_train: 0.007377, loss_test: 0.005715
time: 0.2490551471710205
time: 2.2415013313293457
[1, 6694] loss_train: 0.009262, loss_test: 0.005723
time: 0.24505400657653809
time: 2.2080001831054688
[1, 6695] loss_train: 0.012052, loss_test: 0.005738
time: 0.25006103515625
time: 2.211498737335205
[1, 6696] loss_train: 0.003340, loss_test: 0.005755
time: 0.24408292770385742
time: 2.20849609375
[1, 6697] loss_train: 0.007670, loss_test: 0.005773
time: 0.24305343627929688
time: 2.228498697280884
[1, 6698] loss_train: 0.003313, loss_test: 0.005780
time: 0.24405622482299805
time: 2.229499340057373
[1, 6699] loss_train: 0.003912, loss_test: 0.005765
time: 0.24405431747436523
time: 2.2365002632141113
[1, 6700] loss_train: 0.006018, loss_test: 0.005742
time: 0.25507450103759766
time: 2.2765085697174072
[1, 6701] loss_train: 0.008028, loss_test: 0.005719
time: 0.2450542449951172
time: 2.232511281967163
[1, 6702] loss_train: 0.004045, loss_test: 0.005704
time: 0.2450551986694336
time: 2.2385001182556152
[1, 6703] loss_train: 0.005919, loss_test: 0.005702
time: 0.24305391311645508
time: 2.2154955863952637
[1, 6704] loss_train: 0.010751, loss_test: 0.005712
time: 0.24405384063720703
time: 2.221497058868408
[1, 6705] loss_train: 0.002998, loss_test: 0.005732
time: 0.24805569648742676
time: 2.235501527786255
[1, 6706] loss_train: 0.007635, loss_test: 0.005751
time: 0.24305367469787598
time: 2.219496965408325
[1, 6707] loss_train: 0.007955, loss_test: 0.005761
time: 0.24305343627929688
time: 2.238013744354248
[1, 6708] loss_train: 0.003779, loss_test: 0.005772
time: 0.24405431747436523
time: 2.1964914798736572
[1, 6709] loss_train: 0.005182, loss_test: 0.005780
time: 0.2450547218322754
time: 2.2294983863830566
[1, 6710] loss_train: 0.008735, loss_test: 0.005774
time: 0.25606799125671387
time: 2.234499931335449
[1, 6711] loss_train: 0.014273, loss_test: 0.005763
time: 0.2450549602508545
time: 2.2265090942382812
[1, 6712] loss_train: 0.006288, loss_test: 0.005745
time: 0.25206947326660156
time: 2.2154951095581055
[1, 6713] loss_train: 0.006073, loss_test: 0.005732
time: 0.24405407905578613
time: 2.249521493911743
[1, 6714] loss_train: 0.003943, loss_test: 0.005725
time: 0.2510550022125244
time: 2.208495855331421
[1, 6715] loss_train: 0.010524, loss_test: 0.005715
time: 0.24305367469787598
time: 2.2044925689697266
[1, 6716] loss_train: 0.010195, loss_test: 0.005711
time: 0.24405384063720703
time: 2.2314987182617188
[1, 6717] loss_train: 0.010260, loss_test: 0.005715
time: 0.24405455589294434
time: 2.218499183654785
[1, 6718] loss_train: 0.001048, loss_test: 0.005724
time: 0.24305367469787598
time: 2.215496063232422
[1, 6719] loss_train: 0.013320, loss_test: 0.005738
time: 0.2490551471710205
time: 2.23502254486084
[1, 6720] loss_train: 0.003986, loss_test: 0.005752
time: 0.256056547164917
time: 2.252502918243408
[1, 6721] loss_train: 0.008519, loss_test: 0.005767
time: 0.24405455589294434
time: 2.2430434226989746
[1, 6722] loss_train: 0.009011, loss_test: 0.005778
time: 0.2435595989227295
time: 2.2244982719421387
[1, 6723] loss_train: 0.003762, loss_test: 0.005784
time: 0.24605369567871094
time: 2.2254981994628906
[1, 6724] loss_train: 0.005629, loss_test: 0.005791
time: 0.24406671524047852
time: 2.2355003356933594
[1, 6725] loss_train: 0.006779, loss_test: 0.005799
time: 0.24405479431152344
time: 2.2820651531219482
[1, 6726] loss_train: 0.009487, loss_test: 0.005802
time: 0.24605464935302734
time: 2.2435038089752197
[1, 6727] loss_train: 0.011137, loss_test: 0.005799
time: 0.24305391311645508
time: 2.2375011444091797
[1, 6728] loss_train: 0.005548, loss_test: 0.005795
time: 0.24405360221862793
time: 2.242504596710205
[1, 6729] loss_train: 0.007622, loss_test: 0.005792
time: 0.24406838417053223
time: 2.1994922161102295
[1, 6730] loss_train: 0.003737, loss_test: 0.005793
time: 0.25705814361572266
time: 2.2495036125183105
[1, 6731] loss_train: 0.005743, loss_test: 0.005795
time: 0.24405360221862793
time: 2.203495502471924
[1, 6732] loss_train: 0.014735, loss_test: 0.005784
time: 0.2470548152923584
time: 2.2034947872161865
[1, 6733] loss_train: 0.005321, loss_test: 0.005770
time: 0.24805593490600586
time: 2.2264976501464844
[1, 6734] loss_train: 0.006491, loss_test: 0.005759
time: 0.2450549602508545
time: 2.22149658203125
[1, 6735] loss_train: 0.008093, loss_test: 0.005748
time: 0.2490549087524414
time: 2.246501922607422
[1, 6736] loss_train: 0.003976, loss_test: 0.005740
time: 0.25005650520324707
time: 2.2403459548950195
[1, 6737] loss_train: 0.001334, loss_test: 0.005736
time: 0.24805474281311035
time: 2.2094969749450684
[1, 6738] loss_train: 0.005777, loss_test: 0.005734
time: 0.24305415153503418
time: 2.2243642807006836
[1, 6739] loss_train: 0.006066, loss_test: 0.005732
time: 0.24609136581420898
time: 2.2365026473999023
[1, 6740] loss_train: 0.008397, loss_test: 0.005732
time: 0.2560572624206543
time: 2.286511182785034
[1, 6741] loss_train: 0.011436, loss_test: 0.005735
time: 0.2470550537109375
time: 2.2785093784332275
[1, 6742] loss_train: 0.008311, loss_test: 0.005740
time: 0.24805450439453125
time: 2.243504285812378
[1, 6743] loss_train: 0.002911, loss_test: 0.005748
time: 0.2470550537109375
time: 2.245502233505249
[1, 6744] loss_train: 0.015005, loss_test: 0.005755
time: 0.24405407905578613
time: 2.205493211746216
[1, 6745] loss_train: 0.008001, loss_test: 0.005763
time: 0.2450542449951172
time: 2.2265076637268066
[1, 6746] loss_train: 0.005703, loss_test: 0.005768
time: 0.24305367469787598
time: 2.2104949951171875
[1, 6747] loss_train: 0.012148, loss_test: 0.005770
time: 0.24305367469787598
time: 2.2245125770568848
[1, 6748] loss_train: 0.004388, loss_test: 0.005773
time: 0.24505376815795898
time: 2.2985148429870605
[1, 6749] loss_train: 0.005647, loss_test: 0.005772
time: 0.2650580406188965
time: 2.217496395111084
[1, 6750] loss_train: 0.006697, loss_test: 0.005764
time: 0.25505709648132324
time: 2.2665064334869385
[1, 6751] loss_train: 0.003715, loss_test: 0.005742
time: 0.2450549602508545
time: 2.2565042972564697
[1, 6752] loss_train: 0.008382, loss_test: 0.005719
time: 0.24505400657653809
time: 2.2365007400512695
[1, 6753] loss_train: 0.008145, loss_test: 0.005710
time: 0.24506163597106934
time: 2.249502658843994
[1, 6754] loss_train: 0.013858, loss_test: 0.005717
time: 0.24305391311645508
time: 2.195491313934326
[1, 6755] loss_train: 0.005477, loss_test: 0.005730
time: 0.2490558624267578
time: 2.221497058868408
[1, 6756] loss_train: 0.001119, loss_test: 0.005750
time: 0.25005507469177246
time: 2.2410037517547607
[1, 6757] loss_train: 0.013765, loss_test: 0.005753
time: 0.24305438995361328
time: 2.2094945907592773
[1, 6758] loss_train: 0.006217, loss_test: 0.005753
time: 0.2450542449951172
time: 2.194502353668213
[1, 6759] loss_train: 0.005459, loss_test: 0.005753
time: 0.24405479431152344
time: 2.21049427986145
[1, 6760] loss_train: 0.009095, loss_test: 0.005752
time: 0.2560608386993408
time: 2.2444584369659424
[1, 6761] loss_train: 0.003585, loss_test: 0.005744
time: 0.24405360221862793
time: 2.2389438152313232
[1, 6762] loss_train: 0.011414, loss_test: 0.005737
time: 0.2510554790496826
time: 2.2455029487609863
[1, 6763] loss_train: 0.004950, loss_test: 0.005731
time: 0.24405431747436523
time: 2.210494041442871
[1, 6764] loss_train: 0.000986, loss_test: 0.005726
time: 0.25005578994750977
time: 2.2134952545166016
[1, 6765] loss_train: 0.008536, loss_test: 0.005723
time: 0.24405455589294434
time: 2.2244973182678223
[1, 6766] loss_train: 0.014001, loss_test: 0.005722
time: 0.24605536460876465
time: 2.214498281478882
[1, 6767] loss_train: 0.006337, loss_test: 0.005723
time: 0.24406647682189941
time: 2.2294986248016357
[1, 6768] loss_train: 0.003867, loss_test: 0.005727
time: 0.24305367469787598
time: 2.2360119819641113
[1, 6769] loss_train: 0.003447, loss_test: 0.005734
time: 0.24505376815795898
time: 2.1964943408966064
[1, 6770] loss_train: 0.002828, loss_test: 0.005742
time: 0.256056547164917
time: 2.2625057697296143
[1, 6771] loss_train: 0.005167, loss_test: 0.005747
time: 0.24406695365905762
time: 2.261507034301758
[1, 6772] loss_train: 0.004420, loss_test: 0.005757
time: 0.24605441093444824
time: 2.2234976291656494
[1, 6773] loss_train: 0.004005, loss_test: 0.005766
time: 0.24505400657653809
time: 2.232499599456787
[1, 6774] loss_train: 0.004683, loss_test: 0.005774
time: 0.24305415153503418
time: 2.2252302169799805
[1, 6775] loss_train: 0.006168, loss_test: 0.005778
time: 0.24305319786071777
time: 2.2385013103485107
[1, 6776] loss_train: 0.014333, loss_test: 0.005769
time: 0.24605464935302734
time: 2.2400050163269043
[1, 6777] loss_train: 0.007622, loss_test: 0.005769
time: 0.24305415153503418
time: 2.210494041442871
[1, 6778] loss_train: 0.008181, loss_test: 0.005774
time: 0.24506831169128418
time: 2.2170276641845703
[1, 6779] loss_train: 0.014789, loss_test: 0.005783
time: 0.24405407905578613
time: 2.1974921226501465
[1, 6780] loss_train: 0.003636, loss_test: 0.005798
time: 0.25705647468566895
time: 2.230025291442871
[1, 6781] loss_train: 0.014612, loss_test: 0.005824
time: 0.25005507469177246
time: 2.2104973793029785
[1, 6782] loss_train: 0.006740, loss_test: 0.005843
time: 0.2470552921295166
time: 2.213515281677246
[1, 6783] loss_train: 0.003907, loss_test: 0.005842
time: 0.25005578994750977
time: 2.217495918273926
[1, 6784] loss_train: 0.004112, loss_test: 0.005836
time: 0.24405360221862793
time: 2.2365007400512695
[1, 6785] loss_train: 0.002137, loss_test: 0.005819
time: 0.24605441093444824
time: 2.2355005741119385
[1, 6786] loss_train: 0.003132, loss_test: 0.005798
time: 0.24405336380004883
time: 2.252521514892578
[1, 6787] loss_train: 0.006409, loss_test: 0.005776
time: 0.24405360221862793
time: 2.2224977016448975
[1, 6788] loss_train: 0.006937, loss_test: 0.005755
time: 0.2450549602508545
time: 2.262009382247925
[1, 6789] loss_train: 0.001585, loss_test: 0.005745
time: 0.24605488777160645
time: 2.256504774093628
[1, 6790] loss_train: 0.006845, loss_test: 0.005745
time: 0.25505733489990234
time: 2.2445220947265625
[1, 6791] loss_train: 0.003745, loss_test: 0.005753
time: 0.24305415153503418
time: 2.2665069103240967
[1, 6792] loss_train: 0.004359, loss_test: 0.005772
time: 0.24605083465576172
time: 2.2325081825256348
[1, 6793] loss_train: 0.005535, loss_test: 0.005798
time: 0.2450544834136963
time: 2.2395007610321045
[1, 6794] loss_train: 0.005171, loss_test: 0.005825
time: 0.2450542449951172
time: 2.2154955863952637
[1, 6795] loss_train: 0.006295, loss_test: 0.005852
time: 0.2450544834136963
time: 2.2114949226379395
[1, 6796] loss_train: 0.003342, loss_test: 0.005877
time: 0.24305415153503418
time: 2.2274980545043945
[1, 6797] loss_train: 0.008826, loss_test: 0.005893
time: 0.24605464935302734
time: 2.2254974842071533
[1, 6798] loss_train: 0.009357, loss_test: 0.005901
time: 0.24358868598937988
time: 2.2144954204559326
[1, 6799] loss_train: 0.005634, loss_test: 0.005898
time: 0.24405455589294434
time: 2.2274980545043945
[1, 6800] loss_train: 0.008667, loss_test: 0.005905
time: 0.25707077980041504
time: 2.2635140419006348
[1, 6801] loss_train: 0.001384, loss_test: 0.005909
time: 0.24344944953918457
time: 2.218018054962158
[1, 6802] loss_train: 0.007055, loss_test: 0.005902
time: 0.24505400657653809
time: 2.210392475128174
[1, 6803] loss_train: 0.002940, loss_test: 0.005894
time: 0.24505400657653809
time: 2.2154953479766846
[1, 6804] loss_train: 0.001167, loss_test: 0.005889
time: 0.2490692138671875
time: 2.226498603820801
[1, 6805] loss_train: 0.003350, loss_test: 0.005874
time: 0.24406838417053223
time: 2.221496105194092
[1, 6806] loss_train: 0.005984, loss_test: 0.005838
time: 0.2490549087524414
time: 2.229508876800537
[1, 6807] loss_train: 0.007580, loss_test: 0.005792
time: 0.24605512619018555
time: 2.2134952545166016
[1, 6808] loss_train: 0.004550, loss_test: 0.005755
time: 0.24506640434265137
time: 2.234215259552002
[1, 6809] loss_train: 0.014107, loss_test: 0.005732
time: 0.2450549602508545
time: 2.2274980545043945
[1, 6810] loss_train: 0.005088, loss_test: 0.005722
time: 0.2540557384490967
time: 2.2709381580352783
[1, 6811] loss_train: 0.005352, loss_test: 0.005720
time: 0.2450547218322754
time: 2.2395005226135254
[1, 6812] loss_train: 0.010018, loss_test: 0.005722
time: 0.24405431747436523
time: 2.2415013313293457
[1, 6813] loss_train: 0.006891, loss_test: 0.005726
time: 0.24405431747436523
time: 2.212494134902954
[1, 6814] loss_train: 0.007645, loss_test: 0.005729
time: 0.24506139755249023
time: 2.227497100830078
[1, 6815] loss_train: 0.003233, loss_test: 0.005727
time: 0.24405455589294434
time: 2.202255964279175
[1, 6816] loss_train: 0.008331, loss_test: 0.005726
time: 0.24505400657653809
time: 2.2134954929351807
[1, 6817] loss_train: 0.006981, loss_test: 0.005728
time: 0.24305415153503418
time: 2.190516471862793
[1, 6818] loss_train: 0.001186, loss_test: 0.005731
time: 0.24405360221862793
time: 2.2084944248199463
[1, 6819] loss_train: 0.007842, loss_test: 0.005737
time: 0.24305367469787598
time: 2.2147786617279053
[1, 6820] loss_train: 0.020828, loss_test: 0.005747
time: 0.2540559768676758
time: 2.2485055923461914
[1, 6821] loss_train: 0.003605, loss_test: 0.005762
time: 0.25005626678466797
time: 2.2645061016082764
[1, 6822] loss_train: 0.003411, loss_test: 0.005773
time: 0.24405384063720703
time: 2.218498706817627
[1, 6823] loss_train: 0.008903, loss_test: 0.005784
time: 0.2490549087524414
time: 2.2265007495880127
[1, 6824] loss_train: 0.009298, loss_test: 0.005766
time: 0.24607563018798828
time: 2.2155117988586426
[1, 6825] loss_train: 0.014853, loss_test: 0.005752
time: 0.25005602836608887
time: 2.2194976806640625
[1, 6826] loss_train: 0.015084, loss_test: 0.005738
time: 0.24805521965026855
time: 2.229583501815796
[1, 6827] loss_train: 0.004179, loss_test: 0.005730
time: 0.24605488777160645
time: 2.1974918842315674
[1, 6828] loss_train: 0.006922, loss_test: 0.005723
time: 0.24583959579467773
time: 2.219496726989746
[1, 6829] loss_train: 0.003273, loss_test: 0.005721
time: 0.24405407905578613
time: 2.2355003356933594
[1, 6830] loss_train: 0.005118, loss_test: 0.005723
time: 0.256056547164917
time: 2.2595131397247314
[1, 6831] loss_train: 0.004733, loss_test: 0.005722
time: 0.24306678771972656
time: 2.1995041370391846
[1, 6832] loss_train: 0.006939, loss_test: 0.005724
time: 0.24405431747436523
time: 2.2385005950927734
[1, 6833] loss_train: 0.002114, loss_test: 0.005724
time: 0.24305462837219238
time: 2.2214972972869873
[1, 6834] loss_train: 0.010598, loss_test: 0.005731
time: 0.24405360221862793
time: 2.2285096645355225
[1, 6835] loss_train: 0.007323, loss_test: 0.005741
time: 0.24305438995361328
time: 2.2535133361816406
[1, 6836] loss_train: 0.004512, loss_test: 0.005756
time: 0.2470541000366211
time: 2.2084946632385254
[1, 6837] loss_train: 0.001148, loss_test: 0.005777
time: 0.24405407905578613
time: 2.2145183086395264
[1, 6838] loss_train: 0.014722, loss_test: 0.005776
time: 0.2450542449951172
time: 2.2347564697265625
[1, 6839] loss_train: 0.010633, loss_test: 0.005770
time: 0.24405336380004883
time: 2.232691526412964
[1, 6840] loss_train: 0.003898, loss_test: 0.005767
time: 0.25505900382995605
time: 2.2495028972625732
[1, 6841] loss_train: 0.001329, loss_test: 0.005767
time: 0.25005507469177246
time: 2.2234973907470703
[1, 6842] loss_train: 0.007455, loss_test: 0.005768
time: 0.24706768989562988
time: 2.215496301651001
[1, 6843] loss_train: 0.008150, loss_test: 0.005761
time: 0.2470543384552002
time: 2.2104973793029785
[1, 6844] loss_train: 0.006688, loss_test: 0.005757
time: 0.24805545806884766
time: 2.2515029907226562
[1, 6845] loss_train: 0.005708, loss_test: 0.005751
time: 0.24405384063720703
time: 2.2370126247406006
[1, 6846] loss_train: 0.010295, loss_test: 0.005746
time: 0.24605488777160645
time: 2.2375006675720215
[1, 6847] loss_train: 0.003429, loss_test: 0.005749
time: 0.2450542449951172
time: 2.204998254776001
[1, 6848] loss_train: 0.006593, loss_test: 0.005754
time: 0.24305415153503418
time: 2.22249698638916
[1, 6849] loss_train: 0.002273, loss_test: 0.005754
time: 0.24405479431152344
time: 2.2275161743164062
[1, 6850] loss_train: 0.002990, loss_test: 0.005756
time: 0.25505709648132324
time: 2.2665064334869385
[1, 6851] loss_train: 0.005506, loss_test: 0.005753
time: 0.24305415153503418
time: 2.2244973182678223
[1, 6852] loss_train: 0.002990, loss_test: 0.005751
time: 0.24305343627929688
time: 2.2134957313537598
[1, 6853] loss_train: 0.003271, loss_test: 0.005746
time: 0.24405336380004883
time: 2.2124955654144287
[1, 6854] loss_train: 0.004947, loss_test: 0.005742
time: 0.24506711959838867
time: 2.2314999103546143
[1, 6855] loss_train: 0.009851, loss_test: 0.005738
time: 0.24305319786071777
time: 2.2290022373199463
[1, 6856] loss_train: 0.006458, loss_test: 0.005734
time: 0.24305391311645508
time: 2.2385010719299316
[1, 6857] loss_train: 0.004939, loss_test: 0.005728
time: 0.2450542449951172
time: 2.22249698638916
[1, 6858] loss_train: 0.012271, loss_test: 0.005728
time: 0.24405479431152344
time: 2.243501663208008
[1, 6859] loss_train: 0.003732, loss_test: 0.005732
time: 0.24305343627929688
time: 2.242511510848999
[1, 6860] loss_train: 0.002429, loss_test: 0.005737
time: 0.25905728340148926
time: 2.248502731323242
[1, 6861] loss_train: 0.006712, loss_test: 0.005738
time: 0.24505400657653809
time: 2.2505133152008057
[1, 6862] loss_train: 0.003695, loss_test: 0.005736
time: 0.24305415153503418
time: 2.2695071697235107
[1, 6863] loss_train: 0.008088, loss_test: 0.005730
time: 0.24605441093444824
time: 2.220496892929077
[1, 6864] loss_train: 0.004511, loss_test: 0.005721
time: 0.24405360221862793
time: 2.27150821685791
[1, 6865] loss_train: 0.011654, loss_test: 0.005713
time: 0.2560570240020752
time: 2.2144949436187744
[1, 6866] loss_train: 0.006843, loss_test: 0.005718
time: 0.24405360221862793
time: 2.204500675201416
[1, 6867] loss_train: 0.001279, loss_test: 0.005739
time: 0.25005507469177246
time: 2.229498863220215
[1, 6868] loss_train: 0.002700, loss_test: 0.005770
time: 0.24505305290222168
time: 2.222001075744629
[1, 6869] loss_train: 0.008741, loss_test: 0.005810
time: 0.24805545806884766
time: 2.2364113330841064
[1, 6870] loss_train: 0.003480, loss_test: 0.005827
time: 0.26105833053588867
time: 2.2465035915374756
[1, 6871] loss_train: 0.007660, loss_test: 0.005817
time: 0.25005483627319336
time: 2.264509439468384
[1, 6872] loss_train: 0.003011, loss_test: 0.005796
time: 0.2450549602508545
time: 2.2525036334991455
[1, 6873] loss_train: 0.005899, loss_test: 0.005782
time: 0.252056360244751
time: 2.2284984588623047
[1, 6874] loss_train: 0.011292, loss_test: 0.005764
time: 0.2450544834136963
time: 2.2435014247894287
[1, 6875] loss_train: 0.007445, loss_test: 0.005751
time: 0.2470548152923584
time: 2.2304985523223877
[1, 6876] loss_train: 0.002034, loss_test: 0.005745
time: 0.24305272102355957
time: 2.213017463684082
[1, 6877] loss_train: 0.009159, loss_test: 0.005737
time: 0.24405503273010254
time: 2.2304975986480713
[1, 6878] loss_train: 0.009906, loss_test: 0.005735
time: 0.24305438995361328
time: 2.2340102195739746
[1, 6879] loss_train: 0.004398, loss_test: 0.005734
time: 0.24305391311645508
time: 2.222508430480957
[1, 6880] loss_train: 0.013348, loss_test: 0.005738
time: 0.25705766677856445
time: 2.2695181369781494
[1, 6881] loss_train: 0.012577, loss_test: 0.005748
time: 0.24405407905578613
time: 2.2254979610443115
[1, 6882] loss_train: 0.009726, loss_test: 0.005756
time: 0.24405431747436523
time: 2.234498977661133
[1, 6883] loss_train: 0.010929, loss_test: 0.005758
time: 0.24405479431152344
time: 2.2004926204681396
[1, 6884] loss_train: 0.015676, loss_test: 0.005765
time: 0.24405360221862793
time: 2.239501476287842
[1, 6885] loss_train: 0.006184, loss_test: 0.005765
time: 0.24305415153503418
time: 2.247502326965332
[1, 6886] loss_train: 0.003535, loss_test: 0.005742
time: 0.24405384063720703
time: 2.207542657852173
[1, 6887] loss_train: 0.007384, loss_test: 0.005722
time: 0.24805498123168945
time: 2.230499267578125
[1, 6888] loss_train: 0.005534, loss_test: 0.005709
time: 0.24305391311645508
time: 2.221498966217041
[1, 6889] loss_train: 0.009832, loss_test: 0.005706
time: 0.24505376815795898
time: 2.2365055084228516
[1, 6890] loss_train: 0.005992, loss_test: 0.005712
time: 0.2560560703277588
time: 2.253504514694214
[1, 6891] loss_train: 0.003270, loss_test: 0.005725
time: 0.24606704711914062
time: 2.260505437850952
[1, 6892] loss_train: 0.002405, loss_test: 0.005742
time: 0.24305367469787598
time: 2.219496250152588
[1, 6893] loss_train: 0.009772, loss_test: 0.005752
time: 0.24405407905578613
time: 2.216503858566284
[1, 6894] loss_train: 0.010370, loss_test: 0.005743
time: 0.25005507469177246
time: 2.218496799468994
[1, 6895] loss_train: 0.009129, loss_test: 0.005727
time: 0.2450544834136963
time: 2.224513292312622
[1, 6896] loss_train: 0.008005, loss_test: 0.005716
time: 0.24906635284423828
time: 2.2375006675720215
[1, 6897] loss_train: 0.003389, loss_test: 0.005710
time: 0.2470548152923584
time: 2.2044918537139893
[1, 6898] loss_train: 0.005214, loss_test: 0.005710
time: 0.24405455589294434
time: 2.2390034198760986
[1, 6899] loss_train: 0.012449, loss_test: 0.005712
time: 0.2450549602508545
time: 2.2485334873199463
[1, 6900] loss_train: 0.007470, loss_test: 0.005713
time: 0.2560563087463379
time: 2.235499858856201
[1, 6901] loss_train: 0.007196, loss_test: 0.005717
time: 0.24907469749450684
time: 2.201491594314575
[1, 6902] loss_train: 0.003851, loss_test: 0.005721
time: 0.2470543384552002
time: 2.2195003032684326
[1, 6903] loss_train: 0.004303, loss_test: 0.005725
time: 0.24305367469787598
time: 2.2084946632385254
[1, 6904] loss_train: 0.009521, loss_test: 0.005729
time: 0.2510550022125244
time: 2.2194972038269043
[1, 6905] loss_train: 0.004549, loss_test: 0.005731
time: 0.24405360221862793
time: 2.202493190765381
[1, 6906] loss_train: 0.007578, loss_test: 0.005731
time: 0.2440800666809082
time: 2.229498863220215
[1, 6907] loss_train: 0.003178, loss_test: 0.005729
time: 0.24405407905578613
time: 2.2124953269958496
[1, 6908] loss_train: 0.007737, loss_test: 0.005728
time: 0.24405384063720703
time: 2.2365245819091797
[1, 6909] loss_train: 0.003566, loss_test: 0.005728
time: 0.2450549602508545
time: 2.234508514404297
[1, 6910] loss_train: 0.013258, loss_test: 0.005729
time: 0.2560572624206543
time: 2.254006862640381
[1, 6911] loss_train: 0.002924, loss_test: 0.005733
time: 0.2470543384552002
time: 2.2124977111816406
[1, 6912] loss_train: 0.005455, loss_test: 0.005736
time: 0.2450544834136963
time: 2.2174954414367676
[1, 6913] loss_train: 0.004924, loss_test: 0.005741
time: 0.2490549087524414
time: 2.1984920501708984
[1, 6914] loss_train: 0.003341, loss_test: 0.005745
time: 0.24505400657653809
time: 2.21950626373291
[1, 6915] loss_train: 0.003980, loss_test: 0.005750
time: 0.24405336380004883
time: 2.2124946117401123
[1, 6916] loss_train: 0.010328, loss_test: 0.005757
time: 0.24606943130493164
time: 2.1964917182922363
[1, 6917] loss_train: 0.004435, loss_test: 0.005765
time: 0.24305438995361328
time: 2.2204959392547607
[1, 6918] loss_train: 0.005939, loss_test: 0.005769
time: 0.24305438995361328
time: 2.2405219078063965
[1, 6919] loss_train: 0.007210, loss_test: 0.005767
time: 0.24405336380004883
time: 2.230501651763916
[1, 6920] loss_train: 0.005067, loss_test: 0.005762
time: 0.2540559768676758
time: 2.2375011444091797
[1, 6921] loss_train: 0.005000, loss_test: 0.005759
time: 0.2470543384552002
time: 2.2224974632263184
[1, 6922] loss_train: 0.004915, loss_test: 0.005759
time: 0.2450556755065918
time: 2.233499050140381
[1, 6923] loss_train: 0.009872, loss_test: 0.005744
time: 0.24305438995361328
time: 2.1904923915863037
[1, 6924] loss_train: 0.004526, loss_test: 0.005733
time: 0.24505949020385742
time: 2.2175111770629883
[1, 6925] loss_train: 0.006963, loss_test: 0.005727
time: 0.24605488777160645
time: 2.1894891262054443
[1, 6926] loss_train: 0.012370, loss_test: 0.005718
time: 0.25008177757263184
time: 2.2135121822357178
[1, 6927] loss_train: 0.000640, loss_test: 0.005718
time: 0.24605488777160645
time: 2.2044925689697266
[1, 6928] loss_train: 0.003929, loss_test: 0.005722
time: 0.24606728553771973
time: 2.2620251178741455
[1, 6929] loss_train: 0.006575, loss_test: 0.005732
time: 0.24505376815795898
time: 2.2475030422210693
[1, 6930] loss_train: 0.007368, loss_test: 0.005731
time: 0.2560577392578125
time: 2.2595043182373047
[1, 6931] loss_train: 0.008105, loss_test: 0.005730
time: 0.24605536460876465
time: 2.2415034770965576
[1, 6932] loss_train: 0.003380, loss_test: 0.005726
time: 0.2450549602508545
time: 2.2324986457824707
[1, 6933] loss_train: 0.008880, loss_test: 0.005725
time: 0.24305391311645508
time: 2.2134950160980225
[1, 6934] loss_train: 0.012469, loss_test: 0.005725
time: 0.24505376815795898
time: 2.2625064849853516
[1, 6935] loss_train: 0.004247, loss_test: 0.005726
time: 0.24305367469787598
time: 2.221515417098999
[1, 6936] loss_train: 0.003396, loss_test: 0.005729
time: 0.24405431747436523
time: 2.20450758934021
[1, 6937] loss_train: 0.007073, loss_test: 0.005735
time: 0.24406719207763672
time: 2.2094945907592773
[1, 6938] loss_train: 0.006959, loss_test: 0.005745
time: 0.24605488777160645
time: 2.2314987182617188
[1, 6939] loss_train: 0.010223, loss_test: 0.005756
time: 0.24305391311645508
time: 2.2255117893218994
[1, 6940] loss_train: 0.002092, loss_test: 0.005763
time: 0.25705671310424805
time: 2.250502824783325
[1, 6941] loss_train: 0.004281, loss_test: 0.005767
time: 0.2450549602508545
time: 2.2254981994628906
[1, 6942] loss_train: 0.004598, loss_test: 0.005772
time: 0.24305391311645508
time: 2.227498769760132
[1, 6943] loss_train: 0.006637, loss_test: 0.005769
time: 0.24405360221862793
time: 2.2405014038085938
[1, 6944] loss_train: 0.004513, loss_test: 0.005765
time: 0.24406743049621582
time: 2.219496965408325
[1, 6945] loss_train: 0.007313, loss_test: 0.005759
time: 0.24505829811096191
time: 2.244046449661255
[1, 6946] loss_train: 0.004687, loss_test: 0.005754
time: 0.24607133865356445
time: 2.2450203895568848
[1, 6947] loss_train: 0.004347, loss_test: 0.005750
time: 0.24605417251586914
time: 2.219496965408325
[1, 6948] loss_train: 0.011033, loss_test: 0.005740
time: 0.2470550537109375
time: 2.182487726211548
[1, 6949] loss_train: 0.005007, loss_test: 0.005737
time: 0.2490551471710205
time: 2.2155423164367676
[1, 6950] loss_train: 0.008613, loss_test: 0.005738
time: 0.2560698986053467
time: 2.2715070247650146
[1, 6951] loss_train: 0.006918, loss_test: 0.005747
time: 0.25005555152893066
time: 2.2350034713745117
[1, 6952] loss_train: 0.007716, loss_test: 0.005759
time: 0.24505376815795898
time: 2.206495761871338
[1, 6953] loss_train: 0.001558, loss_test: 0.005763
time: 0.24305462837219238
time: 2.2274982929229736
[1, 6954] loss_train: 0.012732, loss_test: 0.005758
time: 0.24305438995361328
time: 2.2375009059906006
[1, 6955] loss_train: 0.010369, loss_test: 0.005756
time: 0.24405336380004883
time: 2.230017900466919
[1, 6956] loss_train: 0.006367, loss_test: 0.005750
time: 0.2450549602508545
time: 2.2495028972625732
[1, 6957] loss_train: 0.005970, loss_test: 0.005747
time: 0.24405360221862793
time: 2.2320210933685303
[1, 6958] loss_train: 0.008471, loss_test: 0.005749
time: 0.24605417251586914
time: 2.2485034465789795
[1, 6959] loss_train: 0.004717, loss_test: 0.005755
time: 0.24805545806884766
time: 2.2340221405029297
[1, 6960] loss_train: 0.001681, loss_test: 0.005759
time: 0.25505709648132324
time: 2.2645061016082764
[1, 6961] loss_train: 0.010607, loss_test: 0.005765
time: 0.24405336380004883
time: 2.2224998474121094
[1, 6962] loss_train: 0.007769, loss_test: 0.005768
time: 0.24405407905578613
time: 2.2515170574188232
[1, 6963] loss_train: 0.013027, loss_test: 0.005765
time: 0.2510550022125244
time: 2.2445013523101807
[1, 6964] loss_train: 0.007145, loss_test: 0.005759
time: 0.24506664276123047
time: 2.2094950675964355
[1, 6965] loss_train: 0.014658, loss_test: 0.005754
time: 0.24305176734924316
time: 2.221524715423584
[1, 6966] loss_train: 0.007373, loss_test: 0.005753
time: 0.24405360221862793
time: 2.205493927001953
[1, 6967] loss_train: 0.001998, loss_test: 0.005751
time: 0.24405455589294434
time: 2.2371315956115723
[1, 6968] loss_train: 0.002455, loss_test: 0.005749
time: 0.2470545768737793
time: 2.234499931335449
[1, 6969] loss_train: 0.010950, loss_test: 0.005746
time: 0.24505352973937988
time: 2.2525033950805664
[1, 6970] loss_train: 0.006402, loss_test: 0.005743
time: 0.2560572624206543
time: 2.2365000247955322
[1, 6971] loss_train: 0.003083, loss_test: 0.005741
time: 0.24605488777160645
time: 2.2154951095581055
[1, 6972] loss_train: 0.012750, loss_test: 0.005735
time: 0.2483532428741455
time: 2.215498208999634
[1, 6973] loss_train: 0.002628, loss_test: 0.005732
time: 0.24605417251586914
time: 2.220001459121704
[1, 6974] loss_train: 0.007320, loss_test: 0.005730
time: 0.24805450439453125
time: 2.226388692855835
[1, 6975] loss_train: 0.004117, loss_test: 0.005729
time: 0.24606823921203613
time: 2.213550329208374
[1, 6976] loss_train: 0.004399, loss_test: 0.005726
time: 0.244584321975708
time: 2.2300026416778564
[1, 6977] loss_train: 0.003217, loss_test: 0.005721
time: 0.24507975578308105
time: 2.1984920501708984
[1, 6978] loss_train: 0.007512, loss_test: 0.005721
time: 0.24405384063720703
time: 2.214503765106201
[1, 6979] loss_train: 0.001218, loss_test: 0.005723
time: 0.24305391311645508
time: 2.211494207382202
[1, 6980] loss_train: 0.013028, loss_test: 0.005725
time: 0.25505733489990234
time: 2.2615251541137695
[1, 6981] loss_train: 0.008822, loss_test: 0.005727
time: 0.24305415153503418
time: 2.2375004291534424
[1, 6982] loss_train: 0.014251, loss_test: 0.005728
time: 0.2450549602508545
time: 2.2084925174713135
[1, 6983] loss_train: 0.007583, loss_test: 0.005725
time: 0.24507641792297363
time: 2.227498769760132
[1, 6984] loss_train: 0.002618, loss_test: 0.005726
time: 0.24406790733337402
time: 2.212512254714966
[1, 6985] loss_train: 0.006415, loss_test: 0.005729
time: 0.24405384063720703
time: 2.2074942588806152
[1, 6986] loss_train: 0.008236, loss_test: 0.005735
time: 0.2450544834136963
time: 2.2085063457489014
[1, 6987] loss_train: 0.006303, loss_test: 0.005745
time: 0.2490546703338623
time: 2.234499931335449
[1, 6988] loss_train: 0.004588, loss_test: 0.005762
time: 0.24505352973937988
time: 2.1974923610687256
[1, 6989] loss_train: 0.008145, loss_test: 0.005773
time: 0.2510557174682617
time: 2.206493377685547
[1, 6990] loss_train: 0.003678, loss_test: 0.005784
time: 0.256070613861084
time: 2.2685067653656006
[1, 6991] loss_train: 0.002546, loss_test: 0.005793
time: 0.2490551471710205
time: 2.232501983642578
[1, 6992] loss_train: 0.013067, loss_test: 0.005798
time: 0.24656105041503906
time: 2.244502544403076
[1, 6993] loss_train: 0.004403, loss_test: 0.005801
time: 0.24609684944152832
time: 2.2179994583129883
[1, 6994] loss_train: 0.010925, loss_test: 0.005799
time: 0.24405431747436523
time: 2.23050856590271
[1, 6995] loss_train: 0.004193, loss_test: 0.005791
time: 0.24605512619018555
time: 2.2645087242126465
[1, 6996] loss_train: 0.020953, loss_test: 0.005732
time: 0.24405431747436523
time: 2.2024924755096436
[1, 6997] loss_train: 0.007415, loss_test: 0.005723
time: 0.24205374717712402
time: 2.2244980335235596
[1, 6998] loss_train: 0.003390, loss_test: 0.005758
time: 0.24405407905578613
time: 2.2495179176330566
[1, 6999] loss_train: 0.011247, loss_test: 0.005824
time: 0.24505352973937988
time: 2.2124950885772705
[1, 7000] loss_train: 0.013325, loss_test: 0.005904
time: 0.25505638122558594
time: 2.241020917892456
[1, 7001] loss_train: 0.002335, loss_test: 0.005952
time: 0.24505400657653809
time: 2.212505340576172
[1, 7002] loss_train: 0.002642, loss_test: 0.005960
time: 0.24605417251586914
time: 2.216496229171753
[1, 7003] loss_train: 0.007699, loss_test: 0.005924
time: 0.24421930313110352
time: 2.215000629425049
[1, 7004] loss_train: 0.003401, loss_test: 0.005839
time: 0.24405479431152344
time: 2.2010061740875244
[1, 7005] loss_train: 0.011789, loss_test: 0.005775
time: 0.24405407905578613
time: 2.221496820449829
[1, 7006] loss_train: 0.008371, loss_test: 0.005736
time: 0.25306010246276855
time: 2.2174971103668213
[1, 7007] loss_train: 0.008250, loss_test: 0.005720
time: 0.24556589126586914
time: 2.230501890182495
[1, 7008] loss_train: 0.006977, loss_test: 0.005726
time: 0.2490558624267578
time: 2.234506845474243
[1, 7009] loss_train: 0.009432, loss_test: 0.005740
time: 0.2465677261352539
time: 2.2365005016326904
[1, 7010] loss_train: 0.003742, loss_test: 0.005762
time: 0.25905799865722656
time: 2.2324979305267334
[1, 7011] loss_train: 0.007394, loss_test: 0.005766
time: 0.24421286582946777
time: 2.228498697280884
[1, 7012] loss_train: 0.014317, loss_test: 0.005753
time: 0.24405384063720703
time: 2.2114953994750977
[1, 7013] loss_train: 0.013348, loss_test: 0.005729
time: 0.24405360221862793
time: 2.1934914588928223
[1, 7014] loss_train: 0.003419, loss_test: 0.005714
time: 0.24305343627929688
time: 2.2270030975341797
[1, 7015] loss_train: 0.004218, loss_test: 0.005708
time: 0.24405407905578613
time: 2.2294986248016357
[1, 7016] loss_train: 0.007570, loss_test: 0.005715
time: 0.24805593490600586
time: 2.260507345199585
[1, 7017] loss_train: 0.006966, loss_test: 0.005729
time: 0.24405407905578613
time: 2.2345001697540283
[1, 7018] loss_train: 0.008164, loss_test: 0.005738
time: 0.2440662384033203
time: 2.220496416091919
[1, 7019] loss_train: 0.002774, loss_test: 0.005747
time: 0.24305391311645508
time: 2.2475125789642334
[1, 7020] loss_train: 0.010411, loss_test: 0.005752
time: 0.25505661964416504
time: 2.258659839630127
[1, 7021] loss_train: 0.003021, loss_test: 0.005745
time: 0.24405407905578613
time: 2.2254981994628906
[1, 7022] loss_train: 0.008250, loss_test: 0.005736
time: 0.24406909942626953
time: 2.2385010719299316
[1, 7023] loss_train: 0.009474, loss_test: 0.005725
time: 0.2440807819366455
time: 2.2164952754974365
[1, 7024] loss_train: 0.009763, loss_test: 0.005721
time: 0.24706673622131348
time: 2.193491220474243
[1, 7025] loss_train: 0.013546, loss_test: 0.005721
time: 0.2490546703338623
time: 2.2005741596221924
[1, 7026] loss_train: 0.002461, loss_test: 0.005718
time: 0.24605488777160645
time: 2.234548568725586
[1, 7027] loss_train: 0.001331, loss_test: 0.005713
time: 0.24706816673278809
time: 2.2150015830993652
[1, 7028] loss_train: 0.007786, loss_test: 0.005710
time: 0.24305438995361328
time: 2.222496747970581
[1, 7029] loss_train: 0.005667, loss_test: 0.005710
time: 0.24405431747436523
time: 2.2405097484588623
[1, 7030] loss_train: 0.003137, loss_test: 0.005713
time: 0.25505614280700684
time: 2.2465028762817383
[1, 7031] loss_train: 0.008017, loss_test: 0.005717
time: 0.24405455589294434
time: 2.2505104541778564
[1, 7032] loss_train: 0.003679, loss_test: 0.005720
time: 0.24405431747436523
time: 2.2355031967163086
[1, 7033] loss_train: 0.008043, loss_test: 0.005720
time: 0.24605536460876465
time: 2.186488628387451
[1, 7034] loss_train: 0.003938, loss_test: 0.005718
time: 0.24405431747436523
time: 2.252537965774536
[1, 7035] loss_train: 0.003677, loss_test: 0.005718
time: 0.24405360221862793
time: 2.2165145874023438
[1, 7036] loss_train: 0.004779, loss_test: 0.005718
time: 0.24405431747436523
time: 2.2164955139160156
[1, 7037] loss_train: 0.000859, loss_test: 0.005720
time: 0.24505400657653809
time: 2.2005162239074707
[1, 7038] loss_train: 0.006700, loss_test: 0.005722
time: 0.24305438995361328
time: 2.2174956798553467
[1, 7039] loss_train: 0.005293, loss_test: 0.005727
time: 0.24405384063720703
time: 2.229012966156006
[1, 7040] loss_train: 0.009396, loss_test: 0.005730
time: 0.25705671310424805
time: 2.2585055828094482
[1, 7041] loss_train: 0.001303, loss_test: 0.005738
time: 0.2490558624267578
time: 2.2174956798553467
[1, 7042] loss_train: 0.008685, loss_test: 0.005746
time: 0.24505949020385742
time: 2.232499361038208
[1, 7043] loss_train: 0.008154, loss_test: 0.005754
time: 0.24605560302734375
time: 2.222496509552002
[1, 7044] loss_train: 0.013310, loss_test: 0.005753
time: 0.24912095069885254
time: 2.2355005741119385
[1, 7045] loss_train: 0.001465, loss_test: 0.005755
time: 0.2450542449951172
time: 2.2210357189178467
[1, 7046] loss_train: 0.007000, loss_test: 0.005752
time: 0.24806737899780273
time: 2.2220401763916016
[1, 7047] loss_train: 0.001863, loss_test: 0.005750
time: 0.2470543384552002
time: 2.231499433517456
[1, 7048] loss_train: 0.008485, loss_test: 0.005750
time: 0.2450547218322754
time: 2.2134945392608643
[1, 7049] loss_train: 0.005089, loss_test: 0.005748
time: 0.24505925178527832
time: 2.2275032997131348
[1, 7050] loss_train: 0.003873, loss_test: 0.005750
time: 0.256056547164917
time: 2.241502046585083
[1, 7051] loss_train: 0.004853, loss_test: 0.005750
time: 0.2450547218322754
time: 2.1924896240234375
[1, 7052] loss_train: 0.005462, loss_test: 0.005750
time: 0.2450556755065918
time: 2.248502254486084
[1, 7053] loss_train: 0.004666, loss_test: 0.005749
time: 0.24205374717712402
time: 2.24650502204895
[1, 7054] loss_train: 0.010603, loss_test: 0.005739
time: 0.24605488777160645
time: 2.2294986248016357
[1, 7055] loss_train: 0.012412, loss_test: 0.005734
time: 0.24405336380004883
time: 2.2245376110076904
[1, 7056] loss_train: 0.007395, loss_test: 0.005733
time: 0.24405407905578613
time: 2.208494186401367
[1, 7057] loss_train: 0.004176, loss_test: 0.005735
time: 0.2450547218322754
time: 2.2000231742858887
[1, 7058] loss_train: 0.001656, loss_test: 0.005739
time: 0.24305367469787598
time: 2.205493927001953
[1, 7059] loss_train: 0.001012, loss_test: 0.005734
time: 0.24508213996887207
time: 2.203505754470825
[1, 7060] loss_train: 0.006381, loss_test: 0.005728
time: 0.2554488182067871
time: 2.243501663208008
[1, 7061] loss_train: 0.009801, loss_test: 0.005724
time: 0.2510554790496826
time: 2.2355129718780518
[1, 7062] loss_train: 0.011483, loss_test: 0.005717
time: 0.24405384063720703
time: 2.2405014038085938
[1, 7063] loss_train: 0.001011, loss_test: 0.005712
time: 0.25005507469177246
time: 2.230499505996704
[1, 7064] loss_train: 0.002106, loss_test: 0.005709
time: 0.24605393409729004
time: 2.2214972972869873
[1, 7065] loss_train: 0.003209, loss_test: 0.005709
time: 0.24605488777160645
time: 2.2155086994171143
[1, 7066] loss_train: 0.009349, loss_test: 0.005701
time: 0.2450542449951172
time: 2.218496799468994
[1, 7067] loss_train: 0.002907, loss_test: 0.005706
time: 0.24305391311645508
time: 2.207494020462036
[1, 7068] loss_train: 0.008352, loss_test: 0.005726
time: 0.24506855010986328
time: 2.205510377883911
[1, 7069] loss_train: 0.008678, loss_test: 0.005747
time: 0.24605369567871094
time: 2.239522933959961
[1, 7070] loss_train: 0.010622, loss_test: 0.005759
time: 0.254056453704834
time: 2.233499526977539
[1, 7071] loss_train: 0.005708, loss_test: 0.005770
time: 0.24305391311645508
time: 2.245504856109619
[1, 7072] loss_train: 0.006862, loss_test: 0.005770
time: 0.24405360221862793
time: 2.2180020809173584
[1, 7073] loss_train: 0.003147, loss_test: 0.005772
time: 0.24305319786071777
time: 2.2294983863830566
[1, 7074] loss_train: 0.011882, loss_test: 0.005763
time: 0.24305462837219238
time: 2.235499620437622
[1, 7075] loss_train: 0.005791, loss_test: 0.005756
time: 0.24405455589294434
time: 2.2545039653778076
[1, 7076] loss_train: 0.005409, loss_test: 0.005737
time: 0.24605917930603027
time: 2.235745429992676
[1, 7077] loss_train: 0.005794, loss_test: 0.005725
time: 0.24506711959838867
time: 2.2355003356933594
[1, 7078] loss_train: 0.003402, loss_test: 0.005721
time: 0.2470552921295166
time: 2.245502233505249
[1, 7079] loss_train: 0.008367, loss_test: 0.005722
time: 0.2450547218322754
time: 2.2079765796661377
[1, 7080] loss_train: 0.008755, loss_test: 0.005720
time: 0.2560570240020752
time: 2.24550199508667
[1, 7081] loss_train: 0.003274, loss_test: 0.005721
time: 0.25005507469177246
time: 2.2335004806518555
[1, 7082] loss_train: 0.004257, loss_test: 0.005724
time: 0.2470550537109375
time: 2.208495616912842
[1, 7083] loss_train: 0.005603, loss_test: 0.005729
time: 0.24605488777160645
time: 2.261505603790283
[1, 7084] loss_train: 0.008977, loss_test: 0.005733
time: 0.2510554790496826
time: 2.216496229171753
[1, 7085] loss_train: 0.015211, loss_test: 0.005740
time: 0.24405336380004883
time: 2.232541084289551
[1, 7086] loss_train: 0.006979, loss_test: 0.005758
time: 0.25006699562072754
time: 2.2205088138580322
[1, 7087] loss_train: 0.007103, loss_test: 0.005784
time: 0.2430553436279297
time: 2.1994924545288086
[1, 7088] loss_train: 0.005245, loss_test: 0.005797
time: 0.24605393409729004
time: 2.2165091037750244
[1, 7089] loss_train: 0.019469, loss_test: 0.005801
time: 0.2490556240081787
time: 2.248502492904663
[1, 7090] loss_train: 0.007977, loss_test: 0.005783
time: 0.25505638122558594
time: 2.2625086307525635
[1, 7091] loss_train: 0.005814, loss_test: 0.005771
time: 0.2450542449951172
time: 2.2365005016326904
[1, 7092] loss_train: 0.004882, loss_test: 0.005755
time: 0.24355864524841309
time: 2.209493637084961
[1, 7093] loss_train: 0.006856, loss_test: 0.005739
time: 0.24205327033996582
time: 2.2144956588745117
[1, 7094] loss_train: 0.011552, loss_test: 0.005727
time: 0.24405360221862793
time: 2.2355005741119385
[1, 7095] loss_train: 0.001798, loss_test: 0.005720
time: 0.24505400657653809
time: 2.2080304622650146
[1, 7096] loss_train: 0.008703, loss_test: 0.005721
time: 0.24505400657653809
time: 2.2210018634796143
[1, 7097] loss_train: 0.003526, loss_test: 0.005723
time: 0.24305367469787598
time: 2.189507246017456
[1, 7098] loss_train: 0.005110, loss_test: 0.005727
time: 0.24405360221862793
time: 2.22149658203125
[1, 7099] loss_train: 0.007690, loss_test: 0.005730
time: 0.24606680870056152
time: 2.217496633529663
[1, 7100] loss_train: 0.008962, loss_test: 0.005732
time: 0.2560570240020752
time: 2.274573802947998
[1, 7101] loss_train: 0.023530, loss_test: 0.005734
time: 0.2510561943054199
time: 2.2164955139160156
[1, 7102] loss_train: 0.012819, loss_test: 0.005730
time: 0.24505376815795898
time: 2.22649884223938
[1, 7103] loss_train: 0.007501, loss_test: 0.005726
time: 0.24805498123168945
time: 2.2164957523345947
[1, 7104] loss_train: 0.004326, loss_test: 0.005724
time: 0.24405431747436523
time: 2.218496084213257
[1, 7105] loss_train: 0.005934, loss_test: 0.005723
time: 0.2450542449951172
time: 2.2044930458068848
[1, 7106] loss_train: 0.018030, loss_test: 0.005705
time: 0.24405550956726074
time: 2.230043888092041
[1, 7107] loss_train: 0.014567, loss_test: 0.005693
time: 0.24405360221862793
time: 2.2214972972869873
[1, 7108] loss_train: 0.006215, loss_test: 0.005694
time: 0.24305391311645508
time: 2.2150235176086426
[1, 7109] loss_train: 0.006811, loss_test: 0.005701
time: 0.2450706958770752
time: 2.229499101638794
[1, 7110] loss_train: 0.004916, loss_test: 0.005708
time: 0.25509214401245117
time: 2.24550199508667
[1, 7111] loss_train: 0.006438, loss_test: 0.005713
time: 0.2450551986694336
time: 2.233499050140381
[1, 7112] loss_train: 0.007707, loss_test: 0.005716
time: 0.2470545768737793
time: 2.220508575439453
[1, 7113] loss_train: 0.006941, loss_test: 0.005715
time: 0.24405455589294434
time: 2.222496509552002
[1, 7114] loss_train: 0.002492, loss_test: 0.005711
time: 0.24405431747436523
time: 2.192490816116333
[1, 7115] loss_train: 0.012595, loss_test: 0.005707
time: 0.24605488777160645
time: 2.2195181846618652
[1, 7116] loss_train: 0.012974, loss_test: 0.005708
time: 0.24610376358032227
time: 2.2320218086242676
[1, 7117] loss_train: 0.005558, loss_test: 0.005714
time: 0.2450551986694336
time: 2.2274975776672363
[1, 7118] loss_train: 0.001894, loss_test: 0.005721
time: 0.25205564498901367
time: 2.2205138206481934
[1, 7119] loss_train: 0.003215, loss_test: 0.005730
time: 0.24405384063720703
time: 2.2214972972869873
[1, 7120] loss_train: 0.003385, loss_test: 0.005743
time: 0.2593393325805664
time: 2.274510145187378
[1, 7121] loss_train: 0.006739, loss_test: 0.005752
time: 0.24605536460876465
time: 2.2254974842071533
[1, 7122] loss_train: 0.003758, loss_test: 0.005756
time: 0.2470548152923584
time: 2.242016077041626
[1, 7123] loss_train: 0.004651, loss_test: 0.005763
time: 0.24505376815795898
time: 2.2144956588745117
[1, 7124] loss_train: 0.010095, loss_test: 0.005774
time: 0.24405336380004883
time: 2.239501476287842
[1, 7125] loss_train: 0.012375, loss_test: 0.005767
time: 0.24459195137023926
time: 2.2144994735717773
[1, 7126] loss_train: 0.010831, loss_test: 0.005759
time: 0.2510561943054199
time: 2.2405240535736084
[1, 7127] loss_train: 0.004206, loss_test: 0.005752
time: 0.24305438995361328
time: 2.222496747970581
[1, 7128] loss_train: 0.015812, loss_test: 0.005742
time: 0.24305367469787598
time: 2.2224974632263184
[1, 7129] loss_train: 0.001451, loss_test: 0.005740
time: 0.24305319786071777
time: 2.2244975566864014
[1, 7130] loss_train: 0.007774, loss_test: 0.005740
time: 0.2580578327178955
time: 2.24550199508667
[1, 7131] loss_train: 0.003680, loss_test: 0.005740
time: 0.24405360221862793
time: 2.2605185508728027
[1, 7132] loss_train: 0.008180, loss_test: 0.005738
time: 0.24305343627929688
time: 2.216508150100708
[1, 7133] loss_train: 0.001426, loss_test: 0.005737
time: 0.2460789680480957
time: 2.219499349594116
[1, 7134] loss_train: 0.008345, loss_test: 0.005736
time: 0.24406671524047852
time: 2.2167882919311523
[1, 7135] loss_train: 0.001660, loss_test: 0.005737
time: 0.24106597900390625
time: 2.211013078689575
[1, 7136] loss_train: 0.007073, loss_test: 0.005740
time: 0.24605417251586914
time: 2.2134950160980225
[1, 7137] loss_train: 0.011039, loss_test: 0.005745
time: 0.2470545768737793
time: 2.2130165100097656
[1, 7138] loss_train: 0.012197, loss_test: 0.005746
time: 0.24405407905578613
time: 2.2515203952789307
[1, 7139] loss_train: 0.007529, loss_test: 0.005745
time: 0.25005507469177246
time: 2.2214972972869873
[1, 7140] loss_train: 0.009383, loss_test: 0.005747
time: 0.256056547164917
time: 2.275512933731079
[1, 7141] loss_train: 0.011600, loss_test: 0.005743
time: 0.251065731048584
time: 2.2164952754974365
[1, 7142] loss_train: 0.005525, loss_test: 0.005740
time: 0.2450544834136963
time: 2.2505030632019043
[1, 7143] loss_train: 0.003274, loss_test: 0.005735
time: 0.2470543384552002
time: 2.226501703262329
[1, 7144] loss_train: 0.002331, loss_test: 0.005730
time: 0.24305319786071777
time: 2.2264981269836426
[1, 7145] loss_train: 0.009235, loss_test: 0.005727
time: 0.2470557689666748
time: 2.2005183696746826
[1, 7146] loss_train: 0.003331, loss_test: 0.005728
time: 0.24805474281311035
time: 2.258514881134033
[1, 7147] loss_train: 0.008309, loss_test: 0.005729
time: 0.24306392669677734
time: 2.2104978561401367
[1, 7148] loss_train: 0.004600, loss_test: 0.005730
time: 0.24406790733337402
time: 2.248502492904663
[1, 7149] loss_train: 0.004967, loss_test: 0.005734
time: 0.24305438995361328
time: 2.2195138931274414
[1, 7150] loss_train: 0.003657, loss_test: 0.005739
time: 0.2540566921234131
time: 2.2371456623077393
[1, 7151] loss_train: 0.008327, loss_test: 0.005741
time: 0.24406671524047852
time: 2.2205023765563965
[1, 7152] loss_train: 0.005891, loss_test: 0.005743
time: 0.24405407905578613
time: 2.2034926414489746
[1, 7153] loss_train: 0.009209, loss_test: 0.005737
time: 0.2490682601928711
time: 2.201491355895996
[1, 7154] loss_train: 0.007900, loss_test: 0.005729
time: 0.2450554370880127
time: 2.224001169204712
[1, 7155] loss_train: 0.003486, loss_test: 0.005724
time: 0.24305391311645508
time: 2.2154955863952637
[1, 7156] loss_train: 0.009507, loss_test: 0.005715
time: 0.24405360221862793
time: 2.2124950885772705
[1, 7157] loss_train: 0.002529, loss_test: 0.005716
time: 0.2450547218322754
time: 2.212498426437378
[1, 7158] loss_train: 0.007068, loss_test: 0.005721
time: 0.24805498123168945
time: 2.2270681858062744
[1, 7159] loss_train: 0.012278, loss_test: 0.005729
time: 0.24405431747436523
time: 2.225020408630371
[1, 7160] loss_train: 0.007048, loss_test: 0.005735
time: 0.2620580196380615
time: 2.253504514694214
[1, 7161] loss_train: 0.007684, loss_test: 0.005740
time: 0.24505400657653809
time: 2.219496965408325
[1, 7162] loss_train: 0.005820, loss_test: 0.005743
time: 0.2450549602508545
time: 2.2385001182556152
[1, 7163] loss_train: 0.004595, loss_test: 0.005739
time: 0.24605488777160645
time: 2.2164952754974365
[1, 7164] loss_train: 0.011207, loss_test: 0.005735
time: 0.24305343627929688
time: 2.243502378463745
[1, 7165] loss_train: 0.003053, loss_test: 0.005729
time: 0.24405384063720703
time: 2.2295098304748535
[1, 7166] loss_train: 0.002742, loss_test: 0.005723
time: 0.2450544834136963
time: 2.242501735687256
[1, 7167] loss_train: 0.003054, loss_test: 0.005717
time: 0.24605393409729004
time: 2.2135112285614014
[1, 7168] loss_train: 0.013434, loss_test: 0.005715
time: 0.24405431747436523
time: 2.2095000743865967
[1, 7169] loss_train: 0.007601, loss_test: 0.005714
time: 0.2440657615661621
time: 2.1864986419677734
[1, 7170] loss_train: 0.004232, loss_test: 0.005716
time: 0.25905799865722656
time: 2.2405006885528564
[1, 7171] loss_train: 0.003198, loss_test: 0.005720
time: 0.2490556240081787
time: 2.206505298614502
[1, 7172] loss_train: 0.007197, loss_test: 0.005722
time: 0.24405431747436523
time: 2.225506544113159
[1, 7173] loss_train: 0.006718, loss_test: 0.005726
time: 0.24505376815795898
time: 2.2114946842193604
[1, 7174] loss_train: 0.003175, loss_test: 0.005735
time: 0.2450542449951172
time: 2.239501476287842
[1, 7175] loss_train: 0.011139, loss_test: 0.005744
time: 0.2520575523376465
time: 2.231498956680298
[1, 7176] loss_train: 0.005921, loss_test: 0.005748
time: 0.24405431747436523
time: 2.203493118286133
[1, 7177] loss_train: 0.003001, loss_test: 0.005757
time: 0.25305604934692383
time: 2.256504774093628
[1, 7178] loss_train: 0.002857, loss_test: 0.005768
time: 0.2445974349975586
time: 2.2149980068206787
[1, 7179] loss_train: 0.004435, loss_test: 0.005770
time: 0.2450544834136963
time: 2.2261781692504883
[1, 7180] loss_train: 0.002322, loss_test: 0.005773
time: 0.25505638122558594
time: 2.2495036125183105
[1, 7181] loss_train: 0.002324, loss_test: 0.005769
time: 0.24505376815795898
time: 2.232499361038208
[1, 7182] loss_train: 0.000603, loss_test: 0.005772
time: 0.24406862258911133
time: 2.261507749557495
[1, 7183] loss_train: 0.001313, loss_test: 0.005776
time: 0.24505400657653809
time: 2.230499267578125
[1, 7184] loss_train: 0.006015, loss_test: 0.005782
time: 0.24007892608642578
time: 2.2254977226257324
[1, 7185] loss_train: 0.006348, loss_test: 0.005776
time: 0.24406743049621582
time: 2.256505012512207
[1, 7186] loss_train: 0.014085, loss_test: 0.005760
time: 0.24405431747436523
time: 2.2215991020202637
[1, 7187] loss_train: 0.012646, loss_test: 0.005715
time: 0.24805450439453125
time: 2.2225000858306885
[1, 7188] loss_train: 0.002682, loss_test: 0.005698
time: 0.24309349060058594
time: 2.219000816345215
[1, 7189] loss_train: 0.003683, loss_test: 0.005702
time: 0.24305438995361328
time: 2.21151065826416
[1, 7190] loss_train: 0.001619, loss_test: 0.005716
time: 0.25505638122558594
time: 2.2375144958496094
[1, 7191] loss_train: 0.012272, loss_test: 0.005729
time: 0.24305367469787598
time: 2.218496561050415
[1, 7192] loss_train: 0.001973, loss_test: 0.005737
time: 0.24405384063720703
time: 2.220499038696289
[1, 7193] loss_train: 0.010272, loss_test: 0.005736
time: 0.24405360221862793
time: 2.2035036087036133
[1, 7194] loss_train: 0.014879, loss_test: 0.005735
time: 0.24805545806884766
time: 2.2035093307495117
[1, 7195] loss_train: 0.006286, loss_test: 0.005731
time: 0.24505329132080078
time: 2.1844894886016846
[1, 7196] loss_train: 0.009370, loss_test: 0.005728
time: 0.2470541000366211
time: 2.2725179195404053
[1, 7197] loss_train: 0.008681, loss_test: 0.005725
time: 0.24405360221862793
time: 2.2405014038085938
[1, 7198] loss_train: 0.000877, loss_test: 0.005725
time: 0.2470552921295166
time: 2.2115015983581543
[1, 7199] loss_train: 0.008768, loss_test: 0.005730
time: 0.24405384063720703
time: 2.2274980545043945
[1, 7200] loss_train: 0.007997, loss_test: 0.005738
time: 0.25505638122558594
time: 2.2505147457122803
[1, 7201] loss_train: 0.001395, loss_test: 0.005748
time: 0.24605560302734375
time: 2.237499475479126
[1, 7202] loss_train: 0.006723, loss_test: 0.005752
time: 0.24405431747436523
time: 2.22249698638916
[1, 7203] loss_train: 0.005397, loss_test: 0.005756
time: 0.24306797981262207
time: 2.219496011734009
[1, 7204] loss_train: 0.007348, loss_test: 0.005752
time: 0.24305438995361328
time: 2.211516857147217
[1, 7205] loss_train: 0.012994, loss_test: 0.005735
time: 0.24305462837219238
time: 2.2134950160980225
[1, 7206] loss_train: 0.005686, loss_test: 0.005724
time: 0.24588656425476074
time: 2.216522693634033
[1, 7207] loss_train: 0.004830, loss_test: 0.005717
time: 0.2440798282623291
time: 2.2214972972869873
[1, 7208] loss_train: 0.006159, loss_test: 0.005717
time: 0.24405407905578613
time: 2.2230095863342285
[1, 7209] loss_train: 0.006034, loss_test: 0.005725
time: 0.24305415153503418
time: 2.211517810821533
[1, 7210] loss_train: 0.008540, loss_test: 0.005736
time: 0.2562577724456787
time: 2.257504940032959
[1, 7211] loss_train: 0.004694, loss_test: 0.005747
time: 0.24605464935302734
time: 2.2495028972625732
[1, 7212] loss_train: 0.001592, loss_test: 0.005752
time: 0.24306797981262207
time: 2.245504140853882
[1, 7213] loss_train: 0.001107, loss_test: 0.005758
time: 0.24505400657653809
time: 2.239501714706421
[1, 7214] loss_train: 0.005822, loss_test: 0.005761
time: 0.24505376815795898
time: 2.192533016204834
[1, 7215] loss_train: 0.005304, loss_test: 0.005765
time: 0.24805474281311035
time: 2.2024922370910645
[1, 7216] loss_train: 0.014763, loss_test: 0.005767
time: 0.24405384063720703
time: 2.2345521450042725
[1, 7217] loss_train: 0.009534, loss_test: 0.005769
time: 0.2470543384552002
time: 2.238502025604248
[1, 7218] loss_train: 0.001922, loss_test: 0.005766
time: 0.24505352973937988
time: 2.241088628768921
[1, 7219] loss_train: 0.007168, loss_test: 0.005754
time: 0.24305415153503418
time: 2.211494207382202
[1, 7220] loss_train: 0.015735, loss_test: 0.005746
time: 0.2540562152862549
time: 2.2200100421905518
[1, 7221] loss_train: 0.006629, loss_test: 0.005737
time: 0.24505400657653809
time: 2.2545042037963867
[1, 7222] loss_train: 0.004637, loss_test: 0.005726
time: 0.24305438995361328
time: 2.2264981269836426
[1, 7223] loss_train: 0.005884, loss_test: 0.005725
time: 0.24405479431152344
time: 2.227499485015869
[1, 7224] loss_train: 0.005396, loss_test: 0.005733
time: 0.24405455589294434
time: 2.2450649738311768
[1, 7225] loss_train: 0.003219, loss_test: 0.005750
time: 0.24305415153503418
time: 2.24550199508667
[1, 7226] loss_train: 0.017374, loss_test: 0.005751
time: 0.2450544834136963
time: 2.220508337020874
[1, 7227] loss_train: 0.007231, loss_test: 0.005748
time: 0.24506807327270508
time: 2.2184956073760986
[1, 7228] loss_train: 0.000810, loss_test: 0.005748
time: 0.24405407905578613
time: 2.2264983654022217
[1, 7229] loss_train: 0.011400, loss_test: 0.005737
time: 0.24505400657653809
time: 2.218496799468994
[1, 7230] loss_train: 0.003216, loss_test: 0.005733
time: 0.256056547164917
time: 2.228508949279785
[1, 7231] loss_train: 0.008347, loss_test: 0.005727
time: 0.24205350875854492
time: 2.2240006923675537
[1, 7232] loss_train: 0.015139, loss_test: 0.005717
time: 0.24605512619018555
time: 2.2385013103485107
[1, 7233] loss_train: 0.010924, loss_test: 0.005708
time: 0.24408364295959473
time: 2.2184956073760986
[1, 7234] loss_train: 0.005547, loss_test: 0.005710
time: 0.2490544319152832
time: 2.216850996017456
[1, 7235] loss_train: 0.002879, loss_test: 0.005715
time: 0.24645590782165527
time: 2.243100881576538
[1, 7236] loss_train: 0.009822, loss_test: 0.005724
time: 0.24805474281311035
time: 2.255504608154297
[1, 7237] loss_train: 0.007025, loss_test: 0.005736
time: 0.24405407905578613
time: 2.2465028762817383
[1, 7238] loss_train: 0.006278, loss_test: 0.005746
time: 0.252056360244751
time: 2.2215261459350586
[1, 7239] loss_train: 0.004313, loss_test: 0.005752
time: 0.24402523040771484
time: 2.199491500854492
[1, 7240] loss_train: 0.002031, loss_test: 0.005750
time: 0.2540559768676758
time: 2.270522356033325
[1, 7241] loss_train: 0.006862, loss_test: 0.005744
time: 0.24605512619018555
time: 2.2395224571228027
[1, 7242] loss_train: 0.004010, loss_test: 0.005731
time: 0.24305319786071777
time: 2.2355031967163086
[1, 7243] loss_train: 0.007877, loss_test: 0.005722
time: 0.243058443069458
time: 2.203763246536255
[1, 7244] loss_train: 0.015355, loss_test: 0.005720
time: 0.24745869636535645
time: 2.2274982929229736
[1, 7245] loss_train: 0.002053, loss_test: 0.005715
time: 0.2440941333770752
time: 2.2380149364471436
[1, 7246] loss_train: 0.004457, loss_test: 0.005715
time: 0.2450547218322754
time: 2.277043581008911
[1, 7247] loss_train: 0.006588, loss_test: 0.005714
time: 0.24406814575195312
time: 2.2320048809051514
[1, 7248] loss_train: 0.007046, loss_test: 0.005717
time: 0.24606680870056152
time: 2.2235107421875
[1, 7249] loss_train: 0.004795, loss_test: 0.005723
time: 0.24305438995361328
time: 2.2685608863830566
[1, 7250] loss_train: 0.008301, loss_test: 0.005720
time: 0.2580578327178955
time: 2.251504898071289
[1, 7251] loss_train: 0.010345, loss_test: 0.005718
time: 0.24605464935302734
time: 2.240501642227173
[1, 7252] loss_train: 0.010000, loss_test: 0.005725
time: 0.24606728553771973
time: 2.2124974727630615
[1, 7253] loss_train: 0.003641, loss_test: 0.005740
time: 0.24205446243286133
time: 2.234499931335449
[1, 7254] loss_train: 0.005773, loss_test: 0.005757
time: 0.2450542449951172
time: 2.2210333347320557
[1, 7255] loss_train: 0.008298, loss_test: 0.005778
time: 0.24305367469787598
time: 2.1964914798736572
[1, 7256] loss_train: 0.014722, loss_test: 0.005764
time: 0.2450542449951172
time: 2.217496156692505
[1, 7257] loss_train: 0.008972, loss_test: 0.005739
time: 0.2450542449951172
time: 2.22550106048584
[1, 7258] loss_train: 0.016765, loss_test: 0.005718
time: 0.2470543384552002
time: 2.217496395111084
[1, 7259] loss_train: 0.011604, loss_test: 0.005705
time: 0.24805569648742676
time: 2.242605686187744
[1, 7260] loss_train: 0.007154, loss_test: 0.005708
time: 0.2580578327178955
time: 2.256504774093628
[1, 7261] loss_train: 0.011894, loss_test: 0.005726
time: 0.2490549087524414
time: 2.2134947776794434
[1, 7262] loss_train: 0.003026, loss_test: 0.005754
time: 0.24605464935302734
time: 2.2134974002838135
[1, 7263] loss_train: 0.007657, loss_test: 0.005776
time: 0.2470543384552002
time: 2.1879920959472656
[1, 7264] loss_train: 0.011818, loss_test: 0.005794
time: 0.24405455589294434
time: 2.217496395111084
[1, 7265] loss_train: 0.008445, loss_test: 0.005768
time: 0.2470545768737793
time: 2.2010653018951416
[1, 7266] loss_train: 0.004119, loss_test: 0.005731
time: 0.24405479431152344
time: 2.20949387550354
[1, 7267] loss_train: 0.007469, loss_test: 0.005709
time: 0.24405360221862793
time: 2.184511184692383
[1, 7268] loss_train: 0.005308, loss_test: 0.005704
time: 0.2470686435699463
time: 2.2375004291534424
[1, 7269] loss_train: 0.013629, loss_test: 0.005703
time: 0.2490549087524414
time: 2.243502616882324
[1, 7270] loss_train: 0.008231, loss_test: 0.005708
time: 0.2560575008392334
time: 2.308516025543213
[1, 7271] loss_train: 0.006303, loss_test: 0.005723
time: 0.2450547218322754
time: 2.286511182785034
[1, 7272] loss_train: 0.009164, loss_test: 0.005746
time: 0.2450547218322754
time: 2.3170249462127686
[1, 7273] loss_train: 0.006542, loss_test: 0.005764
time: 0.2780618667602539
time: 2.490556478500366
[1, 7274] loss_train: 0.011516, loss_test: 0.005784
time: 0.2870655059814453
time: 2.3405227661132812
[1, 7275] loss_train: 0.006265, loss_test: 0.005784
time: 0.27306032180786133
time: 2.3945353031158447
[1, 7276] loss_train: 0.005244, loss_test: 0.005775
time: 0.2800624370574951
time: 2.3965365886688232
[1, 7277] loss_train: 0.007110, loss_test: 0.005767
time: 0.25305604934692383
time: 2.2745110988616943
[1, 7278] loss_train: 0.008675, loss_test: 0.005760
time: 0.2470550537109375
time: 2.3025145530700684
[1, 7279] loss_train: 0.006088, loss_test: 0.005758
time: 0.251056432723999
time: 2.261505365371704
[1, 7280] loss_train: 0.004563, loss_test: 0.005764
time: 0.26407384872436523
time: 2.297513961791992
[1, 7281] loss_train: 0.001903, loss_test: 0.005773
time: 0.26287078857421875
time: 2.2925126552581787
[1, 7282] loss_train: 0.007427, loss_test: 0.005775
time: 0.26105761528015137
time: 2.2915124893188477
[1, 7283] loss_train: 0.001198, loss_test: 0.005778
time: 0.25505685806274414
time: 2.2805097103118896
[1, 7284] loss_train: 0.003975, loss_test: 0.005781
time: 0.25505781173706055
time: 2.2995166778564453
[1, 7285] loss_train: 0.008908, loss_test: 0.005772
time: 0.2580575942993164
time: 2.3415257930755615
[1, 7286] loss_train: 0.015124, loss_test: 0.005752
time: 0.25905680656433105
time: 2.2895138263702393
[1, 7287] loss_train: 0.002743, loss_test: 0.005745
time: 0.2650594711303711
time: 2.2745132446289062
[1, 7288] loss_train: 0.004958, loss_test: 0.005742
time: 0.25705695152282715
time: 2.2995169162750244
[1, 7289] loss_train: 0.012757, loss_test: 0.005738
time: 0.25305652618408203
time: 2.272507429122925
[1, 7290] loss_train: 0.006026, loss_test: 0.005735
time: 0.2560577392578125
time: 2.285510540008545
[1, 7291] loss_train: 0.006725, loss_test: 0.005735
time: 0.25005578994750977
time: 2.2335002422332764
[1, 7292] loss_train: 0.005147, loss_test: 0.005736
time: 0.24405360221862793
time: 2.2505035400390625
[1, 7293] loss_train: 0.009556, loss_test: 0.005741
time: 0.2450547218322754
time: 2.2515029907226562
[1, 7294] loss_train: 0.015193, loss_test: 0.005744
time: 0.2470545768737793
time: 2.257505416870117
[1, 7295] loss_train: 0.001700, loss_test: 0.005741
time: 0.2470550537109375
time: 2.245502233505249
[1, 7296] loss_train: 0.009410, loss_test: 0.005740
time: 0.2470548152923584
time: 2.2525031566619873
[1, 7297] loss_train: 0.005465, loss_test: 0.005746
time: 0.2500572204589844
time: 2.24650239944458
[1, 7298] loss_train: 0.005625, loss_test: 0.005746
time: 0.24405336380004883
time: 2.2355005741119385
[1, 7299] loss_train: 0.006360, loss_test: 0.005749
time: 0.25005602836608887
time: 2.2224960327148438
[1, 7300] loss_train: 0.000828, loss_test: 0.005746
time: 0.25705742835998535
time: 2.318519353866577
[1, 7301] loss_train: 0.004277, loss_test: 0.005741
time: 0.25005507469177246
time: 2.279510021209717
[1, 7302] loss_train: 0.015031, loss_test: 0.005733
time: 0.2490553855895996
time: 2.2064931392669678
[1, 7303] loss_train: 0.008909, loss_test: 0.005723
time: 0.251056432723999
time: 2.262505531311035
[1, 7304] loss_train: 0.009692, loss_test: 0.005716
time: 0.24605417251586914
time: 2.259504795074463
[1, 7305] loss_train: 0.007761, loss_test: 0.005711
time: 0.2450549602508545
time: 2.2665059566497803
[1, 7306] loss_train: 0.008328, loss_test: 0.005708
time: 0.2850642204284668
time: 2.27150821685791
[1, 7307] loss_train: 0.004383, loss_test: 0.005710
time: 0.25305604934692383
time: 2.282510995864868
[1, 7308] loss_train: 0.001730, loss_test: 0.005719
time: 0.2470545768737793
time: 2.2775087356567383
[1, 7309] loss_train: 0.010557, loss_test: 0.005725
time: 0.25005626678466797
time: 2.2865116596221924
[1, 7310] loss_train: 0.002671, loss_test: 0.005732
time: 0.2690591812133789
time: 2.2915127277374268
[1, 7311] loss_train: 0.008012, loss_test: 0.005739
time: 0.25705671310424805
time: 2.2645070552825928
[1, 7312] loss_train: 0.010505, loss_test: 0.005727
time: 0.2510550022125244
time: 2.276611566543579
[1, 7313] loss_train: 0.004070, loss_test: 0.005721
time: 0.25205492973327637
time: 2.242506742477417
[1, 7314] loss_train: 0.005529, loss_test: 0.005714
time: 0.2620577812194824
time: 2.278512954711914
[1, 7315] loss_train: 0.001515, loss_test: 0.005711
time: 0.24805641174316406
time: 2.254505157470703
[1, 7316] loss_train: 0.015838, loss_test: 0.005702
time: 0.2580571174621582
time: 2.252504348754883
[1, 7317] loss_train: 0.009181, loss_test: 0.005701
time: 0.24405479431152344
time: 2.2625062465667725
[1, 7318] loss_train: 0.006196, loss_test: 0.005706
time: 0.2490558624267578
time: 2.2575042247772217
[1, 7319] loss_train: 0.002819, loss_test: 0.005709
time: 0.2470543384552002
time: 2.3125174045562744
[1, 7320] loss_train: 0.002511, loss_test: 0.005709
time: 0.2670598030090332
time: 2.309516429901123
[1, 7321] loss_train: 0.003994, loss_test: 0.005706
time: 0.2560570240020752
time: 2.284510850906372
[1, 7322] loss_train: 0.004517, loss_test: 0.005704
time: 0.258056640625
time: 2.2895147800445557
[1, 7323] loss_train: 0.011897, loss_test: 0.005705
time: 0.24505400657653809
time: 2.3485255241394043
[1, 7324] loss_train: 0.005335, loss_test: 0.005706
time: 0.25505638122558594
time: 2.3195223808288574
[1, 7325] loss_train: 0.006585, loss_test: 0.005711
time: 0.2580559253692627
time: 2.3715310096740723
[1, 7326] loss_train: 0.004075, loss_test: 0.005715
time: 0.27506089210510254
time: 2.3175177574157715
[1, 7327] loss_train: 0.010660, loss_test: 0.005720
time: 0.25505733489990234
time: 2.459054946899414
[1, 7328] loss_train: 0.003441, loss_test: 0.005725
time: 0.30206727981567383
time: 2.4355452060699463
[1, 7329] loss_train: 0.004462, loss_test: 0.005727
time: 0.2530555725097656
time: 2.480555534362793
[1, 7330] loss_train: 0.003642, loss_test: 0.005727
time: 0.33007287979125977
time: 2.5005595684051514
[1, 7331] loss_train: 0.004450, loss_test: 0.005729
time: 0.2620584964752197
time: 2.4035401344299316
[1, 7332] loss_train: 0.006027, loss_test: 0.005720
time: 0.2520558834075928
time: 2.3485257625579834
[1, 7333] loss_train: 0.005742, loss_test: 0.005714
time: 0.25505661964416504
time: 2.2495028972625732
[1, 7334] loss_train: 0.010518, loss_test: 0.005711
time: 0.2600579261779785
time: 2.259504556655884
[1, 7335] loss_train: 0.011236, loss_test: 0.005709
time: 0.247053861618042
time: 2.204493761062622
[1, 7336] loss_train: 0.003787, loss_test: 0.005711
time: 0.24805498123168945
time: 2.2405011653900146
[1, 7337] loss_train: 0.004267, loss_test: 0.005714
time: 0.24305343627929688
time: 2.2204971313476562
[1, 7338] loss_train: 0.005951, loss_test: 0.005719
time: 0.24405384063720703
time: 2.242501735687256
[1, 7339] loss_train: 0.004442, loss_test: 0.005724
time: 0.24405384063720703
time: 2.215496301651001
[1, 7340] loss_train: 0.009329, loss_test: 0.005732
time: 0.25505685806274414
time: 2.2805259227752686
[1, 7341] loss_train: 0.006341, loss_test: 0.005738
time: 0.24371027946472168
time: 2.2475016117095947
[1, 7342] loss_train: 0.007062, loss_test: 0.005742
time: 0.24605584144592285
time: 2.309023141860962
[1, 7343] loss_train: 0.006667, loss_test: 0.005740
time: 0.24605464935302734
time: 2.224497079849243
[1, 7344] loss_train: 0.001248, loss_test: 0.005736
time: 0.2450542449951172
time: 2.2725088596343994
[1, 7345] loss_train: 0.004140, loss_test: 0.005734
time: 0.24405407905578613
time: 2.218496322631836
[1, 7346] loss_train: 0.006218, loss_test: 0.005732
time: 0.2450547218322754
time: 2.2385051250457764
[1, 7347] loss_train: 0.003275, loss_test: 0.005735
time: 0.24455857276916504
time: 2.2395007610321045
[1, 7348] loss_train: 0.002137, loss_test: 0.005744
time: 0.24405384063720703
time: 2.2194972038269043
[1, 7349] loss_train: 0.007949, loss_test: 0.005752
time: 0.24405336380004883
time: 2.194491386413574
[1, 7350] loss_train: 0.005792, loss_test: 0.005759
time: 0.25505566596984863
time: 2.2585325241088867
[1, 7351] loss_train: 0.008686, loss_test: 0.005763
time: 0.2450551986694336
time: 2.23349928855896
[1, 7352] loss_train: 0.002377, loss_test: 0.005766
time: 0.2450542449951172
time: 2.2264983654022217
[1, 7353] loss_train: 0.002486, loss_test: 0.005770
time: 0.24305319786071777
time: 2.2314999103546143
[1, 7354] loss_train: 0.010373, loss_test: 0.005767
time: 0.24405431747436523
time: 2.219496488571167
[1, 7355] loss_train: 0.004526, loss_test: 0.005765
time: 0.24505400657653809
time: 2.241501808166504
[1, 7356] loss_train: 0.002686, loss_test: 0.005765
time: 0.24305438995361328
time: 2.2274980545043945
[1, 7357] loss_train: 0.005024, loss_test: 0.005765
time: 0.24307990074157715
time: 2.223497152328491
[1, 7358] loss_train: 0.004243, loss_test: 0.005765
time: 0.2510554790496826
time: 2.190497398376465
[1, 7359] loss_train: 0.006963, loss_test: 0.005753
time: 0.2510557174682617
time: 2.193490982055664
[1, 7360] loss_train: 0.005665, loss_test: 0.005744
time: 0.2580568790435791
time: 2.2125139236450195
[1, 7361] loss_train: 0.002948, loss_test: 0.005740
time: 0.2540566921234131
time: 2.2405011653900146
[1, 7362] loss_train: 0.008575, loss_test: 0.005735
time: 0.24505376815795898
time: 2.2365007400512695
[1, 7363] loss_train: 0.002916, loss_test: 0.005733
time: 0.24605679512023926
time: 2.2154951095581055
[1, 7364] loss_train: 0.002473, loss_test: 0.005736
time: 0.2470548152923584
time: 2.232501745223999
[1, 7365] loss_train: 0.002897, loss_test: 0.005739
time: 0.24305438995361328
time: 2.2224974632263184
[1, 7366] loss_train: 0.016909, loss_test: 0.005737
time: 0.24205875396728516
time: 2.236499786376953
[1, 7367] loss_train: 0.004335, loss_test: 0.005736
time: 0.24405455589294434
time: 2.198505163192749
[1, 7368] loss_train: 0.012677, loss_test: 0.005734
time: 0.2450542449951172
time: 2.2274978160858154
[1, 7369] loss_train: 0.007560, loss_test: 0.005733
time: 0.24405431747436523
time: 2.226516008377075
[1, 7370] loss_train: 0.004214, loss_test: 0.005732
time: 0.25706911087036133
time: 2.240534782409668
[1, 7371] loss_train: 0.000637, loss_test: 0.005732
time: 0.2450549602508545
time: 2.244501829147339
[1, 7372] loss_train: 0.006248, loss_test: 0.005732
time: 0.24405384063720703
time: 2.2365007400512695
[1, 7373] loss_train: 0.006239, loss_test: 0.005732
time: 0.24505400657653809
time: 2.219496488571167
[1, 7374] loss_train: 0.004830, loss_test: 0.005732
time: 0.24506807327270508
time: 2.1860125064849854
[1, 7375] loss_train: 0.001448, loss_test: 0.005734
time: 0.2470550537109375
time: 2.2034928798675537
[1, 7376] loss_train: 0.007422, loss_test: 0.005732
time: 0.25005578994750977
time: 2.2174956798553467
[1, 7377] loss_train: 0.003601, loss_test: 0.005731
time: 0.2450549602508545
time: 2.2045021057128906
[1, 7378] loss_train: 0.011833, loss_test: 0.005732
time: 0.24805474281311035
time: 2.247532844543457
[1, 7379] loss_train: 0.006748, loss_test: 0.005732
time: 0.24405384063720703
time: 2.243502378463745
[1, 7380] loss_train: 0.005810, loss_test: 0.005732
time: 0.2600572109222412
time: 2.255176305770874
[1, 7381] loss_train: 0.006522, loss_test: 0.005730
time: 0.24405431747436523
time: 2.2264976501464844
[1, 7382] loss_train: 0.006014, loss_test: 0.005724
time: 0.24605417251586914
time: 2.187992811203003
[1, 7383] loss_train: 0.003751, loss_test: 0.005717
time: 0.24305343627929688
time: 2.2465031147003174
[1, 7384] loss_train: 0.000709, loss_test: 0.005714
time: 0.24305343627929688
time: 2.213998556137085
[1, 7385] loss_train: 0.005230, loss_test: 0.005713
time: 0.24805521965026855
time: 2.2274982929229736
[1, 7386] loss_train: 0.003755, loss_test: 0.005714
time: 0.24405431747436523
time: 2.252514362335205
[1, 7387] loss_train: 0.005241, loss_test: 0.005716
time: 0.24406743049621582
time: 2.2200043201446533
[1, 7388] loss_train: 0.009624, loss_test: 0.005715
time: 0.24405407905578613
time: 2.2254981994628906
[1, 7389] loss_train: 0.008154, loss_test: 0.005714
time: 0.24405431747436523
time: 2.2425014972686768
[1, 7390] loss_train: 0.008543, loss_test: 0.005716
time: 0.25505638122558594
time: 2.244513511657715
[1, 7391] loss_train: 0.005031, loss_test: 0.005719
time: 0.24505376815795898
time: 2.2375006675720215
[1, 7392] loss_train: 0.002127, loss_test: 0.005722
time: 0.24305415153503418
time: 2.235501527786255
[1, 7393] loss_train: 0.011618, loss_test: 0.005722
time: 0.24305438995361328
time: 2.2054924964904785
[1, 7394] loss_train: 0.002619, loss_test: 0.005718
time: 0.24605393409729004
time: 2.1974918842315674
[1, 7395] loss_train: 0.005261, loss_test: 0.005712
time: 0.2490549087524414
time: 2.2285327911376953
[1, 7396] loss_train: 0.004064, loss_test: 0.005708
time: 0.24505376815795898
time: 2.232499122619629
[1, 7397] loss_train: 0.006314, loss_test: 0.005709
time: 0.25005483627319336
time: 2.2120089530944824
[1, 7398] loss_train: 0.005847, loss_test: 0.005712
time: 0.24305367469787598
time: 2.2234976291656494
[1, 7399] loss_train: 0.007373, loss_test: 0.005718
time: 0.2470543384552002
time: 2.231499433517456
[1, 7400] loss_train: 0.013692, loss_test: 0.005726
time: 0.25705766677856445
time: 2.2905118465423584
[1, 7401] loss_train: 0.002015, loss_test: 0.005727
time: 0.2490551471710205
time: 2.2535040378570557
[1, 7402] loss_train: 0.011143, loss_test: 0.005720
time: 0.2450544834136963
time: 2.2204976081848145
[1, 7403] loss_train: 0.008322, loss_test: 0.005724
time: 0.2470545768737793
time: 2.22149658203125
[1, 7404] loss_train: 0.003430, loss_test: 0.005717
time: 0.24405479431152344
time: 2.215759754180908
[1, 7405] loss_train: 0.002666, loss_test: 0.005715
time: 0.24605488777160645
time: 2.2415006160736084
[1, 7406] loss_train: 0.004005, loss_test: 0.005714
time: 0.24506783485412598
time: 2.2084944248199463
[1, 7407] loss_train: 0.003963, loss_test: 0.005717
time: 0.24405407905578613
time: 2.221498966217041
[1, 7408] loss_train: 0.013421, loss_test: 0.005718
time: 0.24305295944213867
time: 2.2004923820495605
[1, 7409] loss_train: 0.009621, loss_test: 0.005721
time: 0.24405455589294434
time: 2.190042495727539
[1, 7410] loss_train: 0.010001, loss_test: 0.005719
time: 0.2540614604949951
time: 2.230003833770752
[1, 7411] loss_train: 0.003101, loss_test: 0.005721
time: 0.24306654930114746
time: 2.2144949436187744
[1, 7412] loss_train: 0.006983, loss_test: 0.005724
time: 0.25005531311035156
time: 2.2224974632263184
[1, 7413] loss_train: 0.006692, loss_test: 0.005727
time: 0.2430582046508789
time: 2.218496322631836
[1, 7414] loss_train: 0.005627, loss_test: 0.005729
time: 0.2490556240081787
time: 2.2024929523468018
[1, 7415] loss_train: 0.001074, loss_test: 0.005731
time: 0.24505352973937988
time: 2.215515375137329
[1, 7416] loss_train: 0.001742, loss_test: 0.005734
time: 0.24805545806884766
time: 2.2075071334838867
[1, 7417] loss_train: 0.003850, loss_test: 0.005734
time: 0.24555325508117676
time: 2.207494020462036
[1, 7418] loss_train: 0.003506, loss_test: 0.005732
time: 0.24605488777160645
time: 2.2044925689697266
[1, 7419] loss_train: 0.003568, loss_test: 0.005730
time: 0.24405479431152344
time: 2.2385172843933105
[1, 7420] loss_train: 0.008448, loss_test: 0.005726
time: 0.2560563087463379
time: 2.2134952545166016
[1, 7421] loss_train: 0.007201, loss_test: 0.005720
time: 0.24405431747436523
time: 2.182488203048706
[1, 7422] loss_train: 0.001705, loss_test: 0.005719
time: 0.24405407905578613
time: 2.1895089149475098
[1, 7423] loss_train: 0.003903, loss_test: 0.005720
time: 0.24605321884155273
time: 2.216496467590332
[1, 7424] loss_train: 0.006833, loss_test: 0.005725
time: 0.2450544834136963
time: 2.221496343612671
[1, 7425] loss_train: 0.015930, loss_test: 0.005720
time: 0.2490553855895996
time: 2.220496892929077
[1, 7426] loss_train: 0.013492, loss_test: 0.005714
time: 0.24548745155334473
time: 2.220496654510498
[1, 7427] loss_train: 0.004488, loss_test: 0.005707
time: 0.2480616569519043
time: 2.224497079849243
[1, 7428] loss_train: 0.004722, loss_test: 0.005703
time: 0.24506831169128418
time: 2.196491003036499
[1, 7429] loss_train: 0.003918, loss_test: 0.005700
time: 0.24205398559570312
time: 2.2144956588745117
[1, 7430] loss_train: 0.007763, loss_test: 0.005702
time: 0.256056547164917
time: 2.252392053604126
[1, 7431] loss_train: 0.013125, loss_test: 0.005709
time: 0.24603056907653809
time: 2.230499267578125
[1, 7432] loss_train: 0.003593, loss_test: 0.005715
time: 0.24405407905578613
time: 2.214507579803467
[1, 7433] loss_train: 0.005630, loss_test: 0.005720
time: 0.2450542449951172
time: 2.246518850326538
[1, 7434] loss_train: 0.003567, loss_test: 0.005718
time: 0.24305367469787598
time: 2.2465059757232666
[1, 7435] loss_train: 0.001870, loss_test: 0.005711
time: 0.2450542449951172
time: 2.216496229171753
[1, 7436] loss_train: 0.008231, loss_test: 0.005705
time: 0.24305343627929688
time: 2.229499340057373
[1, 7437] loss_train: 0.003710, loss_test: 0.005701
time: 0.24405360221862793
time: 2.2215118408203125
[1, 7438] loss_train: 0.003201, loss_test: 0.005700
time: 0.24205327033996582
time: 2.228498697280884
[1, 7439] loss_train: 0.007724, loss_test: 0.005701
time: 0.24405455589294434
time: 2.237558126449585
[1, 7440] loss_train: 0.009777, loss_test: 0.005703
time: 0.25905752182006836
time: 2.2164950370788574
[1, 7441] loss_train: 0.004206, loss_test: 0.005706
time: 0.24405956268310547
time: 2.2066097259521484
[1, 7442] loss_train: 0.003045, loss_test: 0.005714
time: 0.24405407905578613
time: 2.2204971313476562
[1, 7443] loss_train: 0.003075, loss_test: 0.005728
time: 0.24505376815795898
time: 2.197491407394409
[1, 7444] loss_train: 0.004139, loss_test: 0.005739
time: 0.25006842613220215
time: 2.2024924755096436
[1, 7445] loss_train: 0.002252, loss_test: 0.005754
time: 0.24405455589294434
time: 2.2395005226135254
[1, 7446] loss_train: 0.024571, loss_test: 0.005753
time: 0.24605512619018555
time: 2.2230403423309326
[1, 7447] loss_train: 0.005137, loss_test: 0.005752
time: 0.24505376815795898
time: 2.216512680053711
[1, 7448] loss_train: 0.011856, loss_test: 0.005748
time: 0.24405336380004883
time: 2.1949994564056396
[1, 7449] loss_train: 0.003110, loss_test: 0.005746
time: 0.24405431747436523
time: 2.228499174118042
[1, 7450] loss_train: 0.006673, loss_test: 0.005731
time: 0.25707030296325684
time: 2.304530620574951
[1, 7451] loss_train: 0.006745, loss_test: 0.005716
time: 0.25406479835510254
time: 2.250525951385498
[1, 7452] loss_train: 0.001708, loss_test: 0.005708
time: 0.24406647682189941
time: 2.2420098781585693
[1, 7453] loss_train: 0.005523, loss_test: 0.005705
time: 0.24355697631835938
time: 2.254504442214966
[1, 7454] loss_train: 0.003751, loss_test: 0.005705
time: 0.24605441093444824
time: 2.2635064125061035
[1, 7455] loss_train: 0.005751, loss_test: 0.005708
time: 0.24305462837219238
time: 2.236499786376953
[1, 7456] loss_train: 0.000839, loss_test: 0.005711
time: 0.2450542449951172
time: 2.2124953269958496
[1, 7457] loss_train: 0.003317, loss_test: 0.005714
time: 0.24505400657653809
time: 2.2175052165985107
[1, 7458] loss_train: 0.002085, loss_test: 0.005718
time: 0.24305391311645508
time: 2.2144949436187744
[1, 7459] loss_train: 0.001715, loss_test: 0.005719
time: 0.24405384063720703
time: 2.203493118286133
[1, 7460] loss_train: 0.003482, loss_test: 0.005721
time: 0.256056547164917
time: 2.2310047149658203
[1, 7461] loss_train: 0.008871, loss_test: 0.005724
time: 0.25505590438842773
time: 2.2645065784454346
[1, 7462] loss_train: 0.002001, loss_test: 0.005728
time: 0.24606728553771973
time: 2.248504638671875
[1, 7463] loss_train: 0.004214, loss_test: 0.005733
time: 0.24405384063720703
time: 2.280510425567627
[1, 7464] loss_train: 0.002801, loss_test: 0.005737
time: 0.24305415153503418
time: 2.2254977226257324
[1, 7465] loss_train: 0.012335, loss_test: 0.005736
time: 0.24405455589294434
time: 2.209493637084961
[1, 7466] loss_train: 0.004867, loss_test: 0.005734
time: 0.2450549602508545
time: 2.2044923305511475
[1, 7467] loss_train: 0.010404, loss_test: 0.005730
time: 0.25005507469177246
time: 2.2044923305511475
[1, 7468] loss_train: 0.013153, loss_test: 0.005729
time: 0.2450542449951172
time: 2.206493854522705
[1, 7469] loss_train: 0.012387, loss_test: 0.005728
time: 0.2470543384552002
time: 2.2314999103546143
[1, 7470] loss_train: 0.004917, loss_test: 0.005726
time: 0.2560567855834961
time: 2.268528461456299
[1, 7471] loss_train: 0.004510, loss_test: 0.005723
time: 0.24805450439453125
time: 2.214498281478882
[1, 7472] loss_train: 0.004301, loss_test: 0.005718
time: 0.24505400657653809
time: 2.2260210514068604
[1, 7473] loss_train: 0.002695, loss_test: 0.005715
time: 0.24306654930114746
time: 2.25451397895813
[1, 7474] loss_train: 0.001097, loss_test: 0.005721
time: 0.2510559558868408
time: 2.23349928855896
[1, 7475] loss_train: 0.004511, loss_test: 0.005736
time: 0.24305415153503418
time: 2.2405004501342773
[1, 7476] loss_train: 0.004880, loss_test: 0.005757
time: 0.24405479431152344
time: 2.235499858856201
[1, 7477] loss_train: 0.011519, loss_test: 0.005764
time: 0.2470543384552002
time: 2.2094945907592773
[1, 7478] loss_train: 0.000658, loss_test: 0.005771
time: 0.24405479431152344
time: 2.226524591445923
[1, 7479] loss_train: 0.015261, loss_test: 0.005738
time: 0.24405479431152344
time: 2.2385027408599854
[1, 7480] loss_train: 0.007067, loss_test: 0.005711
time: 0.25505638122558594
time: 2.270508050918579
[1, 7481] loss_train: 0.007684, loss_test: 0.005694
time: 0.2450542449951172
time: 2.2331371307373047
[1, 7482] loss_train: 0.005386, loss_test: 0.005697
time: 0.24305415153503418
time: 2.214512825012207
[1, 7483] loss_train: 0.002562, loss_test: 0.005712
time: 0.24405431747436523
time: 2.217503070831299
[1, 7484] loss_train: 0.001989, loss_test: 0.005737
time: 0.24605488777160645
time: 2.2104945182800293
[1, 7485] loss_train: 0.005952, loss_test: 0.005747
time: 0.24405455589294434
time: 2.2144949436187744
[1, 7486] loss_train: 0.012712, loss_test: 0.005756
time: 0.2440786361694336
time: 2.2175092697143555
[1, 7487] loss_train: 0.008817, loss_test: 0.005751
time: 0.2450547218322754
time: 2.2064127922058105
[1, 7488] loss_train: 0.005065, loss_test: 0.005741
time: 0.24805521965026855
time: 2.245502471923828
[1, 7489] loss_train: 0.002804, loss_test: 0.005722
time: 0.24505400657653809
time: 2.2305104732513428
[1, 7490] loss_train: 0.006581, loss_test: 0.005710
time: 0.25905776023864746
time: 2.273028612136841
[1, 7491] loss_train: 0.012541, loss_test: 0.005701
time: 0.24405431747436523
time: 2.2224972248077393
[1, 7492] loss_train: 0.008208, loss_test: 0.005697
time: 0.24805450439453125
time: 2.2365005016326904
[1, 7493] loss_train: 0.006211, loss_test: 0.005695
time: 0.2450544834136963
time: 2.2134950160980225
[1, 7494] loss_train: 0.005073, loss_test: 0.005697
time: 0.24605417251586914
time: 2.216496706008911
[1, 7495] loss_train: 0.003447, loss_test: 0.005701
time: 0.24205303192138672
time: 2.213338851928711
[1, 7496] loss_train: 0.006001, loss_test: 0.005705
time: 0.2450547218322754
time: 2.215496778488159
[1, 7497] loss_train: 0.015854, loss_test: 0.005698
time: 0.24305438995361328
time: 2.23502254486084
[1, 7498] loss_train: 0.003773, loss_test: 0.005693
time: 0.24506735801696777
time: 2.237499952316284
[1, 7499] loss_train: 0.002545, loss_test: 0.005690
time: 0.24405431747436523
time: 2.2506449222564697
[1, 7500] loss_train: 0.004934, loss_test: 0.005689
time: 0.2550699710845947
time: 2.2695095539093018
[1, 7501] loss_train: 0.007871, loss_test: 0.005689
time: 0.24305510520935059
time: 2.249507188796997
[1, 7502] loss_train: 0.007345, loss_test: 0.005688
time: 0.24509406089782715
time: 2.2089991569519043
[1, 7503] loss_train: 0.010037, loss_test: 0.005690
time: 0.24305438995361328
time: 2.2264974117279053
[1, 7504] loss_train: 0.010540, loss_test: 0.005702
time: 0.24605441093444824
time: 2.198500156402588
[1, 7505] loss_train: 0.007789, loss_test: 0.005718
time: 0.2450542449951172
time: 2.2043778896331787
[1, 7506] loss_train: 0.004420, loss_test: 0.005733
time: 0.24405384063720703
time: 2.230025053024292
[1, 7507] loss_train: 0.008603, loss_test: 0.005741
time: 0.24505376815795898
time: 2.220496654510498
[1, 7508] loss_train: 0.007070, loss_test: 0.005740
time: 0.24605488777160645
time: 2.2334985733032227
[1, 7509] loss_train: 0.006743, loss_test: 0.005738
time: 0.2510559558868408
time: 2.2435081005096436
[1, 7510] loss_train: 0.008340, loss_test: 0.005731
time: 0.256056547164917
time: 2.2515039443969727
[1, 7511] loss_train: 0.006921, loss_test: 0.005723
time: 0.2540562152862549
time: 2.229498863220215
[1, 7512] loss_train: 0.000966, loss_test: 0.005714
time: 0.24505376815795898
time: 2.217000722885132
[1, 7513] loss_train: 0.005983, loss_test: 0.005708
time: 0.2470548152923584
time: 2.217473030090332
[1, 7514] loss_train: 0.003938, loss_test: 0.005702
time: 0.24805521965026855
time: 2.2655062675476074
[1, 7515] loss_train: 0.005983, loss_test: 0.005702
time: 0.24805545806884766
time: 2.1990342140197754
[1, 7516] loss_train: 0.009495, loss_test: 0.005704
time: 0.24305367469787598
time: 2.226498603820801
[1, 7517] loss_train: 0.014725, loss_test: 0.005705
time: 0.24505376815795898
time: 2.21449613571167
[1, 7518] loss_train: 0.011956, loss_test: 0.005703
time: 0.25305628776550293
time: 2.270451307296753
[1, 7519] loss_train: 0.014420, loss_test: 0.005702
time: 0.24405360221862793
time: 2.194491386413574
[1, 7520] loss_train: 0.007674, loss_test: 0.005702
time: 0.2560572624206543
time: 2.2430570125579834
[1, 7521] loss_train: 0.002237, loss_test: 0.005703
time: 0.24405360221862793
time: 2.241501808166504
[1, 7522] loss_train: 0.005169, loss_test: 0.005703
time: 0.24305391311645508
time: 2.2395005226135254
[1, 7523] loss_train: 0.003428, loss_test: 0.005703
time: 0.24405407905578613
time: 2.2244982719421387
[1, 7524] loss_train: 0.005198, loss_test: 0.005702
time: 0.2470543384552002
time: 2.2294981479644775
[1, 7525] loss_train: 0.013452, loss_test: 0.005700
time: 0.24405431747436523
time: 2.247523784637451
[1, 7526] loss_train: 0.000759, loss_test: 0.005700
time: 0.24305367469787598
time: 2.2350192070007324
[1, 7527] loss_train: 0.004696, loss_test: 0.005700
time: 0.24420428276062012
time: 2.1957075595855713
[1, 7528] loss_train: 0.006352, loss_test: 0.005699
time: 0.24405384063720703
time: 2.207493782043457
[1, 7529] loss_train: 0.003912, loss_test: 0.005699
time: 0.24405503273010254
time: 2.213019847869873
[1, 7530] loss_train: 0.005773, loss_test: 0.005699
time: 0.26105785369873047
time: 2.2209999561309814
[1, 7531] loss_train: 0.002315, loss_test: 0.005699
time: 0.2510554790496826
time: 2.2184648513793945
[1, 7532] loss_train: 0.005075, loss_test: 0.005696
time: 0.2500588893890381
time: 2.231501817703247
[1, 7533] loss_train: 0.003690, loss_test: 0.005696
time: 0.2450547218322754
time: 2.2395007610321045
[1, 7534] loss_train: 0.004314, loss_test: 0.005696
time: 0.24605464935302734
time: 2.251502752304077
[1, 7535] loss_train: 0.003994, loss_test: 0.005698
time: 0.24305415153503418
time: 2.2405166625976562
[1, 7536] loss_train: 0.004703, loss_test: 0.005704
time: 0.24605512619018555
time: 2.2154951095581055
[1, 7537] loss_train: 0.007386, loss_test: 0.005705
time: 0.24405407905578613
time: 2.2443275451660156
[1, 7538] loss_train: 0.005203, loss_test: 0.005703
time: 0.24105310440063477
time: 2.232499837875366
[1, 7539] loss_train: 0.008253, loss_test: 0.005700
time: 0.24305415153503418
time: 2.2044923305511475
[1, 7540] loss_train: 0.004627, loss_test: 0.005698
time: 0.2570302486419678
time: 2.2492434978485107
[1, 7541] loss_train: 0.000723, loss_test: 0.005697
time: 0.2470545768737793
time: 2.205493688583374
[1, 7542] loss_train: 0.011101, loss_test: 0.005695
time: 0.24305343627929688
time: 2.20149564743042
[1, 7543] loss_train: 0.011861, loss_test: 0.005690
time: 0.2450554370880127
time: 2.2403407096862793
[1, 7544] loss_train: 0.004543, loss_test: 0.005686
time: 0.24305486679077148
time: 2.22149658203125
[1, 7545] loss_train: 0.005369, loss_test: 0.005684
time: 0.24405455589294434
time: 2.232499122619629
[1, 7546] loss_train: 0.003196, loss_test: 0.005684
time: 0.24305367469787598
time: 2.230508804321289
[1, 7547] loss_train: 0.000568, loss_test: 0.005685
time: 0.2450544834136963
time: 2.22149920463562
[1, 7548] loss_train: 0.011778, loss_test: 0.005684
time: 0.2470548152923584
time: 2.2164955139160156
[1, 7549] loss_train: 0.010338, loss_test: 0.005681
time: 0.2490556240081787
time: 2.2254974842071533
[1, 7550] loss_train: 0.005199, loss_test: 0.005678
time: 0.25705742835998535
time: 2.272022247314453
[1, 7551] loss_train: 0.009048, loss_test: 0.005677
time: 0.25205540657043457
time: 2.2529258728027344
[1, 7552] loss_train: 0.006936, loss_test: 0.005676
time: 0.24605488777160645
time: 2.222496509552002
[1, 7553] loss_train: 0.008704, loss_test: 0.005677
time: 0.2490551471710205
time: 2.2335000038146973
[1, 7554] loss_train: 0.011446, loss_test: 0.005679
time: 0.24505376815795898
time: 2.2084944248199463
[1, 7555] loss_train: 0.004543, loss_test: 0.005682
time: 0.25005507469177246
time: 2.2205090522766113
[1, 7556] loss_train: 0.001487, loss_test: 0.005689
time: 0.24306201934814453
time: 2.2465145587921143
[1, 7557] loss_train: 0.001390, loss_test: 0.005701
time: 0.24405431747436523
time: 2.216495990753174
[1, 7558] loss_train: 0.005650, loss_test: 0.005710
time: 0.24305343627929688
time: 2.2585229873657227
[1, 7559] loss_train: 0.000526, loss_test: 0.005723
time: 0.24305462837219238
time: 2.2274982929229736
[1, 7560] loss_train: 0.005122, loss_test: 0.005736
time: 0.25691938400268555
time: 2.2725117206573486
[1, 7561] loss_train: 0.007290, loss_test: 0.005727
time: 0.24605488777160645
time: 2.235499858856201
[1, 7562] loss_train: 0.007132, loss_test: 0.005712
time: 0.24405503273010254
time: 2.261056900024414
[1, 7563] loss_train: 0.003376, loss_test: 0.005708
time: 0.2510559558868408
time: 2.3035151958465576
[1, 7564] loss_train: 0.007658, loss_test: 0.005707
time: 0.2530558109283447
time: 2.2144956588745117
[1, 7565] loss_train: 0.008337, loss_test: 0.005703
time: 0.24205398559570312
time: 2.2385008335113525
[1, 7566] loss_train: 0.009114, loss_test: 0.005705
time: 0.24506545066833496
time: 2.2084972858428955
[1, 7567] loss_train: 0.007535, loss_test: 0.005707
time: 0.24606847763061523
time: 2.1924891471862793
[1, 7568] loss_train: 0.006295, loss_test: 0.005709
time: 0.24506735801696777
time: 2.209494113922119
[1, 7569] loss_train: 0.004979, loss_test: 0.005709
time: 0.24605488777160645
time: 2.2425014972686768
[1, 7570] loss_train: 0.015714, loss_test: 0.005719
time: 0.256056547164917
time: 2.2555181980133057
[1, 7571] loss_train: 0.009230, loss_test: 0.005720
time: 0.2430558204650879
time: 2.2525033950805664
[1, 7572] loss_train: 0.004010, loss_test: 0.005718
time: 0.24305486679077148
time: 2.2294979095458984
[1, 7573] loss_train: 0.008152, loss_test: 0.005716
time: 0.24405455589294434
time: 2.2324986457824707
[1, 7574] loss_train: 0.007238, loss_test: 0.005715
time: 0.24405384063720703
time: 2.220531702041626
[1, 7575] loss_train: 0.018810, loss_test: 0.005722
time: 0.24605536460876465
time: 2.215069532394409
[1, 7576] loss_train: 0.005634, loss_test: 0.005723
time: 0.24605631828308105
time: 2.1984920501708984
[1, 7577] loss_train: 0.006955, loss_test: 0.005721
time: 0.24605393409729004
time: 2.216496229171753
[1, 7578] loss_train: 0.008556, loss_test: 0.005715
time: 0.24805474281311035
time: 2.242539882659912
[1, 7579] loss_train: 0.006264, loss_test: 0.005713
time: 0.24606895446777344
time: 2.2135021686553955
[1, 7580] loss_train: 0.010424, loss_test: 0.005714
time: 0.26007080078125
time: 2.265507221221924
[1, 7581] loss_train: 0.007058, loss_test: 0.005716
time: 0.24605369567871094
time: 2.215496063232422
[1, 7582] loss_train: 0.009600, loss_test: 0.005718
time: 0.25005555152893066
time: 2.2525038719177246
[1, 7583] loss_train: 0.004832, loss_test: 0.005718
time: 0.24405479431152344
time: 2.236499786376953
[1, 7584] loss_train: 0.018179, loss_test: 0.005715
time: 0.24505376815795898
time: 2.2455124855041504
[1, 7585] loss_train: 0.004674, loss_test: 0.005713
time: 0.25075769424438477
time: 2.236499786376953
[1, 7586] loss_train: 0.006548, loss_test: 0.005710
time: 0.24407696723937988
time: 2.204519510269165
[1, 7587] loss_train: 0.006715, loss_test: 0.005706
time: 0.2430567741394043
time: 2.217496156692505
[1, 7588] loss_train: 0.006639, loss_test: 0.005703
time: 0.24405384063720703
time: 2.2094967365264893
[1, 7589] loss_train: 0.011458, loss_test: 0.005698
time: 0.24405431747436523
time: 2.2185096740722656
[1, 7590] loss_train: 0.002443, loss_test: 0.005702
time: 0.2560548782348633
time: 2.2375006675720215
[1, 7591] loss_train: 0.010644, loss_test: 0.005709
time: 0.2470557689666748
time: 2.248502492904663
[1, 7592] loss_train: 0.001471, loss_test: 0.005722
time: 0.24805521965026855
time: 2.2435009479522705
[1, 7593] loss_train: 0.005854, loss_test: 0.005734
time: 0.24405384063720703
time: 2.228499174118042
[1, 7594] loss_train: 0.020059, loss_test: 0.005754
time: 0.24505400657653809
time: 2.2385008335113525
[1, 7595] loss_train: 0.011549, loss_test: 0.005761
time: 0.24405455589294434
time: 2.22049617767334
[1, 7596] loss_train: 0.004284, loss_test: 0.005739
time: 0.2450544834136963
time: 2.214524269104004
[1, 7597] loss_train: 0.009933, loss_test: 0.005718
time: 0.24506664276123047
time: 2.2535037994384766
[1, 7598] loss_train: 0.007939, loss_test: 0.005703
time: 0.24305438995361328
time: 2.214505910873413
[1, 7599] loss_train: 0.003909, loss_test: 0.005696
time: 0.25005555152893066
time: 2.2485032081604004
[1, 7600] loss_train: 0.007255, loss_test: 0.005694
time: 0.256056547164917
time: 2.2625064849853516
[1, 7601] loss_train: 0.005575, loss_test: 0.005695
time: 0.2490684986114502
time: 2.2195043563842773
[1, 7602] loss_train: 0.002274, loss_test: 0.005702
time: 0.24505400657653809
time: 2.2655067443847656
[1, 7603] loss_train: 0.004538, loss_test: 0.005709
time: 0.2490553855895996
time: 2.2124948501586914
[1, 7604] loss_train: 0.014719, loss_test: 0.005713
time: 0.24506497383117676
time: 2.2084944248199463
[1, 7605] loss_train: 0.009993, loss_test: 0.005704
time: 0.2470543384552002
time: 2.2715086936950684
[1, 7606] loss_train: 0.003541, loss_test: 0.005700
time: 0.2460193634033203
time: 2.1975083351135254
[1, 7607] loss_train: 0.012993, loss_test: 0.005688
time: 0.2470550537109375
time: 2.245514392852783
[1, 7608] loss_train: 0.003239, loss_test: 0.005684
time: 0.24205350875854492
time: 2.2094943523406982
[1, 7609] loss_train: 0.005171, loss_test: 0.005686
time: 0.24509048461914062
time: 2.2355000972747803
[1, 7610] loss_train: 0.006072, loss_test: 0.005689
time: 0.25705766677856445
time: 2.238511323928833
[1, 7611] loss_train: 0.006870, loss_test: 0.005694
time: 0.24405431747436523
time: 2.2254974842071533
[1, 7612] loss_train: 0.006379, loss_test: 0.005702
time: 0.24405479431152344
time: 2.2154970169067383
[1, 7613] loss_train: 0.004538, loss_test: 0.005708
time: 0.24405360221862793
time: 2.2244980335235596
[1, 7614] loss_train: 0.002803, loss_test: 0.005711
time: 0.24405360221862793
time: 2.2395007610321045
[1, 7615] loss_train: 0.003304, loss_test: 0.005701
time: 0.24405384063720703
time: 2.216031312942505
[1, 7616] loss_train: 0.006734, loss_test: 0.005698
time: 0.24805474281311035
time: 2.196491241455078
[1, 7617] loss_train: 0.005217, loss_test: 0.005701
time: 0.24305987358093262
time: 2.1884891986846924
[1, 7618] loss_train: 0.003847, loss_test: 0.005716
time: 0.2450542449951172
time: 2.24650239944458
[1, 7619] loss_train: 0.001100, loss_test: 0.005742
time: 0.24405884742736816
time: 2.249016761779785
[1, 7620] loss_train: 0.000708, loss_test: 0.005775
time: 0.2580571174621582
time: 2.2615065574645996
[1, 7621] loss_train: 0.004262, loss_test: 0.005807
time: 0.24305391311645508
time: 2.23443865776062
[1, 7622] loss_train: 0.007845, loss_test: 0.005809
time: 0.2490549087524414
time: 2.233499765396118
[1, 7623] loss_train: 0.003473, loss_test: 0.005810
time: 0.2450547218322754
time: 2.196491241455078
[1, 7624] loss_train: 0.005363, loss_test: 0.005807
time: 0.25005555152893066
time: 2.2034928798675537
[1, 7625] loss_train: 0.004135, loss_test: 0.005804
time: 0.24505400657653809
time: 2.179497003555298
[1, 7626] loss_train: 0.015826, loss_test: 0.005763
time: 0.24305367469787598
time: 2.2234973907470703
[1, 7627] loss_train: 0.009657, loss_test: 0.005738
time: 0.24305367469787598
time: 2.2345001697540283
[1, 7628] loss_train: 0.010933, loss_test: 0.005726
time: 0.24405455589294434
time: 2.235499620437622
[1, 7629] loss_train: 0.005671, loss_test: 0.005739
time: 0.24306201934814453
time: 2.2485034465789795
[1, 7630] loss_train: 0.010763, loss_test: 0.005759
time: 0.25305724143981934
time: 2.2494776248931885
[1, 7631] loss_train: 0.005345, loss_test: 0.005766
time: 0.24405455589294434
time: 2.2104945182800293
[1, 7632] loss_train: 0.003611, loss_test: 0.005774
time: 0.24405384063720703
time: 2.2284996509552
[1, 7633] loss_train: 0.002404, loss_test: 0.005760
time: 0.24605441093444824
time: 2.2294981479644775
[1, 7634] loss_train: 0.001156, loss_test: 0.005740
time: 0.24405360221862793
time: 2.2244982719421387
[1, 7635] loss_train: 0.007277, loss_test: 0.005717
time: 0.24305438995361328
time: 2.2030115127563477
[1, 7636] loss_train: 0.007284, loss_test: 0.005703
time: 0.24605488777160645
time: 2.209494113922119
[1, 7637] loss_train: 0.009047, loss_test: 0.005699
time: 0.2490546703338623
time: 2.2335002422332764
[1, 7638] loss_train: 0.004470, loss_test: 0.005709
time: 0.24505376815795898
time: 2.1994924545288086
[1, 7639] loss_train: 0.006975, loss_test: 0.005722
time: 0.24805474281311035
time: 2.2285475730895996
[1, 7640] loss_train: 0.006090, loss_test: 0.005735
time: 0.25705766677856445
time: 2.285400867462158
[1, 7641] loss_train: 0.007706, loss_test: 0.005750
time: 0.24805521965026855
time: 2.210494041442871
[1, 7642] loss_train: 0.008788, loss_test: 0.005769
time: 0.24405384063720703
time: 2.219496965408325
[1, 7643] loss_train: 0.006020, loss_test: 0.005787
time: 0.2450549602508545
time: 2.2335011959075928
[1, 7644] loss_train: 0.012959, loss_test: 0.005793
time: 0.24305343627929688
time: 2.2234978675842285
[1, 7645] loss_train: 0.008065, loss_test: 0.005786
time: 0.24005436897277832
time: 2.2275071144104004
[1, 7646] loss_train: 0.009891, loss_test: 0.005769
time: 0.24205303192138672
time: 2.227499008178711
[1, 7647] loss_train: 0.017044, loss_test: 0.005727
time: 0.2430582046508789
time: 2.206526517868042
[1, 7648] loss_train: 0.005793, loss_test: 0.005701
time: 0.24305272102355957
time: 2.183488607406616
[1, 7649] loss_train: 0.006576, loss_test: 0.005694
time: 0.24606704711914062
time: 2.218508005142212
[1, 7650] loss_train: 0.006401, loss_test: 0.005714
time: 0.2540559768676758
time: 2.268507242202759
[1, 7651] loss_train: 0.004827, loss_test: 0.005746
time: 0.24606728553771973
time: 2.206493854522705
[1, 7652] loss_train: 0.002118, loss_test: 0.005771
time: 0.24405455589294434
time: 2.223496675491333
[1, 7653] loss_train: 0.011409, loss_test: 0.005787
time: 0.24405336380004883
time: 2.2735109329223633
[1, 7654] loss_train: 0.003964, loss_test: 0.005782
time: 0.24405455589294434
time: 2.2134950160980225
[1, 7655] loss_train: 0.011404, loss_test: 0.005764
time: 0.24405455589294434
time: 2.204493284225464
[1, 7656] loss_train: 0.009364, loss_test: 0.005748
time: 0.24709653854370117
time: 2.2475032806396484
[1, 7657] loss_train: 0.006121, loss_test: 0.005730
time: 0.24605488777160645
time: 2.2300498485565186
[1, 7658] loss_train: 0.003887, loss_test: 0.005709
time: 0.24805450439453125
time: 2.243502140045166
[1, 7659] loss_train: 0.004597, loss_test: 0.005696
time: 0.2450547218322754
time: 2.2425196170806885
[1, 7660] loss_train: 0.002652, loss_test: 0.005685
time: 0.2580575942993164
time: 2.2630386352539062
[1, 7661] loss_train: 0.004721, loss_test: 0.005683
time: 0.24605464935302734
time: 2.207493305206299
[1, 7662] loss_train: 0.004806, loss_test: 0.005694
time: 0.2470548152923584
time: 2.207493305206299
[1, 7663] loss_train: 0.012594, loss_test: 0.005705
time: 0.24305462837219238
time: 2.2184953689575195
[1, 7664] loss_train: 0.006288, loss_test: 0.005718
time: 0.24405431747436523
time: 2.207502603530884
[1, 7665] loss_train: 0.006223, loss_test: 0.005724
time: 0.24305415153503418
time: 2.2125084400177
[1, 7666] loss_train: 0.008763, loss_test: 0.005727
time: 0.24405407905578613
time: 2.2104971408843994
[1, 7667] loss_train: 0.010001, loss_test: 0.005720
time: 0.24505996704101562
time: 2.232501745223999
[1, 7668] loss_train: 0.009381, loss_test: 0.005707
time: 0.24305415153503418
time: 2.2274978160858154
[1, 7669] loss_train: 0.004381, loss_test: 0.005701
time: 0.24405384063720703
time: 2.2365102767944336
[1, 7670] loss_train: 0.014052, loss_test: 0.005703
time: 0.25505685806274414
time: 2.2505033016204834
[1, 7671] loss_train: 0.005245, loss_test: 0.005713
time: 0.24605488777160645
time: 2.247504472732544
[1, 7672] loss_train: 0.004825, loss_test: 0.005723
time: 0.24305343627929688
time: 2.210493803024292
[1, 7673] loss_train: 0.006082, loss_test: 0.005728
time: 0.2450549602508545
time: 2.196491003036499
[1, 7674] loss_train: 0.002272, loss_test: 0.005727
time: 0.2470548152923584
time: 2.2124972343444824
[1, 7675] loss_train: 0.009029, loss_test: 0.005721
time: 0.25006771087646484
time: 2.2044928073883057
[1, 7676] loss_train: 0.006141, loss_test: 0.005712
time: 0.24505400657653809
time: 2.233499050140381
[1, 7677] loss_train: 0.011226, loss_test: 0.005709
time: 0.2470548152923584
time: 2.2215068340301514
[1, 7678] loss_train: 0.012218, loss_test: 0.005703
time: 0.24305462837219238
time: 2.22049617767334
[1, 7679] loss_train: 0.008784, loss_test: 0.005708
time: 0.24305319786071777
time: 2.2080066204071045
[1, 7680] loss_train: 0.007074, loss_test: 0.005715
time: 0.25505733489990234
time: 2.250502824783325
[1, 7681] loss_train: 0.002542, loss_test: 0.005716
time: 0.24606657028198242
time: 2.2254977226257324
[1, 7682] loss_train: 0.006133, loss_test: 0.005715
time: 0.24305486679077148
time: 2.231501579284668
[1, 7683] loss_train: 0.007140, loss_test: 0.005712
time: 0.24305367469787598
time: 2.23449969291687
[1, 7684] loss_train: 0.007401, loss_test: 0.005708
time: 0.2450547218322754
time: 2.2285146713256836
[1, 7685] loss_train: 0.007279, loss_test: 0.005702
time: 0.24506115913391113
time: 2.2224977016448975
[1, 7686] loss_train: 0.002902, loss_test: 0.005698
time: 0.24405479431152344
time: 2.190500497817993
[1, 7687] loss_train: 0.005284, loss_test: 0.005696
time: 0.24305367469787598
time: 2.227498769760132
[1, 7688] loss_train: 0.004493, loss_test: 0.005697
time: 0.24605488777160645
time: 2.1830251216888428
[1, 7689] loss_train: 0.006706, loss_test: 0.005702
time: 0.24405360221862793
time: 2.251007080078125
[1, 7690] loss_train: 0.002767, loss_test: 0.005712
time: 0.27006053924560547
time: 2.2765088081359863
[1, 7691] loss_train: 0.006593, loss_test: 0.005724
time: 0.24405455589294434
time: 2.203493118286133
[1, 7692] loss_train: 0.006362, loss_test: 0.005733
time: 0.2490558624267578
time: 2.234003782272339
[1, 7693] loss_train: 0.000559, loss_test: 0.005745
time: 0.24405455589294434
time: 2.2224984169006348
[1, 7694] loss_train: 0.005223, loss_test: 0.005757
time: 0.2470569610595703
time: 2.235499620437622
[1, 7695] loss_train: 0.004309, loss_test: 0.005769
time: 0.24605512619018555
time: 2.2435014247894287
[1, 7696] loss_train: 0.003257, loss_test: 0.005769
time: 0.24805521965026855
time: 2.2347512245178223
[1, 7697] loss_train: 0.009343, loss_test: 0.005756
time: 0.24305343627929688
time: 2.192267894744873
[1, 7698] loss_train: 0.014828, loss_test: 0.005720
time: 0.24405360221862793
time: 2.2125048637390137
[1, 7699] loss_train: 0.005251, loss_test: 0.005704
time: 0.24507904052734375
time: 2.209494113922119
[1, 7700] loss_train: 0.005306, loss_test: 0.005722
time: 0.25505661964416504
time: 2.2625060081481934
[1, 7701] loss_train: 0.005817, loss_test: 0.005757
time: 0.24405479431152344
time: 2.248502016067505
[1, 7702] loss_train: 0.008398, loss_test: 0.005785
time: 0.24405431747436523
time: 2.23349928855896
[1, 7703] loss_train: 0.010698, loss_test: 0.005799
time: 0.2450547218322754
time: 2.256504774093628
[1, 7704] loss_train: 0.005988, loss_test: 0.005788
time: 0.24205327033996582
time: 2.247518301010132
[1, 7705] loss_train: 0.005828, loss_test: 0.005771
time: 0.24405360221862793
time: 2.241501808166504
[1, 7706] loss_train: 0.006204, loss_test: 0.005753
time: 0.24918818473815918
time: 2.2640128135681152
[1, 7707] loss_train: 0.006397, loss_test: 0.005732
time: 0.24506688117980957
time: 2.224497079849243
[1, 7708] loss_train: 0.012524, loss_test: 0.005717
time: 0.2470548152923584
time: 2.240501642227173
[1, 7709] loss_train: 0.003244, loss_test: 0.005702
time: 0.24406838417053223
time: 2.2515032291412354
[1, 7710] loss_train: 0.005347, loss_test: 0.005692
time: 0.25505757331848145
time: 2.2495028972625732
[1, 7711] loss_train: 0.011047, loss_test: 0.005687
time: 0.24305415153503418
time: 2.208493709564209
[1, 7712] loss_train: 0.010852, loss_test: 0.005683
time: 0.24405407905578613
time: 2.231499433517456
[1, 7713] loss_train: 0.007318, loss_test: 0.005681
time: 0.24305367469787598
time: 2.219496726989746
[1, 7714] loss_train: 0.012433, loss_test: 0.005680
time: 0.24509596824645996
time: 2.229499101638794
[1, 7715] loss_train: 0.013378, loss_test: 0.005679
time: 0.24605417251586914
time: 2.2515201568603516
[1, 7716] loss_train: 0.007350, loss_test: 0.005677
time: 0.24506783485412598
time: 2.2295095920562744
[1, 7717] loss_train: 0.006362, loss_test: 0.005677
time: 0.24407029151916504
time: 2.2124948501586914
[1, 7718] loss_train: 0.003161, loss_test: 0.005679
time: 0.2450547218322754
time: 2.2274980545043945
[1, 7719] loss_train: 0.001919, loss_test: 0.005682
time: 0.24805641174316406
time: 2.2115161418914795
[1, 7720] loss_train: 0.006041, loss_test: 0.005685
time: 0.256070613861084
time: 2.262505531311035
[1, 7721] loss_train: 0.009580, loss_test: 0.005687
time: 0.2510557174682617
time: 2.230499029159546
[1, 7722] loss_train: 0.007127, loss_test: 0.005688
time: 0.24305343627929688
time: 2.232499837875366
[1, 7723] loss_train: 0.010018, loss_test: 0.005690
time: 0.2470564842224121
time: 2.228498935699463
[1, 7724] loss_train: 0.009010, loss_test: 0.005691
time: 0.24405360221862793
time: 2.2214996814727783
[1, 7725] loss_train: 0.003452, loss_test: 0.005692
time: 0.24505376815795898
time: 2.1934914588928223
[1, 7726] loss_train: 0.004007, loss_test: 0.005693
time: 0.24405360221862793
time: 2.2255008220672607
[1, 7727] loss_train: 0.006753, loss_test: 0.005689
time: 0.24305415153503418
time: 2.229498863220215
[1, 7728] loss_train: 0.002117, loss_test: 0.005689
time: 0.24306821823120117
time: 2.250502824783325
[1, 7729] loss_train: 0.011542, loss_test: 0.005686
time: 0.24305343627929688
time: 2.230511426925659
[1, 7730] loss_train: 0.006055, loss_test: 0.005684
time: 0.25406336784362793
time: 2.2144973278045654
[1, 7731] loss_train: 0.005716, loss_test: 0.005681
time: 0.2450544834136963
time: 2.218001127243042
[1, 7732] loss_train: 0.020810, loss_test: 0.005678
time: 0.24805474281311035
time: 2.206998586654663
[1, 7733] loss_train: 0.013064, loss_test: 0.005682
time: 0.24405503273010254
time: 2.189488410949707
[1, 7734] loss_train: 0.006390, loss_test: 0.005690
time: 0.24605536460876465
time: 2.1759910583496094
[1, 7735] loss_train: 0.008335, loss_test: 0.005702
time: 0.24509382247924805
time: 2.232525110244751
[1, 7736] loss_train: 0.009495, loss_test: 0.005713
time: 0.24805450439453125
time: 2.241501569747925
[1, 7737] loss_train: 0.017206, loss_test: 0.005716
time: 0.24805712699890137
time: 2.232499122619629
[1, 7738] loss_train: 0.002494, loss_test: 0.005711
time: 0.24605417251586914
time: 2.219496965408325
[1, 7739] loss_train: 0.004670, loss_test: 0.005695
time: 0.24805498123168945
time: 2.2370216846466064
[1, 7740] loss_train: 0.008628, loss_test: 0.005678
time: 0.25505614280700684
time: 2.2420060634613037
[1, 7741] loss_train: 0.007380, loss_test: 0.005670
time: 0.24805593490600586
time: 2.247501850128174
[1, 7742] loss_train: 0.001959, loss_test: 0.005663
time: 0.24510812759399414
time: 2.24704647064209
[1, 7743] loss_train: 0.012177, loss_test: 0.005662
time: 0.24305248260498047
time: 2.243501663208008
[1, 7744] loss_train: 0.006521, loss_test: 0.005665
time: 0.24205350875854492
time: 2.2435011863708496
[1, 7745] loss_train: 0.009793, loss_test: 0.005666
time: 0.23905324935913086
time: 2.202510356903076
[1, 7746] loss_train: 0.010942, loss_test: 0.005666
time: 0.24605464935302734
time: 2.2190029621124268
[1, 7747] loss_train: 0.006022, loss_test: 0.005665
time: 0.24305486679077148
time: 2.2164976596832275
[1, 7748] loss_train: 0.006967, loss_test: 0.005666
time: 0.2470545768737793
time: 2.2505056858062744
[1, 7749] loss_train: 0.006550, loss_test: 0.005665
time: 0.2450547218322754
time: 2.2184953689575195
[1, 7750] loss_train: 0.006840, loss_test: 0.005665
time: 0.25505757331848145
time: 2.217510938644409
[1, 7751] loss_train: 0.002523, loss_test: 0.005668
time: 0.2450542449951172
time: 2.206493377685547
[1, 7752] loss_train: 0.001421, loss_test: 0.005668
time: 0.24305462837219238
time: 2.232499122619629
[1, 7753] loss_train: 0.010968, loss_test: 0.005669
time: 0.25005626678466797
time: 2.219496011734009
[1, 7754] loss_train: 0.003140, loss_test: 0.005670
time: 0.24405455589294434
time: 2.2264978885650635
[1, 7755] loss_train: 0.008488, loss_test: 0.005670
time: 0.25005602836608887
time: 2.2195138931274414
[1, 7756] loss_train: 0.002590, loss_test: 0.005670
time: 0.24405479431152344
time: 2.193490505218506
[1, 7757] loss_train: 0.014995, loss_test: 0.005669
time: 0.24605417251586914
time: 2.229931592941284
[1, 7758] loss_train: 0.004177, loss_test: 0.005668
time: 0.24405455589294434
time: 2.2184958457946777
[1, 7759] loss_train: 0.006205, loss_test: 0.005668
time: 0.24405360221862793
time: 2.225512742996216
[1, 7760] loss_train: 0.007499, loss_test: 0.005669
time: 0.2560572624206543
time: 2.2805094718933105
[1, 7761] loss_train: 0.010359, loss_test: 0.005670
time: 0.24405574798583984
time: 2.2555036544799805
[1, 7762] loss_train: 0.007447, loss_test: 0.005670
time: 0.2450551986694336
time: 2.2264974117279053
[1, 7763] loss_train: 0.004860, loss_test: 0.005673
time: 0.25005507469177246
time: 2.2450058460235596
[1, 7764] loss_train: 0.008335, loss_test: 0.005676
time: 0.24406862258911133
time: 2.2334980964660645
[1, 7765] loss_train: 0.006932, loss_test: 0.005679
time: 0.24305415153503418
time: 2.235522985458374
[1, 7766] loss_train: 0.004003, loss_test: 0.005684
time: 0.24406671524047852
time: 2.229498863220215
[1, 7767] loss_train: 0.004336, loss_test: 0.005687
time: 0.24605512619018555
time: 2.2515037059783936
[1, 7768] loss_train: 0.003579, loss_test: 0.005689
time: 0.24410271644592285
time: 2.2254977226257324
[1, 7769] loss_train: 0.004180, loss_test: 0.005690
time: 0.24405455589294434
time: 2.194324016571045
[1, 7770] loss_train: 0.006233, loss_test: 0.005690
time: 0.2560544013977051
time: 2.2184970378875732
[1, 7771] loss_train: 0.010739, loss_test: 0.005691
time: 0.2490544319152832
time: 2.228498935699463
[1, 7772] loss_train: 0.007182, loss_test: 0.005693
time: 0.24505949020385742
time: 2.257504463195801
[1, 7773] loss_train: 0.001651, loss_test: 0.005698
time: 0.24405384063720703
time: 2.2004926204681396
[1, 7774] loss_train: 0.003434, loss_test: 0.005701
time: 0.2490551471710205
time: 2.2185113430023193
[1, 7775] loss_train: 0.003398, loss_test: 0.005705
time: 0.24805521965026855
time: 2.2234976291656494
[1, 7776] loss_train: 0.013214, loss_test: 0.005705
time: 0.2490546703338623
time: 2.2385034561157227
[1, 7777] loss_train: 0.002324, loss_test: 0.005708
time: 0.24605488777160645
time: 2.233499765396118
[1, 7778] loss_train: 0.008836, loss_test: 0.005706
time: 0.2490546703338623
time: 2.2255094051361084
[1, 7779] loss_train: 0.002970, loss_test: 0.005704
time: 0.24605417251586914
time: 2.2014925479888916
[1, 7780] loss_train: 0.007139, loss_test: 0.005698
time: 0.25806283950805664
time: 2.2665138244628906
[1, 7781] loss_train: 0.001842, loss_test: 0.005695
time: 0.24305462837219238
time: 2.1994919776916504
[1, 7782] loss_train: 0.007736, loss_test: 0.005692
time: 0.2440650463104248
time: 2.228001356124878
[1, 7783] loss_train: 0.010875, loss_test: 0.005692
time: 0.24305367469787598
time: 2.219496726989746
[1, 7784] loss_train: 0.005332, loss_test: 0.005694
time: 0.24405384063720703
time: 2.2385175228118896
[1, 7785] loss_train: 0.008508, loss_test: 0.005697
time: 0.24405407905578613
time: 2.2495038509368896
[1, 7786] loss_train: 0.003503, loss_test: 0.005697
time: 0.24353742599487305
time: 2.1974916458129883
[1, 7787] loss_train: 0.003694, loss_test: 0.005699
time: 0.2440662384033203
time: 2.2210006713867188
[1, 7788] loss_train: 0.001762, loss_test: 0.005703
time: 0.24507880210876465
time: 2.2256553173065186
[1, 7789] loss_train: 0.006444, loss_test: 0.005706
time: 0.24005341529846191
time: 2.206517219543457
[1, 7790] loss_train: 0.004491, loss_test: 0.005707
time: 0.25705766677856445
time: 2.2665085792541504
[1, 7791] loss_train: 0.005314, loss_test: 0.005713
time: 0.25305652618408203
time: 2.2264981269836426
[1, 7792] loss_train: 0.007523, loss_test: 0.005718
time: 0.24305319786071777
time: 2.228499174118042
[1, 7793] loss_train: 0.004466, loss_test: 0.005721
time: 0.24306774139404297
time: 2.2114977836608887
[1, 7794] loss_train: 0.011646, loss_test: 0.005715
time: 0.24505376815795898
time: 2.216496229171753
[1, 7795] loss_train: 0.005837, loss_test: 0.005713
time: 0.2490549087524414
time: 2.19649338722229
[1, 7796] loss_train: 0.003344, loss_test: 0.005715
time: 0.24505352973937988
time: 2.2385005950927734
[1, 7797] loss_train: 0.002829, loss_test: 0.005719
time: 0.2470545768737793
time: 2.2124953269958496
[1, 7798] loss_train: 0.006012, loss_test: 0.005723
time: 0.2450542449951172
time: 2.1931281089782715
[1, 7799] loss_train: 0.002460, loss_test: 0.005730
time: 0.24405431747436523
time: 2.2325010299682617
[1, 7800] loss_train: 0.012586, loss_test: 0.005725
time: 0.25505638122558594
time: 2.2545042037963867
[1, 7801] loss_train: 0.007181, loss_test: 0.005719
time: 0.24205350875854492
time: 2.228498935699463
[1, 7802] loss_train: 0.009526, loss_test: 0.005708
time: 0.24305319786071777
time: 2.2004921436309814
[1, 7803] loss_train: 0.002424, loss_test: 0.005700
time: 0.24305415153503418
time: 2.2244973182678223
[1, 7804] loss_train: 0.005548, loss_test: 0.005693
time: 0.24505400657653809
time: 2.2130186557769775
[1, 7805] loss_train: 0.002816, loss_test: 0.005690
time: 0.2450549602508545
time: 2.224496841430664
[1, 7806] loss_train: 0.005189, loss_test: 0.005689
time: 0.24506831169128418
time: 2.212512731552124
[1, 7807] loss_train: 0.002790, loss_test: 0.005688
time: 0.24405384063720703
time: 2.2224974632263184
[1, 7808] loss_train: 0.005103, loss_test: 0.005689
time: 0.24505400657653809
time: 2.230515718460083
[1, 7809] loss_train: 0.006928, loss_test: 0.005691
time: 0.24405407905578613
time: 2.2204971313476562
[1, 7810] loss_train: 0.002123, loss_test: 0.005692
time: 0.26105761528015137
time: 2.2465031147003174
[1, 7811] loss_train: 0.002722, loss_test: 0.005694
time: 0.24305391311645508
time: 2.2224972248077393
[1, 7812] loss_train: 0.008522, loss_test: 0.005693
time: 0.25005602836608887
time: 2.2455015182495117
[1, 7813] loss_train: 0.002108, loss_test: 0.005693
time: 0.24305415153503418
time: 2.2164952754974365
[1, 7814] loss_train: 0.002303, loss_test: 0.005693
time: 0.24805474281311035
time: 2.244504928588867
[1, 7815] loss_train: 0.005090, loss_test: 0.005694
time: 0.24305391311645508
time: 2.2445015907287598
[1, 7816] loss_train: 0.005442, loss_test: 0.005697
time: 0.24406695365905762
time: 2.2150113582611084
[1, 7817] loss_train: 0.011008, loss_test: 0.005695
time: 0.24406743049621582
time: 2.226001024246216
[1, 7818] loss_train: 0.009110, loss_test: 0.005691
time: 0.24305343627929688
time: 2.1964921951293945
[1, 7819] loss_train: 0.001266, loss_test: 0.005689
time: 0.2450544834136963
time: 2.195490598678589
[1, 7820] loss_train: 0.003810, loss_test: 0.005688
time: 0.2560572624206543
time: 2.2635064125061035
[1, 7821] loss_train: 0.007677, loss_test: 0.005687
time: 0.24505376815795898
time: 2.218496561050415
[1, 7822] loss_train: 0.016429, loss_test: 0.005685
time: 0.2450542449951172
time: 2.2389943599700928
[1, 7823] loss_train: 0.005911, loss_test: 0.005683
time: 0.24505400657653809
time: 2.2517096996307373
[1, 7824] loss_train: 0.007105, loss_test: 0.005683
time: 0.24405455589294434
time: 2.211494207382202
[1, 7825] loss_train: 0.004906, loss_test: 0.005684
time: 0.24405431747436523
time: 2.191490411758423
[1, 7826] loss_train: 0.003154, loss_test: 0.005684
time: 0.2450544834136963
time: 2.2174954414367676
[1, 7827] loss_train: 0.000691, loss_test: 0.005685
time: 0.25105738639831543
time: 2.248588800430298
[1, 7828] loss_train: 0.003678, loss_test: 0.005686
time: 0.24808192253112793
time: 2.2244973182678223
[1, 7829] loss_train: 0.007594, loss_test: 0.005688
time: 0.25505709648132324
time: 2.2525036334991455
[1, 7830] loss_train: 0.006376, loss_test: 0.005692
time: 0.2560701370239258
time: 2.2575206756591797
[1, 7831] loss_train: 0.005910, loss_test: 0.005694
time: 0.24806785583496094
time: 2.195491313934326
[1, 7832] loss_train: 0.004628, loss_test: 0.005696
time: 0.2450547218322754
time: 2.2294986248016357
[1, 7833] loss_train: 0.013306, loss_test: 0.005690
time: 0.2510552406311035
time: 2.2034945487976074
[1, 7834] loss_train: 0.001005, loss_test: 0.005688
time: 0.24506664276123047
time: 2.240502119064331
[1, 7835] loss_train: 0.003106, loss_test: 0.005688
time: 0.24609827995300293
time: 2.2385010719299316
[1, 7836] loss_train: 0.008673, loss_test: 0.005689
time: 0.24305367469787598
time: 2.2445032596588135
[1, 7837] loss_train: 0.003428, loss_test: 0.005692
time: 0.24305248260498047
time: 2.2214975357055664
[1, 7838] loss_train: 0.011528, loss_test: 0.005694
time: 0.2430713176727295
time: 2.218496084213257
[1, 7839] loss_train: 0.003722, loss_test: 0.005696
time: 0.24706768989562988
time: 2.228511333465576
[1, 7840] loss_train: 0.009189, loss_test: 0.005696
time: 0.2540562152862549
time: 2.257535934448242
[1, 7841] loss_train: 0.006418, loss_test: 0.005696
time: 0.24405479431152344
time: 2.2445015907287598
[1, 7842] loss_train: 0.007315, loss_test: 0.005696
time: 0.2450544834136963
time: 2.23349928855896
[1, 7843] loss_train: 0.003634, loss_test: 0.005697
time: 0.24405479431152344
time: 2.1884918212890625
[1, 7844] loss_train: 0.001587, loss_test: 0.005699
time: 0.24405407905578613
time: 2.2064931392669678
[1, 7845] loss_train: 0.006075, loss_test: 0.005699
time: 0.24405455589294434
time: 2.208684206008911
[1, 7846] loss_train: 0.008774, loss_test: 0.005695
time: 0.2450542449951172
time: 2.218496322631836
[1, 7847] loss_train: 0.006626, loss_test: 0.005690
time: 0.24605417251586914
time: 2.2415099143981934
[1, 7848] loss_train: 0.003146, loss_test: 0.005684
time: 0.24605417251586914
time: 2.2244977951049805
[1, 7849] loss_train: 0.000919, loss_test: 0.005682
time: 0.24405550956726074
time: 2.237501382827759
[1, 7850] loss_train: 0.005230, loss_test: 0.005681
time: 0.26105785369873047
time: 2.2401256561279297
[1, 7851] loss_train: 0.009807, loss_test: 0.005683
time: 0.2450542449951172
time: 2.2385005950927734
[1, 7852] loss_train: 0.001513, loss_test: 0.005689
time: 0.2490682601928711
time: 2.2475016117095947
[1, 7853] loss_train: 0.014275, loss_test: 0.005693
time: 0.2450549602508545
time: 2.2435009479522705
[1, 7854] loss_train: 0.012803, loss_test: 0.005694
time: 0.2470557689666748
time: 2.245502471923828
[1, 7855] loss_train: 0.004556, loss_test: 0.005694
time: 0.24405360221862793
time: 2.2119996547698975
[1, 7856] loss_train: 0.004480, loss_test: 0.005693
time: 0.24605488777160645
time: 2.2365174293518066
[1, 7857] loss_train: 0.005202, loss_test: 0.005692
time: 0.24405217170715332
time: 2.232499599456787
[1, 7858] loss_train: 0.003376, loss_test: 0.005693
time: 0.24405407905578613
time: 2.192490577697754
[1, 7859] loss_train: 0.002358, loss_test: 0.005697
time: 0.24505400657653809
time: 2.2345104217529297
[1, 7860] loss_train: 0.008807, loss_test: 0.005704
time: 0.256056547164917
time: 2.2540342807769775
[1, 7861] loss_train: 0.007146, loss_test: 0.005706
time: 0.24305295944213867
time: 2.2485573291778564
[1, 7862] loss_train: 0.008529, loss_test: 0.005700
time: 0.24305391311645508
time: 2.2254977226257324
[1, 7863] loss_train: 0.002148, loss_test: 0.005696
time: 0.24505400657653809
time: 2.223496913909912
[1, 7864] loss_train: 0.006436, loss_test: 0.005693
time: 0.24306631088256836
time: 2.21049427986145
[1, 7865] loss_train: 0.003595, loss_test: 0.005693
time: 0.2440662384033203
time: 2.2220122814178467
[1, 7866] loss_train: 0.015007, loss_test: 0.005693
time: 0.24805545806884766
time: 2.212496519088745
[1, 7867] loss_train: 0.008683, loss_test: 0.005698
time: 0.24405431747436523
time: 2.2023966312408447
[1, 7868] loss_train: 0.004655, loss_test: 0.005703
time: 0.2450547218322754
time: 2.2024917602539062
[1, 7869] loss_train: 0.013900, loss_test: 0.005705
time: 0.2490699291229248
time: 2.2170088291168213
[1, 7870] loss_train: 0.005023, loss_test: 0.005702
time: 0.256056547164917
time: 2.2365005016326904
[1, 7871] loss_train: 0.002474, loss_test: 0.005701
time: 0.2540562152862549
time: 2.22149920463562
[1, 7872] loss_train: 0.002857, loss_test: 0.005700
time: 0.24405407905578613
time: 2.220496654510498
[1, 7873] loss_train: 0.001212, loss_test: 0.005700
time: 0.25005483627319336
time: 2.232499837875366
[1, 7874] loss_train: 0.014826, loss_test: 0.005706
time: 0.24405407905578613
time: 2.2365005016326904
[1, 7875] loss_train: 0.009628, loss_test: 0.005719
time: 0.24405336380004883
time: 2.228498935699463
[1, 7876] loss_train: 0.007853, loss_test: 0.005727
time: 0.2450551986694336
time: 2.2345263957977295
[1, 7877] loss_train: 0.003704, loss_test: 0.005733
time: 0.24805474281311035
time: 2.2274985313415527
[1, 7878] loss_train: 0.002553, loss_test: 0.005740
time: 0.24405455589294434
time: 2.2034926414489746
[1, 7879] loss_train: 0.004391, loss_test: 0.005738
time: 0.24305343627929688
time: 2.2234978675842285
[1, 7880] loss_train: 0.004894, loss_test: 0.005735
time: 0.25705742835998535
time: 2.2545039653778076
[1, 7881] loss_train: 0.013337, loss_test: 0.005730
time: 0.24306583404541016
time: 2.2084944248199463
[1, 7882] loss_train: 0.010284, loss_test: 0.005726
time: 0.24405360221862793
time: 2.2034947872161865
[1, 7883] loss_train: 0.002615, loss_test: 0.005730
time: 0.2450547218322754
time: 2.2224972248077393
[1, 7884] loss_train: 0.004441, loss_test: 0.005747
time: 0.24305391311645508
time: 2.206494092941284
[1, 7885] loss_train: 0.011750, loss_test: 0.005771
time: 0.24205398559570312
time: 2.2165191173553467
[1, 7886] loss_train: 0.003410, loss_test: 0.005799
time: 0.2490551471710205
time: 2.233499526977539
[1, 7887] loss_train: 0.003649, loss_test: 0.005826
time: 0.24405455589294434
time: 2.232515811920166
[1, 7888] loss_train: 0.008183, loss_test: 0.005846
time: 0.2490684986114502
time: 2.2204976081848145
[1, 7889] loss_train: 0.005642, loss_test: 0.005853
time: 0.2450544834136963
time: 2.2315175533294678
[1, 7890] loss_train: 0.002892, loss_test: 0.005812
time: 0.2630579471588135
time: 2.256507635116577
[1, 7891] loss_train: 0.008106, loss_test: 0.005741
time: 0.24305415153503418
time: 2.219496488571167
[1, 7892] loss_train: 0.007611, loss_test: 0.005704
time: 0.24805521965026855
time: 2.2120001316070557
[1, 7893] loss_train: 0.003725, loss_test: 0.005687
time: 0.24405384063720703
time: 2.2124953269958496
[1, 7894] loss_train: 0.008492, loss_test: 0.005685
time: 0.2430591583251953
time: 2.2314987182617188
[1, 7895] loss_train: 0.008144, loss_test: 0.005685
time: 0.24406671524047852
time: 2.2505040168762207
[1, 7896] loss_train: 0.007292, loss_test: 0.005691
time: 0.2450547218322754
time: 2.224496841430664
[1, 7897] loss_train: 0.003253, loss_test: 0.005703
time: 0.24405479431152344
time: 2.2014923095703125
[1, 7898] loss_train: 0.001357, loss_test: 0.005720
time: 0.24306344985961914
time: 2.2094943523406982
[1, 7899] loss_train: 0.006112, loss_test: 0.005732
time: 0.24605464935302734
time: 2.2134950160980225
[1, 7900] loss_train: 0.008413, loss_test: 0.005741
time: 0.257066011428833
time: 2.231003522872925
[1, 7901] loss_train: 0.006010, loss_test: 0.005738
time: 0.2450547218322754
time: 2.232499599456787
[1, 7902] loss_train: 0.007648, loss_test: 0.005732
time: 0.24306106567382812
time: 2.205493688583374
[1, 7903] loss_train: 0.005361, loss_test: 0.005713
time: 0.2470543384552002
time: 2.1854891777038574
[1, 7904] loss_train: 0.004325, loss_test: 0.005698
time: 0.24606728553771973
time: 2.217012882232666
[1, 7905] loss_train: 0.003647, loss_test: 0.005685
time: 0.2470545768737793
time: 2.2104949951171875
[1, 7906] loss_train: 0.003049, loss_test: 0.005679
time: 0.2450544834136963
time: 2.2230544090270996
[1, 7907] loss_train: 0.001082, loss_test: 0.005679
time: 0.24205422401428223
time: 2.2294983863830566
[1, 7908] loss_train: 0.007100, loss_test: 0.005684
time: 0.24358820915222168
time: 2.22200083732605
[1, 7909] loss_train: 0.009562, loss_test: 0.005687
time: 0.24405384063720703
time: 2.214524984359741
[1, 7910] loss_train: 0.001531, loss_test: 0.005696
time: 0.25505638122558594
time: 2.2385008335113525
[1, 7911] loss_train: 0.006832, loss_test: 0.005703
time: 0.24405431747436523
time: 2.2214975357055664
[1, 7912] loss_train: 0.004968, loss_test: 0.005711
time: 0.24405360221862793
time: 2.217501640319824
[1, 7913] loss_train: 0.004391, loss_test: 0.005713
time: 0.24405431747436523
time: 2.2274985313415527
[1, 7914] loss_train: 0.004169, loss_test: 0.005715
time: 0.24405455589294434
time: 2.2184948921203613
[1, 7915] loss_train: 0.009452, loss_test: 0.005712
time: 0.2450554370880127
time: 2.18548846244812
[1, 7916] loss_train: 0.004540, loss_test: 0.005708
time: 0.24405336380004883
time: 2.193842887878418
[1, 7917] loss_train: 0.008104, loss_test: 0.005704
time: 0.24506711959838867
time: 2.20849347114563
[1, 7918] loss_train: 0.003315, loss_test: 0.005702
time: 0.2540559768676758
time: 2.2395191192626953
[1, 7919] loss_train: 0.006983, loss_test: 0.005701
time: 0.24405503273010254
time: 2.213494300842285
[1, 7920] loss_train: 0.008246, loss_test: 0.005698
time: 0.25705695152282715
time: 2.2225122451782227
[1, 7921] loss_train: 0.009203, loss_test: 0.005696
time: 0.24505376815795898
time: 2.2144954204559326
[1, 7922] loss_train: 0.007533, loss_test: 0.005695
time: 0.24405479431152344
time: 2.197491407394409
[1, 7923] loss_train: 0.007426, loss_test: 0.005695
time: 0.24405407905578613
time: 2.2144954204559326
[1, 7924] loss_train: 0.003978, loss_test: 0.005696
time: 0.24405407905578613
time: 2.2075064182281494
[1, 7925] loss_train: 0.006577, loss_test: 0.005697
time: 0.2470555305480957
time: 2.2254974842071533
[1, 7926] loss_train: 0.005956, loss_test: 0.005698
time: 0.2470545768737793
time: 2.2575340270996094
[1, 7927] loss_train: 0.001393, loss_test: 0.005701
time: 0.2450544834136963
time: 2.2164974212646484
[1, 7928] loss_train: 0.001991, loss_test: 0.005707
time: 0.24305438995361328
time: 2.196491241455078
[1, 7929] loss_train: 0.005462, loss_test: 0.005717
time: 0.24405407905578613
time: 2.2475028038024902
[1, 7930] loss_train: 0.001875, loss_test: 0.005729
time: 0.25505638122558594
time: 2.2094948291778564
[1, 7931] loss_train: 0.007192, loss_test: 0.005732
time: 0.2510552406311035
time: 2.2505054473876953
[1, 7932] loss_train: 0.013706, loss_test: 0.005724
time: 0.2450566291809082
time: 2.2264981269836426
[1, 7933] loss_train: 0.002849, loss_test: 0.005720
time: 0.2490553855895996
time: 2.23249888420105
[1, 7934] loss_train: 0.004557, loss_test: 0.005719
time: 0.24405384063720703
time: 2.2214975357055664
[1, 7935] loss_train: 0.007208, loss_test: 0.005715
time: 0.25305652618408203
time: 2.2294983863830566
[1, 7936] loss_train: 0.005592, loss_test: 0.005711
time: 0.2450544834136963
time: 2.206827402114868
[1, 7937] loss_train: 0.004506, loss_test: 0.005710
time: 0.24405431747436523
time: 2.229513645172119
[1, 7938] loss_train: 0.005478, loss_test: 0.005709
time: 0.24406647682189941
time: 2.230498790740967
[1, 7939] loss_train: 0.002842, loss_test: 0.005710
time: 0.24481797218322754
time: 2.247502326965332
[1, 7940] loss_train: 0.002327, loss_test: 0.005708
time: 0.25505638122558594
time: 2.266526222229004
[1, 7941] loss_train: 0.005402, loss_test: 0.005710
time: 0.24406743049621582
time: 2.21049427986145
[1, 7942] loss_train: 0.006659, loss_test: 0.005711
time: 0.24605441093444824
time: 2.235499620437622
[1, 7943] loss_train: 0.004729, loss_test: 0.005714
time: 0.24305510520935059
time: 2.2114951610565186
[1, 7944] loss_train: 0.004705, loss_test: 0.005715
time: 0.2450544834136963
time: 2.2234973907470703
[1, 7945] loss_train: 0.003218, loss_test: 0.005716
time: 0.24605417251586914
time: 2.2395012378692627
[1, 7946] loss_train: 0.003907, loss_test: 0.005719
time: 0.24405455589294434
time: 2.2265119552612305
[1, 7947] loss_train: 0.006208, loss_test: 0.005721
time: 0.24405407905578613
time: 2.2495028972625732
[1, 7948] loss_train: 0.003382, loss_test: 0.005723
time: 0.24405407905578613
time: 2.2801926136016846
[1, 7949] loss_train: 0.007285, loss_test: 0.005722
time: 0.24605441093444824
time: 2.243501901626587
[1, 7950] loss_train: 0.000816, loss_test: 0.005724
time: 0.25705695152282715
time: 2.2495033740997314
[1, 7951] loss_train: 0.004967, loss_test: 0.005725
time: 0.24505400657653809
time: 2.2365005016326904
[1, 7952] loss_train: 0.020307, loss_test: 0.005700
time: 0.2510559558868408
time: 2.2294986248016357
[1, 7953] loss_train: 0.004780, loss_test: 0.005690
time: 0.24505376815795898
time: 2.2164957523345947
[1, 7954] loss_train: 0.007043, loss_test: 0.005690
time: 0.24405455589294434
time: 2.231498956680298
[1, 7955] loss_train: 0.003941, loss_test: 0.005696
time: 0.24405360221862793
time: 2.2355422973632812
[1, 7956] loss_train: 0.004066, loss_test: 0.005706
time: 0.25305628776550293
time: 2.2134950160980225
[1, 7957] loss_train: 0.009810, loss_test: 0.005720
time: 0.2450547218322754
time: 2.2314987182617188
[1, 7958] loss_train: 0.004980, loss_test: 0.005725
time: 0.2490556240081787
time: 2.243502140045166
[1, 7959] loss_train: 0.005780, loss_test: 0.005734
time: 0.24505400657653809
time: 2.2480177879333496
[1, 7960] loss_train: 0.002749, loss_test: 0.005740
time: 0.25906944274902344
time: 2.2615063190460205
[1, 7961] loss_train: 0.003458, loss_test: 0.005724
time: 0.24405479431152344
time: 2.2170345783233643
[1, 7962] loss_train: 0.004478, loss_test: 0.005708
time: 0.25305652618408203
time: 2.2645061016082764
[1, 7963] loss_train: 0.003630, loss_test: 0.005700
time: 0.2450542449951172
time: 2.2295053005218506
[1, 7964] loss_train: 0.008359, loss_test: 0.005694
time: 0.2490544319152832
time: 2.1954925060272217
[1, 7965] loss_train: 0.006368, loss_test: 0.005689
time: 0.24406671524047852
time: 2.2175192832946777
[1, 7966] loss_train: 0.010539, loss_test: 0.005687
time: 0.2450547218322754
time: 2.1975221633911133
[1, 7967] loss_train: 0.009619, loss_test: 0.005683
time: 0.24405455589294434
time: 2.2835121154785156
[1, 7968] loss_train: 0.008551, loss_test: 0.005677
time: 0.2450554370880127
time: 2.2164971828460693
[1, 7969] loss_train: 0.005132, loss_test: 0.005676
time: 0.2450547218322754
time: 2.2515034675598145
[1, 7970] loss_train: 0.005580, loss_test: 0.005675
time: 0.2560575008392334
time: 2.272507905960083
[1, 7971] loss_train: 0.000559, loss_test: 0.005677
time: 0.24305438995361328
time: 2.227524995803833
[1, 7972] loss_train: 0.002512, loss_test: 0.005681
time: 0.24305391311645508
time: 2.2335093021392822
[1, 7973] loss_train: 0.005465, loss_test: 0.005685
time: 0.24305391311645508
time: 2.2144954204559326
[1, 7974] loss_train: 0.004735, loss_test: 0.005690
time: 0.24305343627929688
time: 2.2495033740997314
[1, 7975] loss_train: 0.006076, loss_test: 0.005695
time: 0.2450551986694336
time: 2.221496343612671
[1, 7976] loss_train: 0.001854, loss_test: 0.005702
time: 0.2470688819885254
time: 2.236499786376953
[1, 7977] loss_train: 0.000902, loss_test: 0.005711
time: 0.24405407905578613
time: 2.2104952335357666
[1, 7978] loss_train: 0.005869, loss_test: 0.005713
time: 0.24405312538146973
time: 2.2551941871643066
[1, 7979] loss_train: 0.010977, loss_test: 0.005710
time: 0.24505376815795898
time: 2.2225189208984375
[1, 7980] loss_train: 0.011197, loss_test: 0.005702
time: 0.2560570240020752
time: 2.257505178451538
[1, 7981] loss_train: 0.005025, loss_test: 0.005695
time: 0.24305391311645508
time: 2.2164957523345947
[1, 7982] loss_train: 0.005648, loss_test: 0.005688
time: 0.24505400657653809
time: 2.2365007400512695
[1, 7983] loss_train: 0.005638, loss_test: 0.005683
time: 0.2450547218322754
time: 2.2024919986724854
[1, 7984] loss_train: 0.004784, loss_test: 0.005681
time: 0.2450549602508545
time: 2.244501829147339
[1, 7985] loss_train: 0.014135, loss_test: 0.005672
time: 0.24805593490600586
time: 2.223001480102539
[1, 7986] loss_train: 0.010429, loss_test: 0.005676
time: 0.24405384063720703
time: 2.2515039443969727
[1, 7987] loss_train: 0.001865, loss_test: 0.005685
time: 0.2490553855895996
time: 2.239520311355591
[1, 7988] loss_train: 0.007631, loss_test: 0.005696
time: 0.24506640434265137
time: 2.2264983654022217
[1, 7989] loss_train: 0.004375, loss_test: 0.005703
time: 0.2490556240081787
time: 2.184502363204956
[1, 7990] loss_train: 0.005343, loss_test: 0.005693
time: 0.2630581855773926
time: 2.265507221221924
[1, 7991] loss_train: 0.008874, loss_test: 0.005684
time: 0.24805474281311035
time: 2.203509569168091
[1, 7992] loss_train: 0.016899, loss_test: 0.005681
time: 0.24505352973937988
time: 2.1944916248321533
[1, 7993] loss_train: 0.015662, loss_test: 0.005677
time: 0.24805450439453125
time: 2.231515884399414
[1, 7994] loss_train: 0.021241, loss_test: 0.005672
time: 0.2440805435180664
time: 2.20949387550354
[1, 7995] loss_train: 0.009501, loss_test: 0.005669
time: 0.24406671524047852
time: 2.257507085800171
[1, 7996] loss_train: 0.006359, loss_test: 0.005667
time: 0.24405384063720703
time: 2.2455027103424072
[1, 7997] loss_train: 0.001854, loss_test: 0.005665
time: 0.24205350875854492
time: 2.241502046585083
[1, 7998] loss_train: 0.001760, loss_test: 0.005664
time: 0.24408674240112305
time: 2.214495897293091
[1, 7999] loss_train: 0.008485, loss_test: 0.005663
time: 0.24556612968444824
time: 2.258516550064087
[1, 8000] loss_train: 0.014001, loss_test: 0.005663
time: 0.2580573558807373
time: 2.2855117321014404
[1, 8001] loss_train: 0.008038, loss_test: 0.005663
time: 0.24605512619018555
time: 2.2294983863830566
[1, 8002] loss_train: 0.009404, loss_test: 0.005662
time: 0.24405431747436523
time: 2.20949387550354
[1, 8003] loss_train: 0.005356, loss_test: 0.005663
time: 0.24305319786071777
time: 2.2144951820373535
[1, 8004] loss_train: 0.000939, loss_test: 0.005664
time: 0.24406743049621582
time: 2.2099976539611816
[1, 8005] loss_train: 0.002975, loss_test: 0.005665
time: 0.2450563907623291
time: 2.203495740890503
[1, 8006] loss_train: 0.017926, loss_test: 0.005667
time: 0.2490546703338623
time: 2.229499340057373
[1, 8007] loss_train: 0.006313, loss_test: 0.005669
time: 0.25005507469177246
time: 2.2395007610321045
[1, 8008] loss_train: 0.006082, loss_test: 0.005667
time: 0.2490556240081787
time: 2.2495033740997314
[1, 8009] loss_train: 0.007432, loss_test: 0.005666
time: 0.24605512619018555
time: 2.2385001182556152
[1, 8010] loss_train: 0.007130, loss_test: 0.005667
time: 0.26105833053588867
time: 2.2685253620147705
[1, 8011] loss_train: 0.012231, loss_test: 0.005671
time: 0.24605464935302734
time: 2.230498790740967
[1, 8012] loss_train: 0.005378, loss_test: 0.005675
time: 0.2470548152923584
time: 2.2440102100372314
[1, 8013] loss_train: 0.011856, loss_test: 0.005671
time: 0.24405431747436523
time: 2.2154951095581055
[1, 8014] loss_train: 0.005727, loss_test: 0.005672
time: 0.25005578994750977
time: 2.2124955654144287
[1, 8015] loss_train: 0.007594, loss_test: 0.005672
time: 0.24405527114868164
time: 2.2455027103424072
[1, 8016] loss_train: 0.012376, loss_test: 0.005675
time: 0.24405479431152344
time: 2.2034926414489746
[1, 8017] loss_train: 0.003409, loss_test: 0.005679
time: 0.2510552406311035
time: 2.1954915523529053
[1, 8018] loss_train: 0.003753, loss_test: 0.005682
time: 0.24308037757873535
time: 2.228583574295044
[1, 8019] loss_train: 0.006163, loss_test: 0.005684
time: 0.24305438995361328
time: 2.2375001907348633
[1, 8020] loss_train: 0.001936, loss_test: 0.005688
time: 0.256056547164917
time: 2.2806575298309326
[1, 8021] loss_train: 0.015469, loss_test: 0.005688
time: 0.24505400657653809
time: 2.217496156692505
[1, 8022] loss_train: 0.009537, loss_test: 0.005687
time: 0.2450544834136963
time: 2.24200701713562
[1, 8023] loss_train: 0.013607, loss_test: 0.005684
time: 0.24505305290222168
time: 2.2515087127685547
[1, 8024] loss_train: 0.002890, loss_test: 0.005683
time: 0.2450551986694336
time: 2.203702926635742
[1, 8025] loss_train: 0.011933, loss_test: 0.005683
time: 0.2450542449951172
time: 2.2074942588806152
[1, 8026] loss_train: 0.001707, loss_test: 0.005683
time: 0.24605488777160645
time: 2.2124946117401123
[1, 8027] loss_train: 0.003109, loss_test: 0.005682
time: 0.24505400657653809
time: 2.234499216079712
[1, 8028] loss_train: 0.011324, loss_test: 0.005680
time: 0.24405455589294434
time: 2.227829694747925
[1, 8029] loss_train: 0.004037, loss_test: 0.005676
time: 0.24805569648742676
time: 2.221496343612671
[1, 8030] loss_train: 0.006229, loss_test: 0.005672
time: 0.2560703754425049
time: 2.2515034675598145
[1, 8031] loss_train: 0.003807, loss_test: 0.005668
time: 0.2510688304901123
time: 2.2505033016204834
[1, 8032] loss_train: 0.007008, loss_test: 0.005667
time: 0.24405336380004883
time: 2.2285094261169434
[1, 8033] loss_train: 0.001567, loss_test: 0.005669
time: 0.24805450439453125
time: 2.2445015907287598
[1, 8034] loss_train: 0.003504, loss_test: 0.005678
time: 0.2460935115814209
time: 2.2425100803375244
[1, 8035] loss_train: 0.010900, loss_test: 0.005680
time: 0.24806761741638184
time: 2.23249888420105
[1, 8036] loss_train: 0.003818, loss_test: 0.005684
time: 0.24405479431152344
time: 2.271524667739868
[1, 8037] loss_train: 0.004726, loss_test: 0.005686
time: 0.24805426597595215
time: 2.2264978885650635
[1, 8038] loss_train: 0.016595, loss_test: 0.005682
time: 0.24305438995361328
time: 2.20804762840271
[1, 8039] loss_train: 0.005819, loss_test: 0.005681
time: 0.24405431747436523
time: 2.22049617767334
[1, 8040] loss_train: 0.000769, loss_test: 0.005683
time: 0.2560575008392334
time: 2.235504150390625
[1, 8041] loss_train: 0.010521, loss_test: 0.005680
time: 0.24405431747436523
time: 2.2054951190948486
[1, 8042] loss_train: 0.005877, loss_test: 0.005677
time: 0.24405407905578613
time: 2.203493356704712
[1, 8043] loss_train: 0.008781, loss_test: 0.005675
time: 0.24305438995361328
time: 2.2445011138916016
[1, 8044] loss_train: 0.006869, loss_test: 0.005673
time: 0.2470550537109375
time: 2.2535040378570557
[1, 8045] loss_train: 0.010428, loss_test: 0.005666
time: 0.2450563907623291
time: 2.2465028762817383
[1, 8046] loss_train: 0.005324, loss_test: 0.005664
time: 0.24205398559570312
time: 2.2375004291534424
[1, 8047] loss_train: 0.005822, loss_test: 0.005663
time: 0.2450549602508545
time: 2.25250244140625
[1, 8048] loss_train: 0.012350, loss_test: 0.005662
time: 0.24605464935302734
time: 2.1914901733398438
[1, 8049] loss_train: 0.001905, loss_test: 0.005662
time: 0.24456548690795898
time: 2.204493284225464
[1, 8050] loss_train: 0.009914, loss_test: 0.005662
time: 0.2560570240020752
time: 2.219496250152588
[1, 8051] loss_train: 0.012914, loss_test: 0.005662
time: 0.2520561218261719
time: 2.2064931392669678
[1, 8052] loss_train: 0.005764, loss_test: 0.005661
time: 0.25305604934692383
time: 2.2432785034179688
[1, 8053] loss_train: 0.003753, loss_test: 0.005661
time: 0.24513506889343262
time: 2.2475175857543945
[1, 8054] loss_train: 0.003118, loss_test: 0.005660
time: 0.2510561943054199
time: 2.283510208129883
[1, 8055] loss_train: 0.003910, loss_test: 0.005659
time: 0.24506759643554688
time: 2.2014925479888916
[1, 8056] loss_train: 0.005262, loss_test: 0.005659
time: 0.2490549087524414
time: 2.230499267578125
[1, 8057] loss_train: 0.003906, loss_test: 0.005658
time: 0.24605488777160645
time: 2.222496747970581
[1, 8058] loss_train: 0.010394, loss_test: 0.005657
time: 0.24805498123168945
time: 2.2365002632141113
[1, 8059] loss_train: 0.006369, loss_test: 0.005657
time: 0.24405407905578613
time: 2.231518507003784
[1, 8060] loss_train: 0.015009, loss_test: 0.005661
time: 0.2580573558807373
time: 2.2685070037841797
[1, 8061] loss_train: 0.012554, loss_test: 0.005665
time: 0.24405455589294434
time: 2.2415037155151367
[1, 8062] loss_train: 0.003269, loss_test: 0.005672
time: 0.2470545768737793
time: 2.233501434326172
[1, 8063] loss_train: 0.006158, loss_test: 0.005678
time: 0.24307584762573242
time: 2.224498748779297
[1, 8064] loss_train: 0.002864, loss_test: 0.005684
time: 0.24805402755737305
time: 2.229499340057373
[1, 8065] loss_train: 0.003400, loss_test: 0.005691
time: 0.24405360221862793
time: 2.257718324661255
[1, 8066] loss_train: 0.002235, loss_test: 0.005698
time: 0.24505376815795898
time: 2.201998472213745
[1, 8067] loss_train: 0.004634, loss_test: 0.005704
time: 0.24405455589294434
time: 2.2324986457824707
[1, 8068] loss_train: 0.013775, loss_test: 0.005707
time: 0.24605488777160645
time: 2.2192749977111816
[1, 8069] loss_train: 0.004288, loss_test: 0.005707
time: 0.24405384063720703
time: 2.2674343585968018
[1, 8070] loss_train: 0.012667, loss_test: 0.005700
time: 0.2580687999725342
time: 2.2595086097717285
[1, 8071] loss_train: 0.010518, loss_test: 0.005694
time: 0.2450547218322754
time: 2.2182445526123047
[1, 8072] loss_train: 0.004448, loss_test: 0.005686
time: 0.24305367469787598
time: 2.24251389503479
[1, 8073] loss_train: 0.009862, loss_test: 0.005676
time: 0.2450544834136963
time: 2.219496250152588
[1, 8074] loss_train: 0.003542, loss_test: 0.005667
time: 0.2450551986694336
time: 2.183074474334717
[1, 8075] loss_train: 0.009733, loss_test: 0.005663
time: 0.24405384063720703
time: 2.2114953994750977
[1, 8076] loss_train: 0.004822, loss_test: 0.005661
time: 0.2440662384033203
time: 2.1934902667999268
[1, 8077] loss_train: 0.010363, loss_test: 0.005661
time: 0.2490549087524414
time: 2.215496063232422
[1, 8078] loss_train: 0.007580, loss_test: 0.005663
time: 0.2470545768737793
time: 2.2325024604797363
[1, 8079] loss_train: 0.003061, loss_test: 0.005666
time: 0.2470548152923584
time: 2.2174954414367676
[1, 8080] loss_train: 0.004322, loss_test: 0.005670
time: 0.25505733489990234
time: 2.2475030422210693
[1, 8081] loss_train: 0.008377, loss_test: 0.005677
time: 0.2470543384552002
time: 2.2225306034088135
[1, 8082] loss_train: 0.005291, loss_test: 0.005688
time: 0.2450544834136963
time: 2.2034928798675537
[1, 8083] loss_train: 0.010722, loss_test: 0.005697
time: 0.24405431747436523
time: 2.191507577896118
[1, 8084] loss_train: 0.001174, loss_test: 0.005705
time: 0.24405407905578613
time: 2.2254974842071533
[1, 8085] loss_train: 0.007123, loss_test: 0.005712
time: 0.24805617332458496
time: 2.20749568939209
[1, 8086] loss_train: 0.001741, loss_test: 0.005718
time: 0.2430555820465088
time: 2.2165122032165527
[1, 8087] loss_train: 0.007692, loss_test: 0.005721
time: 0.24505400657653809
time: 2.2064943313598633
[1, 8088] loss_train: 0.005948, loss_test: 0.005723
time: 0.24405360221862793
time: 2.229498863220215
[1, 8089] loss_train: 0.006043, loss_test: 0.005725
time: 0.24505400657653809
time: 2.242502212524414
[1, 8090] loss_train: 0.013134, loss_test: 0.005719
time: 0.25705742835998535
time: 2.2265076637268066
[1, 8091] loss_train: 0.007651, loss_test: 0.005715
time: 0.2470550537109375
time: 2.2334983348846436
[1, 8092] loss_train: 0.003368, loss_test: 0.005710
time: 0.2470555305480957
time: 2.232510566711426
[1, 8093] loss_train: 0.001465, loss_test: 0.005707
time: 0.2450547218322754
time: 2.230499029159546
[1, 8094] loss_train: 0.009844, loss_test: 0.005699
time: 0.24905610084533691
time: 2.230498790740967
[1, 8095] loss_train: 0.013279, loss_test: 0.005696
time: 0.24505352973937988
time: 2.231499671936035
[1, 8096] loss_train: 0.002214, loss_test: 0.005692
time: 0.24706745147705078
time: 2.244502067565918
[1, 8097] loss_train: 0.007153, loss_test: 0.005691
time: 0.24405407905578613
time: 2.247511625289917
[1, 8098] loss_train: 0.006427, loss_test: 0.005691
time: 0.2470543384552002
time: 2.2355005741119385
[1, 8099] loss_train: 0.006007, loss_test: 0.005692
time: 0.24405384063720703
time: 2.2135071754455566
[1, 8100] loss_train: 0.012049, loss_test: 0.005691
time: 0.25705647468566895
time: 2.267507791519165
[1, 8101] loss_train: 0.007622, loss_test: 0.005692
time: 0.24505400657653809
time: 2.243502140045166
[1, 8102] loss_train: 0.002318, loss_test: 0.005690
time: 0.2450542449951172
time: 2.229498863220215
[1, 8103] loss_train: 0.008124, loss_test: 0.005687
time: 0.24505352973937988
time: 2.230499505996704
[1, 8104] loss_train: 0.007623, loss_test: 0.005683
time: 0.24206185340881348
time: 2.2244906425476074
[1, 8105] loss_train: 0.004562, loss_test: 0.005680
time: 0.2490553855895996
time: 2.2304985523223877
[1, 8106] loss_train: 0.007743, loss_test: 0.005676
time: 0.2445991039276123
time: 2.24550199508667
[1, 8107] loss_train: 0.004654, loss_test: 0.005674
time: 0.24405479431152344
time: 2.2515029907226562
[1, 8108] loss_train: 0.007071, loss_test: 0.005674
time: 0.24405479431152344
time: 2.220370292663574
[1, 8109] loss_train: 0.007098, loss_test: 0.005675
time: 0.24505400657653809
time: 2.19850492477417
[1, 8110] loss_train: 0.002812, loss_test: 0.005678
time: 0.25505685806274414
time: 2.247502326965332
[1, 8111] loss_train: 0.008926, loss_test: 0.005684
time: 0.24306678771972656
time: 2.217496633529663
[1, 8112] loss_train: 0.009561, loss_test: 0.005683
time: 0.24605393409729004
time: 2.2104949951171875
[1, 8113] loss_train: 0.003752, loss_test: 0.005682
time: 0.2470543384552002
time: 2.2114951610565186
[1, 8114] loss_train: 0.012222, loss_test: 0.005681
time: 0.24506735801696777
time: 2.2154948711395264
[1, 8115] loss_train: 0.003328, loss_test: 0.005681
time: 0.25008177757263184
time: 2.225497245788574
[1, 8116] loss_train: 0.004706, loss_test: 0.005681
time: 0.24405407905578613
time: 2.2084944248199463
[1, 8117] loss_train: 0.006873, loss_test: 0.005684
time: 0.2490556240081787
time: 2.248502731323242
[1, 8118] loss_train: 0.007804, loss_test: 0.005690
time: 0.24505376815795898
time: 2.2049636840820312
[1, 8119] loss_train: 0.004293, loss_test: 0.005699
time: 0.2470550537109375
time: 2.206512451171875
[1, 8120] loss_train: 0.000542, loss_test: 0.005713
time: 0.2550685405731201
time: 2.2475030422210693
[1, 8121] loss_train: 0.006456, loss_test: 0.005720
time: 0.24405431747436523
time: 2.231499195098877
[1, 8122] loss_train: 0.003519, loss_test: 0.005723
time: 0.2490553855895996
time: 2.274510622024536
[1, 8123] loss_train: 0.003430, loss_test: 0.005727
time: 0.24205398559570312
time: 2.192490816116333
[1, 8124] loss_train: 0.005866, loss_test: 0.005729
time: 0.24405431747436523
time: 2.1865081787109375
[1, 8125] loss_train: 0.009858, loss_test: 0.005720
time: 0.24405384063720703
time: 2.241501569747925
[1, 8126] loss_train: 0.009946, loss_test: 0.005705
time: 0.24405455589294434
time: 2.2245137691497803
[1, 8127] loss_train: 0.007152, loss_test: 0.005698
time: 0.24405360221862793
time: 2.219496965408325
[1, 8128] loss_train: 0.006988, loss_test: 0.005698
time: 0.24306654930114746
time: 2.198543071746826
[1, 8129] loss_train: 0.003590, loss_test: 0.005701
time: 0.24606704711914062
time: 2.1805179119110107
[1, 8130] loss_train: 0.011449, loss_test: 0.005705
time: 0.25905776023864746
time: 2.254504919052124
[1, 8131] loss_train: 0.004235, loss_test: 0.005703
time: 0.24405431747436523
time: 2.2264978885650635
[1, 8132] loss_train: 0.006613, loss_test: 0.005700
time: 0.2490553855895996
time: 2.24550199508667
[1, 8133] loss_train: 0.003592, loss_test: 0.005695
time: 0.24406719207763672
time: 2.210493564605713
[1, 8134] loss_train: 0.002284, loss_test: 0.005686
time: 0.2490553855895996
time: 2.2108852863311768
[1, 8135] loss_train: 0.001489, loss_test: 0.005682
time: 0.24405384063720703
time: 2.1984920501708984
[1, 8136] loss_train: 0.003811, loss_test: 0.005687
time: 0.24505376815795898
time: 2.206512689590454
[1, 8137] loss_train: 0.005071, loss_test: 0.005696
time: 0.24305415153503418
time: 2.22149658203125
[1, 8138] loss_train: 0.003955, loss_test: 0.005708
time: 0.24505400657653809
time: 2.2125136852264404
[1, 8139] loss_train: 0.009462, loss_test: 0.005713
time: 0.2450573444366455
time: 2.217496395111084
[1, 8140] loss_train: 0.001586, loss_test: 0.005719
time: 0.2560572624206543
time: 2.2665066719055176
[1, 8141] loss_train: 0.011870, loss_test: 0.005711
time: 0.2450542449951172
time: 2.2304983139038086
[1, 8142] loss_train: 0.008504, loss_test: 0.005696
time: 0.24309301376342773
time: 2.235501527786255
[1, 8143] loss_train: 0.013653, loss_test: 0.005683
time: 0.24406647682189941
time: 2.1934902667999268
[1, 8144] loss_train: 0.002951, loss_test: 0.005679
time: 0.24405455589294434
time: 2.2154953479766846
[1, 8145] loss_train: 0.005067, loss_test: 0.005680
time: 0.24506855010986328
time: 2.1984918117523193
[1, 8146] loss_train: 0.010651, loss_test: 0.005684
time: 0.24406695365905762
time: 2.188490152359009
[1, 8147] loss_train: 0.004441, loss_test: 0.005690
time: 0.24806642532348633
time: 2.2165074348449707
[1, 8148] loss_train: 0.017983, loss_test: 0.005694
time: 0.24405407905578613
time: 2.1964914798736572
[1, 8149] loss_train: 0.001529, loss_test: 0.005698
time: 0.24405407905578613
time: 2.213006019592285
[1, 8150] loss_train: 0.005911, loss_test: 0.005701
time: 0.2560560703277588
time: 2.2405035495758057
[1, 8151] loss_train: 0.008723, loss_test: 0.005698
time: 0.24505400657653809
time: 2.2094945907592773
[1, 8152] loss_train: 0.014628, loss_test: 0.005695
time: 0.24305391311645508
time: 2.227498769760132
[1, 8153] loss_train: 0.002979, loss_test: 0.005682
time: 0.24405455589294434
time: 2.244501829147339
[1, 8154] loss_train: 0.006389, loss_test: 0.005667
time: 0.24405503273010254
time: 2.21551251411438
[1, 8155] loss_train: 0.002046, loss_test: 0.005663
time: 0.24405431747436523
time: 2.2154953479766846
[1, 8156] loss_train: 0.007630, loss_test: 0.005668
time: 0.24305391311645508
time: 2.2246408462524414
[1, 8157] loss_train: 0.005521, loss_test: 0.005682
time: 0.2480611801147461
time: 2.2425029277801514
[1, 8158] loss_train: 0.007974, loss_test: 0.005704
time: 0.24505400657653809
time: 2.2134954929351807
[1, 8159] loss_train: 0.015966, loss_test: 0.005703
time: 0.24258208274841309
time: 2.204493522644043
[1, 8160] loss_train: 0.004903, loss_test: 0.005701
time: 0.256056547164917
time: 2.2295374870300293
[1, 8161] loss_train: 0.001609, loss_test: 0.005703
time: 0.2450547218322754
time: 2.2264978885650635
[1, 8162] loss_train: 0.010171, loss_test: 0.005693
time: 0.252056360244751
time: 2.214503049850464
[1, 8163] loss_train: 0.005224, loss_test: 0.005686
time: 0.24605417251586914
time: 2.228499174118042
[1, 8164] loss_train: 0.009583, loss_test: 0.005676
time: 0.25005555152893066
time: 2.2224974632263184
[1, 8165] loss_train: 0.008535, loss_test: 0.005669
time: 0.24405336380004883
time: 2.2102720737457275
[1, 8166] loss_train: 0.005951, loss_test: 0.005667
time: 0.24205327033996582
time: 2.2345004081726074
[1, 8167] loss_train: 0.007524, loss_test: 0.005666
time: 0.24505400657653809
time: 2.2175087928771973
[1, 8168] loss_train: 0.005638, loss_test: 0.005670
time: 0.24305486679077148
time: 2.2405006885528564
[1, 8169] loss_train: 0.018977, loss_test: 0.005674
time: 0.24305462837219238
time: 2.250540256500244
[1, 8170] loss_train: 0.002092, loss_test: 0.005676
time: 0.25707006454467773
time: 2.2665061950683594
[1, 8171] loss_train: 0.008043, loss_test: 0.005679
time: 0.24405407905578613
time: 2.2094945907592773
[1, 8172] loss_train: 0.006200, loss_test: 0.005681
time: 0.24505400657653809
time: 2.2365007400512695
[1, 8173] loss_train: 0.011928, loss_test: 0.005679
time: 0.24405360221862793
time: 2.246502637863159
[1, 8174] loss_train: 0.002181, loss_test: 0.005677
time: 0.2540557384490967
time: 2.2355027198791504
[1, 8175] loss_train: 0.007327, loss_test: 0.005677
time: 0.24505376815795898
time: 2.260505437850952
[1, 8176] loss_train: 0.018478, loss_test: 0.005682
time: 0.24405431747436523
time: 2.217496156692505
[1, 8177] loss_train: 0.001616, loss_test: 0.005687
time: 0.2450547218322754
time: 2.2545223236083984
[1, 8178] loss_train: 0.005098, loss_test: 0.005696
time: 0.2490553855895996
time: 2.2625064849853516
[1, 8179] loss_train: 0.007043, loss_test: 0.005710
time: 0.24305343627929688
time: 2.247504711151123
[1, 8180] loss_train: 0.008853, loss_test: 0.005722
time: 0.25905656814575195
time: 2.2875123023986816
[1, 8181] loss_train: 0.008349, loss_test: 0.005724
time: 0.24505376815795898
time: 2.241511344909668
[1, 8182] loss_train: 0.003399, loss_test: 0.005725
time: 0.24405503273010254
time: 2.235511064529419
[1, 8183] loss_train: 0.008199, loss_test: 0.005715
time: 0.24305438995361328
time: 2.2074930667877197
[1, 8184] loss_train: 0.003110, loss_test: 0.005711
time: 0.24505400657653809
time: 2.2014925479888916
[1, 8185] loss_train: 0.009913, loss_test: 0.005708
time: 0.24205350875854492
time: 2.211493492126465
[1, 8186] loss_train: 0.007483, loss_test: 0.005701
time: 0.2450542449951172
time: 2.2124948501586914
[1, 8187] loss_train: 0.004249, loss_test: 0.005696
time: 0.2520558834075928
time: 2.205493211746216
[1, 8188] loss_train: 0.004559, loss_test: 0.005695
time: 0.24606704711914062
time: 2.248502731323242
[1, 8189] loss_train: 0.006520, loss_test: 0.005696
time: 0.2510554790496826
time: 2.2595057487487793
[1, 8190] loss_train: 0.001730, loss_test: 0.005696
time: 0.25705718994140625
time: 2.2340073585510254
[1, 8191] loss_train: 0.012268, loss_test: 0.005695
time: 0.2540557384490967
time: 2.2315022945404053
[1, 8192] loss_train: 0.009682, loss_test: 0.005695
time: 0.24405360221862793
time: 2.254504680633545
[1, 8193] loss_train: 0.010056, loss_test: 0.005696
time: 0.24605393409729004
time: 2.2194957733154297
[1, 8194] loss_train: 0.007162, loss_test: 0.005698
time: 0.2500574588775635
time: 2.195490598678589
[1, 8195] loss_train: 0.006612, loss_test: 0.005699
time: 0.24505376815795898
time: 2.203493595123291
[1, 8196] loss_train: 0.006861, loss_test: 0.005699
time: 0.24305438995361328
time: 2.2274978160858154
[1, 8197] loss_train: 0.006495, loss_test: 0.005698
time: 0.24305391311645508
time: 2.1909990310668945
[1, 8198] loss_train: 0.003367, loss_test: 0.005697
time: 0.2490549087524414
time: 2.203493118286133
[1, 8199] loss_train: 0.006380, loss_test: 0.005698
time: 0.24305415153503418
time: 2.236499786376953
[1, 8200] loss_train: 0.010843, loss_test: 0.005700
time: 0.25505733489990234
time: 2.2507596015930176
[1, 8201] loss_train: 0.002465, loss_test: 0.005704
time: 0.24305438995361328
time: 2.232517719268799
[1, 8202] loss_train: 0.008293, loss_test: 0.005705
time: 0.24205398559570312
time: 2.248013496398926
[1, 8203] loss_train: 0.006572, loss_test: 0.005705
time: 0.24305415153503418
time: 2.2134947776794434
[1, 8204] loss_train: 0.002733, loss_test: 0.005707
time: 0.2450711727142334
time: 2.2124972343444824
[1, 8205] loss_train: 0.005148, loss_test: 0.005713
time: 0.2490544319152832
time: 2.221496820449829
[1, 8206] loss_train: 0.005518, loss_test: 0.005718
time: 0.2490556240081787
time: 2.195491075515747
[1, 8207] loss_train: 0.003609, loss_test: 0.005724
time: 0.24508237838745117
time: 2.217496395111084
[1, 8208] loss_train: 0.008004, loss_test: 0.005738
time: 0.2470703125
time: 2.2375001907348633
[1, 8209] loss_train: 0.011093, loss_test: 0.005726
time: 0.24405384063720703
time: 2.2365102767944336
[1, 8210] loss_train: 0.008937, loss_test: 0.005713
time: 0.25905799865722656
time: 2.2664072513580322
[1, 8211] loss_train: 0.002876, loss_test: 0.005705
time: 0.24805498123168945
time: 2.225497245788574
[1, 8212] loss_train: 0.004691, loss_test: 0.005701
time: 0.24605441093444824
time: 2.2144975662231445
[1, 8213] loss_train: 0.005417, loss_test: 0.005699
time: 0.2450547218322754
time: 2.2415008544921875
[1, 8214] loss_train: 0.000845, loss_test: 0.005698
time: 0.24205327033996582
time: 2.2234976291656494
[1, 8215] loss_train: 0.005356, loss_test: 0.005698
time: 0.2450547218322754
time: 2.2234973907470703
[1, 8216] loss_train: 0.002892, loss_test: 0.005696
time: 0.24405407905578613
time: 2.2225003242492676
[1, 8217] loss_train: 0.006932, loss_test: 0.005694
time: 0.24405455589294434
time: 2.235499382019043
[1, 8218] loss_train: 0.006025, loss_test: 0.005692
time: 0.24305415153503418
time: 2.2605068683624268
[1, 8219] loss_train: 0.006378, loss_test: 0.005691
time: 0.24289608001708984
time: 2.2284982204437256
[1, 8220] loss_train: 0.008949, loss_test: 0.005689
time: 0.25505661964416504
time: 2.2690320014953613
[1, 8221] loss_train: 0.004333, loss_test: 0.005687
time: 0.2450542449951172
time: 2.198533773422241
[1, 8222] loss_train: 0.011419, loss_test: 0.005678
time: 0.2450544834136963
time: 2.2124953269958496
[1, 8223] loss_train: 0.007726, loss_test: 0.005674
time: 0.24405455589294434
time: 2.198491334915161
[1, 8224] loss_train: 0.003830, loss_test: 0.005678
time: 0.24305391311645508
time: 2.2224972248077393
[1, 8225] loss_train: 0.004771, loss_test: 0.005684
time: 0.24605393409729004
time: 2.2224974632263184
[1, 8226] loss_train: 0.001728, loss_test: 0.005689
time: 0.2450547218322754
time: 2.206493616104126
[1, 8227] loss_train: 0.008785, loss_test: 0.005694
time: 0.24805498123168945
time: 2.2145161628723145
[1, 8228] loss_train: 0.009344, loss_test: 0.005698
time: 0.24605488777160645
time: 2.2238354682922363
[1, 8229] loss_train: 0.010419, loss_test: 0.005696
time: 0.24605488777160645
time: 2.222533941268921
[1, 8230] loss_train: 0.003200, loss_test: 0.005691
time: 0.2560567855834961
time: 2.2707931995391846
[1, 8231] loss_train: 0.002283, loss_test: 0.005688
time: 0.24405455589294434
time: 2.2024924755096436
[1, 8232] loss_train: 0.008953, loss_test: 0.005685
time: 0.24305367469787598
time: 2.2264983654022217
[1, 8233] loss_train: 0.007976, loss_test: 0.005682
time: 0.24305367469787598
time: 2.229499101638794
[1, 8234] loss_train: 0.011448, loss_test: 0.005680
time: 0.24505400657653809
time: 2.1859941482543945
[1, 8235] loss_train: 0.004014, loss_test: 0.005678
time: 0.24205422401428223
time: 2.2395005226135254
[1, 8236] loss_train: 0.013100, loss_test: 0.005679
time: 0.2450547218322754
time: 2.231499433517456
[1, 8237] loss_train: 0.007504, loss_test: 0.005681
time: 0.24405360221862793
time: 2.242502212524414
[1, 8238] loss_train: 0.005052, loss_test: 0.005682
time: 0.2440948486328125
time: 2.2365005016326904
[1, 8239] loss_train: 0.001959, loss_test: 0.005685
time: 0.24405360221862793
time: 2.2455050945281982
[1, 8240] loss_train: 0.002526, loss_test: 0.005691
time: 0.2560567855834961
time: 2.2755255699157715
[1, 8241] loss_train: 0.011804, loss_test: 0.005694
time: 0.24405455589294434
time: 2.227498769760132
[1, 8242] loss_train: 0.002650, loss_test: 0.005700
time: 0.2450547218322754
time: 2.2595326900482178
[1, 8243] loss_train: 0.003038, loss_test: 0.005706
time: 0.2470550537109375
time: 2.2355024814605713
[1, 8244] loss_train: 0.010688, loss_test: 0.005694
time: 0.24405455589294434
time: 2.2391302585601807
[1, 8245] loss_train: 0.009163, loss_test: 0.005684
time: 0.24205446243286133
time: 2.2164955139160156
[1, 8246] loss_train: 0.005901, loss_test: 0.005673
time: 0.24706745147705078
time: 2.2031145095825195
[1, 8247] loss_train: 0.005377, loss_test: 0.005665
time: 0.24605441093444824
time: 2.2039973735809326
[1, 8248] loss_train: 0.013833, loss_test: 0.005666
time: 0.25008416175842285
time: 2.1955068111419678
[1, 8249] loss_train: 0.001066, loss_test: 0.005671
time: 0.24405407905578613
time: 2.228498935699463
[1, 8250] loss_train: 0.005565, loss_test: 0.005680
time: 0.25905680656433105
time: 2.257039785385132
[1, 8251] loss_train: 0.005045, loss_test: 0.005690
time: 0.24406647682189941
time: 2.22249698638916
[1, 8252] loss_train: 0.000878, loss_test: 0.005699
time: 0.24305343627929688
time: 2.2455027103424072
[1, 8253] loss_train: 0.004046, loss_test: 0.005700
time: 0.24605417251586914
time: 2.244502305984497
[1, 8254] loss_train: 0.008284, loss_test: 0.005698
time: 0.24506711959838867
time: 2.233499765396118
[1, 8255] loss_train: 0.005003, loss_test: 0.005691
time: 0.2430253028869629
time: 2.1984918117523193
[1, 8256] loss_train: 0.003132, loss_test: 0.005683
time: 0.24605464935302734
time: 2.2280006408691406
[1, 8257] loss_train: 0.003698, loss_test: 0.005670
time: 0.24405455589294434
time: 2.2014920711517334
[1, 8258] loss_train: 0.014786, loss_test: 0.005665
time: 0.24318575859069824
time: 2.233499765396118
[1, 8259] loss_train: 0.005353, loss_test: 0.005664
time: 0.24405384063720703
time: 2.219752073287964
[1, 8260] loss_train: 0.006674, loss_test: 0.005667
time: 0.2560572624206543
time: 2.240170478820801
[1, 8261] loss_train: 0.006103, loss_test: 0.005675
time: 0.24405455589294434
time: 2.2264976501464844
[1, 8262] loss_train: 0.002250, loss_test: 0.005689
time: 0.24405431747436523
time: 2.231382131576538
[1, 8263] loss_train: 0.001169, loss_test: 0.005710
time: 0.2490549087524414
time: 2.2254977226257324
[1, 8264] loss_train: 0.002517, loss_test: 0.005732
time: 0.24506664276123047
time: 2.218496084213257
[1, 8265] loss_train: 0.006396, loss_test: 0.005747
time: 0.25005531311035156
time: 2.2284982204437256
[1, 8266] loss_train: 0.002813, loss_test: 0.005757
time: 0.24605441093444824
time: 2.243502378463745
[1, 8267] loss_train: 0.011253, loss_test: 0.005745
time: 0.2490546703338623
time: 2.189526081085205
[1, 8268] loss_train: 0.009378, loss_test: 0.005720
time: 0.24605345726013184
time: 2.2050249576568604
[1, 8269] loss_train: 0.003185, loss_test: 0.005703
time: 0.24305367469787598
time: 2.2134957313537598
[1, 8270] loss_train: 0.009283, loss_test: 0.005683
time: 0.2560567855834961
time: 2.223496913909912
[1, 8271] loss_train: 0.003307, loss_test: 0.005672
time: 0.24305367469787598
time: 2.201023817062378
[1, 8272] loss_train: 0.007928, loss_test: 0.005666
time: 0.24406647682189941
time: 2.2555043697357178
[1, 8273] loss_train: 0.004102, loss_test: 0.005666
time: 0.24405384063720703
time: 2.2375011444091797
[1, 8274] loss_train: 0.013814, loss_test: 0.005672
time: 0.24305343627929688
time: 2.269507884979248
[1, 8275] loss_train: 0.006643, loss_test: 0.005681
time: 0.24405455589294434
time: 2.2395009994506836
[1, 8276] loss_train: 0.001181, loss_test: 0.005690
time: 0.24605417251586914
time: 2.2475032806396484
[1, 8277] loss_train: 0.001688, loss_test: 0.005691
time: 0.24805450439453125
time: 2.2264981269836426
[1, 8278] loss_train: 0.002612, loss_test: 0.005682
time: 0.24405455589294434
time: 2.2310104370117188
[1, 8279] loss_train: 0.008028, loss_test: 0.005676
time: 0.24305438995361328
time: 2.226867198944092
[1, 8280] loss_train: 0.006338, loss_test: 0.005667
time: 0.25505733489990234
time: 2.232499122619629
[1, 8281] loss_train: 0.019064, loss_test: 0.005664
time: 0.24306631088256836
time: 2.2050271034240723
[1, 8282] loss_train: 0.002815, loss_test: 0.005665
time: 0.24405407905578613
time: 2.218496322631836
[1, 8283] loss_train: 0.005218, loss_test: 0.005671
time: 0.24405455589294434
time: 2.196995735168457
[1, 8284] loss_train: 0.012154, loss_test: 0.005677
time: 0.25305628776550293
time: 2.220496892929077
[1, 8285] loss_train: 0.011374, loss_test: 0.005681
time: 0.2450542449951172
time: 2.2315073013305664
[1, 8286] loss_train: 0.005798, loss_test: 0.005680
time: 0.24805450439453125
time: 2.2455027103424072
[1, 8287] loss_train: 0.016309, loss_test: 0.005675
time: 0.24405479431152344
time: 2.2314987182617188
[1, 8288] loss_train: 0.013385, loss_test: 0.005662
time: 0.24506640434265137
time: 2.253504514694214
[1, 8289] loss_train: 0.008524, loss_test: 0.005656
time: 0.2450544834136963
time: 2.222506046295166
[1, 8290] loss_train: 0.003352, loss_test: 0.005658
time: 0.256056547164917
time: 2.3005149364471436
[1, 8291] loss_train: 0.000718, loss_test: 0.005660
time: 0.24805498123168945
time: 2.213029146194458
[1, 8292] loss_train: 0.007007, loss_test: 0.005659
time: 0.24605464935302734
time: 2.2345004081726074
[1, 8293] loss_train: 0.010972, loss_test: 0.005659
time: 0.24405407905578613
time: 2.2214972972869873
[1, 8294] loss_train: 0.005178, loss_test: 0.005659
time: 0.24505376815795898
time: 2.2004923820495605
[1, 8295] loss_train: 0.006845, loss_test: 0.005661
time: 0.2450547218322754
time: 2.207503318786621
[1, 8296] loss_train: 0.005690, loss_test: 0.005662
time: 0.24305391311645508
time: 2.2244977951049805
[1, 8297] loss_train: 0.006268, loss_test: 0.005664
time: 0.24205422401428223
time: 2.226515054702759
[1, 8298] loss_train: 0.014516, loss_test: 0.005665
time: 0.2450542449951172
time: 2.2305076122283936
[1, 8299] loss_train: 0.008953, loss_test: 0.005664
time: 0.24405479431152344
time: 2.2085325717926025
[1, 8300] loss_train: 0.004382, loss_test: 0.005664
time: 0.2540566921234131
time: 2.2415008544921875
[1, 8301] loss_train: 0.003761, loss_test: 0.005666
time: 0.24506855010986328
time: 2.242520332336426
[1, 8302] loss_train: 0.003277, loss_test: 0.005674
time: 0.24405431747436523
time: 2.2260022163391113
[1, 8303] loss_train: 0.003654, loss_test: 0.005686
time: 0.24405336380004883
time: 2.2220098972320557
[1, 8304] loss_train: 0.008591, loss_test: 0.005700
time: 0.24805593490600586
time: 2.224496841430664
[1, 8305] loss_train: 0.001288, loss_test: 0.005716
time: 0.24905610084533691
time: 2.19350528717041
[1, 8306] loss_train: 0.003500, loss_test: 0.005732
time: 0.244065523147583
time: 2.228498935699463
[1, 8307] loss_train: 0.001674, loss_test: 0.005750
time: 0.24605441093444824
time: 2.2380504608154297
[1, 8308] loss_train: 0.009177, loss_test: 0.005754
time: 0.2450542449951172
time: 2.2129993438720703
[1, 8309] loss_train: 0.005462, loss_test: 0.005756
time: 0.24406647682189941
time: 2.2184970378875732
[1, 8310] loss_train: 0.006094, loss_test: 0.005744
time: 0.2540562152862549
time: 2.2725086212158203
[1, 8311] loss_train: 0.010661, loss_test: 0.005721
time: 0.24605417251586914
time: 2.228498935699463
[1, 8312] loss_train: 0.008241, loss_test: 0.005699
time: 0.24405670166015625
time: 2.2535054683685303
[1, 8313] loss_train: 0.006606, loss_test: 0.005683
time: 0.24505281448364258
time: 2.232022285461426
[1, 8314] loss_train: 0.007206, loss_test: 0.005674
time: 0.24305415153503418
time: 2.23249888420105
[1, 8315] loss_train: 0.000719, loss_test: 0.005676
time: 0.2450551986694336
time: 2.2465507984161377
[1, 8316] loss_train: 0.010665, loss_test: 0.005685
time: 0.2450542449951172
time: 2.193491220474243
[1, 8317] loss_train: 0.003533, loss_test: 0.005696
time: 0.24305415153503418
time: 2.2144949436187744
[1, 8318] loss_train: 0.008472, loss_test: 0.005704
time: 0.24557256698608398
time: 2.2014925479888916
[1, 8319] loss_train: 0.001616, loss_test: 0.005704
time: 0.24405384063720703
time: 2.210801839828491
[1, 8320] loss_train: 0.012218, loss_test: 0.005696
time: 0.25505614280700684
time: 2.2605061531066895
[1, 8321] loss_train: 0.008127, loss_test: 0.005687
time: 0.2540569305419922
time: 2.2325010299682617
[1, 8322] loss_train: 0.010875, loss_test: 0.005679
time: 0.24506807327270508
time: 2.2134954929351807
[1, 8323] loss_train: 0.012561, loss_test: 0.005675
time: 0.2440807819366455
time: 2.2144956588745117
[1, 8324] loss_train: 0.007873, loss_test: 0.005676
time: 0.25005602836608887
time: 2.239500045776367
[1, 8325] loss_train: 0.005881, loss_test: 0.005681
time: 0.24405407905578613
time: 2.2555041313171387
[1, 8326] loss_train: 0.009240, loss_test: 0.005687
time: 0.2470543384552002
time: 2.252478837966919
[1, 8327] loss_train: 0.002291, loss_test: 0.005697
time: 0.24605488777160645
time: 2.2004921436309814
[1, 8328] loss_train: 0.002932, loss_test: 0.005710
time: 0.24805426597595215
time: 2.2420177459716797
[1, 8329] loss_train: 0.008563, loss_test: 0.005715
time: 0.24405479431152344
time: 2.2190048694610596
[1, 8330] loss_train: 0.002305, loss_test: 0.005721
time: 0.2560575008392334
time: 2.2395005226135254
[1, 8331] loss_train: 0.003762, loss_test: 0.005729
time: 0.2450549602508545
time: 2.223499059677124
[1, 8332] loss_train: 0.003088, loss_test: 0.005736
time: 0.24305367469787598
time: 2.2254984378814697
[1, 8333] loss_train: 0.006055, loss_test: 0.005738
time: 0.24405455589294434
time: 2.235499620437622
[1, 8334] loss_train: 0.002034, loss_test: 0.005745
time: 0.24405407905578613
time: 2.1984922885894775
[1, 8335] loss_train: 0.004807, loss_test: 0.005753
time: 0.24405455589294434
time: 2.225397825241089
[1, 8336] loss_train: 0.003554, loss_test: 0.005762
time: 0.24305391311645508
time: 2.2254979610443115
[1, 8337] loss_train: 0.006132, loss_test: 0.005767
time: 0.2450549602508545
time: 2.2264976501464844
[1, 8338] loss_train: 0.014404, loss_test: 0.005760
time: 0.2450544834136963
time: 2.2390496730804443
[1, 8339] loss_train: 0.013164, loss_test: 0.005731
time: 0.24305295944213867
time: 2.217010259628296
[1, 8340] loss_train: 0.011343, loss_test: 0.005704
time: 0.2560563087463379
time: 2.2365005016326904
[1, 8341] loss_train: 0.004964, loss_test: 0.005696
time: 0.24605417251586914
time: 2.218496799468994
[1, 8342] loss_train: 0.003827, loss_test: 0.005690
time: 0.24405336380004883
time: 2.2335050106048584
[1, 8343] loss_train: 0.003525, loss_test: 0.005692
time: 0.25005507469177246
time: 2.194491147994995
[1, 8344] loss_train: 0.011404, loss_test: 0.005697
time: 0.2450542449951172
time: 2.2215118408203125
[1, 8345] loss_train: 0.004492, loss_test: 0.005702
time: 0.25005531311035156
time: 2.230501413345337
[1, 8346] loss_train: 0.007262, loss_test: 0.005705
time: 0.24405336380004883
time: 2.2254984378814697
[1, 8347] loss_train: 0.009011, loss_test: 0.005705
time: 0.24405360221862793
time: 2.2184970378875732
[1, 8348] loss_train: 0.002710, loss_test: 0.005705
time: 0.24605536460876465
time: 2.2625274658203125
[1, 8349] loss_train: 0.005995, loss_test: 0.005702
time: 0.24505400657653809
time: 2.2375009059906006
[1, 8350] loss_train: 0.011847, loss_test: 0.005696
time: 0.2560703754425049
time: 2.2545037269592285
[1, 8351] loss_train: 0.003800, loss_test: 0.005695
time: 0.2470555305480957
time: 2.2284977436065674
[1, 8352] loss_train: 0.002930, loss_test: 0.005700
time: 0.24105381965637207
time: 2.230499267578125
[1, 8353] loss_train: 0.007614, loss_test: 0.005701
time: 0.24305415153503418
time: 2.2204983234405518
[1, 8354] loss_train: 0.005553, loss_test: 0.005701
time: 0.24305415153503418
time: 2.2294986248016357
[1, 8355] loss_train: 0.004693, loss_test: 0.005701
time: 0.24406886100769043
time: 2.217496633529663
[1, 8356] loss_train: 0.007216, loss_test: 0.005696
time: 0.24406695365905762
time: 2.2355003356933594
[1, 8357] loss_train: 0.003599, loss_test: 0.005693
time: 0.24305367469787598
time: 2.2244977951049805
[1, 8358] loss_train: 0.004860, loss_test: 0.005692
time: 0.24805474281311035
time: 2.244521141052246
[1, 8359] loss_train: 0.008334, loss_test: 0.005690
time: 0.24305343627929688
time: 2.2165205478668213
[1, 8360] loss_train: 0.002055, loss_test: 0.005690
time: 0.254056453704834
time: 2.270521402359009
[1, 8361] loss_train: 0.002341, loss_test: 0.005691
time: 0.24305343627929688
time: 2.230499267578125
[1, 8362] loss_train: 0.015215, loss_test: 0.005689
time: 0.24305415153503418
time: 2.2044928073883057
[1, 8363] loss_train: 0.012903, loss_test: 0.005682
time: 0.24505352973937988
time: 2.2124953269958496
[1, 8364] loss_train: 0.012929, loss_test: 0.005685
time: 0.2490549087524414
time: 2.20350980758667
[1, 8365] loss_train: 0.002905, loss_test: 0.005692
time: 0.2470550537109375
time: 2.2154951095581055
[1, 8366] loss_train: 0.001057, loss_test: 0.005700
time: 0.24805474281311035
time: 2.2035152912139893
[1, 8367] loss_train: 0.005574, loss_test: 0.005703
time: 0.24505400657653809
time: 2.2045044898986816
[1, 8368] loss_train: 0.001010, loss_test: 0.005706
time: 0.24305391311645508
time: 2.230499029159546
[1, 8369] loss_train: 0.006397, loss_test: 0.005712
time: 0.24305415153503418
time: 2.257505178451538
[1, 8370] loss_train: 0.002583, loss_test: 0.005717
time: 0.2560563087463379
time: 2.256505012512207
[1, 8371] loss_train: 0.013380, loss_test: 0.005715
time: 0.24405384063720703
time: 2.2470076084136963
[1, 8372] loss_train: 0.004867, loss_test: 0.005708
time: 0.2450554370880127
time: 2.23349928855896
[1, 8373] loss_train: 0.006439, loss_test: 0.005694
time: 0.24605464935302734
time: 2.223496437072754
[1, 8374] loss_train: 0.008053, loss_test: 0.005679
time: 0.24405336380004883
time: 2.211495876312256
[1, 8375] loss_train: 0.011398, loss_test: 0.005669
time: 0.24605345726013184
time: 2.2055115699768066
[1, 8376] loss_train: 0.011521, loss_test: 0.005662
time: 0.24605870246887207
time: 2.230516195297241
[1, 8377] loss_train: 0.008577, loss_test: 0.005660
time: 0.24405407905578613
time: 2.2004926204681396
[1, 8378] loss_train: 0.009796, loss_test: 0.005664
time: 0.24305391311645508
time: 2.219496488571167
[1, 8379] loss_train: 0.012349, loss_test: 0.005672
time: 0.24406743049621582
time: 2.2075107097625732
[1, 8380] loss_train: 0.008446, loss_test: 0.005677
time: 0.25507307052612305
time: 2.2545042037963867
[1, 8381] loss_train: 0.001503, loss_test: 0.005674
time: 0.25305652618408203
time: 2.250044345855713
[1, 8382] loss_train: 0.003031, loss_test: 0.005668
time: 0.2490556240081787
time: 2.220496654510498
[1, 8383] loss_train: 0.003522, loss_test: 0.005662
time: 0.24808335304260254
time: 2.2274980545043945
[1, 8384] loss_train: 0.015128, loss_test: 0.005662
time: 0.2450549602508545
time: 2.244520425796509
[1, 8385] loss_train: 0.002745, loss_test: 0.005662
time: 0.24805521965026855
time: 2.2525038719177246
[1, 8386] loss_train: 0.008327, loss_test: 0.005662
time: 0.2450544834136963
time: 2.233945846557617
[1, 8387] loss_train: 0.014560, loss_test: 0.005667
time: 0.2470557689666748
time: 2.249516010284424
[1, 8388] loss_train: 0.014241, loss_test: 0.005673
time: 0.24305438995361328
time: 2.2145166397094727
[1, 8389] loss_train: 0.004003, loss_test: 0.005675
time: 0.2470545768737793
time: 2.2235007286071777
[1, 8390] loss_train: 0.004712, loss_test: 0.005675
time: 0.256056547164917
time: 2.2565040588378906
[1, 8391] loss_train: 0.002146, loss_test: 0.005675
time: 0.24305486679077148
time: 2.218724012374878
[1, 8392] loss_train: 0.008908, loss_test: 0.005684
time: 0.24805474281311035
time: 2.2835114002227783
[1, 8393] loss_train: 0.002881, loss_test: 0.005689
time: 0.24805450439453125
time: 2.2284984588623047
[1, 8394] loss_train: 0.005700, loss_test: 0.005683
time: 0.24405407905578613
time: 2.2345004081726074
[1, 8395] loss_train: 0.006415, loss_test: 0.005677
time: 0.24605369567871094
time: 2.2425148487091064
[1, 8396] loss_train: 0.004888, loss_test: 0.005671
time: 0.24305486679077148
time: 2.238508701324463
[1, 8397] loss_train: 0.002238, loss_test: 0.005667
time: 0.24205446243286133
time: 2.2535033226013184
[1, 8398] loss_train: 0.005200, loss_test: 0.005667
time: 0.24605441093444824
time: 2.244502305984497
[1, 8399] loss_train: 0.012548, loss_test: 0.005665
time: 0.24405336380004883
time: 2.2410125732421875
[1, 8400] loss_train: 0.000776, loss_test: 0.005666
time: 0.2560694217681885
time: 2.2064929008483887
[1, 8401] loss_train: 0.003925, loss_test: 0.005670
time: 0.24305415153503418
time: 2.244501829147339
[1, 8402] loss_train: 0.012997, loss_test: 0.005674
time: 0.24905610084533691
time: 2.2215042114257812
[1, 8403] loss_train: 0.002679, loss_test: 0.005684
time: 0.24405384063720703
time: 2.2004928588867188
[1, 8404] loss_train: 0.007272, loss_test: 0.005692
time: 0.24405431747436523
time: 2.214020252227783
[1, 8405] loss_train: 0.002377, loss_test: 0.005704
time: 0.24405407905578613
time: 2.190490484237671
[1, 8406] loss_train: 0.001543, loss_test: 0.005716
time: 0.2470545768737793
time: 2.2395007610321045
[1, 8407] loss_train: 0.008095, loss_test: 0.005720
time: 0.24405431747436523
time: 2.2315011024475098
[1, 8408] loss_train: 0.003043, loss_test: 0.005725
time: 0.2510709762573242
time: 2.219496965408325
[1, 8409] loss_train: 0.007897, loss_test: 0.005730
time: 0.2450549602508545
time: 2.229649543762207
[1, 8410] loss_train: 0.004152, loss_test: 0.005734
time: 0.2600579261779785
time: 2.259505271911621
[1, 8411] loss_train: 0.005063, loss_test: 0.005728
time: 0.24605464935302734
time: 2.2385005950927734
[1, 8412] loss_train: 0.003443, loss_test: 0.005727
time: 0.2490549087524414
time: 2.242501974105835
[1, 8413] loss_train: 0.006305, loss_test: 0.005719
time: 0.24505376815795898
time: 2.1974923610687256
[1, 8414] loss_train: 0.002414, loss_test: 0.005712
time: 0.24305415153503418
time: 2.2304980754852295
[1, 8415] loss_train: 0.016041, loss_test: 0.005708
time: 0.24306750297546387
time: 2.1960389614105225
[1, 8416] loss_train: 0.003183, loss_test: 0.005706
time: 0.24605441093444824
time: 2.256516456604004
[1, 8417] loss_train: 0.008121, loss_test: 0.005703
time: 0.24405837059020996
time: 2.209493398666382
[1, 8418] loss_train: 0.007023, loss_test: 0.005701
time: 0.2450542449951172
time: 2.2495031356811523
[1, 8419] loss_train: 0.002408, loss_test: 0.005700
time: 0.2580564022064209
time: 2.275033712387085
[1, 8420] loss_train: 0.001481, loss_test: 0.005699
time: 0.256056547164917
time: 2.239503860473633
[1, 8421] loss_train: 0.011980, loss_test: 0.005701
time: 0.24705743789672852
time: 2.2630114555358887
[1, 8422] loss_train: 0.003868, loss_test: 0.005695
time: 0.24405574798583984
time: 2.2415056228637695
[1, 8423] loss_train: 0.006117, loss_test: 0.005692
time: 0.24406647682189941
time: 2.230499029159546
[1, 8424] loss_train: 0.002977, loss_test: 0.005693
time: 0.24405384063720703
time: 2.2255027294158936
[1, 8425] loss_train: 0.008740, loss_test: 0.005695
time: 0.24305438995361328
time: 2.235499143600464
[1, 8426] loss_train: 0.001303, loss_test: 0.005700
time: 0.24305438995361328
time: 2.235499858856201
[1, 8427] loss_train: 0.005575, loss_test: 0.005700
time: 0.24405455589294434
time: 2.1855061054229736
[1, 8428] loss_train: 0.005986, loss_test: 0.005698
time: 0.24505376815795898
time: 2.230027914047241
[1, 8429] loss_train: 0.006046, loss_test: 0.005698
time: 0.2470555305480957
time: 2.222496747970581
[1, 8430] loss_train: 0.005812, loss_test: 0.005697
time: 0.25705647468566895
time: 2.2415008544921875
[1, 8431] loss_train: 0.000597, loss_test: 0.005697
time: 0.2430553436279297
time: 2.235501527786255
[1, 8432] loss_train: 0.008976, loss_test: 0.005698
time: 0.24605441093444824
time: 2.2365000247955322
[1, 8433] loss_train: 0.011244, loss_test: 0.005695
time: 0.2510557174682617
time: 2.2084970474243164
[1, 8434] loss_train: 0.005818, loss_test: 0.005696
time: 0.2450544834136963
time: 2.2294986248016357
[1, 8435] loss_train: 0.005229, loss_test: 0.005698
time: 0.25505709648132324
time: 2.241508722305298
[1, 8436] loss_train: 0.001469, loss_test: 0.005705
time: 0.2450544834136963
time: 2.2154979705810547
[1, 8437] loss_train: 0.005332, loss_test: 0.005713
time: 0.2470552921295166
time: 2.2054929733276367
[1, 8438] loss_train: 0.009329, loss_test: 0.005713
time: 0.24405360221862793
time: 2.1974918842315674
[1, 8439] loss_train: 0.008822, loss_test: 0.005708
time: 0.24305367469787598
time: 2.2060000896453857
[1, 8440] loss_train: 0.004292, loss_test: 0.005706
time: 0.255068302154541
time: 2.2475149631500244
[1, 8441] loss_train: 0.005298, loss_test: 0.005699
time: 0.2450542449951172
time: 2.193491220474243
[1, 8442] loss_train: 0.008406, loss_test: 0.005691
time: 0.2450544834136963
time: 2.242006301879883
[1, 8443] loss_train: 0.004795, loss_test: 0.005687
time: 0.24405455589294434
time: 2.2375001907348633
[1, 8444] loss_train: 0.004641, loss_test: 0.005685
time: 0.24605464935302734
time: 2.2214975357055664
[1, 8445] loss_train: 0.004586, loss_test: 0.005684
time: 0.24405455589294434
time: 2.207502841949463
[1, 8446] loss_train: 0.008116, loss_test: 0.005683
time: 0.24405336380004883
time: 2.2365009784698486
[1, 8447] loss_train: 0.009365, loss_test: 0.005684
time: 0.24405431747436523
time: 2.2385005950927734
[1, 8448] loss_train: 0.002051, loss_test: 0.005687
time: 0.24405336380004883
time: 2.2103302478790283
[1, 8449] loss_train: 0.008815, loss_test: 0.005690
time: 0.24505400657653809
time: 2.232499599456787
[1, 8450] loss_train: 0.008349, loss_test: 0.005692
time: 0.26105785369873047
time: 2.26003098487854
[1, 8451] loss_train: 0.002805, loss_test: 0.005690
time: 0.24605417251586914
time: 2.1954939365386963
[1, 8452] loss_train: 0.009916, loss_test: 0.005687
time: 0.25005602836608887
time: 2.2055065631866455
[1, 8453] loss_train: 0.009986, loss_test: 0.005680
time: 0.24605441093444824
time: 2.2625064849853516
[1, 8454] loss_train: 0.002827, loss_test: 0.005674
time: 0.2470550537109375
time: 2.2304985523223877
[1, 8455] loss_train: 0.004234, loss_test: 0.005672
time: 0.2450549602508545
time: 2.202491521835327
[1, 8456] loss_train: 0.005586, loss_test: 0.005674
time: 0.2470550537109375
time: 2.24802303314209
[1, 8457] loss_train: 0.000858, loss_test: 0.005682
time: 0.24305415153503418
time: 2.256504774093628
[1, 8458] loss_train: 0.008613, loss_test: 0.005685
time: 0.24305343627929688
time: 2.2485039234161377
[1, 8459] loss_train: 0.007465, loss_test: 0.005687
time: 0.2490544319152832
time: 2.236513137817383
[1, 8460] loss_train: 0.009413, loss_test: 0.005688
time: 0.2600569725036621
time: 2.2525033950805664
[1, 8461] loss_train: 0.007556, loss_test: 0.005690
time: 0.24306797981262207
time: 2.243501663208008
[1, 8462] loss_train: 0.007783, loss_test: 0.005693
time: 0.24205374717712402
time: 2.1964917182922363
[1, 8463] loss_train: 0.001104, loss_test: 0.005698
time: 0.24605464935302734
time: 2.242501735687256
[1, 8464] loss_train: 0.002588, loss_test: 0.005705
time: 0.24505400657653809
time: 2.209550142288208
[1, 8465] loss_train: 0.007744, loss_test: 0.005711
time: 0.24305438995361328
time: 2.1845145225524902
[1, 8466] loss_train: 0.004969, loss_test: 0.005715
time: 0.24405455589294434
time: 2.2204952239990234
[1, 8467] loss_train: 0.006592, loss_test: 0.005721
time: 0.24309372901916504
time: 2.2185072898864746
[1, 8468] loss_train: 0.009327, loss_test: 0.005711
time: 0.2450544834136963
time: 2.2294983863830566
[1, 8469] loss_train: 0.015189, loss_test: 0.005674
time: 0.2470548152923584
time: 2.2235140800476074
[1, 8470] loss_train: 0.000776, loss_test: 0.005663
time: 0.2600579261779785
time: 2.2635064125061035
[1, 8471] loss_train: 0.006457, loss_test: 0.005681
time: 0.2490551471710205
time: 2.2284984588623047
[1, 8472] loss_train: 0.005136, loss_test: 0.005707
time: 0.2400522232055664
time: 2.2360236644744873
[1, 8473] loss_train: 0.004303, loss_test: 0.005730
time: 0.25006675720214844
time: 2.207494020462036
[1, 8474] loss_train: 0.009766, loss_test: 0.005742
time: 0.24405455589294434
time: 2.1989951133728027
[1, 8475] loss_train: 0.007292, loss_test: 0.005746
time: 0.24405694007873535
time: 2.221496343612671
[1, 8476] loss_train: 0.007802, loss_test: 0.005742
time: 0.24305367469787598
time: 2.2174956798553467
[1, 8477] loss_train: 0.011931, loss_test: 0.005735
time: 0.24405360221862793
time: 2.217620849609375
[1, 8478] loss_train: 0.002256, loss_test: 0.005731
time: 0.24405503273010254
time: 2.2195193767547607
[1, 8479] loss_train: 0.001247, loss_test: 0.005728
time: 0.24505400657653809
time: 2.218496084213257
[1, 8480] loss_train: 0.001350, loss_test: 0.005730
time: 0.2580571174621582
time: 2.2345094680786133
[1, 8481] loss_train: 0.002347, loss_test: 0.005734
time: 0.24405479431152344
time: 2.2164950370788574
[1, 8482] loss_train: 0.000654, loss_test: 0.005740
time: 0.24305415153503418
time: 2.220496654510498
[1, 8483] loss_train: 0.003261, loss_test: 0.005736
time: 0.2450544834136963
time: 2.2294986248016357
[1, 8484] loss_train: 0.003690, loss_test: 0.005739
time: 0.24405431747436523
time: 2.2144951820373535
[1, 8485] loss_train: 0.014968, loss_test: 0.005737
time: 0.24305367469787598
time: 2.2245004177093506
[1, 8486] loss_train: 0.005401, loss_test: 0.005736
time: 0.2510559558868408
time: 2.247504711151123
[1, 8487] loss_train: 0.006599, loss_test: 0.005730
time: 0.2470543384552002
time: 2.1864898204803467
[1, 8488] loss_train: 0.001915, loss_test: 0.005727
time: 0.2490546703338623
time: 2.199512004852295
[1, 8489] loss_train: 0.005927, loss_test: 0.005733
time: 0.24405407905578613
time: 2.2132067680358887
[1, 8490] loss_train: 0.005124, loss_test: 0.005739
time: 0.25505661964416504
time: 2.26751708984375
[1, 8491] loss_train: 0.008503, loss_test: 0.005740
time: 0.24305391311645508
time: 2.2505037784576416
[1, 8492] loss_train: 0.002238, loss_test: 0.005740
time: 0.2450549602508545
time: 2.2225136756896973
[1, 8493] loss_train: 0.005500, loss_test: 0.005744
time: 0.24205398559570312
time: 2.235499858856201
[1, 8494] loss_train: 0.008182, loss_test: 0.005749
time: 0.24505400657653809
time: 2.2385215759277344
[1, 8495] loss_train: 0.007460, loss_test: 0.005750
time: 0.24505925178527832
time: 2.230499267578125
[1, 8496] loss_train: 0.008370, loss_test: 0.005733
time: 0.24106597900390625
time: 2.223513126373291
[1, 8497] loss_train: 0.003756, loss_test: 0.005720
time: 0.24305343627929688
time: 2.2004923820495605
[1, 8498] loss_train: 0.002722, loss_test: 0.005714
time: 0.2450542449951172
time: 2.2010140419006348
[1, 8499] loss_train: 0.003771, loss_test: 0.005709
time: 0.2435595989227295
time: 2.2224974632263184
[1, 8500] loss_train: 0.006302, loss_test: 0.005703
time: 0.25706958770751953
time: 2.239520788192749
[1, 8501] loss_train: 0.003031, loss_test: 0.005698
time: 0.2530555725097656
time: 2.2244982719421387
[1, 8502] loss_train: 0.004057, loss_test: 0.005695
time: 0.2450544834136963
time: 2.231003522872925
[1, 8503] loss_train: 0.003398, loss_test: 0.005692
time: 0.24306774139404297
time: 2.234499454498291
[1, 8504] loss_train: 0.003314, loss_test: 0.005687
time: 0.24505376815795898
time: 2.2254984378814697
[1, 8505] loss_train: 0.007590, loss_test: 0.005682
time: 0.24805498123168945
time: 2.2435104846954346
[1, 8506] loss_train: 0.009200, loss_test: 0.005677
time: 0.2450544834136963
time: 2.2375004291534424
[1, 8507] loss_train: 0.002761, loss_test: 0.005677
time: 0.2490553855895996
time: 2.22149658203125
[1, 8508] loss_train: 0.008143, loss_test: 0.005675
time: 0.24405503273010254
time: 2.24650239944458
[1, 8509] loss_train: 0.003864, loss_test: 0.005672
time: 0.2490556240081787
time: 2.1795122623443604
[1, 8510] loss_train: 0.014682, loss_test: 0.005669
time: 0.25505614280700684
time: 2.244504690170288
[1, 8511] loss_train: 0.001714, loss_test: 0.005666
time: 0.24405312538146973
time: 2.2355024814605713
[1, 8512] loss_train: 0.006659, loss_test: 0.005666
time: 0.24605417251586914
time: 2.207494020462036
[1, 8513] loss_train: 0.008180, loss_test: 0.005670
time: 0.24405479431152344
time: 2.2159974575042725
[1, 8514] loss_train: 0.007124, loss_test: 0.005680
time: 0.24405407905578613
time: 2.2124950885772705
[1, 8515] loss_train: 0.008947, loss_test: 0.005695
time: 0.24305462837219238
time: 2.244503974914551
[1, 8516] loss_train: 0.005399, loss_test: 0.005697
time: 0.24505400657653809
time: 2.222499132156372
[1, 8517] loss_train: 0.005795, loss_test: 0.005699
time: 0.24305319786071777
time: 2.209014415740967
[1, 8518] loss_train: 0.004723, loss_test: 0.005699
time: 0.24405455589294434
time: 2.2125027179718018
[1, 8519] loss_train: 0.008954, loss_test: 0.005695
time: 0.24405407905578613
time: 2.2415213584899902
[1, 8520] loss_train: 0.009810, loss_test: 0.005693
time: 0.2540566921234131
time: 2.273508310317993
[1, 8521] loss_train: 0.002740, loss_test: 0.005691
time: 0.24505400657653809
time: 2.2024929523468018
[1, 8522] loss_train: 0.005303, loss_test: 0.005689
time: 0.24508047103881836
time: 2.2324986457824707
[1, 8523] loss_train: 0.009114, loss_test: 0.005681
time: 0.24405360221862793
time: 2.2274997234344482
[1, 8524] loss_train: 0.004779, loss_test: 0.005675
time: 0.2490551471710205
time: 2.216496229171753
[1, 8525] loss_train: 0.006120, loss_test: 0.005668
time: 0.24805545806884766
time: 2.199490785598755
[1, 8526] loss_train: 0.008804, loss_test: 0.005661
time: 0.2470552921295166
time: 2.2149999141693115
[1, 8527] loss_train: 0.009359, loss_test: 0.005658
time: 0.24305367469787598
time: 2.2365007400512695
[1, 8528] loss_train: 0.007639, loss_test: 0.005656
time: 0.24305319786071777
time: 2.2505040168762207
[1, 8529] loss_train: 0.012396, loss_test: 0.005653
time: 0.24305319786071777
time: 2.253516912460327
[1, 8530] loss_train: 0.008620, loss_test: 0.005651
time: 0.254056453704834
time: 2.2675089836120605
[1, 8531] loss_train: 0.001693, loss_test: 0.005650
time: 0.24605441093444824
time: 2.240003824234009
[1, 8532] loss_train: 0.008286, loss_test: 0.005651
time: 0.24205446243286133
time: 2.223497152328491
[1, 8533] loss_train: 0.014343, loss_test: 0.005653
time: 0.24205398559570312
time: 2.22149658203125
[1, 8534] loss_train: 0.007766, loss_test: 0.005654
time: 0.24405384063720703
time: 2.206493616104126
[1, 8535] loss_train: 0.013875, loss_test: 0.005657
time: 0.24605441093444824
time: 2.239682912826538
[1, 8536] loss_train: 0.009156, loss_test: 0.005659
time: 0.2450547218322754
time: 2.200493097305298
[1, 8537] loss_train: 0.005256, loss_test: 0.005661
time: 0.24605560302734375
time: 2.2165184020996094
[1, 8538] loss_train: 0.008542, loss_test: 0.005664
time: 0.24405384063720703
time: 2.2094967365264893
[1, 8539] loss_train: 0.003413, loss_test: 0.005667
time: 0.24405360221862793
time: 2.221010446548462
[1, 8540] loss_train: 0.003703, loss_test: 0.005669
time: 0.256056547164917
time: 2.2465035915374756
[1, 8541] loss_train: 0.008984, loss_test: 0.005670
time: 0.24305367469787598
time: 2.2770121097564697
[1, 8542] loss_train: 0.020949, loss_test: 0.005670
time: 0.2450547218322754
time: 2.2004919052124023
[1, 8543] loss_train: 0.005544, loss_test: 0.005673
time: 0.24605417251586914
time: 2.23449969291687
[1, 8544] loss_train: 0.007211, loss_test: 0.005678
time: 0.24405455589294434
time: 2.20951247215271
[1, 8545] loss_train: 0.006726, loss_test: 0.005683
time: 0.2490549087524414
time: 2.2475030422210693
[1, 8546] loss_train: 0.004397, loss_test: 0.005683
time: 0.2450547218322754
time: 2.1884891986846924
[1, 8547] loss_train: 0.005983, loss_test: 0.005683
time: 0.24505400657653809
time: 2.217496395111084
[1, 8548] loss_train: 0.006249, loss_test: 0.005687
time: 0.24305343627929688
time: 2.2234978675842285
[1, 8549] loss_train: 0.005964, loss_test: 0.005692
time: 0.24405384063720703
time: 2.2224974632263184
[1, 8550] loss_train: 0.001307, loss_test: 0.005702
time: 0.25507616996765137
time: 2.3110203742980957
[1, 8551] loss_train: 0.007838, loss_test: 0.005711
time: 0.24305319786071777
time: 2.219496726989746
[1, 8552] loss_train: 0.017561, loss_test: 0.005725
time: 0.24756121635437012
time: 2.233499765396118
[1, 8553] loss_train: 0.008857, loss_test: 0.005736
time: 0.2450544834136963
time: 2.233499526977539
[1, 8554] loss_train: 0.009538, loss_test: 0.005731
time: 0.24405431747436523
time: 2.2395009994506836
[1, 8555] loss_train: 0.014114, loss_test: 0.005716
time: 0.24305438995361328
time: 2.210494041442871
[1, 8556] loss_train: 0.005010, loss_test: 0.005700
time: 0.24405360221862793
time: 2.247512102127075
[1, 8557] loss_train: 0.003779, loss_test: 0.005689
time: 0.24405407905578613
time: 2.205493450164795
[1, 8558] loss_train: 0.003262, loss_test: 0.005683
time: 0.24405384063720703
time: 2.2274985313415527
[1, 8559] loss_train: 0.001403, loss_test: 0.005679
time: 0.2470543384552002
time: 2.2035021781921387
[1, 8560] loss_train: 0.012360, loss_test: 0.005677
time: 0.2560563087463379
time: 2.2515039443969727
[1, 8561] loss_train: 0.001527, loss_test: 0.005678
time: 0.2450542449951172
time: 2.2114949226379395
[1, 8562] loss_train: 0.007854, loss_test: 0.005676
time: 0.24405384063720703
time: 2.205503225326538
[1, 8563] loss_train: 0.006988, loss_test: 0.005674
time: 0.24505376815795898
time: 2.210494041442871
[1, 8564] loss_train: 0.009480, loss_test: 0.005672
time: 0.2490558624267578
time: 2.257505416870117
[1, 8565] loss_train: 0.007318, loss_test: 0.005665
time: 0.2470548152923584
time: 2.2044923305511475
[1, 8566] loss_train: 0.001915, loss_test: 0.005662
time: 0.2490544319152832
time: 2.2251787185668945
[1, 8567] loss_train: 0.003482, loss_test: 0.005662
time: 0.24605441093444824
time: 2.233511209487915
[1, 8568] loss_train: 0.006465, loss_test: 0.005661
time: 0.24305319786071777
time: 2.2163326740264893
[1, 8569] loss_train: 0.012274, loss_test: 0.005664
time: 0.2490546703338623
time: 2.2335000038146973
[1, 8570] loss_train: 0.004355, loss_test: 0.005666
time: 0.2560563087463379
time: 2.2690556049346924
[1, 8571] loss_train: 0.008778, loss_test: 0.005668
time: 0.2450544834136963
time: 2.2375004291534424
[1, 8572] loss_train: 0.004299, loss_test: 0.005670
time: 0.24305367469787598
time: 2.22747802734375
[1, 8573] loss_train: 0.003725, loss_test: 0.005669
time: 0.2450542449951172
time: 2.2244980335235596
[1, 8574] loss_train: 0.006130, loss_test: 0.005666
time: 0.24605488777160645
time: 2.236499547958374
[1, 8575] loss_train: 0.011091, loss_test: 0.005664
time: 0.24405431747436523
time: 2.24700665473938
[1, 8576] loss_train: 0.007372, loss_test: 0.005661
time: 0.24305343627929688
time: 2.232499122619629
[1, 8577] loss_train: 0.010559, loss_test: 0.005658
time: 0.24405384063720703
time: 2.2355003356933594
[1, 8578] loss_train: 0.014248, loss_test: 0.005657
time: 0.24405503273010254
time: 2.2215075492858887
[1, 8579] loss_train: 0.003043, loss_test: 0.005657
time: 0.2450542449951172
time: 2.2385010719299316
[1, 8580] loss_train: 0.006524, loss_test: 0.005663
time: 0.25707125663757324
time: 2.246504545211792
[1, 8581] loss_train: 0.011486, loss_test: 0.005669
time: 0.24405932426452637
time: 2.234499454498291
[1, 8582] loss_train: 0.003580, loss_test: 0.005676
time: 0.2450547218322754
time: 2.230498790740967
[1, 8583] loss_train: 0.002427, loss_test: 0.005683
time: 0.24508070945739746
time: 2.218498706817627
[1, 8584] loss_train: 0.000458, loss_test: 0.005697
time: 0.24405360221862793
time: 2.2124946117401123
[1, 8585] loss_train: 0.002806, loss_test: 0.005713
time: 0.24756383895874023
time: 2.204493284225464
[1, 8586] loss_train: 0.003020, loss_test: 0.005729
time: 0.24505400657653809
time: 2.2395262718200684
[1, 8587] loss_train: 0.005782, loss_test: 0.005738
time: 0.24805426597595215
time: 2.2610106468200684
[1, 8588] loss_train: 0.001652, loss_test: 0.005750
time: 0.24605512619018555
time: 2.20849347114563
[1, 8589] loss_train: 0.009823, loss_test: 0.005716
time: 0.25305700302124023
time: 2.2345077991485596
[1, 8590] loss_train: 0.012926, loss_test: 0.005677
time: 0.2580568790435791
time: 2.2600290775299072
[1, 8591] loss_train: 0.014739, loss_test: 0.005656
time: 0.2490551471710205
time: 2.2545034885406494
[1, 8592] loss_train: 0.003139, loss_test: 0.005677
time: 0.24905657768249512
time: 2.2240235805511475
[1, 8593] loss_train: 0.010043, loss_test: 0.005727
time: 0.24605369567871094
time: 2.2620115280151367
[1, 8594] loss_train: 0.001689, loss_test: 0.005781
time: 0.24405479431152344
time: 2.207493305206299
[1, 8595] loss_train: 0.008055, loss_test: 0.005824
time: 0.24405384063720703
time: 2.230499267578125
[1, 8596] loss_train: 0.004101, loss_test: 0.005848
time: 0.24505400657653809
time: 2.191490650177002
[1, 8597] loss_train: 0.008086, loss_test: 0.005845
time: 0.24405431747436523
time: 2.2410061359405518
[1, 8598] loss_train: 0.010615, loss_test: 0.005815
time: 0.2440783977508545
time: 2.220525026321411
[1, 8599] loss_train: 0.006944, loss_test: 0.005769
time: 0.24505376815795898
time: 2.2214977741241455
[1, 8600] loss_train: 0.004105, loss_test: 0.005718
time: 0.25505614280700684
time: 2.2635064125061035
[1, 8601] loss_train: 0.005180, loss_test: 0.005686
time: 0.24305367469787598
time: 2.2340259552001953
[1, 8602] loss_train: 0.007512, loss_test: 0.005669
time: 0.24605464935302734
time: 2.241518497467041
[1, 8603] loss_train: 0.008468, loss_test: 0.005661
time: 0.2450544834136963
time: 2.241502285003662
[1, 8604] loss_train: 0.011195, loss_test: 0.005659
time: 0.24305367469787598
time: 2.2204959392547607
[1, 8605] loss_train: 0.010221, loss_test: 0.005661
time: 0.24605464935302734
time: 2.2230093479156494
[1, 8606] loss_train: 0.001701, loss_test: 0.005666
time: 0.2450549602508545
time: 2.220506429672241
[1, 8607] loss_train: 0.006229, loss_test: 0.005665
time: 0.24405455589294434
time: 2.205995798110962
[1, 8608] loss_train: 0.011130, loss_test: 0.005663
time: 0.2470555305480957
time: 2.2024929523468018
[1, 8609] loss_train: 0.006918, loss_test: 0.005664
time: 0.24505376815795898
time: 2.206494092941284
[1, 8610] loss_train: 0.005681, loss_test: 0.005664
time: 0.2600572109222412
time: 2.23401141166687
[1, 8611] loss_train: 0.008323, loss_test: 0.005666
time: 0.25205564498901367
time: 2.2735090255737305
[1, 8612] loss_train: 0.005780, loss_test: 0.005666
time: 0.24805450439453125
time: 2.230499267578125
[1, 8613] loss_train: 0.007920, loss_test: 0.005668
time: 0.24405360221862793
time: 2.2460098266601562
[1, 8614] loss_train: 0.005028, loss_test: 0.005665
time: 0.2470550537109375
time: 2.2264978885650635
[1, 8615] loss_train: 0.001394, loss_test: 0.005661
time: 0.2470545768737793
time: 2.2294983863830566
[1, 8616] loss_train: 0.006722, loss_test: 0.005659
time: 0.24305343627929688
time: 2.1934916973114014
[1, 8617] loss_train: 0.008100, loss_test: 0.005659
time: 0.247053861618042
time: 2.231502056121826
[1, 8618] loss_train: 0.011293, loss_test: 0.005658
time: 0.24405455589294434
time: 2.2184953689575195
[1, 8619] loss_train: 0.007443, loss_test: 0.005657
time: 0.24605464935302734
time: 2.2275145053863525
[1, 8620] loss_train: 0.005521, loss_test: 0.005659
time: 0.25705671310424805
time: 2.2655069828033447
[1, 8621] loss_train: 0.002107, loss_test: 0.005661
time: 0.2450542449951172
time: 2.2504658699035645
[1, 8622] loss_train: 0.006780, loss_test: 0.005665
time: 0.2490549087524414
time: 2.216496229171753
[1, 8623] loss_train: 0.011667, loss_test: 0.005674
time: 0.2450547218322754
time: 2.21950626373291
[1, 8624] loss_train: 0.008204, loss_test: 0.005686
time: 0.24505376815795898
time: 2.2164955139160156
[1, 8625] loss_train: 0.008317, loss_test: 0.005700
time: 0.24405503273010254
time: 2.246514320373535
[1, 8626] loss_train: 0.013069, loss_test: 0.005710
time: 0.24405479431152344
time: 2.244501829147339
[1, 8627] loss_train: 0.012199, loss_test: 0.005713
time: 0.24305438995361328
time: 2.2164976596832275
[1, 8628] loss_train: 0.003140, loss_test: 0.005698
time: 0.2450547218322754
time: 2.2375049591064453
[1, 8629] loss_train: 0.002490, loss_test: 0.005682
time: 0.2470550537109375
time: 2.235499858856201
[1, 8630] loss_train: 0.005579, loss_test: 0.005663
time: 0.2540566921234131
time: 2.2635059356689453
[1, 8631] loss_train: 0.011110, loss_test: 0.005653
time: 0.24405431747436523
time: 2.2184958457946777
[1, 8632] loss_train: 0.009527, loss_test: 0.005652
time: 0.24505352973937988
time: 2.2204971313476562
[1, 8633] loss_train: 0.009800, loss_test: 0.005663
time: 0.2490556240081787
time: 2.259505033493042
[1, 8634] loss_train: 0.006997, loss_test: 0.005663
time: 0.24605417251586914
time: 2.2074942588806152
[1, 8635] loss_train: 0.006472, loss_test: 0.005669
time: 0.2490551471710205
time: 2.225531816482544
[1, 8636] loss_train: 0.013162, loss_test: 0.005667
time: 0.24405384063720703
time: 2.2224977016448975
[1, 8637] loss_train: 0.008384, loss_test: 0.005661
time: 0.24505400657653809
time: 2.206493854522705
[1, 8638] loss_train: 0.005128, loss_test: 0.005659
time: 0.2450549602508545
time: 2.235499143600464
[1, 8639] loss_train: 0.010157, loss_test: 0.005661
time: 0.24305319786071777
time: 2.23001766204834
[1, 8640] loss_train: 0.003180, loss_test: 0.005665
time: 0.25705718994140625
time: 2.2665064334869385
[1, 8641] loss_train: 0.006299, loss_test: 0.005670
time: 0.24305391311645508
time: 2.232499599456787
[1, 8642] loss_train: 0.006474, loss_test: 0.005677
time: 0.2450547218322754
time: 2.2415032386779785
[1, 8643] loss_train: 0.003134, loss_test: 0.005681
time: 0.24405407905578613
time: 2.212000608444214
[1, 8644] loss_train: 0.007780, loss_test: 0.005681
time: 0.24805450439453125
time: 2.2104949951171875
[1, 8645] loss_train: 0.003853, loss_test: 0.005679
time: 0.24405360221862793
time: 2.215498208999634
[1, 8646] loss_train: 0.003660, loss_test: 0.005680
time: 0.24405360221862793
time: 2.2114973068237305
[1, 8647] loss_train: 0.006699, loss_test: 0.005684
time: 0.24505400657653809
time: 2.214998483657837
[1, 8648] loss_train: 0.003257, loss_test: 0.005692
time: 0.24406886100769043
time: 2.2114944458007812
[1, 8649] loss_train: 0.004705, loss_test: 0.005700
time: 0.24205398559570312
time: 2.1931707859039307
[1, 8650] loss_train: 0.008814, loss_test: 0.005696
time: 0.263059139251709
time: 2.2895116806030273
[1, 8651] loss_train: 0.005762, loss_test: 0.005694
time: 0.24405455589294434
time: 2.232004165649414
[1, 8652] loss_train: 0.003261, loss_test: 0.005693
time: 0.24806761741638184
time: 2.2304985523223877
[1, 8653] loss_train: 0.005098, loss_test: 0.005694
time: 0.24805545806884766
time: 2.2405169010162354
[1, 8654] loss_train: 0.007396, loss_test: 0.005695
time: 0.24805521965026855
time: 2.221497058868408
[1, 8655] loss_train: 0.010021, loss_test: 0.005698
time: 0.2450547218322754
time: 2.218496084213257
[1, 8656] loss_train: 0.004734, loss_test: 0.005700
time: 0.2490549087524414
time: 2.219496726989746
[1, 8657] loss_train: 0.000786, loss_test: 0.005697
time: 0.24405407905578613
time: 2.203493356704712
[1, 8658] loss_train: 0.003582, loss_test: 0.005693
time: 0.24605417251586914
time: 2.23437237739563
[1, 8659] loss_train: 0.009151, loss_test: 0.005688
time: 0.24407052993774414
time: 2.2105047702789307
[1, 8660] loss_train: 0.005572, loss_test: 0.005687
time: 0.2624526023864746
time: 2.267113447189331
[1, 8661] loss_train: 0.010881, loss_test: 0.005684
time: 0.24305438995361328
time: 2.220496654510498
[1, 8662] loss_train: 0.008455, loss_test: 0.005682
time: 0.24605464935302734
time: 2.1974916458129883
[1, 8663] loss_train: 0.009337, loss_test: 0.005680
time: 0.24405384063720703
time: 2.2405014038085938
[1, 8664] loss_train: 0.009712, loss_test: 0.005679
time: 0.24405360221862793
time: 2.243502378463745
[1, 8665] loss_train: 0.007091, loss_test: 0.005678
time: 0.24405431747436523
time: 2.220496892929077
[1, 8666] loss_train: 0.009429, loss_test: 0.005672
time: 0.24405407905578613
time: 2.2124946117401123
[1, 8667] loss_train: 0.002301, loss_test: 0.005672
time: 0.2490556240081787
time: 2.2066380977630615
[1, 8668] loss_train: 0.010042, loss_test: 0.005674
time: 0.2450549602508545
time: 2.2084083557128906
[1, 8669] loss_train: 0.008266, loss_test: 0.005672
time: 0.24805545806884766
time: 2.2542524337768555
[1, 8670] loss_train: 0.001754, loss_test: 0.005670
time: 0.25705671310424805
time: 2.2625067234039307
[1, 8671] loss_train: 0.006239, loss_test: 0.005666
time: 0.2490549087524414
time: 2.2124955654144287
[1, 8672] loss_train: 0.012937, loss_test: 0.005661
time: 0.24605441093444824
time: 2.218496561050415
[1, 8673] loss_train: 0.013488, loss_test: 0.005657
time: 0.2490546703338623
time: 2.2385010719299316
[1, 8674] loss_train: 0.001956, loss_test: 0.005655
time: 0.2450544834136963
time: 2.233499765396118
[1, 8675] loss_train: 0.011943, loss_test: 0.005656
time: 0.2470550537109375
time: 2.246516466140747
[1, 8676] loss_train: 0.004111, loss_test: 0.005657
time: 0.24305391311645508
time: 2.231498956680298
[1, 8677] loss_train: 0.003159, loss_test: 0.005657
time: 0.2510552406311035
time: 2.2665069103240967
[1, 8678] loss_train: 0.005519, loss_test: 0.005658
time: 0.2450542449951172
time: 2.2235143184661865
[1, 8679] loss_train: 0.005999, loss_test: 0.005658
time: 0.24305367469787598
time: 2.207002639770508
[1, 8680] loss_train: 0.005790, loss_test: 0.005658
time: 0.254056453704834
time: 2.250502586364746
[1, 8681] loss_train: 0.003634, loss_test: 0.005657
time: 0.24405431747436523
time: 2.2545034885406494
[1, 8682] loss_train: 0.001988, loss_test: 0.005659
time: 0.24405431747436523
time: 2.2064931392669678
[1, 8683] loss_train: 0.003099, loss_test: 0.005661
time: 0.24405360221862793
time: 2.203495740890503
[1, 8684] loss_train: 0.006078, loss_test: 0.005661
time: 0.24405407905578613
time: 2.234530448913574
[1, 8685] loss_train: 0.004692, loss_test: 0.005660
time: 0.24405407905578613
time: 2.2124946117401123
[1, 8686] loss_train: 0.003973, loss_test: 0.005663
time: 0.24305438995361328
time: 2.232516288757324
[1, 8687] loss_train: 0.012549, loss_test: 0.005662
time: 0.24505400657653809
time: 2.239131212234497
[1, 8688] loss_train: 0.011539, loss_test: 0.005658
time: 0.24305295944213867
time: 2.22811222076416
[1, 8689] loss_train: 0.006463, loss_test: 0.005658
time: 0.24405384063720703
time: 2.2525038719177246
[1, 8690] loss_train: 0.009934, loss_test: 0.005662
time: 0.25505709648132324
time: 2.2405412197113037
[1, 8691] loss_train: 0.004547, loss_test: 0.005667
time: 0.24497580528259277
time: 2.219496726989746
[1, 8692] loss_train: 0.011666, loss_test: 0.005673
time: 0.24405455589294434
time: 2.2124946117401123
[1, 8693] loss_train: 0.003654, loss_test: 0.005674
time: 0.2450542449951172
time: 2.204996347427368
[1, 8694] loss_train: 0.004827, loss_test: 0.005674
time: 0.2490682601928711
time: 2.211160898208618
[1, 8695] loss_train: 0.003885, loss_test: 0.005676
time: 0.24405384063720703
time: 2.208494186401367
[1, 8696] loss_train: 0.015240, loss_test: 0.005677
time: 0.2470550537109375
time: 2.2114946842193604
[1, 8697] loss_train: 0.008401, loss_test: 0.005677
time: 0.24305319786071777
time: 2.2214972972869873
[1, 8698] loss_train: 0.006623, loss_test: 0.005677
time: 0.24405455589294434
time: 2.2425014972686768
[1, 8699] loss_train: 0.004189, loss_test: 0.005680
time: 0.24405360221862793
time: 2.2439184188842773
[1, 8700] loss_train: 0.004312, loss_test: 0.005684
time: 0.256056547164917
time: 2.2635066509246826
[1, 8701] loss_train: 0.007861, loss_test: 0.005684
time: 0.24306750297546387
time: 2.2114949226379395
[1, 8702] loss_train: 0.003094, loss_test: 0.005688
time: 0.24306678771972656
time: 2.248502492904663
[1, 8703] loss_train: 0.009044, loss_test: 0.005687
time: 0.24305343627929688
time: 2.231513261795044
[1, 8704] loss_train: 0.002340, loss_test: 0.005688
time: 0.24405384063720703
time: 2.2294983863830566
[1, 8705] loss_train: 0.005458, loss_test: 0.005688
time: 0.2450549602508545
time: 2.2124946117401123
[1, 8706] loss_train: 0.007544, loss_test: 0.005685
time: 0.24305367469787598
time: 2.207505702972412
[1, 8707] loss_train: 0.006075, loss_test: 0.005684
time: 0.2440657615661621
time: 2.1951076984405518
[1, 8708] loss_train: 0.008419, loss_test: 0.005680
time: 0.2470545768737793
time: 2.2084946632385254
[1, 8709] loss_train: 0.003765, loss_test: 0.005678
time: 0.24805450439453125
time: 2.220522165298462
[1, 8710] loss_train: 0.004956, loss_test: 0.005676
time: 0.25505685806274414
time: 2.2415032386779785
[1, 8711] loss_train: 0.003595, loss_test: 0.005676
time: 0.25205540657043457
time: 2.231499433517456
[1, 8712] loss_train: 0.008366, loss_test: 0.005679
time: 0.2450547218322754
time: 2.219496488571167
[1, 8713] loss_train: 0.007489, loss_test: 0.005679
time: 0.24805450439453125
time: 2.2234981060028076
[1, 8714] loss_train: 0.005904, loss_test: 0.005680
time: 0.24405384063720703
time: 2.2284984588623047
[1, 8715] loss_train: 0.007400, loss_test: 0.005679
time: 0.2450544834136963
time: 2.2250115871429443
[1, 8716] loss_train: 0.002441, loss_test: 0.005682
time: 0.24505376815795898
time: 2.2345004081726074
[1, 8717] loss_train: 0.008163, loss_test: 0.005691
time: 0.24405407905578613
time: 2.2280030250549316
[1, 8718] loss_train: 0.006622, loss_test: 0.005698
time: 0.2450549602508545
time: 2.1894891262054443
[1, 8719] loss_train: 0.005098, loss_test: 0.005707
time: 0.24405479431152344
time: 2.2145469188690186
[1, 8720] loss_train: 0.004556, loss_test: 0.005711
time: 0.2560567855834961
time: 2.2270734310150146
[1, 8721] loss_train: 0.006235, loss_test: 0.005706
time: 0.24405407905578613
time: 2.2385010719299316
[1, 8722] loss_train: 0.007110, loss_test: 0.005693
time: 0.24205350875854492
time: 2.2214972972869873
[1, 8723] loss_train: 0.011657, loss_test: 0.005687
time: 0.24405336380004883
time: 2.242502212524414
[1, 8724] loss_train: 0.008464, loss_test: 0.005683
time: 0.24305343627929688
time: 2.206494092941284
[1, 8725] loss_train: 0.008639, loss_test: 0.005682
time: 0.24805545806884766
time: 2.225966215133667
[1, 8726] loss_train: 0.008488, loss_test: 0.005680
time: 0.24605512619018555
time: 2.228484869003296
[1, 8727] loss_train: 0.009787, loss_test: 0.005678
time: 0.24506711959838867
time: 2.179488182067871
[1, 8728] loss_train: 0.002417, loss_test: 0.005678
time: 0.2510552406311035
time: 2.2254984378814697
[1, 8729] loss_train: 0.011558, loss_test: 0.005677
time: 0.24405384063720703
time: 2.208505868911743
[1, 8730] loss_train: 0.013549, loss_test: 0.005673
time: 0.25705718994140625
time: 2.2555043697357178
[1, 8731] loss_train: 0.005899, loss_test: 0.005671
time: 0.2450547218322754
time: 2.2385003566741943
[1, 8732] loss_train: 0.008571, loss_test: 0.005668
time: 0.2450544834136963
time: 2.2325022220611572
[1, 8733] loss_train: 0.011412, loss_test: 0.005667
time: 0.24605441093444824
time: 2.2345001697540283
[1, 8734] loss_train: 0.007093, loss_test: 0.005670
time: 0.24405384063720703
time: 2.208494186401367
[1, 8735] loss_train: 0.006116, loss_test: 0.005672
time: 0.2470550537109375
time: 2.2135066986083984
[1, 8736] loss_train: 0.000957, loss_test: 0.005676
time: 0.24305367469787598
time: 2.205493688583374
[1, 8737] loss_train: 0.002879, loss_test: 0.005674
time: 0.24505376815795898
time: 2.2105064392089844
[1, 8738] loss_train: 0.007032, loss_test: 0.005668
time: 0.24405384063720703
time: 2.2164957523345947
[1, 8739] loss_train: 0.001909, loss_test: 0.005662
time: 0.24805498123168945
time: 2.1864981651306152
[1, 8740] loss_train: 0.007546, loss_test: 0.005662
time: 0.2560572624206543
time: 2.230498790740967
[1, 8741] loss_train: 0.009586, loss_test: 0.005664
time: 0.2510554790496826
time: 2.2314987182617188
[1, 8742] loss_train: 0.010017, loss_test: 0.005665
time: 0.2450544834136963
time: 2.2274980545043945
[1, 8743] loss_train: 0.014162, loss_test: 0.005668
time: 0.2470550537109375
time: 2.2264978885650635
[1, 8744] loss_train: 0.008643, loss_test: 0.005668
time: 0.24506735801696777
time: 2.2254981994628906
[1, 8745] loss_train: 0.001579, loss_test: 0.005670
time: 0.24805498123168945
time: 2.221496820449829
[1, 8746] loss_train: 0.010207, loss_test: 0.005664
time: 0.24970126152038574
time: 2.226498603820801
[1, 8747] loss_train: 0.015027, loss_test: 0.005663
time: 0.24305438995361328
time: 2.2250125408172607
[1, 8748] loss_train: 0.012403, loss_test: 0.005660
time: 0.24405407905578613
time: 2.2415032386779785
[1, 8749] loss_train: 0.003406, loss_test: 0.005662
time: 0.24405455589294434
time: 2.247039556503296
[1, 8750] loss_train: 0.017760, loss_test: 0.005673
time: 0.25505805015563965
time: 2.2555041313171387
[1, 8751] loss_train: 0.004672, loss_test: 0.005691
time: 0.24405360221862793
time: 2.2335000038146973
[1, 8752] loss_train: 0.003929, loss_test: 0.005702
time: 0.2450547218322754
time: 2.220496892929077
[1, 8753] loss_train: 0.001330, loss_test: 0.005698
time: 0.24305367469787598
time: 2.194491386413574
[1, 8754] loss_train: 0.002473, loss_test: 0.005687
time: 0.24405360221862793
time: 2.2565042972564697
[1, 8755] loss_train: 0.002491, loss_test: 0.005683
time: 0.24405527114868164
time: 2.205493450164795
[1, 8756] loss_train: 0.004602, loss_test: 0.005687
time: 0.2470552921295166
time: 2.1983299255371094
[1, 8757] loss_train: 0.007485, loss_test: 0.005697
time: 0.24405360221862793
time: 2.2084946632385254
[1, 8758] loss_train: 0.016952, loss_test: 0.005705
time: 0.24505400657653809
time: 2.2215070724487305
[1, 8759] loss_train: 0.004136, loss_test: 0.005711
time: 0.2450547218322754
time: 2.2885115146636963
[1, 8760] loss_train: 0.005188, loss_test: 0.005714
time: 0.2560570240020752
time: 2.2500264644622803
[1, 8761] loss_train: 0.006395, loss_test: 0.005718
time: 0.24405384063720703
time: 2.203493118286133
[1, 8762] loss_train: 0.004004, loss_test: 0.005723
time: 0.24805545806884766
time: 2.2405011653900146
[1, 8763] loss_train: 0.009919, loss_test: 0.005727
time: 0.24605488777160645
time: 2.2034928798675537
[1, 8764] loss_train: 0.003826, loss_test: 0.005733
time: 0.2490546703338623
time: 2.241502046585083
[1, 8765] loss_train: 0.008771, loss_test: 0.005727
time: 0.24405455589294434
time: 2.1955080032348633
[1, 8766] loss_train: 0.007419, loss_test: 0.005719
time: 0.2450542449951172
time: 2.238481044769287
[1, 8767] loss_train: 0.008835, loss_test: 0.005707
time: 0.2450542449951172
time: 2.230501413345337
[1, 8768] loss_train: 0.007262, loss_test: 0.005692
time: 0.24605488777160645
time: 2.2305004596710205
[1, 8769] loss_train: 0.006101, loss_test: 0.005683
time: 0.24405360221862793
time: 2.2146337032318115
[1, 8770] loss_train: 0.005686, loss_test: 0.005682
time: 0.25505685806274414
time: 2.2708895206451416
[1, 8771] loss_train: 0.001205, loss_test: 0.005684
time: 0.2440657615661621
time: 2.243501901626587
[1, 8772] loss_train: 0.008675, loss_test: 0.005690
time: 0.24305963516235352
time: 2.2615060806274414
[1, 8773] loss_train: 0.002356, loss_test: 0.005696
time: 0.24405431747436523
time: 2.231498956680298
[1, 8774] loss_train: 0.005255, loss_test: 0.005699
time: 0.24405360221862793
time: 2.2014923095703125
[1, 8775] loss_train: 0.016657, loss_test: 0.005700
time: 0.2450544834136963
time: 2.2274978160858154
[1, 8776] loss_train: 0.003205, loss_test: 0.005702
time: 0.24505352973937988
time: 2.2020230293273926
[1, 8777] loss_train: 0.009022, loss_test: 0.005701
time: 0.24405360221862793
time: 2.215498447418213
[1, 8778] loss_train: 0.001615, loss_test: 0.005696
time: 0.24506640434265137
time: 2.1935019493103027
[1, 8779] loss_train: 0.008165, loss_test: 0.005688
time: 0.2450544834136963
time: 2.1884889602661133
[1, 8780] loss_train: 0.004065, loss_test: 0.005682
time: 0.2620580196380615
time: 2.2655255794525146
[1, 8781] loss_train: 0.003541, loss_test: 0.005682
time: 0.25005507469177246
time: 2.2365005016326904
[1, 8782] loss_train: 0.005720, loss_test: 0.005687
time: 0.2450547218322754
time: 2.246511936187744
[1, 8783] loss_train: 0.004754, loss_test: 0.005696
time: 0.2530555725097656
time: 2.277519941329956
[1, 8784] loss_train: 0.006147, loss_test: 0.005711
time: 0.2495594024658203
time: 2.2455029487609863
[1, 8785] loss_train: 0.014872, loss_test: 0.005717
time: 0.2490549087524414
time: 2.247502565383911
[1, 8786] loss_train: 0.015447, loss_test: 0.005706
time: 0.24605441093444824
time: 2.2180097103118896
[1, 8787] loss_train: 0.005126, loss_test: 0.005691
time: 0.249068021774292
time: 2.2044925689697266
[1, 8788] loss_train: 0.006794, loss_test: 0.005678
time: 0.2450542449951172
time: 2.2245283126831055
[1, 8789] loss_train: 0.009366, loss_test: 0.005677
time: 0.24605512619018555
time: 2.2264981269836426
[1, 8790] loss_train: 0.004198, loss_test: 0.005682
time: 0.25705695152282715
time: 2.2435102462768555
[1, 8791] loss_train: 0.009892, loss_test: 0.005695
time: 0.24305343627929688
time: 2.1984922885894775
[1, 8792] loss_train: 0.002439, loss_test: 0.005708
time: 0.24405455589294434
time: 2.233499526977539
[1, 8793] loss_train: 0.001672, loss_test: 0.005712
time: 0.24605441093444824
time: 2.2114951610565186
[1, 8794] loss_train: 0.006795, loss_test: 0.005715
time: 0.24305343627929688
time: 2.2264981269836426
[1, 8795] loss_train: 0.011490, loss_test: 0.005719
time: 0.24405384063720703
time: 2.2750191688537598
[1, 8796] loss_train: 0.018384, loss_test: 0.005722
time: 0.24305462837219238
time: 2.234499931335449
[1, 8797] loss_train: 0.005758, loss_test: 0.005711
time: 0.24405336380004883
time: 2.234499931335449
[1, 8798] loss_train: 0.006201, loss_test: 0.005696
time: 0.24405384063720703
time: 2.228498935699463
[1, 8799] loss_train: 0.012751, loss_test: 0.005686
time: 0.24305415153503418
time: 2.229515790939331
[1, 8800] loss_train: 0.004777, loss_test: 0.005673
time: 0.2560563087463379
time: 2.228498935699463
[1, 8801] loss_train: 0.004620, loss_test: 0.005664
time: 0.24405479431152344
time: 2.2245070934295654
[1, 8802] loss_train: 0.009274, loss_test: 0.005662
time: 0.24305319786071777
time: 2.2215218544006348
[1, 8803] loss_train: 0.007210, loss_test: 0.005662
time: 0.24505400657653809
time: 2.2079975605010986
[1, 8804] loss_train: 0.001333, loss_test: 0.005663
time: 0.25005578994750977
time: 2.2345070838928223
[1, 8805] loss_train: 0.004554, loss_test: 0.005665
time: 0.24606752395629883
time: 2.2184970378875732
[1, 8806] loss_train: 0.007651, loss_test: 0.005670
time: 0.24805521965026855
time: 2.2264974117279053
[1, 8807] loss_train: 0.008934, loss_test: 0.005675
time: 0.24405455589294434
time: 2.2405099868774414
[1, 8808] loss_train: 0.005331, loss_test: 0.005678
time: 0.24805545806884766
time: 2.2124950885772705
[1, 8809] loss_train: 0.004524, loss_test: 0.005680
time: 0.24308061599731445
time: 2.243511199951172
[1, 8810] loss_train: 0.002527, loss_test: 0.005683
time: 0.26105761528015137
time: 2.258671522140503
[1, 8811] loss_train: 0.005380, loss_test: 0.005685
time: 0.24406766891479492
time: 2.242518424987793
[1, 8812] loss_train: 0.004754, loss_test: 0.005686
time: 0.24505138397216797
time: 2.222498655319214
[1, 8813] loss_train: 0.001079, loss_test: 0.005691
time: 0.24605441093444824
time: 2.2254981994628906
[1, 8814] loss_train: 0.000992, loss_test: 0.005697
time: 0.24405384063720703
time: 2.2274985313415527
[1, 8815] loss_train: 0.006977, loss_test: 0.005698
time: 0.24405431747436523
time: 2.2010135650634766
[1, 8816] loss_train: 0.003897, loss_test: 0.005702
time: 0.2450542449951172
time: 2.2515037059783936
[1, 8817] loss_train: 0.015553, loss_test: 0.005688
time: 0.24606013298034668
time: 2.2144947052001953
[1, 8818] loss_train: 0.010825, loss_test: 0.005681
time: 0.2450542449951172
time: 2.265507221221924
[1, 8819] loss_train: 0.005680, loss_test: 0.005683
time: 0.2450544834136963
time: 2.1965105533599854
[1, 8820] loss_train: 0.006158, loss_test: 0.005694
time: 0.25705718994140625
time: 2.2490413188934326
[1, 8821] loss_train: 0.003435, loss_test: 0.005707
time: 0.25205540657043457
time: 2.223497152328491
[1, 8822] loss_train: 0.004430, loss_test: 0.005721
time: 0.2450547218322754
time: 2.194490671157837
[1, 8823] loss_train: 0.001919, loss_test: 0.005735
time: 0.24305319786071777
time: 2.216496229171753
[1, 8824] loss_train: 0.003431, loss_test: 0.005750
time: 0.24505376815795898
time: 2.2134950160980225
[1, 8825] loss_train: 0.006664, loss_test: 0.005759
time: 0.2510554790496826
time: 2.2405011653900146
[1, 8826] loss_train: 0.009713, loss_test: 0.005764
time: 0.24605512619018555
time: 2.186502695083618
[1, 8827] loss_train: 0.007046, loss_test: 0.005741
time: 0.24805593490600586
time: 2.2445716857910156
[1, 8828] loss_train: 0.005389, loss_test: 0.005723
time: 0.24805450439453125
time: 2.1714885234832764
[1, 8829] loss_train: 0.002077, loss_test: 0.005704
time: 0.24305367469787598
time: 2.2162766456604004
[1, 8830] loss_train: 0.006113, loss_test: 0.005690
time: 0.2620582580566406
time: 2.258505344390869
[1, 8831] loss_train: 0.009892, loss_test: 0.005681
time: 0.24505376815795898
time: 2.2345168590545654
[1, 8832] loss_train: 0.006342, loss_test: 0.005676
time: 0.24405503273010254
time: 2.2244973182678223
[1, 8833] loss_train: 0.011410, loss_test: 0.005680
time: 0.24305391311645508
time: 2.2314984798431396
[1, 8834] loss_train: 0.004737, loss_test: 0.005696
time: 0.24805498123168945
time: 2.1955084800720215
[1, 8835] loss_train: 0.005292, loss_test: 0.005723
time: 0.24205374717712402
time: 2.195491313934326
[1, 8836] loss_train: 0.003697, loss_test: 0.005757
time: 0.24405407905578613
time: 2.2004921436309814
[1, 8837] loss_train: 0.001022, loss_test: 0.005800
time: 0.24405407905578613
time: 2.2555043697357178
[1, 8838] loss_train: 0.010722, loss_test: 0.005788
time: 0.24543237686157227
time: 2.2027766704559326
[1, 8839] loss_train: 0.010545, loss_test: 0.005763
time: 0.24405646324157715
time: 2.2054927349090576
[1, 8840] loss_train: 0.006809, loss_test: 0.005744
time: 0.2630581855773926
time: 2.2465221881866455
[1, 8841] loss_train: 0.004970, loss_test: 0.005729
time: 0.25005578994750977
time: 2.1945078372955322
[1, 8842] loss_train: 0.002889, loss_test: 0.005723
time: 0.25005578994750977
time: 2.222500801086426
[1, 8843] loss_train: 0.002606, loss_test: 0.005722
time: 0.24506831169128418
time: 2.2264983654022217
[1, 8844] loss_train: 0.005436, loss_test: 0.005717
time: 0.24305343627929688
time: 2.22650146484375
[1, 8845] loss_train: 0.010215, loss_test: 0.005715
time: 0.2490546703338623
time: 2.266523599624634
[1, 8846] loss_train: 0.003053, loss_test: 0.005713
time: 0.24305367469787598
time: 2.2355003356933594
[1, 8847] loss_train: 0.004462, loss_test: 0.005710
time: 0.24405479431152344
time: 2.247502088546753
[1, 8848] loss_train: 0.003722, loss_test: 0.005705
time: 0.24505400657653809
time: 2.214495897293091
[1, 8849] loss_train: 0.005046, loss_test: 0.005705
time: 0.24405479431152344
time: 2.235499382019043
[1, 8850] loss_train: 0.004268, loss_test: 0.005703
time: 0.25505661964416504
time: 2.25701904296875
[1, 8851] loss_train: 0.008077, loss_test: 0.005704
time: 0.24305391311645508
time: 2.2144951820373535
[1, 8852] loss_train: 0.006596, loss_test: 0.005704
time: 0.24305248260498047
time: 2.2330071926116943
[1, 8853] loss_train: 0.012004, loss_test: 0.005704
time: 0.24405360221862793
time: 2.191995859146118
[1, 8854] loss_train: 0.008981, loss_test: 0.005701
time: 0.24505400657653809
time: 2.2385013103485107
[1, 8855] loss_train: 0.008941, loss_test: 0.005693
time: 0.24605441093444824
time: 2.21049427986145
[1, 8856] loss_train: 0.003445, loss_test: 0.005686
time: 0.24305415153503418
time: 2.2515037059783936
[1, 8857] loss_train: 0.009854, loss_test: 0.005683
time: 0.24505400657653809
time: 2.226499319076538
[1, 8858] loss_train: 0.006130, loss_test: 0.005680
time: 0.24505400657653809
time: 2.234499931335449
[1, 8859] loss_train: 0.007829, loss_test: 0.005673
time: 0.24605512619018555
time: 2.2134947776794434
[1, 8860] loss_train: 0.003937, loss_test: 0.005666
time: 0.2580571174621582
time: 2.266507148742676
[1, 8861] loss_train: 0.004385, loss_test: 0.005662
time: 0.252056360244751
time: 2.2154948711395264
[1, 8862] loss_train: 0.000993, loss_test: 0.005661
time: 0.24805617332458496
time: 2.230497360229492
[1, 8863] loss_train: 0.000786, loss_test: 0.005664
time: 0.2510559558868408
time: 2.2120003700256348
[1, 8864] loss_train: 0.001004, loss_test: 0.005671
time: 0.24506735801696777
time: 2.204493522644043
[1, 8865] loss_train: 0.008974, loss_test: 0.005677
time: 0.24405431747436523
time: 2.243501663208008
[1, 8866] loss_train: 0.009594, loss_test: 0.005680
time: 0.24305343627929688
time: 2.235506534576416
[1, 8867] loss_train: 0.014822, loss_test: 0.005671
time: 0.24405384063720703
time: 2.2124953269958496
[1, 8868] loss_train: 0.006188, loss_test: 0.005667
time: 0.2450542449951172
time: 2.2335336208343506
[1, 8869] loss_train: 0.006774, loss_test: 0.005662
time: 0.2450547218322754
time: 2.2345004081726074
[1, 8870] loss_train: 0.007502, loss_test: 0.005660
time: 0.2560575008392334
time: 2.2607505321502686
[1, 8871] loss_train: 0.009509, loss_test: 0.005659
time: 0.2450544834136963
time: 2.2104947566986084
[1, 8872] loss_train: 0.010526, loss_test: 0.005662
time: 0.24606585502624512
time: 2.189013957977295
[1, 8873] loss_train: 0.005930, loss_test: 0.005671
time: 0.24305367469787598
time: 2.203493118286133
[1, 8874] loss_train: 0.006438, loss_test: 0.005681
time: 0.24505400657653809
time: 2.220015287399292
[1, 8875] loss_train: 0.010057, loss_test: 0.005700
time: 0.24305367469787598
time: 2.2224974632263184
[1, 8876] loss_train: 0.002483, loss_test: 0.005715
time: 0.24658942222595215
time: 2.2094945907592773
[1, 8877] loss_train: 0.008811, loss_test: 0.005717
time: 0.24355769157409668
time: 2.1850123405456543
[1, 8878] loss_train: 0.011009, loss_test: 0.005721
time: 0.2490549087524414
time: 2.241501569747925
[1, 8879] loss_train: 0.002643, loss_test: 0.005718
time: 0.2450547218322754
time: 2.232499122619629
[1, 8880] loss_train: 0.004009, loss_test: 0.005710
time: 0.2580571174621582
time: 2.24450421333313
[1, 8881] loss_train: 0.001990, loss_test: 0.005693
time: 0.24307680130004883
time: 2.208493232727051
[1, 8882] loss_train: 0.007168, loss_test: 0.005673
time: 0.2431480884552002
time: 2.2455122470855713
[1, 8883] loss_train: 0.006521, loss_test: 0.005657
time: 0.24605417251586914
time: 2.2345001697540283
[1, 8884] loss_train: 0.003425, loss_test: 0.005651
time: 0.24505376815795898
time: 2.237501382827759
[1, 8885] loss_train: 0.007084, loss_test: 0.005654
time: 0.24305343627929688
time: 2.216496467590332
[1, 8886] loss_train: 0.006742, loss_test: 0.005666
time: 0.24405360221862793
time: 2.206494092941284
[1, 8887] loss_train: 0.006220, loss_test: 0.005678
time: 0.24405407905578613
time: 2.244502305984497
[1, 8888] loss_train: 0.003073, loss_test: 0.005695
time: 0.24305343627929688
time: 2.2084946632385254
[1, 8889] loss_train: 0.009535, loss_test: 0.005702
time: 0.24408197402954102
time: 2.220512628555298
[1, 8890] loss_train: 0.006205, loss_test: 0.005702
time: 0.25655484199523926
time: 2.24650239944458
[1, 8891] loss_train: 0.006038, loss_test: 0.005697
time: 0.24606704711914062
time: 2.2220139503479004
[1, 8892] loss_train: 0.004431, loss_test: 0.005695
time: 0.24307703971862793
time: 2.217496156692505
[1, 8893] loss_train: 0.016102, loss_test: 0.005677
time: 0.2510566711425781
time: 2.2593729496002197
[1, 8894] loss_train: 0.010693, loss_test: 0.005667
time: 0.2440791130065918
time: 2.2585055828094482
[1, 8895] loss_train: 0.003727, loss_test: 0.005668
time: 0.24405360221862793
time: 2.2300171852111816
[1, 8896] loss_train: 0.006023, loss_test: 0.005674
time: 0.24605417251586914
time: 2.219496488571167
[1, 8897] loss_train: 0.009218, loss_test: 0.005685
time: 0.2470543384552002
time: 2.194491386413574
[1, 8898] loss_train: 0.010087, loss_test: 0.005708
time: 0.2450547218322754
time: 2.2044928073883057
[1, 8899] loss_train: 0.005318, loss_test: 0.005735
time: 0.2470548152923584
time: 2.244513750076294
[1, 8900] loss_train: 0.004657, loss_test: 0.005762
time: 0.25705671310424805
time: 2.221497058868408
[1, 8901] loss_train: 0.005445, loss_test: 0.005776
time: 0.24406671524047852
time: 2.246511220932007
[1, 8902] loss_train: 0.006915, loss_test: 0.005775
time: 0.24405503273010254
time: 2.2224972248077393
[1, 8903] loss_train: 0.002420, loss_test: 0.005769
time: 0.24405407905578613
time: 2.2355000972747803
[1, 8904] loss_train: 0.003704, loss_test: 0.005763
time: 0.24105429649353027
time: 2.219466209411621
[1, 8905] loss_train: 0.001279, loss_test: 0.005711
time: 0.24405360221862793
time: 2.264098882675171
[1, 8906] loss_train: 0.001873, loss_test: 0.005685
time: 0.24405384063720703
time: 2.233499765396118
[1, 8907] loss_train: 0.002822, loss_test: 0.005676
time: 0.24307894706726074
time: 2.215502977371216
[1, 8908] loss_train: 0.003259, loss_test: 0.005679
time: 0.24305462837219238
time: 2.2435009479522705
[1, 8909] loss_train: 0.010510, loss_test: 0.005683
time: 0.24605560302734375
time: 2.1960067749023438
[1, 8910] loss_train: 0.003700, loss_test: 0.005693
time: 0.2580575942993164
time: 2.212012767791748
[1, 8911] loss_train: 0.003487, loss_test: 0.005706
time: 0.24706649780273438
time: 2.207494020462036
[1, 8912] loss_train: 0.005216, loss_test: 0.005726
time: 0.24405407905578613
time: 2.211493968963623
[1, 8913] loss_train: 0.001830, loss_test: 0.005746
time: 0.24605488777160645
time: 2.212498664855957
[1, 8914] loss_train: 0.003100, loss_test: 0.005764
time: 0.2490549087524414
time: 2.2124955654144287
[1, 8915] loss_train: 0.006006, loss_test: 0.005782
time: 0.24605441093444824
time: 2.2595226764678955
[1, 8916] loss_train: 0.009748, loss_test: 0.005776
time: 0.25005507469177246
time: 2.2455029487609863
[1, 8917] loss_train: 0.005211, loss_test: 0.005767
time: 0.2510552406311035
time: 2.226498603820801
[1, 8918] loss_train: 0.004475, loss_test: 0.005758
time: 0.2490553855895996
time: 2.243501901626587
[1, 8919] loss_train: 0.006160, loss_test: 0.005746
time: 0.24305367469787598
time: 2.2265007495880127
[1, 8920] loss_train: 0.002303, loss_test: 0.005737
time: 0.2630584239959717
time: 2.2755086421966553
[1, 8921] loss_train: 0.004717, loss_test: 0.005731
time: 0.24605488777160645
time: 2.2204959392547607
[1, 8922] loss_train: 0.003235, loss_test: 0.005725
time: 0.2470545768737793
time: 2.232499837875366
[1, 8923] loss_train: 0.006528, loss_test: 0.005716
time: 0.2440662384033203
time: 2.217498779296875
[1, 8924] loss_train: 0.006507, loss_test: 0.005705
time: 0.24405360221862793
time: 2.2014927864074707
[1, 8925] loss_train: 0.005057, loss_test: 0.005694
time: 0.24405384063720703
time: 2.242501974105835
[1, 8926] loss_train: 0.000886, loss_test: 0.005687
time: 0.24405360221862793
time: 2.2300333976745605
[1, 8927] loss_train: 0.008953, loss_test: 0.005676
time: 0.24405479431152344
time: 2.225497245788574
[1, 8928] loss_train: 0.003597, loss_test: 0.005670
time: 0.24305415153503418
time: 2.207512140274048
[1, 8929] loss_train: 0.005727, loss_test: 0.005672
time: 0.24305391311645508
time: 2.2200441360473633
[1, 8930] loss_train: 0.000563, loss_test: 0.005682
time: 0.25705718994140625
time: 2.2515056133270264
[1, 8931] loss_train: 0.008481, loss_test: 0.005707
time: 0.24405455589294434
time: 2.223496437072754
[1, 8932] loss_train: 0.011327, loss_test: 0.005733
time: 0.24305367469787598
time: 2.220059871673584
[1, 8933] loss_train: 0.005713, loss_test: 0.005764
time: 0.24405407905578613
time: 2.2123451232910156
[1, 8934] loss_train: 0.009840, loss_test: 0.005791
time: 0.24505352973937988
time: 2.2025036811828613
[1, 8935] loss_train: 0.006260, loss_test: 0.005766
time: 0.2490546703338623
time: 2.2335002422332764
[1, 8936] loss_train: 0.003944, loss_test: 0.005728
time: 0.24405360221862793
time: 2.241501808166504
[1, 8937] loss_train: 0.004548, loss_test: 0.005696
time: 0.2490549087524414
time: 2.208494186401367
[1, 8938] loss_train: 0.003603, loss_test: 0.005682
time: 0.2450544834136963
time: 2.2035229206085205
[1, 8939] loss_train: 0.003805, loss_test: 0.005674
time: 0.24405407905578613
time: 2.2274985313415527
[1, 8940] loss_train: 0.007356, loss_test: 0.005675
time: 0.2560570240020752
time: 2.24851393699646
[1, 8941] loss_train: 0.006265, loss_test: 0.005681
time: 0.24305391311645508
time: 2.23252010345459
[1, 8942] loss_train: 0.005860, loss_test: 0.005690
time: 0.24305415153503418
time: 2.244501829147339
[1, 8943] loss_train: 0.012941, loss_test: 0.005695
time: 0.24305438995361328
time: 2.234499931335449
[1, 8944] loss_train: 0.001729, loss_test: 0.005704
time: 0.24505352973937988
time: 2.217496633529663
[1, 8945] loss_train: 0.004818, loss_test: 0.005715
time: 0.24605512619018555
time: 2.2294979095458984
[1, 8946] loss_train: 0.002786, loss_test: 0.005729
time: 0.2450542449951172
time: 2.2154953479766846
[1, 8947] loss_train: 0.012276, loss_test: 0.005729
time: 0.24305415153503418
time: 2.2385013103485107
[1, 8948] loss_train: 0.004524, loss_test: 0.005729
time: 0.24505400657653809
time: 2.2155070304870605
[1, 8949] loss_train: 0.012751, loss_test: 0.005732
time: 0.24306631088256836
time: 2.2134952545166016
[1, 8950] loss_train: 0.006942, loss_test: 0.005734
time: 0.25505733489990234
time: 2.259504795074463
[1, 8951] loss_train: 0.004447, loss_test: 0.005724
time: 0.24605441093444824
time: 2.2124950885772705
[1, 8952] loss_train: 0.003349, loss_test: 0.005715
time: 0.24305343627929688
time: 2.203493595123291
[1, 8953] loss_train: 0.004559, loss_test: 0.005704
time: 0.2450544834136963
time: 2.2174956798553467
[1, 8954] loss_train: 0.001399, loss_test: 0.005698
time: 0.24805545806884766
time: 2.221496820449829
[1, 8955] loss_train: 0.004734, loss_test: 0.005694
time: 0.24405384063720703
time: 2.217514991760254
[1, 8956] loss_train: 0.004160, loss_test: 0.005695
time: 0.24805474281311035
time: 2.233499765396118
[1, 8957] loss_train: 0.000838, loss_test: 0.005702
time: 0.24405336380004883
time: 2.218496799468994
[1, 8958] loss_train: 0.006152, loss_test: 0.005710
time: 0.24405407905578613
time: 2.220496892929077
[1, 8959] loss_train: 0.005436, loss_test: 0.005718
time: 0.24406671524047852
time: 2.225497245788574
[1, 8960] loss_train: 0.009668, loss_test: 0.005713
time: 0.256056547164917
time: 2.2605059146881104
[1, 8961] loss_train: 0.009165, loss_test: 0.005709
time: 0.24505400657653809
time: 2.1964917182922363
[1, 8962] loss_train: 0.001666, loss_test: 0.005708
time: 0.2450542449951172
time: 2.216495990753174
[1, 8963] loss_train: 0.001719, loss_test: 0.005709
time: 0.24305367469787598
time: 2.2274985313415527
[1, 8964] loss_train: 0.007285, loss_test: 0.005714
time: 0.24406766891479492
time: 2.2264983654022217
[1, 8965] loss_train: 0.008376, loss_test: 0.005701
time: 0.24406933784484863
time: 2.2335097789764404
[1, 8966] loss_train: 0.004150, loss_test: 0.005692
time: 0.24305415153503418
time: 2.2235138416290283
[1, 8967] loss_train: 0.004629, loss_test: 0.005685
time: 0.24405455589294434
time: 2.2365000247955322
[1, 8968] loss_train: 0.003074, loss_test: 0.005681
time: 0.25208282470703125
time: 2.2154953479766846
[1, 8969] loss_train: 0.006329, loss_test: 0.005676
time: 0.2450547218322754
time: 2.21402907371521
[1, 8970] loss_train: 0.013140, loss_test: 0.005673
time: 0.256056547164917
time: 2.2234978675842285
[1, 8971] loss_train: 0.005753, loss_test: 0.005668
time: 0.25005531311035156
time: 2.231499195098877
[1, 8972] loss_train: 0.002152, loss_test: 0.005667
time: 0.24405598640441895
time: 2.2064950466156006
[1, 8973] loss_train: 0.004899, loss_test: 0.005667
time: 0.24805450439453125
time: 2.2475030422210693
[1, 8974] loss_train: 0.007440, loss_test: 0.005665
time: 0.24605417251586914
time: 2.2185068130493164
[1, 8975] loss_train: 0.004993, loss_test: 0.005666
time: 0.2470543384552002
time: 2.22270131111145
[1, 8976] loss_train: 0.006280, loss_test: 0.005670
time: 0.24205327033996582
time: 2.213496685028076
[1, 8977] loss_train: 0.008242, loss_test: 0.005673
time: 0.24306607246398926
time: 2.219496965408325
[1, 8978] loss_train: 0.005477, loss_test: 0.005673
time: 0.24405384063720703
time: 2.229499340057373
[1, 8979] loss_train: 0.001439, loss_test: 0.005674
time: 0.2430732250213623
time: 2.2465028762817383
[1, 8980] loss_train: 0.006024, loss_test: 0.005673
time: 0.25705647468566895
time: 2.258505344390869
[1, 8981] loss_train: 0.011015, loss_test: 0.005678
time: 0.24305367469787598
time: 2.2485029697418213
[1, 8982] loss_train: 0.003625, loss_test: 0.005680
time: 0.24305343627929688
time: 2.231003999710083
[1, 8983] loss_train: 0.006373, loss_test: 0.005681
time: 0.24505400657653809
time: 2.2355003356933594
[1, 8984] loss_train: 0.001719, loss_test: 0.005681
time: 0.24405384063720703
time: 2.228498697280884
[1, 8985] loss_train: 0.006835, loss_test: 0.005683
time: 0.24605441093444824
time: 2.2285103797912598
[1, 8986] loss_train: 0.007012, loss_test: 0.005680
time: 0.24305367469787598
time: 2.204515218734741
[1, 8987] loss_train: 0.006297, loss_test: 0.005672
time: 0.24305343627929688
time: 2.236002206802368
[1, 8988] loss_train: 0.008093, loss_test: 0.005663
time: 0.24305462837219238
time: 2.2365224361419678
[1, 8989] loss_train: 0.003775, loss_test: 0.005659
time: 0.24405455589294434
time: 2.2044928073883057
[1, 8990] loss_train: 0.002711, loss_test: 0.005659
time: 0.2600576877593994
time: 2.258504629135132
[1, 8991] loss_train: 0.009810, loss_test: 0.005662
time: 0.2490549087524414
time: 2.2415037155151367
[1, 8992] loss_train: 0.005581, loss_test: 0.005664
time: 0.2490553855895996
time: 2.2254979610443115
[1, 8993] loss_train: 0.001446, loss_test: 0.005671
time: 0.24305343627929688
time: 2.239501714706421
[1, 8994] loss_train: 0.006955, loss_test: 0.005680
time: 0.25005483627319336
time: 2.206493854522705
[1, 8995] loss_train: 0.005164, loss_test: 0.005694
time: 0.24605417251586914
time: 2.1945080757141113
[1, 8996] loss_train: 0.009067, loss_test: 0.005707
time: 0.2420663833618164
time: 2.1990115642547607
[1, 8997] loss_train: 0.003008, loss_test: 0.005719
time: 0.24405407905578613
time: 2.219496726989746
[1, 8998] loss_train: 0.004038, loss_test: 0.005729
time: 0.24506664276123047
time: 2.192491054534912
[1, 8999] loss_train: 0.005573, loss_test: 0.005716
time: 0.24710488319396973
time: 2.2019920349121094
[1, 9000] loss_train: 0.005026, loss_test: 0.005704
time: 0.25705814361572266
time: 2.219496011734009
[1, 9001] loss_train: 0.006271, loss_test: 0.005687
time: 0.24605417251586914
time: 2.2265357971191406
[1, 9002] loss_train: 0.006796, loss_test: 0.005673
time: 0.2450544834136963
time: 2.2104945182800293
[1, 9003] loss_train: 0.001113, loss_test: 0.005668
time: 0.24406719207763672
time: 2.2034921646118164
[1, 9004] loss_train: 0.006448, loss_test: 0.005663
time: 0.24605488777160645
time: 2.2294986248016357
[1, 9005] loss_train: 0.001506, loss_test: 0.005660
time: 0.25005555152893066
time: 2.2124102115631104
[1, 9006] loss_train: 0.007964, loss_test: 0.005661
time: 0.2470543384552002
time: 2.1994922161102295
[1, 9007] loss_train: 0.002832, loss_test: 0.005665
time: 0.24605512619018555
time: 2.228029489517212
[1, 9008] loss_train: 0.003949, loss_test: 0.005668
time: 0.24406838417053223
time: 2.2164955139160156
[1, 9009] loss_train: 0.004295, loss_test: 0.005673
time: 0.24505400657653809
time: 2.219517469406128
[1, 9010] loss_train: 0.009558, loss_test: 0.005671
time: 0.256056547164917
time: 2.2635066509246826
[1, 9011] loss_train: 0.002171, loss_test: 0.005670
time: 0.24406862258911133
time: 2.210494041442871
[1, 9012] loss_train: 0.009917, loss_test: 0.005667
time: 0.24306678771972656
time: 2.2535042762756348
[1, 9013] loss_train: 0.005722, loss_test: 0.005666
time: 0.24506711959838867
time: 2.1974937915802
[1, 9014] loss_train: 0.020003, loss_test: 0.005660
time: 0.24305367469787598
time: 2.230499505996704
[1, 9015] loss_train: 0.008720, loss_test: 0.005665
time: 0.24406719207763672
time: 2.245518684387207
[1, 9016] loss_train: 0.004405, loss_test: 0.005675
time: 0.24405407905578613
time: 2.2134957313537598
[1, 9017] loss_train: 0.002085, loss_test: 0.005684
time: 0.24405336380004883
time: 2.2214972972869873
[1, 9018] loss_train: 0.004811, loss_test: 0.005703
time: 0.24605536460876465
time: 2.262507677078247
[1, 9019] loss_train: 0.008258, loss_test: 0.005710
time: 0.24405455589294434
time: 2.2264974117279053
[1, 9020] loss_train: 0.005771, loss_test: 0.005700
time: 0.2560863494873047
time: 2.23350191116333
[1, 9021] loss_train: 0.004491, loss_test: 0.005676
time: 0.2490549087524414
time: 2.2134954929351807
[1, 9022] loss_train: 0.004350, loss_test: 0.005657
time: 0.24505400657653809
time: 2.2345004081726074
[1, 9023] loss_train: 0.007564, loss_test: 0.005650
time: 0.2450547218322754
time: 2.235499858856201
[1, 9024] loss_train: 0.008668, loss_test: 0.005655
time: 0.2490549087524414
time: 2.2074942588806152
[1, 9025] loss_train: 0.018417, loss_test: 0.005656
time: 0.24606752395629883
time: 2.2335000038146973
[1, 9026] loss_train: 0.004509, loss_test: 0.005657
time: 0.24805498123168945
time: 2.22050142288208
[1, 9027] loss_train: 0.010821, loss_test: 0.005655
time: 0.24605536460876465
time: 2.2154946327209473
[1, 9028] loss_train: 0.006350, loss_test: 0.005654
time: 0.24605464935302734
time: 2.2345001697540283
[1, 9029] loss_train: 0.005820, loss_test: 0.005653
time: 0.2450544834136963
time: 2.203493118286133
[1, 9030] loss_train: 0.008467, loss_test: 0.005654
time: 0.25506091117858887
time: 2.2456188201904297
[1, 9031] loss_train: 0.004139, loss_test: 0.005657
time: 0.2450544834136963
time: 2.2385013103485107
[1, 9032] loss_train: 0.004477, loss_test: 0.005661
time: 0.2441234588623047
time: 2.228498697280884
[1, 9033] loss_train: 0.002066, loss_test: 0.005667
time: 0.24305438995361328
time: 2.2305006980895996
[1, 9034] loss_train: 0.012941, loss_test: 0.005664
time: 0.24605441093444824
time: 2.204496145248413
[1, 9035] loss_train: 0.000653, loss_test: 0.005665
time: 0.2450556755065918
time: 2.207494020462036
[1, 9036] loss_train: 0.010163, loss_test: 0.005664
time: 0.24605441093444824
time: 2.2390217781066895
[1, 9037] loss_train: 0.009754, loss_test: 0.005663
time: 0.24305367469787598
time: 2.2320051193237305
[1, 9038] loss_train: 0.005004, loss_test: 0.005661
time: 0.24605441093444824
time: 2.2144951820373535
[1, 9039] loss_train: 0.002010, loss_test: 0.005664
time: 0.24405455589294434
time: 2.226515293121338
[1, 9040] loss_train: 0.010625, loss_test: 0.005664
time: 0.254056453704834
time: 2.246502637863159
[1, 9041] loss_train: 0.007197, loss_test: 0.005664
time: 0.24907994270324707
time: 2.2405009269714355
[1, 9042] loss_train: 0.004549, loss_test: 0.005665
time: 0.2450547218322754
time: 2.22149658203125
[1, 9043] loss_train: 0.006438, loss_test: 0.005664
time: 0.2520561218261719
time: 2.2275071144104004
[1, 9044] loss_train: 0.001875, loss_test: 0.005664
time: 0.2450544834136963
time: 2.2340049743652344
[1, 9045] loss_train: 0.004359, loss_test: 0.005664
time: 0.24805498123168945
time: 2.214495897293091
[1, 9046] loss_train: 0.010778, loss_test: 0.005663
time: 0.245927095413208
time: 2.2294986248016357
[1, 9047] loss_train: 0.001277, loss_test: 0.005665
time: 0.24605631828308105
time: 2.2304983139038086
[1, 9048] loss_train: 0.009004, loss_test: 0.005665
time: 0.24605560302734375
time: 2.206493377685547
[1, 9049] loss_train: 0.009081, loss_test: 0.005666
time: 0.24305391311645508
time: 2.2224974632263184
[1, 9050] loss_train: 0.004359, loss_test: 0.005667
time: 0.2540557384490967
time: 2.261017084121704
[1, 9051] loss_train: 0.008669, loss_test: 0.005667
time: 0.24405455589294434
time: 2.22149658203125
[1, 9052] loss_train: 0.002914, loss_test: 0.005671
time: 0.2450544834136963
time: 2.232499361038208
[1, 9053] loss_train: 0.000836, loss_test: 0.005677
time: 0.24405455589294434
time: 2.2305197715759277
[1, 9054] loss_train: 0.012807, loss_test: 0.005675
time: 0.24405384063720703
time: 2.2254984378814697
[1, 9055] loss_train: 0.017649, loss_test: 0.005674
time: 0.2450547218322754
time: 2.2305009365081787
[1, 9056] loss_train: 0.003310, loss_test: 0.005680
time: 0.24305343627929688
time: 2.212099075317383
[1, 9057] loss_train: 0.003404, loss_test: 0.005688
time: 0.24305438995361328
time: 2.211493730545044
[1, 9058] loss_train: 0.006126, loss_test: 0.005696
time: 0.24405455589294434
time: 2.2265050411224365
[1, 9059] loss_train: 0.005687, loss_test: 0.005704
time: 0.24405360221862793
time: 2.183077573776245
[1, 9060] loss_train: 0.004867, loss_test: 0.005710
time: 0.265059232711792
time: 2.2284982204437256
[1, 9061] loss_train: 0.008384, loss_test: 0.005713
time: 0.2450547218322754
time: 2.2230043411254883
[1, 9062] loss_train: 0.007669, loss_test: 0.005712
time: 0.25005507469177246
time: 2.2485060691833496
[1, 9063] loss_train: 0.010661, loss_test: 0.005707
time: 0.24605369567871094
time: 2.2335000038146973
[1, 9064] loss_train: 0.007559, loss_test: 0.005700
time: 0.24805521965026855
time: 2.2495031356811523
[1, 9065] loss_train: 0.010310, loss_test: 0.005690
time: 0.24606752395629883
time: 2.2365007400512695
[1, 9066] loss_train: 0.006622, loss_test: 0.005676
time: 0.24605393409729004
time: 2.236499547958374
[1, 9067] loss_train: 0.010803, loss_test: 0.005668
time: 0.24506783485412598
time: 2.2335000038146973
[1, 9068] loss_train: 0.008931, loss_test: 0.005663
time: 0.24305391311645508
time: 2.2315309047698975
[1, 9069] loss_train: 0.005767, loss_test: 0.005659
time: 0.24407005310058594
time: 2.228497266769409
[1, 9070] loss_train: 0.007455, loss_test: 0.005658
time: 0.25505733489990234
time: 2.263516664505005
[1, 9071] loss_train: 0.007665, loss_test: 0.005658
time: 0.24405336380004883
time: 2.2138640880584717
[1, 9072] loss_train: 0.002068, loss_test: 0.005659
time: 0.24605488777160645
time: 2.219496726989746
[1, 9073] loss_train: 0.001422, loss_test: 0.005662
time: 0.24509453773498535
time: 2.2244973182678223
[1, 9074] loss_train: 0.008726, loss_test: 0.005665
time: 0.24305391311645508
time: 2.256518602371216
[1, 9075] loss_train: 0.006815, loss_test: 0.005666
time: 0.24805450439453125
time: 2.2264981269836426
[1, 9076] loss_train: 0.005673, loss_test: 0.005668
time: 0.2436971664428711
time: 2.218496561050415
[1, 9077] loss_train: 0.001391, loss_test: 0.005671
time: 0.24305295944213867
time: 2.2050604820251465
[1, 9078] loss_train: 0.004154, loss_test: 0.005674
time: 0.24806857109069824
time: 2.2274978160858154
[1, 9079] loss_train: 0.012039, loss_test: 0.005686
time: 0.2448134422302246
time: 2.2134952545166016
[1, 9080] loss_train: 0.001222, loss_test: 0.005697
time: 0.256026029586792
time: 2.2615063190460205
[1, 9081] loss_train: 0.002945, loss_test: 0.005708
time: 0.24605488777160645
time: 2.235499620437622
[1, 9082] loss_train: 0.008540, loss_test: 0.005708
time: 0.2450547218322754
time: 2.2174956798553467
[1, 9083] loss_train: 0.010415, loss_test: 0.005701
time: 0.24805545806884766
time: 2.2114946842193604
[1, 9084] loss_train: 0.004260, loss_test: 0.005698
time: 0.2450547218322754
time: 2.2425010204315186
[1, 9085] loss_train: 0.006912, loss_test: 0.005691
time: 0.25005412101745605
time: 2.2244980335235596
[1, 9086] loss_train: 0.011603, loss_test: 0.005682
time: 0.24405455589294434
time: 2.245302438735962
[1, 9087] loss_train: 0.000682, loss_test: 0.005678
time: 0.24805569648742676
time: 2.2294979095458984
[1, 9088] loss_train: 0.002827, loss_test: 0.005675
time: 0.24405431747436523
time: 2.227837562561035
[1, 9089] loss_train: 0.006187, loss_test: 0.005673
time: 0.2450544834136963
time: 2.2255167961120605
[1, 9090] loss_train: 0.003501, loss_test: 0.005674
time: 0.25505614280700684
time: 2.268507719039917
[1, 9091] loss_train: 0.005855, loss_test: 0.005673
time: 0.24505400657653809
time: 2.207496166229248
[1, 9092] loss_train: 0.006493, loss_test: 0.005675
time: 0.24405407905578613
time: 2.193493127822876
[1, 9093] loss_train: 0.004985, loss_test: 0.005677
time: 0.24306011199951172
time: 2.2266619205474854
[1, 9094] loss_train: 0.012363, loss_test: 0.005678
time: 0.24405431747436523
time: 2.241501569747925
[1, 9095] loss_train: 0.003001, loss_test: 0.005681
time: 0.24605464935302734
time: 2.2154078483581543
[1, 9096] loss_train: 0.003678, loss_test: 0.005683
time: 0.24305486679077148
time: 2.219496011734009
[1, 9097] loss_train: 0.003900, loss_test: 0.005679
time: 0.24505400657653809
time: 2.2244977951049805
[1, 9098] loss_train: 0.007138, loss_test: 0.005676
time: 0.24305415153503418
time: 2.236499547958374
[1, 9099] loss_train: 0.003187, loss_test: 0.005670
time: 0.2455906867980957
time: 2.213503837585449
[1, 9100] loss_train: 0.006975, loss_test: 0.005666
time: 0.256056547164917
time: 2.231499433517456
[1, 9101] loss_train: 0.008779, loss_test: 0.005663
time: 0.24405336380004883
time: 2.208493947982788
[1, 9102] loss_train: 0.002968, loss_test: 0.005666
time: 0.2520558834075928
time: 2.2345001697540283
[1, 9103] loss_train: 0.005741, loss_test: 0.005673
time: 0.24606704711914062
time: 2.203496217727661
[1, 9104] loss_train: 0.010357, loss_test: 0.005676
time: 0.2510688304901123
time: 2.2355003356933594
[1, 9105] loss_train: 0.012656, loss_test: 0.005674
time: 0.24406766891479492
time: 2.2475128173828125
[1, 9106] loss_train: 0.006445, loss_test: 0.005675
time: 0.24605417251586914
time: 2.2235453128814697
[1, 9107] loss_train: 0.008391, loss_test: 0.005677
time: 0.24505400657653809
time: 2.219496726989746
[1, 9108] loss_train: 0.005506, loss_test: 0.005685
time: 0.24305391311645508
time: 2.2244975566864014
[1, 9109] loss_train: 0.006169, loss_test: 0.005690
time: 0.24606704711914062
time: 2.2230114936828613
[1, 9110] loss_train: 0.012492, loss_test: 0.005684
time: 0.25406956672668457
time: 2.2785096168518066
[1, 9111] loss_train: 0.008159, loss_test: 0.005676
time: 0.24506711959838867
time: 2.195490837097168
[1, 9112] loss_train: 0.006005, loss_test: 0.005671
time: 0.24405455589294434
time: 2.2445015907287598
[1, 9113] loss_train: 0.009670, loss_test: 0.005668
time: 0.24305367469787598
time: 2.205493927001953
[1, 9114] loss_train: 0.004271, loss_test: 0.005667
time: 0.24305367469787598
time: 2.2254981994628906
[1, 9115] loss_train: 0.006928, loss_test: 0.005666
time: 0.2440662384033203
time: 2.215550422668457
[1, 9116] loss_train: 0.005456, loss_test: 0.005668
time: 0.2470688819885254
time: 2.211493968963623
[1, 9117] loss_train: 0.003535, loss_test: 0.005673
time: 0.24405384063720703
time: 2.182497978210449
[1, 9118] loss_train: 0.005166, loss_test: 0.005676
time: 0.2450544834136963
time: 2.208998680114746
[1, 9119] loss_train: 0.006098, loss_test: 0.005680
time: 0.2490556240081787
time: 2.195556879043579
[1, 9120] loss_train: 0.006852, loss_test: 0.005683
time: 0.25705742835998535
time: 2.2264976501464844
[1, 9121] loss_train: 0.008634, loss_test: 0.005685
time: 0.24606728553771973
time: 2.222496747970581
[1, 9122] loss_train: 0.011873, loss_test: 0.005684
time: 0.24305391311645508
time: 2.2375006675720215
[1, 9123] loss_train: 0.004838, loss_test: 0.005684
time: 0.2450544834136963
time: 2.2304985523223877
[1, 9124] loss_train: 0.004315, loss_test: 0.005685
time: 0.2450704574584961
time: 2.207493305206299
[1, 9125] loss_train: 0.002255, loss_test: 0.005682
time: 0.24305367469787598
time: 2.2480413913726807
[1, 9126] loss_train: 0.013080, loss_test: 0.005680
time: 0.24305415153503418
time: 2.2024924755096436
[1, 9127] loss_train: 0.008623, loss_test: 0.005676
time: 0.24405407905578613
time: 2.263031005859375
[1, 9128] loss_train: 0.007149, loss_test: 0.005673
time: 0.24305462837219238
time: 2.2154948711395264
[1, 9129] loss_train: 0.004266, loss_test: 0.005671
time: 0.2450542449951172
time: 2.2010185718536377
[1, 9130] loss_train: 0.008187, loss_test: 0.005669
time: 0.25705671310424805
time: 2.2505059242248535
[1, 9131] loss_train: 0.008883, loss_test: 0.005668
time: 0.24505400657653809
time: 2.2345025539398193
[1, 9132] loss_train: 0.007117, loss_test: 0.005666
time: 0.24405360221862793
time: 2.192491054534912
[1, 9133] loss_train: 0.002401, loss_test: 0.005666
time: 0.24405384063720703
time: 2.2385010719299316
[1, 9134] loss_train: 0.006225, loss_test: 0.005666
time: 0.24405670166015625
time: 2.218498706817627
[1, 9135] loss_train: 0.003037, loss_test: 0.005667
time: 0.25005578994750977
time: 2.228515386581421
[1, 9136] loss_train: 0.002961, loss_test: 0.005672
time: 0.2490546703338623
time: 2.2314999103546143
[1, 9137] loss_train: 0.007090, loss_test: 0.005677
time: 0.24505400657653809
time: 2.202493190765381
[1, 9138] loss_train: 0.005011, loss_test: 0.005684
time: 0.24605512619018555
time: 2.258504629135132
[1, 9139] loss_train: 0.003716, loss_test: 0.005690
time: 0.2450547218322754
time: 2.228515386581421
[1, 9140] loss_train: 0.009017, loss_test: 0.005677
time: 0.26105737686157227
time: 2.296513080596924
[1, 9141] loss_train: 0.008119, loss_test: 0.005671
time: 0.24605584144592285
time: 2.2164952754974365
[1, 9142] loss_train: 0.007209, loss_test: 0.005687
time: 0.24805617332458496
time: 2.2194952964782715
[1, 9143] loss_train: 0.003171, loss_test: 0.005716
time: 0.24606752395629883
time: 2.2114951610565186
[1, 9144] loss_train: 0.010529, loss_test: 0.005759
time: 0.2440657615661621
time: 2.2735085487365723
[1, 9145] loss_train: 0.003901, loss_test: 0.005802
time: 0.24405455589294434
time: 2.2254979610443115
[1, 9146] loss_train: 0.005495, loss_test: 0.005839
time: 0.24205398559570312
time: 2.2174954414367676
[1, 9147] loss_train: 0.005068, loss_test: 0.005870
time: 0.24405384063720703
time: 2.240501642227173
[1, 9148] loss_train: 0.006349, loss_test: 0.005854
time: 0.2470543384552002
time: 2.2825112342834473
[1, 9149] loss_train: 0.005680, loss_test: 0.005800
time: 0.2470543384552002
time: 2.262507915496826
[1, 9150] loss_train: 0.010071, loss_test: 0.005757
time: 0.25406908988952637
time: 2.248502492904663
[1, 9151] loss_train: 0.001433, loss_test: 0.005731
time: 0.2450544834136963
time: 2.2316501140594482
[1, 9152] loss_train: 0.008337, loss_test: 0.005705
time: 0.24405169486999512
time: 2.219496965408325
[1, 9153] loss_train: 0.014683, loss_test: 0.005689
time: 0.24605464935302734
time: 2.231498956680298
[1, 9154] loss_train: 0.010711, loss_test: 0.005668
time: 0.24405407905578613
time: 2.232499361038208
[1, 9155] loss_train: 0.004584, loss_test: 0.005672
time: 0.2450547218322754
time: 2.2234973907470703
[1, 9156] loss_train: 0.009755, loss_test: 0.005687
time: 0.2470552921295166
time: 2.2204978466033936
[1, 9157] loss_train: 0.004700, loss_test: 0.005711
time: 0.24205374717712402
time: 2.224350929260254
[1, 9158] loss_train: 0.008661, loss_test: 0.005728
time: 0.24405455589294434
time: 2.2227208614349365
[1, 9159] loss_train: 0.007615, loss_test: 0.005735
time: 0.24405479431152344
time: 2.20849347114563
[1, 9160] loss_train: 0.004853, loss_test: 0.005738
time: 0.25905752182006836
time: 2.2679800987243652
[1, 9161] loss_train: 0.007373, loss_test: 0.005739
time: 0.2450544834136963
time: 2.194490432739258
[1, 9162] loss_train: 0.006569, loss_test: 0.005712
time: 0.2440643310546875
time: 2.194490671157837
[1, 9163] loss_train: 0.000711, loss_test: 0.005696
time: 0.2510554790496826
time: 2.2234978675842285
[1, 9164] loss_train: 0.004844, loss_test: 0.005679
time: 0.2450544834136963
time: 2.207493305206299
[1, 9165] loss_train: 0.007610, loss_test: 0.005669
time: 0.24606633186340332
time: 2.1944918632507324
[1, 9166] loss_train: 0.005937, loss_test: 0.005668
time: 0.24305295944213867
time: 2.2580130100250244
[1, 9167] loss_train: 0.005352, loss_test: 0.005674
time: 0.24406719207763672
time: 2.1964921951293945
[1, 9168] loss_train: 0.009592, loss_test: 0.005686
time: 0.24305367469787598
time: 2.1962778568267822
[1, 9169] loss_train: 0.005338, loss_test: 0.005701
time: 0.24606609344482422
time: 2.206493616104126
[1, 9170] loss_train: 0.011669, loss_test: 0.005707
time: 0.254056453704834
time: 2.23502516746521
[1, 9171] loss_train: 0.010031, loss_test: 0.005706
time: 0.24405336380004883
time: 2.2234973907470703
[1, 9172] loss_train: 0.003194, loss_test: 0.005707
time: 0.2512838840484619
time: 2.215496063232422
[1, 9173] loss_train: 0.005538, loss_test: 0.005708
time: 0.24509620666503906
time: 2.2284984588623047
[1, 9174] loss_train: 0.006626, loss_test: 0.005706
time: 0.24405407905578613
time: 2.237499475479126
[1, 9175] loss_train: 0.008594, loss_test: 0.005701
time: 0.24405336380004883
time: 2.2314999103546143
[1, 9176] loss_train: 0.006515, loss_test: 0.005697
time: 0.24605512619018555
time: 2.201997756958008
[1, 9177] loss_train: 0.011913, loss_test: 0.005683
time: 0.24506664276123047
time: 2.193490982055664
[1, 9178] loss_train: 0.018103, loss_test: 0.005674
time: 0.2470545768737793
time: 2.229520320892334
[1, 9179] loss_train: 0.002036, loss_test: 0.005674
time: 0.24305343627929688
time: 2.231499433517456
[1, 9180] loss_train: 0.002390, loss_test: 0.005680
time: 0.2560563087463379
time: 2.2368078231811523
[1, 9181] loss_train: 0.006284, loss_test: 0.005691
time: 0.24605441093444824
time: 2.2325148582458496
[1, 9182] loss_train: 0.004366, loss_test: 0.005698
time: 0.24305367469787598
time: 2.2525041103363037
[1, 9183] loss_train: 0.007715, loss_test: 0.005705
time: 0.24305438995361328
time: 2.1884894371032715
[1, 9184] loss_train: 0.003008, loss_test: 0.005709
time: 0.24605512619018555
time: 2.2240004539489746
[1, 9185] loss_train: 0.009719, loss_test: 0.005714
time: 0.24605441093444824
time: 2.2605056762695312
[1, 9186] loss_train: 0.012332, loss_test: 0.005709
time: 0.24805569648742676
time: 2.233501434326172
[1, 9187] loss_train: 0.005091, loss_test: 0.005698
time: 0.24506926536560059
time: 2.2475030422210693
[1, 9188] loss_train: 0.002629, loss_test: 0.005689
time: 0.2450549602508545
time: 2.243502140045166
[1, 9189] loss_train: 0.001132, loss_test: 0.005681
time: 0.24305319786071777
time: 2.206493854522705
[1, 9190] loss_train: 0.000776, loss_test: 0.005686
time: 0.2560563087463379
time: 2.231511354446411
[1, 9191] loss_train: 0.008504, loss_test: 0.005703
time: 0.24805450439453125
time: 2.201873302459717
[1, 9192] loss_train: 0.007074, loss_test: 0.005730
time: 0.2490558624267578
time: 2.2174954414367676
[1, 9193] loss_train: 0.003101, loss_test: 0.005747
time: 0.2450544834136963
time: 2.2254977226257324
[1, 9194] loss_train: 0.010602, loss_test: 0.005738
time: 0.24405455589294434
time: 2.220499038696289
[1, 9195] loss_train: 0.002651, loss_test: 0.005733
time: 0.2490544319152832
time: 2.2104949951171875
[1, 9196] loss_train: 0.003108, loss_test: 0.005730
time: 0.24505400657653809
time: 2.2385010719299316
[1, 9197] loss_train: 0.007766, loss_test: 0.005711
time: 0.24805474281311035
time: 2.228498697280884
[1, 9198] loss_train: 0.003061, loss_test: 0.005694
time: 0.2450542449951172
time: 2.2127819061279297
[1, 9199] loss_train: 0.004184, loss_test: 0.005677
time: 0.24405670166015625
time: 2.2395005226135254
[1, 9200] loss_train: 0.007727, loss_test: 0.005663
time: 0.2540566921234131
time: 2.247012138366699
[1, 9201] loss_train: 0.007635, loss_test: 0.005657
time: 0.2450544834136963
time: 2.2264976501464844
[1, 9202] loss_train: 0.008455, loss_test: 0.005656
time: 0.24406719207763672
time: 2.1864893436431885
[1, 9203] loss_train: 0.010525, loss_test: 0.005666
time: 0.24305438995361328
time: 2.2134947776794434
[1, 9204] loss_train: 0.002259, loss_test: 0.005678
time: 0.24505400657653809
time: 2.2054927349090576
[1, 9205] loss_train: 0.006764, loss_test: 0.005687
time: 0.24505376815795898
time: 2.2234976291656494
[1, 9206] loss_train: 0.002749, loss_test: 0.005680
time: 0.24405407905578613
time: 2.2024929523468018
[1, 9207] loss_train: 0.010906, loss_test: 0.005676
time: 0.24305343627929688
time: 2.245511293411255
[1, 9208] loss_train: 0.006029, loss_test: 0.005674
time: 0.24305415153503418
time: 2.2405128479003906
[1, 9209] loss_train: 0.007989, loss_test: 0.005676
time: 0.24305391311645508
time: 2.2455008029937744
[1, 9210] loss_train: 0.008357, loss_test: 0.005681
time: 0.25305700302124023
time: 2.2525041103363037
[1, 9211] loss_train: 0.005658, loss_test: 0.005691
time: 0.24405407905578613
time: 2.231013774871826
[1, 9212] loss_train: 0.003067, loss_test: 0.005703
time: 0.2450544834136963
time: 2.2415010929107666
[1, 9213] loss_train: 0.010891, loss_test: 0.005718
time: 0.24505376815795898
time: 2.2120094299316406
[1, 9214] loss_train: 0.004269, loss_test: 0.005730
time: 0.24805450439453125
time: 2.2224974632263184
[1, 9215] loss_train: 0.003403, loss_test: 0.005742
time: 0.2490549087524414
time: 2.1914901733398438
[1, 9216] loss_train: 0.011207, loss_test: 0.005758
time: 0.24505400657653809
time: 2.2154951095581055
[1, 9217] loss_train: 0.002922, loss_test: 0.005774
time: 0.24505376815795898
time: 2.2010016441345215
[1, 9218] loss_train: 0.009318, loss_test: 0.005770
time: 0.2440478801727295
time: 2.2345004081726074
[1, 9219] loss_train: 0.007849, loss_test: 0.005757
time: 0.24305367469787598
time: 2.244501829147339
[1, 9220] loss_train: 0.012586, loss_test: 0.005742
time: 0.2560560703277588
time: 2.255505323410034
[1, 9221] loss_train: 0.011944, loss_test: 0.005719
time: 0.24405384063720703
time: 2.2455015182495117
[1, 9222] loss_train: 0.005898, loss_test: 0.005702
time: 0.24306702613830566
time: 2.231498956680298
[1, 9223] loss_train: 0.016144, loss_test: 0.005685
time: 0.2450547218322754
time: 2.216549873352051
[1, 9224] loss_train: 0.002353, loss_test: 0.005675
time: 0.24305415153503418
time: 2.2134945392608643
[1, 9225] loss_train: 0.006146, loss_test: 0.005668
time: 0.24305343627929688
time: 2.2255101203918457
[1, 9226] loss_train: 0.004638, loss_test: 0.005667
time: 0.2450551986694336
time: 2.185488224029541
[1, 9227] loss_train: 0.010623, loss_test: 0.005669
time: 0.24306631088256836
time: 2.1835153102874756
[1, 9228] loss_train: 0.012450, loss_test: 0.005675
time: 0.2450547218322754
time: 2.209493398666382
[1, 9229] loss_train: 0.010073, loss_test: 0.005683
time: 0.25505733489990234
time: 2.210038185119629
[1, 9230] loss_train: 0.008683, loss_test: 0.005688
time: 0.256056547164917
time: 2.269508123397827
[1, 9231] loss_train: 0.004005, loss_test: 0.005689
time: 0.2490549087524414
time: 2.235513210296631
[1, 9232] loss_train: 0.003939, loss_test: 0.005686
time: 0.24605488777160645
time: 2.2174954414367676
[1, 9233] loss_train: 0.009835, loss_test: 0.005682
time: 0.2450549602508545
time: 2.2295103073120117
[1, 9234] loss_train: 0.005882, loss_test: 0.005678
time: 0.24305438995361328
time: 2.2154953479766846
[1, 9235] loss_train: 0.000643, loss_test: 0.005677
time: 0.24406671524047852
time: 2.222007989883423
[1, 9236] loss_train: 0.007756, loss_test: 0.005673
time: 0.24505400657653809
time: 2.225510597229004
[1, 9237] loss_train: 0.006404, loss_test: 0.005668
time: 0.24305343627929688
time: 2.2264983654022217
[1, 9238] loss_train: 0.010696, loss_test: 0.005663
time: 0.24506640434265137
time: 2.2114977836608887
[1, 9239] loss_train: 0.006271, loss_test: 0.005656
time: 0.24405384063720703
time: 2.217496156692505
[1, 9240] loss_train: 0.008817, loss_test: 0.005654
time: 0.256056547164917
time: 2.2255120277404785
[1, 9241] loss_train: 0.013162, loss_test: 0.005654
time: 0.24306750297546387
time: 2.209503173828125
[1, 9242] loss_train: 0.010077, loss_test: 0.005655
time: 0.24405384063720703
time: 2.2234973907470703
[1, 9243] loss_train: 0.001508, loss_test: 0.005657
time: 0.24506855010986328
time: 2.206493377685547
[1, 9244] loss_train: 0.012919, loss_test: 0.005657
time: 0.2490546703338623
time: 2.244032859802246
[1, 9245] loss_train: 0.003600, loss_test: 0.005657
time: 0.2470545768737793
time: 2.2334988117218018
[1, 9246] loss_train: 0.003076, loss_test: 0.005657
time: 0.25305724143981934
time: 2.219496250152588
[1, 9247] loss_train: 0.006060, loss_test: 0.005658
time: 0.24506783485412598
time: 2.2225241661071777
[1, 9248] loss_train: 0.003647, loss_test: 0.005661
time: 0.24805521965026855
time: 2.210494041442871
[1, 9249] loss_train: 0.001618, loss_test: 0.005665
time: 0.24505376815795898
time: 2.2695302963256836
[1, 9250] loss_train: 0.006887, loss_test: 0.005667
time: 0.2600572109222412
time: 2.2555043697357178
[1, 9251] loss_train: 0.004672, loss_test: 0.005668
time: 0.24365019798278809
time: 2.243501901626587
[1, 9252] loss_train: 0.003644, loss_test: 0.005672
time: 0.24605417251586914
time: 2.218496084213257
[1, 9253] loss_train: 0.004940, loss_test: 0.005674
time: 0.2450547218322754
time: 2.218496799468994
[1, 9254] loss_train: 0.006146, loss_test: 0.005675
time: 0.24405360221862793
time: 2.218496799468994
[1, 9255] loss_train: 0.013872, loss_test: 0.005666
time: 0.24305343627929688
time: 2.203000068664551
[1, 9256] loss_train: 0.009440, loss_test: 0.005662
time: 0.24305343627929688
time: 2.228498935699463
[1, 9257] loss_train: 0.002614, loss_test: 0.005661
time: 0.24405360221862793
time: 2.2395012378692627
[1, 9258] loss_train: 0.009796, loss_test: 0.005657
time: 0.2451000213623047
time: 2.2264974117279053
[1, 9259] loss_train: 0.009675, loss_test: 0.005659
time: 0.24505400657653809
time: 2.193491220474243
[1, 9260] loss_train: 0.002122, loss_test: 0.005661
time: 0.2620584964752197
time: 2.2595136165618896
[1, 9261] loss_train: 0.012234, loss_test: 0.005662
time: 0.24405479431152344
time: 2.2185068130493164
[1, 9262] loss_train: 0.001201, loss_test: 0.005663
time: 0.24305367469787598
time: 2.232513189315796
[1, 9263] loss_train: 0.004472, loss_test: 0.005664
time: 0.24405336380004883
time: 2.1944997310638428
[1, 9264] loss_train: 0.010107, loss_test: 0.005660
time: 0.24505329132080078
time: 2.214495897293091
[1, 9265] loss_train: 0.005532, loss_test: 0.005657
time: 0.2490546703338623
time: 2.216495990753174
[1, 9266] loss_train: 0.003223, loss_test: 0.005654
time: 0.2450542449951172
time: 2.2114949226379395
[1, 9267] loss_train: 0.005721, loss_test: 0.005651
time: 0.2490549087524414
time: 2.2385013103485107
[1, 9268] loss_train: 0.004154, loss_test: 0.005649
time: 0.24507904052734375
time: 2.213495969772339
[1, 9269] loss_train: 0.003422, loss_test: 0.005650
time: 0.24605464935302734
time: 2.2635061740875244
[1, 9270] loss_train: 0.007968, loss_test: 0.005649
time: 0.2600579261779785
time: 2.2435014247894287
[1, 9271] loss_train: 0.005044, loss_test: 0.005652
time: 0.2470555305480957
time: 2.208493709564209
[1, 9272] loss_train: 0.002881, loss_test: 0.005656
time: 0.2450547218322754
time: 2.2515032291412354
[1, 9273] loss_train: 0.007926, loss_test: 0.005658
time: 0.24605774879455566
time: 2.2114968299865723
[1, 9274] loss_train: 0.009665, loss_test: 0.005669
time: 0.24505376815795898
time: 2.229501247406006
[1, 9275] loss_train: 0.018459, loss_test: 0.005691
time: 0.24305367469787598
time: 2.231020212173462
[1, 9276] loss_train: 0.005974, loss_test: 0.005718
time: 0.2450549602508545
time: 2.2154948711395264
[1, 9277] loss_train: 0.003559, loss_test: 0.005737
time: 0.24806737899780273
time: 2.207493782043457
[1, 9278] loss_train: 0.008991, loss_test: 0.005739
time: 0.24305343627929688
time: 2.196505308151245
[1, 9279] loss_train: 0.005863, loss_test: 0.005736
time: 0.24405503273010254
time: 2.2294976711273193
[1, 9280] loss_train: 0.005012, loss_test: 0.005720
time: 0.254056453704834
time: 2.2425336837768555
[1, 9281] loss_train: 0.006521, loss_test: 0.005710
time: 0.24205374717712402
time: 2.2245001792907715
[1, 9282] loss_train: 0.006787, loss_test: 0.005703
time: 0.24906682968139648
time: 2.2325022220611572
[1, 9283] loss_train: 0.004044, loss_test: 0.005702
time: 0.24506759643554688
time: 2.2124950885772705
[1, 9284] loss_train: 0.004890, loss_test: 0.005700
time: 0.2530558109283447
time: 2.257505416870117
[1, 9285] loss_train: 0.001029, loss_test: 0.005700
time: 0.24605393409729004
time: 2.2134957313537598
[1, 9286] loss_train: 0.007293, loss_test: 0.005704
time: 0.2470543384552002
time: 2.2495036125183105
[1, 9287] loss_train: 0.008801, loss_test: 0.005705
time: 0.2450542449951172
time: 2.2495036125183105
[1, 9288] loss_train: 0.011314, loss_test: 0.005702
time: 0.24605488777160645
time: 2.2565150260925293
[1, 9289] loss_train: 0.003294, loss_test: 0.005705
time: 0.24405431747436523
time: 2.240501642227173
[1, 9290] loss_train: 0.010807, loss_test: 0.005724
time: 0.2580571174621582
time: 2.2625083923339844
[1, 9291] loss_train: 0.009196, loss_test: 0.005734
time: 0.24405431747436523
time: 2.2164952754974365
[1, 9292] loss_train: 0.006486, loss_test: 0.005743
time: 0.24606728553771973
time: 2.234502077102661
[1, 9293] loss_train: 0.006013, loss_test: 0.005751
time: 0.2450544834136963
time: 2.227501153945923
[1, 9294] loss_train: 0.008615, loss_test: 0.005755
time: 0.2450542449951172
time: 2.2445061206817627
[1, 9295] loss_train: 0.003224, loss_test: 0.005758
time: 0.24265217781066895
time: 2.248522996902466
[1, 9296] loss_train: 0.008050, loss_test: 0.005754
time: 0.24405384063720703
time: 2.217496395111084
[1, 9297] loss_train: 0.009829, loss_test: 0.005745
time: 0.2450547218322754
time: 2.20949387550354
[1, 9298] loss_train: 0.011033, loss_test: 0.005712
time: 0.24505400657653809
time: 2.202038526535034
[1, 9299] loss_train: 0.008388, loss_test: 0.005689
time: 0.24305367469787598
time: 2.2045130729675293
[1, 9300] loss_train: 0.012760, loss_test: 0.005668
time: 0.25609898567199707
time: 2.242502212524414
[1, 9301] loss_train: 0.003421, loss_test: 0.005665
time: 0.24605441093444824
time: 2.259505271911621
[1, 9302] loss_train: 0.008616, loss_test: 0.005674
time: 0.24887967109680176
time: 2.2104969024658203
[1, 9303] loss_train: 0.006091, loss_test: 0.005687
time: 0.24305367469787598
time: 2.206493854522705
[1, 9304] loss_train: 0.010843, loss_test: 0.005688
time: 0.24805474281311035
time: 2.2305214405059814
[1, 9305] loss_train: 0.007400, loss_test: 0.005682
time: 0.24506831169128418
time: 2.20849347114563
[1, 9306] loss_train: 0.006020, loss_test: 0.005676
time: 0.24605488777160645
time: 2.2450718879699707
[1, 9307] loss_train: 0.004579, loss_test: 0.005674
time: 0.2490556240081787
time: 2.231499671936035
[1, 9308] loss_train: 0.006744, loss_test: 0.005666
time: 0.24605584144592285
time: 2.2264981269836426
[1, 9309] loss_train: 0.019108, loss_test: 0.005666
time: 0.24805545806884766
time: 2.220517873764038
[1, 9310] loss_train: 0.005328, loss_test: 0.005667
time: 0.25705647468566895
time: 2.2548322677612305
[1, 9311] loss_train: 0.005128, loss_test: 0.005664
time: 0.2470550537109375
time: 2.2275118827819824
[1, 9312] loss_train: 0.017353, loss_test: 0.005664
time: 0.24405384063720703
time: 2.2180142402648926
[1, 9313] loss_train: 0.003041, loss_test: 0.005664
time: 0.24405407905578613
time: 2.22407865524292
[1, 9314] loss_train: 0.002807, loss_test: 0.005662
time: 0.24608373641967773
time: 2.2174952030181885
[1, 9315] loss_train: 0.017175, loss_test: 0.005671
time: 0.2440626621246338
time: 2.2335243225097656
[1, 9316] loss_train: 0.006981, loss_test: 0.005677
time: 0.24405431747436523
time: 2.1835107803344727
[1, 9317] loss_train: 0.004696, loss_test: 0.005682
time: 0.24405455589294434
time: 2.233499050140381
[1, 9318] loss_train: 0.004382, loss_test: 0.005685
time: 0.24305415153503418
time: 2.220515489578247
[1, 9319] loss_train: 0.003288, loss_test: 0.005680
time: 0.24305343627929688
time: 2.201505661010742
[1, 9320] loss_train: 0.005719, loss_test: 0.005676
time: 0.2560563087463379
time: 2.282510995864868
[1, 9321] loss_train: 0.003053, loss_test: 0.005671
time: 0.2450542449951172
time: 2.215496063232422
[1, 9322] loss_train: 0.010046, loss_test: 0.005668
time: 0.24506616592407227
time: 2.2024929523468018
[1, 9323] loss_train: 0.006305, loss_test: 0.005666
time: 0.24305343627929688
time: 2.2064943313598633
[1, 9324] loss_train: 0.007644, loss_test: 0.005666
time: 0.25205516815185547
time: 2.2134952545166016
[1, 9325] loss_train: 0.015057, loss_test: 0.005664
time: 0.24405407905578613
time: 2.218003273010254
[1, 9326] loss_train: 0.004317, loss_test: 0.005660
time: 0.24605441093444824
time: 2.2144956588745117
[1, 9327] loss_train: 0.007352, loss_test: 0.005657
time: 0.24305391311645508
time: 2.2054929733276367
[1, 9328] loss_train: 0.006807, loss_test: 0.005656
time: 0.24405336380004883
time: 2.2244997024536133
[1, 9329] loss_train: 0.001979, loss_test: 0.005655
time: 0.2450547218322754
time: 2.244518995285034
[1, 9330] loss_train: 0.004823, loss_test: 0.005651
time: 0.2560572624206543
time: 2.2765090465545654
[1, 9331] loss_train: 0.005448, loss_test: 0.005651
time: 0.24605441093444824
time: 2.2264983654022217
[1, 9332] loss_train: 0.006236, loss_test: 0.005652
time: 0.24305367469787598
time: 2.232499361038208
[1, 9333] loss_train: 0.004466, loss_test: 0.005657
time: 0.2450549602508545
time: 2.2014920711517334
[1, 9334] loss_train: 0.010011, loss_test: 0.005657
time: 0.24805521965026855
time: 2.2064931392669678
[1, 9335] loss_train: 0.010424, loss_test: 0.005659
time: 0.2450542449951172
time: 2.1965103149414062
[1, 9336] loss_train: 0.009995, loss_test: 0.005655
time: 0.24508118629455566
time: 2.2164955139160156
[1, 9337] loss_train: 0.008000, loss_test: 0.005651
time: 0.24505376815795898
time: 2.2377560138702393
[1, 9338] loss_train: 0.006451, loss_test: 0.005650
time: 0.2460784912109375
time: 2.219496965408325
[1, 9339] loss_train: 0.007285, loss_test: 0.005650
time: 0.24907302856445312
time: 2.206494092941284
[1, 9340] loss_train: 0.008420, loss_test: 0.005652
time: 0.25505733489990234
time: 2.2260029315948486
[1, 9341] loss_train: 0.007353, loss_test: 0.005656
time: 0.24805521965026855
time: 2.2455027103424072
[1, 9342] loss_train: 0.003450, loss_test: 0.005662
time: 0.24405336380004883
time: 2.253504991531372
[1, 9343] loss_train: 0.004772, loss_test: 0.005668
time: 0.25087904930114746
time: 2.2214996814727783
[1, 9344] loss_train: 0.007772, loss_test: 0.005676
time: 0.24605417251586914
time: 2.232499837875366
[1, 9345] loss_train: 0.010569, loss_test: 0.005688
time: 0.2450542449951172
time: 2.22249698638916
[1, 9346] loss_train: 0.007990, loss_test: 0.005697
time: 0.2457132339477539
time: 2.219496488571167
[1, 9347] loss_train: 0.008668, loss_test: 0.005700
time: 0.24305343627929688
time: 2.2124953269958496
[1, 9348] loss_train: 0.005643, loss_test: 0.005697
time: 0.24606561660766602
time: 2.227498769760132
[1, 9349] loss_train: 0.012621, loss_test: 0.005699
time: 0.24405455589294434
time: 2.205502510070801
[1, 9350] loss_train: 0.005812, loss_test: 0.005697
time: 0.25505709648132324
time: 2.2194979190826416
[1, 9351] loss_train: 0.004446, loss_test: 0.005693
time: 0.2450566291809082
time: 2.2385008335113525
[1, 9352] loss_train: 0.008832, loss_test: 0.005690
time: 0.24405407905578613
time: 2.2144954204559326
[1, 9353] loss_train: 0.002404, loss_test: 0.005687
time: 0.24205446243286133
time: 2.20849347114563
[1, 9354] loss_train: 0.005461, loss_test: 0.005687
time: 0.24405384063720703
time: 2.255505084991455
[1, 9355] loss_train: 0.005611, loss_test: 0.005692
time: 0.2470550537109375
time: 2.238516330718994
[1, 9356] loss_train: 0.003202, loss_test: 0.005703
time: 0.24405455589294434
time: 2.219827175140381
[1, 9357] loss_train: 0.006252, loss_test: 0.005716
time: 0.24405479431152344
time: 2.2124950885772705
[1, 9358] loss_train: 0.007679, loss_test: 0.005718
time: 0.25005507469177246
time: 2.2230212688446045
[1, 9359] loss_train: 0.004111, loss_test: 0.005723
time: 0.24605536460876465
time: 2.192518711090088
[1, 9360] loss_train: 0.004618, loss_test: 0.005727
time: 0.26105761528015137
time: 2.243502140045166
[1, 9361] loss_train: 0.006188, loss_test: 0.005724
time: 0.24405479431152344
time: 2.2385003566741943
[1, 9362] loss_train: 0.002670, loss_test: 0.005722
time: 0.2470541000366211
time: 2.2385077476501465
[1, 9363] loss_train: 0.008626, loss_test: 0.005706
time: 0.24405407905578613
time: 2.224500894546509
[1, 9364] loss_train: 0.008787, loss_test: 0.005695
time: 0.2450544834136963
time: 2.204512357711792
[1, 9365] loss_train: 0.008932, loss_test: 0.005684
time: 0.2450542449951172
time: 2.2334988117218018
[1, 9366] loss_train: 0.009907, loss_test: 0.005678
time: 0.24505400657653809
time: 2.2205090522766113
[1, 9367] loss_train: 0.003012, loss_test: 0.005677
time: 0.24305391311645508
time: 2.207494020462036
[1, 9368] loss_train: 0.006662, loss_test: 0.005679
time: 0.24406814575195312
time: 2.244516134262085
[1, 9369] loss_train: 0.004691, loss_test: 0.005680
time: 0.24605488777160645
time: 2.219513177871704
[1, 9370] loss_train: 0.010153, loss_test: 0.005681
time: 0.2550692558288574
time: 2.2154955863952637
[1, 9371] loss_train: 0.006317, loss_test: 0.005682
time: 0.2470543384552002
time: 2.2254979610443115
[1, 9372] loss_train: 0.002748, loss_test: 0.005682
time: 0.24605441093444824
time: 2.1974916458129883
[1, 9373] loss_train: 0.009950, loss_test: 0.005683
time: 0.24405360221862793
time: 2.2094948291778564
[1, 9374] loss_train: 0.010339, loss_test: 0.005684
time: 0.24405384063720703
time: 2.2105042934417725
[1, 9375] loss_train: 0.012387, loss_test: 0.005683
time: 0.2490553855895996
time: 2.2324984073638916
[1, 9376] loss_train: 0.008448, loss_test: 0.005679
time: 0.24405503273010254
time: 2.2234973907470703
[1, 9377] loss_train: 0.006731, loss_test: 0.005677
time: 0.24505400657653809
time: 2.222475528717041
[1, 9378] loss_train: 0.003496, loss_test: 0.005671
time: 0.24405407905578613
time: 2.231516122817993
[1, 9379] loss_train: 0.006805, loss_test: 0.005663
time: 0.24605274200439453
time: 2.254514694213867
[1, 9380] loss_train: 0.013026, loss_test: 0.005653
time: 0.2560563087463379
time: 2.241009473800659
[1, 9381] loss_train: 0.004542, loss_test: 0.005649
time: 0.24405384063720703
time: 2.2495036125183105
[1, 9382] loss_train: 0.006408, loss_test: 0.005649
time: 0.24505400657653809
time: 2.2104947566986084
[1, 9383] loss_train: 0.002586, loss_test: 0.005652
time: 0.24305343627929688
time: 2.1870007514953613
[1, 9384] loss_train: 0.000532, loss_test: 0.005662
time: 0.24505400657653809
time: 2.2335004806518555
[1, 9385] loss_train: 0.000645, loss_test: 0.005678
time: 0.24305319786071777
time: 2.222501039505005
[1, 9386] loss_train: 0.002288, loss_test: 0.005704
time: 0.24206995964050293
time: 2.2144949436187744
[1, 9387] loss_train: 0.007844, loss_test: 0.005725
time: 0.24405407905578613
time: 2.2180018424987793
[1, 9388] loss_train: 0.004326, loss_test: 0.005744
time: 0.24405384063720703
time: 2.194016456604004
[1, 9389] loss_train: 0.007142, loss_test: 0.005749
time: 0.2450549602508545
time: 2.254523754119873
[1, 9390] loss_train: 0.000900, loss_test: 0.005755
time: 0.2580595016479492
time: 2.2365000247955322
[1, 9391] loss_train: 0.003494, loss_test: 0.005762
time: 0.2450542449951172
time: 2.2525100708007812
[1, 9392] loss_train: 0.009982, loss_test: 0.005750
time: 0.25705742835998535
time: 2.2074925899505615
[1, 9393] loss_train: 0.009337, loss_test: 0.005732
time: 0.247056245803833
time: 2.2154974937438965
[1, 9394] loss_train: 0.008690, loss_test: 0.005713
time: 0.25005578994750977
time: 2.210998058319092
[1, 9395] loss_train: 0.009817, loss_test: 0.005706
time: 0.24605727195739746
time: 2.2124412059783936
[1, 9396] loss_train: 0.005429, loss_test: 0.005704
time: 0.24605464935302734
time: 2.196540594100952
[1, 9397] loss_train: 0.011230, loss_test: 0.005706
time: 0.24305367469787598
time: 2.1914896965026855
[1, 9398] loss_train: 0.002536, loss_test: 0.005710
time: 0.24605441093444824
time: 2.192490816116333
[1, 9399] loss_train: 0.001972, loss_test: 0.005702
time: 0.24405431747436523
time: 2.1874887943267822
[1, 9400] loss_train: 0.010107, loss_test: 0.005690
time: 0.2580575942993164
time: 2.192490339279175
[1, 9401] loss_train: 0.001961, loss_test: 0.005681
time: 0.24497246742248535
time: 2.2515032291412354
[1, 9402] loss_train: 0.004052, loss_test: 0.005676
time: 0.24405384063720703
time: 2.217341184616089
[1, 9403] loss_train: 0.004916, loss_test: 0.005672
time: 0.2530546188354492
time: 2.2605061531066895
[1, 9404] loss_train: 0.005976, loss_test: 0.005669
time: 0.24405384063720703
time: 2.2234973907470703
[1, 9405] loss_train: 0.011779, loss_test: 0.005667
time: 0.24805474281311035
time: 2.220496892929077
[1, 9406] loss_train: 0.000800, loss_test: 0.005668
time: 0.24505400657653809
time: 2.232499837875366
[1, 9407] loss_train: 0.008274, loss_test: 0.005667
time: 0.25005507469177246
time: 2.2565267086029053
[1, 9408] loss_train: 0.004156, loss_test: 0.005667
time: 0.2510552406311035
time: 2.2455031871795654
[1, 9409] loss_train: 0.006863, loss_test: 0.005667
time: 0.24505352973937988
time: 2.2325057983398438
[1, 9410] loss_train: 0.001795, loss_test: 0.005669
time: 0.2560560703277588
time: 2.269508123397827
[1, 9411] loss_train: 0.002412, loss_test: 0.005672
time: 0.24805474281311035
time: 2.223496675491333
[1, 9412] loss_train: 0.003351, loss_test: 0.005676
time: 0.2450554370880127
time: 2.223497152328491
[1, 9413] loss_train: 0.008113, loss_test: 0.005679
time: 0.2490549087524414
time: 2.2254984378814697
[1, 9414] loss_train: 0.008376, loss_test: 0.005679
time: 0.24505400657653809
time: 2.231499433517456
[1, 9415] loss_train: 0.005946, loss_test: 0.005681
time: 0.24305367469787598
time: 2.2315144538879395
[1, 9416] loss_train: 0.007103, loss_test: 0.005685
time: 0.24405384063720703
time: 2.2134952545166016
[1, 9417] loss_train: 0.011930, loss_test: 0.005686
time: 0.2450542449951172
time: 2.2535555362701416
[1, 9418] loss_train: 0.005653, loss_test: 0.005686
time: 0.24405384063720703
time: 2.2385013103485107
[1, 9419] loss_train: 0.007792, loss_test: 0.005685
time: 0.24406671524047852
time: 2.195502519607544
[1, 9420] loss_train: 0.007853, loss_test: 0.005682
time: 0.25806212425231934
time: 2.2124948501586914
[1, 9421] loss_train: 0.004317, loss_test: 0.005679
time: 0.2440967559814453
time: 2.2400152683258057
[1, 9422] loss_train: 0.007644, loss_test: 0.005676
time: 0.24405431747436523
time: 2.2030041217803955
[1, 9423] loss_train: 0.008739, loss_test: 0.005672
time: 0.24505400657653809
time: 2.2054929733276367
[1, 9424] loss_train: 0.006395, loss_test: 0.005670
time: 0.24807310104370117
time: 2.2254974842071533
[1, 9425] loss_train: 0.013982, loss_test: 0.005668
time: 0.24406671524047852
time: 2.2135095596313477
[1, 9426] loss_train: 0.012109, loss_test: 0.005672
time: 0.2490553855895996
time: 2.220496416091919
[1, 9427] loss_train: 0.001707, loss_test: 0.005675
time: 0.24605441093444824
time: 2.241345167160034
[1, 9428] loss_train: 0.009873, loss_test: 0.005677
time: 0.24805474281311035
time: 2.2264983654022217
[1, 9429] loss_train: 0.012683, loss_test: 0.005685
time: 0.24605464935302734
time: 2.2505319118499756
[1, 9430] loss_train: 0.009940, loss_test: 0.005690
time: 0.26105809211730957
time: 2.296513795852661
[1, 9431] loss_train: 0.011008, loss_test: 0.005693
time: 0.24805545806884766
time: 2.2361886501312256
[1, 9432] loss_train: 0.005119, loss_test: 0.005695
time: 0.2510554790496826
time: 2.2214977741241455
[1, 9433] loss_train: 0.005141, loss_test: 0.005691
time: 0.24305391311645508
time: 2.2330050468444824
[1, 9434] loss_train: 0.008072, loss_test: 0.005680
time: 0.2470550537109375
time: 2.206740379333496
[1, 9435] loss_train: 0.005201, loss_test: 0.005667
time: 0.2450542449951172
time: 2.226518154144287
[1, 9436] loss_train: 0.010601, loss_test: 0.005655
time: 0.24306559562683105
time: 2.2395012378692627
[1, 9437] loss_train: 0.010594, loss_test: 0.005645
time: 0.24405479431152344
time: 2.2405004501342773
[1, 9438] loss_train: 0.014719, loss_test: 0.005641
time: 0.24505400657653809
time: 2.2365005016326904
[1, 9439] loss_train: 0.009254, loss_test: 0.005644
time: 0.24306797981262207
time: 2.235551118850708
[1, 9440] loss_train: 0.001637, loss_test: 0.005654
time: 0.2580575942993164
time: 2.2515039443969727
[1, 9441] loss_train: 0.003806, loss_test: 0.005667
time: 0.24405384063720703
time: 2.2465310096740723
[1, 9442] loss_train: 0.004824, loss_test: 0.005682
time: 0.24306821823120117
time: 2.25754451751709
[1, 9443] loss_train: 0.002417, loss_test: 0.005699
time: 0.2450542449951172
time: 2.2244973182678223
[1, 9444] loss_train: 0.009099, loss_test: 0.005702
time: 0.24205279350280762
time: 2.202963352203369
[1, 9445] loss_train: 0.004090, loss_test: 0.005705
time: 0.24305415153503418
time: 2.2395007610321045
[1, 9446] loss_train: 0.008995, loss_test: 0.005700
time: 0.24305438995361328
time: 2.223496675491333
[1, 9447] loss_train: 0.003876, loss_test: 0.005695
time: 0.24305391311645508
time: 2.200995683670044
[1, 9448] loss_train: 0.012471, loss_test: 0.005680
time: 0.24405360221862793
time: 2.2154958248138428
[1, 9449] loss_train: 0.011146, loss_test: 0.005671
time: 0.2450549602508545
time: 2.2255120277404785
[1, 9450] loss_train: 0.007362, loss_test: 0.005678
time: 0.25906991958618164
time: 2.2395007610321045
[1, 9451] loss_train: 0.005901, loss_test: 0.005696
time: 0.24805521965026855
time: 2.2385404109954834
[1, 9452] loss_train: 0.005462, loss_test: 0.005704
time: 0.24506783485412598
time: 2.235502004623413
[1, 9453] loss_train: 0.005693, loss_test: 0.005705
time: 0.25005507469177246
time: 2.2070233821868896
[1, 9454] loss_train: 0.006050, loss_test: 0.005691
time: 0.24506855010986328
time: 2.224403142929077
[1, 9455] loss_train: 0.008053, loss_test: 0.005677
time: 0.24805450439453125
time: 2.2128496170043945
[1, 9456] loss_train: 0.010496, loss_test: 0.005664
time: 0.24505400657653809
time: 2.208494186401367
[1, 9457] loss_train: 0.006114, loss_test: 0.005655
time: 0.2450542449951172
time: 2.2335102558135986
[1, 9458] loss_train: 0.011061, loss_test: 0.005651
time: 0.24405384063720703
time: 2.203493118286133
[1, 9459] loss_train: 0.001485, loss_test: 0.005648
time: 0.24505400657653809
time: 2.2064943313598633
[1, 9460] loss_train: 0.009876, loss_test: 0.005645
time: 0.25505590438842773
time: 2.2480082511901855
[1, 9461] loss_train: 0.003221, loss_test: 0.005641
time: 0.24405479431152344
time: 2.234499454498291
[1, 9462] loss_train: 0.004298, loss_test: 0.005639
time: 0.2440624237060547
time: 2.2120003700256348
[1, 9463] loss_train: 0.004564, loss_test: 0.005638
time: 0.24305438995361328
time: 2.2445011138916016
[1, 9464] loss_train: 0.010406, loss_test: 0.005636
time: 0.24706697463989258
time: 2.242502212524414
[1, 9465] loss_train: 0.001421, loss_test: 0.005635
time: 0.24505376815795898
time: 2.2335097789764404
[1, 9466] loss_train: 0.009873, loss_test: 0.005635
time: 0.24406766891479492
time: 2.21099853515625
[1, 9467] loss_train: 0.005169, loss_test: 0.005634
time: 0.24405479431152344
time: 2.1924901008605957
[1, 9468] loss_train: 0.004552, loss_test: 0.005633
time: 0.2490546703338623
time: 2.2285306453704834
[1, 9469] loss_train: 0.003681, loss_test: 0.005631
time: 0.24605464935302734
time: 2.2358105182647705
[1, 9470] loss_train: 0.011746, loss_test: 0.005631
time: 0.26205873489379883
time: 2.2475016117095947
[1, 9471] loss_train: 0.003133, loss_test: 0.005632
time: 0.24805521965026855
time: 2.242501974105835
[1, 9472] loss_train: 0.004976, loss_test: 0.005632
time: 0.25005674362182617
time: 2.216495990753174
[1, 9473] loss_train: 0.007054, loss_test: 0.005634
time: 0.24305319786071777
time: 2.228499174118042
[1, 9474] loss_train: 0.015293, loss_test: 0.005635
time: 0.2510552406311035
time: 2.226505994796753
[1, 9475] loss_train: 0.006265, loss_test: 0.005638
time: 0.24405431747436523
time: 2.2150278091430664
[1, 9476] loss_train: 0.006909, loss_test: 0.005642
time: 0.24305438995361328
time: 2.223496675491333
[1, 9477] loss_train: 0.005886, loss_test: 0.005646
time: 0.24405455589294434
time: 2.2555041313171387
[1, 9478] loss_train: 0.008190, loss_test: 0.005650
time: 0.24506711959838867
time: 2.233396530151367
[1, 9479] loss_train: 0.004618, loss_test: 0.005651
time: 0.24406743049621582
time: 2.235015869140625
[1, 9480] loss_train: 0.004725, loss_test: 0.005651
time: 0.2560570240020752
time: 2.2485029697418213
[1, 9481] loss_train: 0.004677, loss_test: 0.005650
time: 0.2490546703338623
time: 2.2405035495758057
[1, 9482] loss_train: 0.006851, loss_test: 0.005649
time: 0.24405360221862793
time: 2.2375032901763916
[1, 9483] loss_train: 0.003462, loss_test: 0.005651
time: 0.24305462837219238
time: 2.2134945392608643
[1, 9484] loss_train: 0.005938, loss_test: 0.005655
time: 0.24405336380004883
time: 2.215773344039917
[1, 9485] loss_train: 0.005294, loss_test: 0.005660
time: 0.24305367469787598
time: 2.225498676300049
[1, 9486] loss_train: 0.002027, loss_test: 0.005665
time: 0.24305295944213867
time: 2.2225656509399414
[1, 9487] loss_train: 0.007781, loss_test: 0.005671
time: 0.24405455589294434
time: 2.208493947982788
[1, 9488] loss_train: 0.002076, loss_test: 0.005682
time: 0.24405407905578613
time: 2.2181148529052734
[1, 9489] loss_train: 0.014531, loss_test: 0.005681
time: 0.25005602836608887
time: 2.236013889312744
[1, 9490] loss_train: 0.009852, loss_test: 0.005678
time: 0.2580835819244385
time: 2.273771286010742
[1, 9491] loss_train: 0.002844, loss_test: 0.005677
time: 0.24805521965026855
time: 2.2114944458007812
[1, 9492] loss_train: 0.006251, loss_test: 0.005676
time: 0.2450549602508545
time: 2.19649076461792
[1, 9493] loss_train: 0.001920, loss_test: 0.005677
time: 0.24805545806884766
time: 2.225496530532837
[1, 9494] loss_train: 0.007781, loss_test: 0.005681
time: 0.24606800079345703
time: 2.2245090007781982
[1, 9495] loss_train: 0.009865, loss_test: 0.005683
time: 0.24605488777160645
time: 2.235502004623413
[1, 9496] loss_train: 0.004806, loss_test: 0.005683
time: 0.24405384063720703
time: 2.2475028038024902
[1, 9497] loss_train: 0.001326, loss_test: 0.005684
time: 0.24305391311645508
time: 2.2094943523406982
[1, 9498] loss_train: 0.007399, loss_test: 0.005683
time: 0.24605369567871094
time: 2.2830445766448975
[1, 9499] loss_train: 0.005509, loss_test: 0.005680
time: 0.24405407905578613
time: 2.2154955863952637
[1, 9500] loss_train: 0.003324, loss_test: 0.005676
time: 0.256056547164917
time: 2.242501974105835
[1, 9501] loss_train: 0.009921, loss_test: 0.005673
time: 0.24605441093444824
time: 2.2204973697662354
[1, 9502] loss_train: 0.002972, loss_test: 0.005674
time: 0.24305319786071777
time: 2.2375166416168213
[1, 9503] loss_train: 0.010204, loss_test: 0.005680
time: 0.24405479431152344
time: 2.247502088546753
[1, 9504] loss_train: 0.000990, loss_test: 0.005693
time: 0.24305367469787598
time: 2.207494020462036
[1, 9505] loss_train: 0.002224, loss_test: 0.005714
time: 0.24406886100769043
time: 2.2134950160980225
[1, 9506] loss_train: 0.001607, loss_test: 0.005742
time: 0.24205422401428223
time: 2.214498281478882
[1, 9507] loss_train: 0.006967, loss_test: 0.005764
time: 0.24305343627929688
time: 2.2105133533477783
[1, 9508] loss_train: 0.012536, loss_test: 0.005768
time: 0.24305319786071777
time: 2.2131965160369873
[1, 9509] loss_train: 0.001798, loss_test: 0.005771
time: 0.24605417251586914
time: 2.228498935699463
[1, 9510] loss_train: 0.004030, loss_test: 0.005768
time: 0.2590963840484619
time: 2.238501787185669
[1, 9511] loss_train: 0.006626, loss_test: 0.005757
time: 0.2450556755065918
time: 2.2264976501464844
[1, 9512] loss_train: 0.004257, loss_test: 0.005743
time: 0.2490553855895996
time: 2.2274978160858154
[1, 9513] loss_train: 0.009548, loss_test: 0.005723
time: 0.2450551986694336
time: 2.2735097408294678
[1, 9514] loss_train: 0.004074, loss_test: 0.005710
time: 0.2510557174682617
time: 2.231501817703247
[1, 9515] loss_train: 0.008241, loss_test: 0.005698
time: 0.24605369567871094
time: 2.217514991760254
[1, 9516] loss_train: 0.004551, loss_test: 0.005688
time: 0.2470552921295166
time: 2.2255070209503174
[1, 9517] loss_train: 0.006038, loss_test: 0.005680
time: 0.24405384063720703
time: 2.193490982055664
[1, 9518] loss_train: 0.006624, loss_test: 0.005674
time: 0.2450542449951172
time: 2.2114949226379395
[1, 9519] loss_train: 0.008872, loss_test: 0.005667
time: 0.24405908584594727
time: 2.23551869392395
[1, 9520] loss_train: 0.007936, loss_test: 0.005660
time: 0.2560567855834961
time: 2.2264981269836426
[1, 9521] loss_train: 0.005897, loss_test: 0.005658
time: 0.24405431747436523
time: 2.2104945182800293
[1, 9522] loss_train: 0.010160, loss_test: 0.005660
time: 0.24805521965026855
time: 2.208493709564209
[1, 9523] loss_train: 0.006538, loss_test: 0.005668
time: 0.24405694007873535
time: 2.224496841430664
[1, 9524] loss_train: 0.004630, loss_test: 0.005677
time: 0.24509572982788086
time: 2.241501569747925
[1, 9525] loss_train: 0.006890, loss_test: 0.005687
time: 0.24305438995361328
time: 2.25750470161438
[1, 9526] loss_train: 0.011019, loss_test: 0.005697
time: 0.2490553855895996
time: 2.2225162982940674
[1, 9527] loss_train: 0.012890, loss_test: 0.005706
time: 0.24405431747436523
time: 2.199496030807495
[1, 9528] loss_train: 0.004336, loss_test: 0.005710
time: 0.24305367469787598
time: 2.237513542175293
[1, 9529] loss_train: 0.010010, loss_test: 0.005712
time: 0.2520561218261719
time: 2.2035083770751953
[1, 9530] loss_train: 0.003409, loss_test: 0.005706
time: 0.2580571174621582
time: 2.273508310317993
[1, 9531] loss_train: 0.002694, loss_test: 0.005699
time: 0.2510566711425781
time: 2.203000068664551
[1, 9532] loss_train: 0.002108, loss_test: 0.005687
time: 0.2490558624267578
time: 2.2392029762268066
[1, 9533] loss_train: 0.006741, loss_test: 0.005682
time: 0.2490682601928711
time: 2.258504629135132
[1, 9534] loss_train: 0.002701, loss_test: 0.005687
time: 0.24405455589294434
time: 2.235499620437622
[1, 9535] loss_train: 0.007009, loss_test: 0.005691
time: 0.24905610084533691
time: 2.220048666000366
[1, 9536] loss_train: 0.008500, loss_test: 0.005697
time: 0.24605464935302734
time: 2.207502841949463
[1, 9537] loss_train: 0.005640, loss_test: 0.005700
time: 0.24305391311645508
time: 2.2425014972686768
[1, 9538] loss_train: 0.005664, loss_test: 0.005703
time: 0.24509835243225098
time: 2.218496561050415
[1, 9539] loss_train: 0.005017, loss_test: 0.005706
time: 0.24605464935302734
time: 2.250188112258911
[1, 9540] loss_train: 0.003564, loss_test: 0.005710
time: 0.25505638122558594
time: 2.2320029735565186
[1, 9541] loss_train: 0.008940, loss_test: 0.005703
time: 0.24305391311645508
time: 2.243504524230957
[1, 9542] loss_train: 0.002754, loss_test: 0.005697
time: 0.24605417251586914
time: 2.2485032081604004
[1, 9543] loss_train: 0.007561, loss_test: 0.005686
time: 0.24506640434265137
time: 2.2265002727508545
[1, 9544] loss_train: 0.003784, loss_test: 0.005680
time: 0.24605512619018555
time: 2.2004926204681396
[1, 9545] loss_train: 0.005507, loss_test: 0.005674
time: 0.24405574798583984
time: 2.1894888877868652
[1, 9546] loss_train: 0.000688, loss_test: 0.005675
time: 0.24205374717712402
time: 2.228520631790161
[1, 9547] loss_train: 0.010346, loss_test: 0.005664
time: 0.24466729164123535
time: 2.241502285003662
[1, 9548] loss_train: 0.009601, loss_test: 0.005650
time: 0.24305343627929688
time: 2.217496395111084
[1, 9549] loss_train: 0.005459, loss_test: 0.005642
time: 0.2530951499938965
time: 2.2475192546844482
[1, 9550] loss_train: 0.002162, loss_test: 0.005639
time: 0.2560551166534424
time: 2.254504680633545
[1, 9551] loss_train: 0.009414, loss_test: 0.005638
time: 0.24405479431152344
time: 2.214494466781616
[1, 9552] loss_train: 0.008670, loss_test: 0.005640
time: 0.25005531311035156
time: 2.223001480102539
[1, 9553] loss_train: 0.002652, loss_test: 0.005641
time: 0.2450551986694336
time: 2.2034919261932373
[1, 9554] loss_train: 0.002405, loss_test: 0.005642
time: 0.24905633926391602
time: 2.2635130882263184
[1, 9555] loss_train: 0.005473, loss_test: 0.005642
time: 0.24405336380004883
time: 2.1964948177337646
[1, 9556] loss_train: 0.002422, loss_test: 0.005640
time: 0.2483656406402588
time: 2.218496561050415
[1, 9557] loss_train: 0.005682, loss_test: 0.005640
time: 0.24405407905578613
time: 2.220496892929077
[1, 9558] loss_train: 0.008766, loss_test: 0.005641
time: 0.24405384063720703
time: 2.205493450164795
[1, 9559] loss_train: 0.008679, loss_test: 0.005644
time: 0.2450549602508545
time: 2.219496250152588
[1, 9560] loss_train: 0.005474, loss_test: 0.005648
time: 0.2551119327545166
time: 2.2495028972625732
[1, 9561] loss_train: 0.009652, loss_test: 0.005652
time: 0.24305343627929688
time: 2.2162787914276123
[1, 9562] loss_train: 0.008921, loss_test: 0.005655
time: 0.24306702613830566
time: 2.228916883468628
[1, 9563] loss_train: 0.012598, loss_test: 0.005655
time: 0.2450551986694336
time: 2.2294981479644775
[1, 9564] loss_train: 0.008353, loss_test: 0.005652
time: 0.24305462837219238
time: 2.2024924755096436
[1, 9565] loss_train: 0.008644, loss_test: 0.005650
time: 0.24405384063720703
time: 2.219496965408325
[1, 9566] loss_train: 0.006399, loss_test: 0.005646
time: 0.2470543384552002
time: 2.216510772705078
[1, 9567] loss_train: 0.006909, loss_test: 0.005642
time: 0.2450547218322754
time: 2.260530710220337
[1, 9568] loss_train: 0.002871, loss_test: 0.005639
time: 0.2450547218322754
time: 2.232499361038208
[1, 9569] loss_train: 0.011284, loss_test: 0.005640
time: 0.24805474281311035
time: 2.214508295059204
[1, 9570] loss_train: 0.010282, loss_test: 0.005641
time: 0.258056640625
time: 2.253505229949951
[1, 9571] loss_train: 0.002575, loss_test: 0.005641
time: 0.2520558834075928
time: 2.2175116539001465
[1, 9572] loss_train: 0.002978, loss_test: 0.005644
time: 0.24505400657653809
time: 2.2375011444091797
[1, 9573] loss_train: 0.007076, loss_test: 0.005649
time: 0.24808073043823242
time: 2.2254974842071533
[1, 9574] loss_train: 0.004978, loss_test: 0.005658
time: 0.2450549602508545
time: 2.2365028858184814
[1, 9575] loss_train: 0.006009, loss_test: 0.005668
time: 0.24505400657653809
time: 2.254504919052124
[1, 9576] loss_train: 0.011720, loss_test: 0.005669
time: 0.24405455589294434
time: 2.2350213527679443
[1, 9577] loss_train: 0.001205, loss_test: 0.005673
time: 0.24605369567871094
time: 2.196512460708618
[1, 9578] loss_train: 0.010362, loss_test: 0.005676
time: 0.24305319786071777
time: 2.20249342918396
[1, 9579] loss_train: 0.004907, loss_test: 0.005679
time: 0.24305343627929688
time: 2.2064931392669678
[1, 9580] loss_train: 0.002897, loss_test: 0.005686
time: 0.256056547164917
time: 2.2315189838409424
[1, 9581] loss_train: 0.008834, loss_test: 0.005685
time: 0.24405455589294434
time: 2.213498592376709
[1, 9582] loss_train: 0.007473, loss_test: 0.005692
time: 0.24406003952026367
time: 2.2014927864074707
[1, 9583] loss_train: 0.002979, loss_test: 0.005706
time: 0.25005507469177246
time: 2.265510082244873
[1, 9584] loss_train: 0.005584, loss_test: 0.005723
time: 0.24405360221862793
time: 2.2214972972869873
[1, 9585] loss_train: 0.006468, loss_test: 0.005742
time: 0.24405384063720703
time: 2.2153689861297607
[1, 9586] loss_train: 0.002430, loss_test: 0.005752
time: 0.24605488777160645
time: 2.2130110263824463
[1, 9587] loss_train: 0.001476, loss_test: 0.005763
time: 0.2450542449951172
time: 2.229499101638794
[1, 9588] loss_train: 0.005676, loss_test: 0.005754
time: 0.2490556240081787
time: 2.2125155925750732
[1, 9589] loss_train: 0.008790, loss_test: 0.005734
time: 0.24605464935302734
time: 2.206493854522705
[1, 9590] loss_train: 0.005399, loss_test: 0.005712
time: 0.26105761528015137
time: 2.2160274982452393
[1, 9591] loss_train: 0.002527, loss_test: 0.005696
time: 0.24805450439453125
time: 2.2024922370910645
[1, 9592] loss_train: 0.001159, loss_test: 0.005679
time: 0.24405360221862793
time: 2.1894900798797607
[1, 9593] loss_train: 0.003127, loss_test: 0.005669
time: 0.24405431747436523
time: 2.195490837097168
[1, 9594] loss_train: 0.007986, loss_test: 0.005661
time: 0.24605512619018555
time: 2.2284979820251465
[1, 9595] loss_train: 0.007435, loss_test: 0.005661
time: 0.2450547218322754
time: 2.2164955139160156
[1, 9596] loss_train: 0.003056, loss_test: 0.005667
time: 0.2450542449951172
time: 2.219520092010498
[1, 9597] loss_train: 0.012080, loss_test: 0.005674
time: 0.24405431747436523
time: 2.1945085525512695
[1, 9598] loss_train: 0.006640, loss_test: 0.005678
time: 0.24405312538146973
time: 2.2154979705810547
[1, 9599] loss_train: 0.010155, loss_test: 0.005685
time: 0.24805545806884766
time: 2.195490837097168
[1, 9600] loss_train: 0.003835, loss_test: 0.005694
time: 0.2580578327178955
time: 2.22405743598938
[1, 9601] loss_train: 0.004245, loss_test: 0.005702
time: 0.2510559558868408
time: 2.2234976291656494
[1, 9602] loss_train: 0.007251, loss_test: 0.005700
time: 0.2450544834136963
time: 2.2725112438201904
[1, 9603] loss_train: 0.006640, loss_test: 0.005692
time: 0.25505661964416504
time: 2.2264976501464844
[1, 9604] loss_train: 0.006244, loss_test: 0.005669
time: 0.24606871604919434
time: 2.2234973907470703
[1, 9605] loss_train: 0.006936, loss_test: 0.005653
time: 0.24405407905578613
time: 2.2340118885040283
[1, 9606] loss_train: 0.004331, loss_test: 0.005644
time: 0.2450542449951172
time: 2.246363639831543
[1, 9607] loss_train: 0.015542, loss_test: 0.005642
time: 0.24528717994689941
time: 2.249504327774048
[1, 9608] loss_train: 0.004385, loss_test: 0.005642
time: 0.24405813217163086
time: 2.222498655319214
[1, 9609] loss_train: 0.003469, loss_test: 0.005647
time: 0.24405407905578613
time: 2.2135069370269775
[1, 9610] loss_train: 0.001169, loss_test: 0.005658
time: 0.2560567855834961
time: 2.2025015354156494
[1, 9611] loss_train: 0.003130, loss_test: 0.005673
time: 0.24405407905578613
time: 2.2144970893859863
[1, 9612] loss_train: 0.004967, loss_test: 0.005690
time: 0.24605488777160645
time: 2.206493377685547
[1, 9613] loss_train: 0.009616, loss_test: 0.005688
time: 0.24405431747436523
time: 2.2204978466033936
[1, 9614] loss_train: 0.009242, loss_test: 0.005679
time: 0.2470552921295166
time: 2.1934897899627686
[1, 9615] loss_train: 0.001278, loss_test: 0.005673
time: 0.24505949020385742
time: 2.201505661010742
[1, 9616] loss_train: 0.006946, loss_test: 0.005658
time: 0.24905610084533691
time: 2.219496250152588
[1, 9617] loss_train: 0.005136, loss_test: 0.005645
time: 0.24608063697814941
time: 2.205035448074341
[1, 9618] loss_train: 0.010247, loss_test: 0.005640
time: 0.2510557174682617
time: 2.2244980335235596
[1, 9619] loss_train: 0.004315, loss_test: 0.005647
time: 0.24405407905578613
time: 2.2370104789733887
[1, 9620] loss_train: 0.001997, loss_test: 0.005657
time: 0.25705623626708984
time: 2.232499599456787
[1, 9621] loss_train: 0.005234, loss_test: 0.005668
time: 0.2470557689666748
time: 2.2525031566619873
[1, 9622] loss_train: 0.006087, loss_test: 0.005679
time: 0.24405360221862793
time: 2.2355005741119385
[1, 9623] loss_train: 0.004695, loss_test: 0.005687
time: 0.24506616592407227
time: 2.221497058868408
[1, 9624] loss_train: 0.008777, loss_test: 0.005694
time: 0.24305367469787598
time: 2.2294981479644775
[1, 9625] loss_train: 0.006226, loss_test: 0.005696
time: 0.2450547218322754
time: 2.205493450164795
[1, 9626] loss_train: 0.009995, loss_test: 0.005698
time: 0.24405431747436523
time: 2.2154953479766846
[1, 9627] loss_train: 0.008747, loss_test: 0.005697
time: 0.24405455589294434
time: 2.195490837097168
[1, 9628] loss_train: 0.008327, loss_test: 0.005694
time: 0.2470541000366211
time: 2.201493263244629
[1, 9629] loss_train: 0.004074, loss_test: 0.005690
time: 0.24405503273010254
time: 2.197089672088623
[1, 9630] loss_train: 0.003108, loss_test: 0.005686
time: 0.2580695152282715
time: 2.230499505996704
[1, 9631] loss_train: 0.011416, loss_test: 0.005683
time: 0.25005483627319336
time: 2.185992479324341
[1, 9632] loss_train: 0.007026, loss_test: 0.005680
time: 0.2470543384552002
time: 2.2255003452301025
[1, 9633] loss_train: 0.007949, loss_test: 0.005678
time: 0.2490553855895996
time: 2.2905123233795166
[1, 9634] loss_train: 0.005145, loss_test: 0.005673
time: 0.2450547218322754
time: 2.23449969291687
[1, 9635] loss_train: 0.005916, loss_test: 0.005671
time: 0.2530701160430908
time: 2.2365033626556396
[1, 9636] loss_train: 0.004992, loss_test: 0.005673
time: 0.24505352973937988
time: 2.2104945182800293
[1, 9637] loss_train: 0.002729, loss_test: 0.005681
time: 0.24605417251586914
time: 2.1964919567108154
[1, 9638] loss_train: 0.000570, loss_test: 0.005693
time: 0.24305438995361328
time: 2.2184956073760986
[1, 9639] loss_train: 0.012648, loss_test: 0.005694
time: 0.24405431747436523
time: 2.2134950160980225
[1, 9640] loss_train: 0.003808, loss_test: 0.005694
time: 0.2540566921234131
time: 2.2555041313171387
[1, 9641] loss_train: 0.001729, loss_test: 0.005695
time: 0.24805498123168945
time: 2.2125091552734375
[1, 9642] loss_train: 0.007486, loss_test: 0.005693
time: 0.24305343627929688
time: 2.2014927864074707
[1, 9643] loss_train: 0.004800, loss_test: 0.005689
time: 0.24305415153503418
time: 2.2490108013153076
[1, 9644] loss_train: 0.008087, loss_test: 0.005684
time: 0.2490556240081787
time: 2.2744457721710205
[1, 9645] loss_train: 0.016113, loss_test: 0.005662
time: 0.2490546703338623
time: 2.2335000038146973
[1, 9646] loss_train: 0.006455, loss_test: 0.005648
time: 0.2470543384552002
time: 2.2375011444091797
[1, 9647] loss_train: 0.005584, loss_test: 0.005642
time: 0.24505376815795898
time: 2.228501558303833
[1, 9648] loss_train: 0.006203, loss_test: 0.005641
time: 0.24307847023010254
time: 2.221498727798462
[1, 9649] loss_train: 0.007464, loss_test: 0.005645
time: 0.24405384063720703
time: 2.2305009365081787
[1, 9650] loss_train: 0.011174, loss_test: 0.005647
time: 0.25505638122558594
time: 2.2385013103485107
[1, 9651] loss_train: 0.013474, loss_test: 0.005658
time: 0.24405431747436523
time: 2.238502025604248
[1, 9652] loss_train: 0.004613, loss_test: 0.005669
time: 0.2450551986694336
time: 2.218496084213257
[1, 9653] loss_train: 0.001377, loss_test: 0.005676
time: 0.24405384063720703
time: 2.2254974842071533
[1, 9654] loss_train: 0.003571, loss_test: 0.005674
time: 0.24905610084533691
time: 2.201491355895996
[1, 9655] loss_train: 0.017018, loss_test: 0.005687
time: 0.2450556755065918
time: 2.221510887145996
[1, 9656] loss_train: 0.003045, loss_test: 0.005689
time: 0.2490546703338623
time: 2.2365002632141113
[1, 9657] loss_train: 0.004455, loss_test: 0.005676
time: 0.24405360221862793
time: 2.235511541366577
[1, 9658] loss_train: 0.012840, loss_test: 0.005659
time: 0.24205398559570312
time: 2.205496311187744
[1, 9659] loss_train: 0.007337, loss_test: 0.005647
time: 0.24405312538146973
time: 2.2445247173309326
[1, 9660] loss_train: 0.005114, loss_test: 0.005640
time: 0.25505614280700684
time: 2.292513370513916
[1, 9661] loss_train: 0.005626, loss_test: 0.005638
time: 0.24405479431152344
time: 2.2425005435943604
[1, 9662] loss_train: 0.005414, loss_test: 0.005644
time: 0.24405407905578613
time: 2.2264983654022217
[1, 9663] loss_train: 0.003992, loss_test: 0.005656
time: 0.24507999420166016
time: 2.20149302482605
[1, 9664] loss_train: 0.009352, loss_test: 0.005671
time: 0.2450544834136963
time: 2.2024967670440674
[1, 9665] loss_train: 0.005816, loss_test: 0.005688
time: 0.24405574798583984
time: 2.219496965408325
[1, 9666] loss_train: 0.003796, loss_test: 0.005703
time: 0.24405384063720703
time: 2.2244980335235596
[1, 9667] loss_train: 0.005989, loss_test: 0.005725
time: 0.24405455589294434
time: 2.2415010929107666
[1, 9668] loss_train: 0.004805, loss_test: 0.005747
time: 0.24405360221862793
time: 2.254016876220703
[1, 9669] loss_train: 0.006015, loss_test: 0.005764
time: 0.24405431747436523
time: 2.234590530395508
[1, 9670] loss_train: 0.011386, loss_test: 0.005752
time: 0.25505661964416504
time: 2.244361639022827
[1, 9671] loss_train: 0.005463, loss_test: 0.005735
time: 0.25005483627319336
time: 2.2505042552948
[1, 9672] loss_train: 0.009324, loss_test: 0.005707
time: 0.24588561058044434
time: 2.219496488571167
[1, 9673] loss_train: 0.006300, loss_test: 0.005679
time: 0.2450549602508545
time: 2.2204997539520264
[1, 9674] loss_train: 0.001866, loss_test: 0.005665
time: 0.24405479431152344
time: 2.19549298286438
[1, 9675] loss_train: 0.003223, loss_test: 0.005661
time: 0.25005578994750977
time: 2.242501735687256
[1, 9676] loss_train: 0.009594, loss_test: 0.005661
time: 0.2450547218322754
time: 2.2024941444396973
[1, 9677] loss_train: 0.002803, loss_test: 0.005664
time: 0.24805450439453125
time: 2.2244980335235596
[1, 9678] loss_train: 0.003712, loss_test: 0.005668
time: 0.24505400657653809
time: 2.237535238265991
[1, 9679] loss_train: 0.009539, loss_test: 0.005675
time: 0.24405384063720703
time: 2.2250282764434814
[1, 9680] loss_train: 0.017664, loss_test: 0.005691
time: 0.2530553340911865
time: 2.2595057487487793
[1, 9681] loss_train: 0.005838, loss_test: 0.005699
time: 0.24405312538146973
time: 2.241501569747925
[1, 9682] loss_train: 0.007410, loss_test: 0.005702
time: 0.24605417251586914
time: 2.2555043697357178
[1, 9683] loss_train: 0.018909, loss_test: 0.005699
time: 0.24406647682189941
time: 2.221497058868408
[1, 9684] loss_train: 0.004092, loss_test: 0.005691
time: 0.24506640434265137
time: 2.2615060806274414
[1, 9685] loss_train: 0.006521, loss_test: 0.005680
time: 0.2470545768737793
time: 2.247502565383911
[1, 9686] loss_train: 0.010347, loss_test: 0.005672
time: 0.24406719207763672
time: 2.2140066623687744
[1, 9687] loss_train: 0.003572, loss_test: 0.005664
time: 0.24405360221862793
time: 2.23249888420105
[1, 9688] loss_train: 0.009285, loss_test: 0.005661
time: 0.24405455589294434
time: 2.215507984161377
[1, 9689] loss_train: 0.002954, loss_test: 0.005657
time: 0.2450544834136963
time: 2.256068706512451
[1, 9690] loss_train: 0.007597, loss_test: 0.005652
time: 0.25705766677856445
time: 2.2585062980651855
[1, 9691] loss_train: 0.005445, loss_test: 0.005649
time: 0.24405455589294434
time: 2.217496395111084
[1, 9692] loss_train: 0.002626, loss_test: 0.005650
time: 0.24708199501037598
time: 2.2595057487487793
[1, 9693] loss_train: 0.008711, loss_test: 0.005651
time: 0.24406647682189941
time: 2.2244973182678223
[1, 9694] loss_train: 0.006611, loss_test: 0.005651
time: 0.2450544834136963
time: 2.221496820449829
[1, 9695] loss_train: 0.005387, loss_test: 0.005652
time: 0.24405431747436523
time: 2.228027820587158
[1, 9696] loss_train: 0.003226, loss_test: 0.005655
time: 0.24305510520935059
time: 2.2080156803131104
[1, 9697] loss_train: 0.007730, loss_test: 0.005658
time: 0.2450547218322754
time: 2.2174949645996094
[1, 9698] loss_train: 0.003910, loss_test: 0.005663
time: 0.24806737899780273
time: 2.2165119647979736
[1, 9699] loss_train: 0.003732, loss_test: 0.005669
time: 0.24805545806884766
time: 2.246011734008789
[1, 9700] loss_train: 0.005328, loss_test: 0.005673
time: 0.26105737686157227
time: 2.268507957458496
[1, 9701] loss_train: 0.016930, loss_test: 0.005676
time: 0.2450542449951172
time: 2.2114953994750977
[1, 9702] loss_train: 0.001952, loss_test: 0.005676
time: 0.25005507469177246
time: 2.20149302482605
[1, 9703] loss_train: 0.005368, loss_test: 0.005677
time: 0.24505400657653809
time: 2.207494020462036
[1, 9704] loss_train: 0.003355, loss_test: 0.005679
time: 0.24405336380004883
time: 2.2505154609680176
[1, 9705] loss_train: 0.009205, loss_test: 0.005678
time: 0.24356985092163086
time: 2.2515041828155518
[1, 9706] loss_train: 0.008562, loss_test: 0.005667
time: 0.24405455589294434
time: 2.2155191898345947
[1, 9707] loss_train: 0.009316, loss_test: 0.005660
time: 0.24306797981262207
time: 2.2415006160736084
[1, 9708] loss_train: 0.005183, loss_test: 0.005653
time: 0.24405431747436523
time: 2.2120110988616943
[1, 9709] loss_train: 0.010562, loss_test: 0.005648
time: 0.24655866622924805
time: 2.2244973182678223
[1, 9710] loss_train: 0.008188, loss_test: 0.005643
time: 0.2560567855834961
time: 2.2540948390960693
[1, 9711] loss_train: 0.011125, loss_test: 0.005639
time: 0.24605417251586914
time: 2.230499505996704
[1, 9712] loss_train: 0.008613, loss_test: 0.005638
time: 0.24405360221862793
time: 2.2355003356933594
[1, 9713] loss_train: 0.004916, loss_test: 0.005639
time: 0.24405407905578613
time: 2.217496871948242
[1, 9714] loss_train: 0.014633, loss_test: 0.005646
time: 0.24405431747436523
time: 2.2084929943084717
[1, 9715] loss_train: 0.001247, loss_test: 0.005663
time: 0.24309229850769043
time: 2.233499765396118
[1, 9716] loss_train: 0.005722, loss_test: 0.005682
time: 0.24506187438964844
time: 2.2220335006713867
[1, 9717] loss_train: 0.008211, loss_test: 0.005697
time: 0.24405431747436523
time: 2.191490411758423
[1, 9718] loss_train: 0.006982, loss_test: 0.005706
time: 0.24605369567871094
time: 2.2195136547088623
[1, 9719] loss_train: 0.011656, loss_test: 0.005722
time: 0.24805569648742676
time: 2.2545037269592285
[1, 9720] loss_train: 0.002610, loss_test: 0.005715
time: 0.25705790519714355
time: 2.2215068340301514
[1, 9721] loss_train: 0.006681, loss_test: 0.005692
time: 0.2510561943054199
time: 2.2214999198913574
[1, 9722] loss_train: 0.010099, loss_test: 0.005665
time: 0.24605488777160645
time: 2.2174956798553467
[1, 9723] loss_train: 0.011886, loss_test: 0.005651
time: 0.2450544834136963
time: 2.231499433517456
[1, 9724] loss_train: 0.010330, loss_test: 0.005648
time: 0.24605393409729004
time: 2.218496561050415
[1, 9725] loss_train: 0.006851, loss_test: 0.005662
time: 0.2450542449951172
time: 2.2125208377838135
[1, 9726] loss_train: 0.002736, loss_test: 0.005690
time: 0.24405407905578613
time: 2.250023603439331
[1, 9727] loss_train: 0.004522, loss_test: 0.005732
time: 0.24405431747436523
time: 2.2465028762817383
[1, 9728] loss_train: 0.006944, loss_test: 0.005768
time: 0.24305391311645508
time: 2.239501476287842
[1, 9729] loss_train: 0.003189, loss_test: 0.005782
time: 0.24405407905578613
time: 2.313607931137085
[1, 9730] loss_train: 0.005994, loss_test: 0.005790
time: 0.2540562152862549
time: 2.2645068168640137
[1, 9731] loss_train: 0.002472, loss_test: 0.005785
time: 0.2470545768737793
time: 2.2385008335113525
[1, 9732] loss_train: 0.007468, loss_test: 0.005780
time: 0.24505376815795898
time: 2.263014078140259
[1, 9733] loss_train: 0.004301, loss_test: 0.005778
time: 0.24405360221862793
time: 2.2475032806396484
[1, 9734] loss_train: 0.003766, loss_test: 0.005780
time: 0.24605488777160645
time: 2.199491500854492
[1, 9735] loss_train: 0.009767, loss_test: 0.005758
time: 0.24405455589294434
time: 2.216005325317383
[1, 9736] loss_train: 0.008898, loss_test: 0.005710
time: 0.24406766891479492
time: 2.197507619857788
[1, 9737] loss_train: 0.007891, loss_test: 0.005686
time: 0.2450544834136963
time: 2.243501663208008
[1, 9738] loss_train: 0.001128, loss_test: 0.005684
time: 0.24305367469787598
time: 2.2214972972869873
[1, 9739] loss_train: 0.016588, loss_test: 0.005692
time: 0.24521303176879883
time: 2.2084944248199463
[1, 9740] loss_train: 0.004265, loss_test: 0.005720
time: 0.25505638122558594
time: 2.2385005950927734
[1, 9741] loss_train: 0.002991, loss_test: 0.005763
time: 0.24605393409729004
time: 2.2385010719299316
[1, 9742] loss_train: 0.003284, loss_test: 0.005811
time: 0.24405884742736816
time: 2.2194998264312744
[1, 9743] loss_train: 0.008163, loss_test: 0.005841
time: 0.24405193328857422
time: 2.219496965408325
[1, 9744] loss_train: 0.005805, loss_test: 0.005866
time: 0.2490551471710205
time: 2.2355000972747803
[1, 9745] loss_train: 0.006733, loss_test: 0.005842
time: 0.2450547218322754
time: 2.2402431964874268
[1, 9746] loss_train: 0.007077, loss_test: 0.005807
time: 0.25005626678466797
time: 2.211026191711426
[1, 9747] loss_train: 0.011190, loss_test: 0.005746
time: 0.24405384063720703
time: 2.2084946632385254
[1, 9748] loss_train: 0.008116, loss_test: 0.005700
time: 0.2450542449951172
time: 2.207493782043457
[1, 9749] loss_train: 0.002849, loss_test: 0.005663
time: 0.24305343627929688
time: 2.208494186401367
[1, 9750] loss_train: 0.007284, loss_test: 0.005649
time: 0.2560572624206543
time: 2.258514165878296
[1, 9751] loss_train: 0.005574, loss_test: 0.005649
time: 0.24405455589294434
time: 2.1979947090148926
[1, 9752] loss_train: 0.004560, loss_test: 0.005661
time: 0.24405384063720703
time: 2.2330033779144287
[1, 9753] loss_train: 0.001608, loss_test: 0.005672
time: 0.24605417251586914
time: 2.2094945907592773
[1, 9754] loss_train: 0.005630, loss_test: 0.005689
time: 0.2450559139251709
time: 2.219496726989746
[1, 9755] loss_train: 0.006942, loss_test: 0.005702
time: 0.2430591583251953
time: 2.2305171489715576
[1, 9756] loss_train: 0.004958, loss_test: 0.005714
time: 0.24405455589294434
time: 2.219496250152588
[1, 9757] loss_train: 0.008550, loss_test: 0.005712
time: 0.24305319786071777
time: 2.206493616104126
[1, 9758] loss_train: 0.001110, loss_test: 0.005714
time: 0.24408435821533203
time: 2.2164950370788574
[1, 9759] loss_train: 0.005854, loss_test: 0.005698
time: 0.2470993995666504
time: 2.230499505996704
[1, 9760] loss_train: 0.002912, loss_test: 0.005682
time: 0.2580573558807373
time: 2.23449969291687
[1, 9761] loss_train: 0.008360, loss_test: 0.005663
time: 0.2490551471710205
time: 2.209496021270752
[1, 9762] loss_train: 0.006696, loss_test: 0.005651
time: 0.24405455589294434
time: 2.2265000343322754
[1, 9763] loss_train: 0.005519, loss_test: 0.005644
time: 0.2470550537109375
time: 2.222496747970581
[1, 9764] loss_train: 0.001318, loss_test: 0.005644
time: 0.24305438995361328
time: 2.2415101528167725
[1, 9765] loss_train: 0.006573, loss_test: 0.005647
time: 0.24205327033996582
time: 2.215496301651001
[1, 9766] loss_train: 0.004216, loss_test: 0.005652
time: 0.24405336380004883
time: 2.229499101638794
[1, 9767] loss_train: 0.002799, loss_test: 0.005656
time: 0.24405431747436523
time: 2.2395007610321045
[1, 9768] loss_train: 0.008921, loss_test: 0.005659
time: 0.24306941032409668
time: 2.2254958152770996
[1, 9769] loss_train: 0.008986, loss_test: 0.005660
time: 0.24405479431152344
time: 2.2284982204437256
[1, 9770] loss_train: 0.002452, loss_test: 0.005662
time: 0.25505685806274414
time: 2.26951003074646
[1, 9771] loss_train: 0.005180, loss_test: 0.005662
time: 0.24405455589294434
time: 2.224496603012085
[1, 9772] loss_train: 0.002000, loss_test: 0.005662
time: 0.24405455589294434
time: 2.228524684906006
[1, 9773] loss_train: 0.014579, loss_test: 0.005660
time: 0.24305295944213867
time: 2.2300047874450684
[1, 9774] loss_train: 0.005642, loss_test: 0.005660
time: 0.24405407905578613
time: 2.2224972248077393
[1, 9775] loss_train: 0.004210, loss_test: 0.005662
time: 0.24405407905578613
time: 2.2244982719421387
[1, 9776] loss_train: 0.002229, loss_test: 0.005666
time: 0.24405336380004883
time: 2.206496000289917
[1, 9777] loss_train: 0.007800, loss_test: 0.005671
time: 0.2470550537109375
time: 2.2264983654022217
[1, 9778] loss_train: 0.002733, loss_test: 0.005685
time: 0.2490549087524414
time: 2.2500245571136475
[1, 9779] loss_train: 0.004366, loss_test: 0.005704
time: 0.24405431747436523
time: 2.2685492038726807
[1, 9780] loss_train: 0.006817, loss_test: 0.005713
time: 0.26006269454956055
time: 2.2285006046295166
[1, 9781] loss_train: 0.006200, loss_test: 0.005713
time: 0.24405479431152344
time: 2.2415006160736084
[1, 9782] loss_train: 0.001494, loss_test: 0.005718
time: 0.25005602836608887
time: 2.2294981479644775
[1, 9783] loss_train: 0.005495, loss_test: 0.005707
time: 0.24605536460876465
time: 2.202136516571045
[1, 9784] loss_train: 0.009583, loss_test: 0.005689
time: 0.24805474281311035
time: 2.19250750541687
[1, 9785] loss_train: 0.010379, loss_test: 0.005667
time: 0.24305438995361328
time: 2.21049427986145
[1, 9786] loss_train: 0.007491, loss_test: 0.005646
time: 0.24408268928527832
time: 2.2440292835235596
[1, 9787] loss_train: 0.000524, loss_test: 0.005638
time: 0.2470548152923584
time: 2.216495990753174
[1, 9788] loss_train: 0.002125, loss_test: 0.005638
time: 0.24405360221862793
time: 2.2430529594421387
[1, 9789] loss_train: 0.010046, loss_test: 0.005644
time: 0.24505352973937988
time: 2.218780040740967
[1, 9790] loss_train: 0.004178, loss_test: 0.005649
time: 0.25505709648132324
time: 2.250502824783325
[1, 9791] loss_train: 0.007601, loss_test: 0.005657
time: 0.2450549602508545
time: 2.26950740814209
[1, 9792] loss_train: 0.001496, loss_test: 0.005660
time: 0.24405431747436523
time: 2.2535037994384766
[1, 9793] loss_train: 0.004293, loss_test: 0.005658
time: 0.24405360221862793
time: 2.269510507583618
[1, 9794] loss_train: 0.006867, loss_test: 0.005652
time: 0.2450544834136963
time: 2.2284998893737793
[1, 9795] loss_train: 0.005553, loss_test: 0.005642
time: 0.24306702613830566
time: 2.192490339279175
[1, 9796] loss_train: 0.006341, loss_test: 0.005635
time: 0.24405407905578613
time: 2.221515655517578
[1, 9797] loss_train: 0.003667, loss_test: 0.005635
time: 0.24805521965026855
time: 2.2094948291778564
[1, 9798] loss_train: 0.008167, loss_test: 0.005641
time: 0.24405455589294434
time: 2.1944901943206787
[1, 9799] loss_train: 0.010030, loss_test: 0.005651
time: 0.2450547218322754
time: 2.206502914428711
[1, 9800] loss_train: 0.007903, loss_test: 0.005662
time: 0.25705599784851074
time: 2.2365145683288574
[1, 9801] loss_train: 0.004925, loss_test: 0.005679
time: 0.255068302154541
time: 2.2054941654205322
[1, 9802] loss_train: 0.004675, loss_test: 0.005694
time: 0.24605488777160645
time: 2.2410056591033936
[1, 9803] loss_train: 0.007537, loss_test: 0.005698
time: 0.24805521965026855
time: 2.2244975566864014
[1, 9804] loss_train: 0.006566, loss_test: 0.005695
time: 0.24805474281311035
time: 2.241506576538086
[1, 9805] loss_train: 0.004126, loss_test: 0.005695
time: 0.24605417251586914
time: 2.2385010719299316
[1, 9806] loss_train: 0.001794, loss_test: 0.005696
time: 0.24405455589294434
time: 2.2300162315368652
[1, 9807] loss_train: 0.002954, loss_test: 0.005696
time: 0.24805426597595215
time: 2.2375011444091797
[1, 9808] loss_train: 0.005069, loss_test: 0.005693
time: 0.24305319786071777
time: 2.190490484237671
[1, 9809] loss_train: 0.003283, loss_test: 0.005691
time: 0.24405384063720703
time: 2.1964917182922363
[1, 9810] loss_train: 0.002043, loss_test: 0.005691
time: 0.256056547164917
time: 2.2605061531066895
[1, 9811] loss_train: 0.005695, loss_test: 0.005690
time: 0.2490549087524414
time: 2.1994946002960205
[1, 9812] loss_train: 0.007682, loss_test: 0.005682
time: 0.2450549602508545
time: 2.2254974842071533
[1, 9813] loss_train: 0.005012, loss_test: 0.005675
time: 0.24405479431152344
time: 2.250502824783325
[1, 9814] loss_train: 0.001277, loss_test: 0.005670
time: 0.24505400657653809
time: 2.2094948291778564
[1, 9815] loss_train: 0.003880, loss_test: 0.005666
time: 0.24505376815795898
time: 2.228515863418579
[1, 9816] loss_train: 0.005292, loss_test: 0.005662
time: 0.2450547218322754
time: 2.222496747970581
[1, 9817] loss_train: 0.006481, loss_test: 0.005659
time: 0.24405384063720703
time: 2.234499931335449
[1, 9818] loss_train: 0.005055, loss_test: 0.005652
time: 0.2490556240081787
time: 2.240499973297119
[1, 9819] loss_train: 0.007967, loss_test: 0.005646
time: 0.24506640434265137
time: 2.1981420516967773
[1, 9820] loss_train: 0.006318, loss_test: 0.005645
time: 0.26007771492004395
time: 2.268507242202759
[1, 9821] loss_train: 0.011023, loss_test: 0.005650
time: 0.24605393409729004
time: 2.208502769470215
[1, 9822] loss_train: 0.001983, loss_test: 0.005652
time: 0.25005507469177246
time: 2.200995922088623
[1, 9823] loss_train: 0.010240, loss_test: 0.005656
time: 0.24355745315551758
time: 2.18949031829834
[1, 9824] loss_train: 0.004356, loss_test: 0.005655
time: 0.24605417251586914
time: 2.2335002422332764
[1, 9825] loss_train: 0.006348, loss_test: 0.005646
time: 0.24305343627929688
time: 2.2475223541259766
[1, 9826] loss_train: 0.002115, loss_test: 0.005635
time: 0.24305391311645508
time: 2.217348098754883
[1, 9827] loss_train: 0.002717, loss_test: 0.005630
time: 0.24505877494812012
time: 2.21049427986145
[1, 9828] loss_train: 0.006245, loss_test: 0.005632
time: 0.2450551986694336
time: 2.2084929943084717
[1, 9829] loss_train: 0.002886, loss_test: 0.005640
time: 0.2440800666809082
time: 2.219512939453125
[1, 9830] loss_train: 0.004462, loss_test: 0.005652
time: 0.25507354736328125
time: 2.230499029159546
[1, 9831] loss_train: 0.006631, loss_test: 0.005661
time: 0.24505376815795898
time: 2.234499454498291
[1, 9832] loss_train: 0.009446, loss_test: 0.005669
time: 0.24500608444213867
time: 2.2074942588806152
[1, 9833] loss_train: 0.007151, loss_test: 0.005674
time: 0.24505400657653809
time: 2.1964914798736572
[1, 9834] loss_train: 0.004150, loss_test: 0.005679
time: 0.2450542449951172
time: 2.2094967365264893
[1, 9835] loss_train: 0.004347, loss_test: 0.005682
time: 0.24805545806884766
time: 2.2254974842071533
[1, 9836] loss_train: 0.005927, loss_test: 0.005679
time: 0.2450544834136963
time: 2.2375004291534424
[1, 9837] loss_train: 0.006758, loss_test: 0.005675
time: 0.24605417251586914
time: 2.2520339488983154
[1, 9838] loss_train: 0.014027, loss_test: 0.005670
time: 0.25005578994750977
time: 2.240013599395752
[1, 9839] loss_train: 0.018729, loss_test: 0.005656
time: 0.2450551986694336
time: 2.245501756668091
[1, 9840] loss_train: 0.005987, loss_test: 0.005646
time: 0.25505614280700684
time: 2.2515039443969727
[1, 9841] loss_train: 0.002934, loss_test: 0.005641
time: 0.24805521965026855
time: 2.2264981269836426
[1, 9842] loss_train: 0.011760, loss_test: 0.005642
time: 0.24405455589294434
time: 2.23949933052063
[1, 9843] loss_train: 0.003566, loss_test: 0.005657
time: 0.24305438995361328
time: 2.216496229171753
[1, 9844] loss_train: 0.003182, loss_test: 0.005678
time: 0.24406886100769043
time: 2.2064929008483887
[1, 9845] loss_train: 0.000885, loss_test: 0.005687
time: 0.2450549602508545
time: 2.2144968509674072
[1, 9846] loss_train: 0.007361, loss_test: 0.005690
time: 0.24406647682189941
time: 2.22149658203125
[1, 9847] loss_train: 0.008063, loss_test: 0.005685
time: 0.24505376815795898
time: 2.220499277114868
[1, 9848] loss_train: 0.003072, loss_test: 0.005669
time: 0.24505376815795898
time: 2.242501735687256
[1, 9849] loss_train: 0.005802, loss_test: 0.005648
time: 0.24305391311645508
time: 2.217517614364624
[1, 9850] loss_train: 0.009684, loss_test: 0.005631
time: 0.25505709648132324
time: 2.2435014247894287
[1, 9851] loss_train: 0.000967, loss_test: 0.005626
time: 0.24405360221862793
time: 2.244523048400879
[1, 9852] loss_train: 0.004837, loss_test: 0.005631
time: 0.24305462837219238
time: 2.2415010929107666
[1, 9853] loss_train: 0.009402, loss_test: 0.005636
time: 0.24305438995361328
time: 2.2315008640289307
[1, 9854] loss_train: 0.001840, loss_test: 0.005644
time: 0.24606800079345703
time: 2.2234976291656494
[1, 9855] loss_train: 0.004109, loss_test: 0.005655
time: 0.24605417251586914
time: 2.235499858856201
[1, 9856] loss_train: 0.010372, loss_test: 0.005659
time: 0.24805450439453125
time: 2.1964919567108154
[1, 9857] loss_train: 0.006014, loss_test: 0.005663
time: 0.24505376815795898
time: 2.2230074405670166
[1, 9858] loss_train: 0.004282, loss_test: 0.005665
time: 0.24605417251586914
time: 2.2014927864074707
[1, 9859] loss_train: 0.006106, loss_test: 0.005664
time: 0.24405455589294434
time: 2.2060019969940186
[1, 9860] loss_train: 0.007070, loss_test: 0.005666
time: 0.25505614280700684
time: 2.2545042037963867
[1, 9861] loss_train: 0.006055, loss_test: 0.005664
time: 0.24405360221862793
time: 2.2254981994628906
[1, 9862] loss_train: 0.009552, loss_test: 0.005653
time: 0.24506855010986328
time: 2.2375004291534424
[1, 9863] loss_train: 0.002614, loss_test: 0.005646
time: 0.24305343627929688
time: 2.216495990753174
[1, 9864] loss_train: 0.001483, loss_test: 0.005641
time: 0.24434542655944824
time: 2.2234978675842285
[1, 9865] loss_train: 0.002555, loss_test: 0.005636
time: 0.24405431747436523
time: 2.21651291847229
[1, 9866] loss_train: 0.025436, loss_test: 0.005630
time: 0.24405503273010254
time: 2.2284977436065674
[1, 9867] loss_train: 0.010938, loss_test: 0.005626
time: 0.24305462837219238
time: 2.247502326965332
[1, 9868] loss_train: 0.000755, loss_test: 0.005623
time: 0.24505376815795898
time: 2.2264978885650635
[1, 9869] loss_train: 0.009160, loss_test: 0.005626
time: 0.24406790733337402
time: 2.2165067195892334
[1, 9870] loss_train: 0.008083, loss_test: 0.005631
time: 0.25505614280700684
time: 2.2610087394714355
[1, 9871] loss_train: 0.012190, loss_test: 0.005639
time: 0.24305367469787598
time: 2.2505033016204834
[1, 9872] loss_train: 0.004484, loss_test: 0.005648
time: 0.2470555305480957
time: 2.232499361038208
[1, 9873] loss_train: 0.007919, loss_test: 0.005653
time: 0.24405431747436523
time: 2.228501558303833
[1, 9874] loss_train: 0.012956, loss_test: 0.005652
time: 0.24405431747436523
time: 2.255504608154297
[1, 9875] loss_train: 0.003391, loss_test: 0.005650
time: 0.24605488777160645
time: 2.2480111122131348
[1, 9876] loss_train: 0.009689, loss_test: 0.005644
time: 0.24405479431152344
time: 2.2385001182556152
[1, 9877] loss_train: 0.004650, loss_test: 0.005638
time: 0.2490553855895996
time: 2.243018388748169
[1, 9878] loss_train: 0.006629, loss_test: 0.005632
time: 0.2580568790435791
time: 2.230499267578125
[1, 9879] loss_train: 0.007292, loss_test: 0.005630
time: 0.24805545806884766
time: 2.221496343612671
[1, 9880] loss_train: 0.012775, loss_test: 0.005630
time: 0.25707459449768066
time: 2.2154951095581055
[1, 9881] loss_train: 0.008410, loss_test: 0.005632
time: 0.24918699264526367
time: 2.218496084213257
[1, 9882] loss_train: 0.001895, loss_test: 0.005632
time: 0.2490556240081787
time: 2.231501340866089
[1, 9883] loss_train: 0.000674, loss_test: 0.005635
time: 0.24506711959838867
time: 2.193493604660034
[1, 9884] loss_train: 0.005412, loss_test: 0.005636
time: 0.24406671524047852
time: 2.2515039443969727
[1, 9885] loss_train: 0.005742, loss_test: 0.005639
time: 0.24405360221862793
time: 2.202493190765381
[1, 9886] loss_train: 0.008380, loss_test: 0.005642
time: 0.2450549602508545
time: 2.226010322570801
[1, 9887] loss_train: 0.003394, loss_test: 0.005644
time: 0.2450542449951172
time: 2.218496799468994
[1, 9888] loss_train: 0.009740, loss_test: 0.005644
time: 0.24312067031860352
time: 2.243525266647339
[1, 9889] loss_train: 0.008285, loss_test: 0.005639
time: 0.2450547218322754
time: 2.224514961242676
[1, 9890] loss_train: 0.002359, loss_test: 0.005637
time: 0.256056547164917
time: 2.2635068893432617
[1, 9891] loss_train: 0.002845, loss_test: 0.005634
time: 0.24405360221862793
time: 2.2114951610565186
[1, 9892] loss_train: 0.004154, loss_test: 0.005631
time: 0.24507904052734375
time: 2.202493190765381
[1, 9893] loss_train: 0.005728, loss_test: 0.005628
time: 0.24405431747436523
time: 2.2144980430603027
[1, 9894] loss_train: 0.005856, loss_test: 0.005635
time: 0.24606657028198242
time: 2.192490577697754
[1, 9895] loss_train: 0.007516, loss_test: 0.005647
time: 0.24605417251586914
time: 2.206494092941284
[1, 9896] loss_train: 0.001548, loss_test: 0.005655
time: 0.2490549087524414
time: 2.2195162773132324
[1, 9897] loss_train: 0.004712, loss_test: 0.005656
time: 0.24406719207763672
time: 2.2224977016448975
[1, 9898] loss_train: 0.009102, loss_test: 0.005657
time: 0.24405384063720703
time: 2.2350192070007324
[1, 9899] loss_train: 0.004290, loss_test: 0.005658
time: 0.24605417251586914
time: 2.2114951610565186
[1, 9900] loss_train: 0.004543, loss_test: 0.005657
time: 0.25505638122558594
time: 2.2680602073669434
[1, 9901] loss_train: 0.006857, loss_test: 0.005657
time: 0.2470560073852539
time: 2.2525031566619873
[1, 9902] loss_train: 0.004537, loss_test: 0.005657
time: 0.2450547218322754
time: 2.233499526977539
[1, 9903] loss_train: 0.003062, loss_test: 0.005656
time: 0.24305438995361328
time: 2.2445015907287598
[1, 9904] loss_train: 0.002510, loss_test: 0.005661
time: 0.24305438995361328
time: 2.226499319076538
[1, 9905] loss_train: 0.001369, loss_test: 0.005671
time: 0.24405384063720703
time: 2.215496063232422
[1, 9906] loss_train: 0.005013, loss_test: 0.005692
time: 0.24606728553771973
time: 2.1989963054656982
[1, 9907] loss_train: 0.003779, loss_test: 0.005719
time: 0.24406743049621582
time: 2.219496726989746
[1, 9908] loss_train: 0.002188, loss_test: 0.005750
time: 0.24505400657653809
time: 2.1954915523529053
[1, 9909] loss_train: 0.012179, loss_test: 0.005749
time: 0.2470545768737793
time: 2.180487632751465
[1, 9910] loss_train: 0.007396, loss_test: 0.005743
time: 0.25905776023864746
time: 2.244502305984497
[1, 9911] loss_train: 0.015134, loss_test: 0.005715
time: 0.2510559558868408
time: 2.2094945907592773
[1, 9912] loss_train: 0.014101, loss_test: 0.005679
time: 0.24405431747436523
time: 2.2365000247955322
[1, 9913] loss_train: 0.013290, loss_test: 0.005662
time: 0.25005483627319336
time: 2.2194972038269043
[1, 9914] loss_train: 0.002294, loss_test: 0.005667
time: 0.24605464935302734
time: 2.2350032329559326
[1, 9915] loss_train: 0.006513, loss_test: 0.005691
time: 0.2470543384552002
time: 2.2545108795166016
[1, 9916] loss_train: 0.006228, loss_test: 0.005726
time: 0.24405384063720703
time: 2.216033458709717
[1, 9917] loss_train: 0.007888, loss_test: 0.005769
time: 0.24605369567871094
time: 2.2184970378875732
[1, 9918] loss_train: 0.005687, loss_test: 0.005796
time: 0.24305415153503418
time: 2.233518123626709
[1, 9919] loss_train: 0.010615, loss_test: 0.005803
time: 0.2450542449951172
time: 2.191490411758423
[1, 9920] loss_train: 0.013958, loss_test: 0.005788
time: 0.256056547164917
time: 2.257276773452759
[1, 9921] loss_train: 0.014166, loss_test: 0.005762
time: 0.24605488777160645
time: 2.240501880645752
[1, 9922] loss_train: 0.004084, loss_test: 0.005728
time: 0.24205398559570312
time: 2.2104947566986084
[1, 9923] loss_train: 0.012327, loss_test: 0.005694
time: 0.2450547218322754
time: 2.211498260498047
[1, 9924] loss_train: 0.009108, loss_test: 0.005675
time: 0.24305248260498047
time: 2.222027540206909
[1, 9925] loss_train: 0.005528, loss_test: 0.005683
time: 0.24406790733337402
time: 2.2274982929229736
[1, 9926] loss_train: 0.004032, loss_test: 0.005708
time: 0.24405360221862793
time: 2.2270219326019287
[1, 9927] loss_train: 0.000945, loss_test: 0.005740
time: 0.24405455589294434
time: 2.2294986248016357
[1, 9928] loss_train: 0.002801, loss_test: 0.005781
time: 0.24505376815795898
time: 2.217020273208618
[1, 9929] loss_train: 0.014812, loss_test: 0.005791
time: 0.24506497383117676
time: 2.2145090103149414
[1, 9930] loss_train: 0.005928, loss_test: 0.005798
time: 0.2630584239959717
time: 2.232499122619629
[1, 9931] loss_train: 0.006623, loss_test: 0.005796
time: 0.24405407905578613
time: 2.2014925479888916
[1, 9932] loss_train: 0.011271, loss_test: 0.005789
time: 0.24805474281311035
time: 2.2224979400634766
[1, 9933] loss_train: 0.025870, loss_test: 0.005765
time: 0.2450542449951172
time: 2.230498790740967
[1, 9934] loss_train: 0.007504, loss_test: 0.005754
time: 0.24305438995361328
time: 2.199995756149292
[1, 9935] loss_train: 0.004922, loss_test: 0.005751
time: 0.2450544834136963
time: 2.2405006885528564
[1, 9936] loss_train: 0.004770, loss_test: 0.005758
time: 0.24405384063720703
time: 2.222015142440796
[1, 9937] loss_train: 0.006041, loss_test: 0.005767
time: 0.24805545806884766
time: 2.2099971771240234
[1, 9938] loss_train: 0.009587, loss_test: 0.005768
time: 0.24405503273010254
time: 2.218496084213257
[1, 9939] loss_train: 0.006176, loss_test: 0.005773
time: 0.24405407905578613
time: 2.2285163402557373
[1, 9940] loss_train: 0.009197, loss_test: 0.005776
time: 0.25705790519714355
time: 2.2320382595062256
[1, 9941] loss_train: 0.005797, loss_test: 0.005787
time: 0.2450547218322754
time: 2.2114944458007812
[1, 9942] loss_train: 0.010044, loss_test: 0.005786
time: 0.24406814575195312
time: 2.2264983654022217
[1, 9943] loss_train: 0.000857, loss_test: 0.005788
time: 0.24405407905578613
time: 2.215498208999634
[1, 9944] loss_train: 0.008978, loss_test: 0.005777
time: 0.2520558834075928
time: 2.218496561050415
[1, 9945] loss_train: 0.007937, loss_test: 0.005752
time: 0.25006794929504395
time: 2.228518009185791
[1, 9946] loss_train: 0.013938, loss_test: 0.005708
time: 0.24606657028198242
time: 2.2390170097351074
[1, 9947] loss_train: 0.007196, loss_test: 0.005671
time: 0.24805545806884766
time: 2.2515108585357666
[1, 9948] loss_train: 0.003487, loss_test: 0.005655
time: 0.24605417251586914
time: 2.2124950885772705
[1, 9949] loss_train: 0.001946, loss_test: 0.005654
time: 0.24805474281311035
time: 2.205493450164795
[1, 9950] loss_train: 0.002314, loss_test: 0.005669
time: 0.25505661964416504
time: 2.2257027626037598
[1, 9951] loss_train: 0.007640, loss_test: 0.005689
time: 0.24305343627929688
time: 2.2244982719421387
[1, 9952] loss_train: 0.009662, loss_test: 0.005706
time: 0.24505305290222168
time: 2.196027994155884
[1, 9953] loss_train: 0.002589, loss_test: 0.005721
time: 0.24405360221862793
time: 2.2234973907470703
[1, 9954] loss_train: 0.007396, loss_test: 0.005727
time: 0.24605917930603027
time: 2.216496467590332
[1, 9955] loss_train: 0.008592, loss_test: 0.005721
time: 0.24505352973937988
time: 2.2080087661743164
[1, 9956] loss_train: 0.014582, loss_test: 0.005693
time: 0.24305367469787598
time: 2.2176358699798584
[1, 9957] loss_train: 0.007017, loss_test: 0.005677
time: 0.24305343627929688
time: 2.2220330238342285
[1, 9958] loss_train: 0.006128, loss_test: 0.005676
time: 0.24507975578308105
time: 2.22249698638916
[1, 9959] loss_train: 0.005988, loss_test: 0.005688
time: 0.24505329132080078
time: 2.1905081272125244
[1, 9960] loss_train: 0.005077, loss_test: 0.005711
time: 0.26105737686157227
time: 2.26051664352417
[1, 9961] loss_train: 0.014810, loss_test: 0.005741
time: 0.24806857109069824
time: 2.212494134902954
[1, 9962] loss_train: 0.002928, loss_test: 0.005754
time: 0.24805498123168945
time: 2.2565066814422607
[1, 9963] loss_train: 0.009291, loss_test: 0.005759
time: 0.24406790733337402
time: 2.207493782043457
[1, 9964] loss_train: 0.001752, loss_test: 0.005768
time: 0.24805474281311035
time: 2.222496747970581
[1, 9965] loss_train: 0.010700, loss_test: 0.005732
time: 0.2450547218322754
time: 2.261523723602295
[1, 9966] loss_train: 0.002188, loss_test: 0.005707
time: 0.2470548152923584
time: 2.1975085735321045
[1, 9967] loss_train: 0.013931, loss_test: 0.005692
time: 0.24305462837219238
time: 2.237502336502075
[1, 9968] loss_train: 0.003835, loss_test: 0.005679
time: 0.24405407905578613
time: 2.2214972972869873
[1, 9969] loss_train: 0.003097, loss_test: 0.005663
time: 0.24305295944213867
time: 2.206542730331421
[1, 9970] loss_train: 0.003933, loss_test: 0.005654
time: 0.25705695152282715
time: 2.2635064125061035
[1, 9971] loss_train: 0.003931, loss_test: 0.005648
time: 0.24405479431152344
time: 2.221496343612671
[1, 9972] loss_train: 0.004839, loss_test: 0.005643
time: 0.24405479431152344
time: 2.224497079849243
[1, 9973] loss_train: 0.011381, loss_test: 0.005641
time: 0.24405455589294434
time: 2.2284982204437256
[1, 9974] loss_train: 0.005351, loss_test: 0.005643
time: 0.24606704711914062
time: 2.2254981994628906
[1, 9975] loss_train: 0.009300, loss_test: 0.005644
time: 0.24405407905578613
time: 2.2315070629119873
[1, 9976] loss_train: 0.006850, loss_test: 0.005647
time: 0.24505376815795898
time: 2.2144956588745117
[1, 9977] loss_train: 0.002497, loss_test: 0.005652
time: 0.24405384063720703
time: 2.1970107555389404
[1, 9978] loss_train: 0.010844, loss_test: 0.005658
time: 0.2450549602508545
time: 2.21049427986145
[1, 9979] loss_train: 0.002035, loss_test: 0.005665
time: 0.25005507469177246
time: 2.220334768295288
[1, 9980] loss_train: 0.008187, loss_test: 0.005670
time: 0.2560563087463379
time: 2.2345006465911865
[1, 9981] loss_train: 0.005983, loss_test: 0.005674
time: 0.2510690689086914
time: 2.2074947357177734
[1, 9982] loss_train: 0.004865, loss_test: 0.005678
time: 0.24505376815795898
time: 2.219496488571167
[1, 9983] loss_train: 0.011328, loss_test: 0.005681
time: 0.24305343627929688
time: 2.240220785140991
[1, 9984] loss_train: 0.004658, loss_test: 0.005681
time: 0.2450544834136963
time: 2.2044930458068848
[1, 9985] loss_train: 0.008118, loss_test: 0.005679
time: 0.2450544834136963
time: 2.2185187339782715
[1, 9986] loss_train: 0.007963, loss_test: 0.005673
time: 0.24305343627929688
time: 2.2265002727508545
[1, 9987] loss_train: 0.003197, loss_test: 0.005668
time: 0.24605488777160645
time: 2.2485029697418213
[1, 9988] loss_train: 0.007734, loss_test: 0.005664
time: 0.24405431747436523
time: 2.2024927139282227
[1, 9989] loss_train: 0.003165, loss_test: 0.005660
time: 0.2450547218322754
time: 2.24528431892395
[1, 9990] loss_train: 0.004014, loss_test: 0.005659
time: 0.2560608386993408
time: 2.269507884979248
[1, 9991] loss_train: 0.000868, loss_test: 0.005659
time: 0.24305415153503418
time: 2.2064931392669678
[1, 9992] loss_train: 0.008855, loss_test: 0.005659
time: 0.24706649780273438
time: 2.2004926204681396
[1, 9993] loss_train: 0.003193, loss_test: 0.005660
time: 0.24507856369018555
time: 2.205493450164795
[1, 9994] loss_train: 0.003685, loss_test: 0.005661
time: 0.24305391311645508
time: 2.216498613357544
[1, 9995] loss_train: 0.011210, loss_test: 0.005656
time: 0.2450547218322754
time: 2.1994917392730713
[1, 9996] loss_train: 0.014234, loss_test: 0.005653
time: 0.25110459327697754
time: 2.206998586654663
[1, 9997] loss_train: 0.004291, loss_test: 0.005651
time: 0.2510554790496826
time: 2.2465028762817383
[1, 9998] loss_train: 0.012674, loss_test: 0.005648
time: 0.24805545806884766
time: 2.2294983863830566
[1, 9999] loss_train: 0.004081, loss_test: 0.005647
time: 0.2470555305480957
time: 2.2244973182678223
[1, 10000] loss_train: 0.001086, loss_test: 0.005649
time: 0.25505590438842773
time: 2.2605056762695312
[1, 10001] loss_train: 0.002894, loss_test: 0.005653
time: 0.24405431747436523
time: 2.245502233505249
[1, 10002] loss_train: 0.003605, loss_test: 0.005657
time: 0.2450568675994873
time: 2.219496726989746
[1, 10003] loss_train: 0.004527, loss_test: 0.005659
time: 0.24305438995361328
time: 2.222496747970581
[1, 10004] loss_train: 0.016598, loss_test: 0.005645
time: 0.24405407905578613
time: 2.1864912509918213
[1, 10005] loss_train: 0.001608, loss_test: 0.005635
time: 0.24506831169128418
time: 2.191490888595581
[1, 10006] loss_train: 0.001624, loss_test: 0.005631
time: 0.24305367469787598
time: 2.231499433517456
[1, 10007] loss_train: 0.014394, loss_test: 0.005626
time: 0.24405455589294434
time: 2.2004919052124023
[1, 10008] loss_train: 0.006668, loss_test: 0.005624
time: 0.24505400657653809
time: 2.2084970474243164
[1, 10009] loss_train: 0.003571, loss_test: 0.005624
time: 0.24505376815795898
time: 2.208505153656006
[1, 10010] loss_train: 0.001301, loss_test: 0.005626
time: 0.25705766677856445
time: 2.2675068378448486
[1, 10011] loss_train: 0.002481, loss_test: 0.005632
time: 0.252056360244751
time: 2.222496747970581
[1, 10012] loss_train: 0.008758, loss_test: 0.005635
time: 0.24506592750549316
time: 2.2475030422210693
[1, 10013] loss_train: 0.005086, loss_test: 0.005639
time: 0.2490556240081787
time: 2.1984915733337402
[1, 10014] loss_train: 0.007858, loss_test: 0.005644
time: 0.24405407905578613
time: 2.219496726989746
[1, 10015] loss_train: 0.012520, loss_test: 0.005648
time: 0.24605417251586914
time: 2.2114951610565186
[1, 10016] loss_train: 0.010633, loss_test: 0.005646
time: 0.24805521965026855
time: 2.2120110988616943
[1, 10017] loss_train: 0.006885, loss_test: 0.005639
time: 0.24405431747436523
time: 2.2004919052124023
[1, 10018] loss_train: 0.002605, loss_test: 0.005637
time: 0.24405407905578613
time: 2.2204971313476562
[1, 10019] loss_train: 0.006188, loss_test: 0.005631
time: 0.24405384063720703
time: 2.231499433517456
[1, 10020] loss_train: 0.003009, loss_test: 0.005630
time: 0.25505614280700684
time: 2.2355005741119385
[1, 10021] loss_train: 0.016892, loss_test: 0.005632
time: 0.24305438995361328
time: 2.232499599456787
[1, 10022] loss_train: 0.008241, loss_test: 0.005646
time: 0.24305415153503418
time: 2.2365000247955322
[1, 10023] loss_train: 0.008740, loss_test: 0.005669
time: 0.2450547218322754
time: 2.2345001697540283
[1, 10024] loss_train: 0.003037, loss_test: 0.005686
time: 0.2450549602508545
time: 2.210496187210083
[1, 10025] loss_train: 0.016753, loss_test: 0.005696
time: 0.24405407905578613
time: 2.1994946002960205
[1, 10026] loss_train: 0.009307, loss_test: 0.005702
time: 0.24605464935302734
time: 2.2265071868896484
[1, 10027] loss_train: 0.006315, loss_test: 0.005702
time: 0.24405527114868164
time: 2.207493543624878
[1, 10028] loss_train: 0.002047, loss_test: 0.005701
time: 0.25005507469177246
time: 2.235525369644165
[1, 10029] loss_train: 0.004995, loss_test: 0.005691
time: 0.24405431747436523
time: 2.2185025215148926
[1, 10030] loss_train: 0.003169, loss_test: 0.005680
time: 0.26105737686157227
time: 2.277510166168213
[1, 10031] loss_train: 0.015085, loss_test: 0.005671
time: 0.24305343627929688
time: 2.2505040168762207
[1, 10032] loss_train: 0.002030, loss_test: 0.005667
time: 0.24805474281311035
time: 2.220496892929077
[1, 10033] loss_train: 0.007291, loss_test: 0.005671
time: 0.24605512619018555
time: 2.2395009994506836
[1, 10034] loss_train: 0.009248, loss_test: 0.005670
time: 0.2470550537109375
time: 2.218010663986206
[1, 10035] loss_train: 0.005467, loss_test: 0.005669
time: 0.24405455589294434
time: 2.245502471923828
[1, 10036] loss_train: 0.006274, loss_test: 0.005669
time: 0.24305486679077148
time: 2.2308192253112793
[1, 10037] loss_train: 0.005499, loss_test: 0.005669
time: 0.24405384063720703
time: 2.232499599456787
[1, 10038] loss_train: 0.001757, loss_test: 0.005670
time: 0.24505400657653809
time: 2.2265164852142334
[1, 10039] loss_train: 0.008725, loss_test: 0.005672
time: 0.24305462837219238
time: 2.2064929008483887
[1, 10040] loss_train: 0.002611, loss_test: 0.005678
time: 0.2580692768096924
time: 2.2855217456817627
[1, 10041] loss_train: 0.006490, loss_test: 0.005681
time: 0.24406647682189941
time: 2.247502088546753
[1, 10042] loss_train: 0.005017, loss_test: 0.005682
time: 0.24305367469787598
time: 2.2295174598693848
[1, 10043] loss_train: 0.006393, loss_test: 0.005682
time: 0.2450547218322754
time: 2.2385027408599854
[1, 10044] loss_train: 0.004608, loss_test: 0.005682
time: 0.2450544834136963
time: 2.2335000038146973
[1, 10045] loss_train: 0.003158, loss_test: 0.005683
time: 0.24305438995361328
time: 2.2314984798431396
[1, 10046] loss_train: 0.011283, loss_test: 0.005678
time: 0.24405384063720703
time: 2.229499101638794
[1, 10047] loss_train: 0.005162, loss_test: 0.005675
time: 0.24305391311645508
time: 2.1974921226501465
[1, 10048] loss_train: 0.001323, loss_test: 0.005673
time: 0.24417734146118164
time: 2.255504846572876
[1, 10049] loss_train: 0.003723, loss_test: 0.005671
time: 0.24306774139404297
time: 2.21049427986145
[1, 10050] loss_train: 0.000536, loss_test: 0.005668
time: 0.25505733489990234
time: 2.238286256790161
[1, 10051] loss_train: 0.005762, loss_test: 0.005666
time: 0.24605536460876465
time: 2.1944901943206787
[1, 10052] loss_train: 0.005892, loss_test: 0.005665
time: 0.24509549140930176
time: 2.2090132236480713
[1, 10053] loss_train: 0.007553, loss_test: 0.005660
time: 0.25305604934692383
time: 2.2475030422210693
[1, 10054] loss_train: 0.010590, loss_test: 0.005651
time: 0.2450542449951172
time: 2.219496726989746
[1, 10055] loss_train: 0.002837, loss_test: 0.005644
time: 0.24605512619018555
time: 2.244518756866455
[1, 10056] loss_train: 0.007651, loss_test: 0.005638
time: 0.24605464935302734
time: 2.2355000972747803
[1, 10057] loss_train: 0.006072, loss_test: 0.005636
time: 0.24405431747436523
time: 2.244004726409912
[1, 10058] loss_train: 0.008138, loss_test: 0.005633
time: 0.2450547218322754
time: 2.23427677154541
[1, 10059] loss_train: 0.003678, loss_test: 0.005633
time: 0.24405455589294434
time: 2.262517213821411
[1, 10060] loss_train: 0.001898, loss_test: 0.005633
time: 0.2540566921234131
time: 2.257009506225586
[1, 10061] loss_train: 0.006436, loss_test: 0.005635
time: 0.24305415153503418
time: 2.222496509552002
[1, 10062] loss_train: 0.005285, loss_test: 0.005637
time: 0.2450547218322754
time: 2.237499952316284
[1, 10063] loss_train: 0.006514, loss_test: 0.005640
time: 0.2470552921295166
time: 2.225497245788574
[1, 10064] loss_train: 0.005114, loss_test: 0.005641
time: 0.24405479431152344
time: 2.2164957523345947
[1, 10065] loss_train: 0.005243, loss_test: 0.005638
time: 0.24405336380004883
time: 2.233513116836548
[1, 10066] loss_train: 0.008303, loss_test: 0.005635
time: 0.2450547218322754
time: 2.2385005950927734
[1, 10067] loss_train: 0.001951, loss_test: 0.005632
time: 0.24405384063720703
time: 2.232499361038208
[1, 10068] loss_train: 0.000543, loss_test: 0.005631
time: 0.24405407905578613
time: 2.2475030422210693
[1, 10069] loss_train: 0.015302, loss_test: 0.005628
time: 0.24405360221862793
time: 2.250016927719116
[1, 10070] loss_train: 0.004236, loss_test: 0.005629
time: 0.25505685806274414
time: 2.247502565383911
[1, 10071] loss_train: 0.011288, loss_test: 0.005630
time: 0.2450544834136963
time: 2.2375094890594482
[1, 10072] loss_train: 0.010183, loss_test: 0.005630
time: 0.24305438995361328
time: 2.216508626937866
[1, 10073] loss_train: 0.004957, loss_test: 0.005631
time: 0.24506568908691406
time: 2.1825006008148193
[1, 10074] loss_train: 0.001073, loss_test: 0.005631
time: 0.24405384063720703
time: 2.2170019149780273
[1, 10075] loss_train: 0.005664, loss_test: 0.005630
time: 0.24605441093444824
time: 2.208585023880005
[1, 10076] loss_train: 0.004154, loss_test: 0.005628
time: 0.2470545768737793
time: 2.192777395248413
[1, 10077] loss_train: 0.005361, loss_test: 0.005625
time: 0.24306750297546387
time: 2.207493543624878
[1, 10078] loss_train: 0.004791, loss_test: 0.005624
time: 0.24405431747436523
time: 2.2204971313476562
[1, 10079] loss_train: 0.009648, loss_test: 0.005624
time: 0.24305415153503418
time: 2.2405011653900146
[1, 10080] loss_train: 0.001787, loss_test: 0.005625
time: 0.25705695152282715
time: 2.257504940032959
[1, 10081] loss_train: 0.008423, loss_test: 0.005627
time: 0.24305462837219238
time: 2.237502098083496
[1, 10082] loss_train: 0.000486, loss_test: 0.005630
time: 0.24405455589294434
time: 2.2074954509735107
[1, 10083] loss_train: 0.006818, loss_test: 0.005633
time: 0.24405455589294434
time: 2.2184975147247314
[1, 10084] loss_train: 0.006675, loss_test: 0.005634
time: 0.24605464935302734
time: 2.2154958248138428
[1, 10085] loss_train: 0.000384, loss_test: 0.005637
time: 0.24205327033996582
time: 2.2130072116851807
[1, 10086] loss_train: 0.006457, loss_test: 0.005639
time: 0.24305415153503418
time: 2.230498790740967
[1, 10087] loss_train: 0.011349, loss_test: 0.005638
time: 0.24605417251586914
time: 2.2030093669891357
[1, 10088] loss_train: 0.008919, loss_test: 0.005640
time: 0.24305486679077148
time: 2.2284979820251465
[1, 10089] loss_train: 0.003947, loss_test: 0.005648
time: 0.2470555305480957
time: 2.242521047592163
[1, 10090] loss_train: 0.003748, loss_test: 0.005658
time: 0.2580580711364746
time: 2.2695069313049316
[1, 10091] loss_train: 0.006849, loss_test: 0.005670
time: 0.24805545806884766
time: 2.2315008640289307
[1, 10092] loss_train: 0.013639, loss_test: 0.005683
time: 0.24405360221862793
time: 2.239501476287842
[1, 10093] loss_train: 0.003556, loss_test: 0.005683
time: 0.2490556240081787
time: 2.2164957523345947
[1, 10094] loss_train: 0.007982, loss_test: 0.005682
time: 0.24506711959838867
time: 2.221472978591919
[1, 10095] loss_train: 0.012284, loss_test: 0.005676
time: 0.2470548152923584
time: 2.2515037059783936
[1, 10096] loss_train: 0.004286, loss_test: 0.005664
time: 0.24505376815795898
time: 2.230498790740967
[1, 10097] loss_train: 0.001660, loss_test: 0.005658
time: 0.25005507469177246
time: 2.2450077533721924
[1, 10098] loss_train: 0.003564, loss_test: 0.005653
time: 0.24405360221862793
time: 2.228498935699463
[1, 10099] loss_train: 0.003760, loss_test: 0.005648
time: 0.2450542449951172
time: 2.2215073108673096
[1, 10100] loss_train: 0.005257, loss_test: 0.005648
time: 0.25644683837890625
time: 2.243502140045166
[1, 10101] loss_train: 0.006973, loss_test: 0.005646
time: 0.24405384063720703
time: 2.2074942588806152
[1, 10102] loss_train: 0.006404, loss_test: 0.005646
time: 0.24605417251586914
time: 2.2144978046417236
[1, 10103] loss_train: 0.004861, loss_test: 0.005645
time: 0.24308037757873535
time: 2.2264983654022217
[1, 10104] loss_train: 0.008136, loss_test: 0.005645
time: 0.24306750297546387
time: 2.2244977951049805
[1, 10105] loss_train: 0.003621, loss_test: 0.005645
time: 0.24405431747436523
time: 2.2445077896118164
[1, 10106] loss_train: 0.003216, loss_test: 0.005647
time: 0.24305367469787598
time: 2.2004926204681396
[1, 10107] loss_train: 0.001808, loss_test: 0.005652
time: 0.24305319786071777
time: 2.239006519317627
[1, 10108] loss_train: 0.017364, loss_test: 0.005650
time: 0.2450542449951172
time: 2.2184958457946777
[1, 10109] loss_train: 0.010067, loss_test: 0.005645
time: 0.24405479431152344
time: 2.2314703464508057
[1, 10110] loss_train: 0.010628, loss_test: 0.005639
time: 0.2560689449310303
time: 2.244502067565918
[1, 10111] loss_train: 0.006424, loss_test: 0.005633
time: 0.24506640434265137
time: 2.2395009994506836
[1, 10112] loss_train: 0.009936, loss_test: 0.005634
time: 0.24405336380004883
time: 2.2375009059906006
[1, 10113] loss_train: 0.002933, loss_test: 0.005639
time: 0.24405384063720703
time: 2.192490339279175
[1, 10114] loss_train: 0.001802, loss_test: 0.005646
time: 0.25206947326660156
time: 2.2144947052001953
[1, 10115] loss_train: 0.004375, loss_test: 0.005651
time: 0.24457597732543945
time: 2.231499671936035
[1, 10116] loss_train: 0.005528, loss_test: 0.005652
time: 0.24606752395629883
time: 2.241501808166504
[1, 10117] loss_train: 0.006981, loss_test: 0.005655
time: 0.24405431747436523
time: 2.2461278438568115
[1, 10118] loss_train: 0.004057, loss_test: 0.005651
time: 0.2450547218322754
time: 2.244501829147339
[1, 10119] loss_train: 0.007944, loss_test: 0.005653
time: 0.2440640926361084
time: 2.2240235805511475
[1, 10120] loss_train: 0.005366, loss_test: 0.005652
time: 0.25505590438842773
time: 2.267507553100586
[1, 10121] loss_train: 0.001302, loss_test: 0.005653
time: 0.24405646324157715
time: 2.2244973182678223
[1, 10122] loss_train: 0.013803, loss_test: 0.005652
time: 0.24605655670166016
time: 2.2244973182678223
[1, 10123] loss_train: 0.006638, loss_test: 0.005650
time: 0.24405360221862793
time: 2.237502098083496
[1, 10124] loss_train: 0.007998, loss_test: 0.005647
time: 0.24605464935302734
time: 2.21677565574646
[1, 10125] loss_train: 0.002380, loss_test: 0.005647
time: 0.2450547218322754
time: 2.2395005226135254
[1, 10126] loss_train: 0.010352, loss_test: 0.005646
time: 0.2450549602508545
time: 2.2315196990966797
[1, 10127] loss_train: 0.003656, loss_test: 0.005648
time: 0.2470555305480957
time: 2.230499029159546
[1, 10128] loss_train: 0.004871, loss_test: 0.005646
time: 0.24405431747436523
time: 2.230499744415283
[1, 10129] loss_train: 0.011485, loss_test: 0.005646
time: 0.24307703971862793
time: 2.2345001697540283
[1, 10130] loss_train: 0.011555, loss_test: 0.005640
time: 0.2560563087463379
time: 2.267507791519165
[1, 10131] loss_train: 0.003802, loss_test: 0.005636
time: 0.24405336380004883
time: 2.219496965408325
[1, 10132] loss_train: 0.000813, loss_test: 0.005636
time: 0.24405407905578613
time: 2.24650239944458
[1, 10133] loss_train: 0.015305, loss_test: 0.005635
time: 0.2450542449951172
time: 2.2385008335113525
[1, 10134] loss_train: 0.003582, loss_test: 0.005635
time: 0.24105286598205566
time: 2.218496799468994
[1, 10135] loss_train: 0.006472, loss_test: 0.005637
time: 0.24405384063720703
time: 2.224619150161743
[1, 10136] loss_train: 0.000946, loss_test: 0.005639
time: 0.24405407905578613
time: 2.2104949951171875
[1, 10137] loss_train: 0.009343, loss_test: 0.005639
time: 0.25005507469177246
time: 2.1904900074005127
[1, 10138] loss_train: 0.007735, loss_test: 0.005642
time: 0.24506735801696777
time: 2.1904900074005127
[1, 10139] loss_train: 0.009170, loss_test: 0.005645
time: 0.2450542449951172
time: 2.208505868911743
[1, 10140] loss_train: 0.001977, loss_test: 0.005649
time: 0.25505638122558594
time: 2.235508680343628
[1, 10141] loss_train: 0.016990, loss_test: 0.005652
time: 0.24605369567871094
time: 2.2505040168762207
[1, 10142] loss_train: 0.003155, loss_test: 0.005653
time: 0.24405360221862793
time: 2.224510431289673
[1, 10143] loss_train: 0.009613, loss_test: 0.005654
time: 0.24205303192138672
time: 2.242006778717041
[1, 10144] loss_train: 0.007010, loss_test: 0.005652
time: 0.24405384063720703
time: 2.2084946632385254
[1, 10145] loss_train: 0.005913, loss_test: 0.005651
time: 0.2470541000366211
time: 2.2065072059631348
[1, 10146] loss_train: 0.007049, loss_test: 0.005650
time: 0.24405431747436523
time: 2.2375001907348633
[1, 10147] loss_train: 0.003649, loss_test: 0.005644
time: 0.24405384063720703
time: 2.218496799468994
[1, 10148] loss_train: 0.002163, loss_test: 0.005635
time: 0.24605441093444824
time: 2.2420103549957275
[1, 10149] loss_train: 0.003836, loss_test: 0.005630
time: 0.24306726455688477
time: 2.1934914588928223
[1, 10150] loss_train: 0.009606, loss_test: 0.005630
time: 0.25505685806274414
time: 2.261583089828491
[1, 10151] loss_train: 0.001785, loss_test: 0.005635
time: 0.2470545768737793
time: 2.194491386413574
[1, 10152] loss_train: 0.007226, loss_test: 0.005635
time: 0.24809598922729492
time: 2.2284984588623047
[1, 10153] loss_train: 0.003103, loss_test: 0.005636
time: 0.24509453773498535
time: 2.2154955863952637
[1, 10154] loss_train: 0.003810, loss_test: 0.005638
time: 0.2470545768737793
time: 2.240501642227173
[1, 10155] loss_train: 0.007604, loss_test: 0.005639
time: 0.2510559558868408
time: 2.2376906871795654
[1, 10156] loss_train: 0.007799, loss_test: 0.005639
time: 0.24805545806884766
time: 2.2435014247894287
[1, 10157] loss_train: 0.006024, loss_test: 0.005642
time: 0.24405407905578613
time: 2.199491500854492
[1, 10158] loss_train: 0.016362, loss_test: 0.005646
time: 0.24305343627929688
time: 2.2254984378814697
[1, 10159] loss_train: 0.006034, loss_test: 0.005651
time: 0.24505400657653809
time: 2.2095208168029785
[1, 10160] loss_train: 0.014135, loss_test: 0.005654
time: 0.25505614280700684
time: 2.238006353378296
[1, 10161] loss_train: 0.006584, loss_test: 0.005656
time: 0.24605441093444824
time: 2.20249342918396
[1, 10162] loss_train: 0.009862, loss_test: 0.005653
time: 0.2470545768737793
time: 2.2163360118865967
[1, 10163] loss_train: 0.005859, loss_test: 0.005650
time: 0.24305367469787598
time: 2.216498851776123
[1, 10164] loss_train: 0.010546, loss_test: 0.005647
time: 0.24305367469787598
time: 2.214505434036255
[1, 10165] loss_train: 0.004900, loss_test: 0.005645
time: 0.2450542449951172
time: 2.217496156692505
[1, 10166] loss_train: 0.002660, loss_test: 0.005652
time: 0.24205327033996582
time: 2.223513126373291
[1, 10167] loss_train: 0.014623, loss_test: 0.005658
time: 0.24405479431152344
time: 2.218517780303955
[1, 10168] loss_train: 0.001508, loss_test: 0.005669
time: 0.24405908584594727
time: 2.2145001888275146
[1, 10169] loss_train: 0.012817, loss_test: 0.005673
time: 0.2520561218261719
time: 2.2264976501464844
[1, 10170] loss_train: 0.008021, loss_test: 0.005666
time: 0.2560570240020752
time: 2.239018678665161
[1, 10171] loss_train: 0.004423, loss_test: 0.005661
time: 0.25005507469177246
time: 2.2445123195648193
[1, 10172] loss_train: 0.013556, loss_test: 0.005641
time: 0.24405455589294434
time: 2.233508348464966
[1, 10173] loss_train: 0.004331, loss_test: 0.005635
time: 0.24706602096557617
time: 2.1984922885894775
[1, 10174] loss_train: 0.004384, loss_test: 0.005641
time: 0.2450580596923828
time: 2.2134954929351807
[1, 10175] loss_train: 0.004641, loss_test: 0.005654
time: 0.24305438995361328
time: 2.235499858856201
[1, 10176] loss_train: 0.006843, loss_test: 0.005666
time: 0.2470684051513672
time: 2.2144947052001953
[1, 10177] loss_train: 0.007313, loss_test: 0.005673
time: 0.2450554370880127
time: 2.2345001697540283
[1, 10178] loss_train: 0.004226, loss_test: 0.005666
time: 0.24405431747436523
time: 2.234499216079712
[1, 10179] loss_train: 0.009841, loss_test: 0.005655
time: 0.24405431747436523
time: 2.2224972248077393
[1, 10180] loss_train: 0.011514, loss_test: 0.005653
time: 0.25505638122558594
time: 2.243502616882324
[1, 10181] loss_train: 0.007815, loss_test: 0.005650
time: 0.24605917930603027
time: 2.2625060081481934
[1, 10182] loss_train: 0.004850, loss_test: 0.005647
time: 0.24305438995361328
time: 2.198493719100952
[1, 10183] loss_train: 0.008839, loss_test: 0.005644
time: 0.24305438995361328
time: 2.2174954414367676
[1, 10184] loss_train: 0.012043, loss_test: 0.005642
time: 0.24405479431152344
time: 2.186500072479248
[1, 10185] loss_train: 0.003386, loss_test: 0.005641
time: 0.24406647682189941
time: 2.191490411758423
[1, 10186] loss_train: 0.007672, loss_test: 0.005641
time: 0.24906706809997559
time: 2.2094943523406982
[1, 10187] loss_train: 0.004751, loss_test: 0.005642
time: 0.24508237838745117
time: 2.2210075855255127
[1, 10188] loss_train: 0.004943, loss_test: 0.005645
time: 0.2470545768737793
time: 2.2274982929229736
[1, 10189] loss_train: 0.009128, loss_test: 0.005645
time: 0.24305438995361328
time: 2.2500150203704834
[1, 10190] loss_train: 0.009529, loss_test: 0.005642
time: 0.26405858993530273
time: 2.229499101638794
[1, 10191] loss_train: 0.004090, loss_test: 0.005642
time: 0.24556732177734375
time: 2.2505059242248535
[1, 10192] loss_train: 0.014020, loss_test: 0.005642
time: 0.24305415153503418
time: 2.2505033016204834
[1, 10193] loss_train: 0.005441, loss_test: 0.005642
time: 0.24405360221862793
time: 2.2485034465789795
[1, 10194] loss_train: 0.012515, loss_test: 0.005640
time: 0.24405503273010254
time: 2.237499475479126
[1, 10195] loss_train: 0.002890, loss_test: 0.005635
time: 0.2440659999847412
time: 2.1865041255950928
[1, 10196] loss_train: 0.007056, loss_test: 0.005629
time: 0.24305367469787598
time: 2.1974916458129883
[1, 10197] loss_train: 0.005565, loss_test: 0.005625
time: 0.24505400657653809
time: 2.2066895961761475
[1, 10198] loss_train: 0.006709, loss_test: 0.005621
time: 0.24605417251586914
time: 2.2124953269958496
[1, 10199] loss_train: 0.011654, loss_test: 0.005618
time: 0.24505352973937988
time: 2.203493118286133
[1, 10200] loss_train: 0.002620, loss_test: 0.005615
time: 0.2530558109283447
time: 2.2405014038085938
[1, 10201] loss_train: 0.008336, loss_test: 0.005612
time: 0.24405479431152344
time: 2.206996440887451
[1, 10202] loss_train: 0.007149, loss_test: 0.005610
time: 0.24305438995361328
time: 2.2515037059783936
[1, 10203] loss_train: 0.002773, loss_test: 0.005608
time: 0.24806761741638184
time: 2.231498956680298
[1, 10204] loss_train: 0.002095, loss_test: 0.005608
time: 0.24405503273010254
time: 2.227497100830078
[1, 10205] loss_train: 0.003021, loss_test: 0.005610
time: 0.24805545806884766
time: 2.2310280799865723
[1, 10206] loss_train: 0.002394, loss_test: 0.005613
time: 0.24605464935302734
time: 2.233499526977539
[1, 10207] loss_train: 0.004233, loss_test: 0.005617
time: 0.24855923652648926
time: 2.220498561859131
[1, 10208] loss_train: 0.002898, loss_test: 0.005625
time: 0.24305367469787598
time: 2.217496156692505
[1, 10209] loss_train: 0.006380, loss_test: 0.005633
time: 0.24205350875854492
time: 2.208503007888794
[1, 10210] loss_train: 0.003454, loss_test: 0.005645
time: 0.2560696601867676
time: 2.2705087661743164
[1, 10211] loss_train: 0.012663, loss_test: 0.005646
time: 0.24305343627929688
time: 2.2381415367126465
[1, 10212] loss_train: 0.003772, loss_test: 0.005651
time: 0.2450544834136963
time: 2.2325122356414795
[1, 10213] loss_train: 0.003635, loss_test: 0.005656
time: 0.24405384063720703
time: 2.226513147354126
[1, 10214] loss_train: 0.009139, loss_test: 0.005663
time: 0.24605488777160645
time: 2.2965288162231445
[1, 10215] loss_train: 0.011829, loss_test: 0.005657
time: 0.24405884742736816
time: 2.20949387550354
[1, 10216] loss_train: 0.009365, loss_test: 0.005625
time: 0.24305367469787598
time: 2.2655093669891357
[1, 10217] loss_train: 0.003826, loss_test: 0.005614
time: 0.24405360221862793
time: 2.2215170860290527
[1, 10218] loss_train: 0.005308, loss_test: 0.005617
time: 0.24305438995361328
time: 2.2074930667877197
[1, 10219] loss_train: 0.005557, loss_test: 0.005631
time: 0.24305367469787598
time: 2.2128117084503174
[1, 10220] loss_train: 0.005128, loss_test: 0.005649
time: 0.25505614280700684
time: 2.239501476287842
[1, 10221] loss_train: 0.004180, loss_test: 0.005653
time: 0.2450549602508545
time: 2.2124974727630615
[1, 10222] loss_train: 0.004508, loss_test: 0.005644
time: 0.24465656280517578
time: 2.208494186401367
[1, 10223] loss_train: 0.008886, loss_test: 0.005636
time: 0.2450549602508545
time: 2.188488721847534
[1, 10224] loss_train: 0.010091, loss_test: 0.005630
time: 0.2490546703338623
time: 2.218496799468994
[1, 10225] loss_train: 0.000969, loss_test: 0.005627
time: 0.24505400657653809
time: 2.238013505935669
[1, 10226] loss_train: 0.013743, loss_test: 0.005632
time: 0.24805521965026855
time: 2.24509596824646
[1, 10227] loss_train: 0.002549, loss_test: 0.005643
time: 0.24308085441589355
time: 2.242501974105835
[1, 10228] loss_train: 0.010918, loss_test: 0.005651
time: 0.2490699291229248
time: 2.2485034465789795
[1, 10229] loss_train: 0.001373, loss_test: 0.005663
time: 0.24305462837219238
time: 2.2227532863616943
[1, 10230] loss_train: 0.002140, loss_test: 0.005677
time: 0.2580568790435791
time: 2.2385010719299316
[1, 10231] loss_train: 0.000532, loss_test: 0.005698
time: 0.2490549087524414
time: 2.2165122032165527
[1, 10232] loss_train: 0.007989, loss_test: 0.005707
time: 0.24305367469787598
time: 2.2124953269958496
[1, 10233] loss_train: 0.007548, loss_test: 0.005709
time: 0.24305415153503418
time: 2.218512773513794
[1, 10234] loss_train: 0.004752, loss_test: 0.005709
time: 0.24405288696289062
time: 2.220496654510498
[1, 10235] loss_train: 0.006823, loss_test: 0.005695
time: 0.2440662384033203
time: 2.228498697280884
[1, 10236] loss_train: 0.009346, loss_test: 0.005663
time: 0.24406814575195312
time: 2.223497152328491
[1, 10237] loss_train: 0.004263, loss_test: 0.005646
time: 0.24505376815795898
time: 2.2265007495880127
[1, 10238] loss_train: 0.006290, loss_test: 0.005638
time: 0.2450547218322754
time: 2.209493637084961
[1, 10239] loss_train: 0.020871, loss_test: 0.005639
time: 0.2450542449951172
time: 2.2375006675720215
[1, 10240] loss_train: 0.004242, loss_test: 0.005657
time: 0.2570650577545166
time: 2.242501974105835
[1, 10241] loss_train: 0.010122, loss_test: 0.005688
time: 0.24605417251586914
time: 2.2134957313537598
[1, 10242] loss_train: 0.007059, loss_test: 0.005715
time: 0.24305367469787598
time: 2.240504741668701
[1, 10243] loss_train: 0.002115, loss_test: 0.005743
time: 0.25705647468566895
time: 2.23449969291687
[1, 10244] loss_train: 0.006293, loss_test: 0.005744
time: 0.2430558204650879
time: 2.2104947566986084
[1, 10245] loss_train: 0.005943, loss_test: 0.005734
time: 0.2490546703338623
time: 2.2365005016326904
[1, 10246] loss_train: 0.001219, loss_test: 0.005721
time: 0.2450542449951172
time: 2.199261426925659
[1, 10247] loss_train: 0.012816, loss_test: 0.005684
time: 0.24805140495300293
time: 2.247504711151123
[1, 10248] loss_train: 0.003011, loss_test: 0.005662
time: 0.2490546703338623
time: 2.2020227909088135
[1, 10249] loss_train: 0.006428, loss_test: 0.005647
time: 0.24405360221862793
time: 2.2004928588867188
[1, 10250] loss_train: 0.007611, loss_test: 0.005651
time: 0.25305628776550293
time: 2.2655248641967773
[1, 10251] loss_train: 0.003968, loss_test: 0.005668
time: 0.24005413055419922
time: 2.222496747970581
[1, 10252] loss_train: 0.011795, loss_test: 0.005687
time: 0.24505352973937988
time: 2.241532564163208
[1, 10253] loss_train: 0.004339, loss_test: 0.005703
time: 0.24405455589294434
time: 2.2405006885528564
[1, 10254] loss_train: 0.006393, loss_test: 0.005716
time: 0.2450544834136963
time: 2.242501735687256
[1, 10255] loss_train: 0.004284, loss_test: 0.005728
time: 0.2450547218322754
time: 2.2274978160858154
[1, 10256] loss_train: 0.006148, loss_test: 0.005724
time: 0.24405455589294434
time: 2.174485445022583
[1, 10257] loss_train: 0.007698, loss_test: 0.005695
time: 0.24405455589294434
time: 2.191493511199951
[1, 10258] loss_train: 0.001494, loss_test: 0.005678
time: 0.24405455589294434
time: 2.209494113922119
[1, 10259] loss_train: 0.008033, loss_test: 0.005655
time: 0.24605441093444824
time: 2.2000133991241455
[1, 10260] loss_train: 0.015553, loss_test: 0.005637
time: 0.2627143859863281
time: 2.2361066341400146
[1, 10261] loss_train: 0.011445, loss_test: 0.005645
time: 0.24605393409729004
time: 2.2134954929351807
[1, 10262] loss_train: 0.011084, loss_test: 0.005682
time: 0.2490551471710205
time: 2.226498603820801
[1, 10263] loss_train: 0.005250, loss_test: 0.005740
time: 0.24405455589294434
time: 2.195490598678589
[1, 10264] loss_train: 0.004766, loss_test: 0.005817
time: 0.24506688117980957
time: 2.2375261783599854
[1, 10265] loss_train: 0.002330, loss_test: 0.005835
time: 0.24405431747436523
time: 2.2405009269714355
[1, 10266] loss_train: 0.006131, loss_test: 0.005832
time: 0.2450549602508545
time: 2.2298154830932617
[1, 10267] loss_train: 0.009932, loss_test: 0.005796
time: 0.24305367469787598
time: 2.244502067565918
[1, 10268] loss_train: 0.010986, loss_test: 0.005754
time: 0.2470548152923584
time: 2.2290196418762207
[1, 10269] loss_train: 0.006009, loss_test: 0.005711
time: 0.24305343627929688
time: 2.211496353149414
[1, 10270] loss_train: 0.000885, loss_test: 0.005658
time: 0.2560563087463379
time: 2.249176263809204
[1, 10271] loss_train: 0.001018, loss_test: 0.005625
time: 0.24405384063720703
time: 2.193491220474243
[1, 10272] loss_train: 0.002985, loss_test: 0.005624
time: 0.2490546703338623
time: 2.219003677368164
[1, 10273] loss_train: 0.000520, loss_test: 0.005648
time: 0.24405384063720703
time: 2.2065014839172363
[1, 10274] loss_train: 0.009184, loss_test: 0.005684
time: 0.24405407905578613
time: 2.215496301651001
[1, 10275] loss_train: 0.004387, loss_test: 0.005728
time: 0.24405360221862793
time: 2.2260019779205322
[1, 10276] loss_train: 0.002769, loss_test: 0.005770
time: 0.24405479431152344
time: 2.21049427986145
[1, 10277] loss_train: 0.004423, loss_test: 0.005813
time: 0.24806737899780273
time: 2.230499029159546
[1, 10278] loss_train: 0.008122, loss_test: 0.005832
time: 0.24506711959838867
time: 2.2495174407958984
[1, 10279] loss_train: 0.001336, loss_test: 0.005839
time: 0.2490546703338623
time: 2.2455220222473145
[1, 10280] loss_train: 0.004700, loss_test: 0.005839
time: 0.2560563087463379
time: 2.216496229171753
[1, 10281] loss_train: 0.004393, loss_test: 0.005809
time: 0.2490551471710205
time: 2.2375006675720215
[1, 10282] loss_train: 0.010093, loss_test: 0.005757
time: 0.2510561943054199
time: 2.1904900074005127
[1, 10283] loss_train: 0.001738, loss_test: 0.005723
time: 0.2440659999847412
time: 2.2164952754974365
[1, 10284] loss_train: 0.006613, loss_test: 0.005693
time: 0.24405503273010254
time: 2.220496654510498
[1, 10285] loss_train: 0.004097, loss_test: 0.005669
time: 0.24305367469787598
time: 2.221022129058838
[1, 10286] loss_train: 0.005746, loss_test: 0.005660
time: 0.24405384063720703
time: 2.217517852783203
[1, 10287] loss_train: 0.006874, loss_test: 0.005663
time: 0.24407243728637695
time: 2.232499122619629
[1, 10288] loss_train: 0.012969, loss_test: 0.005677
time: 0.24405431747436523
time: 2.215508460998535
[1, 10289] loss_train: 0.014934, loss_test: 0.005705
time: 0.24805474281311035
time: 2.216496229171753
[1, 10290] loss_train: 0.007753, loss_test: 0.005732
time: 0.2550163269042969
time: 2.253504753112793
[1, 10291] loss_train: 0.006221, loss_test: 0.005748
time: 0.24357342720031738
time: 2.2254984378814697
[1, 10292] loss_train: 0.006237, loss_test: 0.005753
time: 0.24405431747436523
time: 2.2114944458007812
[1, 10293] loss_train: 0.010849, loss_test: 0.005750
time: 0.24607253074645996
time: 2.2124948501586914
[1, 10294] loss_train: 0.014494, loss_test: 0.005744
time: 0.2490692138671875
time: 2.2284984588623047
[1, 10295] loss_train: 0.005840, loss_test: 0.005731
time: 0.24505376815795898
time: 2.253504753112793
[1, 10296] loss_train: 0.004548, loss_test: 0.005704
time: 0.2490546703338623
time: 2.228498935699463
[1, 10297] loss_train: 0.009596, loss_test: 0.005682
time: 0.2450544834136963
time: 2.2124950885772705
[1, 10298] loss_train: 0.002192, loss_test: 0.005666
time: 0.24805426597595215
time: 2.2014927864074707
[1, 10299] loss_train: 0.005013, loss_test: 0.005655
time: 0.24405455589294434
time: 2.2450172901153564
[1, 10300] loss_train: 0.003615, loss_test: 0.005653
time: 0.25505709648132324
time: 2.2625057697296143
[1, 10301] loss_train: 0.011570, loss_test: 0.005654
time: 0.24305391311645508
time: 2.244502305984497
[1, 10302] loss_train: 0.005784, loss_test: 0.005657
time: 0.2450547218322754
time: 2.2274980545043945
[1, 10303] loss_train: 0.001453, loss_test: 0.005662
time: 0.24406671524047852
time: 2.2254981994628906
[1, 10304] loss_train: 0.003923, loss_test: 0.005668
time: 0.2450551986694336
time: 2.2214980125427246
[1, 10305] loss_train: 0.007947, loss_test: 0.005670
time: 0.2437734603881836
time: 2.223771333694458
[1, 10306] loss_train: 0.003172, loss_test: 0.005672
time: 0.2450542449951172
time: 2.225497245788574
[1, 10307] loss_train: 0.012197, loss_test: 0.005669
time: 0.2440645694732666
time: 2.2371537685394287
[1, 10308] loss_train: 0.007173, loss_test: 0.005665
time: 0.2450542449951172
time: 2.2204973697662354
[1, 10309] loss_train: 0.002321, loss_test: 0.005664
time: 0.24405384063720703
time: 2.2315170764923096
[1, 10310] loss_train: 0.004742, loss_test: 0.005665
time: 0.25505614280700684
time: 2.2525033950805664
[1, 10311] loss_train: 0.012313, loss_test: 0.005653
time: 0.2450542449951172
time: 2.2155113220214844
[1, 10312] loss_train: 0.005029, loss_test: 0.005646
time: 0.24305438995361328
time: 2.22078800201416
[1, 10313] loss_train: 0.003050, loss_test: 0.005644
time: 0.2450547218322754
time: 2.2294983863830566
[1, 10314] loss_train: 0.004040, loss_test: 0.005644
time: 0.24506855010986328
time: 2.267516851425171
[1, 10315] loss_train: 0.011025, loss_test: 0.005643
time: 0.24405360221862793
time: 2.232499837875366
[1, 10316] loss_train: 0.005615, loss_test: 0.005641
time: 0.2450542449951172
time: 2.203493356704712
[1, 10317] loss_train: 0.000718, loss_test: 0.005640
time: 0.24805569648742676
time: 2.229027271270752
[1, 10318] loss_train: 0.001708, loss_test: 0.005638
time: 0.24606823921203613
time: 2.2264978885650635
[1, 10319] loss_train: 0.007345, loss_test: 0.005637
time: 0.2490546703338623
time: 2.216024160385132
[1, 10320] loss_train: 0.005637, loss_test: 0.005636
time: 0.2560698986053467
time: 2.2605152130126953
[1, 10321] loss_train: 0.001383, loss_test: 0.005636
time: 0.24805545806884766
time: 2.225001811981201
[1, 10322] loss_train: 0.004650, loss_test: 0.005638
time: 0.24405431747436523
time: 2.2475030422210693
[1, 10323] loss_train: 0.012537, loss_test: 0.005638
time: 0.24405407905578613
time: 2.208493947982788
[1, 10324] loss_train: 0.002577, loss_test: 0.005643
time: 0.24305343627929688
time: 2.2154958248138428
[1, 10325] loss_train: 0.011426, loss_test: 0.005651
time: 0.24305391311645508
time: 2.2395179271698
[1, 10326] loss_train: 0.008799, loss_test: 0.005659
time: 0.24505376815795898
time: 2.226498603820801
[1, 10327] loss_train: 0.001117, loss_test: 0.005671
time: 0.2450547218322754
time: 2.2315146923065186
[1, 10328] loss_train: 0.008879, loss_test: 0.005681
time: 0.24405407905578613
time: 2.1984915733337402
[1, 10329] loss_train: 0.004193, loss_test: 0.005685
time: 0.24405384063720703
time: 2.217121124267578
[1, 10330] loss_train: 0.009226, loss_test: 0.005678
time: 0.25705671310424805
time: 2.2114951610565186
[1, 10331] loss_train: 0.010693, loss_test: 0.005663
time: 0.24405336380004883
time: 2.2045114040374756
[1, 10332] loss_train: 0.015352, loss_test: 0.005651
time: 0.2450547218322754
time: 2.2184958457946777
[1, 10333] loss_train: 0.002727, loss_test: 0.005644
time: 0.25005555152893066
time: 2.2094943523406982
[1, 10334] loss_train: 0.009390, loss_test: 0.005640
time: 0.24805474281311035
time: 2.2234978675842285
[1, 10335] loss_train: 0.001385, loss_test: 0.005639
time: 0.24405360221862793
time: 2.219496965408325
[1, 10336] loss_train: 0.007659, loss_test: 0.005643
time: 0.24805474281311035
time: 2.2325000762939453
[1, 10337] loss_train: 0.010449, loss_test: 0.005652
time: 0.24305367469787598
time: 2.232588291168213
[1, 10338] loss_train: 0.009282, loss_test: 0.005660
time: 0.24405479431152344
time: 2.232499361038208
[1, 10339] loss_train: 0.010286, loss_test: 0.005665
time: 0.24405455589294434
time: 2.2285146713256836
[1, 10340] loss_train: 0.002984, loss_test: 0.005661
time: 0.2560698986053467
time: 2.2415013313293457
[1, 10341] loss_train: 0.009119, loss_test: 0.005654
time: 0.2450544834136963
time: 2.2244977951049805
[1, 10342] loss_train: 0.008011, loss_test: 0.005648
time: 0.24405455589294434
time: 2.2149977684020996
[1, 10343] loss_train: 0.006778, loss_test: 0.005643
time: 0.24405455589294434
time: 2.1964917182922363
[1, 10344] loss_train: 0.006273, loss_test: 0.005640
time: 0.24405384063720703
time: 2.2475032806396484
[1, 10345] loss_train: 0.001585, loss_test: 0.005639
time: 0.24406695365905762
time: 2.2125041484832764
[1, 10346] loss_train: 0.008483, loss_test: 0.005641
time: 0.2450542449951172
time: 2.221497058868408
[1, 10347] loss_train: 0.009125, loss_test: 0.005642
time: 0.24505400657653809
time: 2.2160184383392334
[1, 10348] loss_train: 0.002776, loss_test: 0.005644
time: 0.24305391311645508
time: 2.220496654510498
[1, 10349] loss_train: 0.009913, loss_test: 0.005644
time: 0.24505400657653809
time: 2.221513509750366
[1, 10350] loss_train: 0.002424, loss_test: 0.005646
time: 0.2580575942993164
time: 2.2405009269714355
[1, 10351] loss_train: 0.011437, loss_test: 0.005646
time: 0.2540559768676758
time: 2.219496965408325
[1, 10352] loss_train: 0.004313, loss_test: 0.005645
time: 0.2450544834136963
time: 2.2375004291534424
[1, 10353] loss_train: 0.004729, loss_test: 0.005645
time: 0.2490546703338623
time: 2.203495502471924
[1, 10354] loss_train: 0.002933, loss_test: 0.005647
time: 0.24405360221862793
time: 2.205493688583374
[1, 10355] loss_train: 0.003166, loss_test: 0.005650
time: 0.24405336380004883
time: 2.218496561050415
[1, 10356] loss_train: 0.001036, loss_test: 0.005656
time: 0.2450547218322754
time: 2.240511417388916
[1, 10357] loss_train: 0.008043, loss_test: 0.005647
time: 0.24605441093444824
time: 2.221496820449829
[1, 10358] loss_train: 0.008832, loss_test: 0.005638
time: 0.24305415153503418
time: 2.2034924030303955
[1, 10359] loss_train: 0.011502, loss_test: 0.005632
time: 0.24505400657653809
time: 2.243349313735962
[1, 10360] loss_train: 0.006066, loss_test: 0.005633
time: 0.25505638122558594
time: 2.2531867027282715
[1, 10361] loss_train: 0.004361, loss_test: 0.005637
time: 0.25705647468566895
time: 2.243006706237793
[1, 10362] loss_train: 0.013280, loss_test: 0.005644
time: 0.24405455589294434
time: 2.2575066089630127
[1, 10363] loss_train: 0.005604, loss_test: 0.005647
time: 0.24605464935302734
time: 2.2254974842071533
[1, 10364] loss_train: 0.006302, loss_test: 0.005646
time: 0.24605441093444824
time: 2.206702947616577
[1, 10365] loss_train: 0.002472, loss_test: 0.005637
time: 0.24405407905578613
time: 2.197490930557251
[1, 10366] loss_train: 0.001585, loss_test: 0.005630
time: 0.24305510520935059
time: 2.2064931392669678
[1, 10367] loss_train: 0.001925, loss_test: 0.005635
time: 0.24405384063720703
time: 2.227498769760132
[1, 10368] loss_train: 0.004159, loss_test: 0.005651
time: 0.25005578994750977
time: 2.2034926414489746
[1, 10369] loss_train: 0.005022, loss_test: 0.005676
time: 0.24606752395629883
time: 2.194491386413574
[1, 10370] loss_train: 0.004616, loss_test: 0.005706
time: 0.25905704498291016
time: 2.2715086936950684
[1, 10371] loss_train: 0.003699, loss_test: 0.005742
time: 0.2470543384552002
time: 2.234499931335449
[1, 10372] loss_train: 0.004053, loss_test: 0.005776
time: 0.2510561943054199
time: 2.248502731323242
[1, 10373] loss_train: 0.008550, loss_test: 0.005789
time: 0.24305391311645508
time: 2.240502119064331
[1, 10374] loss_train: 0.007442, loss_test: 0.005797
time: 0.2490546703338623
time: 2.2405083179473877
[1, 10375] loss_train: 0.003934, loss_test: 0.005802
time: 0.24405384063720703
time: 2.2335000038146973
[1, 10376] loss_train: 0.008783, loss_test: 0.005772
time: 0.24405360221862793
time: 2.220496416091919
[1, 10377] loss_train: 0.005978, loss_test: 0.005732
time: 0.24505329132080078
time: 2.2234973907470703
[1, 10378] loss_train: 0.007824, loss_test: 0.005686
time: 0.24405407905578613
time: 2.207510232925415
[1, 10379] loss_train: 0.002940, loss_test: 0.005661
time: 0.24505400657653809
time: 2.2235171794891357
[1, 10380] loss_train: 0.004150, loss_test: 0.005652
time: 0.2560563087463379
time: 2.2645063400268555
[1, 10381] loss_train: 0.000773, loss_test: 0.005658
time: 0.2450547218322754
time: 2.216495990753174
[1, 10382] loss_train: 0.003574, loss_test: 0.005672
time: 0.24405598640441895
time: 2.2365007400512695
[1, 10383] loss_train: 0.009790, loss_test: 0.005695
time: 0.247056245803833
time: 2.208494186401367
[1, 10384] loss_train: 0.004913, loss_test: 0.005713
time: 0.24305391311645508
time: 2.2270050048828125
[1, 10385] loss_train: 0.004043, loss_test: 0.005720
time: 0.2450544834136963
time: 2.183488130569458
[1, 10386] loss_train: 0.006395, loss_test: 0.005722
time: 0.24605488777160645
time: 2.2170021533966064
[1, 10387] loss_train: 0.006335, loss_test: 0.005715
time: 0.2490549087524414
time: 2.2214972972869873
[1, 10388] loss_train: 0.004330, loss_test: 0.005709
time: 0.2470552921295166
time: 2.235499858856201
[1, 10389] loss_train: 0.003201, loss_test: 0.005698
time: 0.24841594696044922
time: 2.204375743865967
[1, 10390] loss_train: 0.006409, loss_test: 0.005688
time: 0.25505638122558594
time: 2.243502140045166
[1, 10391] loss_train: 0.009402, loss_test: 0.005678
time: 0.2540562152862549
time: 2.2064969539642334
[1, 10392] loss_train: 0.004555, loss_test: 0.005675
time: 0.24405360221862793
time: 2.2254979610443115
[1, 10393] loss_train: 0.010012, loss_test: 0.005677
time: 0.24405407905578613
time: 2.2074942588806152
[1, 10394] loss_train: 0.006589, loss_test: 0.005686
time: 0.24281001091003418
time: 2.2308061122894287
[1, 10395] loss_train: 0.006915, loss_test: 0.005692
time: 0.24405384063720703
time: 2.235502243041992
[1, 10396] loss_train: 0.004279, loss_test: 0.005697
time: 0.24410581588745117
time: 2.2104949951171875
[1, 10397] loss_train: 0.005349, loss_test: 0.005700
time: 0.24305343627929688
time: 2.228518009185791
[1, 10398] loss_train: 0.003149, loss_test: 0.005700
time: 0.24605441093444824
time: 2.232499122619629
[1, 10399] loss_train: 0.008222, loss_test: 0.005701
time: 0.24305462837219238
time: 2.203004837036133
[1, 10400] loss_train: 0.002625, loss_test: 0.005703
time: 0.256056547164917
time: 2.261505603790283
[1, 10401] loss_train: 0.009295, loss_test: 0.005693
time: 0.2450547218322754
time: 2.2174956798553467
[1, 10402] loss_train: 0.004028, loss_test: 0.005682
time: 0.24405360221862793
time: 2.207493782043457
[1, 10403] loss_train: 0.006095, loss_test: 0.005672
time: 0.24405503273010254
time: 2.22249698638916
[1, 10404] loss_train: 0.011312, loss_test: 0.005656
time: 0.2490549087524414
time: 2.1984920501708984
[1, 10405] loss_train: 0.005471, loss_test: 0.005643
time: 0.24706792831420898
time: 2.22379469871521
[1, 10406] loss_train: 0.007291, loss_test: 0.005636
time: 0.2470545768737793
time: 2.2034928798675537
[1, 10407] loss_train: 0.010067, loss_test: 0.005634
time: 0.24505400657653809
time: 2.2305080890655518
[1, 10408] loss_train: 0.001012, loss_test: 0.005635
time: 0.2420516014099121
time: 2.2284984588623047
[1, 10409] loss_train: 0.004593, loss_test: 0.005636
time: 0.2430553436279297
time: 2.22100830078125
[1, 10410] loss_train: 0.002366, loss_test: 0.005636
time: 0.254056453704834
time: 2.2495031356811523
[1, 10411] loss_train: 0.004531, loss_test: 0.005638
time: 0.2450547218322754
time: 2.2515032291412354
[1, 10412] loss_train: 0.000559, loss_test: 0.005642
time: 0.2450709342956543
time: 2.2295005321502686
[1, 10413] loss_train: 0.006559, loss_test: 0.005647
time: 0.24406647682189941
time: 2.209494113922119
[1, 10414] loss_train: 0.003369, loss_test: 0.005654
time: 0.24405407905578613
time: 2.227499008178711
[1, 10415] loss_train: 0.002049, loss_test: 0.005663
time: 0.24605369567871094
time: 2.2105019092559814
[1, 10416] loss_train: 0.012068, loss_test: 0.005665
time: 0.24305415153503418
time: 2.1895089149475098
[1, 10417] loss_train: 0.003161, loss_test: 0.005672
time: 0.24305391311645508
time: 2.197490692138672
[1, 10418] loss_train: 0.011700, loss_test: 0.005676
time: 0.24605512619018555
time: 2.2415032386779785
[1, 10419] loss_train: 0.002937, loss_test: 0.005681
time: 0.2490558624267578
time: 2.2274978160858154
[1, 10420] loss_train: 0.003763, loss_test: 0.005685
time: 0.2561173439025879
time: 2.213505744934082
[1, 10421] loss_train: 0.007051, loss_test: 0.005687
time: 0.2540700435638428
time: 2.2320029735565186
[1, 10422] loss_train: 0.002798, loss_test: 0.005690
time: 0.24805521965026855
time: 2.2370035648345947
[1, 10423] loss_train: 0.006251, loss_test: 0.005690
time: 0.2470543384552002
time: 2.214495897293091
[1, 10424] loss_train: 0.012351, loss_test: 0.005685
time: 0.24406719207763672
time: 2.2355008125305176
[1, 10425] loss_train: 0.001103, loss_test: 0.005682
time: 0.24305367469787598
time: 2.2065205574035645
[1, 10426] loss_train: 0.007032, loss_test: 0.005678
time: 0.24305391311645508
time: 2.2144999504089355
[1, 10427] loss_train: 0.011079, loss_test: 0.005660
time: 0.24506568908691406
time: 2.2455027103424072
[1, 10428] loss_train: 0.001252, loss_test: 0.005651
time: 0.24305391311645508
time: 2.217496156692505
[1, 10429] loss_train: 0.004235, loss_test: 0.005646
time: 0.2470555305480957
time: 2.217003107070923
[1, 10430] loss_train: 0.004607, loss_test: 0.005642
time: 0.256056547164917
time: 2.245502471923828
[1, 10431] loss_train: 0.002934, loss_test: 0.005640
time: 0.24305415153503418
time: 2.2220094203948975
[1, 10432] loss_train: 0.004945, loss_test: 0.005640
time: 0.24405479431152344
time: 2.2314987182617188
[1, 10433] loss_train: 0.011953, loss_test: 0.005640
time: 0.24405455589294434
time: 2.2198731899261475
[1, 10434] loss_train: 0.004810, loss_test: 0.005641
time: 0.24205422401428223
time: 2.230498790740967
[1, 10435] loss_train: 0.002507, loss_test: 0.005642
time: 0.24405407905578613
time: 2.2300355434417725
[1, 10436] loss_train: 0.013758, loss_test: 0.005635
time: 0.24505400657653809
time: 2.233499765396118
[1, 10437] loss_train: 0.005306, loss_test: 0.005630
time: 0.24406766891479492
time: 2.2395031452178955
[1, 10438] loss_train: 0.005395, loss_test: 0.005627
time: 0.24805688858032227
time: 2.2154958248138428
[1, 10439] loss_train: 0.008273, loss_test: 0.005625
time: 0.2490546703338623
time: 2.239511013031006
[1, 10440] loss_train: 0.001016, loss_test: 0.005625
time: 0.26205873489379883
time: 2.2535040378570557
[1, 10441] loss_train: 0.001163, loss_test: 0.005627
time: 0.24405384063720703
time: 2.2234976291656494
[1, 10442] loss_train: 0.007657, loss_test: 0.005628
time: 0.2510561943054199
time: 2.199491500854492
[1, 10443] loss_train: 0.001980, loss_test: 0.005631
time: 0.24405431747436523
time: 2.2505035400390625
[1, 10444] loss_train: 0.006997, loss_test: 0.005632
time: 0.24805426597595215
time: 2.2114953994750977
[1, 10445] loss_train: 0.009459, loss_test: 0.005627
time: 0.24406743049621582
time: 2.2175073623657227
[1, 10446] loss_train: 0.001440, loss_test: 0.005625
time: 0.24605512619018555
time: 2.249007225036621
[1, 10447] loss_train: 0.005746, loss_test: 0.005624
time: 0.24606657028198242
time: 2.235503911972046
[1, 10448] loss_train: 0.010308, loss_test: 0.005625
time: 0.24405598640441895
time: 2.2134947776794434
[1, 10449] loss_train: 0.004313, loss_test: 0.005628
time: 0.24505400657653809
time: 2.2105116844177246
[1, 10450] loss_train: 0.011380, loss_test: 0.005629
time: 0.25505709648132324
time: 2.248502254486084
[1, 10451] loss_train: 0.008614, loss_test: 0.005629
time: 0.2440786361694336
time: 2.2244982719421387
[1, 10452] loss_train: 0.003700, loss_test: 0.005629
time: 0.24405336380004883
time: 2.2395009994506836
[1, 10453] loss_train: 0.005265, loss_test: 0.005629
time: 0.24405407905578613
time: 2.2084946632385254
[1, 10454] loss_train: 0.004319, loss_test: 0.005628
time: 0.24405360221862793
time: 2.20349383354187
[1, 10455] loss_train: 0.007309, loss_test: 0.005624
time: 0.24405407905578613
time: 2.220496892929077
[1, 10456] loss_train: 0.005909, loss_test: 0.005621
time: 0.24608087539672852
time: 2.2115066051483154
[1, 10457] loss_train: 0.004311, loss_test: 0.005620
time: 0.2490553855895996
time: 2.22249698638916
[1, 10458] loss_train: 0.009252, loss_test: 0.005619
time: 0.2470560073852539
time: 2.248520612716675
[1, 10459] loss_train: 0.010614, loss_test: 0.005618
time: 0.2490549087524414
time: 2.212494373321533
[1, 10460] loss_train: 0.007480, loss_test: 0.005622
time: 0.25707125663757324
time: 2.2575221061706543
[1, 10461] loss_train: 0.003958, loss_test: 0.005626
time: 0.25205564498901367
time: 2.231499433517456
[1, 10462] loss_train: 0.004559, loss_test: 0.005630
time: 0.24405455589294434
time: 2.219372272491455
[1, 10463] loss_train: 0.008063, loss_test: 0.005635
time: 0.2470545768737793
time: 2.2094945907592773
[1, 10464] loss_train: 0.003976, loss_test: 0.005638
time: 0.24305391311645508
time: 2.2124953269958496
[1, 10465] loss_train: 0.006371, loss_test: 0.005640
time: 0.24205327033996582
time: 2.204493522644043
[1, 10466] loss_train: 0.004151, loss_test: 0.005639
time: 0.24505400657653809
time: 2.2250115871429443
[1, 10467] loss_train: 0.005352, loss_test: 0.005639
time: 0.24405455589294434
time: 2.216495990753174
[1, 10468] loss_train: 0.010778, loss_test: 0.005641
time: 0.24405407905578613
time: 2.235511541366577
[1, 10469] loss_train: 0.002958, loss_test: 0.005645
time: 0.24305415153503418
time: 2.2225301265716553
[1, 10470] loss_train: 0.011516, loss_test: 0.005648
time: 0.256056547164917
time: 2.2525203227996826
[1, 10471] loss_train: 0.003211, loss_test: 0.005651
time: 0.2490558624267578
time: 2.2244973182678223
[1, 10472] loss_train: 0.005578, loss_test: 0.005657
time: 0.24406886100769043
time: 2.22251033782959
[1, 10473] loss_train: 0.019548, loss_test: 0.005647
time: 0.2450547218322754
time: 2.228511095046997
[1, 10474] loss_train: 0.007402, loss_test: 0.005644
time: 0.24405407905578613
time: 2.228498935699463
[1, 10475] loss_train: 0.002652, loss_test: 0.005650
time: 0.2450544834136963
time: 2.2124948501586914
[1, 10476] loss_train: 0.003566, loss_test: 0.005660
time: 0.24805498123168945
time: 2.2170071601867676
[1, 10477] loss_train: 0.006329, loss_test: 0.005673
time: 0.2450549602508545
time: 2.2284977436065674
[1, 10478] loss_train: 0.004066, loss_test: 0.005672
time: 0.24805545806884766
time: 2.2085025310516357
[1, 10479] loss_train: 0.007769, loss_test: 0.005670
time: 0.24405479431152344
time: 2.1894888877868652
[1, 10480] loss_train: 0.006965, loss_test: 0.005665
time: 0.2575812339782715
time: 2.2485029697418213
[1, 10481] loss_train: 0.014542, loss_test: 0.005656
time: 0.24606752395629883
time: 2.2295010089874268
[1, 10482] loss_train: 0.011121, loss_test: 0.005651
time: 0.24405431747436523
time: 2.2134952545166016
[1, 10483] loss_train: 0.010693, loss_test: 0.005653
time: 0.2450544834136963
time: 2.2525036334991455
[1, 10484] loss_train: 0.011090, loss_test: 0.005653
time: 0.2450542449951172
time: 2.218012571334839
[1, 10485] loss_train: 0.004928, loss_test: 0.005653
time: 0.24405479431152344
time: 2.209493398666382
[1, 10486] loss_train: 0.001661, loss_test: 0.005657
time: 0.24405479431152344
time: 2.2555196285247803
[1, 10487] loss_train: 0.006720, loss_test: 0.005661
time: 0.2690591812133789
time: 2.219496726989746
[1, 10488] loss_train: 0.007260, loss_test: 0.005664
time: 0.24305343627929688
time: 2.2335000038146973
[1, 10489] loss_train: 0.011999, loss_test: 0.005662
time: 0.24305462837219238
time: 2.194490432739258
[1, 10490] loss_train: 0.006400, loss_test: 0.005659
time: 0.25705742835998535
time: 2.272507905960083
[1, 10491] loss_train: 0.007014, loss_test: 0.005658
time: 0.24405384063720703
time: 2.242501974105835
[1, 10492] loss_train: 0.004810, loss_test: 0.005659
time: 0.24305415153503418
time: 2.2254974842071533
[1, 10493] loss_train: 0.003551, loss_test: 0.005662
time: 0.2470550537109375
time: 2.2395002841949463
[1, 10494] loss_train: 0.011557, loss_test: 0.005658
time: 0.24405431747436523
time: 2.231499195098877
[1, 10495] loss_train: 0.001192, loss_test: 0.005658
time: 0.2490558624267578
time: 2.260505199432373
[1, 10496] loss_train: 0.004975, loss_test: 0.005660
time: 0.2450544834136963
time: 2.2264976501464844
[1, 10497] loss_train: 0.007077, loss_test: 0.005662
time: 0.2520565986633301
time: 2.2305009365081787
[1, 10498] loss_train: 0.002650, loss_test: 0.005659
time: 0.2450544834136963
time: 2.2300353050231934
[1, 10499] loss_train: 0.010873, loss_test: 0.005660
time: 0.2490687370300293
time: 2.2184958457946777
[1, 10500] loss_train: 0.006214, loss_test: 0.005659
time: 0.256056547164917
time: 2.2600109577178955
[1, 10501] loss_train: 0.008179, loss_test: 0.005656
time: 0.2490546703338623
time: 2.243502378463745
[1, 10502] loss_train: 0.003064, loss_test: 0.005649
time: 0.2450544834136963
time: 2.2144949436187744
[1, 10503] loss_train: 0.004531, loss_test: 0.005642
time: 0.24605441093444824
time: 2.2164993286132812
[1, 10504] loss_train: 0.003440, loss_test: 0.005636
time: 0.24805521965026855
time: 2.2395029067993164
[1, 10505] loss_train: 0.008707, loss_test: 0.005633
time: 0.24406671524047852
time: 2.2314987182617188
[1, 10506] loss_train: 0.000985, loss_test: 0.005636
time: 0.24509358406066895
time: 2.214494228363037
[1, 10507] loss_train: 0.009888, loss_test: 0.005640
time: 0.24306869506835938
time: 2.2264978885650635
[1, 10508] loss_train: 0.005039, loss_test: 0.005646
time: 0.24405431747436523
time: 2.216495990753174
[1, 10509] loss_train: 0.005051, loss_test: 0.005654
time: 0.24307727813720703
time: 2.1874897480010986
[1, 10510] loss_train: 0.012510, loss_test: 0.005659
time: 0.25705718994140625
time: 2.217496156692505
[1, 10511] loss_train: 0.004228, loss_test: 0.005664
time: 0.24505972862243652
time: 2.1870803833007812
[1, 10512] loss_train: 0.006599, loss_test: 0.005657
time: 0.24405407905578613
time: 2.183488130569458
[1, 10513] loss_train: 0.003342, loss_test: 0.005647
time: 0.24605417251586914
time: 2.1754868030548096
[1, 10514] loss_train: 0.005279, loss_test: 0.005641
time: 0.2490553855895996
time: 2.195502996444702
[1, 10515] loss_train: 0.007897, loss_test: 0.005632
time: 0.25005602836608887
time: 2.232499361038208
[1, 10516] loss_train: 0.001888, loss_test: 0.005628
time: 0.24405431747436523
time: 2.2034926414489746
[1, 10517] loss_train: 0.005755, loss_test: 0.005624
time: 0.24605441093444824
time: 2.2264981269836426
[1, 10518] loss_train: 0.008630, loss_test: 0.005624
time: 0.2470555305480957
time: 2.247502088546753
[1, 10519] loss_train: 0.005388, loss_test: 0.005624
time: 0.2450542449951172
time: 2.205493927001953
[1, 10520] loss_train: 0.004117, loss_test: 0.005626
time: 0.25505733489990234
time: 2.2535030841827393
[1, 10521] loss_train: 0.009870, loss_test: 0.005626
time: 0.25006890296936035
time: 2.2134947776794434
[1, 10522] loss_train: 0.004965, loss_test: 0.005628
time: 0.24605488777160645
time: 2.2234973907470703
[1, 10523] loss_train: 0.011559, loss_test: 0.005630
time: 0.24405407905578613
time: 2.193995952606201
[1, 10524] loss_train: 0.013010, loss_test: 0.005632
time: 0.24505400657653809
time: 2.217498302459717
[1, 10525] loss_train: 0.012195, loss_test: 0.005631
time: 0.2450544834136963
time: 2.226515293121338
[1, 10526] loss_train: 0.007407, loss_test: 0.005629
time: 0.2450542449951172
time: 2.211503744125366
[1, 10527] loss_train: 0.011579, loss_test: 0.005627
time: 0.2490549087524414
time: 2.2315146923065186
[1, 10528] loss_train: 0.008006, loss_test: 0.005626
time: 0.24605417251586914
time: 2.232510566711426
[1, 10529] loss_train: 0.003301, loss_test: 0.005623
time: 0.25206780433654785
time: 2.2535033226013184
[1, 10530] loss_train: 0.005236, loss_test: 0.005621
time: 0.2560575008392334
time: 2.2304978370666504
[1, 10531] loss_train: 0.004563, loss_test: 0.005619
time: 0.25205564498901367
time: 2.239046812057495
[1, 10532] loss_train: 0.004784, loss_test: 0.005617
time: 0.24406719207763672
time: 2.2270395755767822
[1, 10533] loss_train: 0.009398, loss_test: 0.005615
time: 0.24605464935302734
time: 2.220496892929077
[1, 10534] loss_train: 0.003839, loss_test: 0.005615
time: 0.24405241012573242
time: 2.2173075675964355
[1, 10535] loss_train: 0.003056, loss_test: 0.005619
time: 0.24305319786071777
time: 2.243025302886963
[1, 10536] loss_train: 0.004308, loss_test: 0.005629
time: 0.24805450439453125
time: 2.2385051250457764
[1, 10537] loss_train: 0.007823, loss_test: 0.005634
time: 0.24306583404541016
time: 2.217495918273926
[1, 10538] loss_train: 0.002128, loss_test: 0.005642
time: 0.24405407905578613
time: 2.2275006771087646
[1, 10539] loss_train: 0.003679, loss_test: 0.005654
time: 0.24605441093444824
time: 2.2120094299316406
[1, 10540] loss_train: 0.006850, loss_test: 0.005664
time: 0.2570686340332031
time: 2.2395012378692627
[1, 10541] loss_train: 0.004593, loss_test: 0.005677
time: 0.24405384063720703
time: 2.2345004081726074
[1, 10542] loss_train: 0.009408, loss_test: 0.005681
time: 0.24305438995361328
time: 2.2395002841949463
[1, 10543] loss_train: 0.004022, loss_test: 0.005685
time: 0.24405407905578613
time: 2.2285008430480957
[1, 10544] loss_train: 0.007989, loss_test: 0.005683
time: 0.24458050727844238
time: 2.203493595123291
[1, 10545] loss_train: 0.005645, loss_test: 0.005675
time: 0.24510407447814941
time: 2.211028814315796
[1, 10546] loss_train: 0.006433, loss_test: 0.005666
time: 0.2490549087524414
time: 2.2264983654022217
[1, 10547] loss_train: 0.009676, loss_test: 0.005657
time: 0.24305367469787598
time: 2.2100086212158203
[1, 10548] loss_train: 0.004734, loss_test: 0.005649
time: 0.24806809425354004
time: 2.21651291847229
[1, 10549] loss_train: 0.012274, loss_test: 0.005639
time: 0.24405455589294434
time: 2.2221171855926514
[1, 10550] loss_train: 0.009562, loss_test: 0.005632
time: 0.25905680656433105
time: 2.2455027103424072
[1, 10551] loss_train: 0.005029, loss_test: 0.005632
time: 0.24406790733337402
time: 2.230031967163086
[1, 10552] loss_train: 0.003712, loss_test: 0.005636
time: 0.24305295944213867
time: 2.20402193069458
[1, 10553] loss_train: 0.012525, loss_test: 0.005647
time: 0.24605464935302734
time: 2.2375004291534424
[1, 10554] loss_train: 0.010545, loss_test: 0.005664
time: 0.24405431747436523
time: 2.2044925689697266
[1, 10555] loss_train: 0.008432, loss_test: 0.005672
time: 0.24305295944213867
time: 2.2224974632263184
[1, 10556] loss_train: 0.012333, loss_test: 0.005687
time: 0.24605441093444824
time: 2.213494300842285
[1, 10557] loss_train: 0.005003, loss_test: 0.005697
time: 0.24305415153503418
time: 2.248025417327881
[1, 10558] loss_train: 0.003404, loss_test: 0.005699
time: 0.24405455589294434
time: 2.2274982929229736
[1, 10559] loss_train: 0.007318, loss_test: 0.005694
time: 0.24405384063720703
time: 2.1905150413513184
[1, 10560] loss_train: 0.001927, loss_test: 0.005682
time: 0.25705671310424805
time: 2.2555043697357178
[1, 10561] loss_train: 0.001851, loss_test: 0.005667
time: 0.24808049201965332
time: 2.2074942588806152
[1, 10562] loss_train: 0.009698, loss_test: 0.005655
time: 0.24506735801696777
time: 2.2134952545166016
[1, 10563] loss_train: 0.006616, loss_test: 0.005650
time: 0.252056360244751
time: 2.2034924030303955
[1, 10564] loss_train: 0.010834, loss_test: 0.005643
time: 0.24605536460876465
time: 2.2194957733154297
[1, 10565] loss_train: 0.001035, loss_test: 0.005640
time: 0.24805545806884766
time: 2.2415010929107666
[1, 10566] loss_train: 0.004376, loss_test: 0.005639
time: 0.2440652847290039
time: 2.2465031147003174
[1, 10567] loss_train: 0.003175, loss_test: 0.005644
time: 0.2470543384552002
time: 2.2365007400512695
[1, 10568] loss_train: 0.006158, loss_test: 0.005650
time: 0.24405431747436523
time: 2.230517625808716
[1, 10569] loss_train: 0.006910, loss_test: 0.005655
time: 0.24306678771972656
time: 2.2745256423950195
[1, 10570] loss_train: 0.011491, loss_test: 0.005657
time: 0.256070613861084
time: 2.2256133556365967
[1, 10571] loss_train: 0.004542, loss_test: 0.005658
time: 0.24205350875854492
time: 2.231499433517456
[1, 10572] loss_train: 0.011616, loss_test: 0.005658
time: 0.24405431747436523
time: 2.243513584136963
[1, 10573] loss_train: 0.006571, loss_test: 0.005653
time: 0.2470548152923584
time: 2.246004819869995
[1, 10574] loss_train: 0.005536, loss_test: 0.005648
time: 0.24605417251586914
time: 2.199493646621704
[1, 10575] loss_train: 0.001644, loss_test: 0.005646
time: 0.24305438995361328
time: 2.207493305206299
[1, 10576] loss_train: 0.010910, loss_test: 0.005642
time: 0.24205374717712402
time: 2.203495740890503
[1, 10577] loss_train: 0.002172, loss_test: 0.005641
time: 0.24706816673278809
time: 2.223496437072754
[1, 10578] loss_train: 0.002635, loss_test: 0.005640
time: 0.24306654930114746
time: 2.220212697982788
[1, 10579] loss_train: 0.004627, loss_test: 0.005640
time: 0.24405360221862793
time: 2.229498863220215
[1, 10580] loss_train: 0.000479, loss_test: 0.005640
time: 0.2580580711364746
time: 2.256521701812744
[1, 10581] loss_train: 0.006894, loss_test: 0.005641
time: 0.249053955078125
time: 2.242502212524414
[1, 10582] loss_train: 0.003641, loss_test: 0.005644
time: 0.24405431747436523
time: 2.234022378921509
[1, 10583] loss_train: 0.007737, loss_test: 0.005644
time: 0.2470545768737793
time: 2.221496820449829
[1, 10584] loss_train: 0.008025, loss_test: 0.005644
time: 0.24605512619018555
time: 2.2184958457946777
[1, 10585] loss_train: 0.003926, loss_test: 0.005646
time: 0.24405360221862793
time: 2.260505199432373
[1, 10586] loss_train: 0.009319, loss_test: 0.005644
time: 0.2490527629852295
time: 2.219496011734009
[1, 10587] loss_train: 0.017976, loss_test: 0.005637
time: 0.24605488777160645
time: 2.263507127761841
[1, 10588] loss_train: 0.003465, loss_test: 0.005631
time: 0.24805450439453125
time: 2.241502046585083
[1, 10589] loss_train: 0.004750, loss_test: 0.005627
time: 0.24505400657653809
time: 2.2049973011016846
[1, 10590] loss_train: 0.009636, loss_test: 0.005623
time: 0.2610585689544678
time: 2.224513053894043
[1, 10591] loss_train: 0.010478, loss_test: 0.005621
time: 0.24806833267211914
time: 2.2254977226257324
[1, 10592] loss_train: 0.003792, loss_test: 0.005619
time: 0.24605464935302734
time: 2.2345128059387207
[1, 10593] loss_train: 0.004496, loss_test: 0.005618
time: 0.2470550537109375
time: 2.2044920921325684
[1, 10594] loss_train: 0.001357, loss_test: 0.005617
time: 0.2450551986694336
time: 2.2375004291534424
[1, 10595] loss_train: 0.007511, loss_test: 0.005617
time: 0.2470545768737793
time: 2.2275030612945557
[1, 10596] loss_train: 0.001725, loss_test: 0.005617
time: 0.24405384063720703
time: 2.23449969291687
[1, 10597] loss_train: 0.013473, loss_test: 0.005615
time: 0.24405646324157715
time: 2.2234976291656494
[1, 10598] loss_train: 0.004028, loss_test: 0.005614
time: 0.24505400657653809
time: 2.2104949951171875
[1, 10599] loss_train: 0.009361, loss_test: 0.005615
time: 0.24248695373535156
time: 2.2375028133392334
[1, 10600] loss_train: 0.006351, loss_test: 0.005619
time: 0.2570931911468506
time: 2.251528739929199
[1, 10601] loss_train: 0.003597, loss_test: 0.005624
time: 0.24305319786071777
time: 2.2515041828155518
[1, 10602] loss_train: 0.008142, loss_test: 0.005628
time: 0.24406719207763672
time: 2.2210192680358887
[1, 10603] loss_train: 0.005668, loss_test: 0.005632
time: 0.24355864524841309
time: 2.2395005226135254
[1, 10604] loss_train: 0.000586, loss_test: 0.005635
time: 0.24505400657653809
time: 2.216498613357544
[1, 10605] loss_train: 0.005031, loss_test: 0.005637
time: 0.2440650463104248
time: 2.222496509552002
[1, 10606] loss_train: 0.006367, loss_test: 0.005638
time: 0.24407219886779785
time: 2.249020576477051
[1, 10607] loss_train: 0.002494, loss_test: 0.005638
time: 0.2470550537109375
time: 2.273508310317993
[1, 10608] loss_train: 0.012977, loss_test: 0.005641
time: 0.25005507469177246
time: 2.194491386413574
[1, 10609] loss_train: 0.002344, loss_test: 0.005643
time: 0.24870514869689941
time: 2.221499443054199
[1, 10610] loss_train: 0.005522, loss_test: 0.005645
time: 0.25905680656433105
time: 2.255505084991455
[1, 10611] loss_train: 0.014360, loss_test: 0.005647
time: 0.25705718994140625
time: 2.2340526580810547
[1, 10612] loss_train: 0.007349, loss_test: 0.005650
time: 0.2450542449951172
time: 2.2084944248199463
[1, 10613] loss_train: 0.001887, loss_test: 0.005648
time: 0.24805521965026855
time: 2.2164978981018066
[1, 10614] loss_train: 0.003870, loss_test: 0.005646
time: 0.24405455589294434
time: 2.226527214050293
[1, 10615] loss_train: 0.020407, loss_test: 0.005644
time: 0.24305462837219238
time: 2.231001615524292
[1, 10616] loss_train: 0.004704, loss_test: 0.005643
time: 0.24505376815795898
time: 2.2345004081726074
[1, 10617] loss_train: 0.006708, loss_test: 0.005645
time: 0.2490556240081787
time: 2.20949387550354
[1, 10618] loss_train: 0.007323, loss_test: 0.005649
time: 0.24407124519348145
time: 2.2144947052001953
[1, 10619] loss_train: 0.007671, loss_test: 0.005650
time: 0.24506759643554688
time: 2.2245514392852783
[1, 10620] loss_train: 0.007223, loss_test: 0.005653
time: 0.2560563087463379
time: 2.2585055828094482
[1, 10621] loss_train: 0.004032, loss_test: 0.005655
time: 0.24505400657653809
time: 2.244502305984497
[1, 10622] loss_train: 0.001810, loss_test: 0.005659
time: 0.2450542449951172
time: 2.245004653930664
[1, 10623] loss_train: 0.010564, loss_test: 0.005660
time: 0.2450559139251709
time: 2.2094929218292236
[1, 10624] loss_train: 0.009689, loss_test: 0.005656
time: 0.24405455589294434
time: 2.170485258102417
[1, 10625] loss_train: 0.005860, loss_test: 0.005654
time: 0.24505400657653809
time: 2.2470319271087646
[1, 10626] loss_train: 0.010637, loss_test: 0.005651
time: 0.24406814575195312
time: 2.196366548538208
[1, 10627] loss_train: 0.003179, loss_test: 0.005649
time: 0.24405431747436523
time: 2.2415010929107666
[1, 10628] loss_train: 0.006278, loss_test: 0.005645
time: 0.2490558624267578
time: 2.203507423400879
[1, 10629] loss_train: 0.008204, loss_test: 0.005641
time: 0.2450542449951172
time: 2.2114946842193604
[1, 10630] loss_train: 0.005693, loss_test: 0.005642
time: 0.25905752182006836
time: 2.2465028762817383
[1, 10631] loss_train: 0.003052, loss_test: 0.005644
time: 0.2480487823486328
time: 2.269533157348633
[1, 10632] loss_train: 0.005266, loss_test: 0.005647
time: 0.2470543384552002
time: 2.217496395111084
[1, 10633] loss_train: 0.002879, loss_test: 0.005650
time: 0.24405407905578613
time: 2.207524061203003
[1, 10634] loss_train: 0.013530, loss_test: 0.005648
time: 0.24305343627929688
time: 2.2224977016448975
[1, 10635] loss_train: 0.008993, loss_test: 0.005646
time: 0.24405360221862793
time: 2.218560218811035
[1, 10636] loss_train: 0.006218, loss_test: 0.005646
time: 0.24405431747436523
time: 2.2340030670166016
[1, 10637] loss_train: 0.004743, loss_test: 0.005647
time: 0.24405455589294434
time: 2.2254974842071533
[1, 10638] loss_train: 0.001583, loss_test: 0.005644
time: 0.2470550537109375
time: 2.2034950256347656
[1, 10639] loss_train: 0.004615, loss_test: 0.005643
time: 0.24405384063720703
time: 2.244502544403076
[1, 10640] loss_train: 0.001656, loss_test: 0.005641
time: 0.256056547164917
time: 2.252504348754883
[1, 10641] loss_train: 0.004536, loss_test: 0.005642
time: 0.24605488777160645
time: 2.2555038928985596
[1, 10642] loss_train: 0.005615, loss_test: 0.005642
time: 0.24405479431152344
time: 2.2445015907287598
[1, 10643] loss_train: 0.004873, loss_test: 0.005643
time: 0.24205422401428223
time: 2.2298450469970703
[1, 10644] loss_train: 0.006014, loss_test: 0.005648
time: 0.24605488777160645
time: 2.2385005950927734
[1, 10645] loss_train: 0.004775, loss_test: 0.005655
time: 0.24406743049621582
time: 2.1975090503692627
[1, 10646] loss_train: 0.004868, loss_test: 0.005666
time: 0.24305367469787598
time: 2.225497245788574
[1, 10647] loss_train: 0.008274, loss_test: 0.005670
time: 0.24505400657653809
time: 2.208505868911743
[1, 10648] loss_train: 0.004700, loss_test: 0.005676
time: 0.24405384063720703
time: 2.205493450164795
[1, 10649] loss_train: 0.003682, loss_test: 0.005683
time: 0.2490682601928711
time: 2.2435176372528076
[1, 10650] loss_train: 0.000751, loss_test: 0.005691
time: 0.2580578327178955
time: 2.268507242202759
[1, 10651] loss_train: 0.007283, loss_test: 0.005694
time: 0.25005578994750977
time: 2.248502492904663
[1, 10652] loss_train: 0.010020, loss_test: 0.005691
time: 0.24405431747436523
time: 2.2234973907470703
[1, 10653] loss_train: 0.007571, loss_test: 0.005688
time: 0.2490551471710205
time: 2.1904897689819336
[1, 10654] loss_train: 0.011799, loss_test: 0.005682
time: 0.24405431747436523
time: 2.2014923095703125
[1, 10655] loss_train: 0.016423, loss_test: 0.005678
time: 0.24405407905578613
time: 2.2144956588745117
[1, 10656] loss_train: 0.019104, loss_test: 0.005683
time: 0.24305438995361328
time: 2.1985015869140625
[1, 10657] loss_train: 0.005205, loss_test: 0.005700
time: 0.24305367469787598
time: 2.217496156692505
[1, 10658] loss_train: 0.004120, loss_test: 0.005710
time: 0.24405360221862793
time: 2.1855125427246094
[1, 10659] loss_train: 0.004758, loss_test: 0.005707
time: 0.24305438995361328
time: 2.2154951095581055
[1, 10660] loss_train: 0.005697, loss_test: 0.005691
time: 0.25705671310424805
time: 2.283165454864502
[1, 10661] loss_train: 0.002972, loss_test: 0.005675
time: 0.24558210372924805
time: 2.224501371383667
[1, 10662] loss_train: 0.007690, loss_test: 0.005656
time: 0.24605417251586914
time: 2.23850154876709
[1, 10663] loss_train: 0.006125, loss_test: 0.005646
time: 0.24205279350280762
time: 2.217496395111084
[1, 10664] loss_train: 0.000587, loss_test: 0.005647
time: 0.24505376815795898
time: 2.2274985313415527
[1, 10665] loss_train: 0.004837, loss_test: 0.005660
time: 0.24605464935302734
time: 2.244502305984497
[1, 10666] loss_train: 0.013252, loss_test: 0.005680
time: 0.25005578994750977
time: 2.2415010929107666
[1, 10667] loss_train: 0.006252, loss_test: 0.005698
time: 0.24405384063720703
time: 2.2224974632263184
[1, 10668] loss_train: 0.013812, loss_test: 0.005707
time: 0.2490549087524414
time: 2.2285404205322266
[1, 10669] loss_train: 0.004788, loss_test: 0.005715
time: 0.2450544834136963
time: 2.2055504322052
[1, 10670] loss_train: 0.003186, loss_test: 0.005723
time: 0.25705695152282715
time: 2.2335000038146973
[1, 10671] loss_train: 0.007658, loss_test: 0.005716
time: 0.24505376815795898
time: 2.220506429672241
[1, 10672] loss_train: 0.003797, loss_test: 0.005704
time: 0.24606752395629883
time: 2.2230021953582764
[1, 10673] loss_train: 0.006406, loss_test: 0.005687
time: 0.24405360221862793
time: 2.22607421875
[1, 10674] loss_train: 0.000608, loss_test: 0.005677
time: 0.24405384063720703
time: 2.2345006465911865
[1, 10675] loss_train: 0.002531, loss_test: 0.005671
time: 0.24405360221862793
time: 2.2375006675720215
[1, 10676] loss_train: 0.000664, loss_test: 0.005670
time: 0.24405384063720703
time: 2.2189455032348633
[1, 10677] loss_train: 0.006867, loss_test: 0.005667
time: 0.24205374717712402
time: 2.2124946117401123
[1, 10678] loss_train: 0.001973, loss_test: 0.005667
time: 0.24305438995361328
time: 2.245532274246216
[1, 10679] loss_train: 0.003830, loss_test: 0.005668
time: 0.24405455589294434
time: 2.218496322631836
[1, 10680] loss_train: 0.009285, loss_test: 0.005666
time: 0.2560570240020752
time: 2.2425012588500977
[1, 10681] loss_train: 0.000926, loss_test: 0.005667
time: 0.24405455589294434
time: 2.2135040760040283
[1, 10682] loss_train: 0.008591, loss_test: 0.005658
time: 0.24605536460876465
time: 2.2274975776672363
[1, 10683] loss_train: 0.005218, loss_test: 0.005650
time: 0.24505376815795898
time: 2.240501642227173
[1, 10684] loss_train: 0.001770, loss_test: 0.005645
time: 0.24506211280822754
time: 2.204493284225464
[1, 10685] loss_train: 0.001439, loss_test: 0.005643
time: 0.25005578994750977
time: 2.2385008335113525
[1, 10686] loss_train: 0.002535, loss_test: 0.005646
time: 0.24605393409729004
time: 2.24302077293396
[1, 10687] loss_train: 0.003752, loss_test: 0.005650
time: 0.2490546703338623
time: 2.231499433517456
[1, 10688] loss_train: 0.009581, loss_test: 0.005659
time: 0.245070219039917
time: 2.2455198764801025
[1, 10689] loss_train: 0.005712, loss_test: 0.005659
time: 0.2470552921295166
time: 2.2405011653900146
[1, 10690] loss_train: 0.003647, loss_test: 0.005658
time: 0.2581038475036621
time: 2.24212646484375
[1, 10691] loss_train: 0.010142, loss_test: 0.005653
time: 0.24905157089233398
time: 2.2405011653900146
[1, 10692] loss_train: 0.019684, loss_test: 0.005643
time: 0.24605441093444824
time: 2.2115046977996826
[1, 10693] loss_train: 0.004534, loss_test: 0.005642
time: 0.24305391311645508
time: 2.2305119037628174
[1, 10694] loss_train: 0.012460, loss_test: 0.005645
time: 0.24505376815795898
time: 2.1984918117523193
[1, 10695] loss_train: 0.005649, loss_test: 0.005653
time: 0.2450547218322754
time: 2.2385129928588867
[1, 10696] loss_train: 0.009191, loss_test: 0.005667
time: 0.24405407905578613
time: 2.2114949226379395
[1, 10697] loss_train: 0.009016, loss_test: 0.005675
time: 0.2440638542175293
time: 2.2124946117401123
[1, 10698] loss_train: 0.013543, loss_test: 0.005674
time: 0.24405360221862793
time: 2.2345244884490967
[1, 10699] loss_train: 0.005387, loss_test: 0.005677
time: 0.24492835998535156
time: 2.227498769760132
[1, 10700] loss_train: 0.010738, loss_test: 0.005677
time: 0.25406980514526367
time: 2.2232537269592285
[1, 10701] loss_train: 0.007682, loss_test: 0.005673
time: 0.2450547218322754
time: 2.2405009269714355
[1, 10702] loss_train: 0.014150, loss_test: 0.005670
time: 0.24505400657653809
time: 2.2365007400512695
[1, 10703] loss_train: 0.008693, loss_test: 0.005676
time: 0.24305415153503418
time: 2.2165074348449707
[1, 10704] loss_train: 0.002019, loss_test: 0.005675
time: 0.24605488777160645
time: 2.211493968963623
[1, 10705] loss_train: 0.001449, loss_test: 0.005671
time: 0.2450542449951172
time: 2.2113795280456543
[1, 10706] loss_train: 0.004943, loss_test: 0.005661
time: 0.25005578994750977
time: 2.2014923095703125
[1, 10707] loss_train: 0.010190, loss_test: 0.005656
time: 0.24405360221862793
time: 2.2024929523468018
[1, 10708] loss_train: 0.003017, loss_test: 0.005652
time: 0.24305438995361328
time: 2.192518949508667
[1, 10709] loss_train: 0.005922, loss_test: 0.005650
time: 0.2470548152923584
time: 2.2185003757476807
[1, 10710] loss_train: 0.004373, loss_test: 0.005649
time: 0.25505638122558594
time: 2.241501569747925
[1, 10711] loss_train: 0.005982, loss_test: 0.005651
time: 0.2470555305480957
time: 2.226339340209961
[1, 10712] loss_train: 0.009149, loss_test: 0.005655
time: 0.24805474281311035
time: 2.2385008335113525
[1, 10713] loss_train: 0.005357, loss_test: 0.005659
time: 0.24805545806884766
time: 2.2004923820495605
[1, 10714] loss_train: 0.006423, loss_test: 0.005662
time: 0.24505400657653809
time: 2.2143430709838867
[1, 10715] loss_train: 0.005219, loss_test: 0.005666
time: 0.2450547218322754
time: 2.220440626144409
[1, 10716] loss_train: 0.004140, loss_test: 0.005665
time: 0.24305367469787598
time: 2.208547353744507
[1, 10717] loss_train: 0.007197, loss_test: 0.005663
time: 0.24305343627929688
time: 2.237499237060547
[1, 10718] loss_train: 0.006020, loss_test: 0.005663
time: 0.24605512619018555
time: 2.219496488571167
[1, 10719] loss_train: 0.006739, loss_test: 0.005661
time: 0.25005483627319336
time: 2.212045907974243
[1, 10720] loss_train: 0.003713, loss_test: 0.005660
time: 0.2580568790435791
time: 2.266507148742676
[1, 10721] loss_train: 0.006167, loss_test: 0.005659
time: 0.2511136531829834
time: 2.2244973182678223
[1, 10722] loss_train: 0.006104, loss_test: 0.005659
time: 0.24605441093444824
time: 2.2375001907348633
[1, 10723] loss_train: 0.004868, loss_test: 0.005658
time: 0.24805569648742676
time: 2.2174952030181885
[1, 10724] loss_train: 0.011591, loss_test: 0.005650
time: 0.24405455589294434
time: 2.2405128479003906
[1, 10725] loss_train: 0.002422, loss_test: 0.005646
time: 0.2470543384552002
time: 2.2134974002838135
[1, 10726] loss_train: 0.008168, loss_test: 0.005644
time: 0.24405527114868164
time: 2.214495897293091
[1, 10727] loss_train: 0.011072, loss_test: 0.005641
time: 0.24405336380004883
time: 2.2184975147247314
[1, 10728] loss_train: 0.009718, loss_test: 0.005635
time: 0.24405431747436523
time: 2.2274985313415527
[1, 10729] loss_train: 0.009971, loss_test: 0.005633
time: 0.24405407905578613
time: 2.1800694465637207
[1, 10730] loss_train: 0.003285, loss_test: 0.005639
time: 0.25705718994140625
time: 2.232499122619629
[1, 10731] loss_train: 0.013765, loss_test: 0.005646
time: 0.2450547218322754
time: 2.2284984588623047
[1, 10732] loss_train: 0.004510, loss_test: 0.005653
time: 0.24406671524047852
time: 2.2204973697662354
[1, 10733] loss_train: 0.010052, loss_test: 0.005666
time: 0.24405431747436523
time: 2.2004923820495605
[1, 10734] loss_train: 0.003460, loss_test: 0.005681
time: 0.2510550022125244
time: 2.206496238708496
[1, 10735] loss_train: 0.002857, loss_test: 0.005684
time: 0.24407291412353516
time: 2.2425222396850586
[1, 10736] loss_train: 0.003630, loss_test: 0.005682
time: 0.2490549087524414
time: 2.216022491455078
[1, 10737] loss_train: 0.004860, loss_test: 0.005663
time: 0.24405407905578613
time: 2.2425014972686768
[1, 10738] loss_train: 0.009038, loss_test: 0.005648
time: 0.2470555305480957
time: 2.2425010204315186
[1, 10739] loss_train: 0.002328, loss_test: 0.005629
time: 0.2450544834136963
time: 2.25101637840271
[1, 10740] loss_train: 0.006085, loss_test: 0.005616
time: 0.2580578327178955
time: 2.2405014038085938
[1, 10741] loss_train: 0.006370, loss_test: 0.005610
time: 0.24405455589294434
time: 2.217495918273926
[1, 10742] loss_train: 0.001221, loss_test: 0.005614
time: 0.2470548152923584
time: 2.2355000972747803
[1, 10743] loss_train: 0.003631, loss_test: 0.005629
time: 0.2470545768737793
time: 2.2025039196014404
[1, 10744] loss_train: 0.001588, loss_test: 0.005651
time: 0.2470552921295166
time: 2.219496011734009
[1, 10745] loss_train: 0.005489, loss_test: 0.005678
time: 0.24605441093444824
time: 2.2285008430480957
[1, 10746] loss_train: 0.003337, loss_test: 0.005707
time: 0.24405264854431152
time: 2.2215051651000977
[1, 10747] loss_train: 0.005826, loss_test: 0.005735
time: 0.24405431747436523
time: 2.1844887733459473
[1, 10748] loss_train: 0.006949, loss_test: 0.005762
time: 0.24605393409729004
time: 2.218496799468994
[1, 10749] loss_train: 0.006140, loss_test: 0.005776
time: 0.2430570125579834
time: 2.2200214862823486
[1, 10750] loss_train: 0.007313, loss_test: 0.005758
time: 0.2540559768676758
time: 2.2575056552886963
[1, 10751] loss_train: 0.012173, loss_test: 0.005699
time: 0.24505376815795898
time: 2.2204971313476562
[1, 10752] loss_train: 0.011389, loss_test: 0.005647
time: 0.24405384063720703
time: 2.2335023880004883
[1, 10753] loss_train: 0.009847, loss_test: 0.005628
time: 0.24405336380004883
time: 2.2244977951049805
[1, 10754] loss_train: 0.013212, loss_test: 0.005630
time: 0.24805521965026855
time: 2.2234973907470703
[1, 10755] loss_train: 0.008412, loss_test: 0.005640
time: 0.2490553855895996
time: 2.237548351287842
[1, 10756] loss_train: 0.004148, loss_test: 0.005652
time: 0.2450542449951172
time: 2.2224974632263184
[1, 10757] loss_train: 0.004678, loss_test: 0.005658
time: 0.2490673065185547
time: 2.2094945907592773
[1, 10758] loss_train: 0.003621, loss_test: 0.005660
time: 0.24605417251586914
time: 2.207494020462036
[1, 10759] loss_train: 0.004715, loss_test: 0.005655
time: 0.24305367469787598
time: 2.202019214630127
[1, 10760] loss_train: 0.008203, loss_test: 0.005649
time: 0.256056547164917
time: 2.262509822845459
[1, 10761] loss_train: 0.005420, loss_test: 0.005643
time: 0.24505376815795898
time: 2.2244975566864014
[1, 10762] loss_train: 0.003116, loss_test: 0.005632
time: 0.24305319786071777
time: 2.253504514694214
[1, 10763] loss_train: 0.001894, loss_test: 0.005620
time: 0.2450544834136963
time: 2.2445082664489746
[1, 10764] loss_train: 0.008941, loss_test: 0.005616
time: 0.2470686435699463
time: 2.233499765396118
[1, 10765] loss_train: 0.001710, loss_test: 0.005621
time: 0.24405384063720703
time: 2.2134954929351807
[1, 10766] loss_train: 0.004733, loss_test: 0.005640
time: 0.2450542449951172
time: 2.219498872756958
[1, 10767] loss_train: 0.005055, loss_test: 0.005666
time: 0.24305343627929688
time: 2.2274985313415527
[1, 10768] loss_train: 0.008511, loss_test: 0.005694
time: 0.24405407905578613
time: 2.2324717044830322
[1, 10769] loss_train: 0.002945, loss_test: 0.005724
time: 0.24405455589294434
time: 2.2165255546569824
[1, 10770] loss_train: 0.001743, loss_test: 0.005760
time: 0.25705671310424805
time: 2.2325000762939453
[1, 10771] loss_train: 0.004679, loss_test: 0.005788
time: 0.24405431747436523
time: 2.2004919052124023
[1, 10772] loss_train: 0.005969, loss_test: 0.005812
time: 0.2470545768737793
time: 2.255504846572876
[1, 10773] loss_train: 0.004474, loss_test: 0.005829
time: 0.2450549602508545
time: 2.226513147354126
[1, 10774] loss_train: 0.008368, loss_test: 0.005824
time: 0.2510688304901123
time: 2.217496156692505
[1, 10775] loss_train: 0.015377, loss_test: 0.005815
time: 0.24606800079345703
time: 2.1974916458129883
[1, 10776] loss_train: 0.003730, loss_test: 0.005811
time: 0.24805545806884766
time: 2.215855360031128
[1, 10777] loss_train: 0.006593, loss_test: 0.005807
time: 0.24305343627929688
time: 2.2335002422332764
[1, 10778] loss_train: 0.001693, loss_test: 0.005808
time: 0.24405360221862793
time: 2.2110097408294678
[1, 10779] loss_train: 0.010858, loss_test: 0.005797
time: 0.24305367469787598
time: 2.2230119705200195
[1, 10780] loss_train: 0.003483, loss_test: 0.005791
time: 0.25606799125671387
time: 2.273524522781372
[1, 10781] loss_train: 0.001581, loss_test: 0.005780
time: 0.24406719207763672
time: 2.243501901626587
[1, 10782] loss_train: 0.001793, loss_test: 0.005763
time: 0.24405336380004883
time: 2.2144954204559326
[1, 10783] loss_train: 0.007973, loss_test: 0.005737
time: 0.2440810203552246
time: 2.220496416091919
[1, 10784] loss_train: 0.009998, loss_test: 0.005710
time: 0.24706792831420898
time: 2.2410945892333984
[1, 10785] loss_train: 0.013672, loss_test: 0.005654
time: 0.24305462837219238
time: 2.233499050140381
[1, 10786] loss_train: 0.003253, loss_test: 0.005634
time: 0.243088960647583
time: 2.210505962371826
[1, 10787] loss_train: 0.010407, loss_test: 0.005642
time: 0.24405479431152344
time: 2.220496416091919
[1, 10788] loss_train: 0.006459, loss_test: 0.005670
time: 0.24505400657653809
time: 2.2135140895843506
[1, 10789] loss_train: 0.008321, loss_test: 0.005701
time: 0.24305343627929688
time: 2.2140085697174072
[1, 10790] loss_train: 0.004149, loss_test: 0.005715
time: 0.25705647468566895
time: 2.23650860786438
[1, 10791] loss_train: 0.015132, loss_test: 0.005719
time: 0.25205540657043457
time: 2.2465028762817383
[1, 10792] loss_train: 0.007361, loss_test: 0.005704
time: 0.24405384063720703
time: 2.235499620437622
[1, 10793] loss_train: 0.008261, loss_test: 0.005686
time: 0.2510561943054199
time: 2.1924898624420166
[1, 10794] loss_train: 0.004458, loss_test: 0.005675
time: 0.2470552921295166
time: 2.2280142307281494
[1, 10795] loss_train: 0.000714, loss_test: 0.005670
time: 0.25005578994750977
time: 2.2304985523223877
[1, 10796] loss_train: 0.000985, loss_test: 0.005662
time: 0.2450547218322754
time: 2.2230522632598877
[1, 10797] loss_train: 0.006467, loss_test: 0.005661
time: 0.24305391311645508
time: 2.2595055103302
[1, 10798] loss_train: 0.005239, loss_test: 0.005670
time: 0.2440502643585205
time: 2.244028091430664
[1, 10799] loss_train: 0.004750, loss_test: 0.005683
time: 0.24405431747436523
time: 2.237499713897705
[1, 10800] loss_train: 0.010457, loss_test: 0.005688
time: 0.2560698986053467
time: 2.2755088806152344
[1, 10801] loss_train: 0.004987, loss_test: 0.005691
time: 0.24405431747436523
time: 2.223339080810547
[1, 10802] loss_train: 0.009898, loss_test: 0.005684
time: 0.24506711959838867
time: 2.1924901008605957
[1, 10803] loss_train: 0.008874, loss_test: 0.005672
time: 0.24405670166015625
time: 2.2435009479522705
[1, 10804] loss_train: 0.012556, loss_test: 0.005651
time: 0.2470550537109375
time: 2.2030303478240967
[1, 10805] loss_train: 0.010369, loss_test: 0.005635
time: 0.24605417251586914
time: 2.205493688583374
[1, 10806] loss_train: 0.004939, loss_test: 0.005628
time: 0.24305367469787598
time: 2.192426919937134
[1, 10807] loss_train: 0.006533, loss_test: 0.005631
time: 0.24405550956726074
time: 2.2174954414367676
[1, 10808] loss_train: 0.004271, loss_test: 0.005642
time: 0.24405360221862793
time: 2.1984918117523193
[1, 10809] loss_train: 0.007249, loss_test: 0.005651
time: 0.2450547218322754
time: 2.2254977226257324
[1, 10810] loss_train: 0.003966, loss_test: 0.005654
time: 0.26006317138671875
time: 2.250505208969116
[1, 10811] loss_train: 0.002372, loss_test: 0.005651
time: 0.2470545768737793
time: 2.2355003356933594
[1, 10812] loss_train: 0.008844, loss_test: 0.005647
time: 0.2490553855895996
time: 2.2425014972686768
[1, 10813] loss_train: 0.004437, loss_test: 0.005639
time: 0.24506664276123047
time: 2.1854891777038574
[1, 10814] loss_train: 0.016585, loss_test: 0.005633
time: 0.24805545806884766
time: 2.2024924755096436
[1, 10815] loss_train: 0.003486, loss_test: 0.005628
time: 0.24205350875854492
time: 2.2004923820495605
[1, 10816] loss_train: 0.003069, loss_test: 0.005625
time: 0.24305438995361328
time: 2.2105231285095215
[1, 10817] loss_train: 0.005652, loss_test: 0.005625
time: 0.24405455589294434
time: 2.2114973068237305
[1, 10818] loss_train: 0.004696, loss_test: 0.005626
time: 0.24305438995361328
time: 2.1904683113098145
[1, 10819] loss_train: 0.002406, loss_test: 0.005629
time: 0.24305367469787598
time: 2.1954915523529053
[1, 10820] loss_train: 0.005736, loss_test: 0.005633
time: 0.25505685806274414
time: 2.242504119873047
[1, 10821] loss_train: 0.006925, loss_test: 0.005639
time: 0.24805545806884766
time: 2.2174956798553467
[1, 10822] loss_train: 0.003296, loss_test: 0.005648
time: 0.24605464935302734
time: 2.2325022220611572
[1, 10823] loss_train: 0.002583, loss_test: 0.005659
time: 0.24605417251586914
time: 2.203493118286133
[1, 10824] loss_train: 0.004954, loss_test: 0.005670
time: 0.24508094787597656
time: 2.2150015830993652
[1, 10825] loss_train: 0.001453, loss_test: 0.005683
time: 0.2490553855895996
time: 2.238502264022827
[1, 10826] loss_train: 0.003904, loss_test: 0.005696
time: 0.24405431747436523
time: 2.2175235748291016
[1, 10827] loss_train: 0.008976, loss_test: 0.005698
time: 0.2470543384552002
time: 2.207005500793457
[1, 10828] loss_train: 0.005221, loss_test: 0.005698
time: 0.24305319786071777
time: 2.2094972133636475
[1, 10829] loss_train: 0.009959, loss_test: 0.005697
time: 0.24707913398742676
time: 2.2178666591644287
[1, 10830] loss_train: 0.001407, loss_test: 0.005697
time: 0.25505638122558594
time: 2.2575056552886963
[1, 10831] loss_train: 0.004041, loss_test: 0.005700
time: 0.24305319786071777
time: 2.2535040378570557
[1, 10832] loss_train: 0.005583, loss_test: 0.005687
time: 0.24405407905578613
time: 2.2385008335113525
[1, 10833] loss_train: 0.009308, loss_test: 0.005668
time: 0.24305391311645508
time: 2.206998348236084
[1, 10834] loss_train: 0.000726, loss_test: 0.005657
time: 0.24305343627929688
time: 2.2335000038146973
[1, 10835] loss_train: 0.003830, loss_test: 0.005649
time: 0.24608254432678223
time: 2.2320005893707275
[1, 10836] loss_train: 0.008728, loss_test: 0.005644
time: 0.24605393409729004
time: 2.2224977016448975
[1, 10837] loss_train: 0.010487, loss_test: 0.005643
time: 0.24305462837219238
time: 2.2435362339019775
[1, 10838] loss_train: 0.002150, loss_test: 0.005645
time: 0.2450542449951172
time: 2.201420545578003
[1, 10839] loss_train: 0.006565, loss_test: 0.005649
time: 0.24405384063720703
time: 2.1938912868499756
[1, 10840] loss_train: 0.007958, loss_test: 0.005654
time: 0.25905776023864746
time: 2.2480058670043945
[1, 10841] loss_train: 0.005995, loss_test: 0.005654
time: 0.2510559558868408
time: 2.2165091037750244
[1, 10842] loss_train: 0.009707, loss_test: 0.005651
time: 0.2470543384552002
time: 2.234499931335449
[1, 10843] loss_train: 0.010739, loss_test: 0.005647
time: 0.2450549602508545
time: 2.23350191116333
[1, 10844] loss_train: 0.005385, loss_test: 0.005641
time: 0.24805474281311035
time: 2.2535030841827393
[1, 10845] loss_train: 0.014275, loss_test: 0.005636
time: 0.24405431747436523
time: 2.232675313949585
[1, 10846] loss_train: 0.004092, loss_test: 0.005631
time: 0.25505733489990234
time: 2.248006582260132
[1, 10847] loss_train: 0.009700, loss_test: 0.005626
time: 0.24405479431152344
time: 2.2274978160858154
[1, 10848] loss_train: 0.010332, loss_test: 0.005621
time: 0.24605464935302734
time: 2.2294986248016357
[1, 10849] loss_train: 0.007243, loss_test: 0.005620
time: 0.24505901336669922
time: 2.2277159690856934
[1, 10850] loss_train: 0.006021, loss_test: 0.005618
time: 0.2560567855834961
time: 2.2104945182800293
[1, 10851] loss_train: 0.004356, loss_test: 0.005617
time: 0.2450547218322754
time: 2.1890647411346436
[1, 10852] loss_train: 0.006212, loss_test: 0.005616
time: 0.24406814575195312
time: 2.2134974002838135
[1, 10853] loss_train: 0.003818, loss_test: 0.005617
time: 0.24506664276123047
time: 2.2074949741363525
[1, 10854] loss_train: 0.007204, loss_test: 0.005616
time: 0.2460956573486328
time: 2.2244982719421387
[1, 10855] loss_train: 0.005473, loss_test: 0.005618
time: 0.24505400657653809
time: 2.219496965408325
[1, 10856] loss_train: 0.004564, loss_test: 0.005619
time: 0.24306535720825195
time: 2.216496706008911
[1, 10857] loss_train: 0.007276, loss_test: 0.005622
time: 0.2450547218322754
time: 2.2225148677825928
[1, 10858] loss_train: 0.010587, loss_test: 0.005626
time: 0.2450549602508545
time: 2.2274997234344482
[1, 10859] loss_train: 0.001854, loss_test: 0.005629
time: 0.254056453704834
time: 2.2616539001464844
[1, 10860] loss_train: 0.009627, loss_test: 0.005629
time: 0.2620580196380615
time: 2.2650105953216553
[1, 10861] loss_train: 0.006137, loss_test: 0.005628
time: 0.24506664276123047
time: 2.259504795074463
[1, 10862] loss_train: 0.006312, loss_test: 0.005628
time: 0.24405479431152344
time: 2.2284977436065674
[1, 10863] loss_train: 0.009625, loss_test: 0.005626
time: 0.2490556240081787
time: 2.204495906829834
[1, 10864] loss_train: 0.018528, loss_test: 0.005619
time: 0.24605441093444824
time: 2.230498790740967
[1, 10865] loss_train: 0.003729, loss_test: 0.005619
time: 0.25005388259887695
time: 2.214495897293091
[1, 10866] loss_train: 0.003631, loss_test: 0.005622
time: 0.24505376815795898
time: 2.2228405475616455
[1, 10867] loss_train: 0.006843, loss_test: 0.005622
time: 0.24605369567871094
time: 2.2170026302337646
[1, 10868] loss_train: 0.004674, loss_test: 0.005622
time: 0.24305391311645508
time: 2.2205142974853516
[1, 10869] loss_train: 0.017732, loss_test: 0.005618
time: 0.24407076835632324
time: 2.2110164165496826
[1, 10870] loss_train: 0.000884, loss_test: 0.005615
time: 0.2580578327178955
time: 2.2905118465423584
[1, 10871] loss_train: 0.002066, loss_test: 0.005614
time: 0.2450544834136963
time: 2.2375006675720215
[1, 10872] loss_train: 0.010047, loss_test: 0.005612
time: 0.2431964874267578
time: 2.2144951820373535
[1, 10873] loss_train: 0.010711, loss_test: 0.005610
time: 0.24805474281311035
time: 2.220496892929077
[1, 10874] loss_train: 0.010054, loss_test: 0.005614
time: 0.24605488777160645
time: 2.2197442054748535
[1, 10875] loss_train: 0.003272, loss_test: 0.005621
time: 0.24307823181152344
time: 2.2134954929351807
[1, 10876] loss_train: 0.002339, loss_test: 0.005629
time: 0.24606895446777344
time: 2.214015245437622
[1, 10877] loss_train: 0.003429, loss_test: 0.005637
time: 0.2440659999847412
time: 2.219496965408325
[1, 10878] loss_train: 0.006980, loss_test: 0.005645
time: 0.24305391311645508
time: 2.2114949226379395
[1, 10879] loss_train: 0.001275, loss_test: 0.005649
time: 0.24405360221862793
time: 2.2105038166046143
[1, 10880] loss_train: 0.008898, loss_test: 0.005649
time: 0.26105761528015137
time: 2.2540230751037598
[1, 10881] loss_train: 0.005345, loss_test: 0.005644
time: 0.24505400657653809
time: 2.2254979610443115
[1, 10882] loss_train: 0.004832, loss_test: 0.005637
time: 0.24909114837646484
time: 2.242502450942993
[1, 10883] loss_train: 0.003700, loss_test: 0.005634
time: 0.24505376815795898
time: 2.235499858856201
[1, 10884] loss_train: 0.003342, loss_test: 0.005633
time: 0.24805521965026855
time: 2.2154972553253174
[1, 10885] loss_train: 0.010207, loss_test: 0.005633
time: 0.2470550537109375
time: 2.2115063667297363
[1, 10886] loss_train: 0.002985, loss_test: 0.005637
time: 0.24305438995361328
time: 2.236499786376953
[1, 10887] loss_train: 0.004824, loss_test: 0.005644
time: 0.24605417251586914
time: 2.2004947662353516
[1, 10888] loss_train: 0.007263, loss_test: 0.005648
time: 0.2450549602508545
time: 2.22450590133667
[1, 10889] loss_train: 0.008950, loss_test: 0.005659
time: 0.24305391311645508
time: 2.2285146713256836
[1, 10890] loss_train: 0.006916, loss_test: 0.005667
time: 0.25531005859375
time: 2.226497173309326
[1, 10891] loss_train: 0.008273, loss_test: 0.005663
time: 0.24405527114868164
time: 2.233499526977539
[1, 10892] loss_train: 0.008723, loss_test: 0.005654
time: 0.24506616592407227
time: 2.226498603820801
[1, 10893] loss_train: 0.007563, loss_test: 0.005647
time: 0.2430565357208252
time: 2.1934943199157715
[1, 10894] loss_train: 0.006990, loss_test: 0.005638
time: 0.2470548152923584
time: 2.2680113315582275
[1, 10895] loss_train: 0.007038, loss_test: 0.005634
time: 0.24305367469787598
time: 2.228501319885254
[1, 10896] loss_train: 0.002087, loss_test: 0.005634
time: 0.24305367469787598
time: 2.2124953269958496
[1, 10897] loss_train: 0.001417, loss_test: 0.005637
time: 0.24606657028198242
time: 2.24650239944458
[1, 10898] loss_train: 0.008046, loss_test: 0.005643
time: 0.24506783485412598
time: 2.222506523132324
[1, 10899] loss_train: 0.005891, loss_test: 0.005650
time: 0.24805474281311035
time: 2.2124950885772705
[1, 10900] loss_train: 0.009805, loss_test: 0.005655
time: 0.2580571174621582
time: 2.2505037784576416
[1, 10901] loss_train: 0.006443, loss_test: 0.005657
time: 0.2520561218261719
time: 2.2185001373291016
[1, 10902] loss_train: 0.003344, loss_test: 0.005659
time: 0.24405479431152344
time: 2.2274975776672363
[1, 10903] loss_train: 0.004888, loss_test: 0.005655
time: 0.2490553855895996
time: 2.222829818725586
[1, 10904] loss_train: 0.015680, loss_test: 0.005653
time: 0.24605488777160645
time: 2.2415013313293457
[1, 10905] loss_train: 0.004707, loss_test: 0.005650
time: 0.24514532089233398
time: 2.2385008335113525
[1, 10906] loss_train: 0.010636, loss_test: 0.005651
time: 0.24506783485412598
time: 2.230011463165283
[1, 10907] loss_train: 0.008830, loss_test: 0.005643
time: 0.24505376815795898
time: 2.2300078868865967
[1, 10908] loss_train: 0.007125, loss_test: 0.005636
time: 0.24405384063720703
time: 2.2515039443969727
[1, 10909] loss_train: 0.002765, loss_test: 0.005632
time: 0.24405431747436523
time: 2.2615232467651367
[1, 10910] loss_train: 0.007576, loss_test: 0.005630
time: 0.2560575008392334
time: 2.2461116313934326
[1, 10911] loss_train: 0.018018, loss_test: 0.005630
time: 0.24405384063720703
time: 2.217496395111084
[1, 10912] loss_train: 0.001823, loss_test: 0.005629
time: 0.24505400657653809
time: 2.2264981269836426
[1, 10913] loss_train: 0.006535, loss_test: 0.005628
time: 0.24405407905578613
time: 2.245511531829834
[1, 10914] loss_train: 0.005662, loss_test: 0.005628
time: 0.24405479431152344
time: 2.2224957942962646
[1, 10915] loss_train: 0.006904, loss_test: 0.005629
time: 0.24605560302734375
time: 2.1779980659484863
[1, 10916] loss_train: 0.005230, loss_test: 0.005630
time: 0.24405384063720703
time: 2.2154958248138428
[1, 10917] loss_train: 0.006723, loss_test: 0.005629
time: 0.2450544834136963
time: 2.2024950981140137
[1, 10918] loss_train: 0.003414, loss_test: 0.005630
time: 0.24506545066833496
time: 2.230499505996704
[1, 10919] loss_train: 0.006349, loss_test: 0.005633
time: 0.2470543384552002
time: 2.221576690673828
[1, 10920] loss_train: 0.007873, loss_test: 0.005638
time: 0.2600724697113037
time: 2.2425014972686768
[1, 10921] loss_train: 0.005573, loss_test: 0.005638
time: 0.24505400657653809
time: 2.242870330810547
[1, 10922] loss_train: 0.013603, loss_test: 0.005631
time: 0.25005555152893066
time: 2.2195076942443848
[1, 10923] loss_train: 0.007311, loss_test: 0.005634
time: 0.2450551986694336
time: 2.234499454498291
[1, 10924] loss_train: 0.010661, loss_test: 0.005639
time: 0.25006890296936035
time: 2.241502046585083
[1, 10925] loss_train: 0.004396, loss_test: 0.005654
time: 0.24505400657653809
time: 2.2365024089813232
[1, 10926] loss_train: 0.004711, loss_test: 0.005668
time: 0.2490556240081787
time: 2.2144954204559326
[1, 10927] loss_train: 0.008386, loss_test: 0.005677
time: 0.24405431747436523
time: 2.2034928798675537
[1, 10928] loss_train: 0.004266, loss_test: 0.005681
time: 0.24405407905578613
time: 2.1874897480010986
[1, 10929] loss_train: 0.008378, loss_test: 0.005690
time: 0.24305438995361328
time: 2.2285284996032715
[1, 10930] loss_train: 0.003888, loss_test: 0.005688
time: 0.2540559768676758
time: 2.255504846572876
[1, 10931] loss_train: 0.003833, loss_test: 0.005677
time: 0.24405479431152344
time: 2.241501569747925
[1, 10932] loss_train: 0.006165, loss_test: 0.005666
time: 0.24405407905578613
time: 2.2315008640289307
[1, 10933] loss_train: 0.002674, loss_test: 0.005652
time: 0.24305462837219238
time: 2.232499122619629
[1, 10934] loss_train: 0.005880, loss_test: 0.005646
time: 0.24605464935302734
time: 2.242025136947632
[1, 10935] loss_train: 0.001730, loss_test: 0.005650
time: 0.24405455589294434
time: 2.199953556060791
[1, 10936] loss_train: 0.004758, loss_test: 0.005658
time: 0.24608302116394043
time: 2.1874887943267822
[1, 10937] loss_train: 0.007219, loss_test: 0.005667
time: 0.24405479431152344
time: 2.2144949436187744
[1, 10938] loss_train: 0.008273, loss_test: 0.005674
time: 0.24505400657653809
time: 2.2274982929229736
[1, 10939] loss_train: 0.010088, loss_test: 0.005671
time: 0.25005531311035156
time: 2.220017671585083
[1, 10940] loss_train: 0.007444, loss_test: 0.005667
time: 0.2560572624206543
time: 2.2505030632019043
[1, 10941] loss_train: 0.005930, loss_test: 0.005666
time: 0.25005602836608887
time: 2.237499952316284
[1, 10942] loss_train: 0.011914, loss_test: 0.005660
time: 0.24605393409729004
time: 2.221496820449829
[1, 10943] loss_train: 0.006581, loss_test: 0.005657
time: 0.24605369567871094
time: 2.240501880645752
[1, 10944] loss_train: 0.005908, loss_test: 0.005653
time: 0.24405431747436523
time: 2.2274980545043945
[1, 10945] loss_train: 0.009158, loss_test: 0.005646
time: 0.24205350875854492
time: 2.24652099609375
[1, 10946] loss_train: 0.010525, loss_test: 0.005640
time: 0.2450547218322754
time: 2.260505437850952
[1, 10947] loss_train: 0.004641, loss_test: 0.005636
time: 0.2450547218322754
time: 2.2265126705169678
[1, 10948] loss_train: 0.002417, loss_test: 0.005637
time: 0.24505400657653809
time: 2.2034924030303955
[1, 10949] loss_train: 0.004942, loss_test: 0.005640
time: 0.24405503273010254
time: 2.2235074043273926
[1, 10950] loss_train: 0.006814, loss_test: 0.005641
time: 0.25505614280700684
time: 2.2705085277557373
[1, 10951] loss_train: 0.016863, loss_test: 0.005641
time: 0.24505400657653809
time: 2.2475030422210693
[1, 10952] loss_train: 0.010089, loss_test: 0.005644
time: 0.24505400657653809
time: 2.2254998683929443
[1, 10953] loss_train: 0.005235, loss_test: 0.005644
time: 0.24405407905578613
time: 2.217496633529663
[1, 10954] loss_train: 0.014260, loss_test: 0.005644
time: 0.24405360221862793
time: 2.277509927749634
[1, 10955] loss_train: 0.004094, loss_test: 0.005641
time: 0.25305628776550293
time: 2.2575132846832275
[1, 10956] loss_train: 0.004854, loss_test: 0.005634
time: 0.26105833053588867
time: 2.282510280609131
[1, 10957] loss_train: 0.008204, loss_test: 0.005629
time: 0.24405455589294434
time: 2.274508476257324
[1, 10958] loss_train: 0.005483, loss_test: 0.005626
time: 0.2470548152923584
time: 2.2915127277374268
[1, 10959] loss_train: 0.001922, loss_test: 0.005626
time: 0.2490556240081787
time: 2.25551438331604
[1, 10960] loss_train: 0.002078, loss_test: 0.005629
time: 0.26105785369873047
time: 2.2785117626190186
[1, 10961] loss_train: 0.002541, loss_test: 0.005638
time: 0.2470543384552002
time: 2.239501476287842
[1, 10962] loss_train: 0.005858, loss_test: 0.005653
time: 0.24405479431152344
time: 2.239499568939209
[1, 10963] loss_train: 0.002754, loss_test: 0.005671
time: 0.24505400657653809
time: 2.2204971313476562
[1, 10964] loss_train: 0.009422, loss_test: 0.005682
time: 0.24806809425354004
time: 2.2114951610565186
[1, 10965] loss_train: 0.003467, loss_test: 0.005697
time: 0.24305391311645508
time: 2.2254977226257324
[1, 10966] loss_train: 0.011566, loss_test: 0.005686
time: 0.24505400657653809
time: 2.2074944972991943
[1, 10967] loss_train: 0.014525, loss_test: 0.005671
time: 0.24305319786071777
time: 2.2094945907592773
[1, 10968] loss_train: 0.003009, loss_test: 0.005658
time: 0.24405384063720703
time: 2.190490245819092
[1, 10969] loss_train: 0.007511, loss_test: 0.005642
time: 0.24405407905578613
time: 2.203004837036133
[1, 10970] loss_train: 0.009787, loss_test: 0.005626
time: 0.25505590438842773
time: 2.2224977016448975
[1, 10971] loss_train: 0.009420, loss_test: 0.005616
time: 0.24805498123168945
time: 2.191490411758423
[1, 10972] loss_train: 0.008948, loss_test: 0.005615
time: 0.2490546703338623
time: 2.2985148429870605
[1, 10973] loss_train: 0.002695, loss_test: 0.005620
time: 0.2470543384552002
time: 2.192992687225342
[1, 10974] loss_train: 0.003587, loss_test: 0.005627
time: 0.2490546703338623
time: 2.2294983863830566
[1, 10975] loss_train: 0.004092, loss_test: 0.005636
time: 0.2470555305480957
time: 2.233499050140381
[1, 10976] loss_train: 0.008448, loss_test: 0.005657
time: 0.25005507469177246
time: 2.2345001697540283
[1, 10977] loss_train: 0.008930, loss_test: 0.005675
time: 0.24305415153503418
time: 2.238025426864624
[1, 10978] loss_train: 0.010908, loss_test: 0.005681
time: 0.2463235855102539
time: 2.223496913909912
[1, 10979] loss_train: 0.008079, loss_test: 0.005680
time: 0.24405527114868164
time: 2.213494300842285
[1, 10980] loss_train: 0.012404, loss_test: 0.005672
time: 0.2540574073791504
time: 2.262009859085083
[1, 10981] loss_train: 0.009556, loss_test: 0.005655
time: 0.24306774139404297
time: 2.240544080734253
[1, 10982] loss_train: 0.007794, loss_test: 0.005641
time: 0.24406647682189941
time: 2.231499671936035
[1, 10983] loss_train: 0.005565, loss_test: 0.005630
time: 0.24405384063720703
time: 2.229498863220215
[1, 10984] loss_train: 0.011037, loss_test: 0.005625
time: 0.2470550537109375
time: 2.2096991539001465
[1, 10985] loss_train: 0.017242, loss_test: 0.005631
time: 0.24405384063720703
time: 2.2234978675842285
[1, 10986] loss_train: 0.005289, loss_test: 0.005639
time: 0.24305415153503418
time: 2.212419033050537
[1, 10987] loss_train: 0.003929, loss_test: 0.005647
time: 0.24305391311645508
time: 2.2004945278167725
[1, 10988] loss_train: 0.005957, loss_test: 0.005656
time: 0.24305391311645508
time: 2.2064921855926514
[1, 10989] loss_train: 0.015697, loss_test: 0.005663
time: 0.2470550537109375
time: 2.205493688583374
[1, 10990] loss_train: 0.008981, loss_test: 0.005674
time: 0.25905776023864746
time: 2.2419662475585938
[1, 10991] loss_train: 0.004205, loss_test: 0.005684
time: 0.2490551471710205
time: 2.2254977226257324
[1, 10992] loss_train: 0.011310, loss_test: 0.005686
time: 0.24805474281311035
time: 2.2206413745880127
[1, 10993] loss_train: 0.011784, loss_test: 0.005692
time: 0.24805521965026855
time: 2.2264981269836426
[1, 10994] loss_train: 0.019850, loss_test: 0.005712
time: 0.24605464935302734
time: 2.210503578186035
[1, 10995] loss_train: 0.005379, loss_test: 0.005737
time: 0.24408197402954102
time: 2.1984922885894775
[1, 10996] loss_train: 0.007392, loss_test: 0.005760
time: 0.24505376815795898
time: 2.2195072174072266
[1, 10997] loss_train: 0.006605, loss_test: 0.005767
time: 0.24305367469787598
time: 2.203493118286133
[1, 10998] loss_train: 0.006759, loss_test: 0.005765
time: 0.24405431747436523
time: 2.2695152759552
[1, 10999] loss_train: 0.006750, loss_test: 0.005751
time: 0.24405384063720703
time: 2.2159998416900635
[1, 11000] loss_train: 0.005152, loss_test: 0.005722
time: 0.2540562152862549
time: 2.2485039234161377
[1, 11001] loss_train: 0.013305, loss_test: 0.005693
time: 0.24405336380004883
time: 2.236499547958374
[1, 11002] loss_train: 0.007676, loss_test: 0.005662
time: 0.24306797981262207
time: 2.23249888420105
[1, 11003] loss_train: 0.009064, loss_test: 0.005643
time: 0.2490549087524414
time: 2.223496913909912
[1, 11004] loss_train: 0.009329, loss_test: 0.005635
time: 0.24305391311645508
time: 2.230529308319092
[1, 11005] loss_train: 0.005591, loss_test: 0.005629
time: 0.24305462837219238
time: 2.249009370803833
[1, 11006] loss_train: 0.003285, loss_test: 0.005625
time: 0.24305319786071777
time: 2.2345001697540283
[1, 11007] loss_train: 0.007532, loss_test: 0.005626
time: 0.24305367469787598
time: 2.202493190765381
[1, 11008] loss_train: 0.005391, loss_test: 0.005631
time: 0.24605488777160645
time: 2.2124953269958496
[1, 11009] loss_train: 0.003100, loss_test: 0.005639
time: 0.24505376815795898
time: 2.21247935295105
[1, 11010] loss_train: 0.009899, loss_test: 0.005645
time: 0.26308751106262207
time: 2.2630155086517334
[1, 11011] loss_train: 0.008696, loss_test: 0.005649
time: 0.2450556755065918
time: 2.2154979705810547
[1, 11012] loss_train: 0.006181, loss_test: 0.005651
time: 0.24805521965026855
time: 2.2254977226257324
[1, 11013] loss_train: 0.000696, loss_test: 0.005657
time: 0.2450559139251709
time: 2.2144951820373535
[1, 11014] loss_train: 0.015240, loss_test: 0.005651
time: 0.24405884742736816
time: 2.2385029792785645
[1, 11015] loss_train: 0.004928, loss_test: 0.005637
time: 0.24407243728637695
time: 2.2294979095458984
[1, 11016] loss_train: 0.008803, loss_test: 0.005624
time: 0.24305486679077148
time: 2.2505030632019043
[1, 11017] loss_train: 0.008792, loss_test: 0.005617
time: 0.24505400657653809
time: 2.228498697280884
[1, 11018] loss_train: 0.007137, loss_test: 0.005618
time: 0.24305367469787598
time: 2.2214958667755127
[1, 11019] loss_train: 0.010605, loss_test: 0.005623
time: 0.24305391311645508
time: 2.226245164871216
[1, 11020] loss_train: 0.006580, loss_test: 0.005630
time: 0.25705742835998535
time: 2.234499931335449
[1, 11021] loss_train: 0.009272, loss_test: 0.005638
time: 0.2490544319152832
time: 2.2124946117401123
[1, 11022] loss_train: 0.004051, loss_test: 0.005647
time: 0.24405503273010254
time: 2.2154958248138428
[1, 11023] loss_train: 0.002618, loss_test: 0.005656
time: 0.24305319786071777
time: 2.19649338722229
[1, 11024] loss_train: 0.005925, loss_test: 0.005658
time: 0.2450554370880127
time: 2.2385005950927734
[1, 11025] loss_train: 0.010368, loss_test: 0.005657
time: 0.2470543384552002
time: 2.197491407394409
[1, 11026] loss_train: 0.008904, loss_test: 0.005650
time: 0.2450547218322754
time: 2.2225000858306885
[1, 11027] loss_train: 0.002931, loss_test: 0.005645
time: 0.25005555152893066
time: 2.235499858856201
[1, 11028] loss_train: 0.004629, loss_test: 0.005641
time: 0.24606752395629883
time: 2.2044928073883057
[1, 11029] loss_train: 0.009503, loss_test: 0.005639
time: 0.24756455421447754
time: 2.233499765396118
[1, 11030] loss_train: 0.004454, loss_test: 0.005632
time: 0.25705766677856445
time: 2.272508144378662
[1, 11031] loss_train: 0.001386, loss_test: 0.005621
time: 0.2485671043395996
time: 2.232499837875366
[1, 11032] loss_train: 0.001894, loss_test: 0.005621
time: 0.24405479431152344
time: 2.257504463195801
[1, 11033] loss_train: 0.001767, loss_test: 0.005628
time: 0.25005483627319336
time: 2.1949946880340576
[1, 11034] loss_train: 0.004300, loss_test: 0.005638
time: 0.24605464935302734
time: 2.215494394302368
[1, 11035] loss_train: 0.003331, loss_test: 0.005652
time: 0.2450547218322754
time: 2.182488441467285
[1, 11036] loss_train: 0.008361, loss_test: 0.005665
time: 0.24805545806884766
time: 2.2060182094573975
[1, 11037] loss_train: 0.009953, loss_test: 0.005676
time: 0.2455594539642334
time: 2.284364700317383
[1, 11038] loss_train: 0.011363, loss_test: 0.005674
time: 0.24405431747436523
time: 2.2164955139160156
[1, 11039] loss_train: 0.003915, loss_test: 0.005670
time: 0.24605488777160645
time: 2.240007162094116
[1, 11040] loss_train: 0.007561, loss_test: 0.005663
time: 0.25707578659057617
time: 2.242555856704712
[1, 11041] loss_train: 0.002892, loss_test: 0.005658
time: 0.24605584144592285
time: 2.2560067176818848
[1, 11042] loss_train: 0.008375, loss_test: 0.005656
time: 0.24305391311645508
time: 2.218496322631836
[1, 11043] loss_train: 0.003937, loss_test: 0.005656
time: 0.2450542449951172
time: 2.231499433517456
[1, 11044] loss_train: 0.009850, loss_test: 0.005651
time: 0.24805450439453125
time: 2.2004966735839844
[1, 11045] loss_train: 0.004072, loss_test: 0.005646
time: 0.24405527114868164
time: 2.1975138187408447
[1, 11046] loss_train: 0.005594, loss_test: 0.005641
time: 0.24805521965026855
time: 2.2114951610565186
[1, 11047] loss_train: 0.004837, loss_test: 0.005639
time: 0.24405360221862793
time: 2.198507308959961
[1, 11048] loss_train: 0.007664, loss_test: 0.005636
time: 0.2470555305480957
time: 2.2695069313049316
[1, 11049] loss_train: 0.001794, loss_test: 0.005636
time: 0.24405407905578613
time: 2.2455027103424072
[1, 11050] loss_train: 0.006429, loss_test: 0.005636
time: 0.2600581645965576
time: 2.272026777267456
[1, 11051] loss_train: 0.013799, loss_test: 0.005629
time: 0.24606800079345703
time: 2.21050763130188
[1, 11052] loss_train: 0.006658, loss_test: 0.005625
time: 0.2470552921295166
time: 2.22650146484375
[1, 11053] loss_train: 0.003858, loss_test: 0.005623
time: 0.24405431747436523
time: 2.2099990844726562
[1, 11054] loss_train: 0.007237, loss_test: 0.005623
time: 0.24405431747436523
time: 2.2375006675720215
[1, 11055] loss_train: 0.003870, loss_test: 0.005624
time: 0.24305319786071777
time: 2.2341527938842773
[1, 11056] loss_train: 0.009028, loss_test: 0.005626
time: 0.24405407905578613
time: 2.2014923095703125
[1, 11057] loss_train: 0.004971, loss_test: 0.005630
time: 0.24305438995361328
time: 2.2480309009552
[1, 11058] loss_train: 0.005166, loss_test: 0.005631
time: 0.24305391311645508
time: 2.2365005016326904
[1, 11059] loss_train: 0.006450, loss_test: 0.005626
time: 0.24205350875854492
time: 2.1835083961486816
[1, 11060] loss_train: 0.003685, loss_test: 0.005623
time: 0.25505614280700684
time: 2.240501642227173
[1, 11061] loss_train: 0.004617, loss_test: 0.005620
time: 0.24605393409729004
time: 2.2114951610565186
[1, 11062] loss_train: 0.008649, loss_test: 0.005619
time: 0.2450549602508545
time: 2.245504140853882
[1, 11063] loss_train: 0.004255, loss_test: 0.005620
time: 0.24305367469787598
time: 2.217498540878296
[1, 11064] loss_train: 0.007691, loss_test: 0.005620
time: 0.24306702613830566
time: 2.212498188018799
[1, 11065] loss_train: 0.000891, loss_test: 0.005620
time: 0.24805426597595215
time: 2.2130191326141357
[1, 11066] loss_train: 0.004962, loss_test: 0.005621
time: 0.24605417251586914
time: 2.216496229171753
[1, 11067] loss_train: 0.004805, loss_test: 0.005620
time: 0.2490553855895996
time: 2.2385172843933105
[1, 11068] loss_train: 0.007196, loss_test: 0.005620
time: 0.2450551986694336
time: 2.218506336212158
[1, 11069] loss_train: 0.013375, loss_test: 0.005623
time: 0.24605488777160645
time: 2.211001396179199
[1, 11070] loss_train: 0.002895, loss_test: 0.005626
time: 0.2560698986053467
time: 2.2345001697540283
[1, 11071] loss_train: 0.007686, loss_test: 0.005628
time: 0.24305367469787598
time: 2.2535042762756348
[1, 11072] loss_train: 0.007849, loss_test: 0.005630
time: 0.24305367469787598
time: 2.2360050678253174
[1, 11073] loss_train: 0.007443, loss_test: 0.005629
time: 0.2440648078918457
time: 2.2064943313598633
[1, 11074] loss_train: 0.010878, loss_test: 0.005629
time: 0.24305367469787598
time: 2.241513729095459
[1, 11075] loss_train: 0.012344, loss_test: 0.005631
time: 0.2470545768737793
time: 2.216495990753174
[1, 11076] loss_train: 0.006583, loss_test: 0.005633
time: 0.24405384063720703
time: 2.197014331817627
[1, 11077] loss_train: 0.002295, loss_test: 0.005634
time: 0.24305367469787598
time: 2.217495918273926
[1, 11078] loss_train: 0.009138, loss_test: 0.005637
time: 0.24305391311645508
time: 2.235499620437622
[1, 11079] loss_train: 0.003279, loss_test: 0.005640
time: 0.2470552921295166
time: 2.2165141105651855
[1, 11080] loss_train: 0.011316, loss_test: 0.005639
time: 0.256056547164917
time: 2.2735204696655273
[1, 11081] loss_train: 0.005655, loss_test: 0.005637
time: 0.24904298782348633
time: 2.2124955654144287
[1, 11082] loss_train: 0.012652, loss_test: 0.005636
time: 0.24605512619018555
time: 2.231498956680298
[1, 11083] loss_train: 0.008093, loss_test: 0.005636
time: 0.24605584144592285
time: 2.1914901733398438
[1, 11084] loss_train: 0.003237, loss_test: 0.005637
time: 0.2490556240081787
time: 2.23349928855896
[1, 11085] loss_train: 0.009957, loss_test: 0.005638
time: 0.2450542449951172
time: 2.193504571914673
[1, 11086] loss_train: 0.002926, loss_test: 0.005639
time: 0.25005555152893066
time: 2.2150256633758545
[1, 11087] loss_train: 0.008482, loss_test: 0.005642
time: 0.24405407905578613
time: 2.253504514694214
[1, 11088] loss_train: 0.008783, loss_test: 0.005646
time: 0.2430586814880371
time: 2.260524272918701
[1, 11089] loss_train: 0.005148, loss_test: 0.005643
time: 0.2470543384552002
time: 2.264509677886963
[1, 11090] loss_train: 0.004183, loss_test: 0.005642
time: 0.2600572109222412
time: 2.2700154781341553
[1, 11091] loss_train: 0.005073, loss_test: 0.005645
time: 0.24205327033996582
time: 2.2485053539276123
[1, 11092] loss_train: 0.003784, loss_test: 0.005651
time: 0.25305724143981934
time: 2.224498748779297
[1, 11093] loss_train: 0.006395, loss_test: 0.005655
time: 0.24405384063720703
time: 2.2134954929351807
[1, 11094] loss_train: 0.001162, loss_test: 0.005666
time: 0.24406099319458008
time: 2.2134950160980225
[1, 11095] loss_train: 0.005270, loss_test: 0.005673
time: 0.24405431747436523
time: 2.203493118286133
[1, 11096] loss_train: 0.010143, loss_test: 0.005669
time: 0.24505376815795898
time: 2.2365031242370605
[1, 11097] loss_train: 0.004263, loss_test: 0.005665
time: 0.24305367469787598
time: 2.2224977016448975
[1, 11098] loss_train: 0.005897, loss_test: 0.005662
time: 0.24605512619018555
time: 2.199552297592163
[1, 11099] loss_train: 0.003944, loss_test: 0.005663
time: 0.24608087539672852
time: 2.246018886566162
[1, 11100] loss_train: 0.006558, loss_test: 0.005662
time: 0.2580575942993164
time: 2.2515056133270264
[1, 11101] loss_train: 0.008444, loss_test: 0.005657
time: 0.2470552921295166
time: 2.209007501602173
[1, 11102] loss_train: 0.002999, loss_test: 0.005653
time: 0.24305415153503418
time: 2.2244975566864014
[1, 11103] loss_train: 0.003726, loss_test: 0.005650
time: 0.24405455589294434
time: 2.235499858856201
[1, 11104] loss_train: 0.005250, loss_test: 0.005649
time: 0.24405360221862793
time: 2.2225098609924316
[1, 11105] loss_train: 0.008613, loss_test: 0.005647
time: 0.2470545768737793
time: 2.216496706008911
[1, 11106] loss_train: 0.018094, loss_test: 0.005639
time: 0.24805450439453125
time: 2.201498508453369
[1, 11107] loss_train: 0.007637, loss_test: 0.005636
time: 0.24905133247375488
time: 2.23349928855896
[1, 11108] loss_train: 0.004416, loss_test: 0.005638
time: 0.24405407905578613
time: 2.2295010089874268
[1, 11109] loss_train: 0.005924, loss_test: 0.005639
time: 0.24505400657653809
time: 2.222529649734497
[1, 11110] loss_train: 0.007608, loss_test: 0.005637
time: 0.2560567855834961
time: 2.282510280609131
[1, 11111] loss_train: 0.006264, loss_test: 0.005636
time: 0.24706745147705078
time: 2.245501756668091
[1, 11112] loss_train: 0.010378, loss_test: 0.005638
time: 0.24405360221862793
time: 2.2285008430480957
[1, 11113] loss_train: 0.007757, loss_test: 0.005636
time: 0.24405288696289062
time: 2.2455029487609863
[1, 11114] loss_train: 0.002002, loss_test: 0.005633
time: 0.24405360221862793
time: 2.2475030422210693
[1, 11115] loss_train: 0.006726, loss_test: 0.005629
time: 0.24305391311645508
time: 2.2365007400512695
[1, 11116] loss_train: 0.003625, loss_test: 0.005625
time: 0.2450549602508545
time: 2.225511312484741
[1, 11117] loss_train: 0.002481, loss_test: 0.005627
time: 0.24506711959838867
time: 2.2395007610321045
[1, 11118] loss_train: 0.005870, loss_test: 0.005618
time: 0.24305343627929688
time: 2.2120189666748047
[1, 11119] loss_train: 0.001580, loss_test: 0.005615
time: 0.24606704711914062
time: 2.2214958667755127
[1, 11120] loss_train: 0.004024, loss_test: 0.005616
time: 0.25505805015563965
time: 2.252531051635742
[1, 11121] loss_train: 0.008362, loss_test: 0.005620
time: 0.24805521965026855
time: 2.2445120811462402
[1, 11122] loss_train: 0.001186, loss_test: 0.005628
time: 0.24505400657653809
time: 2.2525038719177246
[1, 11123] loss_train: 0.005765, loss_test: 0.005639
time: 0.24605488777160645
time: 2.2044930458068848
[1, 11124] loss_train: 0.013875, loss_test: 0.005640
time: 0.24405407905578613
time: 2.2124948501586914
[1, 11125] loss_train: 0.003883, loss_test: 0.005641
time: 0.24405503273010254
time: 2.2264974117279053
[1, 11126] loss_train: 0.008281, loss_test: 0.005641
time: 0.2470552921295166
time: 2.2530760765075684
[1, 11127] loss_train: 0.002238, loss_test: 0.005644
time: 0.24405407905578613
time: 2.2184956073760986
[1, 11128] loss_train: 0.014047, loss_test: 0.005632
time: 0.24405455589294434
time: 2.231010913848877
[1, 11129] loss_train: 0.003204, loss_test: 0.005624
time: 0.24605488777160645
time: 2.220496654510498
[1, 11130] loss_train: 0.008402, loss_test: 0.005618
time: 0.26205873489379883
time: 2.2686455249786377
[1, 11131] loss_train: 0.014690, loss_test: 0.005613
time: 0.2470550537109375
time: 2.2130000591278076
[1, 11132] loss_train: 0.011648, loss_test: 0.005617
time: 0.2510554790496826
time: 2.2184982299804688
[1, 11133] loss_train: 0.015893, loss_test: 0.005631
time: 0.24506831169128418
time: 2.2134952545166016
[1, 11134] loss_train: 0.006698, loss_test: 0.005656
time: 0.24605393409729004
time: 2.2214975357055664
[1, 11135] loss_train: 0.003182, loss_test: 0.005672
time: 0.2433948516845703
time: 2.2234976291656494
[1, 11136] loss_train: 0.012801, loss_test: 0.005683
time: 0.24405336380004883
time: 2.2154955863952637
[1, 11137] loss_train: 0.010911, loss_test: 0.005681
time: 0.2420661449432373
time: 2.2185137271881104
[1, 11138] loss_train: 0.005221, loss_test: 0.005667
time: 0.24327993392944336
time: 2.2254977226257324
[1, 11139] loss_train: 0.010521, loss_test: 0.005655
time: 0.24306774139404297
time: 2.2241108417510986
[1, 11140] loss_train: 0.002629, loss_test: 0.005642
time: 0.25705718994140625
time: 2.258505344390869
[1, 11141] loss_train: 0.009392, loss_test: 0.005631
time: 0.24605417251586914
time: 2.218496799468994
[1, 11142] loss_train: 0.001952, loss_test: 0.005626
time: 0.24406766891479492
time: 2.2094948291778564
[1, 11143] loss_train: 0.005511, loss_test: 0.005631
time: 0.24305343627929688
time: 2.1994926929473877
[1, 11144] loss_train: 0.002882, loss_test: 0.005643
time: 0.24305391311645508
time: 2.205493450164795
[1, 11145] loss_train: 0.012366, loss_test: 0.005663
time: 0.24505352973937988
time: 2.218498706817627
[1, 11146] loss_train: 0.009864, loss_test: 0.005679
time: 0.2450547218322754
time: 2.213494300842285
[1, 11147] loss_train: 0.002046, loss_test: 0.005699
time: 0.2510552406311035
time: 2.243502378463745
[1, 11148] loss_train: 0.013730, loss_test: 0.005691
time: 0.24406814575195312
time: 2.236499786376953
[1, 11149] loss_train: 0.005381, loss_test: 0.005685
time: 0.24805474281311035
time: 2.2385168075561523
[1, 11150] loss_train: 0.005202, loss_test: 0.005672
time: 0.25705742835998535
time: 2.2675070762634277
[1, 11151] loss_train: 0.003304, loss_test: 0.005662
time: 0.2520561218261719
time: 2.2415010929107666
[1, 11152] loss_train: 0.001727, loss_test: 0.005654
time: 0.2450544834136963
time: 2.2365002632141113
[1, 11153] loss_train: 0.006606, loss_test: 0.005643
time: 0.2490546703338623
time: 2.2334985733032227
[1, 11154] loss_train: 0.014560, loss_test: 0.005630
time: 0.24305367469787598
time: 2.2185049057006836
[1, 11155] loss_train: 0.008353, loss_test: 0.005626
time: 0.24405455589294434
time: 2.222515106201172
[1, 11156] loss_train: 0.014673, loss_test: 0.005629
time: 0.24505400657653809
time: 2.236010789871216
[1, 11157] loss_train: 0.003345, loss_test: 0.005637
time: 0.24405431747436523
time: 2.2154955863952637
[1, 11158] loss_train: 0.010704, loss_test: 0.005654
time: 0.24405407905578613
time: 2.2264978885650635
[1, 11159] loss_train: 0.011505, loss_test: 0.005671
time: 0.2470552921295166
time: 2.2264976501464844
[1, 11160] loss_train: 0.004840, loss_test: 0.005679
time: 0.2560560703277588
time: 2.2385008335113525
[1, 11161] loss_train: 0.019910, loss_test: 0.005694
time: 0.2470684051513672
time: 2.2505030632019043
[1, 11162] loss_train: 0.003319, loss_test: 0.005690
time: 0.24436450004577637
time: 2.217495918273926
[1, 11163] loss_train: 0.011638, loss_test: 0.005677
time: 0.24707961082458496
time: 2.243502378463745
[1, 11164] loss_train: 0.002075, loss_test: 0.005671
time: 0.2450542449951172
time: 2.2595157623291016
[1, 11165] loss_train: 0.004064, loss_test: 0.005680
time: 0.24405384063720703
time: 2.194490909576416
[1, 11166] loss_train: 0.001344, loss_test: 0.005703
time: 0.24606776237487793
time: 2.2105023860931396
[1, 11167] loss_train: 0.001864, loss_test: 0.005708
time: 0.24405360221862793
time: 2.219505548477173
[1, 11168] loss_train: 0.005460, loss_test: 0.005705
time: 0.24605441093444824
time: 2.217496871948242
[1, 11169] loss_train: 0.008959, loss_test: 0.005704
time: 0.2440650463104248
time: 2.2020163536071777
[1, 11170] loss_train: 0.008274, loss_test: 0.005693
time: 0.26105737686157227
time: 2.2525064945220947
[1, 11171] loss_train: 0.004845, loss_test: 0.005683
time: 0.24205422401428223
time: 2.2495028972625732
[1, 11172] loss_train: 0.004874, loss_test: 0.005680
time: 0.24805569648742676
time: 2.2375001907348633
[1, 11173] loss_train: 0.004979, loss_test: 0.005682
time: 0.2430553436279297
time: 2.2375011444091797
[1, 11174] loss_train: 0.006146, loss_test: 0.005679
time: 0.24805521965026855
time: 2.2294986248016357
[1, 11175] loss_train: 0.012091, loss_test: 0.005666
time: 0.24405431747436523
time: 2.2655131816864014
[1, 11176] loss_train: 0.003317, loss_test: 0.005658
time: 0.2470543384552002
time: 2.2135140895843506
[1, 11177] loss_train: 0.007160, loss_test: 0.005651
time: 0.24405431747436523
time: 2.2114944458007812
[1, 11178] loss_train: 0.005397, loss_test: 0.005647
time: 0.24506759643554688
time: 2.2235214710235596
[1, 11179] loss_train: 0.008134, loss_test: 0.005646
time: 0.24305367469787598
time: 2.2341763973236084
[1, 11180] loss_train: 0.003852, loss_test: 0.005655
time: 0.258056640625
time: 2.253504753112793
[1, 11181] loss_train: 0.009578, loss_test: 0.005665
time: 0.24505376815795898
time: 2.261514186859131
[1, 11182] loss_train: 0.004215, loss_test: 0.005674
time: 0.24606633186340332
time: 2.2515037059783936
[1, 11183] loss_train: 0.008692, loss_test: 0.005685
time: 0.24405479431152344
time: 2.224496841430664
[1, 11184] loss_train: 0.007273, loss_test: 0.005684
time: 0.24405479431152344
time: 2.2900309562683105
[1, 11185] loss_train: 0.007693, loss_test: 0.005677
time: 0.24305343627929688
time: 2.2174954414367676
[1, 11186] loss_train: 0.011606, loss_test: 0.005670
time: 0.24305415153503418
time: 2.2264981269836426
[1, 11187] loss_train: 0.010697, loss_test: 0.005662
time: 0.2440657615661621
time: 2.2325000762939453
[1, 11188] loss_train: 0.005921, loss_test: 0.005655
time: 0.24505352973937988
time: 2.2075040340423584
[1, 11189] loss_train: 0.012124, loss_test: 0.005650
time: 0.24406194686889648
time: 2.2244977951049805
[1, 11190] loss_train: 0.011396, loss_test: 0.005646
time: 0.2600574493408203
time: 2.2560484409332275
[1, 11191] loss_train: 0.005527, loss_test: 0.005643
time: 0.24405407905578613
time: 2.220496416091919
[1, 11192] loss_train: 0.003714, loss_test: 0.005641
time: 0.2470552921295166
time: 2.2297370433807373
[1, 11193] loss_train: 0.004417, loss_test: 0.005636
time: 0.24305391311645508
time: 2.205493450164795
[1, 11194] loss_train: 0.024259, loss_test: 0.005634
time: 0.2450542449951172
time: 2.2180016040802
[1, 11195] loss_train: 0.006635, loss_test: 0.005634
time: 0.24921083450317383
time: 2.221497058868408
[1, 11196] loss_train: 0.004743, loss_test: 0.005632
time: 0.24405360221862793
time: 2.2184996604919434
[1, 11197] loss_train: 0.018066, loss_test: 0.005633
time: 0.2490546703338623
time: 2.2325000762939453
[1, 11198] loss_train: 0.012323, loss_test: 0.005629
time: 0.2450544834136963
time: 2.2338852882385254
[1, 11199] loss_train: 0.003775, loss_test: 0.005623
time: 0.24605441093444824
time: 2.2204971313476562
[1, 11200] loss_train: 0.002717, loss_test: 0.005621
time: 0.2560701370239258
time: 2.253539800643921
[1, 11201] loss_train: 0.003108, loss_test: 0.005617
time: 0.24805474281311035
time: 2.2365005016326904
[1, 11202] loss_train: 0.000882, loss_test: 0.005615
time: 0.24405384063720703
time: 2.203508138656616
[1, 11203] loss_train: 0.005613, loss_test: 0.005612
time: 0.24405431747436523
time: 2.1954917907714844
[1, 11204] loss_train: 0.009845, loss_test: 0.005609
time: 0.24405384063720703
time: 2.2325072288513184
[1, 11205] loss_train: 0.014115, loss_test: 0.005607
time: 0.24640393257141113
time: 2.221001386642456
[1, 11206] loss_train: 0.005517, loss_test: 0.005607
time: 0.2440662384033203
time: 2.205493927001953
[1, 11207] loss_train: 0.001774, loss_test: 0.005608
time: 0.24605536460876465
time: 2.2214958667755127
[1, 11208] loss_train: 0.001974, loss_test: 0.005609
time: 0.24805593490600586
time: 2.211496353149414
[1, 11209] loss_train: 0.001517, loss_test: 0.005607
time: 0.24305415153503418
time: 2.2254977226257324
[1, 11210] loss_train: 0.005699, loss_test: 0.005604
time: 0.25705790519714355
time: 2.231515407562256
[1, 11211] loss_train: 0.009954, loss_test: 0.005604
time: 0.2470552921295166
time: 2.256504535675049
[1, 11212] loss_train: 0.007313, loss_test: 0.005604
time: 0.24605512619018555
time: 2.2645230293273926
[1, 11213] loss_train: 0.010578, loss_test: 0.005606
time: 0.24305343627929688
time: 2.2365005016326904
[1, 11214] loss_train: 0.002250, loss_test: 0.005606
time: 0.24805569648742676
time: 2.221496343612671
[1, 11215] loss_train: 0.004869, loss_test: 0.005605
time: 0.2450547218322754
time: 2.219496011734009
[1, 11216] loss_train: 0.002678, loss_test: 0.005606
time: 0.2490551471710205
time: 2.230499744415283
[1, 11217] loss_train: 0.010079, loss_test: 0.005610
time: 0.24805474281311035
time: 2.229499101638794
[1, 11218] loss_train: 0.004163, loss_test: 0.005617
time: 0.2470543384552002
time: 2.220506429672241
[1, 11219] loss_train: 0.008527, loss_test: 0.005624
time: 0.2450544834136963
time: 2.257505416870117
[1, 11220] loss_train: 0.002959, loss_test: 0.005632
time: 0.2580568790435791
time: 2.2606451511383057
[1, 11221] loss_train: 0.002602, loss_test: 0.005642
time: 0.24605512619018555
time: 2.2385003566741943
[1, 11222] loss_train: 0.005218, loss_test: 0.005651
time: 0.24605417251586914
time: 2.260523557662964
[1, 11223] loss_train: 0.013063, loss_test: 0.005654
time: 0.2450549602508545
time: 2.2264974117279053
[1, 11224] loss_train: 0.004995, loss_test: 0.005655
time: 0.24405479431152344
time: 2.24650239944458
[1, 11225] loss_train: 0.007549, loss_test: 0.005658
time: 0.24205350875854492
time: 2.2495036125183105
[1, 11226] loss_train: 0.011665, loss_test: 0.005654
time: 0.24305343627929688
time: 2.182488203048706
[1, 11227] loss_train: 0.007906, loss_test: 0.005651
time: 0.24405503273010254
time: 2.210494041442871
[1, 11228] loss_train: 0.002011, loss_test: 0.005650
time: 0.24405360221862793
time: 2.243025302886963
[1, 11229] loss_train: 0.011430, loss_test: 0.005653
time: 0.24405527114868164
time: 2.195496082305908
[1, 11230] loss_train: 0.016917, loss_test: 0.005646
time: 0.25908613204956055
time: 2.2495017051696777
[1, 11231] loss_train: 0.004032, loss_test: 0.005641
time: 0.24605607986450195
time: 2.224497079849243
[1, 11232] loss_train: 0.009662, loss_test: 0.005631
time: 0.24405384063720703
time: 2.215496301651001
[1, 11233] loss_train: 0.008314, loss_test: 0.005626
time: 0.24305319786071777
time: 2.225001811981201
[1, 11234] loss_train: 0.004497, loss_test: 0.005623
time: 0.24305295944213867
time: 2.2335002422332764
[1, 11235] loss_train: 0.005926, loss_test: 0.005622
time: 0.24405455589294434
time: 2.2405009269714355
[1, 11236] loss_train: 0.002104, loss_test: 0.005622
time: 0.24605488777160645
time: 2.229313611984253
[1, 11237] loss_train: 0.001542, loss_test: 0.005624
time: 0.25305652618408203
time: 2.2445292472839355
[1, 11238] loss_train: 0.006496, loss_test: 0.005625
time: 0.24505400657653809
time: 2.2089977264404297
[1, 11239] loss_train: 0.001506, loss_test: 0.005626
time: 0.24805545806884766
time: 2.232541084289551
[1, 11240] loss_train: 0.006353, loss_test: 0.005630
time: 0.25505638122558594
time: 2.2525036334991455
[1, 11241] loss_train: 0.005928, loss_test: 0.005632
time: 0.24905633926391602
time: 2.2405004501342773
[1, 11242] loss_train: 0.004385, loss_test: 0.005635
time: 0.2450547218322754
time: 2.2435173988342285
[1, 11243] loss_train: 0.003472, loss_test: 0.005636
time: 0.24805545806884766
time: 2.2254974842071533
[1, 11244] loss_train: 0.006119, loss_test: 0.005636
time: 0.24405360221862793
time: 2.230499505996704
[1, 11245] loss_train: 0.010494, loss_test: 0.005631
time: 0.24405407905578613
time: 2.2275238037109375
[1, 11246] loss_train: 0.003990, loss_test: 0.005627
time: 0.24205493927001953
time: 2.2300515174865723
[1, 11247] loss_train: 0.011791, loss_test: 0.005625
time: 0.24405455589294434
time: 2.2445013523101807
[1, 11248] loss_train: 0.005261, loss_test: 0.005632
time: 0.24405384063720703
time: 2.2234978675842285
[1, 11249] loss_train: 0.002620, loss_test: 0.005642
time: 0.24305415153503418
time: 2.199491024017334
[1, 11250] loss_train: 0.001917, loss_test: 0.005652
time: 0.256056547164917
time: 2.270507335662842
[1, 11251] loss_train: 0.008175, loss_test: 0.005662
time: 0.2450547218322754
time: 2.2325069904327393
[1, 11252] loss_train: 0.004813, loss_test: 0.005664
time: 0.24306583404541016
time: 2.2294981479644775
[1, 11253] loss_train: 0.002473, loss_test: 0.005666
time: 0.24306535720825195
time: 2.235003709793091
[1, 11254] loss_train: 0.005101, loss_test: 0.005666
time: 0.24405384063720703
time: 2.216496467590332
[1, 11255] loss_train: 0.011690, loss_test: 0.005667
time: 0.24405431747436523
time: 2.219496250152588
[1, 11256] loss_train: 0.007253, loss_test: 0.005664
time: 0.24306654930114746
time: 2.2385003566741943
[1, 11257] loss_train: 0.004940, loss_test: 0.005661
time: 0.2490556240081787
time: 2.231499195098877
[1, 11258] loss_train: 0.001652, loss_test: 0.005655
time: 0.24405288696289062
time: 2.218496799468994
[1, 11259] loss_train: 0.007952, loss_test: 0.005649
time: 0.2440958023071289
time: 2.2275168895721436
[1, 11260] loss_train: 0.012675, loss_test: 0.005645
time: 0.2620584964752197
time: 2.2865116596221924
[1, 11261] loss_train: 0.007710, loss_test: 0.005637
time: 0.24605441093444824
time: 2.2144956588745117
[1, 11262] loss_train: 0.009082, loss_test: 0.005632
time: 0.24805450439453125
time: 2.215498447418213
[1, 11263] loss_train: 0.007036, loss_test: 0.005623
time: 0.24405360221862793
time: 2.216496467590332
[1, 11264] loss_train: 0.003406, loss_test: 0.005614
time: 0.2490551471710205
time: 2.2254981994628906
[1, 11265] loss_train: 0.001652, loss_test: 0.005609
time: 0.24405336380004883
time: 2.2191503047943115
[1, 11266] loss_train: 0.009323, loss_test: 0.005609
time: 0.24405479431152344
time: 2.2024917602539062
[1, 11267] loss_train: 0.009890, loss_test: 0.005616
time: 0.24305438995361328
time: 2.269507884979248
[1, 11268] loss_train: 0.005191, loss_test: 0.005629
time: 0.24306607246398926
time: 2.266508102416992
[1, 11269] loss_train: 0.002857, loss_test: 0.005651
time: 0.24305319786071777
time: 2.24802565574646
[1, 11270] loss_train: 0.005301, loss_test: 0.005671
time: 0.256056547164917
time: 2.2765092849731445
[1, 11271] loss_train: 0.006751, loss_test: 0.005689
time: 0.24405336380004883
time: 2.2385008335113525
[1, 11272] loss_train: 0.003016, loss_test: 0.005702
time: 0.24405455589294434
time: 2.223496913909912
[1, 11273] loss_train: 0.005281, loss_test: 0.005694
time: 0.2450551986694336
time: 2.2304983139038086
[1, 11274] loss_train: 0.016735, loss_test: 0.005691
time: 0.24405431747436523
time: 2.196993827819824
[1, 11275] loss_train: 0.006062, loss_test: 0.005682
time: 0.24405455589294434
time: 2.2024941444396973
[1, 11276] loss_train: 0.008999, loss_test: 0.005675
time: 0.24405431747436523
time: 2.234504222869873
[1, 11277] loss_train: 0.008079, loss_test: 0.005670
time: 0.24605464935302734
time: 2.2104949951171875
[1, 11278] loss_train: 0.009787, loss_test: 0.005662
time: 0.2430553436279297
time: 2.2184970378875732
[1, 11279] loss_train: 0.011912, loss_test: 0.005655
time: 0.24305415153503418
time: 2.1956875324249268
[1, 11280] loss_train: 0.006040, loss_test: 0.005649
time: 0.25505638122558594
time: 2.229498863220215
[1, 11281] loss_train: 0.008697, loss_test: 0.005645
time: 0.2510554790496826
time: 2.215496063232422
[1, 11282] loss_train: 0.010134, loss_test: 0.005649
time: 0.24505925178527832
time: 2.23349928855896
[1, 11283] loss_train: 0.005015, loss_test: 0.005656
time: 0.2470552921295166
time: 2.231498956680298
[1, 11284] loss_train: 0.002482, loss_test: 0.005660
time: 0.24605464935302734
time: 2.21049427986145
[1, 11285] loss_train: 0.006802, loss_test: 0.005658
time: 0.24605488777160645
time: 2.2345001697540283
[1, 11286] loss_train: 0.003021, loss_test: 0.005657
time: 0.24505829811096191
time: 2.2124950885772705
[1, 11287] loss_train: 0.006083, loss_test: 0.005662
time: 0.24505376815795898
time: 2.1894896030426025
[1, 11288] loss_train: 0.006863, loss_test: 0.005672
time: 0.2450551986694336
time: 2.2034921646118164
[1, 11289] loss_train: 0.005344, loss_test: 0.005685
time: 0.24605512619018555
time: 2.2050275802612305
[1, 11290] loss_train: 0.011219, loss_test: 0.005704
time: 0.25605273246765137
time: 2.212494373321533
[1, 11291] loss_train: 0.007241, loss_test: 0.005722
time: 0.2450549602508545
time: 2.1864888668060303
[1, 11292] loss_train: 0.008652, loss_test: 0.005720
time: 0.24607014656066895
time: 2.218496084213257
[1, 11293] loss_train: 0.007814, loss_test: 0.005704
time: 0.24605441093444824
time: 2.241501569747925
[1, 11294] loss_train: 0.003106, loss_test: 0.005682
time: 0.24605441093444824
time: 2.228498697280884
[1, 11295] loss_train: 0.001509, loss_test: 0.005669
time: 0.24405360221862793
time: 2.2125115394592285
[1, 11296] loss_train: 0.008251, loss_test: 0.005657
time: 0.2490549087524414
time: 2.2134957313537598
[1, 11297] loss_train: 0.002980, loss_test: 0.005655
time: 0.24605464935302734
time: 2.2284984588623047
[1, 11298] loss_train: 0.003680, loss_test: 0.005660
time: 0.2490551471710205
time: 2.216495990753174
[1, 11299] loss_train: 0.012401, loss_test: 0.005649
time: 0.2450549602508545
time: 2.2340216636657715
[1, 11300] loss_train: 0.007168, loss_test: 0.005645
time: 0.25505614280700684
time: 2.243501663208008
[1, 11301] loss_train: 0.001713, loss_test: 0.005651
time: 0.24207735061645508
time: 2.2224977016448975
[1, 11302] loss_train: 0.011706, loss_test: 0.005656
time: 0.24405407905578613
time: 2.2124948501586914
[1, 11303] loss_train: 0.002826, loss_test: 0.005673
time: 0.24305438995361328
time: 2.220496654510498
[1, 11304] loss_train: 0.010168, loss_test: 0.005690
time: 0.24605512619018555
time: 2.2244977951049805
[1, 11305] loss_train: 0.008008, loss_test: 0.005711
time: 0.24605441093444824
time: 2.238003730773926
[1, 11306] loss_train: 0.001008, loss_test: 0.005738
time: 0.24373507499694824
time: 2.248504638671875
[1, 11307] loss_train: 0.007343, loss_test: 0.005759
time: 0.24305486679077148
time: 2.2405006885528564
[1, 11308] loss_train: 0.004271, loss_test: 0.005744
time: 0.24305415153503418
time: 2.222499132156372
[1, 11309] loss_train: 0.003568, loss_test: 0.005732
time: 0.24305319786071777
time: 2.2150332927703857
[1, 11310] loss_train: 0.006505, loss_test: 0.005710
time: 0.25505661964416504
time: 2.228381395339966
[1, 11311] loss_train: 0.003509, loss_test: 0.005691
time: 0.2450547218322754
time: 2.221011161804199
[1, 11312] loss_train: 0.007494, loss_test: 0.005676
time: 0.25507116317749023
time: 2.237499713897705
[1, 11313] loss_train: 0.000854, loss_test: 0.005664
time: 0.24605441093444824
time: 2.1834888458251953
[1, 11314] loss_train: 0.007857, loss_test: 0.005655
time: 0.2470543384552002
time: 2.185488700866699
[1, 11315] loss_train: 0.004470, loss_test: 0.005644
time: 0.24505400657653809
time: 2.2144954204559326
[1, 11316] loss_train: 0.007297, loss_test: 0.005632
time: 0.24405479431152344
time: 2.206502914428711
[1, 11317] loss_train: 0.005071, loss_test: 0.005626
time: 0.24305438995361328
time: 2.208494186401367
[1, 11318] loss_train: 0.011677, loss_test: 0.005612
time: 0.24305367469787598
time: 2.2400152683258057
[1, 11319] loss_train: 0.015495, loss_test: 0.005609
time: 0.2470688819885254
time: 2.247520923614502
[1, 11320] loss_train: 0.004437, loss_test: 0.005626
time: 0.2560572624206543
time: 2.2505030632019043
[1, 11321] loss_train: 0.006099, loss_test: 0.005659
time: 0.24405407905578613
time: 2.207494020462036
[1, 11322] loss_train: 0.008168, loss_test: 0.005693
time: 0.24405360221862793
time: 2.241501569747925
[1, 11323] loss_train: 0.011764, loss_test: 0.005730
time: 0.24305367469787598
time: 2.1974916458129883
[1, 11324] loss_train: 0.004666, loss_test: 0.005755
time: 0.2420656681060791
time: 2.2134974002838135
[1, 11325] loss_train: 0.008627, loss_test: 0.005762
time: 0.2450542449951172
time: 2.20149302482605
[1, 11326] loss_train: 0.006224, loss_test: 0.005764
time: 0.2490677833557129
time: 2.1964941024780273
[1, 11327] loss_train: 0.002667, loss_test: 0.005716
time: 0.2450544834136963
time: 2.2415013313293457
[1, 11328] loss_train: 0.014175, loss_test: 0.005678
time: 0.24805498123168945
time: 2.229541063308716
[1, 11329] loss_train: 0.011957, loss_test: 0.005637
time: 0.24405455589294434
time: 2.219496011734009
[1, 11330] loss_train: 0.007504, loss_test: 0.005619
time: 0.25905799865722656
time: 2.2395007610321045
[1, 11331] loss_train: 0.010031, loss_test: 0.005612
time: 0.24405431747436523
time: 2.2545042037963867
[1, 11332] loss_train: 0.004191, loss_test: 0.005613
time: 0.24807071685791016
time: 2.217496395111084
[1, 11333] loss_train: 0.005613, loss_test: 0.005615
time: 0.24405407905578613
time: 2.2204971313476562
[1, 11334] loss_train: 0.010185, loss_test: 0.005618
time: 0.2450544834136963
time: 2.229060649871826
[1, 11335] loss_train: 0.016573, loss_test: 0.005618
time: 0.24305415153503418
time: 2.2165045738220215
[1, 11336] loss_train: 0.000745, loss_test: 0.005617
time: 0.24605417251586914
time: 2.2440249919891357
[1, 11337] loss_train: 0.012365, loss_test: 0.005615
time: 0.26189398765563965
time: 2.2264981269836426
[1, 11338] loss_train: 0.005183, loss_test: 0.005616
time: 0.24505400657653809
time: 2.204505205154419
[1, 11339] loss_train: 0.002832, loss_test: 0.005616
time: 0.24405431747436523
time: 2.2025039196014404
[1, 11340] loss_train: 0.005072, loss_test: 0.005615
time: 0.2580568790435791
time: 2.2535207271575928
[1, 11341] loss_train: 0.001914, loss_test: 0.005612
time: 0.24405431747436523
time: 2.2184958457946777
[1, 11342] loss_train: 0.003462, loss_test: 0.005608
time: 0.24205446243286133
time: 2.2314984798431396
[1, 11343] loss_train: 0.003376, loss_test: 0.005604
time: 0.24405455589294434
time: 2.2395005226135254
[1, 11344] loss_train: 0.001368, loss_test: 0.005601
time: 0.24405384063720703
time: 2.242502212524414
[1, 11345] loss_train: 0.005702, loss_test: 0.005602
time: 0.2445812225341797
time: 2.219496965408325
[1, 11346] loss_train: 0.006126, loss_test: 0.005606
time: 0.24605464935302734
time: 2.251521587371826
[1, 11347] loss_train: 0.013297, loss_test: 0.005610
time: 0.2470555305480957
time: 2.1924898624420166
[1, 11348] loss_train: 0.002998, loss_test: 0.005615
time: 0.2440652847290039
time: 2.2264983654022217
[1, 11349] loss_train: 0.002474, loss_test: 0.005621
time: 0.24805498123168945
time: 2.200507879257202
[1, 11350] loss_train: 0.004948, loss_test: 0.005626
time: 0.25705671310424805
time: 2.266507387161255
[1, 11351] loss_train: 0.013433, loss_test: 0.005625
time: 0.2510547637939453
time: 2.220496892929077
[1, 11352] loss_train: 0.004917, loss_test: 0.005623
time: 0.24405455589294434
time: 2.2125024795532227
[1, 11353] loss_train: 0.006611, loss_test: 0.005620
time: 0.24405407905578613
time: 2.239501714706421
[1, 11354] loss_train: 0.004398, loss_test: 0.005617
time: 0.24305295944213867
time: 2.2375004291534424
[1, 11355] loss_train: 0.003687, loss_test: 0.005617
time: 0.2450547218322754
time: 2.2695152759552
[1, 11356] loss_train: 0.000479, loss_test: 0.005619
time: 0.24605488777160645
time: 2.213013172149658
[1, 11357] loss_train: 0.008929, loss_test: 0.005622
time: 0.24305391311645508
time: 2.2204973697662354
[1, 11358] loss_train: 0.007254, loss_test: 0.005625
time: 0.24406766891479492
time: 2.2505033016204834
[1, 11359] loss_train: 0.006981, loss_test: 0.005627
time: 0.24505376815795898
time: 2.199512004852295
[1, 11360] loss_train: 0.008877, loss_test: 0.005627
time: 0.25505638122558594
time: 2.231502056121826
[1, 11361] loss_train: 0.005921, loss_test: 0.005626
time: 0.24306774139404297
time: 2.1884891986846924
[1, 11362] loss_train: 0.003940, loss_test: 0.005623
time: 0.24405384063720703
time: 2.219496965408325
[1, 11363] loss_train: 0.000500, loss_test: 0.005622
time: 0.24606752395629883
time: 2.226498603820801
[1, 11364] loss_train: 0.002863, loss_test: 0.005619
time: 0.2450542449951172
time: 2.2245020866394043
[1, 11365] loss_train: 0.005879, loss_test: 0.005618
time: 0.24504971504211426
time: 2.2465343475341797
[1, 11366] loss_train: 0.008277, loss_test: 0.005618
time: 0.2470545768737793
time: 2.2445015907287598
[1, 11367] loss_train: 0.003927, loss_test: 0.005619
time: 0.2450542449951172
time: 2.236511468887329
[1, 11368] loss_train: 0.007413, loss_test: 0.005619
time: 0.2490556240081787
time: 2.2435104846954346
[1, 11369] loss_train: 0.012078, loss_test: 0.005617
time: 0.24605488777160645
time: 2.222032308578491
[1, 11370] loss_train: 0.010253, loss_test: 0.005616
time: 0.25905752182006836
time: 2.2785098552703857
[1, 11371] loss_train: 0.005960, loss_test: 0.005616
time: 0.24506592750549316
time: 2.207494020462036
[1, 11372] loss_train: 0.010263, loss_test: 0.005615
time: 0.24805498123168945
time: 2.2385008335113525
[1, 11373] loss_train: 0.002236, loss_test: 0.005615
time: 0.2450547218322754
time: 2.222496747970581
[1, 11374] loss_train: 0.001884, loss_test: 0.005615
time: 0.24805498123168945
time: 2.1884896755218506
[1, 11375] loss_train: 0.003726, loss_test: 0.005613
time: 0.24305367469787598
time: 2.2350335121154785
[1, 11376] loss_train: 0.005260, loss_test: 0.005612
time: 0.2470545768737793
time: 2.2405014038085938
[1, 11377] loss_train: 0.004015, loss_test: 0.005611
time: 0.24305391311645508
time: 2.2175133228302
[1, 11378] loss_train: 0.004670, loss_test: 0.005612
time: 0.24405455589294434
time: 2.20849347114563
[1, 11379] loss_train: 0.006249, loss_test: 0.005614
time: 0.24405455589294434
time: 2.2285304069519043
[1, 11380] loss_train: 0.011619, loss_test: 0.005615
time: 0.25505685806274414
time: 2.2755086421966553
[1, 11381] loss_train: 0.005748, loss_test: 0.005615
time: 0.24406719207763672
time: 2.223497152328491
[1, 11382] loss_train: 0.013674, loss_test: 0.005613
time: 0.24506759643554688
time: 2.2550086975097656
[1, 11383] loss_train: 0.003466, loss_test: 0.005610
time: 0.2540562152862549
time: 2.19749116897583
[1, 11384] loss_train: 0.008035, loss_test: 0.005607
time: 0.24405312538146973
time: 2.1984922885894775
[1, 11385] loss_train: 0.006702, loss_test: 0.005604
time: 0.24505400657653809
time: 2.209505319595337
[1, 11386] loss_train: 0.006219, loss_test: 0.005601
time: 0.24405384063720703
time: 2.1954915523529053
[1, 11387] loss_train: 0.014532, loss_test: 0.005600
time: 0.25005531311035156
time: 2.220005750656128
[1, 11388] loss_train: 0.004223, loss_test: 0.005601
time: 0.2450542449951172
time: 2.212998151779175
[1, 11389] loss_train: 0.005640, loss_test: 0.005601
time: 0.24605417251586914
time: 2.235020875930786
[1, 11390] loss_train: 0.002411, loss_test: 0.005600
time: 0.2620582580566406
time: 2.247502326965332
[1, 11391] loss_train: 0.009371, loss_test: 0.005602
time: 0.24608182907104492
time: 2.214493989944458
[1, 11392] loss_train: 0.011047, loss_test: 0.005601
time: 0.2450547218322754
time: 2.2165005207061768
[1, 11393] loss_train: 0.011029, loss_test: 0.005601
time: 0.24405431747436523
time: 2.218496322631836
[1, 11394] loss_train: 0.013889, loss_test: 0.005603
time: 0.24405527114868164
time: 2.2525031566619873
[1, 11395] loss_train: 0.004882, loss_test: 0.005605
time: 0.2450547218322754
time: 2.2145066261291504
[1, 11396] loss_train: 0.009134, loss_test: 0.005609
time: 0.24355840682983398
time: 2.237499952316284
[1, 11397] loss_train: 0.005153, loss_test: 0.005609
time: 0.2510552406311035
time: 2.255505084991455
[1, 11398] loss_train: 0.008526, loss_test: 0.005610
time: 0.24805474281311035
time: 2.1894922256469727
[1, 11399] loss_train: 0.008217, loss_test: 0.005613
time: 0.24305176734924316
time: 2.2253966331481934
[1, 11400] loss_train: 0.007225, loss_test: 0.005616
time: 0.2555875778198242
time: 2.2855100631713867
[1, 11401] loss_train: 0.013442, loss_test: 0.005619
time: 0.2450556755065918
time: 2.2425012588500977
[1, 11402] loss_train: 0.004104, loss_test: 0.005621
time: 0.2490549087524414
time: 2.247008800506592
[1, 11403] loss_train: 0.009442, loss_test: 0.005624
time: 0.24405336380004883
time: 2.2024929523468018
[1, 11404] loss_train: 0.002900, loss_test: 0.005625
time: 0.24505400657653809
time: 2.204498291015625
[1, 11405] loss_train: 0.005866, loss_test: 0.005623
time: 0.24405479431152344
time: 2.2405006885528564
[1, 11406] loss_train: 0.006373, loss_test: 0.005624
time: 0.2470548152923584
time: 2.232499837875366
[1, 11407] loss_train: 0.005208, loss_test: 0.005627
time: 0.24605464935302734
time: 2.211494207382202
[1, 11408] loss_train: 0.003493, loss_test: 0.005634
time: 0.24805498123168945
time: 2.2135069370269775
[1, 11409] loss_train: 0.008113, loss_test: 0.005638
time: 0.24605512619018555
time: 2.2235162258148193
[1, 11410] loss_train: 0.002609, loss_test: 0.005644
time: 0.25905752182006836
time: 2.2445130348205566
[1, 11411] loss_train: 0.005939, loss_test: 0.005650
time: 0.24305367469787598
time: 2.216495990753174
[1, 11412] loss_train: 0.003133, loss_test: 0.005658
time: 0.24505400657653809
time: 2.242016315460205
[1, 11413] loss_train: 0.005660, loss_test: 0.005665
time: 0.24605417251586914
time: 2.2054972648620605
[1, 11414] loss_train: 0.013396, loss_test: 0.005653
time: 0.24605464935302734
time: 2.2385008335113525
[1, 11415] loss_train: 0.001770, loss_test: 0.005646
time: 0.24405360221862793
time: 2.252504348754883
[1, 11416] loss_train: 0.010526, loss_test: 0.005639
time: 0.2450544834136963
time: 2.2244973182678223
[1, 11417] loss_train: 0.007024, loss_test: 0.005633
time: 0.24405431747436523
time: 2.2645065784454346
[1, 11418] loss_train: 0.002577, loss_test: 0.005630
time: 0.24405360221862793
time: 2.2715413570404053
[1, 11419] loss_train: 0.009891, loss_test: 0.005627
time: 0.24406647682189941
time: 2.241501808166504
[1, 11420] loss_train: 0.008542, loss_test: 0.005626
time: 0.25505590438842773
time: 2.219499349594116
[1, 11421] loss_train: 0.003804, loss_test: 0.005628
time: 0.24405574798583984
time: 2.237499713897705
[1, 11422] loss_train: 0.006487, loss_test: 0.005632
time: 0.24405431747436523
time: 2.2044930458068848
[1, 11423] loss_train: 0.004910, loss_test: 0.005639
time: 0.24405431747436523
time: 2.195490837097168
[1, 11424] loss_train: 0.003077, loss_test: 0.005642
time: 0.2450542449951172
time: 2.2315027713775635
[1, 11425] loss_train: 0.011743, loss_test: 0.005643
time: 0.24305391311645508
time: 2.228498697280884
[1, 11426] loss_train: 0.005034, loss_test: 0.005640
time: 0.24305367469787598
time: 2.2110307216644287
[1, 11427] loss_train: 0.007254, loss_test: 0.005634
time: 0.2450547218322754
time: 2.2224977016448975
[1, 11428] loss_train: 0.003952, loss_test: 0.005631
time: 0.24405384063720703
time: 2.233037233352661
[1, 11429] loss_train: 0.008821, loss_test: 0.005629
time: 0.2490551471710205
time: 2.24550199508667
[1, 11430] loss_train: 0.009223, loss_test: 0.005629
time: 0.2560563087463379
time: 2.2540180683135986
[1, 11431] loss_train: 0.008903, loss_test: 0.005628
time: 0.2510559558868408
time: 2.25750470161438
[1, 11432] loss_train: 0.004307, loss_test: 0.005628
time: 0.2540559768676758
time: 2.2096314430236816
[1, 11433] loss_train: 0.014244, loss_test: 0.005633
time: 0.24805593490600586
time: 2.1794865131378174
[1, 11434] loss_train: 0.008979, loss_test: 0.005635
time: 0.24405360221862793
time: 2.2094948291778564
[1, 11435] loss_train: 0.013462, loss_test: 0.005639
time: 0.2400529384613037
time: 2.199493169784546
[1, 11436] loss_train: 0.009804, loss_test: 0.005643
time: 0.24405312538146973
time: 2.2204971313476562
[1, 11437] loss_train: 0.003530, loss_test: 0.005647
time: 0.2450547218322754
time: 2.223506212234497
[1, 11438] loss_train: 0.004054, loss_test: 0.005652
time: 0.2470543384552002
time: 2.2154958248138428
[1, 11439] loss_train: 0.006051, loss_test: 0.005655
time: 0.24205446243286133
time: 2.236499547958374
[1, 11440] loss_train: 0.012147, loss_test: 0.005658
time: 0.2560572624206543
time: 2.2154951095581055
[1, 11441] loss_train: 0.002692, loss_test: 0.005662
time: 0.24305438995361328
time: 2.225496530532837
[1, 11442] loss_train: 0.005975, loss_test: 0.005667
time: 0.24405574798583984
time: 2.210494041442871
[1, 11443] loss_train: 0.005658, loss_test: 0.005671
time: 0.24605488777160645
time: 2.2425012588500977
[1, 11444] loss_train: 0.004727, loss_test: 0.005672
time: 0.24405384063720703
time: 2.237532615661621
[1, 11445] loss_train: 0.002260, loss_test: 0.005678
time: 0.24657845497131348
time: 2.234499216079712
[1, 11446] loss_train: 0.008351, loss_test: 0.005686
time: 0.24805569648742676
time: 2.195003032684326
[1, 11447] loss_train: 0.003320, loss_test: 0.005695
time: 0.2450547218322754
time: 2.207496404647827
[1, 11448] loss_train: 0.004768, loss_test: 0.005702
time: 0.2470550537109375
time: 2.206493377685547
[1, 11449] loss_train: 0.009531, loss_test: 0.005703
time: 0.2437436580657959
time: 2.2054941654205322
[1, 11450] loss_train: 0.005396, loss_test: 0.005703
time: 0.2560567855834961
time: 2.2535042762756348
[1, 11451] loss_train: 0.003473, loss_test: 0.005700
time: 0.24506664276123047
time: 2.2190418243408203
[1, 11452] loss_train: 0.017780, loss_test: 0.005674
time: 0.2470545768737793
time: 2.2525041103363037
[1, 11453] loss_train: 0.004337, loss_test: 0.005659
time: 0.24407958984375
time: 2.2244977951049805
[1, 11454] loss_train: 0.008144, loss_test: 0.005657
time: 0.24305391311645508
time: 2.219998836517334
[1, 11455] loss_train: 0.011096, loss_test: 0.005670
time: 0.24405479431152344
time: 2.2415010929107666
[1, 11456] loss_train: 0.008575, loss_test: 0.005697
time: 0.24305462837219238
time: 2.197491407394409
[1, 11457] loss_train: 0.008936, loss_test: 0.005732
time: 0.24405431747436523
time: 2.2274978160858154
[1, 11458] loss_train: 0.006206, loss_test: 0.005757
time: 0.24405407905578613
time: 2.2214980125427246
[1, 11459] loss_train: 0.006117, loss_test: 0.005775
time: 0.2450547218322754
time: 2.2244973182678223
[1, 11460] loss_train: 0.010701, loss_test: 0.005784
time: 0.25507020950317383
time: 2.226496934890747
[1, 11461] loss_train: 0.006435, loss_test: 0.005771
time: 0.24606609344482422
time: 2.195491075515747
[1, 11462] loss_train: 0.007476, loss_test: 0.005722
time: 0.24305415153503418
time: 2.2254974842071533
[1, 11463] loss_train: 0.004110, loss_test: 0.005680
time: 0.24706745147705078
time: 2.23349928855896
[1, 11464] loss_train: 0.007739, loss_test: 0.005647
time: 0.24405479431152344
time: 2.2264974117279053
[1, 11465] loss_train: 0.010025, loss_test: 0.005626
time: 0.2490551471710205
time: 2.247389554977417
[1, 11466] loss_train: 0.011875, loss_test: 0.005615
time: 0.2450547218322754
time: 2.236513614654541
[1, 11467] loss_train: 0.003681, loss_test: 0.005615
time: 0.24805545806884766
time: 2.2125048637390137
[1, 11468] loss_train: 0.004162, loss_test: 0.005629
time: 0.24406647682189941
time: 2.2294986248016357
[1, 11469] loss_train: 0.006987, loss_test: 0.005649
time: 0.24405384063720703
time: 2.2385094165802
[1, 11470] loss_train: 0.001525, loss_test: 0.005669
time: 0.25705671310424805
time: 2.2685067653656006
[1, 11471] loss_train: 0.006518, loss_test: 0.005678
time: 0.24605488777160645
time: 2.2040042877197266
[1, 11472] loss_train: 0.006391, loss_test: 0.005687
time: 0.24405503273010254
time: 2.2315192222595215
[1, 11473] loss_train: 0.003438, loss_test: 0.005695
time: 0.24505376815795898
time: 2.2064943313598633
[1, 11474] loss_train: 0.009091, loss_test: 0.005684
time: 0.24305343627929688
time: 2.226498603820801
[1, 11475] loss_train: 0.002981, loss_test: 0.005674
time: 0.24544906616210938
time: 2.2284977436065674
[1, 11476] loss_train: 0.007326, loss_test: 0.005666
time: 0.24706745147705078
time: 2.2445600032806396
[1, 11477] loss_train: 0.006105, loss_test: 0.005656
time: 0.24305462837219238
time: 2.2165145874023438
[1, 11478] loss_train: 0.004708, loss_test: 0.005646
time: 0.24405479431152344
time: 2.2460083961486816
[1, 11479] loss_train: 0.005123, loss_test: 0.005635
time: 0.24405455589294434
time: 2.2315304279327393
[1, 11480] loss_train: 0.006355, loss_test: 0.005630
time: 0.2560560703277588
time: 2.2345097064971924
[1, 11481] loss_train: 0.001662, loss_test: 0.005629
time: 0.24405455589294434
time: 2.2010231018066406
[1, 11482] loss_train: 0.004025, loss_test: 0.005632
time: 0.24906563758850098
time: 2.212999105453491
[1, 11483] loss_train: 0.003962, loss_test: 0.005636
time: 0.24605488777160645
time: 2.228501319885254
[1, 11484] loss_train: 0.009030, loss_test: 0.005640
time: 0.2490682601928711
time: 2.2304985523223877
[1, 11485] loss_train: 0.009527, loss_test: 0.005643
time: 0.24405622482299805
time: 2.244502544403076
[1, 11486] loss_train: 0.002013, loss_test: 0.005646
time: 0.24806880950927734
time: 2.248502731323242
[1, 11487] loss_train: 0.005208, loss_test: 0.005647
time: 0.24305367469787598
time: 2.2275173664093018
[1, 11488] loss_train: 0.013722, loss_test: 0.005651
time: 0.24605464935302734
time: 2.2114949226379395
[1, 11489] loss_train: 0.004683, loss_test: 0.005656
time: 0.24305438995361328
time: 2.2535035610198975
[1, 11490] loss_train: 0.005984, loss_test: 0.005662
time: 0.2540557384490967
time: 2.279510259628296
[1, 11491] loss_train: 0.006104, loss_test: 0.005660
time: 0.2470543384552002
time: 2.2210140228271484
[1, 11492] loss_train: 0.005369, loss_test: 0.005658
time: 0.24405407905578613
time: 2.228498697280884
[1, 11493] loss_train: 0.003531, loss_test: 0.005650
time: 0.24808096885681152
time: 2.2310023307800293
[1, 11494] loss_train: 0.008098, loss_test: 0.005634
time: 0.24405479431152344
time: 2.215494394302368
[1, 11495] loss_train: 0.003558, loss_test: 0.005624
time: 0.24305415153503418
time: 2.2405030727386475
[1, 11496] loss_train: 0.005245, loss_test: 0.005618
time: 0.2450549602508545
time: 2.234499216079712
[1, 11497] loss_train: 0.005873, loss_test: 0.005615
time: 0.24305367469787598
time: 2.2224972248077393
[1, 11498] loss_train: 0.006234, loss_test: 0.005614
time: 0.24506664276123047
time: 2.2144954204559326
[1, 11499] loss_train: 0.008752, loss_test: 0.005613
time: 0.2470545768737793
time: 2.23051118850708
[1, 11500] loss_train: 0.004382, loss_test: 0.005613
time: 0.25707077980041504
time: 2.23249888420105
[1, 11501] loss_train: 0.001014, loss_test: 0.005617
time: 0.24405455589294434
time: 2.2115049362182617
[1, 11502] loss_train: 0.008170, loss_test: 0.005620
time: 0.24305367469787598
time: 2.256507396697998
[1, 11503] loss_train: 0.002413, loss_test: 0.005625
time: 0.24305272102355957
time: 2.2405009269714355
[1, 11504] loss_train: 0.005936, loss_test: 0.005627
time: 0.2450547218322754
time: 2.2154974937438965
[1, 11505] loss_train: 0.005303, loss_test: 0.005627
time: 0.2470557689666748
time: 2.235499382019043
[1, 11506] loss_train: 0.002929, loss_test: 0.005628
time: 0.24505400657653809
time: 2.2264981269836426
[1, 11507] loss_train: 0.008983, loss_test: 0.005626
time: 0.2490553855895996
time: 2.2004923820495605
[1, 11508] loss_train: 0.004387, loss_test: 0.005628
time: 0.24405384063720703
time: 2.2195069789886475
[1, 11509] loss_train: 0.003399, loss_test: 0.005632
time: 0.24805474281311035
time: 2.217496633529663
[1, 11510] loss_train: 0.011035, loss_test: 0.005628
time: 0.2560570240020752
time: 2.2545037269592285
[1, 11511] loss_train: 0.000773, loss_test: 0.005628
time: 0.24305462837219238
time: 2.2154951095581055
[1, 11512] loss_train: 0.011677, loss_test: 0.005626
time: 0.24205327033996582
time: 2.2175076007843018
[1, 11513] loss_train: 0.015294, loss_test: 0.005622
time: 0.24305319786071777
time: 2.253504514694214
[1, 11514] loss_train: 0.001411, loss_test: 0.005622
time: 0.24305415153503418
time: 2.2410147190093994
[1, 11515] loss_train: 0.001782, loss_test: 0.005622
time: 0.24305510520935059
time: 2.2405004501342773
[1, 11516] loss_train: 0.004169, loss_test: 0.005620
time: 0.2470550537109375
time: 2.2425217628479004
[1, 11517] loss_train: 0.003230, loss_test: 0.005619
time: 0.24305486679077148
time: 2.2004916667938232
[1, 11518] loss_train: 0.004560, loss_test: 0.005619
time: 0.2420670986175537
time: 2.1890087127685547
[1, 11519] loss_train: 0.008201, loss_test: 0.005619
time: 0.24205398559570312
time: 2.2034952640533447
[1, 11520] loss_train: 0.005258, loss_test: 0.005617
time: 0.25505614280700684
time: 2.2214999198913574
[1, 11521] loss_train: 0.006453, loss_test: 0.005615
time: 0.24405407905578613
time: 2.2204971313476562
[1, 11522] loss_train: 0.003883, loss_test: 0.005613
time: 0.2490546703338623
time: 2.217496395111084
[1, 11523] loss_train: 0.015019, loss_test: 0.005612
time: 0.24605917930603027
time: 2.2114977836608887
[1, 11524] loss_train: 0.001480, loss_test: 0.005612
time: 0.2490556240081787
time: 2.25750470161438
[1, 11525] loss_train: 0.003169, loss_test: 0.005614
time: 0.24305438995361328
time: 2.2105319499969482
[1, 11526] loss_train: 0.000982, loss_test: 0.005616
time: 0.24805569648742676
time: 2.2184956073760986
[1, 11527] loss_train: 0.006510, loss_test: 0.005624
time: 0.2450547218322754
time: 2.2304985523223877
[1, 11528] loss_train: 0.009173, loss_test: 0.005632
time: 0.24306988716125488
time: 2.20499587059021
[1, 11529] loss_train: 0.007176, loss_test: 0.005643
time: 0.24305367469787598
time: 2.219508409500122
[1, 11530] loss_train: 0.016318, loss_test: 0.005629
time: 0.25705647468566895
time: 2.2605063915252686
[1, 11531] loss_train: 0.002350, loss_test: 0.005621
time: 0.2450542449951172
time: 2.2365007400512695
[1, 11532] loss_train: 0.008133, loss_test: 0.005615
time: 0.24207210540771484
time: 2.2019975185394287
[1, 11533] loss_train: 0.009529, loss_test: 0.005610
time: 0.2510552406311035
time: 2.206495761871338
[1, 11534] loss_train: 0.004582, loss_test: 0.005608
time: 0.24605536460876465
time: 2.244504690170288
[1, 11535] loss_train: 0.007039, loss_test: 0.005606
time: 0.24405455589294434
time: 2.1975128650665283
[1, 11536] loss_train: 0.002406, loss_test: 0.005604
time: 0.2450547218322754
time: 2.218499183654785
[1, 11537] loss_train: 0.007071, loss_test: 0.005604
time: 0.24305415153503418
time: 2.245501756668091
[1, 11538] loss_train: 0.006890, loss_test: 0.005605
time: 0.24405384063720703
time: 2.2566397190093994
[1, 11539] loss_train: 0.012605, loss_test: 0.005608
time: 0.24605464935302734
time: 2.220496654510498
[1, 11540] loss_train: 0.004383, loss_test: 0.005610
time: 0.25907158851623535
time: 2.2705085277557373
[1, 11541] loss_train: 0.004340, loss_test: 0.005612
time: 0.2470548152923584
time: 2.2445015907287598
[1, 11542] loss_train: 0.003888, loss_test: 0.005613
time: 0.24405431747436523
time: 2.2214972972869873
[1, 11543] loss_train: 0.006255, loss_test: 0.005613
time: 0.25205564498901367
time: 2.2154953479766846
[1, 11544] loss_train: 0.002960, loss_test: 0.005614
time: 0.24406719207763672
time: 2.204500675201416
[1, 11545] loss_train: 0.003473, loss_test: 0.005615
time: 0.24606823921203613
time: 2.1994919776916504
[1, 11546] loss_train: 0.002635, loss_test: 0.005620
time: 0.24455690383911133
time: 2.2495288848876953
[1, 11547] loss_train: 0.009352, loss_test: 0.005623
time: 0.24405360221862793
time: 2.239501476287842
[1, 11548] loss_train: 0.003048, loss_test: 0.005626
time: 0.24505400657653809
time: 2.2175164222717285
[1, 11549] loss_train: 0.011287, loss_test: 0.005623
time: 0.24405384063720703
time: 2.2280125617980957
[1, 11550] loss_train: 0.006546, loss_test: 0.005623
time: 0.2620584964752197
time: 2.2675063610076904
[1, 11551] loss_train: 0.003792, loss_test: 0.005629
time: 0.2450542449951172
time: 2.2385008335113525
[1, 11552] loss_train: 0.007762, loss_test: 0.005640
time: 0.24505329132080078
time: 2.226498603820801
[1, 11553] loss_train: 0.007989, loss_test: 0.005650
time: 0.2450547218322754
time: 2.232499122619629
[1, 11554] loss_train: 0.007036, loss_test: 0.005660
time: 0.24305438995361328
time: 2.2300703525543213
[1, 11555] loss_train: 0.003769, loss_test: 0.005675
time: 0.24605488777160645
time: 2.2244982719421387
[1, 11556] loss_train: 0.006252, loss_test: 0.005692
time: 0.24405860900878906
time: 2.227522611618042
[1, 11557] loss_train: 0.004417, loss_test: 0.005707
time: 0.24406099319458008
time: 2.221497058868408
[1, 11558] loss_train: 0.005060, loss_test: 0.005720
time: 0.24405431747436523
time: 2.232499122619629
[1, 11559] loss_train: 0.004565, loss_test: 0.005733
time: 0.24205374717712402
time: 2.2164978981018066
[1, 11560] loss_train: 0.001739, loss_test: 0.005745
time: 0.25705718994140625
time: 2.22149658203125
[1, 11561] loss_train: 0.011713, loss_test: 0.005744
time: 0.24405384063720703
time: 2.216495990753174
[1, 11562] loss_train: 0.007898, loss_test: 0.005725
time: 0.2510561943054199
time: 2.2365000247955322
[1, 11563] loss_train: 0.004484, loss_test: 0.005705
time: 0.24506783485412598
time: 2.2134957313537598
[1, 11564] loss_train: 0.005165, loss_test: 0.005684
time: 0.2510559558868408
time: 2.2585225105285645
[1, 11565] loss_train: 0.003700, loss_test: 0.005660
time: 0.24405431747436523
time: 2.250502824783325
[1, 11566] loss_train: 0.004001, loss_test: 0.005639
time: 0.2490553855895996
time: 2.235029697418213
[1, 11567] loss_train: 0.000909, loss_test: 0.005635
time: 0.24605417251586914
time: 2.204493522644043
[1, 11568] loss_train: 0.004207, loss_test: 0.005642
time: 0.24505400657653809
time: 2.2525041103363037
[1, 11569] loss_train: 0.002412, loss_test: 0.005657
time: 0.24356794357299805
time: 2.213003396987915
[1, 11570] loss_train: 0.005351, loss_test: 0.005671
time: 0.258056640625
time: 2.2495038509368896
[1, 11571] loss_train: 0.008659, loss_test: 0.005679
time: 0.24506807327270508
time: 2.2004919052124023
[1, 11572] loss_train: 0.003066, loss_test: 0.005690
time: 0.24306702613830566
time: 2.217496395111084
[1, 11573] loss_train: 0.009259, loss_test: 0.005694
time: 0.24405360221862793
time: 2.2365009784698486
[1, 11574] loss_train: 0.005603, loss_test: 0.005701
time: 0.24505400657653809
time: 2.239513397216797
[1, 11575] loss_train: 0.009921, loss_test: 0.005707
time: 0.24405312538146973
time: 2.217374563217163
[1, 11576] loss_train: 0.006226, loss_test: 0.005723
time: 0.24405431747436523
time: 2.215013027191162
[1, 11577] loss_train: 0.007912, loss_test: 0.005714
time: 0.24605393409729004
time: 2.1984922885894775
[1, 11578] loss_train: 0.003121, loss_test: 0.005702
time: 0.24305343627929688
time: 2.188514232635498
[1, 11579] loss_train: 0.010740, loss_test: 0.005693
time: 0.24805498123168945
time: 2.2004921436309814
[1, 11580] loss_train: 0.000926, loss_test: 0.005670
time: 0.2580571174621582
time: 2.239501476287842
[1, 11581] loss_train: 0.000756, loss_test: 0.005656
time: 0.25205540657043457
time: 2.2068910598754883
[1, 11582] loss_train: 0.003882, loss_test: 0.005644
time: 0.24305367469787598
time: 2.2115108966827393
[1, 11583] loss_train: 0.003939, loss_test: 0.005635
time: 0.24605536460876465
time: 2.2054927349090576
[1, 11584] loss_train: 0.011581, loss_test: 0.005631
time: 0.24405384063720703
time: 2.219503879547119
[1, 11585] loss_train: 0.007299, loss_test: 0.005627
time: 0.24305415153503418
time: 2.2124972343444824
[1, 11586] loss_train: 0.010136, loss_test: 0.005624
time: 0.24305343627929688
time: 2.2455027103424072
[1, 11587] loss_train: 0.000953, loss_test: 0.005619
time: 0.24505400657653809
time: 2.2244980335235596
[1, 11588] loss_train: 0.013382, loss_test: 0.005618
time: 0.24605488777160645
time: 2.220496416091919
[1, 11589] loss_train: 0.006120, loss_test: 0.005616
time: 0.24306750297546387
time: 2.2115068435668945
[1, 11590] loss_train: 0.007418, loss_test: 0.005612
time: 0.2540566921234131
time: 2.2185020446777344
[1, 11591] loss_train: 0.000484, loss_test: 0.005611
time: 0.24405407905578613
time: 2.217496633529663
[1, 11592] loss_train: 0.003022, loss_test: 0.005611
time: 0.244065523147583
time: 2.228498697280884
[1, 11593] loss_train: 0.003804, loss_test: 0.005611
time: 0.2450547218322754
time: 2.2495028972625732
[1, 11594] loss_train: 0.005450, loss_test: 0.005612
time: 0.24405455589294434
time: 2.2455031871795654
[1, 11595] loss_train: 0.006844, loss_test: 0.005609
time: 0.24506735801696777
time: 2.1975088119506836
[1, 11596] loss_train: 0.003815, loss_test: 0.005607
time: 0.25005602836608887
time: 2.2405006885528564
[1, 11597] loss_train: 0.008438, loss_test: 0.005605
time: 0.2450547218322754
time: 2.23449969291687
[1, 11598] loss_train: 0.012144, loss_test: 0.005603
time: 0.25205564498901367
time: 2.2285122871398926
[1, 11599] loss_train: 0.002346, loss_test: 0.005602
time: 0.24605417251586914
time: 2.2335002422332764
[1, 11600] loss_train: 0.001625, loss_test: 0.005604
time: 0.25905728340148926
time: 2.2655069828033447
[1, 11601] loss_train: 0.009291, loss_test: 0.005605
time: 0.24305224418640137
time: 2.2244975566864014
[1, 11602] loss_train: 0.006612, loss_test: 0.005606
time: 0.24605488777160645
time: 2.2099993228912354
[1, 11603] loss_train: 0.001480, loss_test: 0.005607
time: 0.24405407905578613
time: 2.215498208999634
[1, 11604] loss_train: 0.005315, loss_test: 0.005605
time: 0.24205327033996582
time: 2.1984922885894775
[1, 11605] loss_train: 0.006222, loss_test: 0.005602
time: 0.2470548152923584
time: 2.2225136756896973
[1, 11606] loss_train: 0.001350, loss_test: 0.005598
time: 0.24506759643554688
time: 2.218513011932373
[1, 11607] loss_train: 0.004154, loss_test: 0.005595
time: 0.24305319786071777
time: 2.2505040168762207
[1, 11608] loss_train: 0.011367, loss_test: 0.005595
time: 0.24405455589294434
time: 2.2104945182800293
[1, 11609] loss_train: 0.006916, loss_test: 0.005596
time: 0.244065523147583
time: 2.221531629562378
[1, 11610] loss_train: 0.005536, loss_test: 0.005599
time: 0.256056547164917
time: 2.2575056552886963
[1, 11611] loss_train: 0.003648, loss_test: 0.005599
time: 0.24606800079345703
time: 2.2024924755096436
[1, 11612] loss_train: 0.002469, loss_test: 0.005603
time: 0.24605441093444824
time: 2.2355000972747803
[1, 11613] loss_train: 0.006903, loss_test: 0.005606
time: 0.2400531768798828
time: 2.219496011734009
[1, 11614] loss_train: 0.008998, loss_test: 0.005609
time: 0.24405407905578613
time: 2.227498769760132
[1, 11615] loss_train: 0.009891, loss_test: 0.005613
time: 0.25005507469177246
time: 2.2015154361724854
[1, 11616] loss_train: 0.001462, loss_test: 0.005615
time: 0.24405407905578613
time: 2.18448805809021
[1, 11617] loss_train: 0.010178, loss_test: 0.005616
time: 0.24405455589294434
time: 2.240513324737549
[1, 11618] loss_train: 0.006028, loss_test: 0.005615
time: 0.2430553436279297
time: 2.2000112533569336
[1, 11619] loss_train: 0.005128, loss_test: 0.005614
time: 0.24808096885681152
time: 2.205493211746216
[1, 11620] loss_train: 0.004353, loss_test: 0.005613
time: 0.255077600479126
time: 2.2475028038024902
[1, 11621] loss_train: 0.009428, loss_test: 0.005613
time: 0.24405455589294434
time: 2.2515029907226562
[1, 11622] loss_train: 0.008392, loss_test: 0.005613
time: 0.2450549602508545
time: 2.231498956680298
[1, 11623] loss_train: 0.004873, loss_test: 0.005615
time: 0.24305391311645508
time: 2.2495033740997314
[1, 11624] loss_train: 0.009066, loss_test: 0.005617
time: 0.24305415153503418
time: 2.268507242202759
[1, 11625] loss_train: 0.011134, loss_test: 0.005618
time: 0.24405455589294434
time: 2.236499786376953
[1, 11626] loss_train: 0.013970, loss_test: 0.005616
time: 0.24605488777160645
time: 2.1924893856048584
[1, 11627] loss_train: 0.004728, loss_test: 0.005616
time: 0.24305486679077148
time: 2.234499216079712
[1, 11628] loss_train: 0.009000, loss_test: 0.005616
time: 0.2440652847290039
time: 2.2050130367279053
[1, 11629] loss_train: 0.006419, loss_test: 0.005618
time: 0.24806785583496094
time: 2.205009937286377
[1, 11630] loss_train: 0.012979, loss_test: 0.005621
time: 0.2560563087463379
time: 2.2345001697540283
[1, 11631] loss_train: 0.005296, loss_test: 0.005629
time: 0.24605417251586914
time: 2.1974921226501465
[1, 11632] loss_train: 0.005529, loss_test: 0.005639
time: 0.25005578994750977
time: 2.2216479778289795
[1, 11633] loss_train: 0.004101, loss_test: 0.005652
time: 0.24506688117980957
time: 2.22650146484375
[1, 11634] loss_train: 0.002725, loss_test: 0.005665
time: 0.24805164337158203
time: 2.2383487224578857
[1, 11635] loss_train: 0.013352, loss_test: 0.005676
time: 0.24305343627929688
time: 2.2200191020965576
[1, 11636] loss_train: 0.002957, loss_test: 0.005686
time: 0.24605417251586914
time: 2.218496322631836
[1, 11637] loss_train: 0.006245, loss_test: 0.005683
time: 0.2450547218322754
time: 2.2375001907348633
[1, 11638] loss_train: 0.008124, loss_test: 0.005676
time: 0.2450549602508545
time: 2.1755125522613525
[1, 11639] loss_train: 0.007573, loss_test: 0.005665
time: 0.2450544834136963
time: 2.182363748550415
[1, 11640] loss_train: 0.012670, loss_test: 0.005656
time: 0.25505614280700684
time: 2.244502544403076
[1, 11641] loss_train: 0.010369, loss_test: 0.005642
time: 0.2450575828552246
time: 2.2274975776672363
[1, 11642] loss_train: 0.005356, loss_test: 0.005633
time: 0.24405455589294434
time: 2.2124972343444824
[1, 11643] loss_train: 0.010409, loss_test: 0.005635
time: 0.24605464935302734
time: 2.228498697280884
[1, 11644] loss_train: 0.004209, loss_test: 0.005642
time: 0.24305319786071777
time: 2.226498603820801
[1, 11645] loss_train: 0.000562, loss_test: 0.005652
time: 0.24606680870056152
time: 2.2189993858337402
[1, 11646] loss_train: 0.005338, loss_test: 0.005661
time: 0.24507856369018555
time: 2.216463804244995
[1, 11647] loss_train: 0.003731, loss_test: 0.005659
time: 0.2490553855895996
time: 2.2475030422210693
[1, 11648] loss_train: 0.008415, loss_test: 0.005656
time: 0.2450549602508545
time: 2.23750901222229
[1, 11649] loss_train: 0.008893, loss_test: 0.005651
time: 0.2490558624267578
time: 2.233013868331909
[1, 11650] loss_train: 0.022588, loss_test: 0.005632
time: 0.2580575942993164
time: 2.250133752822876
[1, 11651] loss_train: 0.009196, loss_test: 0.005617
time: 0.25205564498901367
time: 2.2244982719421387
[1, 11652] loss_train: 0.006002, loss_test: 0.005610
time: 0.24405360221862793
time: 2.243516445159912
[1, 11653] loss_train: 0.009769, loss_test: 0.005612
time: 0.24605417251586914
time: 2.243502378463745
[1, 11654] loss_train: 0.007880, loss_test: 0.005623
time: 0.24405384063720703
time: 2.220017910003662
[1, 11655] loss_train: 0.002211, loss_test: 0.005636
time: 0.24405336380004883
time: 2.2345001697540283
[1, 11656] loss_train: 0.000804, loss_test: 0.005658
time: 0.24405455589294434
time: 2.2566561698913574
[1, 11657] loss_train: 0.017047, loss_test: 0.005681
time: 0.2450547218322754
time: 2.234499216079712
[1, 11658] loss_train: 0.019198, loss_test: 0.005695
time: 0.24405455589294434
time: 2.24101185798645
[1, 11659] loss_train: 0.012631, loss_test: 0.005678
time: 0.24405431747436523
time: 2.2505135536193848
[1, 11660] loss_train: 0.004891, loss_test: 0.005657
time: 0.2620842456817627
time: 2.253835439682007
[1, 11661] loss_train: 0.006814, loss_test: 0.005624
time: 0.2400531768798828
time: 2.2520525455474854
[1, 11662] loss_train: 0.001998, loss_test: 0.005609
time: 0.24505400657653809
time: 2.219496965408325
[1, 11663] loss_train: 0.004180, loss_test: 0.005613
time: 0.2470543384552002
time: 2.233510971069336
[1, 11664] loss_train: 0.010102, loss_test: 0.005620
time: 0.24405360221862793
time: 2.2254979610443115
[1, 11665] loss_train: 0.003023, loss_test: 0.005629
time: 0.24305367469787598
time: 2.231501340866089
[1, 11666] loss_train: 0.010932, loss_test: 0.005634
time: 0.24405360221862793
time: 2.1920275688171387
[1, 11667] loss_train: 0.005816, loss_test: 0.005638
time: 0.24305367469787598
time: 2.218496561050415
[1, 11668] loss_train: 0.002958, loss_test: 0.005641
time: 0.24405455589294434
time: 2.2065160274505615
[1, 11669] loss_train: 0.005068, loss_test: 0.005644
time: 0.2420804500579834
time: 2.2134952545166016
[1, 11670] loss_train: 0.003639, loss_test: 0.005646
time: 0.27005982398986816
time: 2.2695252895355225
[1, 11671] loss_train: 0.003068, loss_test: 0.005647
time: 0.24606776237487793
time: 2.203493356704712
[1, 11672] loss_train: 0.003481, loss_test: 0.005650
time: 0.25005531311035156
time: 2.2224974632263184
[1, 11673] loss_train: 0.001230, loss_test: 0.005657
time: 0.2450547218322754
time: 2.235499620437622
[1, 11674] loss_train: 0.009419, loss_test: 0.005658
time: 0.2510561943054199
time: 2.2164955139160156
[1, 11675] loss_train: 0.007422, loss_test: 0.005656
time: 0.24305415153503418
time: 2.2014923095703125
[1, 11676] loss_train: 0.000471, loss_test: 0.005659
time: 0.24405479431152344
time: 2.2375001907348633
[1, 11677] loss_train: 0.004160, loss_test: 0.005662
time: 0.2450547218322754
time: 2.2024943828582764
[1, 11678] loss_train: 0.008891, loss_test: 0.005658
time: 0.24305057525634766
time: 2.225616931915283
[1, 11679] loss_train: 0.002862, loss_test: 0.005657
time: 0.24405407905578613
time: 2.2485032081604004
[1, 11680] loss_train: 0.008924, loss_test: 0.005643
time: 0.25705647468566895
time: 2.264507293701172
[1, 11681] loss_train: 0.009515, loss_test: 0.005628
time: 0.24306631088256836
time: 2.2675063610076904
[1, 11682] loss_train: 0.010663, loss_test: 0.005619
time: 0.24305415153503418
time: 2.2025909423828125
[1, 11683] loss_train: 0.001571, loss_test: 0.005621
time: 0.24305415153503418
time: 2.218494176864624
[1, 11684] loss_train: 0.004143, loss_test: 0.005628
time: 0.24405407905578613
time: 2.2164955139160156
[1, 11685] loss_train: 0.009923, loss_test: 0.005634
time: 0.24605488777160645
time: 2.2244980335235596
[1, 11686] loss_train: 0.008514, loss_test: 0.005642
time: 0.24305343627929688
time: 2.222064971923828
[1, 11687] loss_train: 0.007911, loss_test: 0.005648
time: 0.24605417251586914
time: 2.2254981994628906
[1, 11688] loss_train: 0.014440, loss_test: 0.005648
time: 0.24405384063720703
time: 2.2024927139282227
[1, 11689] loss_train: 0.000810, loss_test: 0.005647
time: 0.25005507469177246
time: 2.2035109996795654
[1, 11690] loss_train: 0.005032, loss_test: 0.005642
time: 0.2560560703277588
time: 2.255709648132324
[1, 11691] loss_train: 0.007928, loss_test: 0.005637
time: 0.2530686855316162
time: 2.241501808166504
[1, 11692] loss_train: 0.003656, loss_test: 0.005630
time: 0.24605464935302734
time: 2.2164950370788574
[1, 11693] loss_train: 0.008950, loss_test: 0.005625
time: 0.24805545806884766
time: 2.2004928588867188
[1, 11694] loss_train: 0.006769, loss_test: 0.005622
time: 0.24405360221862793
time: 2.2164995670318604
[1, 11695] loss_train: 0.005511, loss_test: 0.005623
time: 0.24405407905578613
time: 2.221498727798462
[1, 11696] loss_train: 0.013932, loss_test: 0.005628
time: 0.24358582496643066
time: 2.2174956798553467
[1, 11697] loss_train: 0.001092, loss_test: 0.005627
time: 0.24305319786071777
time: 2.219496250152588
[1, 11698] loss_train: 0.007931, loss_test: 0.005624
time: 0.2450544834136963
time: 2.219008684158325
[1, 11699] loss_train: 0.006505, loss_test: 0.005618
time: 0.24305391311645508
time: 2.2035257816314697
[1, 11700] loss_train: 0.016079, loss_test: 0.005613
time: 0.2550685405731201
time: 2.243502140045166
[1, 11701] loss_train: 0.001564, loss_test: 0.005610
time: 0.24405503273010254
time: 2.2530088424682617
[1, 11702] loss_train: 0.016501, loss_test: 0.005609
time: 0.24805426597595215
time: 2.2164957523345947
[1, 11703] loss_train: 0.003527, loss_test: 0.005605
time: 0.24405384063720703
time: 2.2115015983581543
[1, 11704] loss_train: 0.004651, loss_test: 0.005601
time: 0.2510559558868408
time: 2.2254974842071533
[1, 11705] loss_train: 0.006925, loss_test: 0.005598
time: 0.24405336380004883
time: 2.2395176887512207
[1, 11706] loss_train: 0.005775, loss_test: 0.005595
time: 0.25305604934692383
time: 2.2625062465667725
[1, 11707] loss_train: 0.004914, loss_test: 0.005596
time: 0.24406743049621582
time: 2.2174978256225586
[1, 11708] loss_train: 0.002833, loss_test: 0.005599
time: 0.24905681610107422
time: 2.211494207382202
[1, 11709] loss_train: 0.006739, loss_test: 0.005604
time: 0.24405479431152344
time: 2.207514762878418
[1, 11710] loss_train: 0.003345, loss_test: 0.005610
time: 0.2600581645965576
time: 2.2585041522979736
[1, 11711] loss_train: 0.022079, loss_test: 0.005618
time: 0.25005459785461426
time: 2.2375009059906006
[1, 11712] loss_train: 0.000572, loss_test: 0.005634
time: 0.2470552921295166
time: 2.248502254486084
[1, 11713] loss_train: 0.006892, loss_test: 0.005644
time: 0.24405384063720703
time: 2.2244982719421387
[1, 11714] loss_train: 0.007984, loss_test: 0.005654
time: 0.24605464935302734
time: 2.2315008640289307
[1, 11715] loss_train: 0.007315, loss_test: 0.005655
time: 0.24505400657653809
time: 2.230501413345337
[1, 11716] loss_train: 0.004903, loss_test: 0.005653
time: 0.24405360221862793
time: 2.2204973697662354
[1, 11717] loss_train: 0.008174, loss_test: 0.005647
time: 0.2470543384552002
time: 2.2124950885772705
[1, 11718] loss_train: 0.007326, loss_test: 0.005640
time: 0.24605464935302734
time: 2.218496322631836
[1, 11719] loss_train: 0.003110, loss_test: 0.005637
time: 0.24306654930114746
time: 2.231039524078369
[1, 11720] loss_train: 0.015749, loss_test: 0.005632
time: 0.2560563087463379
time: 2.276512622833252
[1, 11721] loss_train: 0.006703, loss_test: 0.005628
time: 0.2450547218322754
time: 2.250507116317749
[1, 11722] loss_train: 0.014961, loss_test: 0.005623
time: 0.2450542449951172
time: 2.249507427215576
[1, 11723] loss_train: 0.006112, loss_test: 0.005617
time: 0.24405431747436523
time: 2.2034921646118164
[1, 11724] loss_train: 0.002961, loss_test: 0.005612
time: 0.2450542449951172
time: 2.210461378097534
[1, 11725] loss_train: 0.000708, loss_test: 0.005608
time: 0.24305319786071777
time: 2.22800350189209
[1, 11726] loss_train: 0.008843, loss_test: 0.005607
time: 0.24405360221862793
time: 2.2124955654144287
[1, 11727] loss_train: 0.006411, loss_test: 0.005607
time: 0.24405360221862793
time: 2.207493782043457
[1, 11728] loss_train: 0.002625, loss_test: 0.005610
time: 0.2450547218322754
time: 2.196491003036499
[1, 11729] loss_train: 0.001681, loss_test: 0.005616
time: 0.24908137321472168
time: 2.253506660461426
[1, 11730] loss_train: 0.003372, loss_test: 0.005623
time: 0.2560575008392334
time: 2.2830140590667725
[1, 11731] loss_train: 0.004307, loss_test: 0.005631
time: 0.25505685806274414
time: 2.2565042972564697
[1, 11732] loss_train: 0.004496, loss_test: 0.005644
time: 0.24405360221862793
time: 2.22149658203125
[1, 11733] loss_train: 0.005677, loss_test: 0.005655
time: 0.25105714797973633
time: 2.2294983863830566
[1, 11734] loss_train: 0.006477, loss_test: 0.005663
time: 0.24805521965026855
time: 2.201331377029419
[1, 11735] loss_train: 0.009177, loss_test: 0.005650
time: 0.25005531311035156
time: 2.220496892929077
[1, 11736] loss_train: 0.005619, loss_test: 0.005637
time: 0.24405384063720703
time: 2.220496892929077
[1, 11737] loss_train: 0.002588, loss_test: 0.005632
time: 0.24405384063720703
time: 2.226498603820801
[1, 11738] loss_train: 0.004741, loss_test: 0.005630
time: 0.24305367469787598
time: 2.219496726989746
[1, 11739] loss_train: 0.009195, loss_test: 0.005627
time: 0.24405407905578613
time: 2.230294942855835
[1, 11740] loss_train: 0.003740, loss_test: 0.005627
time: 0.25505709648132324
time: 2.251502275466919
[1, 11741] loss_train: 0.003420, loss_test: 0.005626
time: 0.24405503273010254
time: 2.231517791748047
[1, 11742] loss_train: 0.006527, loss_test: 0.005623
time: 0.24606561660766602
time: 2.230499029159546
[1, 11743] loss_train: 0.008106, loss_test: 0.005619
time: 0.24405431747436523
time: 2.2500174045562744
[1, 11744] loss_train: 0.005527, loss_test: 0.005616
time: 0.2450544834136963
time: 2.230499267578125
[1, 11745] loss_train: 0.008906, loss_test: 0.005613
time: 0.2450542449951172
time: 2.243501901626587
[1, 11746] loss_train: 0.004793, loss_test: 0.005610
time: 0.2450544834136963
time: 2.224497079849243
[1, 11747] loss_train: 0.004869, loss_test: 0.005608
time: 0.2450544834136963
time: 2.212000608444214
[1, 11748] loss_train: 0.018890, loss_test: 0.005606
time: 0.24605417251586914
time: 2.1994917392730713
[1, 11749] loss_train: 0.002342, loss_test: 0.005605
time: 0.24405407905578613
time: 2.229499101638794
[1, 11750] loss_train: 0.007918, loss_test: 0.005607
time: 0.2576601505279541
time: 2.2645065784454346
[1, 11751] loss_train: 0.006897, loss_test: 0.005609
time: 0.24405407905578613
time: 2.219496965408325
[1, 11752] loss_train: 0.013037, loss_test: 0.005612
time: 0.25305652618408203
time: 2.2054929733276367
[1, 11753] loss_train: 0.001008, loss_test: 0.005612
time: 0.24509596824645996
time: 2.218496084213257
[1, 11754] loss_train: 0.006264, loss_test: 0.005616
time: 0.25005555152893066
time: 2.2264978885650635
[1, 11755] loss_train: 0.005192, loss_test: 0.005617
time: 0.24405431747436523
time: 2.2395009994506836
[1, 11756] loss_train: 0.004341, loss_test: 0.005611
time: 0.2470543384552002
time: 2.2175076007843018
[1, 11757] loss_train: 0.005862, loss_test: 0.005604
time: 0.2450549602508545
time: 2.2665064334869385
[1, 11758] loss_train: 0.009267, loss_test: 0.005603
time: 0.24305415153503418
time: 2.241006374359131
[1, 11759] loss_train: 0.005561, loss_test: 0.005606
time: 0.24506783485412598
time: 2.230499029159546
[1, 11760] loss_train: 0.010757, loss_test: 0.005613
time: 0.2560572624206543
time: 2.2650396823883057
[1, 11761] loss_train: 0.002620, loss_test: 0.005624
time: 0.24405431747436523
time: 2.205493688583374
[1, 11762] loss_train: 0.007884, loss_test: 0.005632
time: 0.24655938148498535
time: 2.2081751823425293
[1, 11763] loss_train: 0.004703, loss_test: 0.005643
time: 0.24305391311645508
time: 2.2355198860168457
[1, 11764] loss_train: 0.007303, loss_test: 0.005653
time: 0.24405574798583984
time: 2.2014918327331543
[1, 11765] loss_train: 0.003675, loss_test: 0.005665
time: 0.24305486679077148
time: 2.2270030975341797
[1, 11766] loss_train: 0.010577, loss_test: 0.005670
time: 0.24305391311645508
time: 2.2325010299682617
[1, 11767] loss_train: 0.004107, loss_test: 0.005670
time: 0.24205327033996582
time: 2.224497079849243
[1, 11768] loss_train: 0.002559, loss_test: 0.005669
time: 0.2440659999847412
time: 2.232525587081909
[1, 11769] loss_train: 0.004247, loss_test: 0.005668
time: 0.2470550537109375
time: 2.2294981479644775
[1, 11770] loss_train: 0.003872, loss_test: 0.005664
time: 0.25705742835998535
time: 2.260035514831543
[1, 11771] loss_train: 0.015613, loss_test: 0.005647
time: 0.24605965614318848
time: 2.211494207382202
[1, 11772] loss_train: 0.005469, loss_test: 0.005634
time: 0.2450549602508545
time: 2.231501817703247
[1, 11773] loss_train: 0.008562, loss_test: 0.005624
time: 0.24805521965026855
time: 2.2144951820373535
[1, 11774] loss_train: 0.007855, loss_test: 0.005614
time: 0.24605417251586914
time: 2.2155044078826904
[1, 11775] loss_train: 0.002319, loss_test: 0.005612
time: 0.25005483627319336
time: 2.2314999103546143
[1, 11776] loss_train: 0.002256, loss_test: 0.005612
time: 0.24709701538085938
time: 2.221024990081787
[1, 11777] loss_train: 0.008536, loss_test: 0.005615
time: 0.24605417251586914
time: 2.2345001697540283
[1, 11778] loss_train: 0.001104, loss_test: 0.005615
time: 0.2470550537109375
time: 2.2044923305511475
[1, 11779] loss_train: 0.002180, loss_test: 0.005612
time: 0.24305438995361328
time: 2.239513874053955
[1, 11780] loss_train: 0.011585, loss_test: 0.005613
time: 0.2570688724517822
time: 2.245739459991455
[1, 11781] loss_train: 0.005068, loss_test: 0.005615
time: 0.24405455589294434
time: 2.2380049228668213
[1, 11782] loss_train: 0.002478, loss_test: 0.005618
time: 0.2450559139251709
time: 2.2475028038024902
[1, 11783] loss_train: 0.004023, loss_test: 0.005623
time: 0.24405384063720703
time: 2.227498769760132
[1, 11784] loss_train: 0.005188, loss_test: 0.005623
time: 0.24405407905578613
time: 2.2375006675720215
[1, 11785] loss_train: 0.008683, loss_test: 0.005622
time: 0.24505400657653809
time: 2.215496063232422
[1, 11786] loss_train: 0.002810, loss_test: 0.005622
time: 0.24406695365905762
time: 2.2095627784729004
[1, 11787] loss_train: 0.003814, loss_test: 0.005626
time: 0.24405407905578613
time: 2.2144968509674072
[1, 11788] loss_train: 0.004072, loss_test: 0.005635
time: 0.24305343627929688
time: 2.210512161254883
[1, 11789] loss_train: 0.002873, loss_test: 0.005650
time: 0.24605369567871094
time: 2.2595059871673584
[1, 11790] loss_train: 0.001688, loss_test: 0.005670
time: 0.25505638122558594
time: 2.2695248126983643
[1, 11791] loss_train: 0.005335, loss_test: 0.005692
time: 0.24406743049621582
time: 2.2244977951049805
[1, 11792] loss_train: 0.019482, loss_test: 0.005694
time: 0.24405407905578613
time: 2.2154972553253174
[1, 11793] loss_train: 0.008731, loss_test: 0.005691
time: 0.24805593490600586
time: 2.2174954414367676
[1, 11794] loss_train: 0.012623, loss_test: 0.005667
time: 0.2490549087524414
time: 2.2385032176971436
[1, 11795] loss_train: 0.004595, loss_test: 0.005648
time: 0.24305343627929688
time: 2.240501642227173
[1, 11796] loss_train: 0.006836, loss_test: 0.005637
time: 0.25005507469177246
time: 2.2205233573913574
[1, 11797] loss_train: 0.006367, loss_test: 0.005632
time: 0.24405479431152344
time: 2.2405006885528564
[1, 11798] loss_train: 0.002143, loss_test: 0.005636
time: 0.24805498123168945
time: 2.23449969291687
[1, 11799] loss_train: 0.002818, loss_test: 0.005642
time: 0.24405384063720703
time: 2.193507671356201
[1, 11800] loss_train: 0.003138, loss_test: 0.005646
time: 0.25905799865722656
time: 2.2635061740875244
[1, 11801] loss_train: 0.004734, loss_test: 0.005648
time: 0.2450542449951172
time: 2.2254974842071533
[1, 11802] loss_train: 0.008199, loss_test: 0.005642
time: 0.24505400657653809
time: 2.2385008335113525
[1, 11803] loss_train: 0.006686, loss_test: 0.005636
time: 0.24506878852844238
time: 2.2144947052001953
[1, 11804] loss_train: 0.006006, loss_test: 0.005629
time: 0.2450547218322754
time: 2.22005295753479
[1, 11805] loss_train: 0.008094, loss_test: 0.005623
time: 0.2450547218322754
time: 2.22049617767334
[1, 11806] loss_train: 0.011631, loss_test: 0.005616
time: 0.24406790733337402
time: 2.223027467727661
[1, 11807] loss_train: 0.008572, loss_test: 0.005612
time: 0.24305391311645508
time: 2.250520706176758
[1, 11808] loss_train: 0.011550, loss_test: 0.005615
time: 0.24406719207763672
time: 2.1894893646240234
[1, 11809] loss_train: 0.012280, loss_test: 0.005626
time: 0.24405360221862793
time: 2.2065060138702393
[1, 11810] loss_train: 0.011388, loss_test: 0.005633
time: 0.2580568790435791
time: 2.2545039653778076
[1, 11811] loss_train: 0.003531, loss_test: 0.005642
time: 0.24506664276123047
time: 2.1884891986846924
[1, 11812] loss_train: 0.004692, loss_test: 0.005650
time: 0.24405384063720703
time: 2.2134950160980225
[1, 11813] loss_train: 0.005099, loss_test: 0.005657
time: 0.2490544319152832
time: 2.230499029159546
[1, 11814] loss_train: 0.008834, loss_test: 0.005666
time: 0.24605536460876465
time: 2.2274978160858154
[1, 11815] loss_train: 0.007026, loss_test: 0.005670
time: 0.2470541000366211
time: 2.2265191078186035
[1, 11816] loss_train: 0.005880, loss_test: 0.005675
time: 0.2510552406311035
time: 2.2442662715911865
[1, 11817] loss_train: 0.006772, loss_test: 0.005679
time: 0.2470555305480957
time: 2.224501609802246
[1, 11818] loss_train: 0.007418, loss_test: 0.005680
time: 0.24405431747436523
time: 2.234499931335449
[1, 11819] loss_train: 0.001829, loss_test: 0.005681
time: 0.24305415153503418
time: 2.221496820449829
[1, 11820] loss_train: 0.004926, loss_test: 0.005685
time: 0.25705647468566895
time: 2.2335023880004883
[1, 11821] loss_train: 0.002353, loss_test: 0.005690
time: 0.24405550956726074
time: 2.239501476287842
[1, 11822] loss_train: 0.000535, loss_test: 0.005695
time: 0.24505400657653809
time: 2.2234981060028076
[1, 11823] loss_train: 0.008212, loss_test: 0.005692
time: 0.24405336380004883
time: 2.2234978675842285
[1, 11824] loss_train: 0.007433, loss_test: 0.005684
time: 0.2470550537109375
time: 2.2530081272125244
[1, 11825] loss_train: 0.002501, loss_test: 0.005682
time: 0.24405407905578613
time: 2.216495990753174
[1, 11826] loss_train: 0.007632, loss_test: 0.005674
time: 0.24405360221862793
time: 2.2003238201141357
[1, 11827] loss_train: 0.006246, loss_test: 0.005669
time: 0.2510559558868408
time: 2.2728495597839355
[1, 11828] loss_train: 0.009566, loss_test: 0.005662
time: 0.24405384063720703
time: 2.2094948291778564
[1, 11829] loss_train: 0.009462, loss_test: 0.005657
time: 0.24405479431152344
time: 2.2335011959075928
[1, 11830] loss_train: 0.000715, loss_test: 0.005652
time: 0.25505685806274414
time: 2.259023666381836
[1, 11831] loss_train: 0.008019, loss_test: 0.005647
time: 0.24305295944213867
time: 2.217496395111084
[1, 11832] loss_train: 0.004044, loss_test: 0.005645
time: 0.2450542449951172
time: 2.217496156692505
[1, 11833] loss_train: 0.005359, loss_test: 0.005644
time: 0.24605488777160645
time: 2.214496612548828
[1, 11834] loss_train: 0.008166, loss_test: 0.005645
time: 0.2510559558868408
time: 2.22751522064209
[1, 11835] loss_train: 0.005313, loss_test: 0.005646
time: 0.2470548152923584
time: 2.1884915828704834
[1, 11836] loss_train: 0.001445, loss_test: 0.005644
time: 0.2450563907623291
time: 2.2215123176574707
[1, 11837] loss_train: 0.010933, loss_test: 0.005640
time: 0.24406814575195312
time: 2.2144947052001953
[1, 11838] loss_train: 0.009038, loss_test: 0.005631
time: 0.2450542449951172
time: 2.228499174118042
[1, 11839] loss_train: 0.012644, loss_test: 0.005623
time: 0.2490551471710205
time: 2.236006736755371
[1, 11840] loss_train: 0.004427, loss_test: 0.005621
time: 0.25505638122558594
time: 2.2645068168640137
[1, 11841] loss_train: 0.001993, loss_test: 0.005625
time: 0.25005507469177246
time: 2.2745091915130615
[1, 11842] loss_train: 0.005172, loss_test: 0.005634
time: 0.24405860900878906
time: 2.2264978885650635
[1, 11843] loss_train: 0.010162, loss_test: 0.005637
time: 0.2450549602508545
time: 2.2314987182617188
[1, 11844] loss_train: 0.003340, loss_test: 0.005639
time: 0.2450547218322754
time: 2.2314987182617188
[1, 11845] loss_train: 0.002468, loss_test: 0.005642
time: 0.24506711959838867
time: 2.219005584716797
[1, 11846] loss_train: 0.004260, loss_test: 0.005645
time: 0.24305415153503418
time: 2.254512071609497
[1, 11847] loss_train: 0.011233, loss_test: 0.005645
time: 0.24605441093444824
time: 2.207493782043457
[1, 11848] loss_train: 0.007901, loss_test: 0.005646
time: 0.24605441093444824
time: 2.1945409774780273
[1, 11849] loss_train: 0.008244, loss_test: 0.005653
time: 0.24405360221862793
time: 2.221175193786621
[1, 11850] loss_train: 0.004376, loss_test: 0.005657
time: 0.2560563087463379
time: 2.242502212524414
[1, 11851] loss_train: 0.003492, loss_test: 0.005667
time: 0.24405407905578613
time: 2.255504608154297
[1, 11852] loss_train: 0.001381, loss_test: 0.005657
time: 0.24305462837219238
time: 2.236499786376953
[1, 11853] loss_train: 0.001846, loss_test: 0.005642
time: 0.2450549602508545
time: 2.24051570892334
[1, 11854] loss_train: 0.008060, loss_test: 0.005631
time: 0.24405455589294434
time: 2.204493761062622
[1, 11855] loss_train: 0.009871, loss_test: 0.005622
time: 0.256056547164917
time: 2.223497152328491
[1, 11856] loss_train: 0.003252, loss_test: 0.005618
time: 0.24455881118774414
time: 2.2400095462799072
[1, 11857] loss_train: 0.012879, loss_test: 0.005615
time: 0.2490549087524414
time: 2.215496063232422
[1, 11858] loss_train: 0.006580, loss_test: 0.005614
time: 0.2470543384552002
time: 2.2135095596313477
[1, 11859] loss_train: 0.005757, loss_test: 0.005614
time: 0.2450542449951172
time: 2.2365198135375977
[1, 11860] loss_train: 0.001808, loss_test: 0.005615
time: 0.2550692558288574
time: 2.219498634338379
[1, 11861] loss_train: 0.003581, loss_test: 0.005615
time: 0.25005555152893066
time: 2.241501569747925
[1, 11862] loss_train: 0.006491, loss_test: 0.005615
time: 0.24405360221862793
time: 2.1955137252807617
[1, 11863] loss_train: 0.010227, loss_test: 0.005616
time: 0.24406099319458008
time: 2.2254981994628906
[1, 11864] loss_train: 0.009663, loss_test: 0.005616
time: 0.24405479431152344
time: 2.2014918327331543
[1, 11865] loss_train: 0.008445, loss_test: 0.005616
time: 0.2450542449951172
time: 2.261505603790283
[1, 11866] loss_train: 0.000682, loss_test: 0.005615
time: 0.24406695365905762
time: 2.218496322631836
[1, 11867] loss_train: 0.008588, loss_test: 0.005615
time: 0.24305319786071777
time: 2.243502140045166
[1, 11868] loss_train: 0.006799, loss_test: 0.005616
time: 0.24506711959838867
time: 2.216515302658081
[1, 11869] loss_train: 0.010202, loss_test: 0.005615
time: 0.24205350875854492
time: 2.2165112495422363
[1, 11870] loss_train: 0.004141, loss_test: 0.005611
time: 0.25505661964416504
time: 2.2545042037963867
[1, 11871] loss_train: 0.002267, loss_test: 0.005608
time: 0.24405407905578613
time: 2.2144954204559326
[1, 11872] loss_train: 0.007878, loss_test: 0.005605
time: 0.2490556240081787
time: 2.2130019664764404
[1, 11873] loss_train: 0.012089, loss_test: 0.005602
time: 0.2450554370880127
time: 2.2255001068115234
[1, 11874] loss_train: 0.007131, loss_test: 0.005602
time: 0.25005578994750977
time: 2.2545032501220703
[1, 11875] loss_train: 0.003446, loss_test: 0.005605
time: 0.24405431747436523
time: 2.2294979095458984
[1, 11876] loss_train: 0.003327, loss_test: 0.005611
time: 0.24806833267211914
time: 2.223515748977661
[1, 11877] loss_train: 0.007717, loss_test: 0.005620
time: 0.24505400657653809
time: 2.2315077781677246
[1, 11878] loss_train: 0.004018, loss_test: 0.005630
time: 0.24606704711914062
time: 2.2134950160980225
[1, 11879] loss_train: 0.003885, loss_test: 0.005642
time: 0.24405360221862793
time: 2.2224979400634766
[1, 11880] loss_train: 0.007293, loss_test: 0.005651
time: 0.25705838203430176
time: 2.24993896484375
[1, 11881] loss_train: 0.007574, loss_test: 0.005643
time: 0.24405479431152344
time: 2.23539400100708
[1, 11882] loss_train: 0.007626, loss_test: 0.005638
time: 0.24805498123168945
time: 2.2134952545166016
[1, 11883] loss_train: 0.006650, loss_test: 0.005621
time: 0.24405956268310547
time: 2.2264976501464844
[1, 11884] loss_train: 0.011426, loss_test: 0.005596
time: 0.2450547218322754
time: 2.2295072078704834
[1, 11885] loss_train: 0.004591, loss_test: 0.005588
time: 0.24406766891479492
time: 2.221496105194092
[1, 11886] loss_train: 0.007536, loss_test: 0.005592
time: 0.24306774139404297
time: 2.220496416091919
[1, 11887] loss_train: 0.010905, loss_test: 0.005606
time: 0.24305438995361328
time: 2.206495761871338
[1, 11888] loss_train: 0.004311, loss_test: 0.005624
time: 0.24305391311645508
time: 2.1975414752960205
[1, 11889] loss_train: 0.005885, loss_test: 0.005637
time: 0.24605441093444824
time: 2.2475030422210693
[1, 11890] loss_train: 0.005366, loss_test: 0.005633
time: 0.2570838928222656
time: 2.2505087852478027
[1, 11891] loss_train: 0.004846, loss_test: 0.005622
time: 0.2470552921295166
time: 2.2755088806152344
[1, 11892] loss_train: 0.005433, loss_test: 0.005608
time: 0.2470550537109375
time: 2.2247977256774902
[1, 11893] loss_train: 0.013620, loss_test: 0.005600
time: 0.2450566291809082
time: 2.2294983863830566
[1, 11894] loss_train: 0.001662, loss_test: 0.005596
time: 0.2450542449951172
time: 2.2140040397644043
[1, 11895] loss_train: 0.006345, loss_test: 0.005601
time: 0.25005531311035156
time: 2.2465195655822754
[1, 11896] loss_train: 0.006350, loss_test: 0.005612
time: 0.24605441093444824
time: 2.221497058868408
[1, 11897] loss_train: 0.003019, loss_test: 0.005630
time: 0.2470541000366211
time: 2.216496229171753
[1, 11898] loss_train: 0.008465, loss_test: 0.005649
time: 0.24455857276916504
time: 2.2164955139160156
[1, 11899] loss_train: 0.006118, loss_test: 0.005653
time: 0.24305438995361328
time: 2.225497007369995
[1, 11900] loss_train: 0.004648, loss_test: 0.005655
time: 0.256056547164917
time: 2.2665069103240967
[1, 11901] loss_train: 0.009665, loss_test: 0.005655
time: 0.24208283424377441
time: 2.2395033836364746
[1, 11902] loss_train: 0.003690, loss_test: 0.005656
time: 0.24305415153503418
time: 2.2284984588623047
[1, 11903] loss_train: 0.011438, loss_test: 0.005651
time: 0.24305391311645508
time: 2.2034950256347656
[1, 11904] loss_train: 0.006717, loss_test: 0.005641
time: 0.2450549602508545
time: 2.248260498046875
[1, 11905] loss_train: 0.004731, loss_test: 0.005633
time: 0.2450547218322754
time: 2.223497152328491
[1, 11906] loss_train: 0.006564, loss_test: 0.005623
time: 0.2470548152923584
time: 2.2069976329803467
[1, 11907] loss_train: 0.007246, loss_test: 0.005614
time: 0.2430558204650879
time: 2.2304985523223877
[1, 11908] loss_train: 0.007276, loss_test: 0.005604
time: 0.24605441093444824
time: 2.2114975452423096
[1, 11909] loss_train: 0.019141, loss_test: 0.005604
time: 0.24405384063720703
time: 2.209996223449707
[1, 11910] loss_train: 0.011351, loss_test: 0.005622
time: 0.25606822967529297
time: 2.245502471923828
[1, 11911] loss_train: 0.003888, loss_test: 0.005648
time: 0.24405479431152344
time: 2.2275311946868896
[1, 11912] loss_train: 0.008942, loss_test: 0.005668
time: 0.2450556755065918
time: 2.21049427986145
[1, 11913] loss_train: 0.011121, loss_test: 0.005685
time: 0.2540562152862549
time: 2.2250123023986816
[1, 11914] loss_train: 0.005422, loss_test: 0.005677
time: 0.25005578994750977
time: 2.217495918273926
[1, 11915] loss_train: 0.005200, loss_test: 0.005669
time: 0.24305367469787598
time: 2.250016689300537
[1, 11916] loss_train: 0.007457, loss_test: 0.005655
time: 0.24805569648742676
time: 2.2334988117218018
[1, 11917] loss_train: 0.009833, loss_test: 0.005636
time: 0.24506568908691406
time: 2.228499174118042
[1, 11918] loss_train: 0.012898, loss_test: 0.005618
time: 0.24805450439453125
time: 2.2224979400634766
[1, 11919] loss_train: 0.001349, loss_test: 0.005604
time: 0.24305319786071777
time: 2.187994956970215
[1, 11920] loss_train: 0.009771, loss_test: 0.005597
time: 0.258056640625
time: 2.239501476287842
[1, 11921] loss_train: 0.003421, loss_test: 0.005598
time: 0.24405479431152344
time: 2.2319324016571045
[1, 11922] loss_train: 0.001899, loss_test: 0.005608
time: 0.2426588535308838
time: 2.236501932144165
[1, 11923] loss_train: 0.007634, loss_test: 0.005623
time: 0.24405479431152344
time: 2.2365005016326904
[1, 11924] loss_train: 0.003800, loss_test: 0.005644
time: 0.24406695365905762
time: 2.225499153137207
[1, 11925] loss_train: 0.004451, loss_test: 0.005662
time: 0.24305438995361328
time: 2.2355024814605713
[1, 11926] loss_train: 0.013305, loss_test: 0.005666
time: 0.24405384063720703
time: 2.2214972972869873
[1, 11927] loss_train: 0.004544, loss_test: 0.005669
time: 0.24505400657653809
time: 2.2130110263824463
[1, 11928] loss_train: 0.009322, loss_test: 0.005664
time: 0.24405384063720703
time: 2.2535064220428467
[1, 11929] loss_train: 0.007339, loss_test: 0.005657
time: 0.2490551471710205
time: 2.233499765396118
[1, 11930] loss_train: 0.005005, loss_test: 0.005651
time: 0.25905728340148926
time: 2.2355003356933594
[1, 11931] loss_train: 0.007032, loss_test: 0.005638
time: 0.24405384063720703
time: 2.2134957313537598
[1, 11932] loss_train: 0.003118, loss_test: 0.005631
time: 0.2450542449951172
time: 2.257504940032959
[1, 11933] loss_train: 0.007468, loss_test: 0.005620
time: 0.2450542449951172
time: 2.2014925479888916
[1, 11934] loss_train: 0.003042, loss_test: 0.005611
time: 0.24505400657653809
time: 2.2134952545166016
[1, 11935] loss_train: 0.010195, loss_test: 0.005605
time: 0.24605417251586914
time: 2.256514549255371
[1, 11936] loss_train: 0.006111, loss_test: 0.005603
time: 0.24405384063720703
time: 2.226498603820801
[1, 11937] loss_train: 0.005550, loss_test: 0.005601
time: 0.2490549087524414
time: 2.2365007400512695
[1, 11938] loss_train: 0.008345, loss_test: 0.005600
time: 0.2470545768737793
time: 2.226020336151123
[1, 11939] loss_train: 0.002261, loss_test: 0.005600
time: 0.24505400657653809
time: 2.216010570526123
[1, 11940] loss_train: 0.007109, loss_test: 0.005600
time: 0.2580573558807373
time: 2.2785143852233887
[1, 11941] loss_train: 0.014891, loss_test: 0.005598
time: 0.24606657028198242
time: 2.2014927864074707
[1, 11942] loss_train: 0.013634, loss_test: 0.005604
time: 0.24405384063720703
time: 2.2595057487487793
[1, 11943] loss_train: 0.005729, loss_test: 0.005615
time: 0.24405479431152344
time: 2.235499620437622
[1, 11944] loss_train: 0.006247, loss_test: 0.005628
time: 0.2450544834136963
time: 2.213013172149658
[1, 11945] loss_train: 0.004049, loss_test: 0.005637
time: 0.2470543384552002
time: 2.231010913848877
[1, 11946] loss_train: 0.018966, loss_test: 0.005649
time: 0.24205327033996582
time: 2.2024972438812256
[1, 11947] loss_train: 0.006382, loss_test: 0.005655
time: 0.24605512619018555
time: 2.237499952316284
[1, 11948] loss_train: 0.002215, loss_test: 0.005643
time: 0.24305391311645508
time: 2.220526695251465
[1, 11949] loss_train: 0.004781, loss_test: 0.005626
time: 0.247053861618042
time: 2.238980770111084
[1, 11950] loss_train: 0.009512, loss_test: 0.005611
time: 0.25705671310424805
time: 2.275116205215454
[1, 11951] loss_train: 0.007032, loss_test: 0.005602
time: 0.24305391311645508
time: 2.2114944458007812
[1, 11952] loss_train: 0.001685, loss_test: 0.005604
time: 0.24405360221862793
time: 2.226062297821045
[1, 11953] loss_train: 0.005526, loss_test: 0.005619
time: 0.24405384063720703
time: 2.2284982204437256
[1, 11954] loss_train: 0.008797, loss_test: 0.005640
time: 0.2470550537109375
time: 2.2244999408721924
[1, 11955] loss_train: 0.005890, loss_test: 0.005661
time: 0.24405455589294434
time: 2.2124948501586914
[1, 11956] loss_train: 0.007314, loss_test: 0.005678
time: 0.25005578994750977
time: 2.2224955558776855
[1, 11957] loss_train: 0.006163, loss_test: 0.005685
time: 0.24805569648742676
time: 2.2345120906829834
[1, 11958] loss_train: 0.007542, loss_test: 0.005668
time: 0.2470541000366211
time: 2.2500290870666504
[1, 11959] loss_train: 0.004944, loss_test: 0.005654
time: 0.24506592750549316
time: 2.2184970378875732
[1, 11960] loss_train: 0.009667, loss_test: 0.005633
time: 0.2600572109222412
time: 2.2365169525146484
[1, 11961] loss_train: 0.009564, loss_test: 0.005620
time: 0.24505376815795898
time: 2.1984920501708984
[1, 11962] loss_train: 0.008870, loss_test: 0.005615
time: 0.24306702613830566
time: 2.237513542175293
[1, 11963] loss_train: 0.006736, loss_test: 0.005618
time: 0.24305462837219238
time: 2.2234995365142822
[1, 11964] loss_train: 0.006920, loss_test: 0.005626
time: 0.2490549087524414
time: 2.2362608909606934
[1, 11965] loss_train: 0.008435, loss_test: 0.005637
time: 0.24306631088256836
time: 2.2310304641723633
[1, 11966] loss_train: 0.003502, loss_test: 0.005644
time: 0.2450556755065918
time: 2.232508897781372
[1, 11967] loss_train: 0.007110, loss_test: 0.005645
time: 0.24405431747436523
time: 2.238030195236206
[1, 11968] loss_train: 0.002369, loss_test: 0.005639
time: 0.24405407905578613
time: 2.244502305984497
[1, 11969] loss_train: 0.007195, loss_test: 0.005630
time: 0.24405360221862793
time: 2.2470057010650635
[1, 11970] loss_train: 0.012258, loss_test: 0.005625
time: 0.2540624141693115
time: 2.228019952774048
[1, 11971] loss_train: 0.003403, loss_test: 0.005618
time: 0.2470550537109375
time: 2.212496519088745
[1, 11972] loss_train: 0.002632, loss_test: 0.005611
time: 0.24405384063720703
time: 2.2274985313415527
[1, 11973] loss_train: 0.007916, loss_test: 0.005607
time: 0.24505400657653809
time: 2.1804919242858887
[1, 11974] loss_train: 0.004735, loss_test: 0.005606
time: 0.2450554370880127
time: 2.228555917739868
[1, 11975] loss_train: 0.003441, loss_test: 0.005610
time: 0.2490558624267578
time: 2.212494134902954
[1, 11976] loss_train: 0.005239, loss_test: 0.005617
time: 0.24292993545532227
time: 2.2054929733276367
[1, 11977] loss_train: 0.006930, loss_test: 0.005625
time: 0.24805521965026855
time: 2.2014923095703125
[1, 11978] loss_train: 0.009540, loss_test: 0.005630
time: 0.24805521965026855
time: 2.232499599456787
[1, 11979] loss_train: 0.002875, loss_test: 0.005637
time: 0.24405455589294434
time: 2.221527099609375
[1, 11980] loss_train: 0.012880, loss_test: 0.005636
time: 0.2580709457397461
time: 2.2615058422088623
[1, 11981] loss_train: 0.004266, loss_test: 0.005640
time: 0.24505376815795898
time: 2.2224979400634766
[1, 11982] loss_train: 0.001026, loss_test: 0.005641
time: 0.24405384063720703
time: 2.1935012340545654
[1, 11983] loss_train: 0.007754, loss_test: 0.005643
time: 0.24405336380004883
time: 2.2275054454803467
[1, 11984] loss_train: 0.004199, loss_test: 0.005646
time: 0.2450547218322754
time: 2.230498790740967
[1, 11985] loss_train: 0.003809, loss_test: 0.005649
time: 0.24406671524047852
time: 2.2260024547576904
[1, 11986] loss_train: 0.003636, loss_test: 0.005651
time: 0.2440662384033203
time: 2.240501880645752
[1, 11987] loss_train: 0.010344, loss_test: 0.005644
time: 0.24305415153503418
time: 2.2385005950927734
[1, 11988] loss_train: 0.001771, loss_test: 0.005639
time: 0.24605417251586914
time: 2.2405216693878174
[1, 11989] loss_train: 0.004036, loss_test: 0.005635
time: 0.24405431747436523
time: 2.2284982204437256
[1, 11990] loss_train: 0.004380, loss_test: 0.005630
time: 0.25705718994140625
time: 2.2505033016204834
[1, 11991] loss_train: 0.000887, loss_test: 0.005632
time: 0.24542808532714844
time: 2.239501476287842
[1, 11992] loss_train: 0.004004, loss_test: 0.005635
time: 0.24305343627929688
time: 2.224001407623291
[1, 11993] loss_train: 0.009379, loss_test: 0.005631
time: 0.24405574798583984
time: 2.203493118286133
[1, 11994] loss_train: 0.004677, loss_test: 0.005630
time: 0.2490551471710205
time: 2.244502067565918
[1, 11995] loss_train: 0.009983, loss_test: 0.005628
time: 0.243056058883667
time: 2.2014927864074707
[1, 11996] loss_train: 0.007809, loss_test: 0.005620
time: 0.2490549087524414
time: 2.2205145359039307
[1, 11997] loss_train: 0.004829, loss_test: 0.005616
time: 0.24405431747436523
time: 2.243501663208008
[1, 11998] loss_train: 0.002982, loss_test: 0.005614
time: 0.2580575942993164
time: 2.2195053100585938
[1, 11999] loss_train: 0.000856, loss_test: 0.005610
time: 0.2450544834136963
time: 2.2254977226257324
[1, 12000] loss_train: 0.009400, loss_test: 0.005611
time: 0.2540566921234131
time: 2.2505035400390625
[1, 12001] loss_train: 0.008591, loss_test: 0.005611
time: 0.24405360221862793
time: 2.243502140045166
[1, 12002] loss_train: 0.002845, loss_test: 0.005611
time: 0.2450549602508545
time: 2.23349928855896
[1, 12003] loss_train: 0.006341, loss_test: 0.005608
time: 0.24405336380004883
time: 2.2024929523468018
[1, 12004] loss_train: 0.012642, loss_test: 0.005607
time: 0.2450544834136963
time: 2.219496011734009
[1, 12005] loss_train: 0.009265, loss_test: 0.005608
time: 0.2455582618713379
time: 2.231008291244507
[1, 12006] loss_train: 0.009557, loss_test: 0.005610
time: 0.24305272102355957
time: 2.2135109901428223
[1, 12007] loss_train: 0.005598, loss_test: 0.005616
time: 0.24305462837219238
time: 2.2304983139038086
[1, 12008] loss_train: 0.006087, loss_test: 0.005615
time: 0.24405407905578613
time: 2.255504846572876
[1, 12009] loss_train: 0.007245, loss_test: 0.005617
time: 0.24305367469787598
time: 2.235360860824585
[1, 12010] loss_train: 0.002808, loss_test: 0.005616
time: 0.2540562152862549
time: 2.259507894515991
[1, 12011] loss_train: 0.004838, loss_test: 0.005615
time: 0.2470545768737793
time: 2.234502077102661
[1, 12012] loss_train: 0.012089, loss_test: 0.005612
time: 0.24405407905578613
time: 2.2274982929229736
[1, 12013] loss_train: 0.001798, loss_test: 0.005610
time: 0.24305415153503418
time: 2.2234973907470703
[1, 12014] loss_train: 0.004223, loss_test: 0.005609
time: 0.24406671524047852
time: 2.2154953479766846
[1, 12015] loss_train: 0.002014, loss_test: 0.005607
time: 0.24405384063720703
time: 2.2310192584991455
[1, 12016] loss_train: 0.008072, loss_test: 0.005608
time: 0.24605417251586914
time: 2.250521659851074
[1, 12017] loss_train: 0.006544, loss_test: 0.005610
time: 0.2490556240081787
time: 2.228497266769409
[1, 12018] loss_train: 0.006015, loss_test: 0.005612
time: 0.2470550537109375
time: 2.2014925479888916
[1, 12019] loss_train: 0.004992, loss_test: 0.005618
time: 0.2490546703338623
time: 2.215000629425049
[1, 12020] loss_train: 0.003421, loss_test: 0.005625
time: 0.25705766677856445
time: 2.2775087356567383
[1, 12021] loss_train: 0.002632, loss_test: 0.005637
time: 0.24805545806884766
time: 2.218496322631836
[1, 12022] loss_train: 0.003289, loss_test: 0.005654
time: 0.24505400657653809
time: 2.245502233505249
[1, 12023] loss_train: 0.015288, loss_test: 0.005657
time: 0.24506592750549316
time: 2.259505271911621
[1, 12024] loss_train: 0.003031, loss_test: 0.005662
time: 0.24205374717712402
time: 2.2294983863830566
[1, 12025] loss_train: 0.007553, loss_test: 0.005661
time: 0.24405455589294434
time: 2.255021333694458
[1, 12026] loss_train: 0.005100, loss_test: 0.005655
time: 0.24306607246398926
time: 2.202300548553467
[1, 12027] loss_train: 0.003743, loss_test: 0.005648
time: 0.24405407905578613
time: 2.2360031604766846
[1, 12028] loss_train: 0.002296, loss_test: 0.005645
time: 0.24605464935302734
time: 2.221497058868408
[1, 12029] loss_train: 0.008458, loss_test: 0.005638
time: 0.24405455589294434
time: 2.2265067100524902
[1, 12030] loss_train: 0.007034, loss_test: 0.005633
time: 0.25705790519714355
time: 2.251614570617676
[1, 12031] loss_train: 0.006289, loss_test: 0.005627
time: 0.24607038497924805
time: 2.242518424987793
[1, 12032] loss_train: 0.012105, loss_test: 0.005617
time: 0.24405407905578613
time: 2.2465028762817383
[1, 12033] loss_train: 0.000347, loss_test: 0.005612
time: 0.2434217929840088
time: 2.2264978885650635
[1, 12034] loss_train: 0.008180, loss_test: 0.005610
time: 0.24405503273010254
time: 2.2435176372528076
[1, 12035] loss_train: 0.006669, loss_test: 0.005611
time: 0.24305438995361328
time: 2.2370049953460693
[1, 12036] loss_train: 0.008142, loss_test: 0.005614
time: 0.24405360221862793
time: 2.218496084213257
[1, 12037] loss_train: 0.004021, loss_test: 0.005616
time: 0.24405407905578613
time: 2.228034496307373
[1, 12038] loss_train: 0.006734, loss_test: 0.005618
time: 0.24305438995361328
time: 2.210489511489868
[1, 12039] loss_train: 0.005243, loss_test: 0.005619
time: 0.24405336380004883
time: 2.2265079021453857
[1, 12040] loss_train: 0.009601, loss_test: 0.005619
time: 0.2580571174621582
time: 2.2224974632263184
[1, 12041] loss_train: 0.005395, loss_test: 0.005619
time: 0.2470552921295166
time: 2.229498863220215
[1, 12042] loss_train: 0.004935, loss_test: 0.005619
time: 0.25005555152893066
time: 2.193490982055664
[1, 12043] loss_train: 0.006877, loss_test: 0.005620
time: 0.24505376815795898
time: 2.2204973697662354
[1, 12044] loss_train: 0.014090, loss_test: 0.005618
time: 0.24605393409729004
time: 2.243506669998169
[1, 12045] loss_train: 0.007426, loss_test: 0.005611
time: 0.24459218978881836
time: 2.210494041442871
[1, 12046] loss_train: 0.009374, loss_test: 0.005607
time: 0.24205398559570312
time: 2.2035152912139893
[1, 12047] loss_train: 0.004784, loss_test: 0.005602
time: 0.24508047103881836
time: 2.2034924030303955
[1, 12048] loss_train: 0.014551, loss_test: 0.005601
time: 0.24205374717712402
time: 2.2254979610443115
[1, 12049] loss_train: 0.005540, loss_test: 0.005604
time: 0.24305319786071777
time: 2.2235069274902344
[1, 12050] loss_train: 0.008002, loss_test: 0.005609
time: 0.2560689449310303
time: 2.243502616882324
[1, 12051] loss_train: 0.001751, loss_test: 0.005614
time: 0.24405360221862793
time: 2.257030725479126
[1, 12052] loss_train: 0.004534, loss_test: 0.005620
time: 0.24405384063720703
time: 2.2605745792388916
[1, 12053] loss_train: 0.007434, loss_test: 0.005626
time: 0.24305319786071777
time: 2.229499340057373
[1, 12054] loss_train: 0.006239, loss_test: 0.005631
time: 0.24405288696289062
time: 2.255504846572876
[1, 12055] loss_train: 0.003847, loss_test: 0.005639
time: 0.2450542449951172
time: 2.2336223125457764
[1, 12056] loss_train: 0.002505, loss_test: 0.005650
time: 0.24406790733337402
time: 2.22249698638916
[1, 12057] loss_train: 0.013169, loss_test: 0.005652
time: 0.24605417251586914
time: 2.2350244522094727
[1, 12058] loss_train: 0.003918, loss_test: 0.005655
time: 0.24405503273010254
time: 2.2114944458007812
[1, 12059] loss_train: 0.005153, loss_test: 0.005659
time: 0.24605488777160645
time: 2.2174956798553467
[1, 12060] loss_train: 0.007762, loss_test: 0.005660
time: 0.2580573558807373
time: 2.274508476257324
[1, 12061] loss_train: 0.006180, loss_test: 0.005660
time: 0.24605584144592285
time: 2.225497007369995
[1, 12062] loss_train: 0.004055, loss_test: 0.005663
time: 0.24405431747436523
time: 2.2135045528411865
[1, 12063] loss_train: 0.008747, loss_test: 0.005663
time: 0.251068115234375
time: 2.2129993438720703
[1, 12064] loss_train: 0.010623, loss_test: 0.005658
time: 0.24505400657653809
time: 2.2024929523468018
[1, 12065] loss_train: 0.010736, loss_test: 0.005650
time: 0.24605488777160645
time: 2.2055013179779053
[1, 12066] loss_train: 0.004189, loss_test: 0.005641
time: 0.2565581798553467
time: 2.25850510597229
[1, 12067] loss_train: 0.008199, loss_test: 0.005636
time: 0.24305486679077148
time: 2.2236897945404053
[1, 12068] loss_train: 0.004597, loss_test: 0.005635
time: 0.24405550956726074
time: 2.249519109725952
[1, 12069] loss_train: 0.004152, loss_test: 0.005636
time: 0.24506664276123047
time: 2.256014585494995
[1, 12070] loss_train: 0.003717, loss_test: 0.005638
time: 0.2560563087463379
time: 2.278510332107544
[1, 12071] loss_train: 0.006037, loss_test: 0.005641
time: 0.24405431747436523
time: 2.2325289249420166
[1, 12072] loss_train: 0.004621, loss_test: 0.005644
time: 0.24405431747436523
time: 2.217495918273926
[1, 12073] loss_train: 0.005777, loss_test: 0.005643
time: 0.2450547218322754
time: 2.260507345199585
[1, 12074] loss_train: 0.002888, loss_test: 0.005643
time: 0.24405384063720703
time: 2.2465028762817383
[1, 12075] loss_train: 0.003598, loss_test: 0.005636
time: 0.24305438995361328
time: 2.2024922370910645
[1, 12076] loss_train: 0.009604, loss_test: 0.005628
time: 0.24505400657653809
time: 2.216496467590332
[1, 12077] loss_train: 0.010958, loss_test: 0.005620
time: 0.24205350875854492
time: 2.2114970684051514
[1, 12078] loss_train: 0.009185, loss_test: 0.005613
time: 0.24205398559570312
time: 2.204038619995117
[1, 12079] loss_train: 0.001906, loss_test: 0.005612
time: 0.24405384063720703
time: 2.214495897293091
[1, 12080] loss_train: 0.005491, loss_test: 0.005617
time: 0.25505661964416504
time: 2.2515151500701904
[1, 12081] loss_train: 0.002565, loss_test: 0.005627
time: 0.24305343627929688
time: 2.2335000038146973
[1, 12082] loss_train: 0.005649, loss_test: 0.005641
time: 0.24605488777160645
time: 2.2255165576934814
[1, 12083] loss_train: 0.003194, loss_test: 0.005657
time: 0.24305415153503418
time: 2.212012767791748
[1, 12084] loss_train: 0.006842, loss_test: 0.005674
time: 0.2470555305480957
time: 2.229520082473755
[1, 12085] loss_train: 0.007395, loss_test: 0.005680
time: 0.24805569648742676
time: 2.2543442249298096
[1, 12086] loss_train: 0.004673, loss_test: 0.005684
time: 0.24805545806884766
time: 2.2365000247955322
[1, 12087] loss_train: 0.002153, loss_test: 0.005688
time: 0.24305343627929688
time: 2.2274985313415527
[1, 12088] loss_train: 0.011093, loss_test: 0.005662
time: 0.2470548152923584
time: 2.2395012378692627
[1, 12089] loss_train: 0.002609, loss_test: 0.005645
time: 0.24405384063720703
time: 2.2154958248138428
[1, 12090] loss_train: 0.007206, loss_test: 0.005633
time: 0.2540557384490967
time: 2.2715089321136475
[1, 12091] loss_train: 0.008322, loss_test: 0.005631
time: 0.2490549087524414
time: 2.2535037994384766
[1, 12092] loss_train: 0.001602, loss_test: 0.005636
time: 0.24305462837219238
time: 2.217496156692505
[1, 12093] loss_train: 0.010018, loss_test: 0.005639
time: 0.24405360221862793
time: 2.2605063915252686
[1, 12094] loss_train: 0.008942, loss_test: 0.005642
time: 0.24305486679077148
time: 2.242077112197876
[1, 12095] loss_train: 0.004104, loss_test: 0.005640
time: 0.24506640434265137
time: 2.2355000972747803
[1, 12096] loss_train: 0.006061, loss_test: 0.005632
time: 0.24405431747436523
time: 2.2244348526000977
[1, 12097] loss_train: 0.010747, loss_test: 0.005628
time: 0.24408245086669922
time: 2.244501829147339
[1, 12098] loss_train: 0.009269, loss_test: 0.005624
time: 0.247053861618042
time: 2.220025062561035
[1, 12099] loss_train: 0.006580, loss_test: 0.005618
time: 0.24405455589294434
time: 2.223496675491333
[1, 12100] loss_train: 0.006132, loss_test: 0.005615
time: 0.25505614280700684
time: 2.2540078163146973
[1, 12101] loss_train: 0.004296, loss_test: 0.005614
time: 0.2450542449951172
time: 2.208494186401367
[1, 12102] loss_train: 0.001474, loss_test: 0.005615
time: 0.24305391311645508
time: 2.206493854522705
[1, 12103] loss_train: 0.009793, loss_test: 0.005616
time: 0.24405360221862793
time: 2.239501476287842
[1, 12104] loss_train: 0.006285, loss_test: 0.005615
time: 0.24405384063720703
time: 2.217496633529663
[1, 12105] loss_train: 0.003863, loss_test: 0.005616
time: 0.24625205993652344
time: 2.219496726989746
[1, 12106] loss_train: 0.006093, loss_test: 0.005617
time: 0.2400529384613037
time: 2.2195117473602295
[1, 12107] loss_train: 0.005493, loss_test: 0.005620
time: 0.24805402755737305
time: 2.216495990753174
[1, 12108] loss_train: 0.006648, loss_test: 0.005623
time: 0.24105358123779297
time: 2.2385008335113525
[1, 12109] loss_train: 0.002666, loss_test: 0.005628
time: 0.25005602836608887
time: 2.261436939239502
[1, 12110] loss_train: 0.010064, loss_test: 0.005629
time: 0.25505661964416504
time: 2.2465016841888428
[1, 12111] loss_train: 0.002416, loss_test: 0.005632
time: 0.2490684986114502
time: 2.2165043354034424
[1, 12112] loss_train: 0.005810, loss_test: 0.005636
time: 0.24406909942626953
time: 2.254514694213867
[1, 12113] loss_train: 0.007881, loss_test: 0.005639
time: 0.2470545768737793
time: 2.2285068035125732
[1, 12114] loss_train: 0.006148, loss_test: 0.005639
time: 0.2450549602508545
time: 2.2044990062713623
[1, 12115] loss_train: 0.009796, loss_test: 0.005633
time: 0.2470545768737793
time: 2.2440052032470703
[1, 12116] loss_train: 0.012716, loss_test: 0.005626
time: 0.2450547218322754
time: 2.258504629135132
[1, 12117] loss_train: 0.002297, loss_test: 0.005625
time: 0.24305367469787598
time: 2.261535167694092
[1, 12118] loss_train: 0.007784, loss_test: 0.005624
time: 0.2450547218322754
time: 2.221496105194092
[1, 12119] loss_train: 0.005487, loss_test: 0.005623
time: 0.24405431747436523
time: 2.1891462802886963
[1, 12120] loss_train: 0.013848, loss_test: 0.005620
time: 0.2560570240020752
time: 2.2545042037963867
[1, 12121] loss_train: 0.002423, loss_test: 0.005617
time: 0.24405360221862793
time: 2.220496892929077
[1, 12122] loss_train: 0.002094, loss_test: 0.005616
time: 0.24405431747436523
time: 2.245502233505249
[1, 12123] loss_train: 0.010743, loss_test: 0.005619
time: 0.24405455589294434
time: 2.208493947982788
[1, 12124] loss_train: 0.005511, loss_test: 0.005621
time: 0.24405431747436523
time: 2.2014923095703125
[1, 12125] loss_train: 0.007493, loss_test: 0.005622
time: 0.24606800079345703
time: 2.2065093517303467
[1, 12126] loss_train: 0.005084, loss_test: 0.005618
time: 0.24405384063720703
time: 2.205493450164795
[1, 12127] loss_train: 0.011249, loss_test: 0.005617
time: 0.2450542449951172
time: 2.212038040161133
[1, 12128] loss_train: 0.011624, loss_test: 0.005617
time: 0.2490546703338623
time: 2.219496965408325
[1, 12129] loss_train: 0.004669, loss_test: 0.005613
time: 0.24506640434265137
time: 2.243839979171753
[1, 12130] loss_train: 0.001052, loss_test: 0.005610
time: 0.2580568790435791
time: 2.2244982719421387
[1, 12131] loss_train: 0.007116, loss_test: 0.005612
time: 0.2450549602508545
time: 2.220839023590088
[1, 12132] loss_train: 0.008828, loss_test: 0.005614
time: 0.24605512619018555
time: 2.2385010719299316
[1, 12133] loss_train: 0.008202, loss_test: 0.005620
time: 0.24406719207763672
time: 2.217496633529663
[1, 12134] loss_train: 0.003511, loss_test: 0.005631
time: 0.2450547218322754
time: 2.2314987182617188
[1, 12135] loss_train: 0.012832, loss_test: 0.005634
time: 0.24305367469787598
time: 2.22149920463562
[1, 12136] loss_train: 0.012462, loss_test: 0.005621
time: 0.24305438995361328
time: 2.2124946117401123
[1, 12137] loss_train: 0.003192, loss_test: 0.005615
time: 0.2430589199066162
time: 2.2545042037963867
[1, 12138] loss_train: 0.001986, loss_test: 0.005612
time: 0.2450697422027588
time: 2.218496799468994
[1, 12139] loss_train: 0.007282, loss_test: 0.005609
time: 0.2450547218322754
time: 2.212519884109497
[1, 12140] loss_train: 0.003667, loss_test: 0.005606
time: 0.2560572624206543
time: 2.2535130977630615
[1, 12141] loss_train: 0.007724, loss_test: 0.005604
time: 0.24305438995361328
time: 2.205005407333374
[1, 12142] loss_train: 0.001422, loss_test: 0.005602
time: 0.24255776405334473
time: 2.2104947566986084
[1, 12143] loss_train: 0.007826, loss_test: 0.005602
time: 0.24405407905578613
time: 2.255523204803467
[1, 12144] loss_train: 0.004112, loss_test: 0.005603
time: 0.24605464935302734
time: 2.2154958248138428
[1, 12145] loss_train: 0.006238, loss_test: 0.005604
time: 0.24805498123168945
time: 2.2305068969726562
[1, 12146] loss_train: 0.005965, loss_test: 0.005603
time: 0.2470548152923584
time: 2.2205810546875
[1, 12147] loss_train: 0.005594, loss_test: 0.005602
time: 0.24806809425354004
time: 2.206494092941284
[1, 12148] loss_train: 0.013554, loss_test: 0.005603
time: 0.24505400657653809
time: 2.2275009155273438
[1, 12149] loss_train: 0.001676, loss_test: 0.005603
time: 0.24605441093444824
time: 2.1864919662475586
[1, 12150] loss_train: 0.005698, loss_test: 0.005602
time: 0.25705742835998535
time: 2.2655065059661865
[1, 12151] loss_train: 0.002345, loss_test: 0.005599
time: 0.2450547218322754
time: 2.2054929733276367
[1, 12152] loss_train: 0.015940, loss_test: 0.005600
time: 0.24305367469787598
time: 2.205004930496216
[1, 12153] loss_train: 0.008253, loss_test: 0.005602
time: 0.2470552921295166
time: 2.25750470161438
[1, 12154] loss_train: 0.008685, loss_test: 0.005604
time: 0.2450547218322754
time: 2.282510280609131
[1, 12155] loss_train: 0.002961, loss_test: 0.005605
time: 0.24405431747436523
time: 2.2044925689697266
[1, 12156] loss_train: 0.009782, loss_test: 0.005607
time: 0.24405407905578613
time: 2.22249698638916
[1, 12157] loss_train: 0.006163, loss_test: 0.005611
time: 0.24305391311645508
time: 2.2274980545043945
[1, 12158] loss_train: 0.005966, loss_test: 0.005616
time: 0.24406790733337402
time: 2.2125117778778076
[1, 12159] loss_train: 0.003923, loss_test: 0.005622
time: 0.24305343627929688
time: 2.2160298824310303
[1, 12160] loss_train: 0.013347, loss_test: 0.005630
time: 0.25706911087036133
time: 2.2680139541625977
[1, 12161] loss_train: 0.010947, loss_test: 0.005630
time: 0.24405360221862793
time: 2.217496395111084
[1, 12162] loss_train: 0.010231, loss_test: 0.005631
time: 0.24505400657653809
time: 2.20175838470459
[1, 12163] loss_train: 0.008175, loss_test: 0.005629
time: 0.24705982208251953
time: 2.2015092372894287
[1, 12164] loss_train: 0.005931, loss_test: 0.005622
time: 0.2490549087524414
time: 2.231499671936035
[1, 12165] loss_train: 0.004883, loss_test: 0.005616
time: 0.2450542449951172
time: 2.221510648727417
[1, 12166] loss_train: 0.008952, loss_test: 0.005611
time: 0.24905633926391602
time: 2.2505033016204834
[1, 12167] loss_train: 0.006162, loss_test: 0.005610
time: 0.24305295944213867
time: 2.255505084991455
[1, 12168] loss_train: 0.012834, loss_test: 0.005610
time: 0.2470545768737793
time: 2.2465028762817383
[1, 12169] loss_train: 0.004603, loss_test: 0.005611
time: 0.24405455589294434
time: 2.2265102863311768
[1, 12170] loss_train: 0.001980, loss_test: 0.005609
time: 0.2600703239440918
time: 2.270533561706543
[1, 12171] loss_train: 0.003266, loss_test: 0.005607
time: 0.24405407905578613
time: 2.2315146923065186
[1, 12172] loss_train: 0.005441, loss_test: 0.005605
time: 0.24605512619018555
time: 2.216503143310547
[1, 12173] loss_train: 0.001726, loss_test: 0.005601
time: 0.24806761741638184
time: 2.2174949645996094
[1, 12174] loss_train: 0.003352, loss_test: 0.005600
time: 0.24405503273010254
time: 2.219498872756958
[1, 12175] loss_train: 0.016039, loss_test: 0.005598
time: 0.24405431747436523
time: 2.221496105194092
[1, 12176] loss_train: 0.002486, loss_test: 0.005599
time: 0.24306726455688477
time: 2.2285003662109375
[1, 12177] loss_train: 0.002936, loss_test: 0.005601
time: 0.24405908584594727
time: 2.2044928073883057
[1, 12178] loss_train: 0.005970, loss_test: 0.005605
time: 0.24305343627929688
time: 2.2305147647857666
[1, 12179] loss_train: 0.004613, loss_test: 0.005610
time: 0.24405360221862793
time: 2.2272140979766846
[1, 12180] loss_train: 0.010145, loss_test: 0.005611
time: 0.2580568790435791
time: 2.243515968322754
[1, 12181] loss_train: 0.009773, loss_test: 0.005606
time: 0.251056432723999
time: 2.237499952316284
[1, 12182] loss_train: 0.010624, loss_test: 0.005601
time: 0.24405384063720703
time: 2.22649884223938
[1, 12183] loss_train: 0.009779, loss_test: 0.005596
time: 0.2450551986694336
time: 2.201491355895996
[1, 12184] loss_train: 0.009100, loss_test: 0.005597
time: 0.24405479431152344
time: 2.1858444213867188
[1, 12185] loss_train: 0.001855, loss_test: 0.005602
time: 0.25008177757263184
time: 2.221497058868408
[1, 12186] loss_train: 0.009932, loss_test: 0.005613
time: 0.24405384063720703
time: 2.2198777198791504
[1, 12187] loss_train: 0.007369, loss_test: 0.005621
time: 0.2506744861602783
time: 2.2074947357177734
[1, 12188] loss_train: 0.001907, loss_test: 0.005628
time: 0.24505329132080078
time: 2.2040064334869385
[1, 12189] loss_train: 0.003232, loss_test: 0.005630
time: 0.24305391311645508
time: 2.2355000972747803
[1, 12190] loss_train: 0.004534, loss_test: 0.005628
time: 0.2560570240020752
time: 2.2710330486297607
[1, 12191] loss_train: 0.010534, loss_test: 0.005619
time: 0.2450544834136963
time: 2.220496416091919
[1, 12192] loss_train: 0.001746, loss_test: 0.005610
time: 0.2450542449951172
time: 2.231515407562256
[1, 12193] loss_train: 0.008188, loss_test: 0.005605
time: 0.24205398559570312
time: 2.2294983863830566
[1, 12194] loss_train: 0.003049, loss_test: 0.005606
time: 0.24605464935302734
time: 2.2505030632019043
[1, 12195] loss_train: 0.007191, loss_test: 0.005612
time: 0.24405479431152344
time: 2.216015100479126
[1, 12196] loss_train: 0.003055, loss_test: 0.005620
time: 0.24405479431152344
time: 2.1804873943328857
[1, 12197] loss_train: 0.010309, loss_test: 0.005628
time: 0.24405431747436523
time: 2.21449613571167
[1, 12198] loss_train: 0.012631, loss_test: 0.005623
time: 0.2440659999847412
time: 2.194491386413574
[1, 12199] loss_train: 0.010744, loss_test: 0.005619
time: 0.2470543384552002
time: 2.1964917182922363
[1, 12200] loss_train: 0.006081, loss_test: 0.005614
time: 0.2600595951080322
time: 2.246504306793213
[1, 12201] loss_train: 0.005518, loss_test: 0.005612
time: 0.2470548152923584
time: 2.2415013313293457
[1, 12202] loss_train: 0.003211, loss_test: 0.005610
time: 0.2500600814819336
time: 2.230499505996704
[1, 12203] loss_train: 0.003114, loss_test: 0.005610
time: 0.24605488777160645
time: 2.2465016841888428
[1, 12204] loss_train: 0.010821, loss_test: 0.005611
time: 0.2530701160430908
time: 2.2094943523406982
[1, 12205] loss_train: 0.002536, loss_test: 0.005613
time: 0.24505400657653809
time: 2.2385005950927734
[1, 12206] loss_train: 0.017849, loss_test: 0.005613
time: 0.24605441093444824
time: 2.246502637863159
[1, 12207] loss_train: 0.005815, loss_test: 0.005618
time: 0.24505400657653809
time: 2.219289541244507
[1, 12208] loss_train: 0.008005, loss_test: 0.005629
time: 0.24405407905578613
time: 2.243501901626587
[1, 12209] loss_train: 0.003126, loss_test: 0.005640
time: 0.24405384063720703
time: 2.2080070972442627
[1, 12210] loss_train: 0.006238, loss_test: 0.005647
time: 0.25406527519226074
time: 2.2475037574768066
[1, 12211] loss_train: 0.002721, loss_test: 0.005644
time: 0.24305391311645508
time: 2.2175116539001465
[1, 12212] loss_train: 0.007239, loss_test: 0.005638
time: 0.24405312538146973
time: 2.228501081466675
[1, 12213] loss_train: 0.009828, loss_test: 0.005628
time: 0.24305367469787598
time: 2.218496561050415
[1, 12214] loss_train: 0.004916, loss_test: 0.005623
time: 0.24405384063720703
time: 2.2395007610321045
[1, 12215] loss_train: 0.018179, loss_test: 0.005622
time: 0.24405431747436523
time: 2.231499195098877
[1, 12216] loss_train: 0.001468, loss_test: 0.005622
time: 0.24305462837219238
time: 2.2205140590667725
[1, 12217] loss_train: 0.005765, loss_test: 0.005625
time: 0.24405384063720703
time: 2.2314987182617188
[1, 12218] loss_train: 0.005792, loss_test: 0.005629
time: 0.24405503273010254
time: 2.2350523471832275
[1, 12219] loss_train: 0.006333, loss_test: 0.005635
time: 0.24405455589294434
time: 2.2134947776794434
[1, 12220] loss_train: 0.005538, loss_test: 0.005637
time: 0.25705671310424805
time: 2.2495028972625732
[1, 12221] loss_train: 0.004276, loss_test: 0.005641
time: 0.25005578994750977
time: 2.201038122177124
[1, 12222] loss_train: 0.003566, loss_test: 0.005647
time: 0.2450547218322754
time: 2.206505298614502
[1, 12223] loss_train: 0.008344, loss_test: 0.005650
time: 0.2490553855895996
time: 2.2194957733154297
[1, 12224] loss_train: 0.009333, loss_test: 0.005643
time: 0.24405407905578613
time: 2.2305026054382324
[1, 12225] loss_train: 0.007349, loss_test: 0.005636
time: 0.24305295944213867
time: 2.228498935699463
[1, 12226] loss_train: 0.008914, loss_test: 0.005630
time: 0.24405455589294434
time: 2.231498956680298
[1, 12227] loss_train: 0.001505, loss_test: 0.005627
time: 0.24405384063720703
time: 2.2405121326446533
[1, 12228] loss_train: 0.001191, loss_test: 0.005625
time: 0.2420520782470703
time: 2.2251780033111572
[1, 12229] loss_train: 0.001545, loss_test: 0.005624
time: 0.24456381797790527
time: 2.2545053958892822
[1, 12230] loss_train: 0.022402, loss_test: 0.005619
time: 0.2560560703277588
time: 2.296513557434082
[1, 12231] loss_train: 0.008224, loss_test: 0.005627
time: 0.24605417251586914
time: 2.242518663406372
[1, 12232] loss_train: 0.005380, loss_test: 0.005640
time: 0.24405479431152344
time: 2.231499195098877
[1, 12233] loss_train: 0.021139, loss_test: 0.005662
time: 0.24405455589294434
time: 2.248502492904663
[1, 12234] loss_train: 0.005021, loss_test: 0.005673
time: 0.24805474281311035
time: 2.2004926204681396
[1, 12235] loss_train: 0.003782, loss_test: 0.005682
time: 0.24407005310058594
time: 2.194490671157837
[1, 12236] loss_train: 0.006478, loss_test: 0.005684
time: 0.24405431747436523
time: 2.2485029697418213
[1, 12237] loss_train: 0.007333, loss_test: 0.005676
time: 0.24305415153503418
time: 2.2525033950805664
[1, 12238] loss_train: 0.003541, loss_test: 0.005666
time: 0.24307036399841309
time: 2.2004921436309814
[1, 12239] loss_train: 0.002866, loss_test: 0.005654
time: 0.24605512619018555
time: 2.221496820449829
[1, 12240] loss_train: 0.010887, loss_test: 0.005642
time: 0.25606274604797363
time: 2.229508399963379
[1, 12241] loss_train: 0.013093, loss_test: 0.005632
time: 0.2470548152923584
time: 2.2250118255615234
[1, 12242] loss_train: 0.012299, loss_test: 0.005624
time: 0.24805545806884766
time: 2.204493284225464
[1, 12243] loss_train: 0.011709, loss_test: 0.005618
time: 0.24805498123168945
time: 2.19649076461792
[1, 12244] loss_train: 0.012580, loss_test: 0.005612
time: 0.24805521965026855
time: 2.182487726211548
[1, 12245] loss_train: 0.004395, loss_test: 0.005606
time: 0.2470548152923584
time: 2.2220640182495117
[1, 12246] loss_train: 0.003810, loss_test: 0.005607
time: 0.24305343627929688
time: 2.184487819671631
[1, 12247] loss_train: 0.004261, loss_test: 0.005615
time: 0.24406814575195312
time: 2.2354989051818848
[1, 12248] loss_train: 0.004839, loss_test: 0.005626
time: 0.24805498123168945
time: 2.240501642227173
[1, 12249] loss_train: 0.001673, loss_test: 0.005640
time: 0.24305295944213867
time: 2.2154951095581055
[1, 12250] loss_train: 0.008859, loss_test: 0.005648
time: 0.25705766677856445
time: 2.216495990753174
[1, 12251] loss_train: 0.007188, loss_test: 0.005654
time: 0.24405407905578613
time: 2.2155113220214844
[1, 12252] loss_train: 0.005572, loss_test: 0.005659
time: 0.24405384063720703
time: 2.216496229171753
[1, 12253] loss_train: 0.006856, loss_test: 0.005657
time: 0.24505376815795898
time: 2.231499195098877
[1, 12254] loss_train: 0.002455, loss_test: 0.005655
time: 0.2450551986694336
time: 2.2485151290893555
[1, 12255] loss_train: 0.006209, loss_test: 0.005653
time: 0.24509382247924805
time: 2.2144947052001953
[1, 12256] loss_train: 0.004879, loss_test: 0.005650
time: 0.2450547218322754
time: 2.2034926414489746
[1, 12257] loss_train: 0.017186, loss_test: 0.005636
time: 0.24906635284423828
time: 2.190490245819092
[1, 12258] loss_train: 0.007498, loss_test: 0.005624
time: 0.24288678169250488
time: 2.230499267578125
[1, 12259] loss_train: 0.005564, loss_test: 0.005618
time: 0.24605488777160645
time: 2.1874887943267822
[1, 12260] loss_train: 0.001925, loss_test: 0.005614
time: 0.2560572624206543
time: 2.220496416091919
[1, 12261] loss_train: 0.003865, loss_test: 0.005611
time: 0.24305391311645508
time: 2.2118067741394043
[1, 12262] loss_train: 0.006826, loss_test: 0.005609
time: 0.2470552921295166
time: 2.2283742427825928
[1, 12263] loss_train: 0.015795, loss_test: 0.005608
time: 0.24305438995361328
time: 2.248502492904663
[1, 12264] loss_train: 0.003578, loss_test: 0.005608
time: 0.24305343627929688
time: 2.2124953269958496
[1, 12265] loss_train: 0.002538, loss_test: 0.005604
time: 0.24405479431152344
time: 2.211493968963623
[1, 12266] loss_train: 0.003767, loss_test: 0.005603
time: 0.24405384063720703
time: 2.205495595932007
[1, 12267] loss_train: 0.006417, loss_test: 0.005601
time: 0.24305438995361328
time: 2.222010612487793
[1, 12268] loss_train: 0.007821, loss_test: 0.005599
time: 0.24405455589294434
time: 2.2274978160858154
[1, 12269] loss_train: 0.005318, loss_test: 0.005596
time: 0.2470550537109375
time: 2.219496250152588
[1, 12270] loss_train: 0.004913, loss_test: 0.005593
time: 0.26105737686157227
time: 2.285520315170288
[1, 12271] loss_train: 0.005062, loss_test: 0.005590
time: 0.24505400657653809
time: 2.2140355110168457
[1, 12272] loss_train: 0.004302, loss_test: 0.005587
time: 0.24805498123168945
time: 2.2345025539398193
[1, 12273] loss_train: 0.003883, loss_test: 0.005587
time: 0.24505400657653809
time: 2.219498872756958
[1, 12274] loss_train: 0.008138, loss_test: 0.005585
time: 0.25005531311035156
time: 2.2054944038391113
[1, 12275] loss_train: 0.005708, loss_test: 0.005587
time: 0.24405312538146973
time: 2.2355003356933594
[1, 12276] loss_train: 0.010977, loss_test: 0.005587
time: 0.24405384063720703
time: 2.2472751140594482
[1, 12277] loss_train: 0.008505, loss_test: 0.005589
time: 0.24405431747436523
time: 2.2375149726867676
[1, 12278] loss_train: 0.007769, loss_test: 0.005591
time: 0.24305367469787598
time: 2.2175068855285645
[1, 12279] loss_train: 0.010451, loss_test: 0.005586
time: 0.24405407905578613
time: 2.206493377685547
[1, 12280] loss_train: 0.003358, loss_test: 0.005585
time: 0.25505590438842773
time: 2.226506471633911
[1, 12281] loss_train: 0.006982, loss_test: 0.005585
time: 0.24805521965026855
time: 2.2465028762817383
[1, 12282] loss_train: 0.003389, loss_test: 0.005586
time: 0.24305415153503418
time: 2.2585132122039795
[1, 12283] loss_train: 0.000618, loss_test: 0.005589
time: 0.24405479431152344
time: 2.1934893131256104
[1, 12284] loss_train: 0.006112, loss_test: 0.005594
time: 0.24305319786071777
time: 2.2250006198883057
[1, 12285] loss_train: 0.003900, loss_test: 0.005601
time: 0.24305462837219238
time: 2.2472925186157227
[1, 12286] loss_train: 0.009663, loss_test: 0.005608
time: 0.24805474281311035
time: 2.233004093170166
[1, 12287] loss_train: 0.005788, loss_test: 0.005617
time: 0.24305295944213867
time: 2.219472885131836
[1, 12288] loss_train: 0.006342, loss_test: 0.005623
time: 0.24405455589294434
time: 2.217495918273926
[1, 12289] loss_train: 0.003957, loss_test: 0.005626
time: 0.2450547218322754
time: 2.215010404586792
[1, 12290] loss_train: 0.007370, loss_test: 0.005624
time: 0.2570822238922119
time: 2.263505697250366
[1, 12291] loss_train: 0.005227, loss_test: 0.005618
time: 0.2470541000366211
time: 2.2114951610565186
[1, 12292] loss_train: 0.001810, loss_test: 0.005613
time: 0.2450542449951172
time: 2.237116813659668
[1, 12293] loss_train: 0.011415, loss_test: 0.005609
time: 0.25005507469177246
time: 2.2360076904296875
[1, 12294] loss_train: 0.005615, loss_test: 0.005607
time: 0.24605464935302734
time: 2.1934926509857178
[1, 12295] loss_train: 0.005303, loss_test: 0.005605
time: 0.24605441093444824
time: 2.1994922161102295
[1, 12296] loss_train: 0.006392, loss_test: 0.005606
time: 0.24805545806884766
time: 2.210024356842041
[1, 12297] loss_train: 0.006039, loss_test: 0.005604
time: 0.24405455589294434
time: 2.206493377685547
[1, 12298] loss_train: 0.005048, loss_test: 0.005606
time: 0.24405431747436523
time: 2.247502326965332
[1, 12299] loss_train: 0.007417, loss_test: 0.005608
time: 0.24355816841125488
time: 2.2465028762817383
[1, 12300] loss_train: 0.002058, loss_test: 0.005615
time: 0.25505566596984863
time: 2.249539375305176
[1, 12301] loss_train: 0.004860, loss_test: 0.005621
time: 0.24605417251586914
time: 2.2164995670318604
[1, 12302] loss_train: 0.011859, loss_test: 0.005621
time: 0.24305462837219238
time: 2.2144947052001953
[1, 12303] loss_train: 0.007730, loss_test: 0.005625
time: 0.2450542449951172
time: 2.2515039443969727
[1, 12304] loss_train: 0.006080, loss_test: 0.005628
time: 0.24505400657653809
time: 2.218496322631836
[1, 12305] loss_train: 0.006857, loss_test: 0.005628
time: 0.24309468269348145
time: 2.231498956680298
[1, 12306] loss_train: 0.004396, loss_test: 0.005634
time: 0.24305462837219238
time: 2.2395007610321045
[1, 12307] loss_train: 0.003612, loss_test: 0.005640
time: 0.24605512619018555
time: 2.2395005226135254
[1, 12308] loss_train: 0.000803, loss_test: 0.005645
time: 0.24305415153503418
time: 2.233499765396118
[1, 12309] loss_train: 0.010902, loss_test: 0.005651
time: 0.24505376815795898
time: 2.214495897293091
[1, 12310] loss_train: 0.007676, loss_test: 0.005659
time: 0.26306986808776855
time: 2.237509250640869
[1, 12311] loss_train: 0.007741, loss_test: 0.005663
time: 0.24405360221862793
time: 2.2465062141418457
[1, 12312] loss_train: 0.000586, loss_test: 0.005669
time: 0.2490556240081787
time: 2.2565042972564697
[1, 12313] loss_train: 0.007791, loss_test: 0.005669
time: 0.2490558624267578
time: 2.2385003566741943
[1, 12314] loss_train: 0.003740, loss_test: 0.005670
time: 0.2490546703338623
time: 2.256507635116577
[1, 12315] loss_train: 0.005595, loss_test: 0.005665
time: 0.24405455589294434
time: 2.2274978160858154
[1, 12316] loss_train: 0.008274, loss_test: 0.005662
time: 0.2510554790496826
time: 2.2625083923339844
[1, 12317] loss_train: 0.004683, loss_test: 0.005655
time: 0.24605441093444824
time: 2.194491386413574
[1, 12318] loss_train: 0.004942, loss_test: 0.005648
time: 0.2490546703338623
time: 2.2235000133514404
[1, 12319] loss_train: 0.007974, loss_test: 0.005643
time: 0.24405384063720703
time: 2.2625062465667725
[1, 12320] loss_train: 0.001588, loss_test: 0.005638
time: 0.2600588798522949
time: 2.2535033226013184
[1, 12321] loss_train: 0.007202, loss_test: 0.005634
time: 0.24605393409729004
time: 2.2200183868408203
[1, 12322] loss_train: 0.011320, loss_test: 0.005627
time: 0.24606776237487793
time: 2.229499101638794
[1, 12323] loss_train: 0.001970, loss_test: 0.005620
time: 0.24706673622131348
time: 2.2405030727386475
[1, 12324] loss_train: 0.002519, loss_test: 0.005614
time: 0.2420661449432373
time: 2.220496416091919
[1, 12325] loss_train: 0.004111, loss_test: 0.005612
time: 0.24405407905578613
time: 2.240004777908325
[1, 12326] loss_train: 0.005778, loss_test: 0.005612
time: 0.2450547218322754
time: 2.222496747970581
[1, 12327] loss_train: 0.006245, loss_test: 0.005616
time: 0.24305438995361328
time: 2.2175042629241943
[1, 12328] loss_train: 0.011036, loss_test: 0.005622
time: 0.24606704711914062
time: 2.217496156692505
[1, 12329] loss_train: 0.003828, loss_test: 0.005625
time: 0.24405384063720703
time: 2.182506799697876
[1, 12330] loss_train: 0.008447, loss_test: 0.005623
time: 0.2580571174621582
time: 2.230499267578125
[1, 12331] loss_train: 0.003638, loss_test: 0.005619
time: 0.24405384063720703
time: 2.2255120277404785
[1, 12332] loss_train: 0.009058, loss_test: 0.005611
time: 0.24605417251586914
time: 2.22400164604187
[1, 12333] loss_train: 0.007652, loss_test: 0.005608
time: 0.25105738639831543
time: 2.207494020462036
[1, 12334] loss_train: 0.004104, loss_test: 0.005607
time: 0.24405384063720703
time: 2.213498592376709
[1, 12335] loss_train: 0.012446, loss_test: 0.005617
time: 0.2490551471710205
time: 2.193500280380249
[1, 12336] loss_train: 0.005860, loss_test: 0.005629
time: 0.24605417251586914
time: 2.247521162033081
[1, 12337] loss_train: 0.003848, loss_test: 0.005644
time: 0.24605464935302734
time: 2.2244980335235596
[1, 12338] loss_train: 0.009885, loss_test: 0.005659
time: 0.24505329132080078
time: 2.232499599456787
[1, 12339] loss_train: 0.004331, loss_test: 0.005677
time: 0.2450542449951172
time: 2.240534543991089
[1, 12340] loss_train: 0.005596, loss_test: 0.005694
time: 0.25705766677856445
time: 2.2525031566619873
[1, 12341] loss_train: 0.005396, loss_test: 0.005705
time: 0.2450544834136963
time: 2.218496561050415
[1, 12342] loss_train: 0.007024, loss_test: 0.005667
time: 0.24405360221862793
time: 2.20149302482605
[1, 12343] loss_train: 0.002041, loss_test: 0.005633
time: 0.24605488777160645
time: 2.228498697280884
[1, 12344] loss_train: 0.002278, loss_test: 0.005615
time: 0.24505352973937988
time: 2.2125043869018555
[1, 12345] loss_train: 0.005556, loss_test: 0.005599
time: 0.24605464935302734
time: 2.208998441696167
[1, 12346] loss_train: 0.006072, loss_test: 0.005595
time: 0.2450549602508545
time: 2.2264976501464844
[1, 12347] loss_train: 0.006676, loss_test: 0.005600
time: 0.24205398559570312
time: 2.222496747970581
[1, 12348] loss_train: 0.012968, loss_test: 0.005604
time: 0.24405407905578613
time: 2.2274982929229736
[1, 12349] loss_train: 0.006247, loss_test: 0.005609
time: 0.24305391311645508
time: 2.202512741088867
[1, 12350] loss_train: 0.008098, loss_test: 0.005616
time: 0.2650601863861084
time: 2.2445008754730225
[1, 12351] loss_train: 0.002679, loss_test: 0.005623
time: 0.2450542449951172
time: 2.192490816116333
[1, 12352] loss_train: 0.012766, loss_test: 0.005633
time: 0.25305676460266113
time: 2.213505744934082
[1, 12353] loss_train: 0.011102, loss_test: 0.005642
time: 0.2450544834136963
time: 2.2275185585021973
[1, 12354] loss_train: 0.001968, loss_test: 0.005652
time: 0.24405384063720703
time: 2.2320027351379395
[1, 12355] loss_train: 0.008545, loss_test: 0.005647
time: 0.24305415153503418
time: 2.236501693725586
[1, 12356] loss_train: 0.002731, loss_test: 0.005644
time: 0.24405479431152344
time: 2.211494207382202
[1, 12357] loss_train: 0.008236, loss_test: 0.005642
time: 0.2510552406311035
time: 2.2115061283111572
[1, 12358] loss_train: 0.002065, loss_test: 0.005640
time: 0.24405431747436523
time: 2.1994922161102295
[1, 12359] loss_train: 0.000679, loss_test: 0.005628
time: 0.24407958984375
time: 2.2315094470977783
[1, 12360] loss_train: 0.011177, loss_test: 0.005619
time: 0.2560741901397705
time: 2.2495028972625732
[1, 12361] loss_train: 0.005055, loss_test: 0.005610
time: 0.24406647682189941
time: 2.233499765396118
[1, 12362] loss_train: 0.007515, loss_test: 0.005602
time: 0.2450542449951172
time: 2.2214972972869873
[1, 12363] loss_train: 0.005348, loss_test: 0.005598
time: 0.24605464935302734
time: 2.232515335083008
[1, 12364] loss_train: 0.010921, loss_test: 0.005589
time: 0.2470543384552002
time: 2.229499340057373
[1, 12365] loss_train: 0.006115, loss_test: 0.005595
time: 0.24306559562683105
time: 2.2193140983581543
[1, 12366] loss_train: 0.010088, loss_test: 0.005606
time: 0.2437574863433838
time: 2.2164950370788574
[1, 12367] loss_train: 0.005603, loss_test: 0.005621
time: 0.24605417251586914
time: 2.1993038654327393
[1, 12368] loss_train: 0.001808, loss_test: 0.005638
time: 0.24605417251586914
time: 2.2234978675842285
[1, 12369] loss_train: 0.005003, loss_test: 0.005650
time: 0.25006651878356934
time: 2.205493450164795
[1, 12370] loss_train: 0.006588, loss_test: 0.005646
time: 0.256605863571167
time: 2.2610087394714355
[1, 12371] loss_train: 0.001962, loss_test: 0.005629
time: 0.24805521965026855
time: 2.2144992351531982
[1, 12372] loss_train: 0.002169, loss_test: 0.005619
time: 0.2450547218322754
time: 2.2505035400390625
[1, 12373] loss_train: 0.004633, loss_test: 0.005608
time: 0.24305391311645508
time: 2.234391212463379
[1, 12374] loss_train: 0.003911, loss_test: 0.005606
time: 0.24605488777160645
time: 2.2515032291412354
[1, 12375] loss_train: 0.009610, loss_test: 0.005607
time: 0.24305367469787598
time: 2.233499765396118
[1, 12376] loss_train: 0.003507, loss_test: 0.005610
time: 0.24405384063720703
time: 2.2375009059906006
[1, 12377] loss_train: 0.011266, loss_test: 0.005610
time: 0.24405431747436523
time: 2.214508295059204
[1, 12378] loss_train: 0.001872, loss_test: 0.005613
time: 0.24305367469787598
time: 2.2234976291656494
[1, 12379] loss_train: 0.002378, loss_test: 0.005618
time: 0.2450566291809082
time: 2.217496395111084
[1, 12380] loss_train: 0.008146, loss_test: 0.005618
time: 0.25406551361083984
time: 2.248439073562622
[1, 12381] loss_train: 0.006724, loss_test: 0.005616
time: 0.24605488777160645
time: 2.2114992141723633
[1, 12382] loss_train: 0.003249, loss_test: 0.005616
time: 0.24506664276123047
time: 2.206493854522705
[1, 12383] loss_train: 0.006993, loss_test: 0.005611
time: 0.2450547218322754
time: 2.233501434326172
[1, 12384] loss_train: 0.002018, loss_test: 0.005610
time: 0.24405407905578613
time: 2.2455217838287354
[1, 12385] loss_train: 0.006097, loss_test: 0.005605
time: 0.24405431747436523
time: 2.217496156692505
[1, 12386] loss_train: 0.008967, loss_test: 0.005600
time: 0.24405455589294434
time: 2.2435178756713867
[1, 12387] loss_train: 0.006215, loss_test: 0.005597
time: 0.2450542449951172
time: 2.243502140045166
[1, 12388] loss_train: 0.005962, loss_test: 0.005598
time: 0.24805521965026855
time: 2.2435169219970703
[1, 12389] loss_train: 0.007906, loss_test: 0.005599
time: 0.2450547218322754
time: 2.2314987182617188
[1, 12390] loss_train: 0.006460, loss_test: 0.005601
time: 0.26105785369873047
time: 2.2850263118743896
[1, 12391] loss_train: 0.009594, loss_test: 0.005602
time: 0.24405455589294434
time: 2.2305006980895996
[1, 12392] loss_train: 0.003384, loss_test: 0.005602
time: 0.24805474281311035
time: 2.1954917907714844
[1, 12393] loss_train: 0.005199, loss_test: 0.005603
time: 0.24605417251586914
time: 2.208494186401367
[1, 12394] loss_train: 0.003239, loss_test: 0.005605
time: 0.2490551471710205
time: 2.2164976596832275
[1, 12395] loss_train: 0.008466, loss_test: 0.005610
time: 0.24405384063720703
time: 2.22933030128479
[1, 12396] loss_train: 0.007414, loss_test: 0.005619
time: 0.24305343627929688
time: 2.2274985313415527
[1, 12397] loss_train: 0.005668, loss_test: 0.005627
time: 0.24306583404541016
time: 2.2244980335235596
[1, 12398] loss_train: 0.002327, loss_test: 0.005640
time: 0.24605393409729004
time: 2.2350385189056396
[1, 12399] loss_train: 0.002838, loss_test: 0.005653
time: 0.24405455589294434
time: 2.2375001907348633
[1, 12400] loss_train: 0.006590, loss_test: 0.005665
time: 0.2540569305419922
time: 2.2791221141815186
[1, 12401] loss_train: 0.008028, loss_test: 0.005664
time: 0.24605536460876465
time: 2.211493968963623
[1, 12402] loss_train: 0.005510, loss_test: 0.005660
time: 0.24305415153503418
time: 2.2415013313293457
[1, 12403] loss_train: 0.003189, loss_test: 0.005658
time: 0.24205327033996582
time: 2.2244975566864014
[1, 12404] loss_train: 0.011254, loss_test: 0.005645
time: 0.24605369567871094
time: 2.2255008220672607
[1, 12405] loss_train: 0.023098, loss_test: 0.005615
time: 0.24205374717712402
time: 2.2114949226379395
[1, 12406] loss_train: 0.010912, loss_test: 0.005602
time: 0.24406695365905762
time: 2.1835129261016846
[1, 12407] loss_train: 0.004043, loss_test: 0.005613
time: 0.24805474281311035
time: 2.216496467590332
[1, 12408] loss_train: 0.013261, loss_test: 0.005643
time: 0.24505376815795898
time: 2.216505289077759
[1, 12409] loss_train: 0.007669, loss_test: 0.005682
time: 0.2620582580566406
time: 2.2245099544525146
[1, 12410] loss_train: 0.006005, loss_test: 0.005726
time: 0.25705647468566895
time: 2.241509199142456
[1, 12411] loss_train: 0.007359, loss_test: 0.005731
time: 0.251056432723999
time: 2.2460062503814697
[1, 12412] loss_train: 0.003760, loss_test: 0.005720
time: 0.2470545768737793
time: 2.2410049438476562
[1, 12413] loss_train: 0.011330, loss_test: 0.005709
time: 0.24805212020874023
time: 2.241502523422241
[1, 12414] loss_train: 0.004838, loss_test: 0.005690
time: 0.24505400657653809
time: 2.2255003452301025
[1, 12415] loss_train: 0.007499, loss_test: 0.005671
time: 0.24605441093444824
time: 2.1904900074005127
[1, 12416] loss_train: 0.008157, loss_test: 0.005651
time: 0.24405455589294434
time: 2.198491334915161
[1, 12417] loss_train: 0.005448, loss_test: 0.005635
time: 0.24406647682189941
time: 2.2124953269958496
[1, 12418] loss_train: 0.006764, loss_test: 0.005630
time: 0.25005531311035156
time: 2.1930294036865234
[1, 12419] loss_train: 0.004687, loss_test: 0.005634
time: 0.2450547218322754
time: 2.208502769470215
[1, 12420] loss_train: 0.010620, loss_test: 0.005646
time: 0.2560575008392334
time: 2.2430155277252197
[1, 12421] loss_train: 0.004910, loss_test: 0.005657
time: 0.24305462837219238
time: 2.2415008544921875
[1, 12422] loss_train: 0.003400, loss_test: 0.005669
time: 0.24405431747436523
time: 2.2104947566986084
[1, 12423] loss_train: 0.005639, loss_test: 0.005680
time: 0.24405384063720703
time: 2.2254984378814697
[1, 12424] loss_train: 0.008479, loss_test: 0.005682
time: 0.24405384063720703
time: 2.2365007400512695
[1, 12425] loss_train: 0.004466, loss_test: 0.005683
time: 0.2470543384552002
time: 2.246502637863159
[1, 12426] loss_train: 0.005968, loss_test: 0.005682
time: 0.2428436279296875
time: 2.199937343597412
[1, 12427] loss_train: 0.009796, loss_test: 0.005671
time: 0.24305415153503418
time: 2.2029953002929688
[1, 12428] loss_train: 0.002409, loss_test: 0.005662
time: 0.25005531311035156
time: 2.2337751388549805
[1, 12429] loss_train: 0.004899, loss_test: 0.005654
time: 0.24305319786071777
time: 2.2234978675842285
[1, 12430] loss_train: 0.003837, loss_test: 0.005650
time: 0.2580842971801758
time: 2.2485032081604004
[1, 12431] loss_train: 0.007608, loss_test: 0.005648
time: 0.2560567855834961
time: 2.2675089836120605
[1, 12432] loss_train: 0.013610, loss_test: 0.005643
time: 0.2470545768737793
time: 2.242502212524414
[1, 12433] loss_train: 0.003845, loss_test: 0.005641
time: 0.24405384063720703
time: 2.256505250930786
[1, 12434] loss_train: 0.003988, loss_test: 0.005639
time: 0.2490556240081787
time: 2.2385025024414062
[1, 12435] loss_train: 0.020331, loss_test: 0.005650
time: 0.24505400657653809
time: 2.2295010089874268
[1, 12436] loss_train: 0.008128, loss_test: 0.005671
time: 0.24305367469787598
time: 2.2635059356689453
[1, 12437] loss_train: 0.008371, loss_test: 0.005697
time: 0.2450547218322754
time: 2.223496913909912
[1, 12438] loss_train: 0.006346, loss_test: 0.005709
time: 0.24605512619018555
time: 2.2064929008483887
[1, 12439] loss_train: 0.006722, loss_test: 0.005701
time: 0.2450542449951172
time: 2.195490837097168
[1, 12440] loss_train: 0.005861, loss_test: 0.005687
time: 0.25705695152282715
time: 2.2331697940826416
[1, 12441] loss_train: 0.005619, loss_test: 0.005670
time: 0.24405479431152344
time: 2.232499122619629
[1, 12442] loss_train: 0.002009, loss_test: 0.005646
time: 0.24305343627929688
time: 2.245502233505249
[1, 12443] loss_train: 0.005556, loss_test: 0.005624
time: 0.2450547218322754
time: 2.2054927349090576
[1, 12444] loss_train: 0.004499, loss_test: 0.005610
time: 0.24305486679077148
time: 2.181004047393799
[1, 12445] loss_train: 0.011295, loss_test: 0.005606
time: 0.24305343627929688
time: 2.240501642227173
[1, 12446] loss_train: 0.002984, loss_test: 0.005604
time: 0.2450544834136963
time: 2.2305142879486084
[1, 12447] loss_train: 0.005180, loss_test: 0.005609
time: 0.24606943130493164
time: 2.242502212524414
[1, 12448] loss_train: 0.007214, loss_test: 0.005621
time: 0.24306678771972656
time: 2.2315189838409424
[1, 12449] loss_train: 0.004649, loss_test: 0.005637
time: 0.25205564498901367
time: 2.226107358932495
[1, 12450] loss_train: 0.003074, loss_test: 0.005654
time: 0.25705718994140625
time: 2.214367628097534
[1, 12451] loss_train: 0.006808, loss_test: 0.005664
time: 0.2490677833557129
time: 2.25850510597229
[1, 12452] loss_train: 0.002315, loss_test: 0.005673
time: 0.25705647468566895
time: 2.204005241394043
[1, 12453] loss_train: 0.011311, loss_test: 0.005671
time: 0.2470543384552002
time: 2.234502077102661
[1, 12454] loss_train: 0.007053, loss_test: 0.005657
time: 0.24605560302734375
time: 2.212494134902954
[1, 12455] loss_train: 0.008827, loss_test: 0.005629
time: 0.24505400657653809
time: 2.2383720874786377
[1, 12456] loss_train: 0.003895, loss_test: 0.005613
time: 0.24405384063720703
time: 2.2285079956054688
[1, 12457] loss_train: 0.003169, loss_test: 0.005605
time: 0.24506640434265137
time: 2.215496301651001
[1, 12458] loss_train: 0.002912, loss_test: 0.005601
time: 0.24605464935302734
time: 2.22249698638916
[1, 12459] loss_train: 0.010496, loss_test: 0.005600
time: 0.24505400657653809
time: 2.214507579803467
[1, 12460] loss_train: 0.001742, loss_test: 0.005601
time: 0.25707077980041504
time: 2.2655413150787354
[1, 12461] loss_train: 0.000836, loss_test: 0.005602
time: 0.24405384063720703
time: 2.244502544403076
[1, 12462] loss_train: 0.004759, loss_test: 0.005602
time: 0.2470550537109375
time: 2.2285001277923584
[1, 12463] loss_train: 0.004969, loss_test: 0.005601
time: 0.2450549602508545
time: 2.2565040588378906
[1, 12464] loss_train: 0.007698, loss_test: 0.005599
time: 0.24405384063720703
time: 2.2445027828216553
[1, 12465] loss_train: 0.001927, loss_test: 0.005598
time: 0.2450544834136963
time: 2.2325007915496826
[1, 12466] loss_train: 0.008396, loss_test: 0.005596
time: 0.24305319786071777
time: 2.2234976291656494
[1, 12467] loss_train: 0.002103, loss_test: 0.005596
time: 0.24305391311645508
time: 2.226015567779541
[1, 12468] loss_train: 0.008237, loss_test: 0.005595
time: 0.24405455589294434
time: 2.1984903812408447
[1, 12469] loss_train: 0.004949, loss_test: 0.005595
time: 0.24505400657653809
time: 2.2390167713165283
[1, 12470] loss_train: 0.012059, loss_test: 0.005595
time: 0.25705623626708984
time: 2.2425014972686768
[1, 12471] loss_train: 0.009644, loss_test: 0.005595
time: 0.24506807327270508
time: 2.2615063190460205
[1, 12472] loss_train: 0.006989, loss_test: 0.005595
time: 0.24605512619018555
time: 2.2034924030303955
[1, 12473] loss_train: 0.005444, loss_test: 0.005596
time: 0.2450547218322754
time: 2.241501808166504
[1, 12474] loss_train: 0.010074, loss_test: 0.005596
time: 0.2510550022125244
time: 2.202493190765381
[1, 12475] loss_train: 0.001793, loss_test: 0.005597
time: 0.24405455589294434
time: 2.203932762145996
[1, 12476] loss_train: 0.010033, loss_test: 0.005597
time: 0.24305367469787598
time: 2.210505485534668
[1, 12477] loss_train: 0.014675, loss_test: 0.005599
time: 0.24305438995361328
time: 2.2174956798553467
[1, 12478] loss_train: 0.006720, loss_test: 0.005601
time: 0.24305319786071777
time: 2.2495040893554688
[1, 12479] loss_train: 0.005668, loss_test: 0.005604
time: 0.24406766891479492
time: 2.2425148487091064
[1, 12480] loss_train: 0.007024, loss_test: 0.005608
time: 0.2560586929321289
time: 2.235499858856201
[1, 12481] loss_train: 0.007138, loss_test: 0.005611
time: 0.2430586814880371
time: 2.235501289367676
[1, 12482] loss_train: 0.006354, loss_test: 0.005614
time: 0.24506640434265137
time: 2.230499267578125
[1, 12483] loss_train: 0.008115, loss_test: 0.005618
time: 0.24405431747436523
time: 2.2324986457824707
[1, 12484] loss_train: 0.003641, loss_test: 0.005620
time: 0.24405503273010254
time: 2.2495052814483643
[1, 12485] loss_train: 0.014199, loss_test: 0.005621
time: 0.24305462837219238
time: 2.2144949436187744
[1, 12486] loss_train: 0.000674, loss_test: 0.005622
time: 0.24405360221862793
time: 2.216496467590332
[1, 12487] loss_train: 0.009043, loss_test: 0.005622
time: 0.24305319786071777
time: 2.188502073287964
[1, 12488] loss_train: 0.001852, loss_test: 0.005619
time: 0.24405360221862793
time: 2.209494113922119
[1, 12489] loss_train: 0.003323, loss_test: 0.005618
time: 0.25206899642944336
time: 2.2040293216705322
[1, 12490] loss_train: 0.001885, loss_test: 0.005617
time: 0.25705671310424805
time: 2.2234973907470703
[1, 12491] loss_train: 0.009718, loss_test: 0.005615
time: 0.25005507469177246
time: 2.244502067565918
[1, 12492] loss_train: 0.009626, loss_test: 0.005615
time: 0.24605441093444824
time: 2.2355093955993652
[1, 12493] loss_train: 0.004310, loss_test: 0.005614
time: 0.2470545768737793
time: 2.2204971313476562
[1, 12494] loss_train: 0.006021, loss_test: 0.005610
time: 0.2450544834136963
time: 2.220496654510498
[1, 12495] loss_train: 0.007014, loss_test: 0.005605
time: 0.24305438995361328
time: 2.2445175647735596
[1, 12496] loss_train: 0.005963, loss_test: 0.005598
time: 0.2450547218322754
time: 2.236515760421753
[1, 12497] loss_train: 0.011639, loss_test: 0.005596
time: 0.24406647682189941
time: 2.2325077056884766
[1, 12498] loss_train: 0.012490, loss_test: 0.005598
time: 0.24405455589294434
time: 2.2405004501342773
[1, 12499] loss_train: 0.010790, loss_test: 0.005602
time: 0.24605512619018555
time: 2.2014923095703125
[1, 12500] loss_train: 0.007585, loss_test: 0.005606
time: 0.2560727596282959
time: 2.252504587173462
[1, 12501] loss_train: 0.007574, loss_test: 0.005608
time: 0.24505400657653809
time: 2.207000494003296
[1, 12502] loss_train: 0.003779, loss_test: 0.005607
time: 0.24455904960632324
time: 2.2425014972686768
[1, 12503] loss_train: 0.004351, loss_test: 0.005605
time: 0.24405360221862793
time: 2.216498374938965
[1, 12504] loss_train: 0.009431, loss_test: 0.005603
time: 0.24405360221862793
time: 2.2425031661987305
[1, 12505] loss_train: 0.008687, loss_test: 0.005599
time: 0.24405288696289062
time: 2.2254981994628906
[1, 12506] loss_train: 0.002451, loss_test: 0.005596
time: 0.24405431747436523
time: 2.236524820327759
[1, 12507] loss_train: 0.005323, loss_test: 0.005596
time: 0.2450549602508545
time: 2.234511613845825
[1, 12508] loss_train: 0.007459, loss_test: 0.005597
time: 0.24305438995361328
time: 2.261505365371704
[1, 12509] loss_train: 0.007928, loss_test: 0.005601
time: 0.24506759643554688
time: 2.222010850906372
[1, 12510] loss_train: 0.000446, loss_test: 0.005608
time: 0.2580568790435791
time: 2.265507459640503
[1, 12511] loss_train: 0.002316, loss_test: 0.005616
time: 0.2470545768737793
time: 2.2214972972869873
[1, 12512] loss_train: 0.001208, loss_test: 0.005628
time: 0.25005507469177246
time: 2.2114953994750977
[1, 12513] loss_train: 0.000817, loss_test: 0.005643
time: 0.2450563907623291
time: 2.22249698638916
[1, 12514] loss_train: 0.005144, loss_test: 0.005662
time: 0.2490546703338623
time: 2.2234997749328613
[1, 12515] loss_train: 0.005245, loss_test: 0.005682
time: 0.24405479431152344
time: 2.22049617767334
[1, 12516] loss_train: 0.003617, loss_test: 0.005693
time: 0.24605560302734375
time: 2.2395002841949463
[1, 12517] loss_train: 0.008828, loss_test: 0.005700
time: 0.24405455589294434
time: 2.2102322578430176
[1, 12518] loss_train: 0.006863, loss_test: 0.005704
time: 0.24605441093444824
time: 2.231499671936035
[1, 12519] loss_train: 0.005900, loss_test: 0.005704
time: 0.2510559558868408
time: 2.2294983863830566
[1, 12520] loss_train: 0.003011, loss_test: 0.005700
time: 0.2580296993255615
time: 2.2805099487304688
[1, 12521] loss_train: 0.003917, loss_test: 0.005692
time: 0.24405360221862793
time: 2.2395009994506836
[1, 12522] loss_train: 0.002056, loss_test: 0.005683
time: 0.24605488777160645
time: 2.268505334854126
[1, 12523] loss_train: 0.007355, loss_test: 0.005667
time: 0.2470684051513672
time: 2.2134945392608643
[1, 12524] loss_train: 0.004429, loss_test: 0.005653
time: 0.2450563907623291
time: 2.2264976501464844
[1, 12525] loss_train: 0.004863, loss_test: 0.005637
time: 0.24305391311645508
time: 2.2014927864074707
[1, 12526] loss_train: 0.004339, loss_test: 0.005629
time: 0.24305415153503418
time: 2.1924901008605957
[1, 12527] loss_train: 0.000794, loss_test: 0.005624
time: 0.24405479431152344
time: 2.223505973815918
[1, 12528] loss_train: 0.018947, loss_test: 0.005614
time: 0.24605417251586914
time: 2.216495990753174
[1, 12529] loss_train: 0.014065, loss_test: 0.005612
time: 0.24505329132080078
time: 2.2355000972747803
[1, 12530] loss_train: 0.006747, loss_test: 0.005633
time: 0.2560563087463379
time: 2.231025457382202
[1, 12531] loss_train: 0.004451, loss_test: 0.005674
time: 0.24606823921203613
time: 2.233499526977539
[1, 12532] loss_train: 0.002432, loss_test: 0.005733
time: 0.24505400657653809
time: 2.2614710330963135
[1, 12533] loss_train: 0.007989, loss_test: 0.005799
time: 0.24605560302734375
time: 2.2265141010284424
[1, 12534] loss_train: 0.004613, loss_test: 0.005787
time: 0.2450547218322754
time: 2.2495129108428955
[1, 12535] loss_train: 0.005605, loss_test: 0.005730
time: 0.24905681610107422
time: 2.216496229171753
[1, 12536] loss_train: 0.007462, loss_test: 0.005669
time: 0.2450544834136963
time: 2.2375006675720215
[1, 12537] loss_train: 0.001700, loss_test: 0.005624
time: 0.24805450439453125
time: 2.214495897293091
[1, 12538] loss_train: 0.006962, loss_test: 0.005600
time: 0.24405384063720703
time: 2.1965043544769287
[1, 12539] loss_train: 0.019490, loss_test: 0.005591
time: 0.24305462837219238
time: 2.216867446899414
[1, 12540] loss_train: 0.009649, loss_test: 0.005590
time: 0.25705742835998535
time: 2.2765088081359863
[1, 12541] loss_train: 0.009562, loss_test: 0.005592
time: 0.24405455589294434
time: 2.223497152328491
[1, 12542] loss_train: 0.005292, loss_test: 0.005598
time: 0.24305462837219238
time: 2.223496913909912
[1, 12543] loss_train: 0.002046, loss_test: 0.005606
time: 0.24506855010986328
time: 2.248502731323242
[1, 12544] loss_train: 0.006604, loss_test: 0.005617
time: 0.24405407905578613
time: 2.242023229598999
[1, 12545] loss_train: 0.005362, loss_test: 0.005627
time: 0.24307990074157715
time: 2.244504690170288
[1, 12546] loss_train: 0.003681, loss_test: 0.005639
time: 0.24506664276123047
time: 2.22452449798584
[1, 12547] loss_train: 0.006972, loss_test: 0.005656
time: 0.24405384063720703
time: 2.2365009784698486
[1, 12548] loss_train: 0.007361, loss_test: 0.005668
time: 0.24405407905578613
time: 2.1914899349212646
[1, 12549] loss_train: 0.005433, loss_test: 0.005675
time: 0.2450542449951172
time: 2.204493284225464
[1, 12550] loss_train: 0.006195, loss_test: 0.005672
time: 0.256056547164917
time: 2.2244977951049805
[1, 12551] loss_train: 0.004392, loss_test: 0.005667
time: 0.2450563907623291
time: 2.2074930667877197
[1, 12552] loss_train: 0.002680, loss_test: 0.005666
time: 0.2470555305480957
time: 2.2234973907470703
[1, 12553] loss_train: 0.002500, loss_test: 0.005665
time: 0.24605393409729004
time: 2.2254979610443115
[1, 12554] loss_train: 0.008505, loss_test: 0.005662
time: 0.2490551471710205
time: 2.259523391723633
[1, 12555] loss_train: 0.004415, loss_test: 0.005656
time: 0.2490558624267578
time: 2.249502420425415
[1, 12556] loss_train: 0.004357, loss_test: 0.005651
time: 0.25705766677856445
time: 2.246501922607422
[1, 12557] loss_train: 0.015020, loss_test: 0.005630
time: 0.24805521965026855
time: 2.2004921436309814
[1, 12558] loss_train: 0.010021, loss_test: 0.005613
time: 0.2470543384552002
time: 2.218496561050415
[1, 12559] loss_train: 0.006596, loss_test: 0.005603
time: 0.24405455589294434
time: 2.261505365371704
[1, 12560] loss_train: 0.005945, loss_test: 0.005601
time: 0.2610585689544678
time: 2.2800142765045166
[1, 12561] loss_train: 0.006289, loss_test: 0.005605
time: 0.24406743049621582
time: 2.22249698638916
[1, 12562] loss_train: 0.008061, loss_test: 0.005613
time: 0.2470545768737793
time: 2.22649884223938
[1, 12563] loss_train: 0.004630, loss_test: 0.005623
time: 0.24605369567871094
time: 2.2214972972869873
[1, 12564] loss_train: 0.005601, loss_test: 0.005634
time: 0.24305438995361328
time: 2.197007656097412
[1, 12565] loss_train: 0.010120, loss_test: 0.005642
time: 0.24405360221862793
time: 2.212496519088745
[1, 12566] loss_train: 0.011541, loss_test: 0.005646
time: 0.24305415153503418
time: 2.2264981269836426
[1, 12567] loss_train: 0.005293, loss_test: 0.005639
time: 0.24305343627929688
time: 2.2190303802490234
[1, 12568] loss_train: 0.003009, loss_test: 0.005625
time: 0.24405407905578613
time: 2.2535150051116943
[1, 12569] loss_train: 0.001053, loss_test: 0.005610
time: 0.24306726455688477
time: 2.2124953269958496
[1, 12570] loss_train: 0.002278, loss_test: 0.005603
time: 0.258056640625
time: 2.246504783630371
[1, 12571] loss_train: 0.005944, loss_test: 0.005603
time: 0.24406790733337402
time: 2.246502161026001
[1, 12572] loss_train: 0.006524, loss_test: 0.005607
time: 0.24305438995361328
time: 2.219496250152588
[1, 12573] loss_train: 0.002891, loss_test: 0.005615
time: 0.24805688858032227
time: 2.203493356704712
[1, 12574] loss_train: 0.001460, loss_test: 0.005630
time: 0.2470548152923584
time: 2.2034943103790283
[1, 12575] loss_train: 0.005548, loss_test: 0.005644
time: 0.24806761741638184
time: 2.2294986248016357
[1, 12576] loss_train: 0.001850, loss_test: 0.005658
time: 0.24405384063720703
time: 2.216495990753174
[1, 12577] loss_train: 0.007102, loss_test: 0.005665
time: 0.2490556240081787
time: 2.258504867553711
[1, 12578] loss_train: 0.002417, loss_test: 0.005672
time: 0.24405384063720703
time: 2.2355008125305176
[1, 12579] loss_train: 0.008549, loss_test: 0.005655
time: 0.24805450439453125
time: 2.229515552520752
[1, 12580] loss_train: 0.003624, loss_test: 0.005641
time: 0.2620575428009033
time: 2.23651123046875
[1, 12581] loss_train: 0.000490, loss_test: 0.005633
time: 0.24805474281311035
time: 2.2345004081726074
[1, 12582] loss_train: 0.004471, loss_test: 0.005626
time: 0.24405407905578613
time: 2.2455592155456543
[1, 12583] loss_train: 0.005217, loss_test: 0.005619
time: 0.24305415153503418
time: 2.2365000247955322
[1, 12584] loss_train: 0.008740, loss_test: 0.005611
time: 0.24405479431152344
time: 2.198491334915161
[1, 12585] loss_train: 0.002038, loss_test: 0.005607
time: 0.24405360221862793
time: 2.209496259689331
[1, 12586] loss_train: 0.009815, loss_test: 0.005604
time: 0.24605464935302734
time: 2.242501735687256
[1, 12587] loss_train: 0.018625, loss_test: 0.005595
time: 0.24706244468688965
time: 2.2350122928619385
[1, 12588] loss_train: 0.001720, loss_test: 0.005596
time: 0.24405455589294434
time: 2.2065048217773438
[1, 12589] loss_train: 0.007462, loss_test: 0.005602
time: 0.24605226516723633
time: 2.2024922370910645
[1, 12590] loss_train: 0.007452, loss_test: 0.005611
time: 0.25705790519714355
time: 2.2555041313171387
[1, 12591] loss_train: 0.010888, loss_test: 0.005621
time: 0.24305462837219238
time: 2.221496343612671
[1, 12592] loss_train: 0.001689, loss_test: 0.005628
time: 0.2450542449951172
time: 2.217496395111084
[1, 12593] loss_train: 0.001657, loss_test: 0.005630
time: 0.24605417251586914
time: 2.193491220474243
[1, 12594] loss_train: 0.010627, loss_test: 0.005629
time: 0.24805378913879395
time: 2.2254979610443115
[1, 12595] loss_train: 0.003403, loss_test: 0.005624
time: 0.24508118629455566
time: 2.234031915664673
[1, 12596] loss_train: 0.003250, loss_test: 0.005617
time: 0.24805450439453125
time: 2.217496633529663
[1, 12597] loss_train: 0.006812, loss_test: 0.005611
time: 0.24605393409729004
time: 2.2274718284606934
[1, 12598] loss_train: 0.001209, loss_test: 0.005607
time: 0.2470541000366211
time: 2.219496726989746
[1, 12599] loss_train: 0.005326, loss_test: 0.005608
time: 0.24406790733337402
time: 2.2035117149353027
[1, 12600] loss_train: 0.003012, loss_test: 0.005619
time: 0.256056547164917
time: 2.2885234355926514
[1, 12601] loss_train: 0.003208, loss_test: 0.005635
time: 0.2470545768737793
time: 2.243502140045166
[1, 12602] loss_train: 0.007414, loss_test: 0.005659
time: 0.24305391311645508
time: 2.2265005111694336
[1, 12603] loss_train: 0.007080, loss_test: 0.005675
time: 0.24305391311645508
time: 2.228499174118042
[1, 12604] loss_train: 0.004970, loss_test: 0.005691
time: 0.24805521965026855
time: 2.211494207382202
[1, 12605] loss_train: 0.002475, loss_test: 0.005708
time: 0.24405479431152344
time: 2.2405009269714355
[1, 12606] loss_train: 0.001580, loss_test: 0.005726
time: 0.24005413055419922
time: 2.2134947776794434
[1, 12607] loss_train: 0.010046, loss_test: 0.005717
time: 0.24405336380004883
time: 2.2134954929351807
[1, 12608] loss_train: 0.000518, loss_test: 0.005714
time: 0.24405455589294434
time: 2.2114944458007812
[1, 12609] loss_train: 0.007665, loss_test: 0.005692
time: 0.24406743049621582
time: 2.2114944458007812
[1, 12610] loss_train: 0.005863, loss_test: 0.005670
time: 0.2560575008392334
time: 2.2164947986602783
[1, 12611] loss_train: 0.006672, loss_test: 0.005649
time: 0.24929261207580566
time: 2.215545415878296
[1, 12612] loss_train: 0.005254, loss_test: 0.005652
time: 0.24405479431152344
time: 2.224000930786133
[1, 12613] loss_train: 0.007487, loss_test: 0.005671
time: 0.25305628776550293
time: 2.213494300842285
[1, 12614] loss_train: 0.003899, loss_test: 0.005693
time: 0.24405384063720703
time: 2.218496561050415
[1, 12615] loss_train: 0.012919, loss_test: 0.005709
time: 0.2470548152923584
time: 2.2530295848846436
[1, 12616] loss_train: 0.002083, loss_test: 0.005698
time: 0.2450549602508545
time: 2.2184958457946777
[1, 12617] loss_train: 0.001703, loss_test: 0.005672
time: 0.24606680870056152
time: 2.2114944458007812
[1, 12618] loss_train: 0.004233, loss_test: 0.005651
time: 0.24406099319458008
time: 2.2405006885528564
[1, 12619] loss_train: 0.003793, loss_test: 0.005640
time: 0.2450547218322754
time: 2.2145121097564697
[1, 12620] loss_train: 0.004385, loss_test: 0.005636
time: 0.2560575008392334
time: 2.2545042037963867
[1, 12621] loss_train: 0.011297, loss_test: 0.005636
time: 0.25005555152893066
time: 2.2244975566864014
[1, 12622] loss_train: 0.004781, loss_test: 0.005642
time: 0.24507617950439453
time: 2.2244980335235596
[1, 12623] loss_train: 0.007702, loss_test: 0.005640
time: 0.24305343627929688
time: 2.228499174118042
[1, 12624] loss_train: 0.005623, loss_test: 0.005635
time: 0.24357914924621582
time: 2.217000722885132
[1, 12625] loss_train: 0.009707, loss_test: 0.005623
time: 0.24505400657653809
time: 2.222510576248169
[1, 12626] loss_train: 0.003870, loss_test: 0.005614
time: 0.24305367469787598
time: 2.206494092941284
[1, 12627] loss_train: 0.005042, loss_test: 0.005607
time: 0.24305343627929688
time: 2.2054929733276367
[1, 12628] loss_train: 0.005459, loss_test: 0.005604
time: 0.25005364418029785
time: 2.2164952754974365
[1, 12629] loss_train: 0.001561, loss_test: 0.005603
time: 0.24505376815795898
time: 2.2275445461273193
[1, 12630] loss_train: 0.000583, loss_test: 0.005604
time: 0.26105809211730957
time: 2.24550199508667
[1, 12631] loss_train: 0.003505, loss_test: 0.005609
time: 0.24806761741638184
time: 2.256504774093628
[1, 12632] loss_train: 0.010933, loss_test: 0.005611
time: 0.2490549087524414
time: 2.2264983654022217
[1, 12633] loss_train: 0.005668, loss_test: 0.005614
time: 0.24405455589294434
time: 2.218498468399048
[1, 12634] loss_train: 0.011883, loss_test: 0.005612
time: 0.2490549087524414
time: 2.242501974105835
[1, 12635] loss_train: 0.009213, loss_test: 0.005607
time: 0.2450554370880127
time: 2.222496271133423
[1, 12636] loss_train: 0.002250, loss_test: 0.005605
time: 0.24405336380004883
time: 2.228515625
[1, 12637] loss_train: 0.002424, loss_test: 0.005604
time: 0.2470545768737793
time: 2.2204997539520264
[1, 12638] loss_train: 0.004321, loss_test: 0.005605
time: 0.24605464935302734
time: 2.241501569747925
[1, 12639] loss_train: 0.012004, loss_test: 0.005604
time: 0.2530558109283447
time: 2.3405239582061768
[1, 12640] loss_train: 0.008394, loss_test: 0.005605
time: 0.26605844497680664
time: 2.275509834289551
[1, 12641] loss_train: 0.011924, loss_test: 0.005613
time: 0.24805450439453125
time: 2.243502378463745
[1, 12642] loss_train: 0.009196, loss_test: 0.005616
time: 0.2470552921295166
time: 2.25801682472229
[1, 12643] loss_train: 0.006242, loss_test: 0.005623
time: 0.2450542449951172
time: 2.2465028762817383
[1, 12644] loss_train: 0.005881, loss_test: 0.005628
time: 0.2510561943054199
time: 2.214494228363037
[1, 12645] loss_train: 0.004792, loss_test: 0.005629
time: 0.24506783485412598
time: 2.238499879837036
[1, 12646] loss_train: 0.004686, loss_test: 0.005631
time: 0.24605512619018555
time: 2.2085020542144775
[1, 12647] loss_train: 0.003850, loss_test: 0.005621
time: 0.24305391311645508
time: 2.2225093841552734
[1, 12648] loss_train: 0.001756, loss_test: 0.005613
time: 0.24305391311645508
time: 2.2155067920684814
[1, 12649] loss_train: 0.002903, loss_test: 0.005607
time: 0.24405360221862793
time: 2.2365005016326904
[1, 12650] loss_train: 0.003921, loss_test: 0.005608
time: 0.2560563087463379
time: 2.2475028038024902
[1, 12651] loss_train: 0.007518, loss_test: 0.005607
time: 0.24505400657653809
time: 2.227522611618042
[1, 12652] loss_train: 0.001234, loss_test: 0.005610
time: 0.24605488777160645
time: 2.194493055343628
[1, 12653] loss_train: 0.001761, loss_test: 0.005618
time: 0.24405455589294434
time: 2.240499973297119
[1, 12654] loss_train: 0.005157, loss_test: 0.005627
time: 0.24405527114868164
time: 2.2294983863830566
[1, 12655] loss_train: 0.003292, loss_test: 0.005636
time: 0.24605441093444824
time: 2.2154977321624756
[1, 12656] loss_train: 0.005879, loss_test: 0.005643
time: 0.24405455589294434
time: 2.220496416091919
[1, 12657] loss_train: 0.007610, loss_test: 0.005642
time: 0.24405384063720703
time: 2.1974918842315674
[1, 12658] loss_train: 0.002445, loss_test: 0.005643
time: 0.24805450439453125
time: 2.205003261566162
[1, 12659] loss_train: 0.003658, loss_test: 0.005644
time: 0.24805498123168945
time: 2.2365007400512695
[1, 12660] loss_train: 0.001675, loss_test: 0.005649
time: 0.2560577392578125
time: 2.243046760559082
[1, 12661] loss_train: 0.000384, loss_test: 0.005655
time: 0.25005483627319336
time: 2.2139980792999268
[1, 12662] loss_train: 0.001813, loss_test: 0.005661
time: 0.2450544834136963
time: 2.228498697280884
[1, 12663] loss_train: 0.003387, loss_test: 0.005659
time: 0.24405384063720703
time: 2.2415053844451904
[1, 12664] loss_train: 0.008136, loss_test: 0.005650
time: 0.24306750297546387
time: 2.2495028972625732
[1, 12665] loss_train: 0.012357, loss_test: 0.005633
time: 0.24405980110168457
time: 2.245504379272461
[1, 12666] loss_train: 0.008293, loss_test: 0.005615
time: 0.2440659999847412
time: 2.2384679317474365
[1, 12667] loss_train: 0.004845, loss_test: 0.005602
time: 0.24405455589294434
time: 2.2515037059783936
[1, 12668] loss_train: 0.004670, loss_test: 0.005594
time: 0.24605488777160645
time: 2.224497079849243
[1, 12669] loss_train: 0.007463, loss_test: 0.005588
time: 0.24405455589294434
time: 2.211494207382202
[1, 12670] loss_train: 0.006306, loss_test: 0.005586
time: 0.2540609836578369
time: 2.2405190467834473
[1, 12671] loss_train: 0.005752, loss_test: 0.005588
time: 0.2450544834136963
time: 2.214493989944458
[1, 12672] loss_train: 0.004946, loss_test: 0.005592
time: 0.2450542449951172
time: 2.2084944248199463
[1, 12673] loss_train: 0.007061, loss_test: 0.005595
time: 0.24505400657653809
time: 2.216503858566284
[1, 12674] loss_train: 0.001810, loss_test: 0.005594
time: 0.24405360221862793
time: 2.2234978675842285
[1, 12675] loss_train: 0.009164, loss_test: 0.005598
time: 0.24505400657653809
time: 2.206503391265869
[1, 12676] loss_train: 0.003318, loss_test: 0.005599
time: 0.24605369567871094
time: 2.2215049266815186
[1, 12677] loss_train: 0.004552, loss_test: 0.005599
time: 0.24505352973937988
time: 2.23349928855896
[1, 12678] loss_train: 0.004717, loss_test: 0.005599
time: 0.2490553855895996
time: 2.2124946117401123
[1, 12679] loss_train: 0.006976, loss_test: 0.005601
time: 0.2430706024169922
time: 2.2565059661865234
[1, 12680] loss_train: 0.007885, loss_test: 0.005601
time: 0.258056640625
time: 2.2640364170074463
[1, 12681] loss_train: 0.012203, loss_test: 0.005602
time: 0.24305343627929688
time: 2.234502077102661
[1, 12682] loss_train: 0.002077, loss_test: 0.005603
time: 0.24905633926391602
time: 2.218496084213257
[1, 12683] loss_train: 0.007793, loss_test: 0.005604
time: 0.24405431747436523
time: 2.225501775741577
[1, 12684] loss_train: 0.004539, loss_test: 0.005604
time: 0.24305963516235352
time: 2.245502233505249
[1, 12685] loss_train: 0.010446, loss_test: 0.005603
time: 0.24505376815795898
time: 2.2234978675842285
[1, 12686] loss_train: 0.010267, loss_test: 0.005599
time: 0.24405455589294434
time: 2.2295005321502686
[1, 12687] loss_train: 0.006994, loss_test: 0.005597
time: 0.24305343627929688
time: 2.2214972972869873
[1, 12688] loss_train: 0.006125, loss_test: 0.005595
time: 0.2450549602508545
time: 2.2385001182556152
[1, 12689] loss_train: 0.003590, loss_test: 0.005594
time: 0.24305462837219238
time: 2.2532308101654053
[1, 12690] loss_train: 0.008803, loss_test: 0.005593
time: 0.2550692558288574
time: 2.2815098762512207
[1, 12691] loss_train: 0.000989, loss_test: 0.005592
time: 0.24305462837219238
time: 2.2050981521606445
[1, 12692] loss_train: 0.006291, loss_test: 0.005592
time: 0.24605512619018555
time: 2.2144949436187744
[1, 12693] loss_train: 0.006290, loss_test: 0.005594
time: 0.24305343627929688
time: 2.1987292766571045
[1, 12694] loss_train: 0.004435, loss_test: 0.005597
time: 0.2450544834136963
time: 2.245502471923828
[1, 12695] loss_train: 0.005493, loss_test: 0.005599
time: 0.24405312538146973
time: 2.2505056858062744
[1, 12696] loss_train: 0.013383, loss_test: 0.005602
time: 0.24405431747436523
time: 2.20849347114563
[1, 12697] loss_train: 0.006011, loss_test: 0.005604
time: 0.24606871604919434
time: 2.2144951820373535
[1, 12698] loss_train: 0.010600, loss_test: 0.005606
time: 0.24706721305847168
time: 2.1874892711639404
[1, 12699] loss_train: 0.006896, loss_test: 0.005608
time: 0.2510550022125244
time: 2.2134952545166016
[1, 12700] loss_train: 0.008713, loss_test: 0.005611
time: 0.2580578327178955
time: 2.258516788482666
[1, 12701] loss_train: 0.005415, loss_test: 0.005614
time: 0.25005578994750977
time: 2.2274978160858154
[1, 12702] loss_train: 0.000962, loss_test: 0.005617
time: 0.24505376815795898
time: 2.236499786376953
[1, 12703] loss_train: 0.009698, loss_test: 0.005616
time: 0.2470541000366211
time: 2.2465016841888428
[1, 12704] loss_train: 0.001502, loss_test: 0.005615
time: 0.24506831169128418
time: 2.2293758392333984
[1, 12705] loss_train: 0.013061, loss_test: 0.005611
time: 0.24505376815795898
time: 2.2204973697662354
[1, 12706] loss_train: 0.004064, loss_test: 0.005608
time: 0.2450547218322754
time: 2.219538688659668
[1, 12707] loss_train: 0.001401, loss_test: 0.005608
time: 0.24405431747436523
time: 2.242501735687256
[1, 12708] loss_train: 0.005391, loss_test: 0.005605
time: 0.24405407905578613
time: 2.2385013103485107
[1, 12709] loss_train: 0.003918, loss_test: 0.005604
time: 0.24606585502624512
time: 2.223515510559082
[1, 12710] loss_train: 0.002995, loss_test: 0.005604
time: 0.25705742835998535
time: 2.243501663208008
[1, 12711] loss_train: 0.005756, loss_test: 0.005605
time: 0.2470545768737793
time: 2.231499433517456
[1, 12712] loss_train: 0.005645, loss_test: 0.005606
time: 0.2450706958770752
time: 2.240004301071167
[1, 12713] loss_train: 0.002576, loss_test: 0.005610
time: 0.24405407905578613
time: 2.232499361038208
[1, 12714] loss_train: 0.008963, loss_test: 0.005613
time: 0.24305367469787598
time: 2.2395012378692627
[1, 12715] loss_train: 0.004256, loss_test: 0.005618
time: 0.24605488777160645
time: 2.2270071506500244
[1, 12716] loss_train: 0.006730, loss_test: 0.005620
time: 0.24505305290222168
time: 2.2065019607543945
[1, 12717] loss_train: 0.002251, loss_test: 0.005624
time: 0.24405360221862793
time: 2.188490390777588
[1, 12718] loss_train: 0.005351, loss_test: 0.005628
time: 0.24706745147705078
time: 2.2365009784698486
[1, 12719] loss_train: 0.001572, loss_test: 0.005633
time: 0.24405455589294434
time: 2.231355667114258
[1, 12720] loss_train: 0.003471, loss_test: 0.005636
time: 0.2620575428009033
time: 2.258037805557251
[1, 12721] loss_train: 0.002793, loss_test: 0.005640
time: 0.24305367469787598
time: 2.2274985313415527
[1, 12722] loss_train: 0.002559, loss_test: 0.005640
time: 0.25705671310424805
time: 2.2300021648406982
[1, 12723] loss_train: 0.006451, loss_test: 0.005633
time: 0.24405407905578613
time: 2.1884925365448
[1, 12724] loss_train: 0.002423, loss_test: 0.005630
time: 0.24805545806884766
time: 2.2225005626678467
[1, 12725] loss_train: 0.007609, loss_test: 0.005622
time: 0.24405336380004883
time: 2.219496726989746
[1, 12726] loss_train: 0.004433, loss_test: 0.005616
time: 0.24305391311645508
time: 2.220496892929077
[1, 12727] loss_train: 0.008310, loss_test: 0.005618
time: 0.24405455589294434
time: 2.2135095596313477
[1, 12728] loss_train: 0.003452, loss_test: 0.005625
time: 0.2450547218322754
time: 2.211494207382202
[1, 12729] loss_train: 0.006680, loss_test: 0.005632
time: 0.2450547218322754
time: 2.2135441303253174
[1, 12730] loss_train: 0.006375, loss_test: 0.005636
time: 0.25707006454467773
time: 2.2205097675323486
[1, 12731] loss_train: 0.012499, loss_test: 0.005630
time: 0.24405360221862793
time: 2.232499122619629
[1, 12732] loss_train: 0.006524, loss_test: 0.005626
time: 0.24305391311645508
time: 2.2224972248077393
[1, 12733] loss_train: 0.003540, loss_test: 0.005624
time: 0.24506759643554688
time: 2.229499578475952
[1, 12734] loss_train: 0.004619, loss_test: 0.005624
time: 0.24405360221862793
time: 2.241501808166504
[1, 12735] loss_train: 0.006885, loss_test: 0.005621
time: 0.24605464935302734
time: 2.2205135822296143
[1, 12736] loss_train: 0.003768, loss_test: 0.005620
time: 0.24605488777160645
time: 2.2254977226257324
[1, 12737] loss_train: 0.006700, loss_test: 0.005619
time: 0.24805545806884766
time: 2.2264981269836426
[1, 12738] loss_train: 0.006789, loss_test: 0.005616
time: 0.2450544834136963
time: 2.2284984588623047
[1, 12739] loss_train: 0.008160, loss_test: 0.005614
time: 0.251056432723999
time: 2.2345104217529297
[1, 12740] loss_train: 0.009088, loss_test: 0.005614
time: 0.25705766677856445
time: 2.2675065994262695
[1, 12741] loss_train: 0.007184, loss_test: 0.005612
time: 0.2490551471710205
time: 2.202493190765381
[1, 12742] loss_train: 0.001226, loss_test: 0.005610
time: 0.24505376815795898
time: 2.218506097793579
[1, 12743] loss_train: 0.008003, loss_test: 0.005607
time: 0.24605488777160645
time: 2.222999095916748
[1, 12744] loss_train: 0.001557, loss_test: 0.005605
time: 0.24305391311645508
time: 2.2445013523101807
[1, 12745] loss_train: 0.015660, loss_test: 0.005595
time: 0.24405503273010254
time: 2.2365000247955322
[1, 12746] loss_train: 0.004355, loss_test: 0.005589
time: 0.24357390403747559
time: 2.2335000038146973
[1, 12747] loss_train: 0.009506, loss_test: 0.005585
time: 0.2440662384033203
time: 2.219496250152588
[1, 12748] loss_train: 0.012845, loss_test: 0.005585
time: 0.2450542449951172
time: 2.2264983654022217
[1, 12749] loss_train: 0.002814, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2515034675598145
[1, 12750] loss_train: 0.003657, loss_test: 0.005592
time: 0.25457024574279785
time: 2.2735111713409424
[1, 12751] loss_train: 0.009347, loss_test: 0.005594
time: 0.24305343627929688
time: 2.22049880027771
[1, 12752] loss_train: 0.006152, loss_test: 0.005597
time: 0.2450551986694336
time: 2.2104945182800293
[1, 12753] loss_train: 0.004495, loss_test: 0.005598
time: 0.24305367469787598
time: 2.205493927001953
[1, 12754] loss_train: 0.003468, loss_test: 0.005600
time: 0.24505376815795898
time: 2.2014927864074707
[1, 12755] loss_train: 0.003899, loss_test: 0.005602
time: 0.24805521965026855
time: 2.2144968509674072
[1, 12756] loss_train: 0.000449, loss_test: 0.005606
time: 0.24505352973937988
time: 2.2070059776306152
[1, 12757] loss_train: 0.002332, loss_test: 0.005610
time: 0.24605417251586914
time: 2.1724863052368164
[1, 12758] loss_train: 0.004286, loss_test: 0.005615
time: 0.2470543384552002
time: 2.2114946842193604
[1, 12759] loss_train: 0.009637, loss_test: 0.005620
time: 0.24405407905578613
time: 2.2264978885650635
[1, 12760] loss_train: 0.006894, loss_test: 0.005625
time: 0.2580575942993164
time: 2.284520149230957
[1, 12761] loss_train: 0.003309, loss_test: 0.005630
time: 0.24670839309692383
time: 2.2455027103424072
[1, 12762] loss_train: 0.005426, loss_test: 0.005630
time: 0.2450547218322754
time: 2.2720115184783936
[1, 12763] loss_train: 0.006342, loss_test: 0.005627
time: 0.24405527114868164
time: 2.230499267578125
[1, 12764] loss_train: 0.006247, loss_test: 0.005621
time: 0.24605441093444824
time: 2.2325010299682617
[1, 12765] loss_train: 0.012603, loss_test: 0.005613
time: 0.24405527114868164
time: 2.199491500854492
[1, 12766] loss_train: 0.013066, loss_test: 0.005604
time: 0.24508953094482422
time: 2.222445011138916
[1, 12767] loss_train: 0.009438, loss_test: 0.005595
time: 0.24405407905578613
time: 2.2254974842071533
[1, 12768] loss_train: 0.002214, loss_test: 0.005599
time: 0.24506592750549316
time: 2.2054941654205322
[1, 12769] loss_train: 0.013093, loss_test: 0.005613
time: 0.24305367469787598
time: 2.2004919052124023
[1, 12770] loss_train: 0.003761, loss_test: 0.005635
time: 0.2560567855834961
time: 2.252007484436035
[1, 12771] loss_train: 0.004630, loss_test: 0.005658
time: 0.24406647682189941
time: 2.207507848739624
[1, 12772] loss_train: 0.002408, loss_test: 0.005680
time: 0.2450542449951172
time: 2.2545204162597656
[1, 12773] loss_train: 0.002124, loss_test: 0.005699
time: 0.24505352973937988
time: 2.2134954929351807
[1, 12774] loss_train: 0.007053, loss_test: 0.005711
time: 0.2450544834136963
time: 2.2225217819213867
[1, 12775] loss_train: 0.010084, loss_test: 0.005699
time: 0.2490549087524414
time: 2.226497173309326
[1, 12776] loss_train: 0.009170, loss_test: 0.005678
time: 0.24606752395629883
time: 2.2210006713867188
[1, 12777] loss_train: 0.007113, loss_test: 0.005658
time: 0.25005602836608887
time: 2.2405009269714355
[1, 12778] loss_train: 0.008001, loss_test: 0.005630
time: 0.24405407905578613
time: 2.213502883911133
[1, 12779] loss_train: 0.000480, loss_test: 0.005613
time: 0.2490553855895996
time: 2.250096082687378
[1, 12780] loss_train: 0.008361, loss_test: 0.005602
time: 0.2560570240020752
time: 2.2555041313171387
[1, 12781] loss_train: 0.001306, loss_test: 0.005598
time: 0.2510552406311035
time: 2.192491292953491
[1, 12782] loss_train: 0.006040, loss_test: 0.005604
time: 0.24405407905578613
time: 2.2284984588623047
[1, 12783] loss_train: 0.003401, loss_test: 0.005612
time: 0.24405384063720703
time: 2.218496799468994
[1, 12784] loss_train: 0.000917, loss_test: 0.005625
time: 0.24405407905578613
time: 2.2045044898986816
[1, 12785] loss_train: 0.013812, loss_test: 0.005633
time: 0.2450547218322754
time: 2.234499454498291
[1, 12786] loss_train: 0.010315, loss_test: 0.005631
time: 0.24606919288635254
time: 2.231499433517456
[1, 12787] loss_train: 0.005075, loss_test: 0.005621
time: 0.24405431747436523
time: 2.2265143394470215
[1, 12788] loss_train: 0.001467, loss_test: 0.005615
time: 0.24455928802490234
time: 2.2315011024475098
[1, 12789] loss_train: 0.009675, loss_test: 0.005607
time: 0.24305319786071777
time: 2.228015661239624
[1, 12790] loss_train: 0.001789, loss_test: 0.005602
time: 0.2560691833496094
time: 2.245004653930664
[1, 12791] loss_train: 0.007216, loss_test: 0.005595
time: 0.24605417251586914
time: 2.1964917182922363
[1, 12792] loss_train: 0.003101, loss_test: 0.005588
time: 0.24305438995361328
time: 2.2164957523345947
[1, 12793] loss_train: 0.009313, loss_test: 0.005584
time: 0.24805474281311035
time: 2.193490982055664
[1, 12794] loss_train: 0.007962, loss_test: 0.005579
time: 0.24805521965026855
time: 2.248502731323242
[1, 12795] loss_train: 0.006067, loss_test: 0.005579
time: 0.24405479431152344
time: 2.2665069103240967
[1, 12796] loss_train: 0.003635, loss_test: 0.005580
time: 0.2560572624206543
time: 2.237514019012451
[1, 12797] loss_train: 0.016201, loss_test: 0.005585
time: 0.24805474281311035
time: 2.2345004081726074
[1, 12798] loss_train: 0.006577, loss_test: 0.005589
time: 0.2510550022125244
time: 2.2245500087738037
[1, 12799] loss_train: 0.006347, loss_test: 0.005592
time: 0.24805498123168945
time: 2.2224979400634766
[1, 12800] loss_train: 0.003835, loss_test: 0.005590
time: 0.2600572109222412
time: 2.2375006675720215
[1, 12801] loss_train: 0.003604, loss_test: 0.005587
time: 0.24605512619018555
time: 2.218496084213257
[1, 12802] loss_train: 0.009700, loss_test: 0.005586
time: 0.2450542449951172
time: 2.2244977951049805
[1, 12803] loss_train: 0.011740, loss_test: 0.005585
time: 0.24605488777160645
time: 2.2054929733276367
[1, 12804] loss_train: 0.006375, loss_test: 0.005585
time: 0.24605417251586914
time: 2.215496301651001
[1, 12805] loss_train: 0.007088, loss_test: 0.005586
time: 0.24305343627929688
time: 2.198500156402588
[1, 12806] loss_train: 0.008987, loss_test: 0.005586
time: 0.2450544834136963
time: 2.2055416107177734
[1, 12807] loss_train: 0.007048, loss_test: 0.005585
time: 0.24506616592407227
time: 2.2084968090057373
[1, 12808] loss_train: 0.004564, loss_test: 0.005586
time: 0.2450549602508545
time: 2.2164950370788574
[1, 12809] loss_train: 0.006615, loss_test: 0.005587
time: 0.24506711959838867
time: 2.235511302947998
[1, 12810] loss_train: 0.010213, loss_test: 0.005588
time: 0.25505614280700684
time: 2.2575228214263916
[1, 12811] loss_train: 0.010132, loss_test: 0.005587
time: 0.24606657028198242
time: 2.2294986248016357
[1, 12812] loss_train: 0.003755, loss_test: 0.005587
time: 0.2470543384552002
time: 2.2114951610565186
[1, 12813] loss_train: 0.008007, loss_test: 0.005587
time: 0.2490556240081787
time: 2.2234973907470703
[1, 12814] loss_train: 0.002827, loss_test: 0.005589
time: 0.2470548152923584
time: 2.2365000247955322
[1, 12815] loss_train: 0.001128, loss_test: 0.005590
time: 0.24805426597595215
time: 2.2190101146698
[1, 12816] loss_train: 0.007230, loss_test: 0.005590
time: 0.24405384063720703
time: 2.2298338413238525
[1, 12817] loss_train: 0.003593, loss_test: 0.005591
time: 0.25005555152893066
time: 2.234502077102661
[1, 12818] loss_train: 0.008449, loss_test: 0.005586
time: 0.24505400657653809
time: 2.1940107345581055
[1, 12819] loss_train: 0.010235, loss_test: 0.005580
time: 0.24507999420166016
time: 2.229499101638794
[1, 12820] loss_train: 0.006092, loss_test: 0.005580
time: 0.25505638122558594
time: 2.267507553100586
[1, 12821] loss_train: 0.001853, loss_test: 0.005588
time: 0.24805569648742676
time: 2.2044923305511475
[1, 12822] loss_train: 0.001745, loss_test: 0.005603
time: 0.24305391311645508
time: 2.2244982719421387
[1, 12823] loss_train: 0.009482, loss_test: 0.005613
time: 0.24405360221862793
time: 2.2355003356933594
[1, 12824] loss_train: 0.013772, loss_test: 0.005618
time: 0.24505400657653809
time: 2.2124953269958496
[1, 12825] loss_train: 0.001754, loss_test: 0.005614
time: 0.24405431747436523
time: 2.1974916458129883
[1, 12826] loss_train: 0.004641, loss_test: 0.005604
time: 0.24406719207763672
time: 2.2054929733276367
[1, 12827] loss_train: 0.006963, loss_test: 0.005600
time: 0.24405527114868164
time: 2.1784870624542236
[1, 12828] loss_train: 0.004001, loss_test: 0.005601
time: 0.24805521965026855
time: 2.2264981269836426
[1, 12829] loss_train: 0.008832, loss_test: 0.005603
time: 0.24405455589294434
time: 2.2175235748291016
[1, 12830] loss_train: 0.009649, loss_test: 0.005605
time: 0.25905895233154297
time: 2.236499786376953
[1, 12831] loss_train: 0.006496, loss_test: 0.005609
time: 0.24605417251586914
time: 2.2535042762756348
[1, 12832] loss_train: 0.003917, loss_test: 0.005613
time: 0.24605464935302734
time: 2.2124950885772705
[1, 12833] loss_train: 0.008028, loss_test: 0.005615
time: 0.24305415153503418
time: 2.224496841430664
[1, 12834] loss_train: 0.006806, loss_test: 0.005617
time: 0.24305486679077148
time: 2.2365000247955322
[1, 12835] loss_train: 0.007159, loss_test: 0.005616
time: 0.24405312538146973
time: 2.2055039405822754
[1, 12836] loss_train: 0.005754, loss_test: 0.005613
time: 0.24405407905578613
time: 2.2115399837493896
[1, 12837] loss_train: 0.012041, loss_test: 0.005609
time: 0.24405384063720703
time: 2.2109997272491455
[1, 12838] loss_train: 0.006240, loss_test: 0.005605
time: 0.24505400657653809
time: 2.1844892501831055
[1, 12839] loss_train: 0.002269, loss_test: 0.005602
time: 0.24305343627929688
time: 2.2124953269958496
[1, 12840] loss_train: 0.011255, loss_test: 0.005606
time: 0.2560567855834961
time: 2.2595055103302
[1, 12841] loss_train: 0.010868, loss_test: 0.005614
time: 0.2450542449951172
time: 2.2345004081726074
[1, 12842] loss_train: 0.012983, loss_test: 0.005624
time: 0.24605464935302734
time: 2.2395005226135254
[1, 12843] loss_train: 0.006237, loss_test: 0.005631
time: 0.2450551986694336
time: 2.2314984798431396
[1, 12844] loss_train: 0.006355, loss_test: 0.005630
time: 0.24605464935302734
time: 2.2234976291656494
[1, 12845] loss_train: 0.007659, loss_test: 0.005617
time: 0.2470543384552002
time: 2.252354860305786
[1, 12846] loss_train: 0.013454, loss_test: 0.005620
time: 0.24605488777160645
time: 2.2274980545043945
[1, 12847] loss_train: 0.001190, loss_test: 0.005615
time: 0.25005578994750977
time: 2.250502824783325
[1, 12848] loss_train: 0.003406, loss_test: 0.005606
time: 0.2470548152923584
time: 2.2034924030303955
[1, 12849] loss_train: 0.014808, loss_test: 0.005601
time: 0.2470548152923584
time: 2.2295076847076416
[1, 12850] loss_train: 0.003826, loss_test: 0.005598
time: 0.2580573558807373
time: 2.2224972248077393
[1, 12851] loss_train: 0.008014, loss_test: 0.005597
time: 0.2470550537109375
time: 2.2294981479644775
[1, 12852] loss_train: 0.002582, loss_test: 0.005601
time: 0.2430891990661621
time: 2.2124950885772705
[1, 12853] loss_train: 0.004547, loss_test: 0.005605
time: 0.24405384063720703
time: 2.2074944972991943
[1, 12854] loss_train: 0.008813, loss_test: 0.005606
time: 0.24405360221862793
time: 2.2335002422332764
[1, 12855] loss_train: 0.004184, loss_test: 0.005606
time: 0.24406719207763672
time: 2.22841477394104
[1, 12856] loss_train: 0.003557, loss_test: 0.005607
time: 0.24405407905578613
time: 2.2005178928375244
[1, 12857] loss_train: 0.005837, loss_test: 0.005611
time: 0.24406695365905762
time: 2.236499547958374
[1, 12858] loss_train: 0.016609, loss_test: 0.005607
time: 0.24305462837219238
time: 2.230003595352173
[1, 12859] loss_train: 0.005329, loss_test: 0.005605
time: 0.24305415153503418
time: 2.2114944458007812
[1, 12860] loss_train: 0.006987, loss_test: 0.005591
time: 0.25505614280700684
time: 2.234499931335449
[1, 12861] loss_train: 0.007247, loss_test: 0.005584
time: 0.24405479431152344
time: 2.2525033950805664
[1, 12862] loss_train: 0.005773, loss_test: 0.005580
time: 0.2450551986694336
time: 2.259507179260254
[1, 12863] loss_train: 0.013360, loss_test: 0.005581
time: 0.24405431747436523
time: 2.2044930458068848
[1, 12864] loss_train: 0.011290, loss_test: 0.005583
time: 0.24405360221862793
time: 2.2044928073883057
[1, 12865] loss_train: 0.012080, loss_test: 0.005585
time: 0.24806880950927734
time: 2.223497152328491
[1, 12866] loss_train: 0.001723, loss_test: 0.005587
time: 0.24906301498413086
time: 2.209494113922119
[1, 12867] loss_train: 0.001128, loss_test: 0.005582
time: 0.2450544834136963
time: 2.1984918117523193
[1, 12868] loss_train: 0.001507, loss_test: 0.005577
time: 0.24305391311645508
time: 2.219496726989746
[1, 12869] loss_train: 0.013535, loss_test: 0.005577
time: 0.24806833267211914
time: 2.222468137741089
[1, 12870] loss_train: 0.013025, loss_test: 0.005585
time: 0.256056547164917
time: 2.2335000038146973
[1, 12871] loss_train: 0.009557, loss_test: 0.005593
time: 0.2440659999847412
time: 2.231499433517456
[1, 12872] loss_train: 0.016147, loss_test: 0.005603
time: 0.24305462837219238
time: 2.2435014247894287
[1, 12873] loss_train: 0.010015, loss_test: 0.005612
time: 0.24405336380004883
time: 2.2184958457946777
[1, 12874] loss_train: 0.009257, loss_test: 0.005612
time: 0.24405384063720703
time: 2.2270121574401855
[1, 12875] loss_train: 0.004884, loss_test: 0.005601
time: 0.24305319786071777
time: 2.2345004081726074
[1, 12876] loss_train: 0.005255, loss_test: 0.005592
time: 0.24305462837219238
time: 2.210611343383789
[1, 12877] loss_train: 0.002333, loss_test: 0.005583
time: 0.24405455589294434
time: 2.218496561050415
[1, 12878] loss_train: 0.002413, loss_test: 0.005581
time: 0.24505352973937988
time: 2.2135186195373535
[1, 12879] loss_train: 0.007740, loss_test: 0.005589
time: 0.2450551986694336
time: 2.2194995880126953
[1, 12880] loss_train: 0.005464, loss_test: 0.005605
time: 0.25707268714904785
time: 2.2625064849853516
[1, 12881] loss_train: 0.004668, loss_test: 0.005626
time: 0.24605417251586914
time: 2.244502544403076
[1, 12882] loss_train: 0.009260, loss_test: 0.005644
time: 0.24405384063720703
time: 2.222499370574951
[1, 12883] loss_train: 0.009852, loss_test: 0.005654
time: 0.24805498123168945
time: 2.2265002727508545
[1, 12884] loss_train: 0.007916, loss_test: 0.005656
time: 0.24605417251586914
time: 2.2114951610565186
[1, 12885] loss_train: 0.001370, loss_test: 0.005659
time: 0.25006675720214844
time: 2.20149302482605
[1, 12886] loss_train: 0.002737, loss_test: 0.005656
time: 0.2450544834136963
time: 2.216123104095459
[1, 12887] loss_train: 0.005301, loss_test: 0.005653
time: 0.24405384063720703
time: 2.1879918575286865
[1, 12888] loss_train: 0.008297, loss_test: 0.005648
time: 0.24506759643554688
time: 2.216005802154541
[1, 12889] loss_train: 0.001827, loss_test: 0.005648
time: 0.24307942390441895
time: 2.219022512435913
[1, 12890] loss_train: 0.011497, loss_test: 0.005639
time: 0.25705695152282715
time: 2.2445013523101807
[1, 12891] loss_train: 0.004879, loss_test: 0.005630
time: 0.24508094787597656
time: 2.218496084213257
[1, 12892] loss_train: 0.010687, loss_test: 0.005621
time: 0.2450542449951172
time: 2.2234973907470703
[1, 12893] loss_train: 0.007615, loss_test: 0.005608
time: 0.2470550537109375
time: 2.2355217933654785
[1, 12894] loss_train: 0.006025, loss_test: 0.005602
time: 0.24506831169128418
time: 2.219496011734009
[1, 12895] loss_train: 0.010725, loss_test: 0.005603
time: 0.24405407905578613
time: 2.237516403198242
[1, 12896] loss_train: 0.006654, loss_test: 0.005606
time: 0.24405431747436523
time: 2.2486355304718018
[1, 12897] loss_train: 0.003092, loss_test: 0.005610
time: 0.24405407905578613
time: 2.21049427986145
[1, 12898] loss_train: 0.009286, loss_test: 0.005616
time: 0.24805545806884766
time: 2.2215099334716797
[1, 12899] loss_train: 0.003406, loss_test: 0.005620
time: 0.24405312538146973
time: 2.1828725337982178
[1, 12900] loss_train: 0.010010, loss_test: 0.005624
time: 0.2620584964752197
time: 2.2785093784332275
[1, 12901] loss_train: 0.009924, loss_test: 0.005629
time: 0.24305462837219238
time: 2.247502326965332
[1, 12902] loss_train: 0.005866, loss_test: 0.005630
time: 0.24655652046203613
time: 2.2325000762939453
[1, 12903] loss_train: 0.001654, loss_test: 0.005628
time: 0.24605417251586914
time: 2.2355024814605713
[1, 12904] loss_train: 0.004875, loss_test: 0.005628
time: 0.2470543384552002
time: 2.2293548583984375
[1, 12905] loss_train: 0.002972, loss_test: 0.005635
time: 0.24305415153503418
time: 2.24650239944458
[1, 12906] loss_train: 0.002909, loss_test: 0.005647
time: 0.24405384063720703
time: 2.2405176162719727
[1, 12907] loss_train: 0.005752, loss_test: 0.005663
time: 0.25205516815185547
time: 2.223001718521118
[1, 12908] loss_train: 0.006314, loss_test: 0.005671
time: 0.24405455589294434
time: 2.212498188018799
[1, 12909] loss_train: 0.010574, loss_test: 0.005667
time: 0.24305391311645508
time: 2.271501302719116
[1, 12910] loss_train: 0.002472, loss_test: 0.005661
time: 0.25707530975341797
time: 2.2905123233795166
[1, 12911] loss_train: 0.003009, loss_test: 0.005655
time: 0.24405455589294434
time: 2.2301671504974365
[1, 12912] loss_train: 0.007263, loss_test: 0.005649
time: 0.25305652618408203
time: 2.284510612487793
[1, 12913] loss_train: 0.004647, loss_test: 0.005643
time: 0.24605417251586914
time: 2.227499008178711
[1, 12914] loss_train: 0.010663, loss_test: 0.005633
time: 0.24405336380004883
time: 2.2635066509246826
[1, 12915] loss_train: 0.005603, loss_test: 0.005625
time: 0.24305391311645508
time: 2.218001365661621
[1, 12916] loss_train: 0.001340, loss_test: 0.005622
time: 0.2470550537109375
time: 2.26950740814209
[1, 12917] loss_train: 0.002164, loss_test: 0.005619
time: 0.24605488777160645
time: 2.2665066719055176
[1, 12918] loss_train: 0.011519, loss_test: 0.005614
time: 0.24405455589294434
time: 2.23000168800354
[1, 12919] loss_train: 0.010704, loss_test: 0.005609
time: 0.24305391311645508
time: 2.247101306915283
[1, 12920] loss_train: 0.010241, loss_test: 0.005608
time: 0.2600581645965576
time: 2.282510757446289
[1, 12921] loss_train: 0.003866, loss_test: 0.005611
time: 0.24205374717712402
time: 2.2294986248016357
[1, 12922] loss_train: 0.004600, loss_test: 0.005617
time: 0.24405431747436523
time: 2.2515172958374023
[1, 12923] loss_train: 0.007470, loss_test: 0.005622
time: 0.24405360221862793
time: 2.2139980792999268
[1, 12924] loss_train: 0.005071, loss_test: 0.005624
time: 0.24405384063720703
time: 2.2335000038146973
[1, 12925] loss_train: 0.001701, loss_test: 0.005629
time: 0.24605393409729004
time: 2.231498956680298
[1, 12926] loss_train: 0.005031, loss_test: 0.005629
time: 0.24506664276123047
time: 2.207494020462036
[1, 12927] loss_train: 0.003472, loss_test: 0.005630
time: 0.24505376815795898
time: 2.200493335723877
[1, 12928] loss_train: 0.004509, loss_test: 0.005631
time: 0.24406743049621582
time: 2.2014925479888916
[1, 12929] loss_train: 0.004354, loss_test: 0.005632
time: 0.24605393409729004
time: 2.1964917182922363
[1, 12930] loss_train: 0.007811, loss_test: 0.005635
time: 0.2580568790435791
time: 2.2370822429656982
[1, 12931] loss_train: 0.003400, loss_test: 0.005632
time: 0.2510561943054199
time: 2.212494373321533
[1, 12932] loss_train: 0.003389, loss_test: 0.005634
time: 0.2450547218322754
time: 2.2375006675720215
[1, 12933] loss_train: 0.008994, loss_test: 0.005637
time: 0.25005483627319336
time: 2.2565181255340576
[1, 12934] loss_train: 0.007868, loss_test: 0.005634
time: 0.24605417251586914
time: 2.2204973697662354
[1, 12935] loss_train: 0.003737, loss_test: 0.005632
time: 0.2502901554107666
time: 2.2350029945373535
[1, 12936] loss_train: 0.002372, loss_test: 0.005633
time: 0.24405384063720703
time: 2.1974918842315674
[1, 12937] loss_train: 0.006708, loss_test: 0.005623
time: 0.24405360221862793
time: 2.217498779296875
[1, 12938] loss_train: 0.008246, loss_test: 0.005615
time: 0.24605488777160645
time: 2.205493211746216
[1, 12939] loss_train: 0.007181, loss_test: 0.005607
time: 0.24305343627929688
time: 2.2210137844085693
[1, 12940] loss_train: 0.005312, loss_test: 0.005605
time: 0.2560560703277588
time: 2.259019374847412
[1, 12941] loss_train: 0.002894, loss_test: 0.005607
time: 0.2450544834136963
time: 2.2300169467926025
[1, 12942] loss_train: 0.007640, loss_test: 0.005612
time: 0.24406671524047852
time: 2.229499340057373
[1, 12943] loss_train: 0.003650, loss_test: 0.005613
time: 0.24309492111206055
time: 2.231820821762085
[1, 12944] loss_train: 0.012961, loss_test: 0.005618
time: 0.2450547218322754
time: 2.2284979820251465
[1, 12945] loss_train: 0.006767, loss_test: 0.005622
time: 0.24405407905578613
time: 2.235499620437622
[1, 12946] loss_train: 0.008680, loss_test: 0.005627
time: 0.24405455589294434
time: 2.21049427986145
[1, 12947] loss_train: 0.004561, loss_test: 0.005626
time: 0.24805450439453125
time: 2.2124953269958496
[1, 12948] loss_train: 0.010666, loss_test: 0.005626
time: 0.24405360221862793
time: 2.1874890327453613
[1, 12949] loss_train: 0.004849, loss_test: 0.005619
time: 0.24405312538146973
time: 2.224010705947876
[1, 12950] loss_train: 0.008582, loss_test: 0.005615
time: 0.2600581645965576
time: 2.2546982765197754
[1, 12951] loss_train: 0.007385, loss_test: 0.005614
time: 0.24605417251586914
time: 2.203493356704712
[1, 12952] loss_train: 0.010059, loss_test: 0.005615
time: 0.2470545768737793
time: 2.212496042251587
[1, 12953] loss_train: 0.003116, loss_test: 0.005622
time: 0.24505400657653809
time: 2.2115020751953125
[1, 12954] loss_train: 0.003089, loss_test: 0.005633
time: 0.24605512619018555
time: 2.247502565383911
[1, 12955] loss_train: 0.006857, loss_test: 0.005645
time: 0.24305391311645508
time: 2.2350142002105713
[1, 12956] loss_train: 0.002250, loss_test: 0.005658
time: 0.2450542449951172
time: 2.22405743598938
[1, 12957] loss_train: 0.001955, loss_test: 0.005676
time: 0.24305367469787598
time: 2.1974921226501465
[1, 12958] loss_train: 0.006541, loss_test: 0.005694
time: 0.24305391311645508
time: 2.235499858856201
[1, 12959] loss_train: 0.004805, loss_test: 0.005709
time: 0.24405455589294434
time: 2.2155046463012695
[1, 12960] loss_train: 0.004275, loss_test: 0.005722
time: 0.2560563087463379
time: 2.250020980834961
[1, 12961] loss_train: 0.006834, loss_test: 0.005727
time: 0.24405407905578613
time: 2.227001190185547
[1, 12962] loss_train: 0.014063, loss_test: 0.005701
time: 0.24405431747436523
time: 2.233499765396118
[1, 12963] loss_train: 0.003711, loss_test: 0.005679
time: 0.24305319786071777
time: 2.193591594696045
[1, 12964] loss_train: 0.001808, loss_test: 0.005662
time: 0.24605512619018555
time: 2.2184958457946777
[1, 12965] loss_train: 0.003218, loss_test: 0.005648
time: 0.24805474281311035
time: 2.2114953994750977
[1, 12966] loss_train: 0.007065, loss_test: 0.005631
time: 0.24505376815795898
time: 2.2274978160858154
[1, 12967] loss_train: 0.004840, loss_test: 0.005623
time: 0.2470543384552002
time: 2.2545042037963867
[1, 12968] loss_train: 0.006891, loss_test: 0.005617
time: 0.24306583404541016
time: 2.2284984588623047
[1, 12969] loss_train: 0.008153, loss_test: 0.005614
time: 0.2490673065185547
time: 2.2274985313415527
[1, 12970] loss_train: 0.009983, loss_test: 0.005614
time: 0.25706934928894043
time: 2.2665069103240967
[1, 12971] loss_train: 0.001905, loss_test: 0.005612
time: 0.2580578327178955
time: 2.2054929733276367
[1, 12972] loss_train: 0.001952, loss_test: 0.005607
time: 0.24406695365905762
time: 2.2370104789733887
[1, 12973] loss_train: 0.004613, loss_test: 0.005603
time: 0.2450549602508545
time: 2.2194957733154297
[1, 12974] loss_train: 0.014143, loss_test: 0.005601
time: 0.2450542449951172
time: 2.1884894371032715
[1, 12975] loss_train: 0.010883, loss_test: 0.005600
time: 0.24408268928527832
time: 2.218540668487549
[1, 12976] loss_train: 0.003854, loss_test: 0.005600
time: 0.24305319786071777
time: 2.2234981060028076
[1, 12977] loss_train: 0.009515, loss_test: 0.005604
time: 0.24305319786071777
time: 2.226498603820801
[1, 12978] loss_train: 0.006448, loss_test: 0.005610
time: 0.2470555305480957
time: 2.2204954624176025
[1, 12979] loss_train: 0.010545, loss_test: 0.005613
time: 0.2470555305480957
time: 2.2405014038085938
[1, 12980] loss_train: 0.002889, loss_test: 0.005613
time: 0.2560563087463379
time: 2.2475030422210693
[1, 12981] loss_train: 0.006717, loss_test: 0.005613
time: 0.2470548152923584
time: 2.2035012245178223
[1, 12982] loss_train: 0.006748, loss_test: 0.005607
time: 0.2450544834136963
time: 2.205493211746216
[1, 12983] loss_train: 0.005952, loss_test: 0.005601
time: 0.2450544834136963
time: 2.2375075817108154
[1, 12984] loss_train: 0.009324, loss_test: 0.005596
time: 0.24605417251586914
time: 2.2204997539520264
[1, 12985] loss_train: 0.006835, loss_test: 0.005593
time: 0.24405336380004883
time: 2.2260124683380127
[1, 12986] loss_train: 0.005770, loss_test: 0.005593
time: 0.24805545806884766
time: 2.207493543624878
[1, 12987] loss_train: 0.001863, loss_test: 0.005594
time: 0.24305319786071777
time: 2.2105095386505127
[1, 12988] loss_train: 0.004587, loss_test: 0.005595
time: 0.2470548152923584
time: 2.2234978675842285
[1, 12989] loss_train: 0.006189, loss_test: 0.005595
time: 0.24405384063720703
time: 2.234502077102661
[1, 12990] loss_train: 0.000841, loss_test: 0.005593
time: 0.258070707321167
time: 2.2400052547454834
[1, 12991] loss_train: 0.012131, loss_test: 0.005594
time: 0.2470543384552002
time: 2.219496965408325
[1, 12992] loss_train: 0.005028, loss_test: 0.005595
time: 0.24305319786071777
time: 2.2205018997192383
[1, 12993] loss_train: 0.005387, loss_test: 0.005595
time: 0.24605512619018555
time: 2.2284979820251465
[1, 12994] loss_train: 0.003563, loss_test: 0.005593
time: 0.24405837059020996
time: 2.2525033950805664
[1, 12995] loss_train: 0.008094, loss_test: 0.005589
time: 0.24605464935302734
time: 2.2254974842071533
[1, 12996] loss_train: 0.003502, loss_test: 0.005589
time: 0.24405360221862793
time: 2.2027997970581055
[1, 12997] loss_train: 0.006176, loss_test: 0.005589
time: 0.24305343627929688
time: 2.1829919815063477
[1, 12998] loss_train: 0.006460, loss_test: 0.005590
time: 0.2450547218322754
time: 2.2035017013549805
[1, 12999] loss_train: 0.005517, loss_test: 0.005591
time: 0.24805498123168945
time: 2.2375009059906006
[1, 13000] loss_train: 0.011977, loss_test: 0.005592
time: 0.258056640625
time: 2.287055730819702
[1, 13001] loss_train: 0.002657, loss_test: 0.005595
time: 0.25005507469177246
time: 2.2264983654022217
[1, 13002] loss_train: 0.007797, loss_test: 0.005597
time: 0.24605488777160645
time: 2.211503744125366
[1, 13003] loss_train: 0.004614, loss_test: 0.005601
time: 0.2490558624267578
time: 2.245501756668091
[1, 13004] loss_train: 0.004272, loss_test: 0.005606
time: 0.24405479431152344
time: 2.2154953479766846
[1, 13005] loss_train: 0.013876, loss_test: 0.005607
time: 0.2490551471710205
time: 2.243501901626587
[1, 13006] loss_train: 0.004158, loss_test: 0.005606
time: 0.24305415153503418
time: 2.208493947982788
[1, 13007] loss_train: 0.008005, loss_test: 0.005602
time: 0.24605488777160645
time: 2.230015277862549
[1, 13008] loss_train: 0.010157, loss_test: 0.005595
time: 0.24305367469787598
time: 2.207012891769409
[1, 13009] loss_train: 0.005923, loss_test: 0.005590
time: 0.2470541000366211
time: 2.232196092605591
[1, 13010] loss_train: 0.013665, loss_test: 0.005587
time: 0.25505566596984863
time: 2.234502077102661
[1, 13011] loss_train: 0.006295, loss_test: 0.005585
time: 0.24405550956726074
time: 2.2155117988586426
[1, 13012] loss_train: 0.011235, loss_test: 0.005583
time: 0.24405384063720703
time: 2.190490484237671
[1, 13013] loss_train: 0.004799, loss_test: 0.005583
time: 0.24405598640441895
time: 2.1914925575256348
[1, 13014] loss_train: 0.006003, loss_test: 0.005582
time: 0.2450549602508545
time: 2.2218739986419678
[1, 13015] loss_train: 0.021902, loss_test: 0.005582
time: 0.24605512619018555
time: 2.2525036334991455
[1, 13016] loss_train: 0.004492, loss_test: 0.005583
time: 0.24607086181640625
time: 2.2130086421966553
[1, 13017] loss_train: 0.002846, loss_test: 0.005584
time: 0.24605393409729004
time: 2.2345004081726074
[1, 13018] loss_train: 0.012100, loss_test: 0.005587
time: 0.2490556240081787
time: 2.218271255493164
[1, 13019] loss_train: 0.003592, loss_test: 0.005589
time: 0.24356627464294434
time: 2.2144951820373535
[1, 13020] loss_train: 0.005448, loss_test: 0.005588
time: 0.2620718479156494
time: 2.244511127471924
[1, 13021] loss_train: 0.003057, loss_test: 0.005583
time: 0.2450547218322754
time: 2.2134954929351807
[1, 13022] loss_train: 0.008260, loss_test: 0.005581
time: 0.2490549087524414
time: 2.2124946117401123
[1, 13023] loss_train: 0.006542, loss_test: 0.005581
time: 0.24559831619262695
time: 2.232499361038208
[1, 13024] loss_train: 0.002710, loss_test: 0.005582
time: 0.24405407905578613
time: 2.2124950885772705
[1, 13025] loss_train: 0.014657, loss_test: 0.005586
time: 0.24405384063720703
time: 2.232499837875366
[1, 13026] loss_train: 0.001203, loss_test: 0.005592
time: 0.24405384063720703
time: 2.243501663208008
[1, 13027] loss_train: 0.002485, loss_test: 0.005602
time: 0.2450554370880127
time: 2.2135086059570312
[1, 13028] loss_train: 0.008985, loss_test: 0.005611
time: 0.24405360221862793
time: 2.221496820449829
[1, 13029] loss_train: 0.007423, loss_test: 0.005622
time: 0.24309206008911133
time: 2.220170021057129
[1, 13030] loss_train: 0.006370, loss_test: 0.005629
time: 0.258056640625
time: 2.264507293701172
[1, 13031] loss_train: 0.002283, loss_test: 0.005636
time: 0.2450549602508545
time: 2.2415006160736084
[1, 13032] loss_train: 0.004426, loss_test: 0.005642
time: 0.2420654296875
time: 2.217496395111084
[1, 13033] loss_train: 0.002358, loss_test: 0.005648
time: 0.2470543384552002
time: 2.2355735301971436
[1, 13034] loss_train: 0.017046, loss_test: 0.005630
time: 0.24505352973937988
time: 2.204493284225464
[1, 13035] loss_train: 0.005400, loss_test: 0.005614
time: 0.24506902694702148
time: 2.196491003036499
[1, 13036] loss_train: 0.010093, loss_test: 0.005597
time: 0.24605512619018555
time: 2.2305104732513428
[1, 13037] loss_train: 0.006059, loss_test: 0.005589
time: 0.24908733367919922
time: 2.2144956588745117
[1, 13038] loss_train: 0.006324, loss_test: 0.005594
time: 0.24305415153503418
time: 2.2355005741119385
[1, 13039] loss_train: 0.007406, loss_test: 0.005602
time: 0.2470545768737793
time: 2.26202130317688
[1, 13040] loss_train: 0.013736, loss_test: 0.005616
time: 0.2560558319091797
time: 2.2715089321136475
[1, 13041] loss_train: 0.006602, loss_test: 0.005633
time: 0.2510554790496826
time: 2.2310128211975098
[1, 13042] loss_train: 0.006027, loss_test: 0.005649
time: 0.2450544834136963
time: 2.2245073318481445
[1, 13043] loss_train: 0.009486, loss_test: 0.005665
time: 0.25205516815185547
time: 2.2094955444335938
[1, 13044] loss_train: 0.007775, loss_test: 0.005652
time: 0.24305272102355957
time: 2.2165088653564453
[1, 13045] loss_train: 0.010248, loss_test: 0.005632
time: 0.24405312538146973
time: 2.1895029544830322
[1, 13046] loss_train: 0.003918, loss_test: 0.005613
time: 0.24305367469787598
time: 2.1994924545288086
[1, 13047] loss_train: 0.009588, loss_test: 0.005603
time: 0.24605441093444824
time: 2.2154955863952637
[1, 13048] loss_train: 0.003664, loss_test: 0.005604
time: 0.2450542449951172
time: 2.188490152359009
[1, 13049] loss_train: 0.003365, loss_test: 0.005613
time: 0.24305367469787598
time: 2.214508533477783
[1, 13050] loss_train: 0.013082, loss_test: 0.005626
time: 0.25505661964416504
time: 2.280510425567627
[1, 13051] loss_train: 0.012216, loss_test: 0.005641
time: 0.2450542449951172
time: 2.203493595123291
[1, 13052] loss_train: 0.005467, loss_test: 0.005654
time: 0.24605441093444824
time: 2.220496416091919
[1, 13053] loss_train: 0.005020, loss_test: 0.005666
time: 0.24506831169128418
time: 2.1754865646362305
[1, 13054] loss_train: 0.001503, loss_test: 0.005680
time: 0.2510559558868408
time: 2.22149658203125
[1, 13055] loss_train: 0.005393, loss_test: 0.005691
time: 0.2450542449951172
time: 2.2385005950927734
[1, 13056] loss_train: 0.010302, loss_test: 0.005675
time: 0.2470550537109375
time: 2.227498769760132
[1, 13057] loss_train: 0.011829, loss_test: 0.005657
time: 0.24505352973937988
time: 2.2250020503997803
[1, 13058] loss_train: 0.007535, loss_test: 0.005637
time: 0.24305367469787598
time: 2.218496084213257
[1, 13059] loss_train: 0.008138, loss_test: 0.005623
time: 0.24405431747436523
time: 2.2085132598876953
[1, 13060] loss_train: 0.006274, loss_test: 0.005615
time: 0.25505661964416504
time: 2.2575387954711914
[1, 13061] loss_train: 0.008431, loss_test: 0.005610
time: 0.2470545768737793
time: 2.196497917175293
[1, 13062] loss_train: 0.013496, loss_test: 0.005606
time: 0.24506688117980957
time: 2.198535680770874
[1, 13063] loss_train: 0.006686, loss_test: 0.005611
time: 0.24305415153503418
time: 2.2094943523406982
[1, 13064] loss_train: 0.004255, loss_test: 0.005615
time: 0.24305415153503418
time: 2.2635087966918945
[1, 13065] loss_train: 0.001998, loss_test: 0.005613
time: 0.24405407905578613
time: 2.224097967147827
[1, 13066] loss_train: 0.005411, loss_test: 0.005608
time: 0.24405455589294434
time: 2.2405006885528564
[1, 13067] loss_train: 0.008321, loss_test: 0.005598
time: 0.24506092071533203
time: 2.2365174293518066
[1, 13068] loss_train: 0.004858, loss_test: 0.005590
time: 0.2450544834136963
time: 2.2155115604400635
[1, 13069] loss_train: 0.004707, loss_test: 0.005584
time: 0.24605512619018555
time: 2.1984915733337402
[1, 13070] loss_train: 0.004399, loss_test: 0.005582
time: 0.2580568790435791
time: 2.2515037059783936
[1, 13071] loss_train: 0.016185, loss_test: 0.005580
time: 0.25505614280700684
time: 2.208494186401367
[1, 13072] loss_train: 0.005697, loss_test: 0.005587
time: 0.24405479431152344
time: 2.221001625061035
[1, 13073] loss_train: 0.004512, loss_test: 0.005598
time: 0.2470541000366211
time: 2.2165002822875977
[1, 13074] loss_train: 0.011536, loss_test: 0.005606
time: 0.24506759643554688
time: 2.217496633529663
[1, 13075] loss_train: 0.005802, loss_test: 0.005609
time: 0.24305438995361328
time: 2.2085037231445312
[1, 13076] loss_train: 0.002686, loss_test: 0.005614
time: 0.24506688117980957
time: 2.2064931392669678
[1, 13077] loss_train: 0.008276, loss_test: 0.005612
time: 0.24405360221862793
time: 2.226486921310425
[1, 13078] loss_train: 0.005093, loss_test: 0.005604
time: 0.24305319786071777
time: 2.219496488571167
[1, 13079] loss_train: 0.007911, loss_test: 0.005595
time: 0.24305391311645508
time: 2.2345235347747803
[1, 13080] loss_train: 0.013265, loss_test: 0.005590
time: 0.2560572624206543
time: 2.220496654510498
[1, 13081] loss_train: 0.002920, loss_test: 0.005586
time: 0.25005602836608887
time: 2.1894888877868652
[1, 13082] loss_train: 0.003174, loss_test: 0.005585
time: 0.24657630920410156
time: 2.2024919986724854
[1, 13083] loss_train: 0.004188, loss_test: 0.005586
time: 0.24605441093444824
time: 2.217496395111084
[1, 13084] loss_train: 0.004113, loss_test: 0.005588
time: 0.2490549087524414
time: 2.241504430770874
[1, 13085] loss_train: 0.003537, loss_test: 0.005592
time: 0.24605464935302734
time: 2.213494062423706
[1, 13086] loss_train: 0.004398, loss_test: 0.005598
time: 0.24805426597595215
time: 2.1854894161224365
[1, 13087] loss_train: 0.002632, loss_test: 0.005604
time: 0.24405407905578613
time: 2.2055044174194336
[1, 13088] loss_train: 0.006449, loss_test: 0.005612
time: 0.2450549602508545
time: 2.2244982719421387
[1, 13089] loss_train: 0.009392, loss_test: 0.005619
time: 0.2450551986694336
time: 2.259504795074463
[1, 13090] loss_train: 0.006540, loss_test: 0.005626
time: 0.25505638122558594
time: 2.255504846572876
[1, 13091] loss_train: 0.001828, loss_test: 0.005635
time: 0.24505376815795898
time: 2.214495897293091
[1, 13092] loss_train: 0.008877, loss_test: 0.005643
time: 0.2470545768737793
time: 2.265507459640503
[1, 13093] loss_train: 0.001495, loss_test: 0.005651
time: 0.24305462837219238
time: 2.199491500854492
[1, 13094] loss_train: 0.004676, loss_test: 0.005659
time: 0.24305367469787598
time: 2.235499620437622
[1, 13095] loss_train: 0.000694, loss_test: 0.005672
time: 0.24405384063720703
time: 2.2295124530792236
[1, 13096] loss_train: 0.007187, loss_test: 0.005682
time: 0.24506688117980957
time: 2.232499122619629
[1, 13097] loss_train: 0.004700, loss_test: 0.005687
time: 0.24405384063720703
time: 2.202810764312744
[1, 13098] loss_train: 0.008774, loss_test: 0.005686
time: 0.24405384063720703
time: 2.2264983654022217
[1, 13099] loss_train: 0.006187, loss_test: 0.005684
time: 0.24605393409729004
time: 2.240501642227173
[1, 13100] loss_train: 0.007736, loss_test: 0.005664
time: 0.256056547164917
time: 2.224508047103882
[1, 13101] loss_train: 0.005588, loss_test: 0.005649
time: 0.24505352973937988
time: 2.2074942588806152
[1, 13102] loss_train: 0.009625, loss_test: 0.005640
time: 0.24405360221862793
time: 2.235020637512207
[1, 13103] loss_train: 0.008048, loss_test: 0.005631
time: 0.2490551471710205
time: 2.230499267578125
[1, 13104] loss_train: 0.002204, loss_test: 0.005626
time: 0.24405384063720703
time: 2.2500085830688477
[1, 13105] loss_train: 0.009236, loss_test: 0.005627
time: 0.24805474281311035
time: 2.2154955863952637
[1, 13106] loss_train: 0.002724, loss_test: 0.005638
time: 0.2490551471710205
time: 2.218506097793579
[1, 13107] loss_train: 0.004273, loss_test: 0.005654
time: 0.24605488777160645
time: 2.198491096496582
[1, 13108] loss_train: 0.006694, loss_test: 0.005667
time: 0.2430591583251953
time: 2.2104883193969727
[1, 13109] loss_train: 0.005043, loss_test: 0.005678
time: 0.24408411979675293
time: 2.2405009269714355
[1, 13110] loss_train: 0.006712, loss_test: 0.005677
time: 0.25705695152282715
time: 2.2615058422088623
[1, 13111] loss_train: 0.006909, loss_test: 0.005668
time: 0.24405407905578613
time: 2.2375004291534424
[1, 13112] loss_train: 0.006679, loss_test: 0.005656
time: 0.24305367469787598
time: 2.233510971069336
[1, 13113] loss_train: 0.004874, loss_test: 0.005644
time: 0.24505400657653809
time: 2.2234978675842285
[1, 13114] loss_train: 0.008794, loss_test: 0.005634
time: 0.24405384063720703
time: 2.2345123291015625
[1, 13115] loss_train: 0.002898, loss_test: 0.005627
time: 0.24305319786071777
time: 2.204505205154419
[1, 13116] loss_train: 0.002005, loss_test: 0.005619
time: 0.2470555305480957
time: 2.2124946117401123
[1, 13117] loss_train: 0.003436, loss_test: 0.005618
time: 0.24306654930114746
time: 2.2154741287231445
[1, 13118] loss_train: 0.003132, loss_test: 0.005623
time: 0.2450547218322754
time: 2.218496322631836
[1, 13119] loss_train: 0.006703, loss_test: 0.005632
time: 0.24406647682189941
time: 2.2385008335113525
[1, 13120] loss_train: 0.012066, loss_test: 0.005632
time: 0.2580718994140625
time: 2.239023208618164
[1, 13121] loss_train: 0.005230, loss_test: 0.005631
time: 0.24605417251586914
time: 2.1994924545288086
[1, 13122] loss_train: 0.011297, loss_test: 0.005624
time: 0.24805545806884766
time: 2.235053300857544
[1, 13123] loss_train: 0.007473, loss_test: 0.005619
time: 0.2470552921295166
time: 2.2345004081726074
[1, 13124] loss_train: 0.005341, loss_test: 0.005615
time: 0.24605441093444824
time: 2.243501901626587
[1, 13125] loss_train: 0.003145, loss_test: 0.005615
time: 0.24405455589294434
time: 2.2134945392608643
[1, 13126] loss_train: 0.005384, loss_test: 0.005616
time: 0.2470543384552002
time: 2.2405176162719727
[1, 13127] loss_train: 0.006444, loss_test: 0.005614
time: 0.24405479431152344
time: 2.221496343612671
[1, 13128] loss_train: 0.003745, loss_test: 0.005612
time: 0.2450549602508545
time: 2.2295162677764893
[1, 13129] loss_train: 0.001910, loss_test: 0.005612
time: 0.24405431747436523
time: 2.2545034885406494
[1, 13130] loss_train: 0.004021, loss_test: 0.005606
time: 0.2560575008392334
time: 2.245008945465088
[1, 13131] loss_train: 0.008459, loss_test: 0.005603
time: 0.24505400657653809
time: 2.236506700515747
[1, 13132] loss_train: 0.017297, loss_test: 0.005600
time: 0.24409866333007812
time: 2.1945087909698486
[1, 13133] loss_train: 0.003240, loss_test: 0.005599
time: 0.24805474281311035
time: 2.206494092941284
[1, 13134] loss_train: 0.006491, loss_test: 0.005598
time: 0.24405336380004883
time: 2.241187572479248
[1, 13135] loss_train: 0.012484, loss_test: 0.005589
time: 0.24307990074157715
time: 2.2134954929351807
[1, 13136] loss_train: 0.003324, loss_test: 0.005589
time: 0.24305319786071777
time: 2.2094943523406982
[1, 13137] loss_train: 0.012270, loss_test: 0.005591
time: 0.2450544834136963
time: 2.1984903812408447
[1, 13138] loss_train: 0.006325, loss_test: 0.005596
time: 0.2450554370880127
time: 2.2470059394836426
[1, 13139] loss_train: 0.003045, loss_test: 0.005600
time: 0.2470555305480957
time: 2.231498956680298
[1, 13140] loss_train: 0.007315, loss_test: 0.005605
time: 0.2580571174621582
time: 2.2795119285583496
[1, 13141] loss_train: 0.010183, loss_test: 0.005607
time: 0.24907231330871582
time: 2.196490526199341
[1, 13142] loss_train: 0.002918, loss_test: 0.005612
time: 0.2450549602508545
time: 2.2324981689453125
[1, 13143] loss_train: 0.002165, loss_test: 0.005612
time: 0.25005531311035156
time: 2.2395012378692627
[1, 13144] loss_train: 0.004722, loss_test: 0.005611
time: 0.24505400657653809
time: 2.1990315914154053
[1, 13145] loss_train: 0.004507, loss_test: 0.005610
time: 0.2450544834136963
time: 2.1904895305633545
[1, 13146] loss_train: 0.005200, loss_test: 0.005611
time: 0.24405407905578613
time: 2.231498956680298
[1, 13147] loss_train: 0.003544, loss_test: 0.005611
time: 0.24605464935302734
time: 2.213494300842285
[1, 13148] loss_train: 0.004912, loss_test: 0.005614
time: 0.24305295944213867
time: 2.218496561050415
[1, 13149] loss_train: 0.013724, loss_test: 0.005615
time: 0.2450544834136963
time: 2.240513563156128
[1, 13150] loss_train: 0.005827, loss_test: 0.005614
time: 0.25705742835998535
time: 2.2435038089752197
[1, 13151] loss_train: 0.006455, loss_test: 0.005609
time: 0.24405932426452637
time: 2.2134954929351807
[1, 13152] loss_train: 0.006132, loss_test: 0.005607
time: 0.24305343627929688
time: 2.242501735687256
[1, 13153] loss_train: 0.009411, loss_test: 0.005603
time: 0.24305319786071777
time: 2.245502471923828
[1, 13154] loss_train: 0.009863, loss_test: 0.005607
time: 0.24505376815795898
time: 2.2285079956054688
[1, 13155] loss_train: 0.009097, loss_test: 0.005620
time: 0.24405455589294434
time: 2.2124953269958496
[1, 13156] loss_train: 0.005097, loss_test: 0.005635
time: 0.24405384063720703
time: 2.2134954929351807
[1, 13157] loss_train: 0.005160, loss_test: 0.005644
time: 0.24605512619018555
time: 2.2105112075805664
[1, 13158] loss_train: 0.001376, loss_test: 0.005640
time: 0.25005459785461426
time: 2.226048231124878
[1, 13159] loss_train: 0.001796, loss_test: 0.005625
time: 0.24605417251586914
time: 2.2104947566986084
[1, 13160] loss_train: 0.001714, loss_test: 0.005615
time: 0.2580575942993164
time: 2.296513557434082
[1, 13161] loss_train: 0.005108, loss_test: 0.005607
time: 0.25005650520324707
time: 2.232499361038208
[1, 13162] loss_train: 0.003826, loss_test: 0.005604
time: 0.24805426597595215
time: 2.289512872695923
[1, 13163] loss_train: 0.010110, loss_test: 0.005607
time: 0.24505352973937988
time: 2.236509084701538
[1, 13164] loss_train: 0.007739, loss_test: 0.005605
time: 0.24906134605407715
time: 2.220496416091919
[1, 13165] loss_train: 0.001726, loss_test: 0.005603
time: 0.24305438995361328
time: 2.2555043697357178
[1, 13166] loss_train: 0.006952, loss_test: 0.005602
time: 0.24805450439453125
time: 2.237004280090332
[1, 13167] loss_train: 0.000695, loss_test: 0.005604
time: 0.24505400657653809
time: 2.233502149581909
[1, 13168] loss_train: 0.002971, loss_test: 0.005610
time: 0.2470543384552002
time: 2.205498456954956
[1, 13169] loss_train: 0.011656, loss_test: 0.005609
time: 0.24605441093444824
time: 2.2134954929351807
[1, 13170] loss_train: 0.007280, loss_test: 0.005605
time: 0.2580699920654297
time: 2.2385005950927734
[1, 13171] loss_train: 0.004877, loss_test: 0.005600
time: 0.24405360221862793
time: 2.2335000038146973
[1, 13172] loss_train: 0.008630, loss_test: 0.005594
time: 0.24605512619018555
time: 2.233502149581909
[1, 13173] loss_train: 0.009995, loss_test: 0.005588
time: 0.24405360221862793
time: 2.218498706817627
[1, 13174] loss_train: 0.007047, loss_test: 0.005586
time: 0.2450549602508545
time: 2.2164950370788574
[1, 13175] loss_train: 0.004601, loss_test: 0.005585
time: 0.24406743049621582
time: 2.2495033740997314
[1, 13176] loss_train: 0.005479, loss_test: 0.005585
time: 0.24405407905578613
time: 2.2150087356567383
[1, 13177] loss_train: 0.004498, loss_test: 0.005586
time: 0.24805474281311035
time: 2.1874895095825195
[1, 13178] loss_train: 0.003400, loss_test: 0.005586
time: 0.2450723648071289
time: 2.191499710083008
[1, 13179] loss_train: 0.007654, loss_test: 0.005586
time: 0.2460472583770752
time: 2.220496892929077
[1, 13180] loss_train: 0.003525, loss_test: 0.005586
time: 0.2580578327178955
time: 2.262505531311035
[1, 13181] loss_train: 0.008682, loss_test: 0.005590
time: 0.25005507469177246
time: 2.205493927001953
[1, 13182] loss_train: 0.004255, loss_test: 0.005596
time: 0.24505376815795898
time: 2.246516466140747
[1, 13183] loss_train: 0.009230, loss_test: 0.005601
time: 0.25306177139282227
time: 2.2390058040618896
[1, 13184] loss_train: 0.003016, loss_test: 0.005606
time: 0.24805545806884766
time: 2.23349928855896
[1, 13185] loss_train: 0.007397, loss_test: 0.005612
time: 0.24806952476501465
time: 2.232511520385742
[1, 13186] loss_train: 0.005440, loss_test: 0.005612
time: 0.24405384063720703
time: 2.217496156692505
[1, 13187] loss_train: 0.000697, loss_test: 0.005616
time: 0.2470552921295166
time: 2.2485060691833496
[1, 13188] loss_train: 0.006999, loss_test: 0.005615
time: 0.24405384063720703
time: 2.217496395111084
[1, 13189] loss_train: 0.006873, loss_test: 0.005613
time: 0.24205327033996582
time: 2.2084944248199463
[1, 13190] loss_train: 0.013231, loss_test: 0.005598
time: 0.2560572624206543
time: 2.2645058631896973
[1, 13191] loss_train: 0.002323, loss_test: 0.005590
time: 0.24605464935302734
time: 2.2234976291656494
[1, 13192] loss_train: 0.004360, loss_test: 0.005583
time: 0.24305367469787598
time: 2.2124969959259033
[1, 13193] loss_train: 0.000520, loss_test: 0.005580
time: 0.24405455589294434
time: 2.1974916458129883
[1, 13194] loss_train: 0.005225, loss_test: 0.005578
time: 0.24405384063720703
time: 2.2180094718933105
[1, 13195] loss_train: 0.007705, loss_test: 0.005577
time: 0.24606776237487793
time: 2.218496561050415
[1, 13196] loss_train: 0.006687, loss_test: 0.005578
time: 0.2440958023071289
time: 2.218496084213257
[1, 13197] loss_train: 0.007486, loss_test: 0.005579
time: 0.24405384063720703
time: 2.2104945182800293
[1, 13198] loss_train: 0.007770, loss_test: 0.005586
time: 0.2470557689666748
time: 2.23249888420105
[1, 13199] loss_train: 0.006675, loss_test: 0.005594
time: 0.24405384063720703
time: 2.221656322479248
[1, 13200] loss_train: 0.008582, loss_test: 0.005602
time: 0.2630586624145508
time: 2.2635059356689453
[1, 13201] loss_train: 0.005280, loss_test: 0.005603
time: 0.2490549087524414
time: 2.218496561050415
[1, 13202] loss_train: 0.006438, loss_test: 0.005599
time: 0.25005507469177246
time: 2.230499029159546
[1, 13203] loss_train: 0.010410, loss_test: 0.005593
time: 0.24405503273010254
time: 2.204998016357422
[1, 13204] loss_train: 0.004043, loss_test: 0.005585
time: 0.2470545768737793
time: 2.202493190765381
[1, 13205] loss_train: 0.002811, loss_test: 0.005577
time: 0.24406647682189941
time: 2.186023712158203
[1, 13206] loss_train: 0.008213, loss_test: 0.005574
time: 0.2450547218322754
time: 2.2284982204437256
[1, 13207] loss_train: 0.003614, loss_test: 0.005576
time: 0.24306654930114746
time: 2.2180168628692627
[1, 13208] loss_train: 0.012187, loss_test: 0.005579
time: 0.24405384063720703
time: 2.2345001697540283
[1, 13209] loss_train: 0.005796, loss_test: 0.005583
time: 0.24605464935302734
time: 2.2365000247955322
[1, 13210] loss_train: 0.009607, loss_test: 0.005587
time: 0.2560570240020752
time: 2.2605056762695312
[1, 13211] loss_train: 0.010136, loss_test: 0.005585
time: 0.24305415153503418
time: 2.206493377685547
[1, 13212] loss_train: 0.003522, loss_test: 0.005580
time: 0.2450544834136963
time: 2.245502233505249
[1, 13213] loss_train: 0.008822, loss_test: 0.005578
time: 0.24405431747436523
time: 2.254504442214966
[1, 13214] loss_train: 0.006952, loss_test: 0.005576
time: 0.24305510520935059
time: 2.250007390975952
[1, 13215] loss_train: 0.009017, loss_test: 0.005573
time: 0.24405407905578613
time: 2.2355003356933594
[1, 13216] loss_train: 0.002867, loss_test: 0.005573
time: 0.24405407905578613
time: 2.2154958248138428
[1, 13217] loss_train: 0.004166, loss_test: 0.005576
time: 0.24505400657653809
time: 2.2265002727508545
[1, 13218] loss_train: 0.012685, loss_test: 0.005581
time: 0.2490553855895996
time: 2.222499370574951
[1, 13219] loss_train: 0.003644, loss_test: 0.005587
time: 0.2450549602508545
time: 2.212512254714966
[1, 13220] loss_train: 0.004955, loss_test: 0.005587
time: 0.25705742835998535
time: 2.2375004291534424
[1, 13221] loss_train: 0.011167, loss_test: 0.005588
time: 0.25905799865722656
time: 2.225499391555786
[1, 13222] loss_train: 0.012986, loss_test: 0.005586
time: 0.24405479431152344
time: 2.2415008544921875
[1, 13223] loss_train: 0.005193, loss_test: 0.005584
time: 0.24405455589294434
time: 2.2405025959014893
[1, 13224] loss_train: 0.003352, loss_test: 0.005581
time: 0.24505400657653809
time: 2.2244980335235596
[1, 13225] loss_train: 0.010253, loss_test: 0.005584
time: 0.2470550537109375
time: 2.2545034885406494
[1, 13226] loss_train: 0.007144, loss_test: 0.005586
time: 0.24405431747436523
time: 2.217998743057251
[1, 13227] loss_train: 0.006836, loss_test: 0.005587
time: 0.2450563907623291
time: 2.219040632247925
[1, 13228] loss_train: 0.004937, loss_test: 0.005588
time: 0.2470543384552002
time: 2.204761505126953
[1, 13229] loss_train: 0.004531, loss_test: 0.005588
time: 0.24405360221862793
time: 2.2284979820251465
[1, 13230] loss_train: 0.004059, loss_test: 0.005587
time: 0.256056547164917
time: 2.240509510040283
[1, 13231] loss_train: 0.010529, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2395009994506836
[1, 13232] loss_train: 0.006792, loss_test: 0.005590
time: 0.24405455589294434
time: 2.222496509552002
[1, 13233] loss_train: 0.002777, loss_test: 0.005589
time: 0.24305510520935059
time: 2.2405006885528564
[1, 13234] loss_train: 0.006906, loss_test: 0.005591
time: 0.24508118629455566
time: 2.2505033016204834
[1, 13235] loss_train: 0.007830, loss_test: 0.005596
time: 0.24805498123168945
time: 2.206495523452759
[1, 13236] loss_train: 0.007392, loss_test: 0.005603
time: 0.2450542449951172
time: 2.1985080242156982
[1, 13237] loss_train: 0.003535, loss_test: 0.005610
time: 0.24505376815795898
time: 2.199510097503662
[1, 13238] loss_train: 0.013341, loss_test: 0.005612
time: 0.24505352973937988
time: 2.227423667907715
[1, 13239] loss_train: 0.002290, loss_test: 0.005612
time: 0.24505376815795898
time: 2.2275338172912598
[1, 13240] loss_train: 0.002564, loss_test: 0.005611
time: 0.26105761528015137
time: 2.279510259628296
[1, 13241] loss_train: 0.007832, loss_test: 0.005609
time: 0.25005531311035156
time: 2.195491313934326
[1, 13242] loss_train: 0.004082, loss_test: 0.005607
time: 0.2511157989501953
time: 2.20849609375
[1, 13243] loss_train: 0.008908, loss_test: 0.005605
time: 0.2450542449951172
time: 2.2325022220611572
[1, 13244] loss_train: 0.003908, loss_test: 0.005604
time: 0.2470545768737793
time: 2.228498697280884
[1, 13245] loss_train: 0.009130, loss_test: 0.005607
time: 0.2470550537109375
time: 2.2165188789367676
[1, 13246] loss_train: 0.009312, loss_test: 0.005609
time: 0.24405431747436523
time: 2.234498977661133
[1, 13247] loss_train: 0.009369, loss_test: 0.005610
time: 0.24360203742980957
time: 2.2545034885406494
[1, 13248] loss_train: 0.005146, loss_test: 0.005613
time: 0.2450547218322754
time: 2.2275516986846924
[1, 13249] loss_train: 0.004235, loss_test: 0.005615
time: 0.2450547218322754
time: 2.2415034770965576
[1, 13250] loss_train: 0.002379, loss_test: 0.005618
time: 0.2560567855834961
time: 2.238511323928833
[1, 13251] loss_train: 0.008938, loss_test: 0.005616
time: 0.24305319786071777
time: 2.196491003036499
[1, 13252] loss_train: 0.003660, loss_test: 0.005612
time: 0.24805498123168945
time: 2.23342227935791
[1, 13253] loss_train: 0.009359, loss_test: 0.005608
time: 0.24309921264648438
time: 2.2174956798553467
[1, 13254] loss_train: 0.005033, loss_test: 0.005605
time: 0.24509048461914062
time: 2.2535037994384766
[1, 13255] loss_train: 0.005064, loss_test: 0.005602
time: 0.24305367469787598
time: 2.2024953365325928
[1, 13256] loss_train: 0.009260, loss_test: 0.005596
time: 0.2470548152923584
time: 2.2054929733276367
[1, 13257] loss_train: 0.004616, loss_test: 0.005591
time: 0.24505400657653809
time: 2.217496395111084
[1, 13258] loss_train: 0.007688, loss_test: 0.005589
time: 0.2450547218322754
time: 2.2014918327331543
[1, 13259] loss_train: 0.006432, loss_test: 0.005594
time: 0.2540569305419922
time: 2.2235145568847656
[1, 13260] loss_train: 0.013253, loss_test: 0.005608
time: 0.2580568790435791
time: 2.241501808166504
[1, 13261] loss_train: 0.005865, loss_test: 0.005627
time: 0.2490558624267578
time: 2.2395002841949463
[1, 13262] loss_train: 0.008325, loss_test: 0.005648
time: 0.24405455589294434
time: 2.2154951095581055
[1, 13263] loss_train: 0.005904, loss_test: 0.005662
time: 0.2470545768737793
time: 2.204493522644043
[1, 13264] loss_train: 0.008306, loss_test: 0.005665
time: 0.2450547218322754
time: 2.223497152328491
[1, 13265] loss_train: 0.008940, loss_test: 0.005662
time: 0.24405407905578613
time: 2.2495036125183105
[1, 13266] loss_train: 0.003871, loss_test: 0.005641
time: 0.2450542449951172
time: 2.2354233264923096
[1, 13267] loss_train: 0.010064, loss_test: 0.005625
time: 0.24305438995361328
time: 2.195777654647827
[1, 13268] loss_train: 0.003957, loss_test: 0.005611
time: 0.24405384063720703
time: 2.2255167961120605
[1, 13269] loss_train: 0.011393, loss_test: 0.005601
time: 0.24305319786071777
time: 2.2405014038085938
[1, 13270] loss_train: 0.002692, loss_test: 0.005593
time: 0.2560577392578125
time: 2.253514289855957
[1, 13271] loss_train: 0.005116, loss_test: 0.005594
time: 0.25305628776550293
time: 2.2495028972625732
[1, 13272] loss_train: 0.003493, loss_test: 0.005598
time: 0.2400527000427246
time: 2.2594306468963623
[1, 13273] loss_train: 0.004616, loss_test: 0.005606
time: 0.2450549602508545
time: 2.2334988117218018
[1, 13274] loss_train: 0.003432, loss_test: 0.005617
time: 0.2450568675994873
time: 2.249502658843994
[1, 13275] loss_train: 0.003760, loss_test: 0.005629
time: 0.24405407905578613
time: 2.2134974002838135
[1, 13276] loss_train: 0.010847, loss_test: 0.005638
time: 0.2470722198486328
time: 2.207494020462036
[1, 13277] loss_train: 0.009344, loss_test: 0.005642
time: 0.24405336380004883
time: 2.2312657833099365
[1, 13278] loss_train: 0.003025, loss_test: 0.005647
time: 0.24505376815795898
time: 2.230004072189331
[1, 13279] loss_train: 0.015403, loss_test: 0.005640
time: 0.24605417251586914
time: 2.2064943313598633
[1, 13280] loss_train: 0.002167, loss_test: 0.005635
time: 0.2620584964752197
time: 2.237499952316284
[1, 13281] loss_train: 0.005460, loss_test: 0.005626
time: 0.24506902694702148
time: 2.2445013523101807
[1, 13282] loss_train: 0.007267, loss_test: 0.005619
time: 0.2520561218261719
time: 2.2895114421844482
[1, 13283] loss_train: 0.006338, loss_test: 0.005607
time: 0.24505329132080078
time: 2.25429630279541
[1, 13284] loss_train: 0.004673, loss_test: 0.005597
time: 0.24505400657653809
time: 2.218500852584839
[1, 13285] loss_train: 0.009972, loss_test: 0.005591
time: 0.24605488777160645
time: 2.23349928855896
[1, 13286] loss_train: 0.005229, loss_test: 0.005589
time: 0.24805450439453125
time: 2.245502233505249
[1, 13287] loss_train: 0.008455, loss_test: 0.005590
time: 0.2450544834136963
time: 2.207425594329834
[1, 13288] loss_train: 0.004316, loss_test: 0.005593
time: 0.24805474281311035
time: 2.2355024814605713
[1, 13289] loss_train: 0.002797, loss_test: 0.005594
time: 0.24805474281311035
time: 2.2120168209075928
[1, 13290] loss_train: 0.006095, loss_test: 0.005594
time: 0.2580571174621582
time: 2.245502471923828
[1, 13291] loss_train: 0.009635, loss_test: 0.005598
time: 0.2470552921295166
time: 2.220517635345459
[1, 13292] loss_train: 0.002499, loss_test: 0.005600
time: 0.24605441093444824
time: 2.2425050735473633
[1, 13293] loss_train: 0.006315, loss_test: 0.005600
time: 0.2430741786956787
time: 2.2385008335113525
[1, 13294] loss_train: 0.010240, loss_test: 0.005601
time: 0.2450547218322754
time: 2.195491075515747
[1, 13295] loss_train: 0.006554, loss_test: 0.005601
time: 0.2450544834136963
time: 2.2304980754852295
[1, 13296] loss_train: 0.012702, loss_test: 0.005610
time: 0.2430553436279297
time: 2.260505199432373
[1, 13297] loss_train: 0.007667, loss_test: 0.005617
time: 0.24405384063720703
time: 2.221508741378784
[1, 13298] loss_train: 0.013456, loss_test: 0.005634
time: 0.24405431747436523
time: 2.220305919647217
[1, 13299] loss_train: 0.005446, loss_test: 0.005643
time: 0.2470543384552002
time: 2.2420060634613037
[1, 13300] loss_train: 0.006085, loss_test: 0.005633
time: 0.25705718994140625
time: 2.229001522064209
[1, 13301] loss_train: 0.005200, loss_test: 0.005617
time: 0.2450542449951172
time: 2.2124953269958496
[1, 13302] loss_train: 0.006471, loss_test: 0.005603
time: 0.24405384063720703
time: 2.181488275527954
[1, 13303] loss_train: 0.008956, loss_test: 0.005593
time: 0.24405431747436523
time: 2.2154958248138428
[1, 13304] loss_train: 0.010879, loss_test: 0.005590
time: 0.2450544834136963
time: 2.1884894371032715
[1, 13305] loss_train: 0.004322, loss_test: 0.005589
time: 0.2470541000366211
time: 2.231534481048584
[1, 13306] loss_train: 0.007538, loss_test: 0.005594
time: 0.24605464935302734
time: 2.2395005226135254
[1, 13307] loss_train: 0.003701, loss_test: 0.005604
time: 0.24606776237487793
time: 2.2765088081359863
[1, 13308] loss_train: 0.011201, loss_test: 0.005610
time: 0.24305367469787598
time: 2.2274978160858154
[1, 13309] loss_train: 0.002393, loss_test: 0.005621
time: 0.2490553855895996
time: 2.254520893096924
[1, 13310] loss_train: 0.007069, loss_test: 0.005636
time: 0.25705790519714355
time: 2.271507978439331
[1, 13311] loss_train: 0.001768, loss_test: 0.005649
time: 0.2490558624267578
time: 2.234498977661133
[1, 13312] loss_train: 0.009476, loss_test: 0.005662
time: 0.24305438995361328
time: 2.209494113922119
[1, 13313] loss_train: 0.006153, loss_test: 0.005659
time: 0.24307942390441895
time: 2.213494062423706
[1, 13314] loss_train: 0.002896, loss_test: 0.005651
time: 0.24305462837219238
time: 2.2134947776794434
[1, 13315] loss_train: 0.012921, loss_test: 0.005635
time: 0.24405384063720703
time: 2.219517469406128
[1, 13316] loss_train: 0.006608, loss_test: 0.005621
time: 0.2470545768737793
time: 2.219496726989746
[1, 13317] loss_train: 0.009181, loss_test: 0.005610
time: 0.24405431747436523
time: 2.234018325805664
[1, 13318] loss_train: 0.010258, loss_test: 0.005603
time: 0.24455904960632324
time: 2.245502233505249
[1, 13319] loss_train: 0.008156, loss_test: 0.005597
time: 0.2450544834136963
time: 2.2520270347595215
[1, 13320] loss_train: 0.004847, loss_test: 0.005597
time: 0.25705909729003906
time: 2.295513391494751
[1, 13321] loss_train: 0.004209, loss_test: 0.005597
time: 0.24305343627929688
time: 2.21700119972229
[1, 13322] loss_train: 0.001746, loss_test: 0.005597
time: 0.24405431747436523
time: 2.241501569747925
[1, 13323] loss_train: 0.005599, loss_test: 0.005599
time: 0.24606704711914062
time: 2.1984915733337402
[1, 13324] loss_train: 0.000940, loss_test: 0.005601
time: 0.24405431747436523
time: 2.2174956798553467
[1, 13325] loss_train: 0.008553, loss_test: 0.005608
time: 0.24505400657653809
time: 2.2375006675720215
[1, 13326] loss_train: 0.000894, loss_test: 0.005623
time: 0.2470543384552002
time: 2.2355003356933594
[1, 13327] loss_train: 0.005590, loss_test: 0.005644
time: 0.2450547218322754
time: 2.1984918117523193
[1, 13328] loss_train: 0.004459, loss_test: 0.005666
time: 0.24935030937194824
time: 2.2495055198669434
[1, 13329] loss_train: 0.002406, loss_test: 0.005685
time: 0.2450544834136963
time: 2.2405288219451904
[1, 13330] loss_train: 0.009573, loss_test: 0.005678
time: 0.26105761528015137
time: 2.260509967803955
[1, 13331] loss_train: 0.013266, loss_test: 0.005667
time: 0.24605417251586914
time: 2.232499599456787
[1, 13332] loss_train: 0.002103, loss_test: 0.005651
time: 0.24905610084533691
time: 2.230293035507202
[1, 13333] loss_train: 0.017210, loss_test: 0.005627
time: 0.2450544834136963
time: 2.232499122619629
[1, 13334] loss_train: 0.007839, loss_test: 0.005612
time: 0.24805521965026855
time: 2.2284982204437256
[1, 13335] loss_train: 0.004910, loss_test: 0.005602
time: 0.24605488777160645
time: 2.218496084213257
[1, 13336] loss_train: 0.012147, loss_test: 0.005598
time: 0.2510550022125244
time: 2.236224412918091
[1, 13337] loss_train: 0.002857, loss_test: 0.005598
time: 0.24305367469787598
time: 2.228498935699463
[1, 13338] loss_train: 0.007956, loss_test: 0.005599
time: 0.2520565986633301
time: 2.212515115737915
[1, 13339] loss_train: 0.009547, loss_test: 0.005606
time: 0.24305367469787598
time: 2.1995043754577637
[1, 13340] loss_train: 0.013757, loss_test: 0.005613
time: 0.2550535202026367
time: 2.2665088176727295
[1, 13341] loss_train: 0.009001, loss_test: 0.005627
time: 0.24505400657653809
time: 2.2114949226379395
[1, 13342] loss_train: 0.009316, loss_test: 0.005639
time: 0.24205374717712402
time: 2.219510555267334
[1, 13343] loss_train: 0.002568, loss_test: 0.005638
time: 0.24706745147705078
time: 2.2355003356933594
[1, 13344] loss_train: 0.004576, loss_test: 0.005634
time: 0.24405336380004883
time: 2.2545053958892822
[1, 13345] loss_train: 0.005081, loss_test: 0.005635
time: 0.24405384063720703
time: 2.2525036334991455
[1, 13346] loss_train: 0.006710, loss_test: 0.005618
time: 0.2450544834136963
time: 2.2415013313293457
[1, 13347] loss_train: 0.001982, loss_test: 0.005603
time: 0.24405360221862793
time: 2.2114946842193604
[1, 13348] loss_train: 0.002961, loss_test: 0.005591
time: 0.24305367469787598
time: 2.210029125213623
[1, 13349] loss_train: 0.010462, loss_test: 0.005587
time: 0.24605464935302734
time: 2.219472885131836
[1, 13350] loss_train: 0.001057, loss_test: 0.005590
time: 0.2580575942993164
time: 2.230759620666504
[1, 13351] loss_train: 0.009975, loss_test: 0.005599
time: 0.24806523323059082
time: 2.218496084213257
[1, 13352] loss_train: 0.007082, loss_test: 0.005601
time: 0.2450542449951172
time: 2.2205147743225098
[1, 13353] loss_train: 0.015151, loss_test: 0.005600
time: 0.2510557174682617
time: 2.218499183654785
[1, 13354] loss_train: 0.003087, loss_test: 0.005596
time: 0.24305367469787598
time: 2.2134950160980225
[1, 13355] loss_train: 0.009753, loss_test: 0.005585
time: 0.24505901336669922
time: 2.2365007400512695
[1, 13356] loss_train: 0.004686, loss_test: 0.005580
time: 0.24405360221862793
time: 2.229501724243164
[1, 13357] loss_train: 0.002463, loss_test: 0.005576
time: 0.24405384063720703
time: 2.229498863220215
[1, 13358] loss_train: 0.007137, loss_test: 0.005573
time: 0.24405455589294434
time: 2.21551775932312
[1, 13359] loss_train: 0.001818, loss_test: 0.005570
time: 0.24605417251586914
time: 2.2114968299865723
[1, 13360] loss_train: 0.004313, loss_test: 0.005570
time: 0.25707030296325684
time: 2.2570600509643555
[1, 13361] loss_train: 0.002033, loss_test: 0.005570
time: 0.24505376815795898
time: 2.2134957313537598
[1, 13362] loss_train: 0.007492, loss_test: 0.005571
time: 0.24405407905578613
time: 2.245501756668091
[1, 13363] loss_train: 0.006082, loss_test: 0.005573
time: 0.2470545768737793
time: 2.188490152359009
[1, 13364] loss_train: 0.005722, loss_test: 0.005574
time: 0.24405384063720703
time: 2.189384937286377
[1, 13365] loss_train: 0.007391, loss_test: 0.005576
time: 0.24605417251586914
time: 2.2224972248077393
[1, 13366] loss_train: 0.007262, loss_test: 0.005578
time: 0.2450549602508545
time: 2.234412670135498
[1, 13367] loss_train: 0.001836, loss_test: 0.005580
time: 0.24805521965026855
time: 2.2365000247955322
[1, 13368] loss_train: 0.010019, loss_test: 0.005584
time: 0.24805545806884766
time: 2.2311432361602783
[1, 13369] loss_train: 0.011338, loss_test: 0.005588
time: 0.24605393409729004
time: 2.230499505996704
[1, 13370] loss_train: 0.001401, loss_test: 0.005592
time: 0.2620577812194824
time: 2.2625067234039307
[1, 13371] loss_train: 0.006480, loss_test: 0.005596
time: 0.24605512619018555
time: 2.2154948711395264
[1, 13372] loss_train: 0.000489, loss_test: 0.005601
time: 0.2470569610595703
time: 2.218496322631836
[1, 13373] loss_train: 0.001926, loss_test: 0.005603
time: 0.24405884742736816
time: 2.2014925479888916
[1, 13374] loss_train: 0.003756, loss_test: 0.005607
time: 0.24811601638793945
time: 2.2265138626098633
[1, 13375] loss_train: 0.002961, loss_test: 0.005611
time: 0.24405407905578613
time: 2.2114949226379395
[1, 13376] loss_train: 0.003111, loss_test: 0.005616
time: 0.24305343627929688
time: 2.213498592376709
[1, 13377] loss_train: 0.022271, loss_test: 0.005628
time: 0.2490544319152832
time: 2.2515037059783936
[1, 13378] loss_train: 0.008407, loss_test: 0.005645
time: 0.2450544834136963
time: 2.244502305984497
[1, 13379] loss_train: 0.001376, loss_test: 0.005669
time: 0.2450547218322754
time: 2.248502731323242
[1, 13380] loss_train: 0.005224, loss_test: 0.005693
time: 0.25505685806274414
time: 2.280012845993042
[1, 13381] loss_train: 0.012953, loss_test: 0.005692
time: 0.24506688117980957
time: 2.2485053539276123
[1, 13382] loss_train: 0.006637, loss_test: 0.005683
time: 0.24405288696289062
time: 2.240501642227173
[1, 13383] loss_train: 0.010892, loss_test: 0.005664
time: 0.24305415153503418
time: 2.3020288944244385
[1, 13384] loss_train: 0.005697, loss_test: 0.005644
time: 0.265059232711792
time: 2.3125174045562744
[1, 13385] loss_train: 0.011142, loss_test: 0.005627
time: 0.24406766891479492
time: 2.225003242492676
[1, 13386] loss_train: 0.004822, loss_test: 0.005612
time: 0.24205446243286133
time: 2.2265005111694336
[1, 13387] loss_train: 0.012227, loss_test: 0.005609
time: 0.2470552921295166
time: 2.212496757507324
[1, 13388] loss_train: 0.009742, loss_test: 0.005611
time: 0.24405384063720703
time: 2.2455034255981445
[1, 13389] loss_train: 0.006828, loss_test: 0.005620
time: 0.24305415153503418
time: 2.230499505996704
[1, 13390] loss_train: 0.006758, loss_test: 0.005628
time: 0.25505638122558594
time: 2.247502565383911
[1, 13391] loss_train: 0.010200, loss_test: 0.005635
time: 0.2470555305480957
time: 2.245501756668091
[1, 13392] loss_train: 0.008280, loss_test: 0.005637
time: 0.24405360221862793
time: 2.2485034465789795
[1, 13393] loss_train: 0.002159, loss_test: 0.005627
time: 0.24405455589294434
time: 2.234502077102661
[1, 13394] loss_train: 0.006969, loss_test: 0.005615
time: 0.2450547218322754
time: 2.2515032291412354
[1, 13395] loss_train: 0.015256, loss_test: 0.005608
time: 0.24405384063720703
time: 2.232499599456787
[1, 13396] loss_train: 0.006923, loss_test: 0.005601
time: 0.24405384063720703
time: 2.2395248413085938
[1, 13397] loss_train: 0.001437, loss_test: 0.005597
time: 0.24706745147705078
time: 2.2162816524505615
[1, 13398] loss_train: 0.006269, loss_test: 0.005596
time: 0.24306678771972656
time: 2.219496726989746
[1, 13399] loss_train: 0.006902, loss_test: 0.005599
time: 0.24405384063720703
time: 2.206493854522705
[1, 13400] loss_train: 0.005222, loss_test: 0.005602
time: 0.2580573558807373
time: 2.2345004081726074
[1, 13401] loss_train: 0.008076, loss_test: 0.005604
time: 0.2510561943054199
time: 2.221496343612671
[1, 13402] loss_train: 0.011367, loss_test: 0.005606
time: 0.2440662384033203
time: 2.2284998893737793
[1, 13403] loss_train: 0.000781, loss_test: 0.005610
time: 0.2520565986633301
time: 2.2315077781677246
[1, 13404] loss_train: 0.001883, loss_test: 0.005611
time: 0.2470557689666748
time: 2.2164955139160156
[1, 13405] loss_train: 0.007603, loss_test: 0.005608
time: 0.24805474281311035
time: 2.2535042762756348
[1, 13406] loss_train: 0.003382, loss_test: 0.005607
time: 0.2450549602508545
time: 2.2415008544921875
[1, 13407] loss_train: 0.010468, loss_test: 0.005605
time: 0.2490551471710205
time: 2.2154951095581055
[1, 13408] loss_train: 0.001048, loss_test: 0.005605
time: 0.2450542449951172
time: 2.206496000289917
[1, 13409] loss_train: 0.006294, loss_test: 0.005603
time: 0.2440659999847412
time: 2.215498447418213
[1, 13410] loss_train: 0.004137, loss_test: 0.005601
time: 0.2550690174102783
time: 2.2665069103240967
[1, 13411] loss_train: 0.003332, loss_test: 0.005602
time: 0.2450542449951172
time: 2.1900134086608887
[1, 13412] loss_train: 0.009124, loss_test: 0.005597
time: 0.24605488777160645
time: 2.2124946117401123
[1, 13413] loss_train: 0.002502, loss_test: 0.005596
time: 0.2450542449951172
time: 2.2254984378814697
[1, 13414] loss_train: 0.004999, loss_test: 0.005598
time: 0.24405407905578613
time: 2.2505178451538086
[1, 13415] loss_train: 0.003831, loss_test: 0.005602
time: 0.24306607246398926
time: 2.2284982204437256
[1, 13416] loss_train: 0.011043, loss_test: 0.005601
time: 0.2450549602508545
time: 2.1894893646240234
[1, 13417] loss_train: 0.003542, loss_test: 0.005603
time: 0.24405455589294434
time: 2.2199981212615967
[1, 13418] loss_train: 0.007155, loss_test: 0.005600
time: 0.24605560302734375
time: 2.237515449523926
[1, 13419] loss_train: 0.013746, loss_test: 0.005581
time: 0.24405431747436523
time: 2.219515800476074
[1, 13420] loss_train: 0.000921, loss_test: 0.005577
time: 0.2600834369659424
time: 2.261017084121704
[1, 13421] loss_train: 0.004615, loss_test: 0.005583
time: 0.24706792831420898
time: 2.2114949226379395
[1, 13422] loss_train: 0.007395, loss_test: 0.005600
time: 0.2490551471710205
time: 2.219496250152588
[1, 13423] loss_train: 0.008359, loss_test: 0.005637
time: 0.24305438995361328
time: 2.2134947776794434
[1, 13424] loss_train: 0.000878, loss_test: 0.005687
time: 0.26105761528015137
time: 2.2350032329559326
[1, 13425] loss_train: 0.008657, loss_test: 0.005720
time: 0.24405407905578613
time: 2.220518112182617
[1, 13426] loss_train: 0.001592, loss_test: 0.005729
time: 0.24305486679077148
time: 2.253512144088745
[1, 13427] loss_train: 0.010535, loss_test: 0.005721
time: 0.24205422401428223
time: 2.224030017852783
[1, 13428] loss_train: 0.006582, loss_test: 0.005695
time: 0.2450542449951172
time: 2.2224972248077393
[1, 13429] loss_train: 0.003354, loss_test: 0.005657
time: 0.24306774139404297
time: 2.2314987182617188
[1, 13430] loss_train: 0.013991, loss_test: 0.005625
time: 0.2570664882659912
time: 2.272507905960083
[1, 13431] loss_train: 0.006903, loss_test: 0.005601
time: 0.2470552921295166
time: 2.2385001182556152
[1, 13432] loss_train: 0.004374, loss_test: 0.005585
time: 0.24405479431152344
time: 2.2024922370910645
[1, 13433] loss_train: 0.010281, loss_test: 0.005592
time: 0.24405431747436523
time: 2.2244973182678223
[1, 13434] loss_train: 0.009344, loss_test: 0.005611
time: 0.24405503273010254
time: 2.2234976291656494
[1, 13435] loss_train: 0.001937, loss_test: 0.005645
time: 0.24605417251586914
time: 2.2054941654205322
[1, 13436] loss_train: 0.002670, loss_test: 0.005688
time: 0.24405479431152344
time: 2.204501152038574
[1, 13437] loss_train: 0.007496, loss_test: 0.005714
time: 0.24405336380004883
time: 2.1865057945251465
[1, 13438] loss_train: 0.005954, loss_test: 0.005709
time: 0.24605393409729004
time: 2.2234976291656494
[1, 13439] loss_train: 0.001062, loss_test: 0.005707
time: 0.24805474281311035
time: 2.2355000972747803
[1, 13440] loss_train: 0.002764, loss_test: 0.005699
time: 0.2560567855834961
time: 2.276012897491455
[1, 13441] loss_train: 0.003572, loss_test: 0.005694
time: 0.25005626678466797
time: 2.245501756668091
[1, 13442] loss_train: 0.004330, loss_test: 0.005689
time: 0.24605441093444824
time: 2.218496799468994
[1, 13443] loss_train: 0.003431, loss_test: 0.005685
time: 0.24805569648742676
time: 2.2303080558776855
[1, 13444] loss_train: 0.009093, loss_test: 0.005668
time: 0.24505400657653809
time: 2.2615060806274414
[1, 13445] loss_train: 0.010846, loss_test: 0.005641
time: 0.2480604648590088
time: 2.2210171222686768
[1, 13446] loss_train: 0.002152, loss_test: 0.005619
time: 0.24405479431152344
time: 2.2545061111450195
[1, 13447] loss_train: 0.008311, loss_test: 0.005601
time: 0.24605464935302734
time: 2.2054929733276367
[1, 13448] loss_train: 0.007014, loss_test: 0.005589
time: 0.24606752395629883
time: 2.2285120487213135
[1, 13449] loss_train: 0.002781, loss_test: 0.005582
time: 0.2450542449951172
time: 2.250523567199707
[1, 13450] loss_train: 0.001762, loss_test: 0.005579
time: 0.25705742835998535
time: 2.2615058422088623
[1, 13451] loss_train: 0.001692, loss_test: 0.005576
time: 0.24405407905578613
time: 2.2380049228668213
[1, 13452] loss_train: 0.001603, loss_test: 0.005574
time: 0.24405360221862793
time: 2.22049617767334
[1, 13453] loss_train: 0.002745, loss_test: 0.005573
time: 0.2450547218322754
time: 2.213495969772339
[1, 13454] loss_train: 0.016623, loss_test: 0.005573
time: 0.24405431747436523
time: 2.2314987182617188
[1, 13455] loss_train: 0.001560, loss_test: 0.005574
time: 0.2450549602508545
time: 2.241513729095459
[1, 13456] loss_train: 0.006782, loss_test: 0.005574
time: 0.24405455589294434
time: 2.2014925479888916
[1, 13457] loss_train: 0.005456, loss_test: 0.005575
time: 0.24505352973937988
time: 2.218496084213257
[1, 13458] loss_train: 0.011580, loss_test: 0.005576
time: 0.2450547218322754
time: 2.2140021324157715
[1, 13459] loss_train: 0.009529, loss_test: 0.005578
time: 0.24305343627929688
time: 2.182497501373291
[1, 13460] loss_train: 0.000958, loss_test: 0.005579
time: 0.256056547164917
time: 2.2355003356933594
[1, 13461] loss_train: 0.005318, loss_test: 0.005581
time: 0.24305343627929688
time: 2.2175137996673584
[1, 13462] loss_train: 0.005954, loss_test: 0.005582
time: 0.2510561943054199
time: 2.241501569747925
[1, 13463] loss_train: 0.012691, loss_test: 0.005583
time: 0.24305438995361328
time: 2.2134971618652344
[1, 13464] loss_train: 0.007089, loss_test: 0.005583
time: 0.2470555305480957
time: 2.2435014247894287
[1, 13465] loss_train: 0.022411, loss_test: 0.005578
time: 0.2470543384552002
time: 2.242492437362671
[1, 13466] loss_train: 0.010159, loss_test: 0.005577
time: 0.24605417251586914
time: 2.242504358291626
[1, 13467] loss_train: 0.007038, loss_test: 0.005574
time: 0.24305391311645508
time: 2.2254979610443115
[1, 13468] loss_train: 0.003530, loss_test: 0.005572
time: 0.24605369567871094
time: 2.209505319595337
[1, 13469] loss_train: 0.003628, loss_test: 0.005572
time: 0.24305343627929688
time: 2.2205324172973633
[1, 13470] loss_train: 0.007014, loss_test: 0.005574
time: 0.256056547164917
time: 2.266507387161255
[1, 13471] loss_train: 0.008203, loss_test: 0.005578
time: 0.24405384063720703
time: 2.2114949226379395
[1, 13472] loss_train: 0.002824, loss_test: 0.005587
time: 0.2450549602508545
time: 2.2395005226135254
[1, 13473] loss_train: 0.005425, loss_test: 0.005596
time: 0.2450549602508545
time: 2.2174952030181885
[1, 13474] loss_train: 0.006472, loss_test: 0.005605
time: 0.24305343627929688
time: 2.2395012378692627
[1, 13475] loss_train: 0.003913, loss_test: 0.005615
time: 0.24605393409729004
time: 2.2164225578308105
[1, 13476] loss_train: 0.010533, loss_test: 0.005616
time: 0.24405384063720703
time: 2.2294981479644775
[1, 13477] loss_train: 0.010292, loss_test: 0.005615
time: 0.24406766891479492
time: 2.2284982204437256
[1, 13478] loss_train: 0.016864, loss_test: 0.005611
time: 0.24405407905578613
time: 2.242501735687256
[1, 13479] loss_train: 0.010036, loss_test: 0.005608
time: 0.24507832527160645
time: 2.2235145568847656
[1, 13480] loss_train: 0.008814, loss_test: 0.005603
time: 0.2560575008392334
time: 2.2837889194488525
[1, 13481] loss_train: 0.006608, loss_test: 0.005598
time: 0.24305391311645508
time: 2.209495782852173
[1, 13482] loss_train: 0.006939, loss_test: 0.005594
time: 0.24405407905578613
time: 2.209494113922119
[1, 13483] loss_train: 0.007339, loss_test: 0.005595
time: 0.2470543384552002
time: 2.228498697280884
[1, 13484] loss_train: 0.007492, loss_test: 0.005603
time: 0.24405455589294434
time: 2.1984918117523193
[1, 13485] loss_train: 0.005375, loss_test: 0.005615
time: 0.25005531311035156
time: 2.229499101638794
[1, 13486] loss_train: 0.005751, loss_test: 0.005625
time: 0.24505400657653809
time: 2.2067549228668213
[1, 13487] loss_train: 0.005159, loss_test: 0.005625
time: 0.2440810203552246
time: 2.2475016117095947
[1, 13488] loss_train: 0.007266, loss_test: 0.005622
time: 0.24405193328857422
time: 2.2540283203125
[1, 13489] loss_train: 0.003084, loss_test: 0.005613
time: 0.24205374717712402
time: 2.261505126953125
[1, 13490] loss_train: 0.004325, loss_test: 0.005609
time: 0.25505685806274414
time: 2.270508050918579
[1, 13491] loss_train: 0.005741, loss_test: 0.005607
time: 0.2470550537109375
time: 2.2274980545043945
[1, 13492] loss_train: 0.008737, loss_test: 0.005607
time: 0.2450547218322754
time: 2.2295162677764893
[1, 13493] loss_train: 0.004298, loss_test: 0.005610
time: 0.24405479431152344
time: 2.221496820449829
[1, 13494] loss_train: 0.013487, loss_test: 0.005609
time: 0.24305343627929688
time: 2.219496726989746
[1, 13495] loss_train: 0.006175, loss_test: 0.005607
time: 0.24405384063720703
time: 2.2104945182800293
[1, 13496] loss_train: 0.005105, loss_test: 0.005603
time: 0.2490551471710205
time: 2.199005126953125
[1, 13497] loss_train: 0.003316, loss_test: 0.005599
time: 0.2450544834136963
time: 2.2134947776794434
[1, 13498] loss_train: 0.007835, loss_test: 0.005594
time: 0.24405479431152344
time: 2.209505558013916
[1, 13499] loss_train: 0.004086, loss_test: 0.005591
time: 0.24305343627929688
time: 2.218498706817627
[1, 13500] loss_train: 0.006337, loss_test: 0.005591
time: 0.2560572624206543
time: 2.2274980545043945
[1, 13501] loss_train: 0.004477, loss_test: 0.005593
time: 0.24505376815795898
time: 2.2405030727386475
[1, 13502] loss_train: 0.011110, loss_test: 0.005592
time: 0.2466721534729004
time: 2.229499578475952
[1, 13503] loss_train: 0.014068, loss_test: 0.005594
time: 0.24505376815795898
time: 2.223496675491333
[1, 13504] loss_train: 0.003974, loss_test: 0.005595
time: 0.25005602836608887
time: 2.2515034675598145
[1, 13505] loss_train: 0.005640, loss_test: 0.005596
time: 0.24805450439453125
time: 2.2124953269958496
[1, 13506] loss_train: 0.006301, loss_test: 0.005594
time: 0.2490549087524414
time: 2.2100160121917725
[1, 13507] loss_train: 0.001529, loss_test: 0.005590
time: 0.24405503273010254
time: 2.2475032806396484
[1, 13508] loss_train: 0.005437, loss_test: 0.005587
time: 0.2450542449951172
time: 2.215529441833496
[1, 13509] loss_train: 0.018328, loss_test: 0.005588
time: 0.24405455589294434
time: 2.215496301651001
[1, 13510] loss_train: 0.010381, loss_test: 0.005591
time: 0.2560553550720215
time: 2.287522315979004
[1, 13511] loss_train: 0.005682, loss_test: 0.005589
time: 0.24406695365905762
time: 2.2224974632263184
[1, 13512] loss_train: 0.004868, loss_test: 0.005586
time: 0.24808526039123535
time: 2.227510452270508
[1, 13513] loss_train: 0.007053, loss_test: 0.005586
time: 0.2450542449951172
time: 2.2420051097869873
[1, 13514] loss_train: 0.011919, loss_test: 0.005582
time: 0.24305200576782227
time: 2.218496322631836
[1, 13515] loss_train: 0.001869, loss_test: 0.005580
time: 0.24405384063720703
time: 2.229499101638794
[1, 13516] loss_train: 0.007067, loss_test: 0.005579
time: 0.24405431747436523
time: 2.235502004623413
[1, 13517] loss_train: 0.001063, loss_test: 0.005578
time: 0.24407148361206055
time: 2.2164957523345947
[1, 13518] loss_train: 0.009845, loss_test: 0.005577
time: 0.24305319786071777
time: 2.219496726989746
[1, 13519] loss_train: 0.009449, loss_test: 0.005578
time: 0.24305486679077148
time: 2.2305009365081787
[1, 13520] loss_train: 0.002139, loss_test: 0.005578
time: 0.2560701370239258
time: 2.285510540008545
[1, 13521] loss_train: 0.010608, loss_test: 0.005579
time: 0.24305391311645508
time: 2.219496250152588
[1, 13522] loss_train: 0.001120, loss_test: 0.005579
time: 0.24805521965026855
time: 2.2134957313537598
[1, 13523] loss_train: 0.007343, loss_test: 0.005576
time: 0.24405360221862793
time: 2.2264981269836426
[1, 13524] loss_train: 0.006375, loss_test: 0.005573
time: 0.24405384063720703
time: 2.2745094299316406
[1, 13525] loss_train: 0.009261, loss_test: 0.005571
time: 0.25005555152893066
time: 2.2284984588623047
[1, 13526] loss_train: 0.002987, loss_test: 0.005571
time: 0.2450544834136963
time: 2.2365002632141113
[1, 13527] loss_train: 0.000754, loss_test: 0.005573
time: 0.24805545806884766
time: 2.2314984798431396
[1, 13528] loss_train: 0.005245, loss_test: 0.005577
time: 0.24605441093444824
time: 2.1864891052246094
[1, 13529] loss_train: 0.010253, loss_test: 0.005578
time: 0.249068021774292
time: 2.200007915496826
[1, 13530] loss_train: 0.008639, loss_test: 0.005579
time: 0.2540569305419922
time: 2.24550199508667
[1, 13531] loss_train: 0.001335, loss_test: 0.005581
time: 0.2470557689666748
time: 2.215498208999634
[1, 13532] loss_train: 0.004386, loss_test: 0.005586
time: 0.24608612060546875
time: 2.223499298095703
[1, 13533] loss_train: 0.001010, loss_test: 0.005593
time: 0.24305343627929688
time: 2.1864895820617676
[1, 13534] loss_train: 0.004078, loss_test: 0.005599
time: 0.24405455589294434
time: 2.2024943828582764
[1, 13535] loss_train: 0.001783, loss_test: 0.005608
time: 0.244065523147583
time: 2.204457998275757
[1, 13536] loss_train: 0.001125, loss_test: 0.005618
time: 0.24605488777160645
time: 2.233524799346924
[1, 13537] loss_train: 0.004901, loss_test: 0.005630
time: 0.24305415153503418
time: 2.2265028953552246
[1, 13538] loss_train: 0.001768, loss_test: 0.005644
time: 0.24506282806396484
time: 2.235609531402588
[1, 13539] loss_train: 0.008119, loss_test: 0.005659
time: 0.2490546703338623
time: 2.2295217514038086
[1, 13540] loss_train: 0.017374, loss_test: 0.005662
time: 0.2560570240020752
time: 2.2655084133148193
[1, 13541] loss_train: 0.020058, loss_test: 0.005633
time: 0.24405455589294434
time: 2.221497058868408
[1, 13542] loss_train: 0.009036, loss_test: 0.005595
time: 0.2470555305480957
time: 2.175487756729126
[1, 13543] loss_train: 0.011763, loss_test: 0.005577
time: 0.24405455589294434
time: 2.195491075515747
[1, 13544] loss_train: 0.005236, loss_test: 0.005583
time: 0.24505376815795898
time: 2.241501808166504
[1, 13545] loss_train: 0.006133, loss_test: 0.005607
time: 0.24405527114868164
time: 2.196155548095703
[1, 13546] loss_train: 0.002564, loss_test: 0.005632
time: 0.24405455589294434
time: 2.198491096496582
[1, 13547] loss_train: 0.003938, loss_test: 0.005640
time: 0.24605417251586914
time: 2.2254996299743652
[1, 13548] loss_train: 0.005971, loss_test: 0.005634
time: 0.24406814575195312
time: 2.237520217895508
[1, 13549] loss_train: 0.008791, loss_test: 0.005618
time: 0.24805593490600586
time: 2.240015983581543
[1, 13550] loss_train: 0.001793, loss_test: 0.005599
time: 0.2560570240020752
time: 2.2765092849731445
[1, 13551] loss_train: 0.001313, loss_test: 0.005583
time: 0.2450542449951172
time: 2.2565126419067383
[1, 13552] loss_train: 0.003727, loss_test: 0.005579
time: 0.24405407905578613
time: 2.2385008335113525
[1, 13553] loss_train: 0.008664, loss_test: 0.005583
time: 0.24805521965026855
time: 2.1894891262054443
[1, 13554] loss_train: 0.004334, loss_test: 0.005594
time: 0.24405455589294434
time: 2.2164957523345947
[1, 13555] loss_train: 0.002920, loss_test: 0.005610
time: 0.24305391311645508
time: 2.2340285778045654
[1, 13556] loss_train: 0.008913, loss_test: 0.005629
time: 0.24605417251586914
time: 2.210494041442871
[1, 13557] loss_train: 0.003246, loss_test: 0.005646
time: 0.24405384063720703
time: 2.2144973278045654
[1, 13558] loss_train: 0.003188, loss_test: 0.005660
time: 0.24405360221862793
time: 2.218499183654785
[1, 13559] loss_train: 0.010675, loss_test: 0.005658
time: 0.25005578994750977
time: 2.236004590988159
[1, 13560] loss_train: 0.003051, loss_test: 0.005654
time: 0.2580573558807373
time: 2.2535059452056885
[1, 13561] loss_train: 0.006336, loss_test: 0.005645
time: 0.25005531311035156
time: 2.237501621246338
[1, 13562] loss_train: 0.002350, loss_test: 0.005639
time: 0.2450551986694336
time: 2.2314987182617188
[1, 13563] loss_train: 0.009753, loss_test: 0.005618
time: 0.2510552406311035
time: 2.253504753112793
[1, 13564] loss_train: 0.006568, loss_test: 0.005604
time: 0.2450544834136963
time: 2.2244973182678223
[1, 13565] loss_train: 0.010475, loss_test: 0.005589
time: 0.2490553855895996
time: 2.220029592514038
[1, 13566] loss_train: 0.003020, loss_test: 0.005580
time: 0.24505400657653809
time: 2.2435035705566406
[1, 13567] loss_train: 0.004300, loss_test: 0.005577
time: 0.2470543384552002
time: 2.191490650177002
[1, 13568] loss_train: 0.008302, loss_test: 0.005577
time: 0.2450549602508545
time: 2.227497100830078
[1, 13569] loss_train: 0.008740, loss_test: 0.005582
time: 0.24605488777160645
time: 2.2485241889953613
[1, 13570] loss_train: 0.005296, loss_test: 0.005585
time: 0.25705838203430176
time: 2.2855117321014404
[1, 13571] loss_train: 0.006254, loss_test: 0.005588
time: 0.24605441093444824
time: 2.197493553161621
[1, 13572] loss_train: 0.000949, loss_test: 0.005589
time: 0.24305319786071777
time: 2.2500083446502686
[1, 13573] loss_train: 0.004155, loss_test: 0.005586
time: 0.24605488777160645
time: 2.2635061740875244
[1, 13574] loss_train: 0.003830, loss_test: 0.005583
time: 0.24405455589294434
time: 2.222496747970581
[1, 13575] loss_train: 0.006859, loss_test: 0.005584
time: 0.24405479431152344
time: 2.2035024166107178
[1, 13576] loss_train: 0.008003, loss_test: 0.005583
time: 0.24405455589294434
time: 2.242006778717041
[1, 13577] loss_train: 0.006510, loss_test: 0.005584
time: 0.24305343627929688
time: 2.2114956378936768
[1, 13578] loss_train: 0.012895, loss_test: 0.005583
time: 0.24405431747436523
time: 2.21449613571167
[1, 13579] loss_train: 0.003193, loss_test: 0.005585
time: 0.24405360221862793
time: 2.220526933670044
[1, 13580] loss_train: 0.002056, loss_test: 0.005589
time: 0.25705647468566895
time: 2.2154958248138428
[1, 13581] loss_train: 0.010832, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2345001697540283
[1, 13582] loss_train: 0.003248, loss_test: 0.005589
time: 0.2470552921295166
time: 2.2139580249786377
[1, 13583] loss_train: 0.002412, loss_test: 0.005591
time: 0.24605464935302734
time: 2.222496747970581
[1, 13584] loss_train: 0.008499, loss_test: 0.005594
time: 0.2470552921295166
time: 2.2164952754974365
[1, 13585] loss_train: 0.001757, loss_test: 0.005597
time: 0.24505972862243652
time: 2.23150897026062
[1, 13586] loss_train: 0.003802, loss_test: 0.005599
time: 0.24805545806884766
time: 2.2004921436309814
[1, 13587] loss_train: 0.003082, loss_test: 0.005603
time: 0.2450547218322754
time: 2.2124946117401123
[1, 13588] loss_train: 0.007540, loss_test: 0.005595
time: 0.24405384063720703
time: 2.217332124710083
[1, 13589] loss_train: 0.006771, loss_test: 0.005589
time: 0.24505281448364258
time: 2.2114949226379395
[1, 13590] loss_train: 0.009839, loss_test: 0.005582
time: 0.2580578327178955
time: 2.2710540294647217
[1, 13591] loss_train: 0.001498, loss_test: 0.005582
time: 0.2490549087524414
time: 2.2034926414489746
[1, 13592] loss_train: 0.010476, loss_test: 0.005583
time: 0.24405503273010254
time: 2.2270267009735107
[1, 13593] loss_train: 0.005573, loss_test: 0.005583
time: 0.24305367469787598
time: 2.1764907836914062
[1, 13594] loss_train: 0.001926, loss_test: 0.005580
time: 0.2470548152923584
time: 2.1754870414733887
[1, 13595] loss_train: 0.003389, loss_test: 0.005577
time: 0.2490546703338623
time: 2.246502161026001
[1, 13596] loss_train: 0.011525, loss_test: 0.005577
time: 0.2470552921295166
time: 2.2264978885650635
[1, 13597] loss_train: 0.007259, loss_test: 0.005580
time: 0.24805521965026855
time: 2.226496934890747
[1, 13598] loss_train: 0.006882, loss_test: 0.005587
time: 0.2436528205871582
time: 2.222496747970581
[1, 13599] loss_train: 0.009934, loss_test: 0.005593
time: 0.2470548152923584
time: 2.2395009994506836
[1, 13600] loss_train: 0.010108, loss_test: 0.005591
time: 0.25705766677856445
time: 2.257504463195801
[1, 13601] loss_train: 0.002757, loss_test: 0.005591
time: 0.24805569648742676
time: 2.223496913909912
[1, 13602] loss_train: 0.005588, loss_test: 0.005593
time: 0.24405479431152344
time: 2.2099978923797607
[1, 13603] loss_train: 0.004201, loss_test: 0.005593
time: 0.24305319786071777
time: 2.217496395111084
[1, 13604] loss_train: 0.003848, loss_test: 0.005596
time: 0.2450549602508545
time: 2.234499931335449
[1, 13605] loss_train: 0.004269, loss_test: 0.005599
time: 0.24305391311645508
time: 2.1964917182922363
[1, 13606] loss_train: 0.009548, loss_test: 0.005597
time: 0.2470545768737793
time: 2.2140002250671387
[1, 13607] loss_train: 0.003569, loss_test: 0.005597
time: 0.2430555820465088
time: 2.219498872756958
[1, 13608] loss_train: 0.005090, loss_test: 0.005595
time: 0.2450551986694336
time: 2.2275071144104004
[1, 13609] loss_train: 0.007615, loss_test: 0.005594
time: 0.24305343627929688
time: 2.280510663986206
[1, 13610] loss_train: 0.012908, loss_test: 0.005593
time: 0.25505685806274414
time: 2.275057315826416
[1, 13611] loss_train: 0.004828, loss_test: 0.005594
time: 0.24605488777160645
time: 2.2455132007598877
[1, 13612] loss_train: 0.003760, loss_test: 0.005596
time: 0.2450547218322754
time: 2.231498956680298
[1, 13613] loss_train: 0.003294, loss_test: 0.005597
time: 0.24405384063720703
time: 2.229499101638794
[1, 13614] loss_train: 0.010742, loss_test: 0.005601
time: 0.24605417251586914
time: 2.218496561050415
[1, 13615] loss_train: 0.004123, loss_test: 0.005614
time: 0.24305343627929688
time: 2.2254984378814697
[1, 13616] loss_train: 0.010414, loss_test: 0.005636
time: 0.25005578994750977
time: 2.208493232727051
[1, 13617] loss_train: 0.011244, loss_test: 0.005667
time: 0.24405550956726074
time: 2.2174975872039795
[1, 13618] loss_train: 0.010418, loss_test: 0.005699
time: 0.25205421447753906
time: 2.2104947566986084
[1, 13619] loss_train: 0.001052, loss_test: 0.005715
time: 0.24805498123168945
time: 2.2274985313415527
[1, 13620] loss_train: 0.013855, loss_test: 0.005733
time: 0.2600586414337158
time: 2.268514633178711
[1, 13621] loss_train: 0.017934, loss_test: 0.005757
time: 0.24805545806884766
time: 2.2304983139038086
[1, 13622] loss_train: 0.002329, loss_test: 0.005748
time: 0.2490558624267578
time: 2.241523027420044
[1, 13623] loss_train: 0.004064, loss_test: 0.005690
time: 0.24606895446777344
time: 2.2515065670013428
[1, 13624] loss_train: 0.000528, loss_test: 0.005653
time: 0.2470543384552002
time: 2.2475223541259766
[1, 13625] loss_train: 0.004691, loss_test: 0.005614
time: 0.2450544834136963
time: 2.2465052604675293
[1, 13626] loss_train: 0.007503, loss_test: 0.005606
time: 0.2490551471710205
time: 2.19549298286438
[1, 13627] loss_train: 0.004757, loss_test: 0.005611
time: 0.2450547218322754
time: 2.216495990753174
[1, 13628] loss_train: 0.007960, loss_test: 0.005625
time: 0.2450559139251709
time: 2.2120001316070557
[1, 13629] loss_train: 0.008623, loss_test: 0.005643
time: 0.24205350875854492
time: 2.2475030422210693
[1, 13630] loss_train: 0.008650, loss_test: 0.005655
time: 0.26105833053588867
time: 2.2425012588500977
[1, 13631] loss_train: 0.005388, loss_test: 0.005668
time: 0.24605417251586914
time: 2.229498863220215
[1, 13632] loss_train: 0.006927, loss_test: 0.005676
time: 0.2450549602508545
time: 2.2385003566741943
[1, 13633] loss_train: 0.011949, loss_test: 0.005658
time: 0.2430555820465088
time: 2.2465012073516846
[1, 13634] loss_train: 0.001981, loss_test: 0.005646
time: 0.24505400657653809
time: 2.244502305984497
[1, 13635] loss_train: 0.006102, loss_test: 0.005630
time: 0.2450549602508545
time: 2.2134947776794434
[1, 13636] loss_train: 0.005537, loss_test: 0.005619
time: 0.24305415153503418
time: 2.2164976596832275
[1, 13637] loss_train: 0.003972, loss_test: 0.005612
time: 0.24405455589294434
time: 2.2400059700012207
[1, 13638] loss_train: 0.002643, loss_test: 0.005609
time: 0.2450544834136963
time: 2.1934900283813477
[1, 13639] loss_train: 0.000704, loss_test: 0.005609
time: 0.2450549602508545
time: 2.2324986457824707
[1, 13640] loss_train: 0.006683, loss_test: 0.005611
time: 0.25705742835998535
time: 2.2425122261047363
[1, 13641] loss_train: 0.008307, loss_test: 0.005612
time: 0.24605536460876465
time: 2.2315008640289307
[1, 13642] loss_train: 0.007419, loss_test: 0.005612
time: 0.24406671524047852
time: 2.2193992137908936
[1, 13643] loss_train: 0.004432, loss_test: 0.005612
time: 0.2490546703338623
time: 2.2345004081726074
[1, 13644] loss_train: 0.009336, loss_test: 0.005609
time: 0.24405455589294434
time: 2.2395005226135254
[1, 13645] loss_train: 0.001328, loss_test: 0.005608
time: 0.2470548152923584
time: 2.2705225944519043
[1, 13646] loss_train: 0.008026, loss_test: 0.005606
time: 0.2450547218322754
time: 2.2355005741119385
[1, 13647] loss_train: 0.001409, loss_test: 0.005609
time: 0.24905800819396973
time: 2.263503313064575
[1, 13648] loss_train: 0.004479, loss_test: 0.005613
time: 0.25305652618408203
time: 2.24550199508667
[1, 13649] loss_train: 0.002684, loss_test: 0.005618
time: 0.25005531311035156
time: 2.225499153137207
[1, 13650] loss_train: 0.009198, loss_test: 0.005619
time: 0.2560553550720215
time: 2.2475738525390625
[1, 13651] loss_train: 0.001524, loss_test: 0.005615
time: 0.2520565986633301
time: 2.2415106296539307
[1, 13652] loss_train: 0.005113, loss_test: 0.005610
time: 0.24405336380004883
time: 2.2295234203338623
[1, 13653] loss_train: 0.001848, loss_test: 0.005606
time: 0.2470543384552002
time: 2.212521553039551
[1, 13654] loss_train: 0.002001, loss_test: 0.005604
time: 0.24405336380004883
time: 2.2084944248199463
[1, 13655] loss_train: 0.007926, loss_test: 0.005601
time: 0.24405455589294434
time: 2.247502326965332
[1, 13656] loss_train: 0.006238, loss_test: 0.005598
time: 0.24505400657653809
time: 2.239501476287842
[1, 13657] loss_train: 0.003171, loss_test: 0.005597
time: 0.24405360221862793
time: 2.238513231277466
[1, 13658] loss_train: 0.008696, loss_test: 0.005596
time: 0.24605464935302734
time: 2.248502731323242
[1, 13659] loss_train: 0.012679, loss_test: 0.005592
time: 0.24505376815795898
time: 2.2405014038085938
[1, 13660] loss_train: 0.004623, loss_test: 0.005590
time: 0.2560577392578125
time: 2.253505229949951
[1, 13661] loss_train: 0.003932, loss_test: 0.005590
time: 0.2470550537109375
time: 2.2300264835357666
[1, 13662] loss_train: 0.004427, loss_test: 0.005590
time: 0.24405455589294434
time: 2.2525033950805664
[1, 13663] loss_train: 0.005932, loss_test: 0.005590
time: 0.24305391311645508
time: 2.2066519260406494
[1, 13664] loss_train: 0.006424, loss_test: 0.005587
time: 0.24305438995361328
time: 2.224496841430664
[1, 13665] loss_train: 0.014594, loss_test: 0.005582
time: 0.24606704711914062
time: 2.2084949016571045
[1, 13666] loss_train: 0.004121, loss_test: 0.005579
time: 0.24405336380004883
time: 2.2014923095703125
[1, 13667] loss_train: 0.003027, loss_test: 0.005577
time: 0.24405384063720703
time: 2.2385056018829346
[1, 13668] loss_train: 0.011140, loss_test: 0.005576
time: 0.24805521965026855
time: 2.2395002841949463
[1, 13669] loss_train: 0.006801, loss_test: 0.005578
time: 0.24405360221862793
time: 2.250526189804077
[1, 13670] loss_train: 0.001779, loss_test: 0.005580
time: 0.256056547164917
time: 2.2677602767944336
[1, 13671] loss_train: 0.008205, loss_test: 0.005584
time: 0.24605536460876465
time: 2.2545042037963867
[1, 13672] loss_train: 0.004402, loss_test: 0.005589
time: 0.25005555152893066
time: 2.2164957523345947
[1, 13673] loss_train: 0.009984, loss_test: 0.005596
time: 0.24405527114868164
time: 2.2154951095581055
[1, 13674] loss_train: 0.004920, loss_test: 0.005606
time: 0.25006747245788574
time: 2.1924896240234375
[1, 13675] loss_train: 0.006391, loss_test: 0.005612
time: 0.2490558624267578
time: 2.2090163230895996
[1, 13676] loss_train: 0.002061, loss_test: 0.005618
time: 0.24805545806884766
time: 2.2565064430236816
[1, 13677] loss_train: 0.007928, loss_test: 0.005626
time: 0.24505233764648438
time: 2.237027645111084
[1, 13678] loss_train: 0.003021, loss_test: 0.005631
time: 0.2470567226409912
time: 2.1955020427703857
[1, 13679] loss_train: 0.004572, loss_test: 0.005636
time: 0.2450551986694336
time: 2.2174952030181885
[1, 13680] loss_train: 0.002834, loss_test: 0.005643
time: 0.25706958770751953
time: 2.2515034675598145
[1, 13681] loss_train: 0.003207, loss_test: 0.005651
time: 0.24305415153503418
time: 2.2645063400268555
[1, 13682] loss_train: 0.004380, loss_test: 0.005650
time: 0.24305343627929688
time: 2.2455027103424072
[1, 13683] loss_train: 0.008473, loss_test: 0.005642
time: 0.24405407905578613
time: 2.208496332168579
[1, 13684] loss_train: 0.006101, loss_test: 0.005632
time: 0.24405407905578613
time: 2.2395009994506836
[1, 13685] loss_train: 0.003486, loss_test: 0.005624
time: 0.24407124519348145
time: 2.2274980545043945
[1, 13686] loss_train: 0.008484, loss_test: 0.005611
time: 0.24205470085144043
time: 2.222496509552002
[1, 13687] loss_train: 0.003854, loss_test: 0.005606
time: 0.24305415153503418
time: 2.179006576538086
[1, 13688] loss_train: 0.010620, loss_test: 0.005602
time: 0.24655914306640625
time: 2.200491428375244
[1, 13689] loss_train: 0.006416, loss_test: 0.005602
time: 0.2450554370880127
time: 2.2039995193481445
[1, 13690] loss_train: 0.011567, loss_test: 0.005605
time: 0.25705695152282715
time: 2.2795090675354004
[1, 13691] loss_train: 0.001996, loss_test: 0.005611
time: 0.24805545806884766
time: 2.2280030250549316
[1, 13692] loss_train: 0.007263, loss_test: 0.005613
time: 0.24505329132080078
time: 2.228501081466675
[1, 13693] loss_train: 0.005872, loss_test: 0.005608
time: 0.2490549087524414
time: 2.244502305984497
[1, 13694] loss_train: 0.014325, loss_test: 0.005599
time: 0.2450544834136963
time: 2.193490505218506
[1, 13695] loss_train: 0.003484, loss_test: 0.005593
time: 0.25005602836608887
time: 2.252507209777832
[1, 13696] loss_train: 0.004652, loss_test: 0.005591
time: 0.24605464935302734
time: 2.250505208969116
[1, 13697] loss_train: 0.005219, loss_test: 0.005594
time: 0.2470548152923584
time: 2.245502471923828
[1, 13698] loss_train: 0.004455, loss_test: 0.005600
time: 0.24605441093444824
time: 2.233499526977539
[1, 13699] loss_train: 0.008846, loss_test: 0.005608
time: 0.24605512619018555
time: 2.203498601913452
[1, 13700] loss_train: 0.008649, loss_test: 0.005617
time: 0.2560567855834961
time: 2.285510778427124
[1, 13701] loss_train: 0.002250, loss_test: 0.005626
time: 0.25005531311035156
time: 2.2194995880126953
[1, 13702] loss_train: 0.009645, loss_test: 0.005632
time: 0.24505400657653809
time: 2.226498603820801
[1, 13703] loss_train: 0.007375, loss_test: 0.005632
time: 0.24305343627929688
time: 2.2244997024536133
[1, 13704] loss_train: 0.010131, loss_test: 0.005621
time: 0.2450568675994873
time: 2.20849347114563
[1, 13705] loss_train: 0.009775, loss_test: 0.005604
time: 0.24605488777160645
time: 2.2365167140960693
[1, 13706] loss_train: 0.005631, loss_test: 0.005593
time: 0.24405598640441895
time: 2.244502544403076
[1, 13707] loss_train: 0.006549, loss_test: 0.005586
time: 0.24307870864868164
time: 2.2315187454223633
[1, 13708] loss_train: 0.007271, loss_test: 0.005584
time: 0.24405384063720703
time: 2.2655069828033447
[1, 13709] loss_train: 0.003364, loss_test: 0.005584
time: 0.24406743049621582
time: 2.192490577697754
[1, 13710] loss_train: 0.010110, loss_test: 0.005592
time: 0.25505638122558594
time: 2.231498956680298
[1, 13711] loss_train: 0.006765, loss_test: 0.005604
time: 0.2450547218322754
time: 2.230499267578125
[1, 13712] loss_train: 0.009898, loss_test: 0.005615
time: 0.24605512619018555
time: 2.209061861038208
[1, 13713] loss_train: 0.004936, loss_test: 0.005625
time: 0.24405407905578613
time: 2.2009947299957275
[1, 13714] loss_train: 0.013405, loss_test: 0.005648
time: 0.2490549087524414
time: 2.204495429992676
[1, 13715] loss_train: 0.003794, loss_test: 0.005661
time: 0.24405407905578613
time: 2.2010040283203125
[1, 13716] loss_train: 0.005108, loss_test: 0.005658
time: 0.24805498123168945
time: 2.243501901626587
[1, 13717] loss_train: 0.009137, loss_test: 0.005657
time: 0.2510554790496826
time: 2.270508289337158
[1, 13718] loss_train: 0.004016, loss_test: 0.005652
time: 0.2510559558868408
time: 2.2355000972747803
[1, 13719] loss_train: 0.015014, loss_test: 0.005636
time: 0.25505614280700684
time: 2.268507242202759
[1, 13720] loss_train: 0.012153, loss_test: 0.005624
time: 0.2580580711364746
time: 2.298513889312744
[1, 13721] loss_train: 0.002758, loss_test: 0.005613
time: 0.24605417251586914
time: 2.254504442214966
[1, 13722] loss_train: 0.004627, loss_test: 0.005604
time: 0.2540569305419922
time: 2.2415010929107666
[1, 13723] loss_train: 0.002048, loss_test: 0.005597
time: 0.24508023262023926
time: 2.207493543624878
[1, 13724] loss_train: 0.004327, loss_test: 0.005595
time: 0.24605512619018555
time: 2.209493398666382
[1, 13725] loss_train: 0.005428, loss_test: 0.005598
time: 0.24605536460876465
time: 2.2019948959350586
[1, 13726] loss_train: 0.001223, loss_test: 0.005604
time: 0.2450547218322754
time: 2.209010124206543
[1, 13727] loss_train: 0.007748, loss_test: 0.005608
time: 0.24505400657653809
time: 2.2475030422210693
[1, 13728] loss_train: 0.008387, loss_test: 0.005606
time: 0.2450542449951172
time: 2.2390434741973877
[1, 13729] loss_train: 0.003487, loss_test: 0.005605
time: 0.24405336380004883
time: 2.2174954414367676
[1, 13730] loss_train: 0.003670, loss_test: 0.005606
time: 0.25705718994140625
time: 2.2555136680603027
[1, 13731] loss_train: 0.004207, loss_test: 0.005606
time: 0.2450547218322754
time: 2.2565042972564697
[1, 13732] loss_train: 0.004631, loss_test: 0.005605
time: 0.24806523323059082
time: 2.2505056858062744
[1, 13733] loss_train: 0.004531, loss_test: 0.005602
time: 0.2450549602508545
time: 2.2224972248077393
[1, 13734] loss_train: 0.003735, loss_test: 0.005602
time: 0.24356508255004883
time: 2.242502212524414
[1, 13735] loss_train: 0.007642, loss_test: 0.005602
time: 0.2450549602508545
time: 2.2074928283691406
[1, 13736] loss_train: 0.009344, loss_test: 0.005600
time: 0.24805569648742676
time: 2.2184958457946777
[1, 13737] loss_train: 0.005252, loss_test: 0.005598
time: 0.24405455589294434
time: 2.207998514175415
[1, 13738] loss_train: 0.001836, loss_test: 0.005596
time: 0.24405384063720703
time: 2.2134950160980225
[1, 13739] loss_train: 0.013103, loss_test: 0.005592
time: 0.24805593490600586
time: 2.1764867305755615
[1, 13740] loss_train: 0.001142, loss_test: 0.005591
time: 0.2570686340332031
time: 2.257505416870117
[1, 13741] loss_train: 0.008576, loss_test: 0.005587
time: 0.24605441093444824
time: 2.2345001697540283
[1, 13742] loss_train: 0.013316, loss_test: 0.005585
time: 0.24405455589294434
time: 2.261507272720337
[1, 13743] loss_train: 0.006260, loss_test: 0.005585
time: 0.2470543384552002
time: 2.224496603012085
[1, 13744] loss_train: 0.000630, loss_test: 0.005586
time: 0.2450571060180664
time: 2.2515037059783936
[1, 13745] loss_train: 0.009206, loss_test: 0.005588
time: 0.24805569648742676
time: 2.2204957008361816
[1, 13746] loss_train: 0.001159, loss_test: 0.005588
time: 0.2450549602508545
time: 2.2705256938934326
[1, 13747] loss_train: 0.001095, loss_test: 0.005586
time: 0.24605488777160645
time: 2.1954925060272217
[1, 13748] loss_train: 0.002284, loss_test: 0.005584
time: 0.24506640434265137
time: 2.2020976543426514
[1, 13749] loss_train: 0.008552, loss_test: 0.005583
time: 0.24405455589294434
time: 2.2155284881591797
[1, 13750] loss_train: 0.007735, loss_test: 0.005582
time: 0.2560563087463379
time: 2.2345001697540283
[1, 13751] loss_train: 0.011146, loss_test: 0.005582
time: 0.24205398559570312
time: 2.2244975566864014
[1, 13752] loss_train: 0.001435, loss_test: 0.005585
time: 0.24405384063720703
time: 2.2390053272247314
[1, 13753] loss_train: 0.005660, loss_test: 0.005589
time: 0.24405407905578613
time: 2.2294986248016357
[1, 13754] loss_train: 0.000724, loss_test: 0.005597
time: 0.2450549602508545
time: 2.245501756668091
[1, 13755] loss_train: 0.007738, loss_test: 0.005604
time: 0.2450547218322754
time: 2.2385001182556152
[1, 13756] loss_train: 0.010078, loss_test: 0.005607
time: 0.24455785751342773
time: 2.2244977951049805
[1, 13757] loss_train: 0.007897, loss_test: 0.005605
time: 0.24305343627929688
time: 2.22749924659729
[1, 13758] loss_train: 0.005316, loss_test: 0.005600
time: 0.24305343627929688
time: 2.2210381031036377
[1, 13759] loss_train: 0.010315, loss_test: 0.005587
time: 0.24405431747436523
time: 2.2144968509674072
[1, 13760] loss_train: 0.008727, loss_test: 0.005584
time: 0.25505661964416504
time: 2.2244980335235596
[1, 13761] loss_train: 0.005563, loss_test: 0.005581
time: 0.24605703353881836
time: 2.219496250152588
[1, 13762] loss_train: 0.006985, loss_test: 0.005578
time: 0.24605417251586914
time: 2.246110439300537
[1, 13763] loss_train: 0.002582, loss_test: 0.005576
time: 0.25005578994750977
time: 2.2084970474243164
[1, 13764] loss_train: 0.002752, loss_test: 0.005573
time: 0.2450542449951172
time: 2.239501476287842
[1, 13765] loss_train: 0.011349, loss_test: 0.005569
time: 0.24405336380004883
time: 2.216496467590332
[1, 13766] loss_train: 0.002225, loss_test: 0.005566
time: 0.2450542449951172
time: 2.2465038299560547
[1, 13767] loss_train: 0.011946, loss_test: 0.005564
time: 0.24305415153503418
time: 2.2334988117218018
[1, 13768] loss_train: 0.001734, loss_test: 0.005564
time: 0.24305343627929688
time: 2.2695159912109375
[1, 13769] loss_train: 0.007181, loss_test: 0.005562
time: 0.24405407905578613
time: 2.2365000247955322
[1, 13770] loss_train: 0.003883, loss_test: 0.005563
time: 0.2560572624206543
time: 2.2635061740875244
[1, 13771] loss_train: 0.008327, loss_test: 0.005565
time: 0.24305391311645508
time: 2.228498697280884
[1, 13772] loss_train: 0.007302, loss_test: 0.005568
time: 0.24305343627929688
time: 2.234004020690918
[1, 13773] loss_train: 0.004548, loss_test: 0.005573
time: 0.24605512619018555
time: 2.217496156692505
[1, 13774] loss_train: 0.004932, loss_test: 0.005575
time: 0.24205350875854492
time: 2.220496654510498
[1, 13775] loss_train: 0.005312, loss_test: 0.005579
time: 0.24306559562683105
time: 2.2015037536621094
[1, 13776] loss_train: 0.001984, loss_test: 0.005586
time: 0.24605417251586914
time: 2.236358880996704
[1, 13777] loss_train: 0.001175, loss_test: 0.005595
time: 0.24306869506835938
time: 2.2395009994506836
[1, 13778] loss_train: 0.007721, loss_test: 0.005599
time: 0.24405455589294434
time: 2.234499454498291
[1, 13779] loss_train: 0.008774, loss_test: 0.005597
time: 0.2450549602508545
time: 2.2221765518188477
[1, 13780] loss_train: 0.007657, loss_test: 0.005595
time: 0.2560691833496094
time: 2.26950740814209
[1, 13781] loss_train: 0.014861, loss_test: 0.005587
time: 0.24605464935302734
time: 2.243501663208008
[1, 13782] loss_train: 0.006685, loss_test: 0.005577
time: 0.24205350875854492
time: 2.255504846572876
[1, 13783] loss_train: 0.001324, loss_test: 0.005576
time: 0.2490549087524414
time: 2.193490982055664
[1, 13784] loss_train: 0.005778, loss_test: 0.005578
time: 0.24406695365905762
time: 2.2084944248199463
[1, 13785] loss_train: 0.005102, loss_test: 0.005583
time: 0.24805498123168945
time: 2.2079050540924072
[1, 13786] loss_train: 0.001569, loss_test: 0.005585
time: 0.24605584144592285
time: 2.2295308113098145
[1, 13787] loss_train: 0.006546, loss_test: 0.005586
time: 0.24605441093444824
time: 2.207998514175415
[1, 13788] loss_train: 0.005132, loss_test: 0.005586
time: 0.24605417251586914
time: 2.2525038719177246
[1, 13789] loss_train: 0.002284, loss_test: 0.005585
time: 0.2450547218322754
time: 2.2244975566864014
[1, 13790] loss_train: 0.010424, loss_test: 0.005577
time: 0.258056640625
time: 2.291513442993164
[1, 13791] loss_train: 0.009756, loss_test: 0.005571
time: 0.24605441093444824
time: 2.1990575790405273
[1, 13792] loss_train: 0.006972, loss_test: 0.005568
time: 0.24405407905578613
time: 2.2505037784576416
[1, 13793] loss_train: 0.006439, loss_test: 0.005567
time: 0.24505376815795898
time: 2.234499931335449
[1, 13794] loss_train: 0.002513, loss_test: 0.005568
time: 0.24506735801696777
time: 2.2294986248016357
[1, 13795] loss_train: 0.015482, loss_test: 0.005565
time: 0.24405360221862793
time: 2.272508382797241
[1, 13796] loss_train: 0.016765, loss_test: 0.005561
time: 0.24405431747436523
time: 2.221496105194092
[1, 13797] loss_train: 0.001484, loss_test: 0.005561
time: 0.24405407905578613
time: 2.193013906478882
[1, 13798] loss_train: 0.010570, loss_test: 0.005561
time: 0.24405455589294434
time: 2.250514268875122
[1, 13799] loss_train: 0.005858, loss_test: 0.005565
time: 0.24405527114868164
time: 2.2004923820495605
[1, 13800] loss_train: 0.005869, loss_test: 0.005568
time: 0.2580575942993164
time: 2.2505033016204834
[1, 13801] loss_train: 0.009000, loss_test: 0.005568
time: 0.24405431747436523
time: 2.2034924030303955
[1, 13802] loss_train: 0.009728, loss_test: 0.005568
time: 0.24405407905578613
time: 2.232499837875366
[1, 13803] loss_train: 0.002737, loss_test: 0.005566
time: 0.2450542449951172
time: 2.221497058868408
[1, 13804] loss_train: 0.013514, loss_test: 0.005567
time: 0.2450542449951172
time: 2.2405552864074707
[1, 13805] loss_train: 0.002664, loss_test: 0.005569
time: 0.24455904960632324
time: 2.267509698867798
[1, 13806] loss_train: 0.013944, loss_test: 0.005572
time: 0.24405407905578613
time: 2.2114949226379395
[1, 13807] loss_train: 0.010679, loss_test: 0.005576
time: 0.24805593490600586
time: 2.2185142040252686
[1, 13808] loss_train: 0.010787, loss_test: 0.005577
time: 0.24805474281311035
time: 2.192490577697754
[1, 13809] loss_train: 0.006789, loss_test: 0.005580
time: 0.24405407905578613
time: 2.2335121631622314
[1, 13810] loss_train: 0.003811, loss_test: 0.005585
time: 0.2600574493408203
time: 2.260505437850952
[1, 13811] loss_train: 0.001657, loss_test: 0.005590
time: 0.24405336380004883
time: 2.2530548572540283
[1, 13812] loss_train: 0.016053, loss_test: 0.005584
time: 0.24805521965026855
time: 2.2325186729431152
[1, 13813] loss_train: 0.008027, loss_test: 0.005581
time: 0.24605512619018555
time: 2.2144951820373535
[1, 13814] loss_train: 0.006449, loss_test: 0.005582
time: 0.24605488777160645
time: 2.200995445251465
[1, 13815] loss_train: 0.002814, loss_test: 0.005586
time: 0.2430558204650879
time: 2.223497152328491
[1, 13816] loss_train: 0.003744, loss_test: 0.005591
time: 0.24605512619018555
time: 2.208493947982788
[1, 13817] loss_train: 0.001759, loss_test: 0.005594
time: 0.24805450439453125
time: 2.216495990753174
[1, 13818] loss_train: 0.003415, loss_test: 0.005595
time: 0.24405384063720703
time: 2.20149302482605
[1, 13819] loss_train: 0.004746, loss_test: 0.005598
time: 0.2450547218322754
time: 2.194509267807007
[1, 13820] loss_train: 0.003665, loss_test: 0.005602
time: 0.2560591697692871
time: 2.2425010204315186
[1, 13821] loss_train: 0.009290, loss_test: 0.005605
time: 0.24605441093444824
time: 2.2200005054473877
[1, 13822] loss_train: 0.007218, loss_test: 0.005607
time: 0.24607014656066895
time: 2.193490982055664
[1, 13823] loss_train: 0.006606, loss_test: 0.005608
time: 0.24605345726013184
time: 2.2044951915740967
[1, 13824] loss_train: 0.012499, loss_test: 0.005606
time: 0.24605441093444824
time: 2.2320215702056885
[1, 13825] loss_train: 0.003717, loss_test: 0.005604
time: 0.24708080291748047
time: 2.2220401763916016
[1, 13826] loss_train: 0.005152, loss_test: 0.005603
time: 0.24405407905578613
time: 2.2365002632141113
[1, 13827] loss_train: 0.000442, loss_test: 0.005604
time: 0.2470548152923584
time: 2.246011734008789
[1, 13828] loss_train: 0.008261, loss_test: 0.005597
time: 0.24439096450805664
time: 2.247502326965332
[1, 13829] loss_train: 0.002991, loss_test: 0.005590
time: 0.24607396125793457
time: 2.2254974842071533
[1, 13830] loss_train: 0.009583, loss_test: 0.005586
time: 0.2560703754425049
time: 2.279510021209717
[1, 13831] loss_train: 0.009770, loss_test: 0.005585
time: 0.2490553855895996
time: 2.2450273036956787
[1, 13832] loss_train: 0.004439, loss_test: 0.005585
time: 0.24405384063720703
time: 2.2445034980773926
[1, 13833] loss_train: 0.007131, loss_test: 0.005588
time: 0.24405336380004883
time: 2.242501974105835
[1, 13834] loss_train: 0.007080, loss_test: 0.005592
time: 0.24605417251586914
time: 2.2274982929229736
[1, 13835] loss_train: 0.008504, loss_test: 0.005593
time: 0.2440662384033203
time: 2.2134954929351807
[1, 13836] loss_train: 0.002868, loss_test: 0.005591
time: 0.24405479431152344
time: 2.2760119438171387
[1, 13837] loss_train: 0.009912, loss_test: 0.005587
time: 0.24506688117980957
time: 2.218496322631836
[1, 13838] loss_train: 0.012364, loss_test: 0.005583
time: 0.24305462837219238
time: 2.200014352798462
[1, 13839] loss_train: 0.017980, loss_test: 0.005584
time: 0.24305391311645508
time: 2.2055113315582275
[1, 13840] loss_train: 0.008596, loss_test: 0.005583
time: 0.25705742835998535
time: 2.259507179260254
[1, 13841] loss_train: 0.007715, loss_test: 0.005582
time: 0.24805569648742676
time: 2.2124948501586914
[1, 13842] loss_train: 0.007754, loss_test: 0.005580
time: 0.2450542449951172
time: 2.235499382019043
[1, 13843] loss_train: 0.010078, loss_test: 0.005579
time: 0.2450551986694336
time: 2.2575042247772217
[1, 13844] loss_train: 0.001013, loss_test: 0.005577
time: 0.24405407905578613
time: 2.2605652809143066
[1, 13845] loss_train: 0.003261, loss_test: 0.005581
time: 0.24306583404541016
time: 2.208505153656006
[1, 13846] loss_train: 0.002788, loss_test: 0.005590
time: 0.24605512619018555
time: 2.219496488571167
[1, 13847] loss_train: 0.003186, loss_test: 0.005603
time: 0.2470550537109375
time: 2.230499029159546
[1, 13848] loss_train: 0.012322, loss_test: 0.005612
time: 0.24305367469787598
time: 2.1874890327453613
[1, 13849] loss_train: 0.006531, loss_test: 0.005616
time: 0.2470550537109375
time: 2.2224977016448975
[1, 13850] loss_train: 0.008793, loss_test: 0.005617
time: 0.2580568790435791
time: 2.2360057830810547
[1, 13851] loss_train: 0.008862, loss_test: 0.005617
time: 0.2530555725097656
time: 2.245502471923828
[1, 13852] loss_train: 0.011088, loss_test: 0.005611
time: 0.2470548152923584
time: 2.212496519088745
[1, 13853] loss_train: 0.005153, loss_test: 0.005607
time: 0.24405384063720703
time: 2.243502140045166
[1, 13854] loss_train: 0.013215, loss_test: 0.005603
time: 0.2450547218322754
time: 2.2034928798675537
[1, 13855] loss_train: 0.003074, loss_test: 0.005601
time: 0.24405360221862793
time: 2.2244977951049805
[1, 13856] loss_train: 0.005306, loss_test: 0.005595
time: 0.24405455589294434
time: 2.210502862930298
[1, 13857] loss_train: 0.006677, loss_test: 0.005592
time: 0.2440798282623291
time: 2.2004926204681396
[1, 13858] loss_train: 0.005397, loss_test: 0.005591
time: 0.24605393409729004
time: 2.216513156890869
[1, 13859] loss_train: 0.001349, loss_test: 0.005590
time: 0.24405360221862793
time: 2.2202019691467285
[1, 13860] loss_train: 0.005369, loss_test: 0.005590
time: 0.2560567855834961
time: 2.2865118980407715
[1, 13861] loss_train: 0.001681, loss_test: 0.005591
time: 0.2450542449951172
time: 2.2515037059783936
[1, 13862] loss_train: 0.003394, loss_test: 0.005594
time: 0.24305248260498047
time: 2.2295007705688477
[1, 13863] loss_train: 0.006656, loss_test: 0.005597
time: 0.24308395385742188
time: 2.219496250152588
[1, 13864] loss_train: 0.008342, loss_test: 0.005601
time: 0.24405407905578613
time: 2.2405014038085938
[1, 13865] loss_train: 0.001700, loss_test: 0.005605
time: 0.24805498123168945
time: 2.235499858856201
[1, 13866] loss_train: 0.015891, loss_test: 0.005605
time: 0.2450542449951172
time: 2.2154958248138428
[1, 13867] loss_train: 0.003363, loss_test: 0.005605
time: 0.24305391311645508
time: 2.246029853820801
[1, 13868] loss_train: 0.004008, loss_test: 0.005606
time: 0.2470552921295166
time: 2.2224984169006348
[1, 13869] loss_train: 0.005736, loss_test: 0.005607
time: 0.24605560302734375
time: 2.2124948501586914
[1, 13870] loss_train: 0.003838, loss_test: 0.005608
time: 0.25705695152282715
time: 2.248521566390991
[1, 13871] loss_train: 0.012002, loss_test: 0.005600
time: 0.2470543384552002
time: 2.2244982719421387
[1, 13872] loss_train: 0.004206, loss_test: 0.005594
time: 0.24405360221862793
time: 2.2134974002838135
[1, 13873] loss_train: 0.006644, loss_test: 0.005590
time: 0.2450544834136963
time: 2.2224979400634766
[1, 13874] loss_train: 0.007164, loss_test: 0.005587
time: 0.24405336380004883
time: 2.2515060901641846
[1, 13875] loss_train: 0.008485, loss_test: 0.005585
time: 0.2460634708404541
time: 2.2525041103363037
[1, 13876] loss_train: 0.007277, loss_test: 0.005583
time: 0.24405407905578613
time: 2.204493761062622
[1, 13877] loss_train: 0.007791, loss_test: 0.005583
time: 0.24305415153503418
time: 2.245501756668091
[1, 13878] loss_train: 0.005746, loss_test: 0.005584
time: 0.24405431747436523
time: 2.2144956588745117
[1, 13879] loss_train: 0.002643, loss_test: 0.005586
time: 0.24405431747436523
time: 2.195490598678589
[1, 13880] loss_train: 0.004664, loss_test: 0.005589
time: 0.2580573558807373
time: 2.2312119007110596
[1, 13881] loss_train: 0.003268, loss_test: 0.005589
time: 0.24608182907104492
time: 2.2490074634552
[1, 13882] loss_train: 0.005218, loss_test: 0.005589
time: 0.24605464935302734
time: 2.2005014419555664
[1, 13883] loss_train: 0.005182, loss_test: 0.005591
time: 0.24405360221862793
time: 2.2044930458068848
[1, 13884] loss_train: 0.005806, loss_test: 0.005595
time: 0.24406766891479492
time: 2.220496892929077
[1, 13885] loss_train: 0.008860, loss_test: 0.005599
time: 0.24506640434265137
time: 2.228498935699463
[1, 13886] loss_train: 0.004072, loss_test: 0.005603
time: 0.24806666374206543
time: 2.2235145568847656
[1, 13887] loss_train: 0.006917, loss_test: 0.005606
time: 0.24305438995361328
time: 2.225496768951416
[1, 13888] loss_train: 0.009101, loss_test: 0.005612
time: 0.24805641174316406
time: 2.259505271911621
[1, 13889] loss_train: 0.002365, loss_test: 0.005616
time: 0.25205540657043457
time: 2.243039131164551
[1, 13890] loss_train: 0.011500, loss_test: 0.005621
time: 0.26205873489379883
time: 2.288529872894287
[1, 13891] loss_train: 0.003109, loss_test: 0.005627
time: 0.24605464935302734
time: 2.231499433517456
[1, 13892] loss_train: 0.003464, loss_test: 0.005636
time: 0.2510552406311035
time: 2.252504348754883
[1, 13893] loss_train: 0.010910, loss_test: 0.005633
time: 0.24405384063720703
time: 2.246502161026001
[1, 13894] loss_train: 0.002051, loss_test: 0.005630
time: 0.25005626678466797
time: 2.2284984588623047
[1, 13895] loss_train: 0.009618, loss_test: 0.005623
time: 0.2470545768737793
time: 2.231499433517456
[1, 13896] loss_train: 0.008189, loss_test: 0.005615
time: 0.2470543384552002
time: 2.203808546066284
[1, 13897] loss_train: 0.007778, loss_test: 0.005609
time: 0.24305415153503418
time: 2.1954917907714844
[1, 13898] loss_train: 0.002620, loss_test: 0.005601
time: 0.24405407905578613
time: 2.2425007820129395
[1, 13899] loss_train: 0.005391, loss_test: 0.005598
time: 0.24405527114868164
time: 2.2140026092529297
[1, 13900] loss_train: 0.013158, loss_test: 0.005597
time: 0.2560563087463379
time: 2.2538251876831055
[1, 13901] loss_train: 0.006234, loss_test: 0.005600
time: 0.2450544834136963
time: 2.2421724796295166
[1, 13902] loss_train: 0.009827, loss_test: 0.005606
time: 0.24805521965026855
time: 2.243501663208008
[1, 13903] loss_train: 0.009680, loss_test: 0.005616
time: 0.24406790733337402
time: 2.2307519912719727
[1, 13904] loss_train: 0.005897, loss_test: 0.005622
time: 0.24406933784484863
time: 2.21449613571167
[1, 13905] loss_train: 0.005751, loss_test: 0.005628
time: 0.24305367469787598
time: 2.2114949226379395
[1, 13906] loss_train: 0.001240, loss_test: 0.005633
time: 0.2470545768737793
time: 2.1954922676086426
[1, 13907] loss_train: 0.003359, loss_test: 0.005628
time: 0.24505352973937988
time: 2.2074944972991943
[1, 13908] loss_train: 0.001515, loss_test: 0.005611
time: 0.24605417251586914
time: 2.219496250152588
[1, 13909] loss_train: 0.008375, loss_test: 0.005600
time: 0.24605560302734375
time: 2.22049617767334
[1, 13910] loss_train: 0.004872, loss_test: 0.005596
time: 0.258056640625
time: 2.2695083618164062
[1, 13911] loss_train: 0.011070, loss_test: 0.005595
time: 0.24805521965026855
time: 2.2435014247894287
[1, 13912] loss_train: 0.006102, loss_test: 0.005596
time: 0.24606895446777344
time: 2.2264978885650635
[1, 13913] loss_train: 0.012523, loss_test: 0.005594
time: 0.25006747245788574
time: 2.235511064529419
[1, 13914] loss_train: 0.006365, loss_test: 0.005591
time: 0.24405431747436523
time: 2.2405028343200684
[1, 13915] loss_train: 0.000866, loss_test: 0.005589
time: 0.24605417251586914
time: 2.223512649536133
[1, 13916] loss_train: 0.005202, loss_test: 0.005587
time: 0.24805498123168945
time: 2.2224974632263184
[1, 13917] loss_train: 0.006719, loss_test: 0.005586
time: 0.24405384063720703
time: 2.197514295578003
[1, 13918] loss_train: 0.010021, loss_test: 0.005586
time: 0.24405407905578613
time: 2.1844892501831055
[1, 13919] loss_train: 0.008831, loss_test: 0.005585
time: 0.24505376815795898
time: 2.2264981269836426
[1, 13920] loss_train: 0.004236, loss_test: 0.005583
time: 0.2560577392578125
time: 2.2204997539520264
[1, 13921] loss_train: 0.010507, loss_test: 0.005583
time: 0.24305343627929688
time: 2.247518539428711
[1, 13922] loss_train: 0.001413, loss_test: 0.005584
time: 0.2440662384033203
time: 2.2204995155334473
[1, 13923] loss_train: 0.004175, loss_test: 0.005588
time: 0.24605417251586914
time: 2.2421419620513916
[1, 13924] loss_train: 0.001337, loss_test: 0.005594
time: 0.24406790733337402
time: 2.234501600265503
[1, 13925] loss_train: 0.013882, loss_test: 0.005597
time: 0.24605941772460938
time: 2.230548143386841
[1, 13926] loss_train: 0.007531, loss_test: 0.005587
time: 0.24405384063720703
time: 2.2365000247955322
[1, 13927] loss_train: 0.007053, loss_test: 0.005579
time: 0.2440938949584961
time: 2.233711004257202
[1, 13928] loss_train: 0.006298, loss_test: 0.005577
time: 0.24405384063720703
time: 2.270507574081421
[1, 13929] loss_train: 0.004619, loss_test: 0.005578
time: 0.2450547218322754
time: 2.1841025352478027
[1, 13930] loss_train: 0.005669, loss_test: 0.005582
time: 0.25905704498291016
time: 2.2825114727020264
[1, 13931] loss_train: 0.004539, loss_test: 0.005587
time: 0.24505400657653809
time: 2.267507553100586
[1, 13932] loss_train: 0.005433, loss_test: 0.005589
time: 0.24505376815795898
time: 2.2104971408843994
[1, 13933] loss_train: 0.007876, loss_test: 0.005589
time: 0.24605488777160645
time: 2.2174954414367676
[1, 13934] loss_train: 0.009557, loss_test: 0.005589
time: 0.25206971168518066
time: 2.2615058422088623
[1, 13935] loss_train: 0.007977, loss_test: 0.005591
time: 0.24305391311645508
time: 2.2470219135284424
[1, 13936] loss_train: 0.007203, loss_test: 0.005594
time: 0.24805450439453125
time: 2.243502378463745
[1, 13937] loss_train: 0.003746, loss_test: 0.005599
time: 0.2450547218322754
time: 2.2340028285980225
[1, 13938] loss_train: 0.003508, loss_test: 0.005600
time: 0.2470557689666748
time: 2.249504566192627
[1, 13939] loss_train: 0.002819, loss_test: 0.005603
time: 0.2450544834136963
time: 2.2560105323791504
[1, 13940] loss_train: 0.018002, loss_test: 0.005610
time: 0.25905776023864746
time: 2.2505035400390625
[1, 13941] loss_train: 0.007021, loss_test: 0.005617
time: 0.24805426597595215
time: 2.211520195007324
[1, 13942] loss_train: 0.008305, loss_test: 0.005626
time: 0.2450544834136963
time: 2.2174952030181885
[1, 13943] loss_train: 0.006079, loss_test: 0.005629
time: 0.24405527114868164
time: 2.2545039653778076
[1, 13944] loss_train: 0.004297, loss_test: 0.005629
time: 0.24657225608825684
time: 2.2244977951049805
[1, 13945] loss_train: 0.006213, loss_test: 0.005626
time: 0.2450544834136963
time: 2.214020252227783
[1, 13946] loss_train: 0.001268, loss_test: 0.005614
time: 0.24606585502624512
time: 2.218000650405884
[1, 13947] loss_train: 0.006006, loss_test: 0.005606
time: 0.24505329132080078
time: 2.227498769760132
[1, 13948] loss_train: 0.006008, loss_test: 0.005600
time: 0.24405384063720703
time: 2.2535035610198975
[1, 13949] loss_train: 0.008772, loss_test: 0.005599
time: 0.24305415153503418
time: 2.2285008430480957
[1, 13950] loss_train: 0.003853, loss_test: 0.005601
time: 0.25505661964416504
time: 2.2405011653900146
[1, 13951] loss_train: 0.010504, loss_test: 0.005604
time: 0.24405384063720703
time: 2.2365007400512695
[1, 13952] loss_train: 0.006414, loss_test: 0.005609
time: 0.24405455589294434
time: 2.219496488571167
[1, 13953] loss_train: 0.011988, loss_test: 0.005617
time: 0.2470552921295166
time: 2.2254974842071533
[1, 13954] loss_train: 0.009957, loss_test: 0.005624
time: 0.246079683303833
time: 2.2715084552764893
[1, 13955] loss_train: 0.007417, loss_test: 0.005630
time: 0.24405407905578613
time: 2.2044925689697266
[1, 13956] loss_train: 0.001611, loss_test: 0.005638
time: 0.2450551986694336
time: 2.245501756668091
[1, 13957] loss_train: 0.003062, loss_test: 0.005633
time: 0.24505376815795898
time: 2.206494092941284
[1, 13958] loss_train: 0.006266, loss_test: 0.005630
time: 0.24457883834838867
time: 2.2334988117218018
[1, 13959] loss_train: 0.013352, loss_test: 0.005620
time: 0.24605417251586914
time: 2.232755184173584
[1, 13960] loss_train: 0.005304, loss_test: 0.005612
time: 0.25905656814575195
time: 2.252504348754883
[1, 13961] loss_train: 0.009847, loss_test: 0.005602
time: 0.24406838417053223
time: 2.234502077102661
[1, 13962] loss_train: 0.006971, loss_test: 0.005592
time: 0.24605369567871094
time: 2.2175071239471436
[1, 13963] loss_train: 0.010950, loss_test: 0.005585
time: 0.2510566711425781
time: 2.2535037994384766
[1, 13964] loss_train: 0.005112, loss_test: 0.005581
time: 0.24509549140930176
time: 2.215496063232422
[1, 13965] loss_train: 0.004502, loss_test: 0.005580
time: 0.2470543384552002
time: 2.2274985313415527
[1, 13966] loss_train: 0.011080, loss_test: 0.005582
time: 0.24405431747436523
time: 2.2415130138397217
[1, 13967] loss_train: 0.000989, loss_test: 0.005583
time: 0.24805474281311035
time: 2.2234976291656494
[1, 13968] loss_train: 0.003805, loss_test: 0.005584
time: 0.24405479431152344
time: 2.1995081901550293
[1, 13969] loss_train: 0.000741, loss_test: 0.005582
time: 0.24405384063720703
time: 2.2134957313537598
[1, 13970] loss_train: 0.005463, loss_test: 0.005582
time: 0.258056640625
time: 2.266028642654419
[1, 13971] loss_train: 0.003956, loss_test: 0.005583
time: 0.24405431747436523
time: 2.232499122619629
[1, 13972] loss_train: 0.001241, loss_test: 0.005584
time: 0.2450544834136963
time: 2.2305147647857666
[1, 13973] loss_train: 0.002699, loss_test: 0.005588
time: 0.2470545768737793
time: 2.241501569747925
[1, 13974] loss_train: 0.010018, loss_test: 0.005596
time: 0.2450544834136963
time: 2.2525031566619873
[1, 13975] loss_train: 0.002284, loss_test: 0.005607
time: 0.24405503273010254
time: 2.2545039653778076
[1, 13976] loss_train: 0.002899, loss_test: 0.005622
time: 0.2490556240081787
time: 2.2155046463012695
[1, 13977] loss_train: 0.006612, loss_test: 0.005641
time: 0.24405407905578613
time: 2.208503007888794
[1, 13978] loss_train: 0.012489, loss_test: 0.005650
time: 0.24405384063720703
time: 2.207057476043701
[1, 13979] loss_train: 0.001064, loss_test: 0.005664
time: 0.24305367469787598
time: 2.229532241821289
[1, 13980] loss_train: 0.010862, loss_test: 0.005669
time: 0.25905728340148926
time: 2.2495036125183105
[1, 13981] loss_train: 0.003611, loss_test: 0.005669
time: 0.2440659999847412
time: 2.2004923820495605
[1, 13982] loss_train: 0.013861, loss_test: 0.005666
time: 0.24505400657653809
time: 2.2510063648223877
[1, 13983] loss_train: 0.005672, loss_test: 0.005659
time: 0.24605441093444824
time: 2.203493118286133
[1, 13984] loss_train: 0.008186, loss_test: 0.005644
time: 0.24867701530456543
time: 2.227498769760132
[1, 13985] loss_train: 0.009927, loss_test: 0.005635
time: 0.24505376815795898
time: 2.2485036849975586
[1, 13986] loss_train: 0.008393, loss_test: 0.005634
time: 0.24605011940002441
time: 2.222496509552002
[1, 13987] loss_train: 0.002663, loss_test: 0.005639
time: 0.25005483627319336
time: 2.230499267578125
[1, 13988] loss_train: 0.006178, loss_test: 0.005642
time: 0.2470550537109375
time: 2.2122199535369873
[1, 13989] loss_train: 0.004798, loss_test: 0.005637
time: 0.24605536460876465
time: 2.218867540359497
[1, 13990] loss_train: 0.006757, loss_test: 0.005627
time: 0.25505685806274414
time: 2.218496322631836
[1, 13991] loss_train: 0.008984, loss_test: 0.005617
time: 0.2470545768737793
time: 2.24650502204895
[1, 13992] loss_train: 0.002841, loss_test: 0.005607
time: 0.24306774139404297
time: 2.2234981060028076
[1, 13993] loss_train: 0.003001, loss_test: 0.005597
time: 0.24305415153503418
time: 2.2154948711395264
[1, 13994] loss_train: 0.007285, loss_test: 0.005592
time: 0.24605321884155273
time: 2.249035358428955
[1, 13995] loss_train: 0.007449, loss_test: 0.005590
time: 0.24405431747436523
time: 2.2174954414367676
[1, 13996] loss_train: 0.004706, loss_test: 0.005592
time: 0.2450544834136963
time: 2.233513355255127
[1, 13997] loss_train: 0.007331, loss_test: 0.005588
time: 0.24405360221862793
time: 2.2375030517578125
[1, 13998] loss_train: 0.004342, loss_test: 0.005585
time: 0.2430577278137207
time: 2.229501485824585
[1, 13999] loss_train: 0.005844, loss_test: 0.005583
time: 0.24405479431152344
time: 2.245501756668091
[1, 14000] loss_train: 0.014210, loss_test: 0.005578
time: 0.256056547164917
time: 2.256504535675049
[1, 14001] loss_train: 0.008750, loss_test: 0.005574
time: 0.24405431747436523
time: 2.214494228363037
[1, 14002] loss_train: 0.001532, loss_test: 0.005573
time: 0.24306726455688477
time: 2.230511426925659
[1, 14003] loss_train: 0.005815, loss_test: 0.005571
time: 0.24605393409729004
time: 2.2224974632263184
[1, 14004] loss_train: 0.008649, loss_test: 0.005570
time: 0.24606633186340332
time: 2.2365005016326904
[1, 14005] loss_train: 0.007806, loss_test: 0.005572
time: 0.24606800079345703
time: 2.1994926929473877
[1, 14006] loss_train: 0.006919, loss_test: 0.005574
time: 0.24506521224975586
time: 2.229498863220215
[1, 14007] loss_train: 0.002769, loss_test: 0.005578
time: 0.2470555305480957
time: 2.235499382019043
[1, 14008] loss_train: 0.007727, loss_test: 0.005582
time: 0.24506855010986328
time: 2.2655062675476074
[1, 14009] loss_train: 0.004737, loss_test: 0.005586
time: 0.2490549087524414
time: 2.2224984169006348
[1, 14010] loss_train: 0.000494, loss_test: 0.005592
time: 0.25905680656433105
time: 2.2645063400268555
[1, 14011] loss_train: 0.004019, loss_test: 0.005598
time: 0.25005531311035156
time: 2.2635068893432617
[1, 14012] loss_train: 0.004335, loss_test: 0.005605
time: 0.24405431747436523
time: 2.2274980545043945
[1, 14013] loss_train: 0.003600, loss_test: 0.005616
time: 0.24805545806884766
time: 2.2039954662323
[1, 14014] loss_train: 0.014009, loss_test: 0.005603
time: 0.24305415153503418
time: 2.233499050140381
[1, 14015] loss_train: 0.008996, loss_test: 0.005597
time: 0.2450547218322754
time: 2.19649076461792
[1, 14016] loss_train: 0.001818, loss_test: 0.005592
time: 0.2450547218322754
time: 2.2395009994506836
[1, 14017] loss_train: 0.006903, loss_test: 0.005591
time: 0.24505400657653809
time: 2.1994926929473877
[1, 14018] loss_train: 0.015291, loss_test: 0.005585
time: 0.24605417251586914
time: 2.2274985313415527
[1, 14019] loss_train: 0.007719, loss_test: 0.005583
time: 0.24405431747436523
time: 2.219515800476074
[1, 14020] loss_train: 0.011304, loss_test: 0.005584
time: 0.2560563087463379
time: 2.253504753112793
[1, 14021] loss_train: 0.007124, loss_test: 0.005590
time: 0.24405431747436523
time: 2.22902512550354
[1, 14022] loss_train: 0.004748, loss_test: 0.005596
time: 0.24405384063720703
time: 2.218010663986206
[1, 14023] loss_train: 0.010507, loss_test: 0.005607
time: 0.24405407905578613
time: 2.2485029697418213
[1, 14024] loss_train: 0.004497, loss_test: 0.005616
time: 0.24405384063720703
time: 2.2405011653900146
[1, 14025] loss_train: 0.010360, loss_test: 0.005628
time: 0.2450547218322754
time: 2.2264981269836426
[1, 14026] loss_train: 0.007077, loss_test: 0.005645
time: 0.24405598640441895
time: 2.1854889392852783
[1, 14027] loss_train: 0.006481, loss_test: 0.005650
time: 0.2470543384552002
time: 2.2165122032165527
[1, 14028] loss_train: 0.005563, loss_test: 0.005648
time: 0.24705743789672852
time: 2.257504940032959
[1, 14029] loss_train: 0.004506, loss_test: 0.005641
time: 0.24405407905578613
time: 2.2114946842193604
[1, 14030] loss_train: 0.003054, loss_test: 0.005622
time: 0.2600579261779785
time: 2.2555043697357178
[1, 14031] loss_train: 0.007858, loss_test: 0.005602
time: 0.24605417251586914
time: 2.2585055828094482
[1, 14032] loss_train: 0.004373, loss_test: 0.005587
time: 0.24605512619018555
time: 2.224496364593506
[1, 14033] loss_train: 0.004125, loss_test: 0.005579
time: 0.24405455589294434
time: 2.21449613571167
[1, 14034] loss_train: 0.012083, loss_test: 0.005578
time: 0.2440657615661621
time: 2.233499526977539
[1, 14035] loss_train: 0.004570, loss_test: 0.005582
time: 0.2450542449951172
time: 2.242501974105835
[1, 14036] loss_train: 0.005009, loss_test: 0.005592
time: 0.2450551986694336
time: 2.213496685028076
[1, 14037] loss_train: 0.001350, loss_test: 0.005607
time: 0.2450547218322754
time: 2.2445032596588135
[1, 14038] loss_train: 0.008240, loss_test: 0.005613
time: 0.2450547218322754
time: 2.2525064945220947
[1, 14039] loss_train: 0.011000, loss_test: 0.005608
time: 0.24405455589294434
time: 2.2004919052124023
[1, 14040] loss_train: 0.010457, loss_test: 0.005596
time: 0.25705623626708984
time: 2.28351092338562
[1, 14041] loss_train: 0.013834, loss_test: 0.005584
time: 0.2450547218322754
time: 2.2244999408721924
[1, 14042] loss_train: 0.004678, loss_test: 0.005578
time: 0.24605464935302734
time: 2.2004926204681396
[1, 14043] loss_train: 0.004015, loss_test: 0.005574
time: 0.24405336380004883
time: 2.234099864959717
[1, 14044] loss_train: 0.005510, loss_test: 0.005572
time: 0.24405455589294434
time: 2.243004322052002
[1, 14045] loss_train: 0.009922, loss_test: 0.005572
time: 0.2450542449951172
time: 2.229499101638794
[1, 14046] loss_train: 0.005915, loss_test: 0.005575
time: 0.24706721305847168
time: 2.2305033206939697
[1, 14047] loss_train: 0.008654, loss_test: 0.005581
time: 0.24405431747436523
time: 2.2245094776153564
[1, 14048] loss_train: 0.005390, loss_test: 0.005588
time: 0.24406766891479492
time: 2.2114949226379395
[1, 14049] loss_train: 0.001227, loss_test: 0.005594
time: 0.2470545768737793
time: 2.260528087615967
[1, 14050] loss_train: 0.006722, loss_test: 0.005598
time: 0.2580695152282715
time: 2.254504680633545
[1, 14051] loss_train: 0.010741, loss_test: 0.005605
time: 0.24506807327270508
time: 2.205493688583374
[1, 14052] loss_train: 0.005883, loss_test: 0.005609
time: 0.2470557689666748
time: 2.196491003036499
[1, 14053] loss_train: 0.012346, loss_test: 0.005613
time: 0.24505400657653809
time: 2.2234976291656494
[1, 14054] loss_train: 0.013008, loss_test: 0.005617
time: 0.24305367469787598
time: 2.2254981994628906
[1, 14055] loss_train: 0.005073, loss_test: 0.005617
time: 0.24508070945739746
time: 2.2274982929229736
[1, 14056] loss_train: 0.011367, loss_test: 0.005620
time: 0.24405360221862793
time: 2.239501714706421
[1, 14057] loss_train: 0.014158, loss_test: 0.005620
time: 0.24505949020385742
time: 2.2625057697296143
[1, 14058] loss_train: 0.001462, loss_test: 0.005621
time: 0.24305343627929688
time: 2.229499101638794
[1, 14059] loss_train: 0.002249, loss_test: 0.005623
time: 0.2450544834136963
time: 2.218496322631836
[1, 14060] loss_train: 0.004438, loss_test: 0.005629
time: 0.2530558109283447
time: 2.242502212524414
[1, 14061] loss_train: 0.011555, loss_test: 0.005643
time: 0.2450547218322754
time: 2.2174954414367676
[1, 14062] loss_train: 0.013199, loss_test: 0.005647
time: 0.24405360221862793
time: 2.257505416870117
[1, 14063] loss_train: 0.007243, loss_test: 0.005650
time: 0.24305438995361328
time: 2.248502731323242
[1, 14064] loss_train: 0.010116, loss_test: 0.005647
time: 0.24305486679077148
time: 2.24550199508667
[1, 14065] loss_train: 0.015144, loss_test: 0.005637
time: 0.24405312538146973
time: 2.224135160446167
[1, 14066] loss_train: 0.007864, loss_test: 0.005635
time: 0.2450542449951172
time: 2.221496105194092
[1, 14067] loss_train: 0.003361, loss_test: 0.005635
time: 0.24406814575195312
time: 2.205507516860962
[1, 14068] loss_train: 0.001805, loss_test: 0.005628
time: 0.24406862258911133
time: 2.2465462684631348
[1, 14069] loss_train: 0.009564, loss_test: 0.005619
time: 0.24805426597595215
time: 2.2215170860290527
[1, 14070] loss_train: 0.001868, loss_test: 0.005611
time: 0.2560560703277588
time: 2.2635066509246826
[1, 14071] loss_train: 0.009343, loss_test: 0.005609
time: 0.24606847763061523
time: 2.2252719402313232
[1, 14072] loss_train: 0.005460, loss_test: 0.005609
time: 0.24406099319458008
time: 2.2224977016448975
[1, 14073] loss_train: 0.010386, loss_test: 0.005611
time: 0.24506711959838867
time: 2.2355000972747803
[1, 14074] loss_train: 0.004382, loss_test: 0.005608
time: 0.24605512619018555
time: 2.1845011711120605
[1, 14075] loss_train: 0.005924, loss_test: 0.005608
time: 0.24305462837219238
time: 2.2044928073883057
[1, 14076] loss_train: 0.003642, loss_test: 0.005606
time: 0.2470550537109375
time: 2.2318737506866455
[1, 14077] loss_train: 0.000590, loss_test: 0.005600
time: 0.2430567741394043
time: 2.2114951610565186
[1, 14078] loss_train: 0.002200, loss_test: 0.005588
time: 0.24305391311645508
time: 2.230502128601074
[1, 14079] loss_train: 0.001431, loss_test: 0.005584
time: 0.24305391311645508
time: 2.2034926414489746
[1, 14080] loss_train: 0.003382, loss_test: 0.005591
time: 0.2600581645965576
time: 2.2495028972625732
[1, 14081] loss_train: 0.002335, loss_test: 0.005609
time: 0.24305367469787598
time: 2.2204971313476562
[1, 14082] loss_train: 0.006837, loss_test: 0.005627
time: 0.24605417251586914
time: 2.235020160675049
[1, 14083] loss_train: 0.008177, loss_test: 0.005644
time: 0.2470557689666748
time: 2.2240021228790283
[1, 14084] loss_train: 0.005406, loss_test: 0.005657
time: 0.24405384063720703
time: 2.2214980125427246
[1, 14085] loss_train: 0.011490, loss_test: 0.005669
time: 0.24406766891479492
time: 2.2425012588500977
[1, 14086] loss_train: 0.003822, loss_test: 0.005684
time: 0.2450547218322754
time: 2.2014925479888916
[1, 14087] loss_train: 0.016447, loss_test: 0.005694
time: 0.24406647682189941
time: 2.2134947776794434
[1, 14088] loss_train: 0.002275, loss_test: 0.005703
time: 0.24405455589294434
time: 2.2390074729919434
[1, 14089] loss_train: 0.010619, loss_test: 0.005698
time: 0.24805474281311035
time: 2.2090096473693848
[1, 14090] loss_train: 0.004816, loss_test: 0.005674
time: 0.2600581645965576
time: 2.236499786376953
[1, 14091] loss_train: 0.005658, loss_test: 0.005651
time: 0.24805474281311035
time: 2.217496633529663
[1, 14092] loss_train: 0.005256, loss_test: 0.005630
time: 0.2450549602508545
time: 2.248023509979248
[1, 14093] loss_train: 0.002152, loss_test: 0.005614
time: 0.24605417251586914
time: 2.2525110244750977
[1, 14094] loss_train: 0.003764, loss_test: 0.005602
time: 0.2500488758087158
time: 2.23349928855896
[1, 14095] loss_train: 0.003340, loss_test: 0.005595
time: 0.24506878852844238
time: 2.208493947982788
[1, 14096] loss_train: 0.009041, loss_test: 0.005590
time: 0.2450547218322754
time: 2.267507314682007
[1, 14097] loss_train: 0.003406, loss_test: 0.005586
time: 0.24405407905578613
time: 2.2274985313415527
[1, 14098] loss_train: 0.009275, loss_test: 0.005587
time: 0.24505376815795898
time: 2.2369439601898193
[1, 14099] loss_train: 0.004470, loss_test: 0.005588
time: 0.24405455589294434
time: 2.2029953002929688
[1, 14100] loss_train: 0.003304, loss_test: 0.005590
time: 0.25908637046813965
time: 2.2372653484344482
[1, 14101] loss_train: 0.003863, loss_test: 0.005592
time: 0.25005578994750977
time: 2.219496250152588
[1, 14102] loss_train: 0.001835, loss_test: 0.005600
time: 0.24605393409729004
time: 2.2294998168945312
[1, 14103] loss_train: 0.003245, loss_test: 0.005606
time: 0.24505877494812012
time: 2.223003387451172
[1, 14104] loss_train: 0.006816, loss_test: 0.005614
time: 0.24405336380004883
time: 2.218496561050415
[1, 14105] loss_train: 0.005409, loss_test: 0.005621
time: 0.24406695365905762
time: 2.205493211746216
[1, 14106] loss_train: 0.003359, loss_test: 0.005632
time: 0.24405384063720703
time: 2.2405011653900146
[1, 14107] loss_train: 0.007310, loss_test: 0.005639
time: 0.24606680870056152
time: 2.229501724243164
[1, 14108] loss_train: 0.003429, loss_test: 0.005647
time: 0.24405455589294434
time: 2.210493803024292
[1, 14109] loss_train: 0.002019, loss_test: 0.005656
time: 0.24405431747436523
time: 2.2094950675964355
[1, 14110] loss_train: 0.002461, loss_test: 0.005668
time: 0.2740600109100342
time: 2.267509698867798
[1, 14111] loss_train: 0.001266, loss_test: 0.005681
time: 0.2510678768157959
time: 2.229498863220215
[1, 14112] loss_train: 0.001007, loss_test: 0.005699
time: 0.24605512619018555
time: 2.2174978256225586
[1, 14113] loss_train: 0.007009, loss_test: 0.005705
time: 0.24505376815795898
time: 2.2004926204681396
[1, 14114] loss_train: 0.004437, loss_test: 0.005698
time: 0.2490546703338623
time: 2.193000316619873
[1, 14115] loss_train: 0.012548, loss_test: 0.005665
time: 0.24405455589294434
time: 2.2094931602478027
[1, 14116] loss_train: 0.001075, loss_test: 0.005643
time: 0.24408340454101562
time: 2.216495990753174
[1, 14117] loss_train: 0.002519, loss_test: 0.005627
time: 0.24405336380004883
time: 2.217496395111084
[1, 14118] loss_train: 0.004110, loss_test: 0.005616
time: 0.2450544834136963
time: 2.217012882232666
[1, 14119] loss_train: 0.012811, loss_test: 0.005602
time: 0.24405384063720703
time: 2.2515039443969727
[1, 14120] loss_train: 0.011642, loss_test: 0.005597
time: 0.2560563087463379
time: 2.254504919052124
[1, 14121] loss_train: 0.004827, loss_test: 0.005604
time: 0.24705934524536133
time: 2.2014918327331543
[1, 14122] loss_train: 0.000933, loss_test: 0.005612
time: 0.24588942527770996
time: 2.2294983863830566
[1, 14123] loss_train: 0.005738, loss_test: 0.005615
time: 0.24305462837219238
time: 2.2144970893859863
[1, 14124] loss_train: 0.001475, loss_test: 0.005619
time: 0.24605512619018555
time: 2.248502731323242
[1, 14125] loss_train: 0.003575, loss_test: 0.005610
time: 0.24405455589294434
time: 2.2054951190948486
[1, 14126] loss_train: 0.016680, loss_test: 0.005603
time: 0.24407005310058594
time: 2.211505174636841
[1, 14127] loss_train: 0.008390, loss_test: 0.005595
time: 0.24605441093444824
time: 2.217498540878296
[1, 14128] loss_train: 0.012515, loss_test: 0.005584
time: 0.2490682601928711
time: 2.22149658203125
[1, 14129] loss_train: 0.002610, loss_test: 0.005574
time: 0.24605512619018555
time: 2.260505199432373
[1, 14130] loss_train: 0.005823, loss_test: 0.005567
time: 0.25505661964416504
time: 2.2645063400268555
[1, 14131] loss_train: 0.002064, loss_test: 0.005567
time: 0.24605417251586914
time: 2.219498872756958
[1, 14132] loss_train: 0.014574, loss_test: 0.005574
time: 0.24505400657653809
time: 2.2395710945129395
[1, 14133] loss_train: 0.010406, loss_test: 0.005585
time: 0.2450549602508545
time: 2.2324984073638916
[1, 14134] loss_train: 0.006705, loss_test: 0.005590
time: 0.24605536460876465
time: 2.247502326965332
[1, 14135] loss_train: 0.002970, loss_test: 0.005593
time: 0.24405479431152344
time: 2.196491003036499
[1, 14136] loss_train: 0.003483, loss_test: 0.005599
time: 0.24305343627929688
time: 2.225501537322998
[1, 14137] loss_train: 0.010592, loss_test: 0.005599
time: 0.24405431747436523
time: 2.2244999408721924
[1, 14138] loss_train: 0.003095, loss_test: 0.005600
time: 0.24608230590820312
time: 2.231498956680298
[1, 14139] loss_train: 0.000962, loss_test: 0.005600
time: 0.24305343627929688
time: 2.2090237140655518
[1, 14140] loss_train: 0.005578, loss_test: 0.005599
time: 0.2540557384490967
time: 2.253504514694214
[1, 14141] loss_train: 0.007843, loss_test: 0.005595
time: 0.24707269668579102
time: 2.2294986248016357
[1, 14142] loss_train: 0.005558, loss_test: 0.005593
time: 0.24306917190551758
time: 2.206493616104126
[1, 14143] loss_train: 0.007220, loss_test: 0.005592
time: 0.24405503273010254
time: 2.233503818511963
[1, 14144] loss_train: 0.015956, loss_test: 0.005583
time: 0.2450547218322754
time: 2.232499122619629
[1, 14145] loss_train: 0.008896, loss_test: 0.005582
time: 0.24805498123168945
time: 2.2095110416412354
[1, 14146] loss_train: 0.006652, loss_test: 0.005582
time: 0.24605393409729004
time: 2.2215349674224854
[1, 14147] loss_train: 0.010167, loss_test: 0.005582
time: 0.24605655670166016
time: 2.2094943523406982
[1, 14148] loss_train: 0.004004, loss_test: 0.005583
time: 0.24605441093444824
time: 2.1884899139404297
[1, 14149] loss_train: 0.003801, loss_test: 0.005584
time: 0.24305486679077148
time: 2.209024429321289
[1, 14150] loss_train: 0.004111, loss_test: 0.005584
time: 0.25505638122558594
time: 2.251516342163086
[1, 14151] loss_train: 0.002682, loss_test: 0.005584
time: 0.24605345726013184
time: 2.228501319885254
[1, 14152] loss_train: 0.002498, loss_test: 0.005584
time: 0.24605393409729004
time: 2.2780141830444336
[1, 14153] loss_train: 0.001328, loss_test: 0.005585
time: 0.24405407905578613
time: 2.2044928073883057
[1, 14154] loss_train: 0.006174, loss_test: 0.005586
time: 0.24405384063720703
time: 2.2144949436187744
[1, 14155] loss_train: 0.008031, loss_test: 0.005589
time: 0.24405407905578613
time: 2.2500181198120117
[1, 14156] loss_train: 0.003597, loss_test: 0.005592
time: 0.2470550537109375
time: 2.2415010929107666
[1, 14157] loss_train: 0.004442, loss_test: 0.005595
time: 0.24406671524047852
time: 2.2282814979553223
[1, 14158] loss_train: 0.008427, loss_test: 0.005594
time: 0.24405431747436523
time: 2.222496271133423
[1, 14159] loss_train: 0.008729, loss_test: 0.005589
time: 0.24405360221862793
time: 2.2115113735198975
[1, 14160] loss_train: 0.011006, loss_test: 0.005582
time: 0.25705671310424805
time: 2.227498769760132
[1, 14161] loss_train: 0.006212, loss_test: 0.005577
time: 0.24305367469787598
time: 2.1994919776916504
[1, 14162] loss_train: 0.007819, loss_test: 0.005575
time: 0.2470545768737793
time: 2.203493356704712
[1, 14163] loss_train: 0.005236, loss_test: 0.005574
time: 0.2510688304901123
time: 2.2109978199005127
[1, 14164] loss_train: 0.007428, loss_test: 0.005574
time: 0.24605441093444824
time: 2.2375006675720215
[1, 14165] loss_train: 0.010909, loss_test: 0.005575
time: 0.24805593490600586
time: 2.2685632705688477
[1, 14166] loss_train: 0.005063, loss_test: 0.005576
time: 0.24405384063720703
time: 2.232510805130005
[1, 14167] loss_train: 0.006776, loss_test: 0.005576
time: 0.25005531311035156
time: 2.2084946632385254
[1, 14168] loss_train: 0.008956, loss_test: 0.005577
time: 0.2440509796142578
time: 2.2375009059906006
[1, 14169] loss_train: 0.007497, loss_test: 0.005579
time: 0.24805450439453125
time: 2.2425131797790527
[1, 14170] loss_train: 0.003299, loss_test: 0.005580
time: 0.25705718994140625
time: 2.262505292892456
[1, 14171] loss_train: 0.001480, loss_test: 0.005581
time: 0.24606704711914062
time: 2.2124955654144287
[1, 14172] loss_train: 0.005736, loss_test: 0.005581
time: 0.24605417251586914
time: 2.2084946632385254
[1, 14173] loss_train: 0.005776, loss_test: 0.005581
time: 0.24505400657653809
time: 2.2004926204681396
[1, 14174] loss_train: 0.003718, loss_test: 0.005583
time: 0.24309563636779785
time: 2.2134952545166016
[1, 14175] loss_train: 0.004892, loss_test: 0.005586
time: 0.24405384063720703
time: 2.2510128021240234
[1, 14176] loss_train: 0.008444, loss_test: 0.005590
time: 0.2450542449951172
time: 2.2490074634552
[1, 14177] loss_train: 0.008720, loss_test: 0.005596
time: 0.24405407905578613
time: 2.2094967365264893
[1, 14178] loss_train: 0.007859, loss_test: 0.005599
time: 0.24405479431152344
time: 2.2154953479766846
[1, 14179] loss_train: 0.006178, loss_test: 0.005603
time: 0.25005459785461426
time: 2.19490122795105
[1, 14180] loss_train: 0.003280, loss_test: 0.005597
time: 0.2560563087463379
time: 2.261514902114868
[1, 14181] loss_train: 0.010476, loss_test: 0.005592
time: 0.2490549087524414
time: 2.267507791519165
[1, 14182] loss_train: 0.011846, loss_test: 0.005583
time: 0.24605488777160645
time: 2.20849347114563
[1, 14183] loss_train: 0.003391, loss_test: 0.005577
time: 0.24605536460876465
time: 2.198491334915161
[1, 14184] loss_train: 0.002570, loss_test: 0.005575
time: 0.25005483627319336
time: 2.20149302482605
[1, 14185] loss_train: 0.003353, loss_test: 0.005575
time: 0.24305391311645508
time: 2.2194957733154297
[1, 14186] loss_train: 0.007447, loss_test: 0.005578
time: 0.24960994720458984
time: 2.2295007705688477
[1, 14187] loss_train: 0.007703, loss_test: 0.005588
time: 0.24405384063720703
time: 2.239501476287842
[1, 14188] loss_train: 0.005416, loss_test: 0.005598
time: 0.2440636157989502
time: 2.207494020462036
[1, 14189] loss_train: 0.015230, loss_test: 0.005612
time: 0.2450547218322754
time: 2.2245090007781982
[1, 14190] loss_train: 0.008245, loss_test: 0.005624
time: 0.25705742835998535
time: 2.22249698638916
[1, 14191] loss_train: 0.005630, loss_test: 0.005625
time: 0.2490553855895996
time: 2.247502088546753
[1, 14192] loss_train: 0.003634, loss_test: 0.005615
time: 0.24405479431152344
time: 2.2355165481567383
[1, 14193] loss_train: 0.019196, loss_test: 0.005608
time: 0.24405455589294434
time: 2.2370083332061768
[1, 14194] loss_train: 0.008200, loss_test: 0.005601
time: 0.24305415153503418
time: 2.2395007610321045
[1, 14195] loss_train: 0.005153, loss_test: 0.005590
time: 0.2430586814880371
time: 2.222496747970581
[1, 14196] loss_train: 0.007736, loss_test: 0.005580
time: 0.24706816673278809
time: 2.2154951095581055
[1, 14197] loss_train: 0.010182, loss_test: 0.005578
time: 0.24405384063720703
time: 2.204493761062622
[1, 14198] loss_train: 0.004413, loss_test: 0.005576
time: 0.24405384063720703
time: 2.204026937484741
[1, 14199] loss_train: 0.009334, loss_test: 0.005577
time: 0.24505400657653809
time: 2.196028232574463
[1, 14200] loss_train: 0.007885, loss_test: 0.005580
time: 0.25705695152282715
time: 2.2665090560913086
[1, 14201] loss_train: 0.003974, loss_test: 0.005585
time: 0.2490551471710205
time: 2.2004928588867188
[1, 14202] loss_train: 0.010472, loss_test: 0.005590
time: 0.24505376815795898
time: 2.219496726989746
[1, 14203] loss_train: 0.009486, loss_test: 0.005595
time: 0.25005531311035156
time: 2.243501901626587
[1, 14204] loss_train: 0.009186, loss_test: 0.005600
time: 0.24408292770385742
time: 2.2396557331085205
[1, 14205] loss_train: 0.005433, loss_test: 0.005606
time: 0.24808120727539062
time: 2.2375006675720215
[1, 14206] loss_train: 0.005771, loss_test: 0.005610
time: 0.2450544834136963
time: 2.233508586883545
[1, 14207] loss_train: 0.007760, loss_test: 0.005610
time: 0.24505329132080078
time: 2.221496820449829
[1, 14208] loss_train: 0.008173, loss_test: 0.005612
time: 0.2450544834136963
time: 2.2040212154388428
[1, 14209] loss_train: 0.002962, loss_test: 0.005615
time: 0.24305391311645508
time: 2.2425267696380615
[1, 14210] loss_train: 0.007244, loss_test: 0.005613
time: 0.25505614280700684
time: 2.2415013313293457
[1, 14211] loss_train: 0.005545, loss_test: 0.005606
time: 0.2450544834136963
time: 2.1889946460723877
[1, 14212] loss_train: 0.003060, loss_test: 0.005602
time: 0.24305343627929688
time: 2.2385010719299316
[1, 14213] loss_train: 0.001554, loss_test: 0.005600
time: 0.2470552921295166
time: 2.2005043029785156
[1, 14214] loss_train: 0.004058, loss_test: 0.005600
time: 0.2450542449951172
time: 2.241549015045166
[1, 14215] loss_train: 0.000731, loss_test: 0.005602
time: 0.2450544834136963
time: 2.2264978885650635
[1, 14216] loss_train: 0.003447, loss_test: 0.005604
time: 0.2450544834136963
time: 2.2190117835998535
[1, 14217] loss_train: 0.003049, loss_test: 0.005602
time: 0.24606800079345703
time: 2.2000157833099365
[1, 14218] loss_train: 0.006969, loss_test: 0.005601
time: 0.2470548152923584
time: 2.2254979610443115
[1, 14219] loss_train: 0.017060, loss_test: 0.005595
time: 0.24405407905578613
time: 2.2565155029296875
[1, 14220] loss_train: 0.002750, loss_test: 0.005591
time: 0.2620584964752197
time: 2.252140998840332
[1, 14221] loss_train: 0.007872, loss_test: 0.005588
time: 0.24405384063720703
time: 2.225510358810425
[1, 14222] loss_train: 0.004297, loss_test: 0.005584
time: 0.2470548152923584
time: 2.210493803024292
[1, 14223] loss_train: 0.004103, loss_test: 0.005584
time: 0.2450547218322754
time: 2.2325022220611572
[1, 14224] loss_train: 0.001554, loss_test: 0.005585
time: 0.2470543384552002
time: 2.205493927001953
[1, 14225] loss_train: 0.005815, loss_test: 0.005586
time: 0.24405384063720703
time: 2.229499101638794
[1, 14226] loss_train: 0.004545, loss_test: 0.005588
time: 0.24405360221862793
time: 2.24052095413208
[1, 14227] loss_train: 0.005330, loss_test: 0.005592
time: 0.24605441093444824
time: 2.2525038719177246
[1, 14228] loss_train: 0.004420, loss_test: 0.005596
time: 0.24405384063720703
time: 2.2215301990509033
[1, 14229] loss_train: 0.011517, loss_test: 0.005599
time: 0.24405384063720703
time: 2.2475032806396484
[1, 14230] loss_train: 0.001012, loss_test: 0.005605
time: 0.25705695152282715
time: 2.2505042552948
[1, 14231] loss_train: 0.003621, loss_test: 0.005609
time: 0.24405336380004883
time: 2.2155039310455322
[1, 14232] loss_train: 0.004908, loss_test: 0.005614
time: 0.24405455589294434
time: 2.2635083198547363
[1, 14233] loss_train: 0.013039, loss_test: 0.005617
time: 0.24305343627929688
time: 2.2094969749450684
[1, 14234] loss_train: 0.005337, loss_test: 0.005619
time: 0.24406743049621582
time: 2.197493076324463
[1, 14235] loss_train: 0.004885, loss_test: 0.005620
time: 0.24305248260498047
time: 2.178487777709961
[1, 14236] loss_train: 0.003270, loss_test: 0.005621
time: 0.2450547218322754
time: 2.208510637283325
[1, 14237] loss_train: 0.008748, loss_test: 0.005618
time: 0.24805521965026855
time: 2.2124946117401123
[1, 14238] loss_train: 0.009952, loss_test: 0.005611
time: 0.24605464935302734
time: 2.254523277282715
[1, 14239] loss_train: 0.016415, loss_test: 0.005594
time: 0.24805521965026855
time: 2.2425014972686768
[1, 14240] loss_train: 0.010513, loss_test: 0.005582
time: 0.25705695152282715
time: 2.268517255783081
[1, 14241] loss_train: 0.011086, loss_test: 0.005578
time: 0.25005531311035156
time: 2.2355141639709473
[1, 14242] loss_train: 0.006404, loss_test: 0.005580
time: 0.2450547218322754
time: 2.221496820449829
[1, 14243] loss_train: 0.003878, loss_test: 0.005584
time: 0.24828195571899414
time: 2.217495918273926
[1, 14244] loss_train: 0.016661, loss_test: 0.005593
time: 0.24405479431152344
time: 2.2093029022216797
[1, 14245] loss_train: 0.005037, loss_test: 0.005597
time: 0.24405384063720703
time: 2.219499111175537
[1, 14246] loss_train: 0.004362, loss_test: 0.005598
time: 0.24305438995361328
time: 2.2164952754974365
[1, 14247] loss_train: 0.007714, loss_test: 0.005592
time: 0.2470684051513672
time: 2.2184953689575195
[1, 14248] loss_train: 0.002024, loss_test: 0.005581
time: 0.2450556755065918
time: 2.203591823577881
[1, 14249] loss_train: 0.005795, loss_test: 0.005574
time: 0.2450706958770752
time: 2.2204959392547607
[1, 14250] loss_train: 0.004136, loss_test: 0.005570
time: 0.25705742835998535
time: 2.269507646560669
[1, 14251] loss_train: 0.001133, loss_test: 0.005568
time: 0.2450542449951172
time: 2.235499858856201
[1, 14252] loss_train: 0.002263, loss_test: 0.005574
time: 0.24405336380004883
time: 2.248504161834717
[1, 14253] loss_train: 0.004733, loss_test: 0.005583
time: 0.25505661964416504
time: 2.257504940032959
[1, 14254] loss_train: 0.012909, loss_test: 0.005592
time: 0.2470543384552002
time: 2.228498935699463
[1, 14255] loss_train: 0.007625, loss_test: 0.005603
time: 0.24405598640441895
time: 2.2515029907226562
[1, 14256] loss_train: 0.003114, loss_test: 0.005616
time: 0.24405312538146973
time: 2.2004928588867188
[1, 14257] loss_train: 0.006314, loss_test: 0.005625
time: 0.2450551986694336
time: 2.213508129119873
[1, 14258] loss_train: 0.005451, loss_test: 0.005630
time: 0.2450544834136963
time: 2.2034926414489746
[1, 14259] loss_train: 0.004556, loss_test: 0.005634
time: 0.24505376815795898
time: 2.227510452270508
[1, 14260] loss_train: 0.001249, loss_test: 0.005635
time: 0.2630577087402344
time: 2.258507251739502
[1, 14261] loss_train: 0.002502, loss_test: 0.005635
time: 0.2490549087524414
time: 2.230501174926758
[1, 14262] loss_train: 0.008388, loss_test: 0.005633
time: 0.24805498123168945
time: 2.248504638671875
[1, 14263] loss_train: 0.003708, loss_test: 0.005629
time: 0.24605464935302734
time: 2.231498956680298
[1, 14264] loss_train: 0.003636, loss_test: 0.005627
time: 0.25005555152893066
time: 2.2375009059906006
[1, 14265] loss_train: 0.002358, loss_test: 0.005630
time: 0.24805474281311035
time: 2.21950626373291
[1, 14266] loss_train: 0.007164, loss_test: 0.005627
time: 0.25005555152893066
time: 2.2280449867248535
[1, 14267] loss_train: 0.010377, loss_test: 0.005607
time: 0.24305391311645508
time: 2.2254979610443115
[1, 14268] loss_train: 0.009963, loss_test: 0.005583
time: 0.2450549602508545
time: 2.2064929008483887
[1, 14269] loss_train: 0.011635, loss_test: 0.005574
time: 0.24506664276123047
time: 2.211562156677246
[1, 14270] loss_train: 0.012622, loss_test: 0.005587
time: 0.25505614280700684
time: 2.257507085800171
[1, 14271] loss_train: 0.006819, loss_test: 0.005617
time: 0.24405407905578613
time: 2.2244796752929688
[1, 14272] loss_train: 0.008543, loss_test: 0.005647
time: 0.24605417251586914
time: 2.2335002422332764
[1, 14273] loss_train: 0.011240, loss_test: 0.005675
time: 0.24305438995361328
time: 2.2485034465789795
[1, 14274] loss_train: 0.005592, loss_test: 0.005678
time: 0.24606704711914062
time: 2.226498603820801
[1, 14275] loss_train: 0.004705, loss_test: 0.005675
time: 0.24344944953918457
time: 2.2274982929229736
[1, 14276] loss_train: 0.001054, loss_test: 0.005639
time: 0.24405479431152344
time: 2.2185068130493164
[1, 14277] loss_train: 0.006261, loss_test: 0.005602
time: 0.24405336380004883
time: 2.216496229171753
[1, 14278] loss_train: 0.009223, loss_test: 0.005584
time: 0.2470545768737793
time: 2.2405011653900146
[1, 14279] loss_train: 0.005732, loss_test: 0.005577
time: 0.24405503273010254
time: 2.2105116844177246
[1, 14280] loss_train: 0.005616, loss_test: 0.005580
time: 0.25705766677856445
time: 2.244502067565918
[1, 14281] loss_train: 0.003415, loss_test: 0.005592
time: 0.24605369567871094
time: 2.227499008178711
[1, 14282] loss_train: 0.004409, loss_test: 0.005609
time: 0.24305438995361328
time: 2.23349928855896
[1, 14283] loss_train: 0.005377, loss_test: 0.005625
time: 0.25005531311035156
time: 2.2134950160980225
[1, 14284] loss_train: 0.009699, loss_test: 0.005613
time: 0.2470545768737793
time: 2.2204973697662354
[1, 14285] loss_train: 0.005415, loss_test: 0.005602
time: 0.2490544319152832
time: 2.215189218521118
[1, 14286] loss_train: 0.005050, loss_test: 0.005593
time: 0.24505400657653809
time: 2.2175276279449463
[1, 14287] loss_train: 0.007198, loss_test: 0.005585
time: 0.24405384063720703
time: 2.242502450942993
[1, 14288] loss_train: 0.002532, loss_test: 0.005582
time: 0.24205422401428223
time: 2.2024950981140137
[1, 14289] loss_train: 0.006125, loss_test: 0.005582
time: 0.24506855010986328
time: 2.2575042247772217
[1, 14290] loss_train: 0.004527, loss_test: 0.005582
time: 0.25705671310424805
time: 2.2955141067504883
[1, 14291] loss_train: 0.003027, loss_test: 0.005579
time: 0.24605417251586914
time: 2.194491147994995
[1, 14292] loss_train: 0.016964, loss_test: 0.005576
time: 0.2440803050994873
time: 2.2535035610198975
[1, 14293] loss_train: 0.003461, loss_test: 0.005573
time: 0.24305415153503418
time: 2.2565038204193115
[1, 14294] loss_train: 0.002420, loss_test: 0.005570
time: 0.24605417251586914
time: 2.2024922370910645
[1, 14295] loss_train: 0.007454, loss_test: 0.005568
time: 0.24405360221862793
time: 2.2030282020568848
[1, 14296] loss_train: 0.007573, loss_test: 0.005569
time: 0.24405360221862793
time: 2.1954917907714844
[1, 14297] loss_train: 0.004162, loss_test: 0.005572
time: 0.24405407905578613
time: 2.221496820449829
[1, 14298] loss_train: 0.003230, loss_test: 0.005575
time: 0.24505376815795898
time: 2.227498769760132
[1, 14299] loss_train: 0.006428, loss_test: 0.005576
time: 0.24305367469787598
time: 2.211008071899414
[1, 14300] loss_train: 0.004247, loss_test: 0.005577
time: 0.2580573558807373
time: 2.2605080604553223
[1, 14301] loss_train: 0.004470, loss_test: 0.005578
time: 0.2470552921295166
time: 2.242501974105835
[1, 14302] loss_train: 0.003830, loss_test: 0.005579
time: 0.24605369567871094
time: 2.2114953994750977
[1, 14303] loss_train: 0.009366, loss_test: 0.005578
time: 0.24405336380004883
time: 2.24650239944458
[1, 14304] loss_train: 0.002053, loss_test: 0.005578
time: 0.24905610084533691
time: 2.2355003356933594
[1, 14305] loss_train: 0.006678, loss_test: 0.005578
time: 0.24405384063720703
time: 2.2084970474243164
[1, 14306] loss_train: 0.004530, loss_test: 0.005578
time: 0.24605393409729004
time: 2.2274985313415527
[1, 14307] loss_train: 0.005811, loss_test: 0.005577
time: 0.24805474281311035
time: 2.2264981269836426
[1, 14308] loss_train: 0.005421, loss_test: 0.005574
time: 0.2507903575897217
time: 2.220496892929077
[1, 14309] loss_train: 0.008704, loss_test: 0.005571
time: 0.24405384063720703
time: 2.22300124168396
[1, 14310] loss_train: 0.007997, loss_test: 0.005568
time: 0.25705742835998535
time: 2.2555043697357178
[1, 14311] loss_train: 0.002803, loss_test: 0.005566
time: 0.24305319786071777
time: 2.252504348754883
[1, 14312] loss_train: 0.006910, loss_test: 0.005563
time: 0.24605464935302734
time: 2.2501089572906494
[1, 14313] loss_train: 0.007091, loss_test: 0.005562
time: 0.24305319786071777
time: 2.259505271911621
[1, 14314] loss_train: 0.014178, loss_test: 0.005560
time: 0.2450559139251709
time: 2.191497802734375
[1, 14315] loss_train: 0.007457, loss_test: 0.005561
time: 0.24506759643554688
time: 2.2274980545043945
[1, 14316] loss_train: 0.001065, loss_test: 0.005564
time: 0.24306631088256836
time: 2.2365005016326904
[1, 14317] loss_train: 0.007054, loss_test: 0.005567
time: 0.24205303192138672
time: 2.2170374393463135
[1, 14318] loss_train: 0.014223, loss_test: 0.005569
time: 0.24605441093444824
time: 2.228498697280884
[1, 14319] loss_train: 0.017452, loss_test: 0.005574
time: 0.24405336380004883
time: 2.22001576423645
[1, 14320] loss_train: 0.013019, loss_test: 0.005583
time: 0.2540557384490967
time: 2.2735092639923096
[1, 14321] loss_train: 0.006490, loss_test: 0.005597
time: 0.2470545768737793
time: 2.231499433517456
[1, 14322] loss_train: 0.002235, loss_test: 0.005612
time: 0.2450544834136963
time: 2.2511563301086426
[1, 14323] loss_train: 0.006512, loss_test: 0.005626
time: 0.24406790733337402
time: 2.230498790740967
[1, 14324] loss_train: 0.007802, loss_test: 0.005616
time: 0.2450542449951172
time: 2.208494186401367
[1, 14325] loss_train: 0.007190, loss_test: 0.005580
time: 0.25005555152893066
time: 2.229498863220215
[1, 14326] loss_train: 0.004164, loss_test: 0.005562
time: 0.2450547218322754
time: 2.2550086975097656
[1, 14327] loss_train: 0.006288, loss_test: 0.005558
time: 0.24805474281311035
time: 2.2375006675720215
[1, 14328] loss_train: 0.003272, loss_test: 0.005561
time: 0.24405384063720703
time: 2.220515012741089
[1, 14329] loss_train: 0.006844, loss_test: 0.005568
time: 0.2470545768737793
time: 2.223506212234497
[1, 14330] loss_train: 0.009778, loss_test: 0.005576
time: 0.25705718994140625
time: 2.266228675842285
[1, 14331] loss_train: 0.002689, loss_test: 0.005588
time: 0.24805545806884766
time: 2.2415101528167725
[1, 14332] loss_train: 0.007228, loss_test: 0.005595
time: 0.2450544834136963
time: 2.2294986248016357
[1, 14333] loss_train: 0.007530, loss_test: 0.005600
time: 0.24605464935302734
time: 2.2034921646118164
[1, 14334] loss_train: 0.011212, loss_test: 0.005585
time: 0.24405336380004883
time: 2.227015256881714
[1, 14335] loss_train: 0.002025, loss_test: 0.005574
time: 0.24405384063720703
time: 2.252910852432251
[1, 14336] loss_train: 0.010695, loss_test: 0.005568
time: 0.24305462837219238
time: 2.2224955558776855
[1, 14337] loss_train: 0.001096, loss_test: 0.005563
time: 0.24405431747436523
time: 2.2525460720062256
[1, 14338] loss_train: 0.002808, loss_test: 0.005561
time: 0.24405598640441895
time: 2.2334983348846436
[1, 14339] loss_train: 0.012037, loss_test: 0.005560
time: 0.2450549602508545
time: 2.234499216079712
[1, 14340] loss_train: 0.006688, loss_test: 0.005560
time: 0.2570619583129883
time: 2.2675089836120605
[1, 14341] loss_train: 0.001967, loss_test: 0.005559
time: 0.24805569648742676
time: 2.197490930557251
[1, 14342] loss_train: 0.013878, loss_test: 0.005561
time: 0.2470557689666748
time: 2.235507011413574
[1, 14343] loss_train: 0.012539, loss_test: 0.005565
time: 0.24406695365905762
time: 2.212496280670166
[1, 14344] loss_train: 0.005465, loss_test: 0.005571
time: 0.24405264854431152
time: 2.2355005741119385
[1, 14345] loss_train: 0.004282, loss_test: 0.005578
time: 0.2450542449951172
time: 2.218496561050415
[1, 14346] loss_train: 0.004189, loss_test: 0.005583
time: 0.24505376815795898
time: 2.2104949951171875
[1, 14347] loss_train: 0.001410, loss_test: 0.005590
time: 0.2450549602508545
time: 2.210494041442871
[1, 14348] loss_train: 0.003965, loss_test: 0.005596
time: 0.24505400657653809
time: 2.237037420272827
[1, 14349] loss_train: 0.002212, loss_test: 0.005603
time: 0.24506783485412598
time: 2.2085111141204834
[1, 14350] loss_train: 0.000788, loss_test: 0.005611
time: 0.2620582580566406
time: 2.2545037269592285
[1, 14351] loss_train: 0.003369, loss_test: 0.005616
time: 0.24605464935302734
time: 2.2515037059783936
[1, 14352] loss_train: 0.002236, loss_test: 0.005618
time: 0.2510561943054199
time: 2.2545042037963867
[1, 14353] loss_train: 0.006260, loss_test: 0.005617
time: 0.2450542449951172
time: 2.220496654510498
[1, 14354] loss_train: 0.007309, loss_test: 0.005611
time: 0.2470552921295166
time: 2.236016035079956
[1, 14355] loss_train: 0.007149, loss_test: 0.005598
time: 0.2450547218322754
time: 2.2214975357055664
[1, 14356] loss_train: 0.002445, loss_test: 0.005592
time: 0.24605512619018555
time: 2.2245213985443115
[1, 14357] loss_train: 0.011891, loss_test: 0.005587
time: 0.2420654296875
time: 2.2263152599334717
[1, 14358] loss_train: 0.007466, loss_test: 0.005582
time: 0.24405455589294434
time: 2.2194979190826416
[1, 14359] loss_train: 0.002321, loss_test: 0.005579
time: 0.24305319786071777
time: 2.217496633529663
[1, 14360] loss_train: 0.006242, loss_test: 0.005579
time: 0.2560710906982422
time: 2.2835140228271484
[1, 14361] loss_train: 0.009275, loss_test: 0.005577
time: 0.24805545806884766
time: 2.2525036334991455
[1, 14362] loss_train: 0.002233, loss_test: 0.005577
time: 0.25005555152893066
time: 2.2485055923461914
[1, 14363] loss_train: 0.002252, loss_test: 0.005579
time: 0.24306702613830566
time: 2.2265024185180664
[1, 14364] loss_train: 0.003680, loss_test: 0.005582
time: 0.24405217170715332
time: 2.2124974727630615
[1, 14365] loss_train: 0.006578, loss_test: 0.005584
time: 0.2450544834136963
time: 2.2014918327331543
[1, 14366] loss_train: 0.004975, loss_test: 0.005584
time: 0.24405407905578613
time: 2.240501642227173
[1, 14367] loss_train: 0.002545, loss_test: 0.005584
time: 0.24405384063720703
time: 2.232499837875366
[1, 14368] loss_train: 0.003201, loss_test: 0.005586
time: 0.24405336380004883
time: 2.237196207046509
[1, 14369] loss_train: 0.004509, loss_test: 0.005589
time: 0.24605441093444824
time: 2.2615063190460205
[1, 14370] loss_train: 0.005040, loss_test: 0.005595
time: 0.2560567855834961
time: 2.2722597122192383
[1, 14371] loss_train: 0.001679, loss_test: 0.005603
time: 0.24805545806884766
time: 2.241501569747925
[1, 14372] loss_train: 0.009851, loss_test: 0.005604
time: 0.24605441093444824
time: 2.2665226459503174
[1, 14373] loss_train: 0.005622, loss_test: 0.005602
time: 0.24405455589294434
time: 2.234502077102661
[1, 14374] loss_train: 0.005196, loss_test: 0.005601
time: 0.24306321144104004
time: 2.2235002517700195
[1, 14375] loss_train: 0.003243, loss_test: 0.005601
time: 0.2450544834136963
time: 2.2655060291290283
[1, 14376] loss_train: 0.007866, loss_test: 0.005597
time: 0.24605417251586914
time: 2.234513998031616
[1, 14377] loss_train: 0.005867, loss_test: 0.005596
time: 0.24405360221862793
time: 2.216496229171753
[1, 14378] loss_train: 0.005880, loss_test: 0.005599
time: 0.2450551986694336
time: 2.2145071029663086
[1, 14379] loss_train: 0.014292, loss_test: 0.005598
time: 0.24505949020385742
time: 2.2154955863952637
[1, 14380] loss_train: 0.003001, loss_test: 0.005597
time: 0.25705742835998535
time: 2.2465031147003174
[1, 14381] loss_train: 0.010434, loss_test: 0.005599
time: 0.25005412101745605
time: 2.231499671936035
[1, 14382] loss_train: 0.007428, loss_test: 0.005600
time: 0.24605417251586914
time: 2.1864893436431885
[1, 14383] loss_train: 0.008944, loss_test: 0.005602
time: 0.2470545768737793
time: 2.2224974632263184
[1, 14384] loss_train: 0.000818, loss_test: 0.005601
time: 0.2450544834136963
time: 2.230499029159546
[1, 14385] loss_train: 0.001895, loss_test: 0.005594
time: 0.2470550537109375
time: 2.219496250152588
[1, 14386] loss_train: 0.006731, loss_test: 0.005587
time: 0.24606847763061523
time: 2.2315502166748047
[1, 14387] loss_train: 0.005705, loss_test: 0.005580
time: 0.2470564842224121
time: 2.211493968963623
[1, 14388] loss_train: 0.003444, loss_test: 0.005576
time: 0.24305415153503418
time: 2.240499973297119
[1, 14389] loss_train: 0.005427, loss_test: 0.005576
time: 0.24406814575195312
time: 2.218498945236206
[1, 14390] loss_train: 0.016753, loss_test: 0.005576
time: 0.2560567855834961
time: 2.2545039653778076
[1, 14391] loss_train: 0.009081, loss_test: 0.005580
time: 0.24405407905578613
time: 2.2285003662109375
[1, 14392] loss_train: 0.007957, loss_test: 0.005580
time: 0.24506831169128418
time: 2.232499599456787
[1, 14393] loss_train: 0.004915, loss_test: 0.005583
time: 0.24805450439453125
time: 2.2044928073883057
[1, 14394] loss_train: 0.012423, loss_test: 0.005583
time: 0.24405527114868164
time: 2.2174978256225586
[1, 14395] loss_train: 0.012623, loss_test: 0.005577
time: 0.2450547218322754
time: 2.220046281814575
[1, 14396] loss_train: 0.010933, loss_test: 0.005574
time: 0.24505376815795898
time: 2.2375102043151855
[1, 14397] loss_train: 0.003271, loss_test: 0.005573
time: 0.24605393409729004
time: 2.2084944248199463
[1, 14398] loss_train: 0.012873, loss_test: 0.005573
time: 0.24905705451965332
time: 2.2284984588623047
[1, 14399] loss_train: 0.009864, loss_test: 0.005575
time: 0.24805402755737305
time: 2.230501174926758
[1, 14400] loss_train: 0.012789, loss_test: 0.005576
time: 0.2610585689544678
time: 2.296513080596924
[1, 14401] loss_train: 0.005909, loss_test: 0.005577
time: 0.24405527114868164
time: 2.2134945392608643
[1, 14402] loss_train: 0.007638, loss_test: 0.005586
time: 0.2540557384490967
time: 2.2024953365325928
[1, 14403] loss_train: 0.002871, loss_test: 0.005596
time: 0.24505376815795898
time: 2.214495897293091
[1, 14404] loss_train: 0.013669, loss_test: 0.005601
time: 0.2450549602508545
time: 2.2114944458007812
[1, 14405] loss_train: 0.004519, loss_test: 0.005607
time: 0.24405455589294434
time: 2.224534034729004
[1, 14406] loss_train: 0.003069, loss_test: 0.005602
time: 0.24506592750549316
time: 2.2515058517456055
[1, 14407] loss_train: 0.003382, loss_test: 0.005592
time: 0.24305415153503418
time: 2.220496892929077
[1, 14408] loss_train: 0.004846, loss_test: 0.005587
time: 0.24305415153503418
time: 2.2415003776550293
[1, 14409] loss_train: 0.007282, loss_test: 0.005585
time: 0.24605584144592285
time: 2.2303011417388916
[1, 14410] loss_train: 0.000666, loss_test: 0.005586
time: 0.25706958770751953
time: 2.275510787963867
[1, 14411] loss_train: 0.010552, loss_test: 0.005590
time: 0.2450549602508545
time: 2.2314987182617188
[1, 14412] loss_train: 0.001326, loss_test: 0.005600
time: 0.24605536460876465
time: 2.2395002841949463
[1, 14413] loss_train: 0.003051, loss_test: 0.005614
time: 0.24405431747436523
time: 2.217496156692505
[1, 14414] loss_train: 0.003177, loss_test: 0.005634
time: 0.24405431747436523
time: 2.193542957305908
[1, 14415] loss_train: 0.003649, loss_test: 0.005650
time: 0.24406743049621582
time: 2.197061061859131
[1, 14416] loss_train: 0.000461, loss_test: 0.005672
time: 0.2450547218322754
time: 2.199490547180176
[1, 14417] loss_train: 0.001845, loss_test: 0.005697
time: 0.24605488777160645
time: 2.1959950923919678
[1, 14418] loss_train: 0.005684, loss_test: 0.005708
time: 0.24405384063720703
time: 2.1934587955474854
[1, 14419] loss_train: 0.004778, loss_test: 0.005711
time: 0.2470545768737793
time: 2.210167407989502
[1, 14420] loss_train: 0.005681, loss_test: 0.005705
time: 0.25705671310424805
time: 2.277509927749634
[1, 14421] loss_train: 0.005854, loss_test: 0.005683
time: 0.24605512619018555
time: 2.2254977226257324
[1, 14422] loss_train: 0.012255, loss_test: 0.005645
time: 0.24305343627929688
time: 2.212494373321533
[1, 14423] loss_train: 0.007592, loss_test: 0.005617
time: 0.24405384063720703
time: 2.2355003356933594
[1, 14424] loss_train: 0.007005, loss_test: 0.005601
time: 0.24305415153503418
time: 2.221496820449829
[1, 14425] loss_train: 0.004008, loss_test: 0.005597
time: 0.24405384063720703
time: 2.2141520977020264
[1, 14426] loss_train: 0.005588, loss_test: 0.005601
time: 0.24606752395629883
time: 2.217496156692505
[1, 14427] loss_train: 0.001767, loss_test: 0.005604
time: 0.24305415153503418
time: 2.188502073287964
[1, 14428] loss_train: 0.000747, loss_test: 0.005603
time: 0.24505352973937988
time: 2.2104952335357666
[1, 14429] loss_train: 0.009869, loss_test: 0.005606
time: 0.24405336380004883
time: 2.2055294513702393
[1, 14430] loss_train: 0.008924, loss_test: 0.005605
time: 0.25705695152282715
time: 2.283526659011841
[1, 14431] loss_train: 0.006782, loss_test: 0.005603
time: 0.24405455589294434
time: 2.2274982929229736
[1, 14432] loss_train: 0.004225, loss_test: 0.005603
time: 0.2450544834136963
time: 2.2615058422088623
[1, 14433] loss_train: 0.007732, loss_test: 0.005602
time: 0.24405407905578613
time: 2.220496416091919
[1, 14434] loss_train: 0.001789, loss_test: 0.005601
time: 0.24509215354919434
time: 2.1964914798736572
[1, 14435] loss_train: 0.010590, loss_test: 0.005599
time: 0.24406766891479492
time: 2.235499858856201
[1, 14436] loss_train: 0.005824, loss_test: 0.005597
time: 0.24649691581726074
time: 2.232499361038208
[1, 14437] loss_train: 0.002975, loss_test: 0.005596
time: 0.24305438995361328
time: 2.211493968963623
[1, 14438] loss_train: 0.005912, loss_test: 0.005595
time: 0.2450547218322754
time: 2.1984329223632812
[1, 14439] loss_train: 0.007055, loss_test: 0.005596
time: 0.24405527114868164
time: 2.200572967529297
[1, 14440] loss_train: 0.004156, loss_test: 0.005599
time: 0.25905823707580566
time: 2.298522472381592
[1, 14441] loss_train: 0.000655, loss_test: 0.005605
time: 0.24405908584594727
time: 2.221497058868408
[1, 14442] loss_train: 0.000588, loss_test: 0.005617
time: 0.24405360221862793
time: 2.2279860973358154
[1, 14443] loss_train: 0.001670, loss_test: 0.005631
time: 0.2470545768737793
time: 2.2355010509490967
[1, 14444] loss_train: 0.008798, loss_test: 0.005646
time: 0.24605393409729004
time: 2.2231078147888184
[1, 14445] loss_train: 0.006669, loss_test: 0.005655
time: 0.24405479431152344
time: 2.2535033226013184
[1, 14446] loss_train: 0.004064, loss_test: 0.005669
time: 0.24305438995361328
time: 2.2115116119384766
[1, 14447] loss_train: 0.007246, loss_test: 0.005682
time: 0.24305438995361328
time: 2.2254974842071533
[1, 14448] loss_train: 0.002606, loss_test: 0.005693
time: 0.24505400657653809
time: 2.234034776687622
[1, 14449] loss_train: 0.008960, loss_test: 0.005697
time: 0.2450544834136963
time: 2.217782497406006
[1, 14450] loss_train: 0.008855, loss_test: 0.005685
time: 0.25705599784851074
time: 2.241502046585083
[1, 14451] loss_train: 0.003492, loss_test: 0.005676
time: 0.24505400657653809
time: 2.2385013103485107
[1, 14452] loss_train: 0.008225, loss_test: 0.005654
time: 0.2470543384552002
time: 2.2134952545166016
[1, 14453] loss_train: 0.006016, loss_test: 0.005627
time: 0.24605441093444824
time: 2.219496726989746
[1, 14454] loss_train: 0.005726, loss_test: 0.005609
time: 0.2450542449951172
time: 2.2217187881469727
[1, 14455] loss_train: 0.002245, loss_test: 0.005597
time: 0.2490549087524414
time: 2.225499153137207
[1, 14456] loss_train: 0.004134, loss_test: 0.005588
time: 0.24505329132080078
time: 2.22912859916687
[1, 14457] loss_train: 0.007291, loss_test: 0.005582
time: 0.24705934524536133
time: 2.2204997539520264
[1, 14458] loss_train: 0.007383, loss_test: 0.005579
time: 0.24305415153503418
time: 2.222515106201172
[1, 14459] loss_train: 0.002318, loss_test: 0.005577
time: 0.24405384063720703
time: 2.231499671936035
[1, 14460] loss_train: 0.004317, loss_test: 0.005576
time: 0.2580573558807373
time: 2.2855112552642822
[1, 14461] loss_train: 0.011619, loss_test: 0.005576
time: 0.24306631088256836
time: 2.218496561050415
[1, 14462] loss_train: 0.003420, loss_test: 0.005576
time: 0.24406719207763672
time: 2.245501756668091
[1, 14463] loss_train: 0.008426, loss_test: 0.005577
time: 0.2450549602508545
time: 2.2064931392669678
[1, 14464] loss_train: 0.004244, loss_test: 0.005580
time: 0.24405431747436523
time: 2.2124946117401123
[1, 14465] loss_train: 0.004023, loss_test: 0.005581
time: 0.24605441093444824
time: 2.205493688583374
[1, 14466] loss_train: 0.004086, loss_test: 0.005581
time: 0.24405455589294434
time: 2.222496509552002
[1, 14467] loss_train: 0.003472, loss_test: 0.005582
time: 0.24606704711914062
time: 2.256505250930786
[1, 14468] loss_train: 0.004483, loss_test: 0.005584
time: 0.24505400657653809
time: 2.255523443222046
[1, 14469] loss_train: 0.001750, loss_test: 0.005590
time: 0.24306678771972656
time: 2.2195048332214355
[1, 14470] loss_train: 0.007008, loss_test: 0.005597
time: 0.258068323135376
time: 2.2535040378570557
[1, 14471] loss_train: 0.004338, loss_test: 0.005607
time: 0.2520608901977539
time: 2.213505506515503
[1, 14472] loss_train: 0.009437, loss_test: 0.005614
time: 0.24509239196777344
time: 2.2274982929229736
[1, 14473] loss_train: 0.005161, loss_test: 0.005617
time: 0.24405431747436523
time: 2.2395012378692627
[1, 14474] loss_train: 0.002372, loss_test: 0.005621
time: 0.24605417251586914
time: 2.210494041442871
[1, 14475] loss_train: 0.007390, loss_test: 0.005618
time: 0.24605512619018555
time: 2.2117903232574463
[1, 14476] loss_train: 0.002358, loss_test: 0.005615
time: 0.24605441093444824
time: 2.1944985389709473
[1, 14477] loss_train: 0.007735, loss_test: 0.005609
time: 0.24706697463989258
time: 2.2515039443969727
[1, 14478] loss_train: 0.005034, loss_test: 0.005605
time: 0.24505400657653809
time: 2.226020574569702
[1, 14479] loss_train: 0.004401, loss_test: 0.005601
time: 0.24405360221862793
time: 2.2470076084136963
[1, 14480] loss_train: 0.011870, loss_test: 0.005590
time: 0.2580568790435791
time: 2.283512592315674
[1, 14481] loss_train: 0.005175, loss_test: 0.005584
time: 0.24505853652954102
time: 2.2144954204559326
[1, 14482] loss_train: 0.006223, loss_test: 0.005582
time: 0.24405431747436523
time: 2.2495033740997314
[1, 14483] loss_train: 0.005214, loss_test: 0.005584
time: 0.24405527114868164
time: 2.2415003776550293
[1, 14484] loss_train: 0.004657, loss_test: 0.005588
time: 0.24309396743774414
time: 2.2325072288513184
[1, 14485] loss_train: 0.007711, loss_test: 0.005592
time: 0.24405527114868164
time: 2.223496913909912
[1, 14486] loss_train: 0.006305, loss_test: 0.005591
time: 0.24505376815795898
time: 2.2035043239593506
[1, 14487] loss_train: 0.003506, loss_test: 0.005586
time: 0.24605488777160645
time: 2.2124953269958496
[1, 14488] loss_train: 0.005422, loss_test: 0.005583
time: 0.24605417251586914
time: 2.217496156692505
[1, 14489] loss_train: 0.007838, loss_test: 0.005583
time: 0.2450542449951172
time: 2.204493284225464
[1, 14490] loss_train: 0.010940, loss_test: 0.005587
time: 0.25505661964416504
time: 2.280510425567627
[1, 14491] loss_train: 0.009938, loss_test: 0.005590
time: 0.24405574798583984
time: 2.2244977951049805
[1, 14492] loss_train: 0.009024, loss_test: 0.005593
time: 0.24405384063720703
time: 2.214508056640625
[1, 14493] loss_train: 0.006640, loss_test: 0.005593
time: 0.24605393409729004
time: 2.2184956073760986
[1, 14494] loss_train: 0.005790, loss_test: 0.005593
time: 0.2450547218322754
time: 2.206493616104126
[1, 14495] loss_train: 0.004891, loss_test: 0.005594
time: 0.25025415420532227
time: 2.2285101413726807
[1, 14496] loss_train: 0.006791, loss_test: 0.005595
time: 0.2450549602508545
time: 2.230515241622925
[1, 14497] loss_train: 0.014899, loss_test: 0.005593
time: 0.2490549087524414
time: 2.2635068893432617
[1, 14498] loss_train: 0.003603, loss_test: 0.005592
time: 0.2450542449951172
time: 2.2355003356933594
[1, 14499] loss_train: 0.008286, loss_test: 0.005594
time: 0.2470545768737793
time: 2.1780011653900146
[1, 14500] loss_train: 0.002807, loss_test: 0.005597
time: 0.2560570240020752
time: 2.293513536453247
[1, 14501] loss_train: 0.009151, loss_test: 0.005601
time: 0.247053861618042
time: 2.244502305984497
[1, 14502] loss_train: 0.002598, loss_test: 0.005599
time: 0.24405360221862793
time: 2.2034928798675537
[1, 14503] loss_train: 0.003747, loss_test: 0.005592
time: 0.24405455589294434
time: 2.21950626373291
[1, 14504] loss_train: 0.006719, loss_test: 0.005586
time: 0.24805426597595215
time: 2.255505323410034
[1, 14505] loss_train: 0.004406, loss_test: 0.005580
time: 0.24805426597595215
time: 2.2335169315338135
[1, 14506] loss_train: 0.007553, loss_test: 0.005577
time: 0.24405336380004883
time: 2.25201678276062
[1, 14507] loss_train: 0.007490, loss_test: 0.005576
time: 0.24505376815795898
time: 2.2224974632263184
[1, 14508] loss_train: 0.010033, loss_test: 0.005575
time: 0.24305343627929688
time: 2.2615063190460205
[1, 14509] loss_train: 0.010035, loss_test: 0.005573
time: 0.24205255508422852
time: 2.2260148525238037
[1, 14510] loss_train: 0.001211, loss_test: 0.005572
time: 0.2520561218261719
time: 2.2114944458007812
[1, 14511] loss_train: 0.007000, loss_test: 0.005571
time: 0.24405336380004883
time: 2.2054929733276367
[1, 14512] loss_train: 0.002383, loss_test: 0.005571
time: 0.24508166313171387
time: 2.1994917392730713
[1, 14513] loss_train: 0.002247, loss_test: 0.005571
time: 0.24505400657653809
time: 2.2285051345825195
[1, 14514] loss_train: 0.006659, loss_test: 0.005571
time: 0.2490546703338623
time: 2.2345004081726074
[1, 14515] loss_train: 0.000442, loss_test: 0.005573
time: 0.24605417251586914
time: 2.2204971313476562
[1, 14516] loss_train: 0.003042, loss_test: 0.005578
time: 0.24409055709838867
time: 2.2224977016448975
[1, 14517] loss_train: 0.006865, loss_test: 0.005581
time: 0.24405431747436523
time: 2.2194957733154297
[1, 14518] loss_train: 0.010581, loss_test: 0.005585
time: 0.2470543384552002
time: 2.2355005741119385
[1, 14519] loss_train: 0.006779, loss_test: 0.005589
time: 0.24405407905578613
time: 2.2585251331329346
[1, 14520] loss_train: 0.011265, loss_test: 0.005594
time: 0.25705718994140625
time: 2.243501663208008
[1, 14521] loss_train: 0.007375, loss_test: 0.005601
time: 0.24906015396118164
time: 2.2344799041748047
[1, 14522] loss_train: 0.001735, loss_test: 0.005604
time: 0.24605417251586914
time: 2.232499599456787
[1, 14523] loss_train: 0.006443, loss_test: 0.005606
time: 0.24405336380004883
time: 2.215496301651001
[1, 14524] loss_train: 0.004441, loss_test: 0.005606
time: 0.24605488777160645
time: 2.231502056121826
[1, 14525] loss_train: 0.007470, loss_test: 0.005608
time: 0.24305462837219238
time: 2.226613759994507
[1, 14526] loss_train: 0.006622, loss_test: 0.005610
time: 0.2450544834136963
time: 2.2415013313293457
[1, 14527] loss_train: 0.004213, loss_test: 0.005613
time: 0.2450547218322754
time: 2.2194981575012207
[1, 14528] loss_train: 0.007213, loss_test: 0.005614
time: 0.24805593490600586
time: 2.2124948501586914
[1, 14529] loss_train: 0.007586, loss_test: 0.005613
time: 0.24305462837219238
time: 2.2250189781188965
[1, 14530] loss_train: 0.004421, loss_test: 0.005612
time: 0.25406861305236816
time: 2.266507863998413
[1, 14531] loss_train: 0.013347, loss_test: 0.005599
time: 0.24405431747436523
time: 2.236511707305908
[1, 14532] loss_train: 0.009852, loss_test: 0.005585
time: 0.24405479431152344
time: 2.2234995365142822
[1, 14533] loss_train: 0.006176, loss_test: 0.005575
time: 0.24405384063720703
time: 2.228498697280884
[1, 14534] loss_train: 0.007238, loss_test: 0.005569
time: 0.24405431747436523
time: 2.1954898834228516
[1, 14535] loss_train: 0.009151, loss_test: 0.005565
time: 0.24605488777160645
time: 2.217496395111084
[1, 14536] loss_train: 0.003751, loss_test: 0.005568
time: 0.24453282356262207
time: 2.1924901008605957
[1, 14537] loss_train: 0.012851, loss_test: 0.005572
time: 0.24605464935302734
time: 2.2144954204559326
[1, 14538] loss_train: 0.008449, loss_test: 0.005578
time: 0.2450547218322754
time: 2.2004919052124023
[1, 14539] loss_train: 0.008657, loss_test: 0.005588
time: 0.2470703125
time: 2.1790084838867188
[1, 14540] loss_train: 0.011384, loss_test: 0.005601
time: 0.2560572624206543
time: 2.2415013313293457
[1, 14541] loss_train: 0.007195, loss_test: 0.005606
time: 0.24605512619018555
time: 2.2375006675720215
[1, 14542] loss_train: 0.013643, loss_test: 0.005609
time: 0.2450542449951172
time: 2.23449969291687
[1, 14543] loss_train: 0.004831, loss_test: 0.005603
time: 0.24405455589294434
time: 2.23349928855896
[1, 14544] loss_train: 0.002910, loss_test: 0.005593
time: 0.24405670166015625
time: 2.2124948501586914
[1, 14545] loss_train: 0.006375, loss_test: 0.005583
time: 0.24405336380004883
time: 2.2124955654144287
[1, 14546] loss_train: 0.001912, loss_test: 0.005571
time: 0.2450542449951172
time: 2.2105026245117188
[1, 14547] loss_train: 0.003818, loss_test: 0.005565
time: 0.24405455589294434
time: 2.2110984325408936
[1, 14548] loss_train: 0.000744, loss_test: 0.005563
time: 0.24405360221862793
time: 2.229498863220215
[1, 14549] loss_train: 0.009565, loss_test: 0.005565
time: 0.24605488777160645
time: 2.2075424194335938
[1, 14550] loss_train: 0.006965, loss_test: 0.005569
time: 0.2560572624206543
time: 2.2505078315734863
[1, 14551] loss_train: 0.005561, loss_test: 0.005573
time: 0.24405598640441895
time: 2.2154953479766846
[1, 14552] loss_train: 0.002672, loss_test: 0.005580
time: 0.2490549087524414
time: 2.205493927001953
[1, 14553] loss_train: 0.005119, loss_test: 0.005585
time: 0.24605393409729004
time: 2.22249698638916
[1, 14554] loss_train: 0.010449, loss_test: 0.005580
time: 0.24905610084533691
time: 2.2270052433013916
[1, 14555] loss_train: 0.002039, loss_test: 0.005578
time: 0.24605369567871094
time: 2.23402738571167
[1, 14556] loss_train: 0.002879, loss_test: 0.005579
time: 0.2450547218322754
time: 2.2184958457946777
[1, 14557] loss_train: 0.006393, loss_test: 0.005575
time: 0.2420670986175537
time: 2.204493522644043
[1, 14558] loss_train: 0.001781, loss_test: 0.005575
time: 0.24505400657653809
time: 2.269015312194824
[1, 14559] loss_train: 0.003708, loss_test: 0.005574
time: 0.24405407905578613
time: 2.2195053100585938
[1, 14560] loss_train: 0.010970, loss_test: 0.005570
time: 0.25705671310424805
time: 2.2540416717529297
[1, 14561] loss_train: 0.007690, loss_test: 0.005567
time: 0.24406671524047852
time: 2.228498935699463
[1, 14562] loss_train: 0.006816, loss_test: 0.005569
time: 0.24405360221862793
time: 2.223015785217285
[1, 14563] loss_train: 0.004628, loss_test: 0.005576
time: 0.2450542449951172
time: 2.230499267578125
[1, 14564] loss_train: 0.005853, loss_test: 0.005585
time: 0.243056058883667
time: 2.2495038509368896
[1, 14565] loss_train: 0.012041, loss_test: 0.005596
time: 0.24412250518798828
time: 2.2284982204437256
[1, 14566] loss_train: 0.005827, loss_test: 0.005604
time: 0.24505376815795898
time: 2.212495803833008
[1, 14567] loss_train: 0.006957, loss_test: 0.005613
time: 0.2450544834136963
time: 2.2385332584381104
[1, 14568] loss_train: 0.007032, loss_test: 0.005616
time: 0.24405455589294434
time: 2.236499071121216
[1, 14569] loss_train: 0.004498, loss_test: 0.005614
time: 0.24405503273010254
time: 2.230498790740967
[1, 14570] loss_train: 0.010512, loss_test: 0.005608
time: 0.2580568790435791
time: 2.2365002632141113
[1, 14571] loss_train: 0.006993, loss_test: 0.005603
time: 0.24405431747436523
time: 2.2124948501586914
[1, 14572] loss_train: 0.007976, loss_test: 0.005598
time: 0.24405455589294434
time: 2.2114944458007812
[1, 14573] loss_train: 0.008284, loss_test: 0.005594
time: 0.24605417251586914
time: 2.205493688583374
[1, 14574] loss_train: 0.005503, loss_test: 0.005592
time: 0.24405431747436523
time: 2.2284984588623047
[1, 14575] loss_train: 0.005461, loss_test: 0.005595
time: 0.24705815315246582
time: 2.2115702629089355
[1, 14576] loss_train: 0.003912, loss_test: 0.005603
time: 0.2450551986694336
time: 2.2284979820251465
[1, 14577] loss_train: 0.003141, loss_test: 0.005616
time: 0.2480604648590088
time: 2.248502731323242
[1, 14578] loss_train: 0.004001, loss_test: 0.005635
time: 0.24305319786071777
time: 2.241502046585083
[1, 14579] loss_train: 0.001603, loss_test: 0.005657
time: 0.24605393409729004
time: 2.2104947566986084
[1, 14580] loss_train: 0.005489, loss_test: 0.005673
time: 0.2540559768676758
time: 2.28052020072937
[1, 14581] loss_train: 0.005811, loss_test: 0.005682
time: 0.25005531311035156
time: 2.2274980545043945
[1, 14582] loss_train: 0.003935, loss_test: 0.005691
time: 0.24405431747436523
time: 2.2224996089935303
[1, 14583] loss_train: 0.002056, loss_test: 0.005700
time: 0.24505376815795898
time: 2.242501735687256
[1, 14584] loss_train: 0.004370, loss_test: 0.005709
time: 0.24506807327270508
time: 2.222496747970581
[1, 14585] loss_train: 0.010640, loss_test: 0.005695
time: 0.24305367469787598
time: 2.227499008178711
[1, 14586] loss_train: 0.009111, loss_test: 0.005663
time: 0.24606704711914062
time: 2.2084946632385254
[1, 14587] loss_train: 0.001566, loss_test: 0.005644
time: 0.24506711959838867
time: 2.244502544403076
[1, 14588] loss_train: 0.003750, loss_test: 0.005633
time: 0.24405336380004883
time: 2.204016923904419
[1, 14589] loss_train: 0.007386, loss_test: 0.005625
time: 0.24405455589294434
time: 2.2144951820373535
[1, 14590] loss_train: 0.004981, loss_test: 0.005623
time: 0.2560563087463379
time: 2.2515041828155518
[1, 14591] loss_train: 0.013127, loss_test: 0.005625
time: 0.2450549602508545
time: 2.2485177516937256
[1, 14592] loss_train: 0.007979, loss_test: 0.005627
time: 0.2450547218322754
time: 2.261171579360962
[1, 14593] loss_train: 0.004122, loss_test: 0.005629
time: 0.24505877494812012
time: 2.221497058868408
[1, 14594] loss_train: 0.016369, loss_test: 0.005649
time: 0.2510554790496826
time: 2.2254981994628906
[1, 14595] loss_train: 0.012211, loss_test: 0.005676
time: 0.24605488777160645
time: 2.195490837097168
[1, 14596] loss_train: 0.003356, loss_test: 0.005690
time: 0.24605417251586914
time: 2.2254979610443115
[1, 14597] loss_train: 0.011123, loss_test: 0.005685
time: 0.24405455589294434
time: 2.2124950885772705
[1, 14598] loss_train: 0.010866, loss_test: 0.005675
time: 0.24505376815795898
time: 2.239503860473633
[1, 14599] loss_train: 0.006388, loss_test: 0.005661
time: 0.24406003952026367
time: 2.2244975566864014
[1, 14600] loss_train: 0.004700, loss_test: 0.005615
time: 0.2560615539550781
time: 2.2555041313171387
[1, 14601] loss_train: 0.014252, loss_test: 0.005591
time: 0.24605488777160645
time: 2.225497245788574
[1, 14602] loss_train: 0.005172, loss_test: 0.005579
time: 0.24507904052734375
time: 2.2274982929229736
[1, 14603] loss_train: 0.009093, loss_test: 0.005578
time: 0.24305343627929688
time: 2.2395012378692627
[1, 14604] loss_train: 0.003820, loss_test: 0.005584
time: 0.2470545768737793
time: 2.2274982929229736
[1, 14605] loss_train: 0.010280, loss_test: 0.005591
time: 0.24305438995361328
time: 2.230498790740967
[1, 14606] loss_train: 0.008522, loss_test: 0.005594
time: 0.24306774139404297
time: 2.221496343612671
[1, 14607] loss_train: 0.007540, loss_test: 0.005593
time: 0.2450544834136963
time: 2.2264978885650635
[1, 14608] loss_train: 0.007908, loss_test: 0.005592
time: 0.24505400657653809
time: 2.248502731323242
[1, 14609] loss_train: 0.019510, loss_test: 0.005587
time: 0.24305415153503418
time: 2.221541166305542
[1, 14610] loss_train: 0.006304, loss_test: 0.005589
time: 0.2580571174621582
time: 2.2475028038024902
[1, 14611] loss_train: 0.011018, loss_test: 0.005599
time: 0.24705934524536133
time: 2.190490245819092
[1, 14612] loss_train: 0.003920, loss_test: 0.005614
time: 0.24605751037597656
time: 2.233502149581909
[1, 14613] loss_train: 0.004422, loss_test: 0.005627
time: 0.24805521965026855
time: 2.2124948501586914
[1, 14614] loss_train: 0.003426, loss_test: 0.005634
time: 0.24605536460876465
time: 2.256009817123413
[1, 14615] loss_train: 0.000900, loss_test: 0.005632
time: 0.25705718994140625
time: 2.223684787750244
[1, 14616] loss_train: 0.005548, loss_test: 0.005621
time: 0.24505400657653809
time: 2.2081260681152344
[1, 14617] loss_train: 0.001464, loss_test: 0.005610
time: 0.2470543384552002
time: 2.2635068893432617
[1, 14618] loss_train: 0.005244, loss_test: 0.005595
time: 0.2470545768737793
time: 2.2114946842193604
[1, 14619] loss_train: 0.007553, loss_test: 0.005582
time: 0.24605488777160645
time: 2.248502731323242
[1, 14620] loss_train: 0.006053, loss_test: 0.005577
time: 0.25708889961242676
time: 2.2234997749328613
[1, 14621] loss_train: 0.006888, loss_test: 0.005582
time: 0.24605441093444824
time: 2.190490245819092
[1, 14622] loss_train: 0.010643, loss_test: 0.005591
time: 0.24406695365905762
time: 2.2134945392608643
[1, 14623] loss_train: 0.004105, loss_test: 0.005602
time: 0.2450563907623291
time: 2.2214972972869873
[1, 14624] loss_train: 0.007409, loss_test: 0.005615
time: 0.24505400657653809
time: 2.2114970684051514
[1, 14625] loss_train: 0.013144, loss_test: 0.005623
time: 0.25005531311035156
time: 2.228498935699463
[1, 14626] loss_train: 0.003776, loss_test: 0.005631
time: 0.24405384063720703
time: 2.2355024814605713
[1, 14627] loss_train: 0.004014, loss_test: 0.005642
time: 0.24306559562683105
time: 2.2003445625305176
[1, 14628] loss_train: 0.006224, loss_test: 0.005647
time: 0.2450542449951172
time: 2.208508014678955
[1, 14629] loss_train: 0.007507, loss_test: 0.005629
time: 0.24505972862243652
time: 2.213494300842285
[1, 14630] loss_train: 0.007833, loss_test: 0.005612
time: 0.2610585689544678
time: 2.2505030632019043
[1, 14631] loss_train: 0.008856, loss_test: 0.005601
time: 0.2510716915130615
time: 2.217498540878296
[1, 14632] loss_train: 0.012600, loss_test: 0.005600
time: 0.2520568370819092
time: 2.219496965408325
[1, 14633] loss_train: 0.003434, loss_test: 0.005611
time: 0.2450563907623291
time: 2.241421699523926
[1, 14634] loss_train: 0.005535, loss_test: 0.005624
time: 0.2490553855895996
time: 2.2335002422332764
[1, 14635] loss_train: 0.001627, loss_test: 0.005636
time: 0.24505376815795898
time: 2.236506223678589
[1, 14636] loss_train: 0.005794, loss_test: 0.005642
time: 0.24805521965026855
time: 2.2144951820373535
[1, 14637] loss_train: 0.010602, loss_test: 0.005633
time: 0.24505400657653809
time: 2.215535879135132
[1, 14638] loss_train: 0.001476, loss_test: 0.005624
time: 0.24405455589294434
time: 2.2365000247955322
[1, 14639] loss_train: 0.007893, loss_test: 0.005616
time: 0.24205327033996582
time: 2.2150232791900635
[1, 14640] loss_train: 0.005297, loss_test: 0.005607
time: 0.2560570240020752
time: 2.2815101146698
[1, 14641] loss_train: 0.008911, loss_test: 0.005602
time: 0.24605464935302734
time: 2.2405009269714355
[1, 14642] loss_train: 0.005661, loss_test: 0.005600
time: 0.24305391311645508
time: 2.2335002422332764
[1, 14643] loss_train: 0.007565, loss_test: 0.005598
time: 0.24505400657653809
time: 2.2385010719299316
[1, 14644] loss_train: 0.003471, loss_test: 0.005598
time: 0.24506664276123047
time: 2.2164957523345947
[1, 14645] loss_train: 0.007236, loss_test: 0.005598
time: 0.2450547218322754
time: 2.2285146713256836
[1, 14646] loss_train: 0.003870, loss_test: 0.005598
time: 0.24405384063720703
time: 2.2014923095703125
[1, 14647] loss_train: 0.002736, loss_test: 0.005600
time: 0.24305415153503418
time: 2.216512680053711
[1, 14648] loss_train: 0.004902, loss_test: 0.005601
time: 0.24406695365905762
time: 2.2254979610443115
[1, 14649] loss_train: 0.004630, loss_test: 0.005604
time: 0.24805521965026855
time: 2.2385082244873047
[1, 14650] loss_train: 0.005432, loss_test: 0.005605
time: 0.25905728340148926
time: 2.2365007400512695
[1, 14651] loss_train: 0.003671, loss_test: 0.005609
time: 0.2450542449951172
time: 2.230499029159546
[1, 14652] loss_train: 0.004256, loss_test: 0.005614
time: 0.24605512619018555
time: 2.246502161026001
[1, 14653] loss_train: 0.004930, loss_test: 0.005611
time: 0.24805521965026855
time: 2.219496011734009
[1, 14654] loss_train: 0.005193, loss_test: 0.005607
time: 0.24406790733337402
time: 2.233499526977539
[1, 14655] loss_train: 0.005618, loss_test: 0.005601
time: 0.24805569648742676
time: 2.251519203186035
[1, 14656] loss_train: 0.009563, loss_test: 0.005596
time: 0.24505376815795898
time: 2.22649884223938
[1, 14657] loss_train: 0.003290, loss_test: 0.005590
time: 0.2470545768737793
time: 2.2335126399993896
[1, 14658] loss_train: 0.002391, loss_test: 0.005585
time: 0.24405360221862793
time: 2.253504514694214
[1, 14659] loss_train: 0.001227, loss_test: 0.005584
time: 0.2470543384552002
time: 2.214512348175049
[1, 14660] loss_train: 0.001068, loss_test: 0.005587
time: 0.25505638122558594
time: 2.2895121574401855
[1, 14661] loss_train: 0.004997, loss_test: 0.005593
time: 0.2490556240081787
time: 2.233499526977539
[1, 14662] loss_train: 0.002473, loss_test: 0.005602
time: 0.2450544834136963
time: 2.2385003566741943
[1, 14663] loss_train: 0.002412, loss_test: 0.005615
time: 0.2470541000366211
time: 2.2330052852630615
[1, 14664] loss_train: 0.005750, loss_test: 0.005631
time: 0.2450556755065918
time: 2.2314980030059814
[1, 14665] loss_train: 0.007031, loss_test: 0.005640
time: 0.2470550537109375
time: 2.256019115447998
[1, 14666] loss_train: 0.005013, loss_test: 0.005646
time: 0.24405455589294434
time: 2.2265002727508545
[1, 14667] loss_train: 0.006741, loss_test: 0.005648
time: 0.24305462837219238
time: 2.2385003566741943
[1, 14668] loss_train: 0.003949, loss_test: 0.005652
time: 0.2490546703338623
time: 2.2445027828216553
[1, 14669] loss_train: 0.002514, loss_test: 0.005659
time: 0.24405336380004883
time: 2.2094948291778564
[1, 14670] loss_train: 0.005623, loss_test: 0.005665
time: 0.256056547164917
time: 2.2655251026153564
[1, 14671] loss_train: 0.009325, loss_test: 0.005668
time: 0.24305367469787598
time: 2.2254979610443115
[1, 14672] loss_train: 0.012408, loss_test: 0.005657
time: 0.24605464935302734
time: 2.2365000247955322
[1, 14673] loss_train: 0.007768, loss_test: 0.005642
time: 0.24205422401428223
time: 2.192490339279175
[1, 14674] loss_train: 0.010116, loss_test: 0.005625
time: 0.24305415153503418
time: 2.2505056858062744
[1, 14675] loss_train: 0.005343, loss_test: 0.005614
time: 0.2450542449951172
time: 2.216496229171753
[1, 14676] loss_train: 0.007004, loss_test: 0.005607
time: 0.2440659999847412
time: 2.2305147647857666
[1, 14677] loss_train: 0.007050, loss_test: 0.005605
time: 0.24505352973937988
time: 2.2475028038024902
[1, 14678] loss_train: 0.009223, loss_test: 0.005606
time: 0.2450549602508545
time: 2.20949387550354
[1, 14679] loss_train: 0.004431, loss_test: 0.005606
time: 0.24405455589294434
time: 2.208512783050537
[1, 14680] loss_train: 0.007351, loss_test: 0.005609
time: 0.26105666160583496
time: 2.2585055828094482
[1, 14681] loss_train: 0.011956, loss_test: 0.005608
time: 0.24505400657653809
time: 2.2204959392547607
[1, 14682] loss_train: 0.004729, loss_test: 0.005605
time: 0.2510557174682617
time: 2.2475035190582275
[1, 14683] loss_train: 0.009766, loss_test: 0.005599
time: 0.2450547218322754
time: 2.2314987182617188
[1, 14684] loss_train: 0.009382, loss_test: 0.005595
time: 0.2510552406311035
time: 2.210494041442871
[1, 14685] loss_train: 0.006538, loss_test: 0.005591
time: 0.24405407905578613
time: 2.2154953479766846
[1, 14686] loss_train: 0.017373, loss_test: 0.005589
time: 0.24805450439453125
time: 2.217506170272827
[1, 14687] loss_train: 0.006485, loss_test: 0.005586
time: 0.24405431747436523
time: 2.2385003566741943
[1, 14688] loss_train: 0.004980, loss_test: 0.005583
time: 0.24505925178527832
time: 2.2255218029022217
[1, 14689] loss_train: 0.008495, loss_test: 0.005583
time: 0.24305438995361328
time: 2.2284984588623047
[1, 14690] loss_train: 0.002614, loss_test: 0.005585
time: 0.2560570240020752
time: 2.2715189456939697
[1, 14691] loss_train: 0.010306, loss_test: 0.005589
time: 0.24305367469787598
time: 2.2515039443969727
[1, 14692] loss_train: 0.005853, loss_test: 0.005597
time: 0.24305367469787598
time: 2.2420339584350586
[1, 14693] loss_train: 0.006887, loss_test: 0.005603
time: 0.24405360221862793
time: 2.2395033836364746
[1, 14694] loss_train: 0.011298, loss_test: 0.005605
time: 0.24305319786071777
time: 2.2385010719299316
[1, 14695] loss_train: 0.007665, loss_test: 0.005606
time: 0.2450556755065918
time: 2.195491313934326
[1, 14696] loss_train: 0.008233, loss_test: 0.005604
time: 0.24505972862243652
time: 2.211493968963623
[1, 14697] loss_train: 0.009118, loss_test: 0.005604
time: 0.24407291412353516
time: 2.2234978675842285
[1, 14698] loss_train: 0.006637, loss_test: 0.005600
time: 0.24405407905578613
time: 2.2485032081604004
[1, 14699] loss_train: 0.009854, loss_test: 0.005597
time: 0.24405384063720703
time: 2.2294979095458984
[1, 14700] loss_train: 0.002899, loss_test: 0.005593
time: 0.25705742835998535
time: 2.2635064125061035
[1, 14701] loss_train: 0.007916, loss_test: 0.005591
time: 0.24405455589294434
time: 2.24302077293396
[1, 14702] loss_train: 0.011192, loss_test: 0.005588
time: 0.2450547218322754
time: 2.2135186195373535
[1, 14703] loss_train: 0.005846, loss_test: 0.005588
time: 0.24606919288635254
time: 2.2294983863830566
[1, 14704] loss_train: 0.005348, loss_test: 0.005589
time: 0.24605441093444824
time: 2.2230162620544434
[1, 14705] loss_train: 0.006271, loss_test: 0.005590
time: 0.24805498123168945
time: 2.213020086288452
[1, 14706] loss_train: 0.010872, loss_test: 0.005592
time: 0.2450542449951172
time: 2.216496706008911
[1, 14707] loss_train: 0.007705, loss_test: 0.005594
time: 0.2470541000366211
time: 2.203493118286133
[1, 14708] loss_train: 0.006761, loss_test: 0.005595
time: 0.24405360221862793
time: 2.2004950046539307
[1, 14709] loss_train: 0.007888, loss_test: 0.005591
time: 0.24605655670166016
time: 2.221497058868408
[1, 14710] loss_train: 0.007180, loss_test: 0.005586
time: 0.2560567855834961
time: 2.258514404296875
[1, 14711] loss_train: 0.003064, loss_test: 0.005582
time: 0.24805474281311035
time: 2.215496063232422
[1, 14712] loss_train: 0.006998, loss_test: 0.005578
time: 0.2450542449951172
time: 2.2680201530456543
[1, 14713] loss_train: 0.014371, loss_test: 0.005577
time: 0.24305415153503418
time: 2.222001552581787
[1, 14714] loss_train: 0.005792, loss_test: 0.005576
time: 0.2450551986694336
time: 2.2164955139160156
[1, 14715] loss_train: 0.007083, loss_test: 0.005578
time: 0.24406814575195312
time: 2.2284982204437256
[1, 14716] loss_train: 0.007726, loss_test: 0.005581
time: 0.24405384063720703
time: 2.2274982929229736
[1, 14717] loss_train: 0.004670, loss_test: 0.005588
time: 0.24605417251586914
time: 2.2224977016448975
[1, 14718] loss_train: 0.002862, loss_test: 0.005598
time: 0.24305343627929688
time: 2.216495990753174
[1, 14719] loss_train: 0.003880, loss_test: 0.005610
time: 0.24605488777160645
time: 2.200655460357666
[1, 14720] loss_train: 0.003189, loss_test: 0.005621
time: 0.25505638122558594
time: 2.2395009994506836
[1, 14721] loss_train: 0.004237, loss_test: 0.005631
time: 0.24505400657653809
time: 2.1905064582824707
[1, 14722] loss_train: 0.004218, loss_test: 0.005632
time: 0.2470548152923584
time: 2.204495429992676
[1, 14723] loss_train: 0.009933, loss_test: 0.005621
time: 0.24605488777160645
time: 2.25228214263916
[1, 14724] loss_train: 0.013431, loss_test: 0.005596
time: 0.24506783485412598
time: 2.2584099769592285
[1, 14725] loss_train: 0.010203, loss_test: 0.005578
time: 0.2450542449951172
time: 2.2330031394958496
[1, 14726] loss_train: 0.003441, loss_test: 0.005570
time: 0.2510559558868408
time: 2.2154958248138428
[1, 14727] loss_train: 0.004687, loss_test: 0.005574
time: 0.24405360221862793
time: 2.2355003356933594
[1, 14728] loss_train: 0.004482, loss_test: 0.005586
time: 0.2450544834136963
time: 2.2097647190093994
[1, 14729] loss_train: 0.000994, loss_test: 0.005599
time: 0.2470545768737793
time: 2.243502616882324
[1, 14730] loss_train: 0.002243, loss_test: 0.005614
time: 0.258056640625
time: 2.2545182704925537
[1, 14731] loss_train: 0.007673, loss_test: 0.005624
time: 0.24405384063720703
time: 2.2244977951049805
[1, 14732] loss_train: 0.007018, loss_test: 0.005632
time: 0.24505400657653809
time: 2.2085072994232178
[1, 14733] loss_train: 0.012712, loss_test: 0.005640
time: 0.24405503273010254
time: 2.234499931335449
[1, 14734] loss_train: 0.004352, loss_test: 0.005642
time: 0.24405384063720703
time: 2.234502077102661
[1, 14735] loss_train: 0.005174, loss_test: 0.005641
time: 0.2450547218322754
time: 2.210510015487671
[1, 14736] loss_train: 0.001787, loss_test: 0.005637
time: 0.24805426597595215
time: 2.279510021209717
[1, 14737] loss_train: 0.007315, loss_test: 0.005637
time: 0.24405455589294434
time: 2.2294983863830566
[1, 14738] loss_train: 0.003333, loss_test: 0.005634
time: 0.24405407905578613
time: 2.2495036125183105
[1, 14739] loss_train: 0.001350, loss_test: 0.005631
time: 0.24306964874267578
time: 2.240004539489746
[1, 14740] loss_train: 0.002452, loss_test: 0.005634
time: 0.25505709648132324
time: 2.2675068378448486
[1, 14741] loss_train: 0.010335, loss_test: 0.005632
time: 0.2450542449951172
time: 2.2064969539642334
[1, 14742] loss_train: 0.005108, loss_test: 0.005627
time: 0.24405384063720703
time: 2.229501485824585
[1, 14743] loss_train: 0.008472, loss_test: 0.005622
time: 0.2450542449951172
time: 2.21449613571167
[1, 14744] loss_train: 0.007236, loss_test: 0.005613
time: 0.24305272102355957
time: 2.225497245788574
[1, 14745] loss_train: 0.009307, loss_test: 0.005597
time: 0.2490549087524414
time: 2.209502935409546
[1, 14746] loss_train: 0.007074, loss_test: 0.005585
time: 0.24605441093444824
time: 2.21750807762146
[1, 14747] loss_train: 0.004127, loss_test: 0.005579
time: 0.24805521965026855
time: 2.209998607635498
[1, 14748] loss_train: 0.003807, loss_test: 0.005578
time: 0.24405407905578613
time: 2.247502565383911
[1, 14749] loss_train: 0.006847, loss_test: 0.005580
time: 0.24505400657653809
time: 2.2235100269317627
[1, 14750] loss_train: 0.005904, loss_test: 0.005584
time: 0.2580573558807373
time: 2.2525033950805664
[1, 14751] loss_train: 0.006559, loss_test: 0.005590
time: 0.24405503273010254
time: 2.2620315551757812
[1, 14752] loss_train: 0.002260, loss_test: 0.005595
time: 0.2450542449951172
time: 2.233508348464966
[1, 14753] loss_train: 0.001007, loss_test: 0.005603
time: 0.2470552921295166
time: 2.205493211746216
[1, 14754] loss_train: 0.001878, loss_test: 0.005606
time: 0.24605464935302734
time: 2.196491241455078
[1, 14755] loss_train: 0.008321, loss_test: 0.005606
time: 0.24605488777160645
time: 2.23249888420105
[1, 14756] loss_train: 0.010016, loss_test: 0.005607
time: 0.24505400657653809
time: 2.2244982719421387
[1, 14757] loss_train: 0.007251, loss_test: 0.005606
time: 0.2450549602508545
time: 2.196491003036499
[1, 14758] loss_train: 0.006489, loss_test: 0.005607
time: 0.2450554370880127
time: 2.211493492126465
[1, 14759] loss_train: 0.003338, loss_test: 0.005610
time: 0.24205374717712402
time: 2.212507963180542
[1, 14760] loss_train: 0.003538, loss_test: 0.005616
time: 0.25705742835998535
time: 2.237499952316284
[1, 14761] loss_train: 0.008819, loss_test: 0.005616
time: 0.24305367469787598
time: 2.2345244884490967
[1, 14762] loss_train: 0.008635, loss_test: 0.005612
time: 0.24706816673278809
time: 2.230498790740967
[1, 14763] loss_train: 0.001840, loss_test: 0.005612
time: 0.24405360221862793
time: 2.2365005016326904
[1, 14764] loss_train: 0.001632, loss_test: 0.005615
time: 0.24806880950927734
time: 2.250502824783325
[1, 14765] loss_train: 0.004556, loss_test: 0.005617
time: 0.2450563907623291
time: 2.2154996395111084
[1, 14766] loss_train: 0.001408, loss_test: 0.005622
time: 0.24805545806884766
time: 2.211493968963623
[1, 14767] loss_train: 0.013482, loss_test: 0.005615
time: 0.2470555305480957
time: 2.2064929008483887
[1, 14768] loss_train: 0.004773, loss_test: 0.005611
time: 0.24405360221862793
time: 2.218496084213257
[1, 14769] loss_train: 0.008855, loss_test: 0.005603
time: 0.24408364295959473
time: 2.2136571407318115
[1, 14770] loss_train: 0.002842, loss_test: 0.005600
time: 0.2540569305419922
time: 2.235499858856201
[1, 14771] loss_train: 0.004647, loss_test: 0.005601
time: 0.24506807327270508
time: 2.2395007610321045
[1, 14772] loss_train: 0.007442, loss_test: 0.005603
time: 0.2450549602508545
time: 2.2410037517547607
[1, 14773] loss_train: 0.012144, loss_test: 0.005605
time: 0.24205350875854492
time: 2.250896692276001
[1, 14774] loss_train: 0.013456, loss_test: 0.005610
time: 0.24405455589294434
time: 2.2134947776794434
[1, 14775] loss_train: 0.006101, loss_test: 0.005613
time: 0.24405479431152344
time: 2.218505620956421
[1, 14776] loss_train: 0.013666, loss_test: 0.005621
time: 0.24305391311645508
time: 2.225497007369995
[1, 14777] loss_train: 0.006124, loss_test: 0.005630
time: 0.24605584144592285
time: 2.240509510040283
[1, 14778] loss_train: 0.003675, loss_test: 0.005640
time: 0.24506783485412598
time: 2.2615063190460205
[1, 14779] loss_train: 0.001720, loss_test: 0.005649
time: 0.24306750297546387
time: 2.2174952030181885
[1, 14780] loss_train: 0.004182, loss_test: 0.005638
time: 0.2580573558807373
time: 2.23249888420105
[1, 14781] loss_train: 0.002225, loss_test: 0.005614
time: 0.24805545806884766
time: 2.245007038116455
[1, 14782] loss_train: 0.005684, loss_test: 0.005593
time: 0.24605417251586914
time: 2.229499101638794
[1, 14783] loss_train: 0.009357, loss_test: 0.005582
time: 0.2420670986175537
time: 2.222510576248169
[1, 14784] loss_train: 0.001884, loss_test: 0.005579
time: 0.2450549602508545
time: 2.2014920711517334
[1, 14785] loss_train: 0.017299, loss_test: 0.005584
time: 0.2510559558868408
time: 2.2348196506500244
[1, 14786] loss_train: 0.002882, loss_test: 0.005596
time: 0.2450547218322754
time: 2.223499059677124
[1, 14787] loss_train: 0.012013, loss_test: 0.005604
time: 0.2540555000305176
time: 2.250330686569214
[1, 14788] loss_train: 0.007407, loss_test: 0.005614
time: 0.24405384063720703
time: 2.229499101638794
[1, 14789] loss_train: 0.004105, loss_test: 0.005621
time: 0.2470552921295166
time: 2.1950135231018066
[1, 14790] loss_train: 0.013661, loss_test: 0.005600
time: 0.2580575942993164
time: 2.219496250152588
[1, 14791] loss_train: 0.012198, loss_test: 0.005583
time: 0.24405360221862793
time: 2.2254981994628906
[1, 14792] loss_train: 0.009248, loss_test: 0.005580
time: 0.24506640434265137
time: 2.253504514694214
[1, 14793] loss_train: 0.012792, loss_test: 0.005587
time: 0.24405360221862793
time: 2.2314999103546143
[1, 14794] loss_train: 0.001947, loss_test: 0.005600
time: 0.24405336380004883
time: 2.2545061111450195
[1, 14795] loss_train: 0.003060, loss_test: 0.005610
time: 0.24405407905578613
time: 2.2114951610565186
[1, 14796] loss_train: 0.005243, loss_test: 0.005619
time: 0.24405384063720703
time: 2.2244977951049805
[1, 14797] loss_train: 0.003610, loss_test: 0.005620
time: 0.2450549602508545
time: 2.2284977436065674
[1, 14798] loss_train: 0.005785, loss_test: 0.005617
time: 0.24406671524047852
time: 2.221510410308838
[1, 14799] loss_train: 0.008179, loss_test: 0.005616
time: 0.2450551986694336
time: 2.1964902877807617
[1, 14800] loss_train: 0.007679, loss_test: 0.005608
time: 0.25707030296325684
time: 2.2935333251953125
[1, 14801] loss_train: 0.005157, loss_test: 0.005599
time: 0.24305391311645508
time: 2.22049880027771
[1, 14802] loss_train: 0.006395, loss_test: 0.005598
time: 0.24505615234375
time: 2.245502471923828
[1, 14803] loss_train: 0.004590, loss_test: 0.005600
time: 0.2450549602508545
time: 2.194490909576416
[1, 14804] loss_train: 0.006815, loss_test: 0.005598
time: 0.2490832805633545
time: 2.2144954204559326
[1, 14805] loss_train: 0.011261, loss_test: 0.005596
time: 0.24605417251586914
time: 2.214498519897461
[1, 14806] loss_train: 0.003100, loss_test: 0.005594
time: 0.2470536231994629
time: 2.2164406776428223
[1, 14807] loss_train: 0.001688, loss_test: 0.005596
time: 0.2436537742614746
time: 2.2365007400512695
[1, 14808] loss_train: 0.004039, loss_test: 0.005604
time: 0.24605512619018555
time: 2.272507667541504
[1, 14809] loss_train: 0.001824, loss_test: 0.005613
time: 0.24605441093444824
time: 2.2155685424804688
[1, 14810] loss_train: 0.004150, loss_test: 0.005624
time: 0.2560567855834961
time: 2.272508382797241
[1, 14811] loss_train: 0.018591, loss_test: 0.005615
time: 0.24506831169128418
time: 2.208494186401367
[1, 14812] loss_train: 0.004690, loss_test: 0.005607
time: 0.24405384063720703
time: 2.242501974105835
[1, 14813] loss_train: 0.003464, loss_test: 0.005600
time: 0.2450547218322754
time: 2.2164955139160156
[1, 14814] loss_train: 0.008042, loss_test: 0.005595
time: 0.24506783485412598
time: 2.235002279281616
[1, 14815] loss_train: 0.007687, loss_test: 0.005592
time: 0.2450549602508545
time: 2.222505807876587
[1, 14816] loss_train: 0.006010, loss_test: 0.005590
time: 0.24305319786071777
time: 2.246572732925415
[1, 14817] loss_train: 0.010722, loss_test: 0.005585
time: 0.24406719207763672
time: 2.1954903602600098
[1, 14818] loss_train: 0.006880, loss_test: 0.005583
time: 0.24405455589294434
time: 2.203003406524658
[1, 14819] loss_train: 0.011924, loss_test: 0.005586
time: 0.24505376815795898
time: 2.2214996814727783
[1, 14820] loss_train: 0.009605, loss_test: 0.005592
time: 0.2560563087463379
time: 2.2690653800964355
[1, 14821] loss_train: 0.005868, loss_test: 0.005599
time: 0.24805474281311035
time: 2.2335002422332764
[1, 14822] loss_train: 0.006118, loss_test: 0.005605
time: 0.24407958984375
time: 2.2255191802978516
[1, 14823] loss_train: 0.002426, loss_test: 0.005605
time: 0.24606776237487793
time: 2.2485055923461914
[1, 14824] loss_train: 0.001888, loss_test: 0.005598
time: 0.24405479431152344
time: 2.2405006885528564
[1, 14825] loss_train: 0.009225, loss_test: 0.005585
time: 0.2450549602508545
time: 2.228426694869995
[1, 14826] loss_train: 0.002275, loss_test: 0.005576
time: 0.24605441093444824
time: 2.232499122619629
[1, 14827] loss_train: 0.006095, loss_test: 0.005573
time: 0.2490551471710205
time: 2.215496063232422
[1, 14828] loss_train: 0.003488, loss_test: 0.005573
time: 0.24605393409729004
time: 2.24601674079895
[1, 14829] loss_train: 0.006017, loss_test: 0.005579
time: 0.24805569648742676
time: 2.2505030632019043
[1, 14830] loss_train: 0.001778, loss_test: 0.005588
time: 0.2580575942993164
time: 2.2155001163482666
[1, 14831] loss_train: 0.004352, loss_test: 0.005602
time: 0.25105714797973633
time: 2.256502389907837
[1, 14832] loss_train: 0.004847, loss_test: 0.005616
time: 0.24406766891479492
time: 2.250502109527588
[1, 14833] loss_train: 0.006190, loss_test: 0.005627
time: 0.2470560073852539
time: 2.23449969291687
[1, 14834] loss_train: 0.007829, loss_test: 0.005633
time: 0.24405431747436523
time: 2.257017135620117
[1, 14835] loss_train: 0.013506, loss_test: 0.005629
time: 0.24605464935302734
time: 2.2154948711395264
[1, 14836] loss_train: 0.004233, loss_test: 0.005619
time: 0.24356722831726074
time: 2.2234959602355957
[1, 14837] loss_train: 0.010681, loss_test: 0.005608
time: 0.24305486679077148
time: 2.2835354804992676
[1, 14838] loss_train: 0.009586, loss_test: 0.005589
time: 0.24405360221862793
time: 2.2455224990844727
[1, 14839] loss_train: 0.001614, loss_test: 0.005581
time: 0.24305343627929688
time: 2.219496726989746
[1, 14840] loss_train: 0.006865, loss_test: 0.005574
time: 0.2560563087463379
time: 2.259467601776123
[1, 14841] loss_train: 0.009544, loss_test: 0.005571
time: 0.24605441093444824
time: 2.219496250152588
[1, 14842] loss_train: 0.007558, loss_test: 0.005571
time: 0.24405407905578613
time: 2.222020387649536
[1, 14843] loss_train: 0.009482, loss_test: 0.005573
time: 0.24505400657653809
time: 2.2535037994384766
[1, 14844] loss_train: 0.004431, loss_test: 0.005577
time: 0.24405407905578613
time: 2.2525038719177246
[1, 14845] loss_train: 0.004998, loss_test: 0.005581
time: 0.24405360221862793
time: 2.2310264110565186
[1, 14846] loss_train: 0.002612, loss_test: 0.005582
time: 0.24305415153503418
time: 2.2415013313293457
[1, 14847] loss_train: 0.002516, loss_test: 0.005579
time: 0.24305415153503418
time: 2.2375001907348633
[1, 14848] loss_train: 0.006910, loss_test: 0.005574
time: 0.2450547218322754
time: 2.22049617767334
[1, 14849] loss_train: 0.002919, loss_test: 0.005566
time: 0.2445676326751709
time: 2.2265007495880127
[1, 14850] loss_train: 0.003008, loss_test: 0.005558
time: 0.25508832931518555
time: 2.2485032081604004
[1, 14851] loss_train: 0.001413, loss_test: 0.005554
time: 0.2490549087524414
time: 2.2114951610565186
[1, 14852] loss_train: 0.008217, loss_test: 0.005554
time: 0.24405574798583984
time: 2.230498790740967
[1, 14853] loss_train: 0.007070, loss_test: 0.005558
time: 0.2450547218322754
time: 2.2244975566864014
[1, 14854] loss_train: 0.006461, loss_test: 0.005563
time: 0.24305391311645508
time: 2.2125070095062256
[1, 14855] loss_train: 0.004501, loss_test: 0.005570
time: 0.2450547218322754
time: 2.2320034503936768
[1, 14856] loss_train: 0.000727, loss_test: 0.005580
time: 0.24606728553771973
time: 2.232499122619629
[1, 14857] loss_train: 0.007701, loss_test: 0.005587
time: 0.2510550022125244
time: 2.227499008178711
[1, 14858] loss_train: 0.009402, loss_test: 0.005592
time: 0.2490544319152832
time: 2.231499671936035
[1, 14859] loss_train: 0.001277, loss_test: 0.005597
time: 0.24605536460876465
time: 2.201491117477417
[1, 14860] loss_train: 0.000961, loss_test: 0.005606
time: 0.25705766677856445
time: 2.273024082183838
[1, 14861] loss_train: 0.003724, loss_test: 0.005617
time: 0.24505376815795898
time: 2.2335002422332764
[1, 14862] loss_train: 0.001608, loss_test: 0.005626
time: 0.24505400657653809
time: 2.2385010719299316
[1, 14863] loss_train: 0.005450, loss_test: 0.005631
time: 0.2450554370880127
time: 2.2204973697662354
[1, 14864] loss_train: 0.009068, loss_test: 0.005620
time: 0.24305152893066406
time: 2.2165095806121826
[1, 14865] loss_train: 0.006422, loss_test: 0.005605
time: 0.24605441093444824
time: 2.2405014038085938
[1, 14866] loss_train: 0.003466, loss_test: 0.005597
time: 0.24405384063720703
time: 2.2355146408081055
[1, 14867] loss_train: 0.005628, loss_test: 0.005590
time: 0.24405431747436523
time: 2.2114946842193604
[1, 14868] loss_train: 0.001345, loss_test: 0.005587
time: 0.2470548152923584
time: 2.2395009994506836
[1, 14869] loss_train: 0.002723, loss_test: 0.005586
time: 0.24305415153503418
time: 2.207493782043457
[1, 14870] loss_train: 0.008857, loss_test: 0.005583
time: 0.2560570240020752
time: 2.259505033493042
[1, 14871] loss_train: 0.008530, loss_test: 0.005581
time: 0.2450544834136963
time: 2.244502305984497
[1, 14872] loss_train: 0.009014, loss_test: 0.005581
time: 0.24405407905578613
time: 2.2460055351257324
[1, 14873] loss_train: 0.005309, loss_test: 0.005582
time: 0.24405431747436523
time: 2.2274978160858154
[1, 14874] loss_train: 0.008173, loss_test: 0.005580
time: 0.2450544834136963
time: 2.2084946632385254
[1, 14875] loss_train: 0.002759, loss_test: 0.005578
time: 0.24605393409729004
time: 2.1954920291900635
[1, 14876] loss_train: 0.002961, loss_test: 0.005574
time: 0.24405455589294434
time: 2.2260231971740723
[1, 14877] loss_train: 0.015690, loss_test: 0.005571
time: 0.2470543384552002
time: 2.239035129547119
[1, 14878] loss_train: 0.000769, loss_test: 0.005569
time: 0.24406647682189941
time: 2.222102642059326
[1, 14879] loss_train: 0.010093, loss_test: 0.005566
time: 0.24805498123168945
time: 2.2254979610443115
[1, 14880] loss_train: 0.005628, loss_test: 0.005564
time: 0.2600574493408203
time: 2.242501974105835
[1, 14881] loss_train: 0.006007, loss_test: 0.005561
time: 0.2470550537109375
time: 2.247504234313965
[1, 14882] loss_train: 0.011917, loss_test: 0.005558
time: 0.2470555305480957
time: 2.213496685028076
[1, 14883] loss_train: 0.002819, loss_test: 0.005555
time: 0.24605560302734375
time: 2.2435011863708496
[1, 14884] loss_train: 0.016313, loss_test: 0.005553
time: 0.2450544834136963
time: 2.244502067565918
[1, 14885] loss_train: 0.010417, loss_test: 0.005552
time: 0.2450542449951172
time: 2.250511407852173
[1, 14886] loss_train: 0.002873, loss_test: 0.005551
time: 0.24405360221862793
time: 2.254504680633545
[1, 14887] loss_train: 0.013114, loss_test: 0.005551
time: 0.24408292770385742
time: 2.2455523014068604
[1, 14888] loss_train: 0.003178, loss_test: 0.005552
time: 0.24405384063720703
time: 2.2365007400512695
[1, 14889] loss_train: 0.007152, loss_test: 0.005554
time: 0.2450549602508545
time: 2.2004919052124023
[1, 14890] loss_train: 0.005025, loss_test: 0.005557
time: 0.2560563087463379
time: 2.2580177783966064
[1, 14891] loss_train: 0.011150, loss_test: 0.005560
time: 0.2440652847290039
time: 2.233499765396118
[1, 14892] loss_train: 0.010908, loss_test: 0.005565
time: 0.2450551986694336
time: 2.2665066719055176
[1, 14893] loss_train: 0.005283, loss_test: 0.005567
time: 0.24306702613830566
time: 2.2460575103759766
[1, 14894] loss_train: 0.006617, loss_test: 0.005568
time: 0.24405431747436523
time: 2.2294981479644775
[1, 14895] loss_train: 0.007991, loss_test: 0.005573
time: 0.2460651397705078
time: 2.246565580368042
[1, 14896] loss_train: 0.005775, loss_test: 0.005578
time: 0.2450549602508545
time: 2.22049617767334
[1, 14897] loss_train: 0.003848, loss_test: 0.005582
time: 0.24406933784484863
time: 2.239499568939209
[1, 14898] loss_train: 0.004960, loss_test: 0.005571
time: 0.24405431747436523
time: 2.188491106033325
[1, 14899] loss_train: 0.003302, loss_test: 0.005558
time: 0.24405407905578613
time: 2.229522466659546
[1, 14900] loss_train: 0.013270, loss_test: 0.005553
time: 0.25705647468566895
time: 2.2645070552825928
[1, 14901] loss_train: 0.007221, loss_test: 0.005553
time: 0.2510695457458496
time: 2.224499464035034
[1, 14902] loss_train: 0.005204, loss_test: 0.005556
time: 0.2470548152923584
time: 2.2144951820373535
[1, 14903] loss_train: 0.010958, loss_test: 0.005559
time: 0.24405384063720703
time: 2.2084944248199463
[1, 14904] loss_train: 0.007724, loss_test: 0.005563
time: 0.2450542449951172
time: 2.224497079849243
[1, 14905] loss_train: 0.002050, loss_test: 0.005570
time: 0.2450549602508545
time: 2.2055130004882812
[1, 14906] loss_train: 0.003506, loss_test: 0.005579
time: 0.24805450439453125
time: 2.243502378463745
[1, 14907] loss_train: 0.004281, loss_test: 0.005588
time: 0.24405217170715332
time: 2.2205286026000977
[1, 14908] loss_train: 0.001655, loss_test: 0.005600
time: 0.2490556240081787
time: 2.2244973182678223
[1, 14909] loss_train: 0.001405, loss_test: 0.005615
time: 0.24705886840820312
time: 2.2255072593688965
[1, 14910] loss_train: 0.006380, loss_test: 0.005622
time: 0.25305676460266113
time: 2.2189993858337402
[1, 14911] loss_train: 0.004387, loss_test: 0.005625
time: 0.24505376815795898
time: 2.210494041442871
[1, 14912] loss_train: 0.002400, loss_test: 0.005630
time: 0.24505376815795898
time: 2.266507625579834
[1, 14913] loss_train: 0.001716, loss_test: 0.005638
time: 0.24405360221862793
time: 2.204528331756592
[1, 14914] loss_train: 0.004321, loss_test: 0.005640
time: 0.24506783485412598
time: 2.2004926204681396
[1, 14915] loss_train: 0.007494, loss_test: 0.005635
time: 0.24306726455688477
time: 2.219212055206299
[1, 14916] loss_train: 0.005184, loss_test: 0.005629
time: 0.2450556755065918
time: 2.25952410697937
[1, 14917] loss_train: 0.010132, loss_test: 0.005612
time: 0.24405384063720703
time: 2.2355029582977295
[1, 14918] loss_train: 0.011395, loss_test: 0.005598
time: 0.24305343627929688
time: 2.242501974105835
[1, 14919] loss_train: 0.006598, loss_test: 0.005590
time: 0.24605441093444824
time: 2.2007861137390137
[1, 14920] loss_train: 0.012301, loss_test: 0.005591
time: 0.25905680656433105
time: 2.2475032806396484
[1, 14921] loss_train: 0.003810, loss_test: 0.005603
time: 0.24507403373718262
time: 2.2485034465789795
[1, 14922] loss_train: 0.000747, loss_test: 0.005632
time: 0.24425506591796875
time: 2.2144951820373535
[1, 14923] loss_train: 0.008476, loss_test: 0.005663
time: 0.24505400657653809
time: 2.2014927864074707
[1, 14924] loss_train: 0.005358, loss_test: 0.005696
time: 0.24605512619018555
time: 2.198491334915161
[1, 14925] loss_train: 0.004018, loss_test: 0.005707
time: 0.2490549087524414
time: 2.226498603820801
[1, 14926] loss_train: 0.005999, loss_test: 0.005708
time: 0.2470543384552002
time: 2.215000867843628
[1, 14927] loss_train: 0.005376, loss_test: 0.005690
time: 0.24305462837219238
time: 2.2164952754974365
[1, 14928] loss_train: 0.009556, loss_test: 0.005672
time: 0.24305367469787598
time: 2.244504451751709
[1, 14929] loss_train: 0.009615, loss_test: 0.005657
time: 0.24506759643554688
time: 2.248518943786621
[1, 14930] loss_train: 0.008982, loss_test: 0.005636
time: 0.25705695152282715
time: 2.2425010204315186
[1, 14931] loss_train: 0.003316, loss_test: 0.005616
time: 0.24305415153503418
time: 2.2505035400390625
[1, 14932] loss_train: 0.006743, loss_test: 0.005605
time: 0.24605393409729004
time: 2.2335002422332764
[1, 14933] loss_train: 0.015578, loss_test: 0.005598
time: 0.24505376815795898
time: 2.232499122619629
[1, 14934] loss_train: 0.007374, loss_test: 0.005587
time: 0.24405550956726074
time: 2.2164971828460693
[1, 14935] loss_train: 0.011876, loss_test: 0.005581
time: 0.2450697422027588
time: 2.21549654006958
[1, 14936] loss_train: 0.005407, loss_test: 0.005577
time: 0.24605393409729004
time: 2.2225048542022705
[1, 14937] loss_train: 0.001850, loss_test: 0.005577
time: 0.24405431747436523
time: 2.2024919986724854
[1, 14938] loss_train: 0.006890, loss_test: 0.005574
time: 0.24505376815795898
time: 2.215508222579956
[1, 14939] loss_train: 0.012715, loss_test: 0.005575
time: 0.24405384063720703
time: 2.2144978046417236
[1, 14940] loss_train: 0.004752, loss_test: 0.005576
time: 0.25905799865722656
time: 2.261505603790283
[1, 14941] loss_train: 0.009320, loss_test: 0.005577
time: 0.2490553855895996
time: 2.2164952754974365
[1, 14942] loss_train: 0.005175, loss_test: 0.005580
time: 0.24805545806884766
time: 2.2415313720703125
[1, 14943] loss_train: 0.006041, loss_test: 0.005578
time: 0.2470541000366211
time: 2.2124953269958496
[1, 14944] loss_train: 0.005386, loss_test: 0.005576
time: 0.24805545806884766
time: 2.2375004291534424
[1, 14945] loss_train: 0.002988, loss_test: 0.005574
time: 0.24505400657653809
time: 2.243501901626587
[1, 14946] loss_train: 0.010561, loss_test: 0.005572
time: 0.2470545768737793
time: 2.228498935699463
[1, 14947] loss_train: 0.008036, loss_test: 0.005570
time: 0.24405384063720703
time: 2.1864895820617676
[1, 14948] loss_train: 0.004633, loss_test: 0.005569
time: 0.24305367469787598
time: 2.229525566101074
[1, 14949] loss_train: 0.001371, loss_test: 0.005568
time: 0.24405384063720703
time: 2.232510566711426
[1, 14950] loss_train: 0.005196, loss_test: 0.005567
time: 0.25705790519714355
time: 2.2635059356689453
[1, 14951] loss_train: 0.007916, loss_test: 0.005570
time: 0.24405384063720703
time: 2.2335054874420166
[1, 14952] loss_train: 0.003184, loss_test: 0.005572
time: 0.24505400657653809
time: 2.2735090255737305
[1, 14953] loss_train: 0.001350, loss_test: 0.005580
time: 0.24405384063720703
time: 2.2365026473999023
[1, 14954] loss_train: 0.003331, loss_test: 0.005592
time: 0.24405384063720703
time: 2.2300291061401367
[1, 14955] loss_train: 0.003772, loss_test: 0.005602
time: 0.24405360221862793
time: 2.2215182781219482
[1, 14956] loss_train: 0.006789, loss_test: 0.005611
time: 0.2470552921295166
time: 2.2545039653778076
[1, 14957] loss_train: 0.002390, loss_test: 0.005617
time: 0.2450542449951172
time: 2.2254979610443115
[1, 14958] loss_train: 0.003206, loss_test: 0.005623
time: 0.24505400657653809
time: 2.2355096340179443
[1, 14959] loss_train: 0.002089, loss_test: 0.005632
time: 0.24306797981262207
time: 2.20849347114563
[1, 14960] loss_train: 0.003765, loss_test: 0.005643
time: 0.25705742835998535
time: 2.2615725994110107
[1, 14961] loss_train: 0.005065, loss_test: 0.005651
time: 0.24405336380004883
time: 2.242502212524414
[1, 14962] loss_train: 0.007512, loss_test: 0.005638
time: 0.2440793514251709
time: 2.2155187129974365
[1, 14963] loss_train: 0.005347, loss_test: 0.005622
time: 0.24805450439453125
time: 2.213498115539551
[1, 14964] loss_train: 0.003118, loss_test: 0.005612
time: 0.24405455589294434
time: 2.2074954509735107
[1, 14965] loss_train: 0.008180, loss_test: 0.005599
time: 0.2460787296295166
time: 2.2365000247955322
[1, 14966] loss_train: 0.008124, loss_test: 0.005599
time: 0.2450547218322754
time: 2.244516134262085
[1, 14967] loss_train: 0.002861, loss_test: 0.005606
time: 0.25205564498901367
time: 2.2104945182800293
[1, 14968] loss_train: 0.006751, loss_test: 0.005615
time: 0.24405455589294434
time: 2.2430059909820557
[1, 14969] loss_train: 0.012563, loss_test: 0.005598
time: 0.2540559768676758
time: 2.2044928073883057
[1, 14970] loss_train: 0.016044, loss_test: 0.005589
time: 0.2560558319091797
time: 2.2504868507385254
[1, 14971] loss_train: 0.009826, loss_test: 0.005585
time: 0.25106096267700195
time: 2.209033250808716
[1, 14972] loss_train: 0.012546, loss_test: 0.005588
time: 0.24605345726013184
time: 2.2505035400390625
[1, 14973] loss_train: 0.003183, loss_test: 0.005596
time: 0.24605512619018555
time: 2.2064931392669678
[1, 14974] loss_train: 0.005267, loss_test: 0.005604
time: 0.2450542449951172
time: 2.2094950675964355
[1, 14975] loss_train: 0.001258, loss_test: 0.005613
time: 0.24405384063720703
time: 2.2074928283691406
[1, 14976] loss_train: 0.002939, loss_test: 0.005622
time: 0.24505949020385742
time: 2.2314999103546143
[1, 14977] loss_train: 0.005079, loss_test: 0.005624
time: 0.24406695365905762
time: 2.2545039653778076
[1, 14978] loss_train: 0.001739, loss_test: 0.005632
time: 0.24405431747436523
time: 2.2515034675598145
[1, 14979] loss_train: 0.001520, loss_test: 0.005647
time: 0.24206781387329102
time: 2.214495897293091
[1, 14980] loss_train: 0.002014, loss_test: 0.005664
time: 0.25905752182006836
time: 2.2895119190216064
[1, 14981] loss_train: 0.005319, loss_test: 0.005676
time: 0.24505400657653809
time: 2.284518241882324
[1, 14982] loss_train: 0.007044, loss_test: 0.005687
time: 0.25104856491088867
time: 2.2489068508148193
[1, 14983] loss_train: 0.004507, loss_test: 0.005703
time: 0.2500731945037842
time: 2.2134954929351807
[1, 14984] loss_train: 0.005484, loss_test: 0.005707
time: 0.24405384063720703
time: 2.2355000972747803
[1, 14985] loss_train: 0.004930, loss_test: 0.005708
time: 0.24508953094482422
time: 2.1994922161102295
[1, 14986] loss_train: 0.010139, loss_test: 0.005680
time: 0.24405455589294434
time: 2.2005131244659424
[1, 14987] loss_train: 0.007383, loss_test: 0.005640
time: 0.24505305290222168
time: 2.1884896755218506
[1, 14988] loss_train: 0.005192, loss_test: 0.005598
time: 0.25005555152893066
time: 2.2154958248138428
[1, 14989] loss_train: 0.010225, loss_test: 0.005562
time: 0.24605417251586914
time: 2.217496633529663
[1, 14990] loss_train: 0.014528, loss_test: 0.005557
time: 0.26605844497680664
time: 2.2865118980407715
[1, 14991] loss_train: 0.006013, loss_test: 0.005590
time: 0.24605512619018555
time: 2.233503818511963
[1, 14992] loss_train: 0.016455, loss_test: 0.005663
time: 0.24805545806884766
time: 2.222496747970581
[1, 14993] loss_train: 0.006204, loss_test: 0.005740
time: 0.24305415153503418
time: 2.2057931423187256
[1, 14994] loss_train: 0.005108, loss_test: 0.005760
time: 0.24605441093444824
time: 2.2234981060028076
[1, 14995] loss_train: 0.001953, loss_test: 0.005772
time: 0.24205350875854492
time: 2.2366034984588623
[1, 14996] loss_train: 0.003593, loss_test: 0.005714
time: 0.24505376815795898
time: 2.2105109691619873
[1, 14997] loss_train: 0.006570, loss_test: 0.005639
time: 0.2470550537109375
time: 2.2815122604370117
[1, 14998] loss_train: 0.004554, loss_test: 0.005592
time: 0.24405360221862793
time: 2.228498935699463
[1, 14999] loss_train: 0.011887, loss_test: 0.005573
time: 0.2450549602508545
time: 2.197298765182495
[1, 15000] loss_train: 0.008539, loss_test: 0.005576
time: 0.25905728340148926
time: 2.283511161804199
[1, 15001] loss_train: 0.006196, loss_test: 0.005592
time: 0.2450547218322754
time: 2.244501829147339
[1, 15002] loss_train: 0.001731, loss_test: 0.005615
time: 0.24406695365905762
time: 2.2094950675964355
[1, 15003] loss_train: 0.005108, loss_test: 0.005641
time: 0.2470550537109375
time: 2.245501756668091
[1, 15004] loss_train: 0.000591, loss_test: 0.005667
time: 0.24505400657653809
time: 2.2224977016448975
[1, 15005] loss_train: 0.001960, loss_test: 0.005695
time: 0.24405407905578613
time: 2.2490479946136475
[1, 15006] loss_train: 0.002265, loss_test: 0.005723
time: 0.24405455589294434
time: 2.2535035610198975
[1, 15007] loss_train: 0.005960, loss_test: 0.005749
time: 0.2450544834136963
time: 2.2130136489868164
[1, 15008] loss_train: 0.012489, loss_test: 0.005735
time: 0.24405407905578613
time: 2.1884896755218506
[1, 15009] loss_train: 0.002725, loss_test: 0.005718
time: 0.24405407905578613
time: 2.1885085105895996
[1, 15010] loss_train: 0.004747, loss_test: 0.005695
time: 0.2580571174621582
time: 2.2465028762817383
[1, 15011] loss_train: 0.005256, loss_test: 0.005666
time: 0.2470552921295166
time: 2.194490671157837
[1, 15012] loss_train: 0.007976, loss_test: 0.005639
time: 0.2470552921295166
time: 2.222496509552002
[1, 15013] loss_train: 0.008282, loss_test: 0.005612
time: 0.2470545768737793
time: 2.2214972972869873
[1, 15014] loss_train: 0.003035, loss_test: 0.005594
time: 0.24505996704101562
time: 2.213494300842285
[1, 15015] loss_train: 0.004481, loss_test: 0.005581
time: 0.24405384063720703
time: 2.235520362854004
[1, 15016] loss_train: 0.001219, loss_test: 0.005572
time: 0.24305510520935059
time: 2.243506908416748
[1, 15017] loss_train: 0.010039, loss_test: 0.005566
time: 0.2450547218322754
time: 2.2295169830322266
[1, 15018] loss_train: 0.006598, loss_test: 0.005568
time: 0.24409198760986328
time: 2.23349928855896
[1, 15019] loss_train: 0.002465, loss_test: 0.005575
time: 0.24405384063720703
time: 2.2135121822357178
[1, 15020] loss_train: 0.002404, loss_test: 0.005585
time: 0.256056547164917
time: 2.268507719039917
[1, 15021] loss_train: 0.001440, loss_test: 0.005596
time: 0.2450542449951172
time: 2.2204971313476562
[1, 15022] loss_train: 0.003562, loss_test: 0.005604
time: 0.2450549602508545
time: 2.2014918327331543
[1, 15023] loss_train: 0.009216, loss_test: 0.005608
time: 0.24405455589294434
time: 2.2254977226257324
[1, 15024] loss_train: 0.010321, loss_test: 0.005611
time: 0.2470550537109375
time: 2.2034945487976074
[1, 15025] loss_train: 0.002942, loss_test: 0.005602
time: 0.24605417251586914
time: 2.239501476287842
[1, 15026] loss_train: 0.007267, loss_test: 0.005593
time: 0.24405384063720703
time: 2.2125072479248047
[1, 15027] loss_train: 0.006217, loss_test: 0.005585
time: 0.24605488777160645
time: 2.246502637863159
[1, 15028] loss_train: 0.002169, loss_test: 0.005580
time: 0.24605441093444824
time: 2.228498935699463
[1, 15029] loss_train: 0.011966, loss_test: 0.005572
time: 0.24405407905578613
time: 2.2264983654022217
[1, 15030] loss_train: 0.001826, loss_test: 0.005568
time: 0.25905752182006836
time: 2.2655062675476074
[1, 15031] loss_train: 0.005789, loss_test: 0.005568
time: 0.251056432723999
time: 2.2224979400634766
[1, 15032] loss_train: 0.001358, loss_test: 0.005577
time: 0.24805545806884766
time: 2.188490152359009
[1, 15033] loss_train: 0.010274, loss_test: 0.005581
time: 0.24405360221862793
time: 2.2234976291656494
[1, 15034] loss_train: 0.002397, loss_test: 0.005587
time: 0.24405360221862793
time: 2.21850848197937
[1, 15035] loss_train: 0.016973, loss_test: 0.005590
time: 0.24405360221862793
time: 2.217496395111084
[1, 15036] loss_train: 0.009092, loss_test: 0.005596
time: 0.24405407905578613
time: 2.236029624938965
[1, 15037] loss_train: 0.006702, loss_test: 0.005599
time: 0.25205564498901367
time: 2.2405011653900146
[1, 15038] loss_train: 0.005487, loss_test: 0.005604
time: 0.24405384063720703
time: 2.2221763134002686
[1, 15039] loss_train: 0.003251, loss_test: 0.005609
time: 0.24405384063720703
time: 2.2332210540771484
[1, 15040] loss_train: 0.005425, loss_test: 0.005605
time: 0.25705718994140625
time: 2.2600080966949463
[1, 15041] loss_train: 0.002148, loss_test: 0.005603
time: 0.24605369567871094
time: 2.2375009059906006
[1, 15042] loss_train: 0.006241, loss_test: 0.005597
time: 0.24405360221862793
time: 2.2244982719421387
[1, 15043] loss_train: 0.006677, loss_test: 0.005591
time: 0.24305391311645508
time: 2.183488130569458
[1, 15044] loss_train: 0.006292, loss_test: 0.005582
time: 0.24405384063720703
time: 2.229499101638794
[1, 15045] loss_train: 0.004725, loss_test: 0.005577
time: 0.24505400657653809
time: 2.1984915733337402
[1, 15046] loss_train: 0.005391, loss_test: 0.005574
time: 0.2470550537109375
time: 2.2335000038146973
[1, 15047] loss_train: 0.004846, loss_test: 0.005574
time: 0.2470543384552002
time: 2.2264981269836426
[1, 15048] loss_train: 0.007819, loss_test: 0.005574
time: 0.2470560073852539
time: 2.222104549407959
[1, 15049] loss_train: 0.017246, loss_test: 0.005574
time: 0.2490549087524414
time: 2.2340283393859863
[1, 15050] loss_train: 0.008387, loss_test: 0.005576
time: 0.25705742835998535
time: 2.238004684448242
[1, 15051] loss_train: 0.009517, loss_test: 0.005575
time: 0.2520558834075928
time: 2.2124950885772705
[1, 15052] loss_train: 0.008713, loss_test: 0.005574
time: 0.24405431747436523
time: 2.245504856109619
[1, 15053] loss_train: 0.004567, loss_test: 0.005574
time: 0.24505376815795898
time: 2.2365012168884277
[1, 15054] loss_train: 0.012746, loss_test: 0.005576
time: 0.24505400657653809
time: 2.2355000972747803
[1, 15055] loss_train: 0.001368, loss_test: 0.005580
time: 0.24405384063720703
time: 2.2395007610321045
[1, 15056] loss_train: 0.003093, loss_test: 0.005586
time: 0.24405407905578613
time: 2.235018491744995
[1, 15057] loss_train: 0.004329, loss_test: 0.005594
time: 0.24405384063720703
time: 2.2144954204559326
[1, 15058] loss_train: 0.009210, loss_test: 0.005594
time: 0.24605488777160645
time: 2.272520065307617
[1, 15059] loss_train: 0.002069, loss_test: 0.005588
time: 0.24405431747436523
time: 2.231499195098877
[1, 15060] loss_train: 0.010298, loss_test: 0.005581
time: 0.25505614280700684
time: 2.2455029487609863
[1, 15061] loss_train: 0.004014, loss_test: 0.005575
time: 0.24605393409729004
time: 2.227498769760132
[1, 15062] loss_train: 0.006835, loss_test: 0.005569
time: 0.24305343627929688
time: 2.227501392364502
[1, 15063] loss_train: 0.010233, loss_test: 0.005567
time: 0.2580575942993164
time: 2.248502254486084
[1, 15064] loss_train: 0.007866, loss_test: 0.005564
time: 0.2450542449951172
time: 2.225029945373535
[1, 15065] loss_train: 0.008967, loss_test: 0.005564
time: 0.24305391311645508
time: 2.2625060081481934
[1, 15066] loss_train: 0.001754, loss_test: 0.005567
time: 0.2440636157989502
time: 2.218496799468994
[1, 15067] loss_train: 0.005135, loss_test: 0.005571
time: 0.24405360221862793
time: 2.204493761062622
[1, 15068] loss_train: 0.007436, loss_test: 0.005575
time: 0.2470543384552002
time: 2.1945345401763916
[1, 15069] loss_train: 0.005166, loss_test: 0.005580
time: 0.24405479431152344
time: 2.2004942893981934
[1, 15070] loss_train: 0.001786, loss_test: 0.005584
time: 0.2600574493408203
time: 2.242501974105835
[1, 15071] loss_train: 0.003155, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2385005950927734
[1, 15072] loss_train: 0.006978, loss_test: 0.005592
time: 0.2490551471710205
time: 2.214495897293091
[1, 15073] loss_train: 0.001907, loss_test: 0.005598
time: 0.24305343627929688
time: 2.2074944972991943
[1, 15074] loss_train: 0.008441, loss_test: 0.005603
time: 0.2470545768737793
time: 2.2320353984832764
[1, 15075] loss_train: 0.004135, loss_test: 0.005609
time: 0.24505376815795898
time: 2.2234981060028076
[1, 15076] loss_train: 0.004518, loss_test: 0.005612
time: 0.24356746673583984
time: 2.2264981269836426
[1, 15077] loss_train: 0.004257, loss_test: 0.005614
time: 0.24305438995361328
time: 2.234499931335449
[1, 15078] loss_train: 0.008101, loss_test: 0.005611
time: 0.24405384063720703
time: 2.2585208415985107
[1, 15079] loss_train: 0.003422, loss_test: 0.005610
time: 0.24405431747436523
time: 2.235515832901001
[1, 15080] loss_train: 0.008374, loss_test: 0.005604
time: 0.2560572624206543
time: 2.2104947566986084
[1, 15081] loss_train: 0.004923, loss_test: 0.005600
time: 0.24605441093444824
time: 2.233499765396118
[1, 15082] loss_train: 0.006341, loss_test: 0.005592
time: 0.2450542449951172
time: 2.229501962661743
[1, 15083] loss_train: 0.003490, loss_test: 0.005588
time: 0.24405646324157715
time: 2.208495616912842
[1, 15084] loss_train: 0.008951, loss_test: 0.005587
time: 0.24506831169128418
time: 2.2390260696411133
[1, 15085] loss_train: 0.001262, loss_test: 0.005589
time: 0.2490682601928711
time: 2.243502140045166
[1, 15086] loss_train: 0.004893, loss_test: 0.005593
time: 0.24405384063720703
time: 2.1954915523529053
[1, 15087] loss_train: 0.013064, loss_test: 0.005589
time: 0.2490556240081787
time: 2.2224977016448975
[1, 15088] loss_train: 0.004295, loss_test: 0.005588
time: 0.25505518913269043
time: 2.2475030422210693
[1, 15089] loss_train: 0.001406, loss_test: 0.005585
time: 0.24805784225463867
time: 2.2565019130706787
[1, 15090] loss_train: 0.007946, loss_test: 0.005582
time: 0.25705814361572266
time: 2.2324984073638916
[1, 15091] loss_train: 0.001748, loss_test: 0.005581
time: 0.24605512619018555
time: 2.2014920711517334
[1, 15092] loss_train: 0.008178, loss_test: 0.005582
time: 0.24706649780273438
time: 2.217496395111084
[1, 15093] loss_train: 0.004069, loss_test: 0.005583
time: 0.2470550537109375
time: 2.21650767326355
[1, 15094] loss_train: 0.004883, loss_test: 0.005581
time: 0.24605488777160645
time: 2.1814887523651123
[1, 15095] loss_train: 0.007068, loss_test: 0.005579
time: 0.24405360221862793
time: 2.2555220127105713
[1, 15096] loss_train: 0.002850, loss_test: 0.005578
time: 0.24605417251586914
time: 2.2250189781188965
[1, 15097] loss_train: 0.004495, loss_test: 0.005577
time: 0.24405384063720703
time: 2.192491054534912
[1, 15098] loss_train: 0.005445, loss_test: 0.005575
time: 0.24405431747436523
time: 2.2345130443573
[1, 15099] loss_train: 0.004801, loss_test: 0.005571
time: 0.2450544834136963
time: 2.2365005016326904
[1, 15100] loss_train: 0.007125, loss_test: 0.005569
time: 0.25905799865722656
time: 2.295513391494751
[1, 15101] loss_train: 0.004925, loss_test: 0.005566
time: 0.24305319786071777
time: 2.252939224243164
[1, 15102] loss_train: 0.004908, loss_test: 0.005564
time: 0.24805498123168945
time: 2.2124972343444824
[1, 15103] loss_train: 0.011724, loss_test: 0.005562
time: 0.2450547218322754
time: 2.2275006771087646
[1, 15104] loss_train: 0.007034, loss_test: 0.005562
time: 0.24507951736450195
time: 2.244504451751709
[1, 15105] loss_train: 0.004817, loss_test: 0.005564
time: 0.24405455589294434
time: 2.2204978466033936
[1, 15106] loss_train: 0.003824, loss_test: 0.005566
time: 0.24405384063720703
time: 2.23349928855896
[1, 15107] loss_train: 0.002921, loss_test: 0.005568
time: 0.24405312538146973
time: 2.1934916973114014
[1, 15108] loss_train: 0.009419, loss_test: 0.005571
time: 0.24405312538146973
time: 2.228499174118042
[1, 15109] loss_train: 0.009856, loss_test: 0.005573
time: 0.2490551471710205
time: 2.219496488571167
[1, 15110] loss_train: 0.002595, loss_test: 0.005573
time: 0.25705647468566895
time: 2.2355003356933594
[1, 15111] loss_train: 0.002866, loss_test: 0.005571
time: 0.2490558624267578
time: 2.261507987976074
[1, 15112] loss_train: 0.003845, loss_test: 0.005570
time: 0.24505400657653809
time: 2.2264981269836426
[1, 15113] loss_train: 0.000604, loss_test: 0.005572
time: 0.24605488777160645
time: 2.2365002632141113
[1, 15114] loss_train: 0.001726, loss_test: 0.005581
time: 0.2470543384552002
time: 2.219496726989746
[1, 15115] loss_train: 0.007861, loss_test: 0.005591
time: 0.24605512619018555
time: 2.2615139484405518
[1, 15116] loss_train: 0.008879, loss_test: 0.005596
time: 0.25005578994750977
time: 2.1945087909698486
[1, 15117] loss_train: 0.006039, loss_test: 0.005593
time: 0.24405407905578613
time: 2.209494113922119
[1, 15118] loss_train: 0.004546, loss_test: 0.005590
time: 0.24305343627929688
time: 2.2224974632263184
[1, 15119] loss_train: 0.003723, loss_test: 0.005588
time: 0.24205350875854492
time: 2.2485554218292236
[1, 15120] loss_train: 0.001416, loss_test: 0.005589
time: 0.25705718994140625
time: 2.2375051975250244
[1, 15121] loss_train: 0.004025, loss_test: 0.005590
time: 0.2450542449951172
time: 2.2154955863952637
[1, 15122] loss_train: 0.011018, loss_test: 0.005588
time: 0.24305367469787598
time: 2.2244973182678223
[1, 15123] loss_train: 0.002058, loss_test: 0.005587
time: 0.24405503273010254
time: 2.234499454498291
[1, 15124] loss_train: 0.009957, loss_test: 0.005591
time: 0.24305343627929688
time: 2.2204971313476562
[1, 15125] loss_train: 0.007880, loss_test: 0.005593
time: 0.24405384063720703
time: 2.223497152328491
[1, 15126] loss_train: 0.005549, loss_test: 0.005591
time: 0.24605464935302734
time: 2.2365012168884277
[1, 15127] loss_train: 0.006330, loss_test: 0.005596
time: 0.24505352973937988
time: 2.2175137996673584
[1, 15128] loss_train: 0.007568, loss_test: 0.005600
time: 0.24505376815795898
time: 2.2245171070098877
[1, 15129] loss_train: 0.004932, loss_test: 0.005598
time: 0.24405360221862793
time: 2.2350528240203857
[1, 15130] loss_train: 0.003047, loss_test: 0.005600
time: 0.256056547164917
time: 2.2515032291412354
[1, 15131] loss_train: 0.009551, loss_test: 0.005596
time: 0.24606728553771973
time: 2.2234976291656494
[1, 15132] loss_train: 0.011625, loss_test: 0.005592
time: 0.24405455589294434
time: 2.2024950981140137
[1, 15133] loss_train: 0.003359, loss_test: 0.005588
time: 0.2510561943054199
time: 2.1874916553497314
[1, 15134] loss_train: 0.009779, loss_test: 0.005583
time: 0.2450544834136963
time: 2.2525036334991455
[1, 15135] loss_train: 0.003311, loss_test: 0.005580
time: 0.24706625938415527
time: 2.2004928588867188
[1, 15136] loss_train: 0.015140, loss_test: 0.005578
time: 0.24405384063720703
time: 2.22049617767334
[1, 15137] loss_train: 0.008636, loss_test: 0.005579
time: 0.24508428573608398
time: 2.251518964767456
[1, 15138] loss_train: 0.002808, loss_test: 0.005583
time: 0.2430555820465088
time: 2.2375001907348633
[1, 15139] loss_train: 0.004225, loss_test: 0.005588
time: 0.24405336380004883
time: 2.2444546222686768
[1, 15140] loss_train: 0.000958, loss_test: 0.005588
time: 0.2560567855834961
time: 2.2845184803009033
[1, 15141] loss_train: 0.011194, loss_test: 0.005588
time: 0.2470548152923584
time: 2.2144954204559326
[1, 15142] loss_train: 0.007625, loss_test: 0.005590
time: 0.24405336380004883
time: 2.227498769760132
[1, 15143] loss_train: 0.003220, loss_test: 0.005590
time: 0.2450556755065918
time: 2.228498697280884
[1, 15144] loss_train: 0.003863, loss_test: 0.005586
time: 0.24305391311645508
time: 2.203493356704712
[1, 15145] loss_train: 0.002224, loss_test: 0.005582
time: 0.24405384063720703
time: 2.2114951610565186
[1, 15146] loss_train: 0.007556, loss_test: 0.005581
time: 0.24605488777160645
time: 2.2280027866363525
[1, 15147] loss_train: 0.001419, loss_test: 0.005580
time: 0.24505352973937988
time: 2.229499101638794
[1, 15148] loss_train: 0.013262, loss_test: 0.005574
time: 0.24405431747436523
time: 2.2004921436309814
[1, 15149] loss_train: 0.003292, loss_test: 0.005574
time: 0.24605417251586914
time: 2.217017412185669
[1, 15150] loss_train: 0.003303, loss_test: 0.005578
time: 0.2580578327178955
time: 2.266510248184204
[1, 15151] loss_train: 0.006785, loss_test: 0.005580
time: 0.24405574798583984
time: 2.2314999103546143
[1, 15152] loss_train: 0.010699, loss_test: 0.005581
time: 0.24805951118469238
time: 2.2264974117279053
[1, 15153] loss_train: 0.008335, loss_test: 0.005582
time: 0.24805545806884766
time: 2.217496156692505
[1, 15154] loss_train: 0.008536, loss_test: 0.005580
time: 0.24605488777160645
time: 2.2220325469970703
[1, 15155] loss_train: 0.008187, loss_test: 0.005576
time: 0.24405360221862793
time: 2.2224974632263184
[1, 15156] loss_train: 0.006069, loss_test: 0.005574
time: 0.245863676071167
time: 2.232509136199951
[1, 15157] loss_train: 0.004703, loss_test: 0.005574
time: 0.24305391311645508
time: 2.219496250152588
[1, 15158] loss_train: 0.018465, loss_test: 0.005575
time: 0.24405384063720703
time: 2.2375011444091797
[1, 15159] loss_train: 0.001825, loss_test: 0.005580
time: 0.24305367469787598
time: 2.2375032901763916
[1, 15160] loss_train: 0.006821, loss_test: 0.005585
time: 0.25505685806274414
time: 2.2250008583068848
[1, 15161] loss_train: 0.005530, loss_test: 0.005587
time: 0.2450549602508545
time: 2.270927667617798
[1, 15162] loss_train: 0.008210, loss_test: 0.005590
time: 0.24363422393798828
time: 2.220400094985962
[1, 15163] loss_train: 0.003000, loss_test: 0.005588
time: 0.24405431747436523
time: 2.243501901626587
[1, 15164] loss_train: 0.005613, loss_test: 0.005583
time: 0.24405431747436523
time: 2.2254974842071533
[1, 15165] loss_train: 0.005553, loss_test: 0.005578
time: 0.24305391311645508
time: 2.226497173309326
[1, 15166] loss_train: 0.010742, loss_test: 0.005574
time: 0.24805474281311035
time: 2.1940088272094727
[1, 15167] loss_train: 0.006039, loss_test: 0.005572
time: 0.24405431747436523
time: 2.245502233505249
[1, 15168] loss_train: 0.004235, loss_test: 0.005573
time: 0.24406647682189941
time: 2.234508514404297
[1, 15169] loss_train: 0.006432, loss_test: 0.005575
time: 0.24405407905578613
time: 2.1960253715515137
[1, 15170] loss_train: 0.001790, loss_test: 0.005580
time: 0.25705766677856445
time: 2.2534232139587402
[1, 15171] loss_train: 0.010847, loss_test: 0.005585
time: 0.24605512619018555
time: 2.236504316329956
[1, 15172] loss_train: 0.007474, loss_test: 0.005591
time: 0.2450544834136963
time: 2.2515039443969727
[1, 15173] loss_train: 0.012818, loss_test: 0.005597
time: 0.24806666374206543
time: 2.219496726989746
[1, 15174] loss_train: 0.007462, loss_test: 0.005599
time: 0.24506759643554688
time: 2.2004928588867188
[1, 15175] loss_train: 0.008109, loss_test: 0.005593
time: 0.2450544834136963
time: 2.2264976501464844
[1, 15176] loss_train: 0.001252, loss_test: 0.005588
time: 0.24605512619018555
time: 2.2390074729919434
[1, 15177] loss_train: 0.005101, loss_test: 0.005587
time: 0.24605441093444824
time: 2.216306447982788
[1, 15178] loss_train: 0.007417, loss_test: 0.005586
time: 0.24305391311645508
time: 2.2341086864471436
[1, 15179] loss_train: 0.009447, loss_test: 0.005583
time: 0.2450544834136963
time: 2.242513656616211
[1, 15180] loss_train: 0.008004, loss_test: 0.005581
time: 0.25608086585998535
time: 2.24550199508667
[1, 15181] loss_train: 0.000898, loss_test: 0.005582
time: 0.251056432723999
time: 2.247511148452759
[1, 15182] loss_train: 0.004715, loss_test: 0.005582
time: 0.24505400657653809
time: 2.2390036582946777
[1, 15183] loss_train: 0.009153, loss_test: 0.005580
time: 0.2470550537109375
time: 2.208493947982788
[1, 15184] loss_train: 0.002994, loss_test: 0.005575
time: 0.24405384063720703
time: 2.2700278759002686
[1, 15185] loss_train: 0.019820, loss_test: 0.005565
time: 0.24405360221862793
time: 2.239525079727173
[1, 15186] loss_train: 0.008385, loss_test: 0.005569
time: 0.24505400657653809
time: 2.2585058212280273
[1, 15187] loss_train: 0.009044, loss_test: 0.005582
time: 0.24505376815795898
time: 2.240504026412964
[1, 15188] loss_train: 0.002742, loss_test: 0.005596
time: 0.24405479431152344
time: 2.2415194511413574
[1, 15189] loss_train: 0.003862, loss_test: 0.005611
time: 0.2450547218322754
time: 2.1905064582824707
[1, 15190] loss_train: 0.004498, loss_test: 0.005615
time: 0.2560572624206543
time: 2.248502492904663
[1, 15191] loss_train: 0.004145, loss_test: 0.005604
time: 0.24505400657653809
time: 2.1999971866607666
[1, 15192] loss_train: 0.007122, loss_test: 0.005591
time: 0.24405384063720703
time: 2.191490888595581
[1, 15193] loss_train: 0.005871, loss_test: 0.005578
time: 0.24605417251586914
time: 2.2114949226379395
[1, 15194] loss_train: 0.003523, loss_test: 0.005571
time: 0.2490546703338623
time: 2.2114949226379395
[1, 15195] loss_train: 0.001891, loss_test: 0.005566
time: 0.24605488777160645
time: 2.223497152328491
[1, 15196] loss_train: 0.007655, loss_test: 0.005567
time: 0.2470545768737793
time: 2.2245523929595947
[1, 15197] loss_train: 0.002385, loss_test: 0.005575
time: 0.2470552921295166
time: 2.194490909576416
[1, 15198] loss_train: 0.004200, loss_test: 0.005589
time: 0.24405336380004883
time: 2.244502544403076
[1, 15199] loss_train: 0.010577, loss_test: 0.005598
time: 0.24605512619018555
time: 2.2195053100585938
[1, 15200] loss_train: 0.002014, loss_test: 0.005612
time: 0.25905728340148926
time: 2.308516502380371
[1, 15201] loss_train: 0.009723, loss_test: 0.005622
time: 0.2450549602508545
time: 2.215998649597168
[1, 15202] loss_train: 0.004766, loss_test: 0.005632
time: 0.2440640926361084
time: 2.240501642227173
[1, 15203] loss_train: 0.000362, loss_test: 0.005641
time: 0.24605512619018555
time: 2.2440240383148193
[1, 15204] loss_train: 0.008849, loss_test: 0.005646
time: 0.24405431747436523
time: 2.217496633529663
[1, 15205] loss_train: 0.001968, loss_test: 0.005650
time: 0.2450542449951172
time: 2.203995943069458
[1, 15206] loss_train: 0.008568, loss_test: 0.005648
time: 0.2450549602508545
time: 2.2204971313476562
[1, 15207] loss_train: 0.009429, loss_test: 0.005637
time: 0.25005578994750977
time: 2.227499485015869
[1, 15208] loss_train: 0.006537, loss_test: 0.005621
time: 0.24405455589294434
time: 2.2274985313415527
[1, 15209] loss_train: 0.000547, loss_test: 0.005611
time: 0.24205350875854492
time: 2.2235100269317627
[1, 15210] loss_train: 0.007655, loss_test: 0.005599
time: 0.2580575942993164
time: 2.260505199432373
[1, 15211] loss_train: 0.013687, loss_test: 0.005588
time: 0.24271893501281738
time: 2.2244977951049805
[1, 15212] loss_train: 0.005716, loss_test: 0.005579
time: 0.24405455589294434
time: 2.245511054992676
[1, 15213] loss_train: 0.004649, loss_test: 0.005573
time: 0.24505400657653809
time: 2.2485032081604004
[1, 15214] loss_train: 0.005707, loss_test: 0.005570
time: 0.2450544834136963
time: 2.2435009479522705
[1, 15215] loss_train: 0.012815, loss_test: 0.005569
time: 0.24305272102355957
time: 2.2114951610565186
[1, 15216] loss_train: 0.004105, loss_test: 0.005570
time: 0.2450544834136963
time: 2.2235171794891357
[1, 15217] loss_train: 0.016878, loss_test: 0.005571
time: 0.24805545806884766
time: 2.2054712772369385
[1, 15218] loss_train: 0.005836, loss_test: 0.005574
time: 0.2450547218322754
time: 2.2314987182617188
[1, 15219] loss_train: 0.002326, loss_test: 0.005581
time: 0.2470543384552002
time: 2.2465028762817383
[1, 15220] loss_train: 0.011797, loss_test: 0.005588
time: 0.25705671310424805
time: 2.267507553100586
[1, 15221] loss_train: 0.004765, loss_test: 0.005595
time: 0.24605488777160645
time: 2.235499620437622
[1, 15222] loss_train: 0.010817, loss_test: 0.005599
time: 0.2450544834136963
time: 2.244501829147339
[1, 15223] loss_train: 0.003137, loss_test: 0.005601
time: 0.2470550537109375
time: 2.233499765396118
[1, 15224] loss_train: 0.004675, loss_test: 0.005597
time: 0.24805474281311035
time: 2.232004165649414
[1, 15225] loss_train: 0.007003, loss_test: 0.005597
time: 0.24505376815795898
time: 2.20149302482605
[1, 15226] loss_train: 0.004603, loss_test: 0.005603
time: 0.2440776824951172
time: 2.2420096397399902
[1, 15227] loss_train: 0.013316, loss_test: 0.005596
time: 0.2460794448852539
time: 2.212998151779175
[1, 15228] loss_train: 0.008426, loss_test: 0.005592
time: 0.24405384063720703
time: 2.231499671936035
[1, 15229] loss_train: 0.007726, loss_test: 0.005590
time: 0.24305343627929688
time: 2.2285263538360596
[1, 15230] loss_train: 0.005256, loss_test: 0.005589
time: 0.25705647468566895
time: 2.2615063190460205
[1, 15231] loss_train: 0.002170, loss_test: 0.005593
time: 0.2470545768737793
time: 2.213000535964966
[1, 15232] loss_train: 0.009469, loss_test: 0.005592
time: 0.24206972122192383
time: 2.2204973697662354
[1, 15233] loss_train: 0.011012, loss_test: 0.005591
time: 0.24606776237487793
time: 2.2345001697540283
[1, 15234] loss_train: 0.010054, loss_test: 0.005600
time: 0.24405384063720703
time: 2.2154958248138428
[1, 15235] loss_train: 0.007940, loss_test: 0.005611
time: 0.24605536460876465
time: 2.226027727127075
[1, 15236] loss_train: 0.014292, loss_test: 0.005630
time: 0.24405241012573242
time: 2.2375144958496094
[1, 15237] loss_train: 0.004813, loss_test: 0.005654
time: 0.24706792831420898
time: 2.1944899559020996
[1, 15238] loss_train: 0.013733, loss_test: 0.005688
time: 0.24506425857543945
time: 2.195491313934326
[1, 15239] loss_train: 0.005063, loss_test: 0.005725
time: 0.24605441093444824
time: 2.2273612022399902
[1, 15240] loss_train: 0.010689, loss_test: 0.005738
time: 0.2600827217102051
time: 2.244502544403076
[1, 15241] loss_train: 0.003637, loss_test: 0.005749
time: 0.2470684051513672
time: 2.249502658843994
[1, 15242] loss_train: 0.003613, loss_test: 0.005709
time: 0.24405455589294434
time: 2.203495979309082
[1, 15243] loss_train: 0.004612, loss_test: 0.005669
time: 0.2450542449951172
time: 2.221497058868408
[1, 15244] loss_train: 0.001619, loss_test: 0.005615
time: 0.24406790733337402
time: 2.2034928798675537
[1, 15245] loss_train: 0.006360, loss_test: 0.005585
time: 0.24405455589294434
time: 2.24550199508667
[1, 15246] loss_train: 0.008788, loss_test: 0.005572
time: 0.2450542449951172
time: 2.206510066986084
[1, 15247] loss_train: 0.017341, loss_test: 0.005574
time: 0.24405360221862793
time: 2.2425050735473633
[1, 15248] loss_train: 0.011446, loss_test: 0.005584
time: 0.24507784843444824
time: 2.2424356937408447
[1, 15249] loss_train: 0.008565, loss_test: 0.005595
time: 0.24605584144592285
time: 2.212031126022339
[1, 15250] loss_train: 0.005693, loss_test: 0.005603
time: 0.25707101821899414
time: 2.24751615524292
[1, 15251] loss_train: 0.003138, loss_test: 0.005614
time: 0.24805521965026855
time: 2.2785096168518066
[1, 15252] loss_train: 0.008755, loss_test: 0.005625
time: 0.24405455589294434
time: 2.2415010929107666
[1, 15253] loss_train: 0.007661, loss_test: 0.005629
time: 0.2450544834136963
time: 2.2304985523223877
[1, 15254] loss_train: 0.005677, loss_test: 0.005633
time: 0.24405455589294434
time: 2.2255115509033203
[1, 15255] loss_train: 0.010903, loss_test: 0.005638
time: 0.24405336380004883
time: 2.2124955654144287
[1, 15256] loss_train: 0.003729, loss_test: 0.005642
time: 0.24605512619018555
time: 2.2385003566741943
[1, 15257] loss_train: 0.011252, loss_test: 0.005633
time: 0.2450542449951172
time: 2.247504472732544
[1, 15258] loss_train: 0.006378, loss_test: 0.005624
time: 0.24405527114868164
time: 2.222104787826538
[1, 15259] loss_train: 0.005958, loss_test: 0.005612
time: 0.2450547218322754
time: 2.2134969234466553
[1, 15260] loss_train: 0.006849, loss_test: 0.005598
time: 0.25705695152282715
time: 2.258505344390869
[1, 15261] loss_train: 0.008105, loss_test: 0.005589
time: 0.25205564498901367
time: 2.2274978160858154
[1, 15262] loss_train: 0.007518, loss_test: 0.005582
time: 0.2450547218322754
time: 2.224515914916992
[1, 15263] loss_train: 0.010513, loss_test: 0.005578
time: 0.2490549087524414
time: 2.2385010719299316
[1, 15264] loss_train: 0.003390, loss_test: 0.005579
time: 0.2450544834136963
time: 2.2284984588623047
[1, 15265] loss_train: 0.002932, loss_test: 0.005580
time: 0.2470545768737793
time: 2.2335000038146973
[1, 15266] loss_train: 0.006729, loss_test: 0.005582
time: 0.24405455589294434
time: 2.23449969291687
[1, 15267] loss_train: 0.007429, loss_test: 0.005584
time: 0.2470557689666748
time: 2.243575096130371
[1, 15268] loss_train: 0.001629, loss_test: 0.005585
time: 0.24205470085144043
time: 2.2124948501586914
[1, 15269] loss_train: 0.004628, loss_test: 0.005585
time: 0.24306535720825195
time: 2.244504690170288
[1, 15270] loss_train: 0.012483, loss_test: 0.005583
time: 0.25705718994140625
time: 2.2545478343963623
[1, 15271] loss_train: 0.011981, loss_test: 0.005582
time: 0.2470543384552002
time: 2.295013666152954
[1, 15272] loss_train: 0.014458, loss_test: 0.005583
time: 0.24505400657653809
time: 2.2466304302215576
[1, 15273] loss_train: 0.014532, loss_test: 0.005587
time: 0.2450542449951172
time: 2.204493284225464
[1, 15274] loss_train: 0.006238, loss_test: 0.005594
time: 0.2470543384552002
time: 2.203495740890503
[1, 15275] loss_train: 0.007988, loss_test: 0.005604
time: 0.24405407905578613
time: 2.2114944458007812
[1, 15276] loss_train: 0.009251, loss_test: 0.005613
time: 0.2450547218322754
time: 2.1894900798797607
[1, 15277] loss_train: 0.019357, loss_test: 0.005629
time: 0.24305343627929688
time: 2.220496654510498
[1, 15278] loss_train: 0.008699, loss_test: 0.005645
time: 0.24605512619018555
time: 2.2135496139526367
[1, 15279] loss_train: 0.005533, loss_test: 0.005652
time: 0.24405312538146973
time: 2.2284982204437256
[1, 15280] loss_train: 0.009730, loss_test: 0.005642
time: 0.2560572624206543
time: 2.2495033740997314
[1, 15281] loss_train: 0.011541, loss_test: 0.005629
time: 0.24605441093444824
time: 2.250518321990967
[1, 15282] loss_train: 0.006421, loss_test: 0.005614
time: 0.24605536460876465
time: 2.2084929943084717
[1, 15283] loss_train: 0.005158, loss_test: 0.005596
time: 0.2450551986694336
time: 2.2195045948028564
[1, 15284] loss_train: 0.003307, loss_test: 0.005583
time: 0.2490551471710205
time: 2.2234973907470703
[1, 15285] loss_train: 0.007263, loss_test: 0.005571
time: 0.24405479431152344
time: 2.2165141105651855
[1, 15286] loss_train: 0.011450, loss_test: 0.005564
time: 0.24805450439453125
time: 2.240501642227173
[1, 15287] loss_train: 0.012280, loss_test: 0.005557
time: 0.2450547218322754
time: 2.2535037994384766
[1, 15288] loss_train: 0.003823, loss_test: 0.005554
time: 0.2510550022125244
time: 2.222550630569458
[1, 15289] loss_train: 0.003482, loss_test: 0.005555
time: 0.24509310722351074
time: 2.2209994792938232
[1, 15290] loss_train: 0.005168, loss_test: 0.005558
time: 0.25505614280700684
time: 2.2525038719177246
[1, 15291] loss_train: 0.004802, loss_test: 0.005562
time: 0.2450542449951172
time: 2.2415010929107666
[1, 15292] loss_train: 0.005853, loss_test: 0.005567
time: 0.24305462837219238
time: 2.236499547958374
[1, 15293] loss_train: 0.005318, loss_test: 0.005573
time: 0.2450542449951172
time: 2.2542965412139893
[1, 15294] loss_train: 0.006416, loss_test: 0.005579
time: 0.24405527114868164
time: 2.2895116806030273
[1, 15295] loss_train: 0.013502, loss_test: 0.005578
time: 0.24805593490600586
time: 2.2885117530822754
[1, 15296] loss_train: 0.001070, loss_test: 0.005580
time: 0.2540559768676758
time: 2.2735092639923096
[1, 15297] loss_train: 0.002983, loss_test: 0.005584
time: 0.2560570240020752
time: 2.257504463195801
[1, 15298] loss_train: 0.004012, loss_test: 0.005588
time: 0.2470548152923584
time: 2.217495918273926
[1, 15299] loss_train: 0.006497, loss_test: 0.005590
time: 0.24405407905578613
time: 2.2094945907592773
[1, 15300] loss_train: 0.004903, loss_test: 0.005592
time: 0.256056547164917
time: 2.2747268676757812
[1, 15301] loss_train: 0.009180, loss_test: 0.005586
time: 0.2470557689666748
time: 2.2154953479766846
[1, 15302] loss_train: 0.000733, loss_test: 0.005581
time: 0.24305415153503418
time: 2.219999313354492
[1, 15303] loss_train: 0.004822, loss_test: 0.005579
time: 0.2440659999847412
time: 2.220496892929077
[1, 15304] loss_train: 0.004011, loss_test: 0.005577
time: 0.24405360221862793
time: 2.230499267578125
[1, 15305] loss_train: 0.011153, loss_test: 0.005576
time: 0.24405598640441895
time: 2.2244975566864014
[1, 15306] loss_train: 0.002670, loss_test: 0.005575
time: 0.2450547218322754
time: 2.205493211746216
[1, 15307] loss_train: 0.005491, loss_test: 0.005575
time: 0.24405717849731445
time: 2.2184956073760986
[1, 15308] loss_train: 0.009500, loss_test: 0.005574
time: 0.24605488777160645
time: 2.214911460876465
[1, 15309] loss_train: 0.004302, loss_test: 0.005573
time: 0.2450549602508545
time: 2.208493709564209
[1, 15310] loss_train: 0.005174, loss_test: 0.005570
time: 0.2560563087463379
time: 2.221062421798706
[1, 15311] loss_train: 0.003366, loss_test: 0.005567
time: 0.24605441093444824
time: 2.1904921531677246
[1, 15312] loss_train: 0.002238, loss_test: 0.005565
time: 0.24405384063720703
time: 2.2114951610565186
[1, 15313] loss_train: 0.002089, loss_test: 0.005564
time: 0.24606657028198242
time: 2.2244977951049805
[1, 15314] loss_train: 0.004379, loss_test: 0.005564
time: 0.2470548152923584
time: 2.219496726989746
[1, 15315] loss_train: 0.010413, loss_test: 0.005564
time: 0.2470543384552002
time: 2.2254979610443115
[1, 15316] loss_train: 0.011472, loss_test: 0.005564
time: 0.2450542449951172
time: 2.242501974105835
[1, 15317] loss_train: 0.006095, loss_test: 0.005564
time: 0.24457454681396484
time: 2.2590112686157227
[1, 15318] loss_train: 0.015940, loss_test: 0.005560
time: 0.24805498123168945
time: 2.2134954929351807
[1, 15319] loss_train: 0.008436, loss_test: 0.005560
time: 0.24625325202941895
time: 2.242502212524414
[1, 15320] loss_train: 0.007238, loss_test: 0.005560
time: 0.25505661964416504
time: 2.256504774093628
[1, 15321] loss_train: 0.004144, loss_test: 0.005561
time: 0.24591469764709473
time: 2.2274985313415527
[1, 15322] loss_train: 0.003142, loss_test: 0.005561
time: 0.2450547218322754
time: 2.2385003566741943
[1, 15323] loss_train: 0.004578, loss_test: 0.005560
time: 0.24405407905578613
time: 2.215501070022583
[1, 15324] loss_train: 0.002084, loss_test: 0.005561
time: 0.2450542449951172
time: 2.245502233505249
[1, 15325] loss_train: 0.011719, loss_test: 0.005561
time: 0.2470548152923584
time: 2.2530298233032227
[1, 15326] loss_train: 0.006607, loss_test: 0.005564
time: 0.24306654930114746
time: 2.2105143070220947
[1, 15327] loss_train: 0.013606, loss_test: 0.005567
time: 0.24405407905578613
time: 2.204493284225464
[1, 15328] loss_train: 0.003691, loss_test: 0.005571
time: 0.24405407905578613
time: 2.221497058868408
[1, 15329] loss_train: 0.007796, loss_test: 0.005573
time: 0.24405479431152344
time: 2.233013153076172
[1, 15330] loss_train: 0.001575, loss_test: 0.005572
time: 0.2580578327178955
time: 2.276508092880249
[1, 15331] loss_train: 0.002472, loss_test: 0.005568
time: 0.2450547218322754
time: 2.236001968383789
[1, 15332] loss_train: 0.007985, loss_test: 0.005566
time: 0.24405384063720703
time: 2.218496561050415
[1, 15333] loss_train: 0.013921, loss_test: 0.005568
time: 0.24605488777160645
time: 2.209495782852173
[1, 15334] loss_train: 0.007724, loss_test: 0.005571
time: 0.2470545768737793
time: 2.214897394180298
[1, 15335] loss_train: 0.004996, loss_test: 0.005573
time: 0.2450547218322754
time: 2.204493284225464
[1, 15336] loss_train: 0.014646, loss_test: 0.005577
time: 0.2470545768737793
time: 2.21601939201355
[1, 15337] loss_train: 0.005136, loss_test: 0.005581
time: 0.2461535930633545
time: 2.230499505996704
[1, 15338] loss_train: 0.005665, loss_test: 0.005585
time: 0.24505400657653809
time: 2.205493927001953
[1, 15339] loss_train: 0.004046, loss_test: 0.005587
time: 0.2470545768737793
time: 2.2184970378875732
[1, 15340] loss_train: 0.001864, loss_test: 0.005579
time: 0.256056547164917
time: 2.2445144653320312
[1, 15341] loss_train: 0.005562, loss_test: 0.005568
time: 0.24305343627929688
time: 2.235502243041992
[1, 15342] loss_train: 0.008317, loss_test: 0.005564
time: 0.24505352973937988
time: 2.2865116596221924
[1, 15343] loss_train: 0.009281, loss_test: 0.005569
time: 0.24405217170715332
time: 2.235499858856201
[1, 15344] loss_train: 0.002378, loss_test: 0.005578
time: 0.24405407905578613
time: 2.233499765396118
[1, 15345] loss_train: 0.009850, loss_test: 0.005584
time: 0.24405384063720703
time: 2.260507822036743
[1, 15346] loss_train: 0.004650, loss_test: 0.005587
time: 0.2540562152862549
time: 2.257505416870117
[1, 15347] loss_train: 0.017687, loss_test: 0.005574
time: 0.24405479431152344
time: 2.2270143032073975
[1, 15348] loss_train: 0.004036, loss_test: 0.005567
time: 0.24405407905578613
time: 2.2014927864074707
[1, 15349] loss_train: 0.006622, loss_test: 0.005565
time: 0.2465658187866211
time: 2.2204971313476562
[1, 15350] loss_train: 0.002722, loss_test: 0.005566
time: 0.25705671310424805
time: 2.229499101638794
[1, 15351] loss_train: 0.007814, loss_test: 0.005571
time: 0.24406147003173828
time: 2.2014455795288086
[1, 15352] loss_train: 0.000639, loss_test: 0.005572
time: 0.24605464935302734
time: 2.209493398666382
[1, 15353] loss_train: 0.004223, loss_test: 0.005569
time: 0.2470560073852539
time: 2.2415037155151367
[1, 15354] loss_train: 0.010564, loss_test: 0.005569
time: 0.2450549602508545
time: 2.248504638671875
[1, 15355] loss_train: 0.013136, loss_test: 0.005570
time: 0.2490546703338623
time: 2.239501476287842
[1, 15356] loss_train: 0.004123, loss_test: 0.005569
time: 0.24405455589294434
time: 2.2154974937438965
[1, 15357] loss_train: 0.005772, loss_test: 0.005569
time: 0.2510552406311035
time: 2.252504587173462
[1, 15358] loss_train: 0.000913, loss_test: 0.005572
time: 0.24605488777160645
time: 2.2244973182678223
[1, 15359] loss_train: 0.006761, loss_test: 0.005576
time: 0.2510552406311035
time: 2.2475171089172363
[1, 15360] loss_train: 0.007894, loss_test: 0.005581
time: 0.25505590438842773
time: 2.2745087146759033
[1, 15361] loss_train: 0.004638, loss_test: 0.005588
time: 0.24876904487609863
time: 2.217495918273926
[1, 15362] loss_train: 0.006696, loss_test: 0.005589
time: 0.24505400657653809
time: 2.2365005016326904
[1, 15363] loss_train: 0.008282, loss_test: 0.005589
time: 0.2470548152923584
time: 2.2124950885772705
[1, 15364] loss_train: 0.003260, loss_test: 0.005590
time: 0.24405384063720703
time: 2.2495036125183105
[1, 15365] loss_train: 0.008241, loss_test: 0.005589
time: 0.24505376815795898
time: 2.2254984378814697
[1, 15366] loss_train: 0.006426, loss_test: 0.005587
time: 0.24505996704101562
time: 2.247502088546753
[1, 15367] loss_train: 0.007364, loss_test: 0.005584
time: 0.2450542449951172
time: 2.1934914588928223
[1, 15368] loss_train: 0.005795, loss_test: 0.005580
time: 0.24605441093444824
time: 2.1884891986846924
[1, 15369] loss_train: 0.012811, loss_test: 0.005577
time: 0.251056432723999
time: 2.2074577808380127
[1, 15370] loss_train: 0.007490, loss_test: 0.005580
time: 0.2560567855834961
time: 2.2054929733276367
[1, 15371] loss_train: 0.000538, loss_test: 0.005582
time: 0.24605488777160645
time: 2.2144951820373535
[1, 15372] loss_train: 0.007319, loss_test: 0.005583
time: 0.24405431747436523
time: 2.1794872283935547
[1, 15373] loss_train: 0.005321, loss_test: 0.005584
time: 0.24505376815795898
time: 2.213498115539551
[1, 15374] loss_train: 0.006704, loss_test: 0.005585
time: 0.2490544319152832
time: 2.224888563156128
[1, 15375] loss_train: 0.006322, loss_test: 0.005586
time: 0.243666410446167
time: 2.249502420425415
[1, 15376] loss_train: 0.010114, loss_test: 0.005582
time: 0.2510557174682617
time: 2.2680442333221436
[1, 15377] loss_train: 0.004846, loss_test: 0.005579
time: 0.24405384063720703
time: 2.2495028972625732
[1, 15378] loss_train: 0.004395, loss_test: 0.005576
time: 0.24805498123168945
time: 2.2515039443969727
[1, 15379] loss_train: 0.004759, loss_test: 0.005574
time: 0.24805569648742676
time: 2.233499050140381
[1, 15380] loss_train: 0.005091, loss_test: 0.005573
time: 0.26105833053588867
time: 2.2731125354766846
[1, 15381] loss_train: 0.005231, loss_test: 0.005571
time: 0.24605488777160645
time: 2.221496343612671
[1, 15382] loss_train: 0.003646, loss_test: 0.005570
time: 0.25005483627319336
time: 2.2221860885620117
[1, 15383] loss_train: 0.000630, loss_test: 0.005570
time: 0.2450547218322754
time: 2.2385001182556152
[1, 15384] loss_train: 0.004620, loss_test: 0.005570
time: 0.24605560302734375
time: 2.239499807357788
[1, 15385] loss_train: 0.001613, loss_test: 0.005571
time: 0.24305367469787598
time: 2.186488151550293
[1, 15386] loss_train: 0.009122, loss_test: 0.005572
time: 0.2450544834136963
time: 2.2044928073883057
[1, 15387] loss_train: 0.007484, loss_test: 0.005574
time: 0.24205327033996582
time: 2.2034943103790283
[1, 15388] loss_train: 0.002690, loss_test: 0.005579
time: 0.2450549602508545
time: 2.2375009059906006
[1, 15389] loss_train: 0.006048, loss_test: 0.005583
time: 0.25005435943603516
time: 2.2365005016326904
[1, 15390] loss_train: 0.007371, loss_test: 0.005585
time: 0.256056547164917
time: 2.2738418579101562
[1, 15391] loss_train: 0.006888, loss_test: 0.005585
time: 0.24407005310058594
time: 2.255504608154297
[1, 15392] loss_train: 0.004334, loss_test: 0.005584
time: 0.24605512619018555
time: 2.2204954624176025
[1, 15393] loss_train: 0.006758, loss_test: 0.005580
time: 0.24405527114868164
time: 2.24650239944458
[1, 15394] loss_train: 0.011966, loss_test: 0.005575
time: 0.2430589199066162
time: 2.2635085582733154
[1, 15395] loss_train: 0.003948, loss_test: 0.005571
time: 0.24405431747436523
time: 2.2144973278045654
[1, 15396] loss_train: 0.003774, loss_test: 0.005569
time: 0.2450547218322754
time: 2.202491521835327
[1, 15397] loss_train: 0.001396, loss_test: 0.005568
time: 0.2440659999847412
time: 2.2365031242370605
[1, 15398] loss_train: 0.007156, loss_test: 0.005565
time: 0.24605393409729004
time: 2.2219042778015137
[1, 15399] loss_train: 0.001626, loss_test: 0.005566
time: 0.2470545768737793
time: 2.216496229171753
[1, 15400] loss_train: 0.017643, loss_test: 0.005563
time: 0.25705647468566895
time: 2.2665205001831055
[1, 15401] loss_train: 0.005443, loss_test: 0.005562
time: 0.24805521965026855
time: 2.2104947566986084
[1, 15402] loss_train: 0.000947, loss_test: 0.005562
time: 0.2470545768737793
time: 2.2485029697418213
[1, 15403] loss_train: 0.001753, loss_test: 0.005565
time: 0.2470545768737793
time: 2.221496343612671
[1, 15404] loss_train: 0.005993, loss_test: 0.005569
time: 0.2450547218322754
time: 2.2385005950927734
[1, 15405] loss_train: 0.003268, loss_test: 0.005575
time: 0.24605488777160645
time: 2.2475149631500244
[1, 15406] loss_train: 0.003543, loss_test: 0.005580
time: 0.24405431747436523
time: 2.229498863220215
[1, 15407] loss_train: 0.008617, loss_test: 0.005585
time: 0.24605894088745117
time: 2.2214980125427246
[1, 15408] loss_train: 0.004446, loss_test: 0.005591
time: 0.24305367469787598
time: 2.2100086212158203
[1, 15409] loss_train: 0.003889, loss_test: 0.005596
time: 0.24605417251586914
time: 2.2175159454345703
[1, 15410] loss_train: 0.003945, loss_test: 0.005604
time: 0.2570805549621582
time: 2.230498790740967
[1, 15411] loss_train: 0.002430, loss_test: 0.005614
time: 0.25305652618408203
time: 2.241501569747925
[1, 15412] loss_train: 0.005767, loss_test: 0.005623
time: 0.2450547218322754
time: 2.249006509780884
[1, 15413] loss_train: 0.004746, loss_test: 0.005631
time: 0.24405407905578613
time: 2.2485032081604004
[1, 15414] loss_train: 0.003704, loss_test: 0.005640
time: 0.24305367469787598
time: 2.2325022220611572
[1, 15415] loss_train: 0.005234, loss_test: 0.005646
time: 0.24405407905578613
time: 2.2375028133392334
[1, 15416] loss_train: 0.009372, loss_test: 0.005650
time: 0.24405336380004883
time: 2.251504421234131
[1, 15417] loss_train: 0.001822, loss_test: 0.005652
time: 0.2450544834136963
time: 2.2274985313415527
[1, 15418] loss_train: 0.000783, loss_test: 0.005657
time: 0.24506688117980957
time: 2.2254981994628906
[1, 15419] loss_train: 0.002553, loss_test: 0.005656
time: 0.24303460121154785
time: 2.242501735687256
[1, 15420] loss_train: 0.003075, loss_test: 0.005651
time: 0.25705671310424805
time: 2.243504285812378
[1, 15421] loss_train: 0.003147, loss_test: 0.005646
time: 0.24405431747436523
time: 2.239250898361206
[1, 15422] loss_train: 0.010739, loss_test: 0.005620
time: 0.2470543384552002
time: 2.2104945182800293
[1, 15423] loss_train: 0.003517, loss_test: 0.005602
time: 0.24605512619018555
time: 2.248502731323242
[1, 15424] loss_train: 0.007125, loss_test: 0.005590
time: 0.24506616592407227
time: 2.2585055828094482
[1, 15425] loss_train: 0.001112, loss_test: 0.005583
time: 0.24606609344482422
time: 2.2405011653900146
[1, 15426] loss_train: 0.002849, loss_test: 0.005578
time: 0.24606776237487793
time: 2.2345170974731445
[1, 15427] loss_train: 0.005949, loss_test: 0.005573
time: 0.24605417251586914
time: 2.2244999408721924
[1, 15428] loss_train: 0.001520, loss_test: 0.005572
time: 0.24805521965026855
time: 2.2555043697357178
[1, 15429] loss_train: 0.003575, loss_test: 0.005571
time: 0.24605441093444824
time: 2.203511953353882
[1, 15430] loss_train: 0.002243, loss_test: 0.005572
time: 0.26405906677246094
time: 2.2575039863586426
[1, 15431] loss_train: 0.009408, loss_test: 0.005572
time: 0.24605488777160645
time: 2.214498519897461
[1, 15432] loss_train: 0.003489, loss_test: 0.005572
time: 0.2510561943054199
time: 2.218496322631836
[1, 15433] loss_train: 0.007425, loss_test: 0.005571
time: 0.24505352973937988
time: 2.236501693725586
[1, 15434] loss_train: 0.006579, loss_test: 0.005570
time: 0.24805498123168945
time: 2.2415006160736084
[1, 15435] loss_train: 0.014038, loss_test: 0.005565
time: 0.2450542449951172
time: 2.1915271282196045
[1, 15436] loss_train: 0.006048, loss_test: 0.005564
time: 0.24305367469787598
time: 2.2515220642089844
[1, 15437] loss_train: 0.001736, loss_test: 0.005566
time: 0.24306583404541016
time: 2.2535042762756348
[1, 15438] loss_train: 0.009778, loss_test: 0.005570
time: 0.24405455589294434
time: 2.2335007190704346
[1, 15439] loss_train: 0.006677, loss_test: 0.005571
time: 0.24405312538146973
time: 2.222496747970581
[1, 15440] loss_train: 0.006787, loss_test: 0.005570
time: 0.25505685806274414
time: 2.269026041030884
[1, 15441] loss_train: 0.010518, loss_test: 0.005567
time: 0.25905752182006836
time: 2.245501756668091
[1, 15442] loss_train: 0.006017, loss_test: 0.005565
time: 0.24605393409729004
time: 2.242502212524414
[1, 15443] loss_train: 0.006819, loss_test: 0.005561
time: 0.2490544319152832
time: 2.217496395111084
[1, 15444] loss_train: 0.002852, loss_test: 0.005556
time: 0.24305438995361328
time: 2.246502161026001
[1, 15445] loss_train: 0.008513, loss_test: 0.005554
time: 0.2440483570098877
time: 2.2243404388427734
[1, 15446] loss_train: 0.006404, loss_test: 0.005552
time: 0.24305367469787598
time: 2.2625064849853516
[1, 15447] loss_train: 0.007200, loss_test: 0.005550
time: 0.24394440650939941
time: 2.2134957313537598
[1, 15448] loss_train: 0.003242, loss_test: 0.005549
time: 0.24405884742736816
time: 2.20849609375
[1, 15449] loss_train: 0.008113, loss_test: 0.005549
time: 0.24305438995361328
time: 2.236499547958374
[1, 15450] loss_train: 0.015052, loss_test: 0.005548
time: 0.256056547164917
time: 2.228498697280884
[1, 15451] loss_train: 0.008064, loss_test: 0.005548
time: 0.24805617332458496
time: 2.2695066928863525
[1, 15452] loss_train: 0.004224, loss_test: 0.005548
time: 0.25005578994750977
time: 2.213496208190918
[1, 15453] loss_train: 0.009068, loss_test: 0.005549
time: 0.24405336380004883
time: 2.2154953479766846
[1, 15454] loss_train: 0.010627, loss_test: 0.005549
time: 0.24506640434265137
time: 2.2305006980895996
[1, 15455] loss_train: 0.004135, loss_test: 0.005551
time: 0.2490558624267578
time: 2.1934897899627686
[1, 15456] loss_train: 0.004885, loss_test: 0.005553
time: 0.24405360221862793
time: 2.198139190673828
[1, 15457] loss_train: 0.006628, loss_test: 0.005554
time: 0.24805474281311035
time: 2.216499090194702
[1, 15458] loss_train: 0.001251, loss_test: 0.005556
time: 0.2430589199066162
time: 2.2034926414489746
[1, 15459] loss_train: 0.003566, loss_test: 0.005561
time: 0.2450542449951172
time: 2.2104945182800293
[1, 15460] loss_train: 0.010686, loss_test: 0.005567
time: 0.25705671310424805
time: 2.266507387161255
[1, 15461] loss_train: 0.004117, loss_test: 0.005573
time: 0.2450547218322754
time: 2.2355031967163086
[1, 15462] loss_train: 0.010422, loss_test: 0.005575
time: 0.24305462837219238
time: 2.2585043907165527
[1, 15463] loss_train: 0.004639, loss_test: 0.005577
time: 0.24405407905578613
time: 2.2635092735290527
[1, 15464] loss_train: 0.007517, loss_test: 0.005576
time: 0.2490553855895996
time: 2.2367186546325684
[1, 15465] loss_train: 0.006993, loss_test: 0.005575
time: 0.2450542449951172
time: 2.2665069103240967
[1, 15466] loss_train: 0.006977, loss_test: 0.005574
time: 0.24405479431152344
time: 2.2415008544921875
[1, 15467] loss_train: 0.007608, loss_test: 0.005576
time: 0.24605393409729004
time: 2.243502616882324
[1, 15468] loss_train: 0.010190, loss_test: 0.005578
time: 0.24205303192138672
time: 2.2104949951171875
[1, 15469] loss_train: 0.000982, loss_test: 0.005578
time: 0.24509286880493164
time: 2.190490245819092
[1, 15470] loss_train: 0.006027, loss_test: 0.005578
time: 0.2580568790435791
time: 2.2585058212280273
[1, 15471] loss_train: 0.003602, loss_test: 0.005579
time: 0.24405360221862793
time: 2.2280051708221436
[1, 15472] loss_train: 0.003022, loss_test: 0.005581
time: 0.24405360221862793
time: 2.226506233215332
[1, 15473] loss_train: 0.016529, loss_test: 0.005580
time: 0.2450547218322754
time: 2.2069995403289795
[1, 15474] loss_train: 0.005830, loss_test: 0.005579
time: 0.24405384063720703
time: 2.2265005111694336
[1, 15475] loss_train: 0.002115, loss_test: 0.005580
time: 0.24505400657653809
time: 2.2445027828216553
[1, 15476] loss_train: 0.005135, loss_test: 0.005580
time: 0.2510557174682617
time: 2.263509511947632
[1, 15477] loss_train: 0.002173, loss_test: 0.005581
time: 0.24505400657653809
time: 2.2615251541137695
[1, 15478] loss_train: 0.001671, loss_test: 0.005583
time: 0.24506735801696777
time: 2.2495031356811523
[1, 15479] loss_train: 0.003731, loss_test: 0.005585
time: 0.24805521965026855
time: 2.230498790740967
[1, 15480] loss_train: 0.012226, loss_test: 0.005579
time: 0.25905728340148926
time: 2.2488088607788086
[1, 15481] loss_train: 0.010495, loss_test: 0.005570
time: 0.24805498123168945
time: 2.2094943523406982
[1, 15482] loss_train: 0.010039, loss_test: 0.005564
time: 0.2499074935913086
time: 2.209604024887085
[1, 15483] loss_train: 0.009609, loss_test: 0.005561
time: 0.24605441093444824
time: 2.2485032081604004
[1, 15484] loss_train: 0.012663, loss_test: 0.005564
time: 0.2490551471710205
time: 2.2495059967041016
[1, 15485] loss_train: 0.011779, loss_test: 0.005579
time: 0.24405384063720703
time: 2.226501941680908
[1, 15486] loss_train: 0.001671, loss_test: 0.005605
time: 0.24805331230163574
time: 2.2345023155212402
[1, 15487] loss_train: 0.003894, loss_test: 0.005625
time: 0.24305367469787598
time: 2.243501901626587
[1, 15488] loss_train: 0.006561, loss_test: 0.005637
time: 0.24505376815795898
time: 2.2415013313293457
[1, 15489] loss_train: 0.008365, loss_test: 0.005632
time: 0.24606728553771973
time: 2.223012685775757
[1, 15490] loss_train: 0.003677, loss_test: 0.005613
time: 0.25705695152282715
time: 2.264507532119751
[1, 15491] loss_train: 0.009850, loss_test: 0.005593
time: 0.2450542449951172
time: 2.2555038928985596
[1, 15492] loss_train: 0.003003, loss_test: 0.005578
time: 0.24605393409729004
time: 2.2345001697540283
[1, 15493] loss_train: 0.001791, loss_test: 0.005567
time: 0.24605441093444824
time: 2.2355003356933594
[1, 15494] loss_train: 0.005019, loss_test: 0.005563
time: 0.2450544834136963
time: 2.2024946212768555
[1, 15495] loss_train: 0.007618, loss_test: 0.005568
time: 0.24405384063720703
time: 2.229498863220215
[1, 15496] loss_train: 0.007452, loss_test: 0.005578
time: 0.24405336380004883
time: 2.216495990753174
[1, 15497] loss_train: 0.001370, loss_test: 0.005594
time: 0.24405527114868164
time: 2.2380027770996094
[1, 15498] loss_train: 0.004226, loss_test: 0.005611
time: 0.24605441093444824
time: 2.2335000038146973
[1, 15499] loss_train: 0.004787, loss_test: 0.005626
time: 0.25005507469177246
time: 2.2455027103424072
[1, 15500] loss_train: 0.009664, loss_test: 0.005628
time: 0.25505685806274414
time: 2.2555065155029297
[1, 15501] loss_train: 0.003428, loss_test: 0.005629
time: 0.24305343627929688
time: 2.2134149074554443
[1, 15502] loss_train: 0.007797, loss_test: 0.005623
time: 0.24605584144592285
time: 2.229498863220215
[1, 15503] loss_train: 0.003428, loss_test: 0.005618
time: 0.24406743049621582
time: 2.2114946842193604
[1, 15504] loss_train: 0.004475, loss_test: 0.005614
time: 0.24505376815795898
time: 2.228498935699463
[1, 15505] loss_train: 0.003074, loss_test: 0.005611
time: 0.24605441093444824
time: 2.2154958248138428
[1, 15506] loss_train: 0.004798, loss_test: 0.005607
time: 0.24605417251586914
time: 2.2425284385681152
[1, 15507] loss_train: 0.011188, loss_test: 0.005599
time: 0.24805521965026855
time: 2.2365002632141113
[1, 15508] loss_train: 0.007371, loss_test: 0.005592
time: 0.24505376815795898
time: 2.199495553970337
[1, 15509] loss_train: 0.008261, loss_test: 0.005587
time: 0.2510554790496826
time: 2.2250044345855713
[1, 15510] loss_train: 0.003749, loss_test: 0.005587
time: 0.25705718994140625
time: 2.2425150871276855
[1, 15511] loss_train: 0.003176, loss_test: 0.005590
time: 0.24605488777160645
time: 2.2064931392669678
[1, 15512] loss_train: 0.004965, loss_test: 0.005591
time: 0.2430558204650879
time: 2.252502202987671
[1, 15513] loss_train: 0.007997, loss_test: 0.005591
time: 0.24305391311645508
time: 2.2499449253082275
[1, 15514] loss_train: 0.003681, loss_test: 0.005590
time: 0.24405431747436523
time: 2.2485029697418213
[1, 15515] loss_train: 0.005714, loss_test: 0.005588
time: 0.24405431747436523
time: 2.2405011653900146
[1, 15516] loss_train: 0.003218, loss_test: 0.005586
time: 0.247053861618042
time: 2.233055353164673
[1, 15517] loss_train: 0.006748, loss_test: 0.005586
time: 0.2450542449951172
time: 2.2655069828033447
[1, 15518] loss_train: 0.006277, loss_test: 0.005588
time: 0.24608087539672852
time: 2.2465178966522217
[1, 15519] loss_train: 0.009136, loss_test: 0.005587
time: 0.24506807327270508
time: 2.2385003566741943
[1, 15520] loss_train: 0.007392, loss_test: 0.005585
time: 0.25707077980041504
time: 2.2555043697357178
[1, 15521] loss_train: 0.002698, loss_test: 0.005585
time: 0.2450542449951172
time: 2.2255001068115234
[1, 15522] loss_train: 0.002659, loss_test: 0.005587
time: 0.24405384063720703
time: 2.240501642227173
[1, 15523] loss_train: 0.007895, loss_test: 0.005583
time: 0.24406695365905762
time: 2.21549654006958
[1, 15524] loss_train: 0.011388, loss_test: 0.005577
time: 0.244065523147583
time: 2.2455027103424072
[1, 15525] loss_train: 0.009124, loss_test: 0.005571
time: 0.24305415153503418
time: 2.2365305423736572
[1, 15526] loss_train: 0.007077, loss_test: 0.005567
time: 0.24305391311645508
time: 2.214449405670166
[1, 15527] loss_train: 0.007374, loss_test: 0.005564
time: 0.24405384063720703
time: 2.2144951820373535
[1, 15528] loss_train: 0.008175, loss_test: 0.005563
time: 0.24305367469787598
time: 2.1855063438415527
[1, 15529] loss_train: 0.004001, loss_test: 0.005562
time: 0.2470543384552002
time: 2.248542308807373
[1, 15530] loss_train: 0.001522, loss_test: 0.005560
time: 0.25705647468566895
time: 2.242502450942993
[1, 15531] loss_train: 0.006127, loss_test: 0.005558
time: 0.2470557689666748
time: 2.21049427986145
[1, 15532] loss_train: 0.002941, loss_test: 0.005558
time: 0.2510678768157959
time: 2.2421743869781494
[1, 15533] loss_train: 0.003397, loss_test: 0.005560
time: 0.24506664276123047
time: 2.245502233505249
[1, 15534] loss_train: 0.010192, loss_test: 0.005562
time: 0.2490546703338623
time: 2.2375006675720215
[1, 15535] loss_train: 0.013788, loss_test: 0.005564
time: 0.24605512619018555
time: 2.2244973182678223
[1, 15536] loss_train: 0.002919, loss_test: 0.005565
time: 0.2510559558868408
time: 2.246863842010498
[1, 15537] loss_train: 0.001377, loss_test: 0.005566
time: 0.2450547218322754
time: 2.250502824783325
[1, 15538] loss_train: 0.006785, loss_test: 0.005567
time: 0.24805545806884766
time: 2.2210190296173096
[1, 15539] loss_train: 0.004932, loss_test: 0.005567
time: 0.2450547218322754
time: 2.221999168395996
[1, 15540] loss_train: 0.008986, loss_test: 0.005569
time: 0.25707006454467773
time: 2.2345001697540283
[1, 15541] loss_train: 0.003147, loss_test: 0.005572
time: 0.24407052993774414
time: 2.2054953575134277
[1, 15542] loss_train: 0.011291, loss_test: 0.005572
time: 0.24405360221862793
time: 2.2185113430023193
[1, 15543] loss_train: 0.012000, loss_test: 0.005574
time: 0.2450549602508545
time: 2.208494186401367
[1, 15544] loss_train: 0.008775, loss_test: 0.005579
time: 0.24405384063720703
time: 2.2124974727630615
[1, 15545] loss_train: 0.005047, loss_test: 0.005584
time: 0.24405407905578613
time: 2.2024946212768555
[1, 15546] loss_train: 0.001877, loss_test: 0.005584
time: 0.24605441093444824
time: 2.217499017715454
[1, 15547] loss_train: 0.008625, loss_test: 0.005588
time: 0.2430562973022461
time: 2.2395012378692627
[1, 15548] loss_train: 0.007399, loss_test: 0.005593
time: 0.24605417251586914
time: 2.2505040168762207
[1, 15549] loss_train: 0.005727, loss_test: 0.005596
time: 0.24405932426452637
time: 2.2144949436187744
[1, 15550] loss_train: 0.006795, loss_test: 0.005596
time: 0.2580571174621582
time: 2.2790560722351074
[1, 15551] loss_train: 0.002592, loss_test: 0.005596
time: 0.24606704711914062
time: 2.2054929733276367
[1, 15552] loss_train: 0.008113, loss_test: 0.005600
time: 0.2450551986694336
time: 2.220496416091919
[1, 15553] loss_train: 0.005945, loss_test: 0.005603
time: 0.25205516815185547
time: 2.2144956588745117
[1, 15554] loss_train: 0.007621, loss_test: 0.005602
time: 0.24505400657653809
time: 2.2114951610565186
[1, 15555] loss_train: 0.007558, loss_test: 0.005599
time: 0.24805545806884766
time: 2.200995683670044
[1, 15556] loss_train: 0.006922, loss_test: 0.005598
time: 0.24405598640441895
time: 2.1874890327453613
[1, 15557] loss_train: 0.002195, loss_test: 0.005602
time: 0.24605441093444824
time: 2.234499931335449
[1, 15558] loss_train: 0.004246, loss_test: 0.005606
time: 0.24405407905578613
time: 2.241501569747925
[1, 15559] loss_train: 0.001399, loss_test: 0.005605
time: 0.24444794654846191
time: 2.216496229171753
[1, 15560] loss_train: 0.002685, loss_test: 0.005603
time: 0.2600572109222412
time: 2.267510175704956
[1, 15561] loss_train: 0.006424, loss_test: 0.005594
time: 0.2470543384552002
time: 2.2355003356933594
[1, 15562] loss_train: 0.005065, loss_test: 0.005587
time: 0.24405455589294434
time: 2.2365000247955322
[1, 15563] loss_train: 0.002509, loss_test: 0.005582
time: 0.2450556755065918
time: 2.246501922607422
[1, 15564] loss_train: 0.008788, loss_test: 0.005575
time: 0.25505757331848145
time: 2.197491407394409
[1, 15565] loss_train: 0.006138, loss_test: 0.005571
time: 0.24306225776672363
time: 2.2244982719421387
[1, 15566] loss_train: 0.008494, loss_test: 0.005567
time: 0.24405455589294434
time: 2.244011402130127
[1, 15567] loss_train: 0.003760, loss_test: 0.005567
time: 0.2450547218322754
time: 2.229499340057373
[1, 15568] loss_train: 0.007562, loss_test: 0.005568
time: 0.24505400657653809
time: 2.232499361038208
[1, 15569] loss_train: 0.002611, loss_test: 0.005570
time: 0.24606847763061523
time: 2.2244980335235596
[1, 15570] loss_train: 0.007672, loss_test: 0.005575
time: 0.25705742835998535
time: 2.2445144653320312
[1, 15571] loss_train: 0.009265, loss_test: 0.005580
time: 0.24506783485412598
time: 2.2224974632263184
[1, 15572] loss_train: 0.003717, loss_test: 0.005580
time: 0.24608397483825684
time: 2.213505983352661
[1, 15573] loss_train: 0.003344, loss_test: 0.005580
time: 0.24305391311645508
time: 2.2184958457946777
[1, 15574] loss_train: 0.008164, loss_test: 0.005577
time: 0.25006699562072754
time: 2.2224977016448975
[1, 15575] loss_train: 0.009354, loss_test: 0.005575
time: 0.24605512619018555
time: 2.2280187606811523
[1, 15576] loss_train: 0.003529, loss_test: 0.005574
time: 0.24405431747436523
time: 2.2144951820373535
[1, 15577] loss_train: 0.006751, loss_test: 0.005575
time: 0.24205374717712402
time: 2.1852917671203613
[1, 15578] loss_train: 0.009875, loss_test: 0.005571
time: 0.24405503273010254
time: 2.209493398666382
[1, 15579] loss_train: 0.003327, loss_test: 0.005570
time: 0.24305415153503418
time: 2.2405200004577637
[1, 15580] loss_train: 0.007613, loss_test: 0.005570
time: 0.2560572624206543
time: 2.2395007610321045
[1, 15581] loss_train: 0.004025, loss_test: 0.005571
time: 0.2510561943054199
time: 2.235499382019043
[1, 15582] loss_train: 0.009342, loss_test: 0.005570
time: 0.24305438995361328
time: 2.2395145893096924
[1, 15583] loss_train: 0.004112, loss_test: 0.005570
time: 0.24605417251586914
time: 2.2084944248199463
[1, 15584] loss_train: 0.006286, loss_test: 0.005572
time: 0.24505352973937988
time: 2.2345004081726074
[1, 15585] loss_train: 0.013727, loss_test: 0.005573
time: 0.24305415153503418
time: 2.217510223388672
[1, 15586] loss_train: 0.007935, loss_test: 0.005574
time: 0.24506640434265137
time: 2.214000701904297
[1, 15587] loss_train: 0.006435, loss_test: 0.005575
time: 0.24805521965026855
time: 2.2455029487609863
[1, 15588] loss_train: 0.006334, loss_test: 0.005576
time: 0.24605393409729004
time: 2.2275004386901855
[1, 15589] loss_train: 0.006191, loss_test: 0.005576
time: 0.2490546703338623
time: 2.219519853591919
[1, 15590] loss_train: 0.008412, loss_test: 0.005577
time: 0.2560570240020752
time: 2.2375004291534424
[1, 15591] loss_train: 0.005007, loss_test: 0.005578
time: 0.25006937980651855
time: 2.2274980545043945
[1, 15592] loss_train: 0.004133, loss_test: 0.005580
time: 0.24505400657653809
time: 2.2445056438446045
[1, 15593] loss_train: 0.003577, loss_test: 0.005581
time: 0.24805378913879395
time: 2.2255613803863525
[1, 15594] loss_train: 0.008135, loss_test: 0.005584
time: 0.24205422401428223
time: 2.217498540878296
[1, 15595] loss_train: 0.005955, loss_test: 0.005586
time: 0.2430570125579834
time: 2.224498987197876
[1, 15596] loss_train: 0.006294, loss_test: 0.005588
time: 0.24405479431152344
time: 2.2565040588378906
[1, 15597] loss_train: 0.005354, loss_test: 0.005590
time: 0.24405479431152344
time: 2.2144997119903564
[1, 15598] loss_train: 0.004048, loss_test: 0.005592
time: 0.2470543384552002
time: 2.2365005016326904
[1, 15599] loss_train: 0.013813, loss_test: 0.005588
time: 0.24605488777160645
time: 2.2295007705688477
[1, 15600] loss_train: 0.001992, loss_test: 0.005592
time: 0.2580571174621582
time: 2.2495028972625732
[1, 15601] loss_train: 0.004426, loss_test: 0.005605
time: 0.2450544834136963
time: 2.2114946842193604
[1, 15602] loss_train: 0.008957, loss_test: 0.005623
time: 0.24605488777160645
time: 2.217496156692505
[1, 15603] loss_train: 0.006936, loss_test: 0.005646
time: 0.24405384063720703
time: 2.2082972526550293
[1, 15604] loss_train: 0.003154, loss_test: 0.005666
time: 0.24505376815795898
time: 2.241502046585083
[1, 15605] loss_train: 0.009711, loss_test: 0.005663
time: 0.24505400657653809
time: 2.2040133476257324
[1, 15606] loss_train: 0.002588, loss_test: 0.005661
time: 0.2450542449951172
time: 2.2244975566864014
[1, 15607] loss_train: 0.004378, loss_test: 0.005646
time: 0.24405479431152344
time: 2.22351336479187
[1, 15608] loss_train: 0.005986, loss_test: 0.005634
time: 0.2510559558868408
time: 2.205493211746216
[1, 15609] loss_train: 0.005971, loss_test: 0.005625
time: 0.24405455589294434
time: 2.2385098934173584
[1, 15610] loss_train: 0.004668, loss_test: 0.005616
time: 0.25905847549438477
time: 2.249502658843994
[1, 15611] loss_train: 0.008642, loss_test: 0.005607
time: 0.24605488777160645
time: 2.2535040378570557
[1, 15612] loss_train: 0.012449, loss_test: 0.005595
time: 0.24605417251586914
time: 2.2204971313476562
[1, 15613] loss_train: 0.007800, loss_test: 0.005589
time: 0.24305319786071777
time: 2.2495038509368896
[1, 15614] loss_train: 0.009988, loss_test: 0.005590
time: 0.24605441093444824
time: 2.244502544403076
[1, 15615] loss_train: 0.006588, loss_test: 0.005601
time: 0.24405384063720703
time: 2.2144947052001953
[1, 15616] loss_train: 0.006809, loss_test: 0.005618
time: 0.24305367469787598
time: 2.235004425048828
[1, 15617] loss_train: 0.008979, loss_test: 0.005636
time: 0.2450542449951172
time: 2.253504753112793
[1, 15618] loss_train: 0.011473, loss_test: 0.005654
time: 0.24605393409729004
time: 2.2345001697540283
[1, 15619] loss_train: 0.003163, loss_test: 0.005665
time: 0.24305438995361328
time: 2.22900128364563
[1, 15620] loss_train: 0.009948, loss_test: 0.005669
time: 0.2560563087463379
time: 2.253504514694214
[1, 15621] loss_train: 0.009813, loss_test: 0.005654
time: 0.2450544834136963
time: 2.2405009269714355
[1, 15622] loss_train: 0.016847, loss_test: 0.005640
time: 0.24506807327270508
time: 2.2415006160736084
[1, 15623] loss_train: 0.003545, loss_test: 0.005613
time: 0.2450542449951172
time: 2.2515039443969727
[1, 15624] loss_train: 0.004695, loss_test: 0.005589
time: 0.24405360221862793
time: 2.231499433517456
[1, 15625] loss_train: 0.002254, loss_test: 0.005574
time: 0.24305415153503418
time: 2.245502471923828
[1, 15626] loss_train: 0.002179, loss_test: 0.005571
time: 0.2440662384033203
time: 2.2395007610321045
[1, 15627] loss_train: 0.009160, loss_test: 0.005576
time: 0.24505376815795898
time: 2.1885032653808594
[1, 15628] loss_train: 0.005743, loss_test: 0.005585
time: 0.24605417251586914
time: 2.2345004081726074
[1, 15629] loss_train: 0.009839, loss_test: 0.005586
time: 0.24405646324157715
time: 2.2108821868896484
[1, 15630] loss_train: 0.004673, loss_test: 0.005587
time: 0.2580575942993164
time: 2.262507677078247
[1, 15631] loss_train: 0.004302, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2205007076263428
[1, 15632] loss_train: 0.003712, loss_test: 0.005587
time: 0.2450549602508545
time: 2.233499526977539
[1, 15633] loss_train: 0.004076, loss_test: 0.005588
time: 0.2450547218322754
time: 2.22149658203125
[1, 15634] loss_train: 0.007523, loss_test: 0.005587
time: 0.24307656288146973
time: 2.2395031452178955
[1, 15635] loss_train: 0.020420, loss_test: 0.005579
time: 0.2470550537109375
time: 2.2365000247955322
[1, 15636] loss_train: 0.001810, loss_test: 0.005575
time: 0.24605512619018555
time: 2.20949387550354
[1, 15637] loss_train: 0.018778, loss_test: 0.005570
time: 0.24605488777160645
time: 2.1972410678863525
[1, 15638] loss_train: 0.006617, loss_test: 0.005570
time: 0.2450542449951172
time: 2.2264983654022217
[1, 15639] loss_train: 0.005147, loss_test: 0.005569
time: 0.24605417251586914
time: 2.2455027103424072
[1, 15640] loss_train: 0.004682, loss_test: 0.005569
time: 0.2540559768676758
time: 2.2385332584381104
[1, 15641] loss_train: 0.003259, loss_test: 0.005571
time: 0.24405384063720703
time: 2.2146718502044678
[1, 15642] loss_train: 0.002235, loss_test: 0.005572
time: 0.24605441093444824
time: 2.2295188903808594
[1, 15643] loss_train: 0.011866, loss_test: 0.005572
time: 0.24306797981262207
time: 2.256504535675049
[1, 15644] loss_train: 0.002746, loss_test: 0.005574
time: 0.2450544834136963
time: 2.24650239944458
[1, 15645] loss_train: 0.005364, loss_test: 0.005575
time: 0.24805426597595215
time: 2.2455027103424072
[1, 15646] loss_train: 0.011383, loss_test: 0.005565
time: 0.2440652847290039
time: 2.2314987182617188
[1, 15647] loss_train: 0.002369, loss_test: 0.005562
time: 0.24405360221862793
time: 2.230499744415283
[1, 15648] loss_train: 0.005702, loss_test: 0.005560
time: 0.2470545768737793
time: 2.2355170249938965
[1, 15649] loss_train: 0.007855, loss_test: 0.005558
time: 0.2470686435699463
time: 2.1843185424804688
[1, 15650] loss_train: 0.008730, loss_test: 0.005558
time: 0.2560575008392334
time: 2.2034924030303955
[1, 15651] loss_train: 0.011054, loss_test: 0.005557
time: 0.2470545768737793
time: 2.224884033203125
[1, 15652] loss_train: 0.008782, loss_test: 0.005555
time: 0.2470548152923584
time: 2.2274889945983887
[1, 15653] loss_train: 0.003194, loss_test: 0.005552
time: 0.2450544834136963
time: 2.2545039653778076
[1, 15654] loss_train: 0.007596, loss_test: 0.005551
time: 0.24805450439453125
time: 2.19049072265625
[1, 15655] loss_train: 0.004222, loss_test: 0.005551
time: 0.24605464935302734
time: 2.254512310028076
[1, 15656] loss_train: 0.003002, loss_test: 0.005553
time: 0.2490553855895996
time: 2.2405011653900146
[1, 15657] loss_train: 0.000545, loss_test: 0.005554
time: 0.24505400657653809
time: 2.225501775741577
[1, 15658] loss_train: 0.005811, loss_test: 0.005557
time: 0.24805426597595215
time: 2.2265002727508545
[1, 15659] loss_train: 0.005016, loss_test: 0.005561
time: 0.24305415153503418
time: 2.257504463195801
[1, 15660] loss_train: 0.006961, loss_test: 0.005564
time: 0.25905776023864746
time: 2.2540171146392822
[1, 15661] loss_train: 0.004954, loss_test: 0.005568
time: 0.24505376815795898
time: 2.212496042251587
[1, 15662] loss_train: 0.006481, loss_test: 0.005571
time: 0.24805402755737305
time: 2.205552577972412
[1, 15663] loss_train: 0.008657, loss_test: 0.005573
time: 0.24405431747436523
time: 2.197491407394409
[1, 15664] loss_train: 0.011671, loss_test: 0.005575
time: 0.24505400657653809
time: 2.228499174118042
[1, 15665] loss_train: 0.005624, loss_test: 0.005574
time: 0.24405384063720703
time: 2.205493450164795
[1, 15666] loss_train: 0.012120, loss_test: 0.005574
time: 0.24305343627929688
time: 2.2345025539398193
[1, 15667] loss_train: 0.010861, loss_test: 0.005566
time: 0.24305438995361328
time: 2.2314987182617188
[1, 15668] loss_train: 0.012761, loss_test: 0.005564
time: 0.24405384063720703
time: 2.225517511367798
[1, 15669] loss_train: 0.004942, loss_test: 0.005565
time: 0.2470550537109375
time: 2.22149920463562
[1, 15670] loss_train: 0.001868, loss_test: 0.005564
time: 0.2560698986053467
time: 2.2695298194885254
[1, 15671] loss_train: 0.007352, loss_test: 0.005565
time: 0.24406671524047852
time: 2.2264976501464844
[1, 15672] loss_train: 0.005309, loss_test: 0.005564
time: 0.24605488777160645
time: 2.2460336685180664
[1, 15673] loss_train: 0.007717, loss_test: 0.005565
time: 0.2450542449951172
time: 2.217496395111084
[1, 15674] loss_train: 0.003147, loss_test: 0.005564
time: 0.24405431747436523
time: 2.205754041671753
[1, 15675] loss_train: 0.002481, loss_test: 0.005563
time: 0.24805521965026855
time: 2.244501829147339
[1, 15676] loss_train: 0.003055, loss_test: 0.005564
time: 0.24505400657653809
time: 2.2234976291656494
[1, 15677] loss_train: 0.009703, loss_test: 0.005566
time: 0.2470543384552002
time: 2.2224974632263184
[1, 15678] loss_train: 0.002638, loss_test: 0.005569
time: 0.24505376815795898
time: 2.218496561050415
[1, 15679] loss_train: 0.004794, loss_test: 0.005573
time: 0.25005555152893066
time: 2.247502565383911
[1, 15680] loss_train: 0.006561, loss_test: 0.005579
time: 0.25705671310424805
time: 2.260518789291382
[1, 15681] loss_train: 0.006143, loss_test: 0.005588
time: 0.25505709648132324
time: 2.2014923095703125
[1, 15682] loss_train: 0.004596, loss_test: 0.005588
time: 0.25005555152893066
time: 2.2425196170806885
[1, 15683] loss_train: 0.005544, loss_test: 0.005583
time: 0.2470548152923584
time: 2.2545042037963867
[1, 15684] loss_train: 0.005438, loss_test: 0.005577
time: 0.24306726455688477
time: 2.2825095653533936
[1, 15685] loss_train: 0.008116, loss_test: 0.005573
time: 0.2490556240081787
time: 2.209054946899414
[1, 15686] loss_train: 0.010509, loss_test: 0.005567
time: 0.24306511878967285
time: 2.215587615966797
[1, 15687] loss_train: 0.004333, loss_test: 0.005563
time: 0.24305462837219238
time: 2.232499122619629
[1, 15688] loss_train: 0.001674, loss_test: 0.005561
time: 0.24405384063720703
time: 2.2015016078948975
[1, 15689] loss_train: 0.004838, loss_test: 0.005561
time: 0.24605417251586914
time: 2.2214975357055664
[1, 15690] loss_train: 0.009922, loss_test: 0.005561
time: 0.25505590438842773
time: 2.243502140045166
[1, 15691] loss_train: 0.004462, loss_test: 0.005563
time: 0.24506616592407227
time: 2.255504608154297
[1, 15692] loss_train: 0.008108, loss_test: 0.005567
time: 0.2450549602508545
time: 2.2525033950805664
[1, 15693] loss_train: 0.004397, loss_test: 0.005571
time: 0.2450542449951172
time: 2.2775096893310547
[1, 15694] loss_train: 0.007049, loss_test: 0.005573
time: 0.24405312538146973
time: 2.2495031356811523
[1, 15695] loss_train: 0.002335, loss_test: 0.005568
time: 0.2450544834136963
time: 2.2174980640411377
[1, 15696] loss_train: 0.005527, loss_test: 0.005567
time: 0.2450544834136963
time: 2.206493377685547
[1, 15697] loss_train: 0.006719, loss_test: 0.005567
time: 0.24305415153503418
time: 2.2130126953125
[1, 15698] loss_train: 0.009678, loss_test: 0.005562
time: 0.24506664276123047
time: 2.18548846244812
[1, 15699] loss_train: 0.004714, loss_test: 0.005559
time: 0.24705982208251953
time: 2.231515407562256
[1, 15700] loss_train: 0.009074, loss_test: 0.005556
time: 0.2580571174621582
time: 2.2615182399749756
[1, 15701] loss_train: 0.009863, loss_test: 0.005555
time: 0.2450542449951172
time: 2.2124948501586914
[1, 15702] loss_train: 0.007365, loss_test: 0.005557
time: 0.2510554790496826
time: 2.218496799468994
[1, 15703] loss_train: 0.004719, loss_test: 0.005561
time: 0.24505400657653809
time: 2.1844887733459473
[1, 15704] loss_train: 0.002104, loss_test: 0.005564
time: 0.2450544834136963
time: 2.2360191345214844
[1, 15705] loss_train: 0.003344, loss_test: 0.005566
time: 0.24706816673278809
time: 2.240502119064331
[1, 15706] loss_train: 0.004853, loss_test: 0.005567
time: 0.24405407905578613
time: 2.2114946842193604
[1, 15707] loss_train: 0.011990, loss_test: 0.005569
time: 0.2450544834136963
time: 2.2114944458007812
[1, 15708] loss_train: 0.002577, loss_test: 0.005569
time: 0.2440807819366455
time: 2.233013391494751
[1, 15709] loss_train: 0.005052, loss_test: 0.005570
time: 0.2450551986694336
time: 2.2205042839050293
[1, 15710] loss_train: 0.009496, loss_test: 0.005571
time: 0.27005982398986816
time: 2.3185181617736816
[1, 15711] loss_train: 0.002320, loss_test: 0.005570
time: 0.24306702613830566
time: 2.2044928073883057
[1, 15712] loss_train: 0.001759, loss_test: 0.005571
time: 0.2450549602508545
time: 2.2114944458007812
[1, 15713] loss_train: 0.006345, loss_test: 0.005573
time: 0.2450549602508545
time: 2.236499786376953
[1, 15714] loss_train: 0.007074, loss_test: 0.005574
time: 0.2450542449951172
time: 2.2265002727508545
[1, 15715] loss_train: 0.006810, loss_test: 0.005576
time: 0.24405384063720703
time: 2.231501340866089
[1, 15716] loss_train: 0.004999, loss_test: 0.005576
time: 0.24405479431152344
time: 2.2530229091644287
[1, 15717] loss_train: 0.000587, loss_test: 0.005576
time: 0.24305367469787598
time: 2.239501714706421
[1, 15718] loss_train: 0.012663, loss_test: 0.005573
time: 0.24205374717712402
time: 2.2395007610321045
[1, 15719] loss_train: 0.005340, loss_test: 0.005568
time: 0.2470550537109375
time: 2.219496011734009
[1, 15720] loss_train: 0.009155, loss_test: 0.005563
time: 0.258056640625
time: 2.2535202503204346
[1, 15721] loss_train: 0.003560, loss_test: 0.005558
time: 0.24305415153503418
time: 2.2274975776672363
[1, 15722] loss_train: 0.008762, loss_test: 0.005554
time: 0.24405455589294434
time: 2.22149658203125
[1, 15723] loss_train: 0.002325, loss_test: 0.005552
time: 0.24605441093444824
time: 2.2013628482818604
[1, 15724] loss_train: 0.002887, loss_test: 0.005551
time: 0.24605417251586914
time: 2.2114951610565186
[1, 15725] loss_train: 0.004905, loss_test: 0.005551
time: 0.25005507469177246
time: 2.2194972038269043
[1, 15726] loss_train: 0.003543, loss_test: 0.005551
time: 0.2470541000366211
time: 2.2254981994628906
[1, 15727] loss_train: 0.009759, loss_test: 0.005551
time: 0.24606728553771973
time: 2.2227914333343506
[1, 15728] loss_train: 0.011628, loss_test: 0.005551
time: 0.24405503273010254
time: 2.2425191402435303
[1, 15729] loss_train: 0.003450, loss_test: 0.005553
time: 0.24405455589294434
time: 2.232499122619629
[1, 15730] loss_train: 0.007799, loss_test: 0.005554
time: 0.25606203079223633
time: 2.2364988327026367
[1, 15731] loss_train: 0.005607, loss_test: 0.005555
time: 0.24906373023986816
time: 2.251483201980591
[1, 15732] loss_train: 0.008917, loss_test: 0.005555
time: 0.24405407905578613
time: 2.2775089740753174
[1, 15733] loss_train: 0.004997, loss_test: 0.005555
time: 0.24405360221862793
time: 2.237511157989502
[1, 15734] loss_train: 0.013627, loss_test: 0.005557
time: 0.24506711959838867
time: 2.217495918273926
[1, 15735] loss_train: 0.006707, loss_test: 0.005559
time: 0.24405384063720703
time: 2.242593288421631
[1, 15736] loss_train: 0.001417, loss_test: 0.005560
time: 0.24506759643554688
time: 2.2274973392486572
[1, 15737] loss_train: 0.005793, loss_test: 0.005560
time: 0.24405503273010254
time: 2.2535033226013184
[1, 15738] loss_train: 0.008099, loss_test: 0.005562
time: 0.24405431747436523
time: 2.2124946117401123
[1, 15739] loss_train: 0.004745, loss_test: 0.005565
time: 0.2450544834136963
time: 2.2234973907470703
[1, 15740] loss_train: 0.003156, loss_test: 0.005569
time: 0.25705695152282715
time: 2.281510829925537
[1, 15741] loss_train: 0.008597, loss_test: 0.005572
time: 0.24405407905578613
time: 2.2355003356933594
[1, 15742] loss_train: 0.008111, loss_test: 0.005571
time: 0.24405384063720703
time: 2.2274982929229736
[1, 15743] loss_train: 0.006678, loss_test: 0.005572
time: 0.2450544834136963
time: 2.2154958248138428
[1, 15744] loss_train: 0.016251, loss_test: 0.005568
time: 0.24505352973937988
time: 2.2345004081726074
[1, 15745] loss_train: 0.009240, loss_test: 0.005567
time: 0.24405455589294434
time: 2.2233035564422607
[1, 15746] loss_train: 0.009055, loss_test: 0.005573
time: 0.24706625938415527
time: 2.1954994201660156
[1, 15747] loss_train: 0.005862, loss_test: 0.005581
time: 0.24606823921203613
time: 2.218496322631836
[1, 15748] loss_train: 0.004385, loss_test: 0.005583
time: 0.25005578994750977
time: 2.2400155067443848
[1, 15749] loss_train: 0.007660, loss_test: 0.005584
time: 0.24605512619018555
time: 2.2160024642944336
[1, 15750] loss_train: 0.000709, loss_test: 0.005587
time: 0.2600581645965576
time: 2.2505033016204834
[1, 15751] loss_train: 0.007737, loss_test: 0.005586
time: 0.2450547218322754
time: 2.2435011863708496
[1, 15752] loss_train: 0.001219, loss_test: 0.005585
time: 0.2470545768737793
time: 2.229004144668579
[1, 15753] loss_train: 0.003529, loss_test: 0.005582
time: 0.24405455589294434
time: 2.235499620437622
[1, 15754] loss_train: 0.003497, loss_test: 0.005579
time: 0.2450547218322754
time: 2.214005708694458
[1, 15755] loss_train: 0.006582, loss_test: 0.005576
time: 0.2450547218322754
time: 2.2145020961761475
[1, 15756] loss_train: 0.011258, loss_test: 0.005577
time: 0.2490556240081787
time: 2.245502233505249
[1, 15757] loss_train: 0.003566, loss_test: 0.005573
time: 0.2440800666809082
time: 2.232499122619629
[1, 15758] loss_train: 0.003962, loss_test: 0.005573
time: 0.24606871604919434
time: 2.208508253097534
[1, 15759] loss_train: 0.006256, loss_test: 0.005574
time: 0.2470545768737793
time: 2.2224977016448975
[1, 15760] loss_train: 0.002057, loss_test: 0.005576
time: 0.25505614280700684
time: 2.2213661670684814
[1, 15761] loss_train: 0.010490, loss_test: 0.005576
time: 0.24509215354919434
time: 2.230015993118286
[1, 15762] loss_train: 0.008161, loss_test: 0.005576
time: 0.24707984924316406
time: 2.1974904537200928
[1, 15763] loss_train: 0.015370, loss_test: 0.005572
time: 0.24605488777160645
time: 2.2575058937072754
[1, 15764] loss_train: 0.001293, loss_test: 0.005570
time: 0.24305295944213867
time: 2.2154958248138428
[1, 15765] loss_train: 0.009182, loss_test: 0.005568
time: 0.24606847763061523
time: 2.211494207382202
[1, 15766] loss_train: 0.004348, loss_test: 0.005567
time: 0.2490553855895996
time: 2.235499858856201
[1, 15767] loss_train: 0.004322, loss_test: 0.005567
time: 0.24805521965026855
time: 2.221496820449829
[1, 15768] loss_train: 0.003888, loss_test: 0.005568
time: 0.24605655670166016
time: 2.225508213043213
[1, 15769] loss_train: 0.002233, loss_test: 0.005572
time: 0.24805450439453125
time: 2.243502140045166
[1, 15770] loss_train: 0.001410, loss_test: 0.005577
time: 0.26105761528015137
time: 2.2525041103363037
[1, 15771] loss_train: 0.001117, loss_test: 0.005583
time: 0.24805474281311035
time: 2.203493356704712
[1, 15772] loss_train: 0.007696, loss_test: 0.005589
time: 0.24506855010986328
time: 2.224497079849243
[1, 15773] loss_train: 0.004471, loss_test: 0.005593
time: 0.2470543384552002
time: 2.205493927001953
[1, 15774] loss_train: 0.007173, loss_test: 0.005593
time: 0.24505400657653809
time: 2.2428324222564697
[1, 15775] loss_train: 0.003453, loss_test: 0.005591
time: 0.24306702613830566
time: 2.219496011734009
[1, 15776] loss_train: 0.011639, loss_test: 0.005585
time: 0.24405455589294434
time: 2.2254977226257324
[1, 15777] loss_train: 0.006862, loss_test: 0.005578
time: 0.24605417251586914
time: 2.246502637863159
[1, 15778] loss_train: 0.008667, loss_test: 0.005569
time: 0.2440803050994873
time: 2.2315151691436768
[1, 15779] loss_train: 0.005296, loss_test: 0.005566
time: 0.2450542449951172
time: 2.244504690170288
[1, 15780] loss_train: 0.006993, loss_test: 0.005565
time: 0.2580575942993164
time: 2.242501735687256
[1, 15781] loss_train: 0.003122, loss_test: 0.005567
time: 0.24606680870056152
time: 2.255507707595825
[1, 15782] loss_train: 0.003934, loss_test: 0.005570
time: 0.24405384063720703
time: 2.221497058868408
[1, 15783] loss_train: 0.003812, loss_test: 0.005572
time: 0.24605417251586914
time: 2.1974923610687256
[1, 15784] loss_train: 0.002968, loss_test: 0.005575
time: 0.24405384063720703
time: 2.215041160583496
[1, 15785] loss_train: 0.008950, loss_test: 0.005577
time: 0.24405336380004883
time: 2.194499969482422
[1, 15786] loss_train: 0.005043, loss_test: 0.005575
time: 0.24509453773498535
time: 2.206493854522705
[1, 15787] loss_train: 0.006269, loss_test: 0.005572
time: 0.24605488777160645
time: 2.2024929523468018
[1, 15788] loss_train: 0.008805, loss_test: 0.005568
time: 0.2465662956237793
time: 2.2274982929229736
[1, 15789] loss_train: 0.006933, loss_test: 0.005564
time: 0.24605441093444824
time: 2.2094943523406982
[1, 15790] loss_train: 0.006673, loss_test: 0.005562
time: 0.25905752182006836
time: 2.2435038089752197
[1, 15791] loss_train: 0.000482, loss_test: 0.005561
time: 0.24405384063720703
time: 2.2397751808166504
[1, 15792] loss_train: 0.009213, loss_test: 0.005562
time: 0.2450547218322754
time: 2.2530181407928467
[1, 15793] loss_train: 0.008226, loss_test: 0.005562
time: 0.24405479431152344
time: 2.223497152328491
[1, 15794] loss_train: 0.005187, loss_test: 0.005564
time: 0.24205374717712402
time: 2.2415013313293457
[1, 15795] loss_train: 0.004402, loss_test: 0.005565
time: 0.24405407905578613
time: 2.220496892929077
[1, 15796] loss_train: 0.002622, loss_test: 0.005566
time: 0.24405479431152344
time: 2.199500560760498
[1, 15797] loss_train: 0.010507, loss_test: 0.005566
time: 0.24605441093444824
time: 2.203106641769409
[1, 15798] loss_train: 0.005150, loss_test: 0.005567
time: 0.24405407905578613
time: 2.208494186401367
[1, 15799] loss_train: 0.010409, loss_test: 0.005564
time: 0.24260330200195312
time: 2.2515041828155518
[1, 15800] loss_train: 0.018609, loss_test: 0.005559
time: 0.2580578327178955
time: 2.2304983139038086
[1, 15801] loss_train: 0.006815, loss_test: 0.005558
time: 0.24305129051208496
time: 2.216014862060547
[1, 15802] loss_train: 0.010104, loss_test: 0.005559
time: 0.24606728553771973
time: 2.2480251789093018
[1, 15803] loss_train: 0.000800, loss_test: 0.005561
time: 0.24506711959838867
time: 2.2124953269958496
[1, 15804] loss_train: 0.004652, loss_test: 0.005563
time: 0.24605512619018555
time: 2.2395143508911133
[1, 15805] loss_train: 0.004847, loss_test: 0.005563
time: 0.25006747245788574
time: 2.2274982929229736
[1, 15806] loss_train: 0.008146, loss_test: 0.005562
time: 0.24406743049621582
time: 2.204493761062622
[1, 15807] loss_train: 0.010364, loss_test: 0.005561
time: 0.25505590438842773
time: 2.199056386947632
[1, 15808] loss_train: 0.003465, loss_test: 0.005561
time: 0.24405550956726074
time: 2.234541654586792
[1, 15809] loss_train: 0.011347, loss_test: 0.005562
time: 0.24405431747436523
time: 2.209494113922119
[1, 15810] loss_train: 0.004669, loss_test: 0.005564
time: 0.25505638122558594
time: 2.293513536453247
[1, 15811] loss_train: 0.010434, loss_test: 0.005567
time: 0.24205374717712402
time: 2.271151542663574
[1, 15812] loss_train: 0.005284, loss_test: 0.005571
time: 0.24205398559570312
time: 2.2284984588623047
[1, 15813] loss_train: 0.010984, loss_test: 0.005574
time: 0.24405384063720703
time: 2.227503538131714
[1, 15814] loss_train: 0.007650, loss_test: 0.005576
time: 0.24605417251586914
time: 2.239015817642212
[1, 15815] loss_train: 0.003405, loss_test: 0.005577
time: 0.24505925178527832
time: 2.235499620437622
[1, 15816] loss_train: 0.001865, loss_test: 0.005579
time: 0.24605512619018555
time: 2.2425007820129395
[1, 15817] loss_train: 0.004859, loss_test: 0.005573
time: 0.24805521965026855
time: 2.2365005016326904
[1, 15818] loss_train: 0.002635, loss_test: 0.005566
time: 0.2450723648071289
time: 2.2234978675842285
[1, 15819] loss_train: 0.008981, loss_test: 0.005558
time: 0.24405431747436523
time: 2.197024345397949
[1, 15820] loss_train: 0.001483, loss_test: 0.005555
time: 0.256056547164917
time: 2.2415008544921875
[1, 15821] loss_train: 0.003234, loss_test: 0.005559
time: 0.2450551986694336
time: 2.2395172119140625
[1, 15822] loss_train: 0.007599, loss_test: 0.005562
time: 0.2450544834136963
time: 2.2090132236480713
[1, 15823] loss_train: 0.017153, loss_test: 0.005564
time: 0.24405360221862793
time: 2.2024929523468018
[1, 15824] loss_train: 0.007114, loss_test: 0.005568
time: 0.2470552921295166
time: 2.2215096950531006
[1, 15825] loss_train: 0.007127, loss_test: 0.005570
time: 0.24405431747436523
time: 2.259507179260254
[1, 15826] loss_train: 0.005058, loss_test: 0.005571
time: 0.24805569648742676
time: 2.2304983139038086
[1, 15827] loss_train: 0.008228, loss_test: 0.005568
time: 0.2490556240081787
time: 2.254774570465088
[1, 15828] loss_train: 0.003824, loss_test: 0.005566
time: 0.2490553855895996
time: 2.219496011734009
[1, 15829] loss_train: 0.001988, loss_test: 0.005563
time: 0.24405360221862793
time: 2.219514846801758
[1, 15830] loss_train: 0.005531, loss_test: 0.005564
time: 0.263059139251709
time: 2.263505458831787
[1, 15831] loss_train: 0.005564, loss_test: 0.005566
time: 0.2450547218322754
time: 2.220496654510498
[1, 15832] loss_train: 0.009844, loss_test: 0.005569
time: 0.2490689754486084
time: 2.2184371948242188
[1, 15833] loss_train: 0.006381, loss_test: 0.005572
time: 0.24405407905578613
time: 2.2295007705688477
[1, 15834] loss_train: 0.004892, loss_test: 0.005576
time: 0.24505376815795898
time: 2.230499267578125
[1, 15835] loss_train: 0.003898, loss_test: 0.005583
time: 0.24606585502624512
time: 2.209496259689331
[1, 15836] loss_train: 0.007553, loss_test: 0.005591
time: 0.24305343627929688
time: 2.2184970378875732
[1, 15837] loss_train: 0.008183, loss_test: 0.005598
time: 0.24405360221862793
time: 2.266509771347046
[1, 15838] loss_train: 0.001921, loss_test: 0.005607
time: 0.24605441093444824
time: 2.2535040378570557
[1, 15839] loss_train: 0.004140, loss_test: 0.005617
time: 0.24405479431152344
time: 2.2195160388946533
[1, 15840] loss_train: 0.000981, loss_test: 0.005626
time: 0.2560560703277588
time: 2.292276620864868
[1, 15841] loss_train: 0.006871, loss_test: 0.005606
time: 0.24605488777160645
time: 2.254023551940918
[1, 15842] loss_train: 0.003723, loss_test: 0.005589
time: 0.24406814575195312
time: 2.2245254516601562
[1, 15843] loss_train: 0.005523, loss_test: 0.005576
time: 0.2450542449951172
time: 2.2274980545043945
[1, 15844] loss_train: 0.009287, loss_test: 0.005564
time: 0.24605464935302734
time: 2.20849609375
[1, 15845] loss_train: 0.004656, loss_test: 0.005564
time: 0.24405431747436523
time: 2.1934902667999268
[1, 15846] loss_train: 0.003456, loss_test: 0.005571
time: 0.24405407905578613
time: 2.208494186401367
[1, 15847] loss_train: 0.003928, loss_test: 0.005579
time: 0.24505400657653809
time: 2.2380282878875732
[1, 15848] loss_train: 0.008018, loss_test: 0.005587
time: 0.24505400657653809
time: 2.20149302482605
[1, 15849] loss_train: 0.006901, loss_test: 0.005585
time: 0.2490558624267578
time: 2.22804856300354
[1, 15850] loss_train: 0.008569, loss_test: 0.005583
time: 0.2560689449310303
time: 2.2655093669891357
[1, 15851] loss_train: 0.001371, loss_test: 0.005580
time: 0.25505638122558594
time: 2.2255024909973145
[1, 15852] loss_train: 0.005761, loss_test: 0.005579
time: 0.2450549602508545
time: 2.232499599456787
[1, 15853] loss_train: 0.004036, loss_test: 0.005575
time: 0.2520561218261719
time: 2.226513147354126
[1, 15854] loss_train: 0.007135, loss_test: 0.005570
time: 0.2450547218322754
time: 2.2274978160858154
[1, 15855] loss_train: 0.005543, loss_test: 0.005568
time: 0.25005626678466797
time: 2.2090063095092773
[1, 15856] loss_train: 0.005545, loss_test: 0.005571
time: 0.2450551986694336
time: 2.215998649597168
[1, 15857] loss_train: 0.013013, loss_test: 0.005571
time: 0.244065523147583
time: 2.2315070629119873
[1, 15858] loss_train: 0.004155, loss_test: 0.005571
time: 0.24605488777160645
time: 2.243501901626587
[1, 15859] loss_train: 0.007281, loss_test: 0.005572
time: 0.24405431747436523
time: 2.213503122329712
[1, 15860] loss_train: 0.007486, loss_test: 0.005575
time: 0.25705671310424805
time: 2.2335000038146973
[1, 15861] loss_train: 0.002647, loss_test: 0.005578
time: 0.2450547218322754
time: 2.2540283203125
[1, 15862] loss_train: 0.006712, loss_test: 0.005581
time: 0.2450547218322754
time: 2.2430057525634766
[1, 15863] loss_train: 0.003868, loss_test: 0.005581
time: 0.24405360221862793
time: 2.238478899002075
[1, 15864] loss_train: 0.008314, loss_test: 0.005579
time: 0.2450544834136963
time: 2.2555041313171387
[1, 15865] loss_train: 0.010849, loss_test: 0.005577
time: 0.2450542449951172
time: 2.217498779296875
[1, 15866] loss_train: 0.002987, loss_test: 0.005574
time: 0.24405407905578613
time: 2.2254979610443115
[1, 15867] loss_train: 0.012270, loss_test: 0.005569
time: 0.24306774139404297
time: 2.247502565383911
[1, 15868] loss_train: 0.006663, loss_test: 0.005565
time: 0.24305367469787598
time: 2.193490982055664
[1, 15869] loss_train: 0.003789, loss_test: 0.005565
time: 0.24406003952026367
time: 2.190490484237671
[1, 15870] loss_train: 0.007036, loss_test: 0.005566
time: 0.25705647468566895
time: 2.258507490158081
[1, 15871] loss_train: 0.002732, loss_test: 0.005568
time: 0.2530555725097656
time: 2.2024924755096436
[1, 15872] loss_train: 0.002729, loss_test: 0.005570
time: 0.2510550022125244
time: 2.257509708404541
[1, 15873] loss_train: 0.011083, loss_test: 0.005570
time: 0.24506783485412598
time: 2.2244980335235596
[1, 15874] loss_train: 0.002638, loss_test: 0.005570
time: 0.24805450439453125
time: 2.2428762912750244
[1, 15875] loss_train: 0.003179, loss_test: 0.005572
time: 0.24605345726013184
time: 2.2403223514556885
[1, 15876] loss_train: 0.001594, loss_test: 0.005575
time: 0.24805474281311035
time: 2.236499786376953
[1, 15877] loss_train: 0.005774, loss_test: 0.005582
time: 0.24405479431152344
time: 2.244520664215088
[1, 15878] loss_train: 0.000450, loss_test: 0.005592
time: 0.25005507469177246
time: 2.2395009994506836
[1, 15879] loss_train: 0.007696, loss_test: 0.005596
time: 0.24305367469787598
time: 2.2264976501464844
[1, 15880] loss_train: 0.003248, loss_test: 0.005601
time: 0.26008176803588867
time: 2.2520360946655273
[1, 15881] loss_train: 0.003657, loss_test: 0.005604
time: 0.24505376815795898
time: 2.255511522293091
[1, 15882] loss_train: 0.007995, loss_test: 0.005599
time: 0.24605464935302734
time: 2.214491605758667
[1, 15883] loss_train: 0.007365, loss_test: 0.005595
time: 0.24305415153503418
time: 2.218498945236206
[1, 15884] loss_train: 0.002357, loss_test: 0.005593
time: 0.24605417251586914
time: 2.201314687728882
[1, 15885] loss_train: 0.003864, loss_test: 0.005591
time: 0.24405407905578613
time: 2.2174952030181885
[1, 15886] loss_train: 0.003910, loss_test: 0.005590
time: 0.2440657615661621
time: 2.2227060794830322
[1, 15887] loss_train: 0.008016, loss_test: 0.005589
time: 0.24505400657653809
time: 2.2274982929229736
[1, 15888] loss_train: 0.001917, loss_test: 0.005591
time: 0.24605131149291992
time: 2.2215194702148438
[1, 15889] loss_train: 0.007289, loss_test: 0.005595
time: 0.24305367469787598
time: 2.2335002422332764
[1, 15890] loss_train: 0.006507, loss_test: 0.005600
time: 0.25705742835998535
time: 2.2425010204315186
[1, 15891] loss_train: 0.001013, loss_test: 0.005605
time: 0.24706697463989258
time: 2.220499038696289
[1, 15892] loss_train: 0.007017, loss_test: 0.005611
time: 0.24306321144104004
time: 2.2585058212280273
[1, 15893] loss_train: 0.004677, loss_test: 0.005616
time: 0.24405407905578613
time: 2.1934924125671387
[1, 15894] loss_train: 0.008864, loss_test: 0.005619
time: 0.2470543384552002
time: 2.2120115756988525
[1, 15895] loss_train: 0.002353, loss_test: 0.005622
time: 0.24805426597595215
time: 2.2345004081726074
[1, 15896] loss_train: 0.002361, loss_test: 0.005629
time: 0.2450544834136963
time: 2.2274980545043945
[1, 15897] loss_train: 0.001937, loss_test: 0.005632
time: 0.2490549087524414
time: 2.230499267578125
[1, 15898] loss_train: 0.004948, loss_test: 0.005634
time: 0.2450549602508545
time: 2.2294983863830566
[1, 15899] loss_train: 0.007946, loss_test: 0.005626
time: 0.2470550537109375
time: 2.2224974632263184
[1, 15900] loss_train: 0.005689, loss_test: 0.005619
time: 0.25705718994140625
time: 2.2900359630584717
[1, 15901] loss_train: 0.003745, loss_test: 0.005611
time: 0.25505638122558594
time: 2.255506992340088
[1, 15902] loss_train: 0.001814, loss_test: 0.005604
time: 0.2450547218322754
time: 2.235499858856201
[1, 15903] loss_train: 0.003985, loss_test: 0.005594
time: 0.2470552921295166
time: 2.195493459701538
[1, 15904] loss_train: 0.005607, loss_test: 0.005587
time: 0.24305319786071777
time: 2.2244980335235596
[1, 15905] loss_train: 0.004969, loss_test: 0.005582
time: 0.24305367469787598
time: 2.232499837875366
[1, 15906] loss_train: 0.005891, loss_test: 0.005579
time: 0.24406695365905762
time: 2.2255094051361084
[1, 15907] loss_train: 0.006705, loss_test: 0.005575
time: 0.2430553436279297
time: 2.211494207382202
[1, 15908] loss_train: 0.001996, loss_test: 0.005574
time: 0.2450547218322754
time: 2.1895055770874023
[1, 15909] loss_train: 0.012179, loss_test: 0.005571
time: 0.24405455589294434
time: 2.2345004081726074
[1, 15910] loss_train: 0.002571, loss_test: 0.005571
time: 0.2560708522796631
time: 2.259504795074463
[1, 15911] loss_train: 0.010556, loss_test: 0.005570
time: 0.2450544834136963
time: 2.259505033493042
[1, 15912] loss_train: 0.006575, loss_test: 0.005570
time: 0.2450547218322754
time: 2.2294986248016357
[1, 15913] loss_train: 0.015595, loss_test: 0.005570
time: 0.24305438995361328
time: 2.247502326965332
[1, 15914] loss_train: 0.001774, loss_test: 0.005570
time: 0.24305391311645508
time: 2.221497058868408
[1, 15915] loss_train: 0.005084, loss_test: 0.005568
time: 0.24506759643554688
time: 2.2244977951049805
[1, 15916] loss_train: 0.010774, loss_test: 0.005566
time: 0.24507856369018555
time: 2.247023820877075
[1, 15917] loss_train: 0.002607, loss_test: 0.005564
time: 0.24305367469787598
time: 2.2144956588745117
[1, 15918] loss_train: 0.006711, loss_test: 0.005561
time: 0.2470545768737793
time: 2.2110378742218018
[1, 15919] loss_train: 0.006849, loss_test: 0.005557
time: 0.24505376815795898
time: 2.217496156692505
[1, 15920] loss_train: 0.003754, loss_test: 0.005553
time: 0.2635819911956787
time: 2.2745091915130615
[1, 15921] loss_train: 0.000918, loss_test: 0.005550
time: 0.24805450439453125
time: 2.243502378463745
[1, 15922] loss_train: 0.001670, loss_test: 0.005553
time: 0.2490556240081787
time: 2.2645061016082764
[1, 15923] loss_train: 0.005189, loss_test: 0.005564
time: 0.24405360221862793
time: 2.233501672744751
[1, 15924] loss_train: 0.007157, loss_test: 0.005581
time: 0.25005531311035156
time: 2.2505037784576416
[1, 15925] loss_train: 0.008161, loss_test: 0.005603
time: 0.2450542449951172
time: 2.2234978675842285
[1, 15926] loss_train: 0.002849, loss_test: 0.005619
time: 0.2470545768737793
time: 2.254504680633545
[1, 15927] loss_train: 0.006443, loss_test: 0.005630
time: 0.24605536460876465
time: 2.2154951095581055
[1, 15928] loss_train: 0.002806, loss_test: 0.005637
time: 0.24805474281311035
time: 2.229020118713379
[1, 15929] loss_train: 0.009133, loss_test: 0.005634
time: 0.24505400657653809
time: 2.2154955863952637
[1, 15930] loss_train: 0.000993, loss_test: 0.005635
time: 0.256056547164917
time: 2.241501569747925
[1, 15931] loss_train: 0.012683, loss_test: 0.005614
time: 0.2470548152923584
time: 2.2079968452453613
[1, 15932] loss_train: 0.003560, loss_test: 0.005605
time: 0.24405431747436523
time: 2.2475051879882812
[1, 15933] loss_train: 0.006092, loss_test: 0.005606
time: 0.2470686435699463
time: 2.223496675491333
[1, 15934] loss_train: 0.005317, loss_test: 0.005614
time: 0.24405479431152344
time: 2.2274980545043945
[1, 15935] loss_train: 0.006107, loss_test: 0.005627
time: 0.24305343627929688
time: 2.2345001697540283
[1, 15936] loss_train: 0.007967, loss_test: 0.005640
time: 0.24305176734924316
time: 2.2415006160736084
[1, 15937] loss_train: 0.008713, loss_test: 0.005649
time: 0.24405479431152344
time: 2.235459327697754
[1, 15938] loss_train: 0.013011, loss_test: 0.005662
time: 0.24309492111206055
time: 2.220496654510498
[1, 15939] loss_train: 0.004019, loss_test: 0.005680
time: 0.2450547218322754
time: 2.208709478378296
[1, 15940] loss_train: 0.004761, loss_test: 0.005674
time: 0.25705671310424805
time: 2.2154958248138428
[1, 15941] loss_train: 0.005875, loss_test: 0.005664
time: 0.24805521965026855
time: 2.216092586517334
[1, 15942] loss_train: 0.005611, loss_test: 0.005648
time: 0.24605464935302734
time: 2.232499122619629
[1, 15943] loss_train: 0.002470, loss_test: 0.005637
time: 0.24606609344482422
time: 2.231499433517456
[1, 15944] loss_train: 0.005431, loss_test: 0.005634
time: 0.2450547218322754
time: 2.2405011653900146
[1, 15945] loss_train: 0.003870, loss_test: 0.005638
time: 0.2470552921295166
time: 2.254513740539551
[1, 15946] loss_train: 0.003199, loss_test: 0.005649
time: 0.24508118629455566
time: 2.22350811958313
[1, 15947] loss_train: 0.005941, loss_test: 0.005659
time: 0.2450547218322754
time: 2.2284982204437256
[1, 15948] loss_train: 0.001214, loss_test: 0.005673
time: 0.24605441093444824
time: 2.258505344390869
[1, 15949] loss_train: 0.006229, loss_test: 0.005680
time: 0.24805474281311035
time: 2.2330033779144287
[1, 15950] loss_train: 0.007690, loss_test: 0.005668
time: 0.25705647468566895
time: 2.279510498046875
[1, 15951] loss_train: 0.005142, loss_test: 0.005658
time: 0.25705766677856445
time: 2.2024941444396973
[1, 15952] loss_train: 0.002261, loss_test: 0.005651
time: 0.24405431747436523
time: 2.201498031616211
[1, 15953] loss_train: 0.004858, loss_test: 0.005638
time: 0.247053861618042
time: 2.2224960327148438
[1, 15954] loss_train: 0.004730, loss_test: 0.005630
time: 0.2450549602508545
time: 2.206493616104126
[1, 15955] loss_train: 0.009568, loss_test: 0.005612
time: 0.24406671524047852
time: 2.2284982204437256
[1, 15956] loss_train: 0.006157, loss_test: 0.005601
time: 0.24405384063720703
time: 2.2235000133514404
[1, 15957] loss_train: 0.010882, loss_test: 0.005598
time: 0.24305438995361328
time: 2.240520477294922
[1, 15958] loss_train: 0.009076, loss_test: 0.005612
time: 0.24706745147705078
time: 2.2264974117279053
[1, 15959] loss_train: 0.002473, loss_test: 0.005641
time: 0.2450549602508545
time: 2.2650258541107178
[1, 15960] loss_train: 0.003530, loss_test: 0.005658
time: 0.2560570240020752
time: 2.2620105743408203
[1, 15961] loss_train: 0.011465, loss_test: 0.005671
time: 0.2470552921295166
time: 2.2555065155029297
[1, 15962] loss_train: 0.010610, loss_test: 0.005683
time: 0.24405455589294434
time: 2.211494207382202
[1, 15963] loss_train: 0.004270, loss_test: 0.005676
time: 0.24405455589294434
time: 2.2294986248016357
[1, 15964] loss_train: 0.010602, loss_test: 0.005653
time: 0.24405384063720703
time: 2.204493522644043
[1, 15965] loss_train: 0.007304, loss_test: 0.005621
time: 0.24505400657653809
time: 2.202502965927124
[1, 15966] loss_train: 0.002541, loss_test: 0.005589
time: 0.24605393409729004
time: 2.2224974632263184
[1, 15967] loss_train: 0.008219, loss_test: 0.005569
time: 0.2450547218322754
time: 2.2155303955078125
[1, 15968] loss_train: 0.005113, loss_test: 0.005559
time: 0.25305604934692383
time: 2.2104949951171875
[1, 15969] loss_train: 0.008577, loss_test: 0.005561
time: 0.24505400657653809
time: 2.2375030517578125
[1, 15970] loss_train: 0.013723, loss_test: 0.005567
time: 0.2600576877593994
time: 2.2765088081359863
[1, 15971] loss_train: 0.002545, loss_test: 0.005575
time: 0.24805545806884766
time: 2.240044355392456
[1, 15972] loss_train: 0.013459, loss_test: 0.005581
time: 0.24805521965026855
time: 2.26251220703125
[1, 15973] loss_train: 0.004092, loss_test: 0.005585
time: 0.24505400657653809
time: 2.2560417652130127
[1, 15974] loss_train: 0.013346, loss_test: 0.005585
time: 0.2490546703338623
time: 2.2515039443969727
[1, 15975] loss_train: 0.012411, loss_test: 0.005584
time: 0.2450551986694336
time: 2.253512144088745
[1, 15976] loss_train: 0.009284, loss_test: 0.005574
time: 0.24805569648742676
time: 2.2265005111694336
[1, 15977] loss_train: 0.011333, loss_test: 0.005566
time: 0.24305486679077148
time: 2.210493803024292
[1, 15978] loss_train: 0.003271, loss_test: 0.005563
time: 0.24405455589294434
time: 2.2334988117218018
[1, 15979] loss_train: 0.003976, loss_test: 0.005563
time: 0.2450559139251709
time: 2.1984915733337402
[1, 15980] loss_train: 0.013496, loss_test: 0.005562
time: 0.25705742835998535
time: 2.26851224899292
[1, 15981] loss_train: 0.008961, loss_test: 0.005562
time: 0.24605393409729004
time: 2.2465028762817383
[1, 15982] loss_train: 0.003347, loss_test: 0.005561
time: 0.24309372901916504
time: 2.24550461769104
[1, 15983] loss_train: 0.003822, loss_test: 0.005561
time: 0.2440805435180664
time: 2.218496084213257
[1, 15984] loss_train: 0.006381, loss_test: 0.005562
time: 0.2450544834136963
time: 2.244502544403076
[1, 15985] loss_train: 0.005378, loss_test: 0.005564
time: 0.24305486679077148
time: 2.232020616531372
[1, 15986] loss_train: 0.003029, loss_test: 0.005566
time: 0.24405360221862793
time: 2.231498956680298
[1, 15987] loss_train: 0.008125, loss_test: 0.005569
time: 0.24405384063720703
time: 2.218231439590454
[1, 15988] loss_train: 0.004089, loss_test: 0.005573
time: 0.24305224418640137
time: 2.216496467590332
[1, 15989] loss_train: 0.008734, loss_test: 0.005575
time: 0.24405384063720703
time: 2.1995086669921875
[1, 15990] loss_train: 0.003809, loss_test: 0.005578
time: 0.2580583095550537
time: 2.2810182571411133
[1, 15991] loss_train: 0.005235, loss_test: 0.005582
time: 0.24605393409729004
time: 2.223515033721924
[1, 15992] loss_train: 0.006573, loss_test: 0.005586
time: 0.24605488777160645
time: 2.224498987197876
[1, 15993] loss_train: 0.004133, loss_test: 0.005592
time: 0.25005531311035156
time: 2.244502544403076
[1, 15994] loss_train: 0.014289, loss_test: 0.005597
time: 0.24557709693908691
time: 2.225497245788574
[1, 15995] loss_train: 0.015576, loss_test: 0.005599
time: 0.24405455589294434
time: 2.2680232524871826
[1, 15996] loss_train: 0.000708, loss_test: 0.005598
time: 0.24605488777160645
time: 2.247502326965332
[1, 15997] loss_train: 0.004673, loss_test: 0.005596
time: 0.2450542449951172
time: 2.2495036125183105
[1, 15998] loss_train: 0.003704, loss_test: 0.005594
time: 0.24105334281921387
time: 2.229499101638794
[1, 15999] loss_train: 0.022050, loss_test: 0.005596
time: 0.2450549602508545
time: 2.2184951305389404
[1, 16000] loss_train: 0.009487, loss_test: 0.005601
time: 0.2580573558807373
time: 2.2695109844207764
[1, 16001] loss_train: 0.010245, loss_test: 0.005618
time: 0.24605488777160645
time: 2.23836612701416
[1, 16002] loss_train: 0.007348, loss_test: 0.005644
time: 0.2450547218322754
time: 2.2495038509368896
[1, 16003] loss_train: 0.010944, loss_test: 0.005677
time: 0.24808263778686523
time: 2.233499050140381
[1, 16004] loss_train: 0.004899, loss_test: 0.005694
time: 0.24505376815795898
time: 2.22845196723938
[1, 16005] loss_train: 0.010556, loss_test: 0.005695
time: 0.24605464935302734
time: 2.2274982929229736
[1, 16006] loss_train: 0.003248, loss_test: 0.005671
time: 0.24505400657653809
time: 2.2395009994506836
[1, 16007] loss_train: 0.003523, loss_test: 0.005637
time: 0.25005602836608887
time: 2.2265164852142334
[1, 16008] loss_train: 0.001381, loss_test: 0.005609
time: 0.24506759643554688
time: 2.2555041313171387
[1, 16009] loss_train: 0.005985, loss_test: 0.005594
time: 0.2450547218322754
time: 2.2315011024475098
[1, 16010] loss_train: 0.003710, loss_test: 0.005596
time: 0.2572150230407715
time: 2.286353349685669
[1, 16011] loss_train: 0.004045, loss_test: 0.005609
time: 0.24606680870056152
time: 2.2235045433044434
[1, 16012] loss_train: 0.003736, loss_test: 0.005629
time: 0.256056547164917
time: 2.220496892929077
[1, 16013] loss_train: 0.000793, loss_test: 0.005657
time: 0.24405431747436523
time: 2.1944899559020996
[1, 16014] loss_train: 0.018799, loss_test: 0.005694
time: 0.24706697463989258
time: 2.2254996299743652
[1, 16015] loss_train: 0.009399, loss_test: 0.005735
time: 0.24306702613830566
time: 2.2327444553375244
[1, 16016] loss_train: 0.003456, loss_test: 0.005751
time: 0.24405384063720703
time: 2.205493688583374
[1, 16017] loss_train: 0.004122, loss_test: 0.005736
time: 0.24606800079345703
time: 2.2395012378692627
[1, 16018] loss_train: 0.002847, loss_test: 0.005725
time: 0.24405407905578613
time: 2.2144951820373535
[1, 16019] loss_train: 0.005827, loss_test: 0.005718
time: 0.24605441093444824
time: 2.2046990394592285
[1, 16020] loss_train: 0.003538, loss_test: 0.005710
time: 0.25705647468566895
time: 2.2525064945220947
[1, 16021] loss_train: 0.002869, loss_test: 0.005707
time: 0.24405431747436523
time: 2.2435038089752197
[1, 16022] loss_train: 0.001549, loss_test: 0.005707
time: 0.25305628776550293
time: 2.2134945392608643
[1, 16023] loss_train: 0.020173, loss_test: 0.005648
time: 0.24505400657653809
time: 2.266509771347046
[1, 16024] loss_train: 0.013503, loss_test: 0.005610
time: 0.2470545768737793
time: 2.230499029159546
[1, 16025] loss_train: 0.000761, loss_test: 0.005589
time: 0.24605512619018555
time: 2.209494113922119
[1, 16026] loss_train: 0.012828, loss_test: 0.005585
time: 0.24606633186340332
time: 2.2540252208709717
[1, 16027] loss_train: 0.009727, loss_test: 0.005596
time: 0.24605417251586914
time: 2.2046525478363037
[1, 16028] loss_train: 0.004267, loss_test: 0.005619
time: 0.24805450439453125
time: 2.195491313934326
[1, 16029] loss_train: 0.005685, loss_test: 0.005636
time: 0.24605441093444824
time: 2.2079968452453613
[1, 16030] loss_train: 0.012098, loss_test: 0.005635
time: 0.25705671310424805
time: 2.273508310317993
[1, 16031] loss_train: 0.003148, loss_test: 0.005636
time: 0.24605536460876465
time: 2.2425014972686768
[1, 16032] loss_train: 0.004658, loss_test: 0.005634
time: 0.2450542449951172
time: 2.23150372505188
[1, 16033] loss_train: 0.002334, loss_test: 0.005630
time: 0.24405455589294434
time: 2.2324986457824707
[1, 16034] loss_train: 0.012234, loss_test: 0.005626
time: 0.247053861618042
time: 2.2390148639678955
[1, 16035] loss_train: 0.004159, loss_test: 0.005614
time: 0.24505400657653809
time: 2.2525064945220947
[1, 16036] loss_train: 0.005206, loss_test: 0.005606
time: 0.24305438995361328
time: 2.20749568939209
[1, 16037] loss_train: 0.002984, loss_test: 0.005601
time: 0.24505615234375
time: 2.2194972038269043
[1, 16038] loss_train: 0.010524, loss_test: 0.005601
time: 0.24405360221862793
time: 2.2155041694641113
[1, 16039] loss_train: 0.008289, loss_test: 0.005600
time: 0.24305367469787598
time: 2.215015411376953
[1, 16040] loss_train: 0.004714, loss_test: 0.005601
time: 0.256056547164917
time: 2.227004051208496
[1, 16041] loss_train: 0.001299, loss_test: 0.005604
time: 0.24305438995361328
time: 2.2004919052124023
[1, 16042] loss_train: 0.004975, loss_test: 0.005609
time: 0.24405479431152344
time: 2.2180211544036865
[1, 16043] loss_train: 0.001729, loss_test: 0.005615
time: 0.24405479431152344
time: 2.2184958457946777
[1, 16044] loss_train: 0.007620, loss_test: 0.005614
time: 0.24505400657653809
time: 2.2264983654022217
[1, 16045] loss_train: 0.012125, loss_test: 0.005607
time: 0.24805521965026855
time: 2.2625057697296143
[1, 16046] loss_train: 0.005268, loss_test: 0.005599
time: 0.24506902694702148
time: 2.222496747970581
[1, 16047] loss_train: 0.005012, loss_test: 0.005593
time: 0.2470548152923584
time: 2.2355000972747803
[1, 16048] loss_train: 0.007785, loss_test: 0.005584
time: 0.24405455589294434
time: 2.209028482437134
[1, 16049] loss_train: 0.005443, loss_test: 0.005579
time: 0.24605393409729004
time: 2.2094948291778564
[1, 16050] loss_train: 0.001209, loss_test: 0.005576
time: 0.2560567855834961
time: 2.2415060997009277
[1, 16051] loss_train: 0.004496, loss_test: 0.005576
time: 0.24405622482299805
time: 2.2525036334991455
[1, 16052] loss_train: 0.003995, loss_test: 0.005574
time: 0.2450549602508545
time: 2.2005062103271484
[1, 16053] loss_train: 0.007691, loss_test: 0.005572
time: 0.24405360221862793
time: 2.206493854522705
[1, 16054] loss_train: 0.001110, loss_test: 0.005571
time: 0.24605512619018555
time: 2.2274982929229736
[1, 16055] loss_train: 0.002960, loss_test: 0.005572
time: 0.24605417251586914
time: 2.2314987182617188
[1, 16056] loss_train: 0.005651, loss_test: 0.005574
time: 0.24305415153503418
time: 2.2004921436309814
[1, 16057] loss_train: 0.010633, loss_test: 0.005576
time: 0.24305343627929688
time: 2.215496063232422
[1, 16058] loss_train: 0.004895, loss_test: 0.005578
time: 0.24405407905578613
time: 2.257505416870117
[1, 16059] loss_train: 0.007956, loss_test: 0.005579
time: 0.2450542449951172
time: 2.236518144607544
[1, 16060] loss_train: 0.007005, loss_test: 0.005579
time: 0.25705790519714355
time: 2.2525153160095215
[1, 16061] loss_train: 0.006727, loss_test: 0.005578
time: 0.24605488777160645
time: 2.2294986248016357
[1, 16062] loss_train: 0.007224, loss_test: 0.005577
time: 0.24405336380004883
time: 2.228503704071045
[1, 16063] loss_train: 0.003316, loss_test: 0.005583
time: 0.24409985542297363
time: 2.221496820449829
[1, 16064] loss_train: 0.001046, loss_test: 0.005591
time: 0.2490556240081787
time: 2.2024927139282227
[1, 16065] loss_train: 0.006953, loss_test: 0.005598
time: 0.2470548152923584
time: 2.2264981269836426
[1, 16066] loss_train: 0.004907, loss_test: 0.005607
time: 0.24605417251586914
time: 2.2100958824157715
[1, 16067] loss_train: 0.008950, loss_test: 0.005611
time: 0.2450542449951172
time: 2.238501787185669
[1, 16068] loss_train: 0.002701, loss_test: 0.005618
time: 0.24605417251586914
time: 2.2405011653900146
[1, 16069] loss_train: 0.002134, loss_test: 0.005620
time: 0.24305367469787598
time: 2.2927849292755127
[1, 16070] loss_train: 0.003811, loss_test: 0.005621
time: 0.25905752182006836
time: 2.2735087871551514
[1, 16071] loss_train: 0.004796, loss_test: 0.005621
time: 0.2450547218322754
time: 2.231501340866089
[1, 16072] loss_train: 0.003770, loss_test: 0.005621
time: 0.24805474281311035
time: 2.243504524230957
[1, 16073] loss_train: 0.008195, loss_test: 0.005618
time: 0.24405527114868164
time: 2.2165048122406006
[1, 16074] loss_train: 0.003621, loss_test: 0.005617
time: 0.25905799865722656
time: 2.2765116691589355
[1, 16075] loss_train: 0.011006, loss_test: 0.005608
time: 0.2450549602508545
time: 2.2495028972625732
[1, 16076] loss_train: 0.007373, loss_test: 0.005592
time: 0.24805474281311035
time: 2.214495897293091
[1, 16077] loss_train: 0.002856, loss_test: 0.005578
time: 0.24605417251586914
time: 2.2205114364624023
[1, 16078] loss_train: 0.006326, loss_test: 0.005569
time: 0.24605441093444824
time: 2.221497058868408
[1, 16079] loss_train: 0.000700, loss_test: 0.005565
time: 0.24405550956726074
time: 2.245501756668091
[1, 16080] loss_train: 0.007789, loss_test: 0.005559
time: 0.2560570240020752
time: 2.273510217666626
[1, 16081] loss_train: 0.012055, loss_test: 0.005555
time: 0.24405527114868164
time: 2.230242967605591
[1, 16082] loss_train: 0.000615, loss_test: 0.005553
time: 0.24305415153503418
time: 2.2340028285980225
[1, 16083] loss_train: 0.013045, loss_test: 0.005550
time: 0.24406647682189941
time: 2.212493896484375
[1, 16084] loss_train: 0.002393, loss_test: 0.005549
time: 0.24405384063720703
time: 2.2154953479766846
[1, 16085] loss_train: 0.007325, loss_test: 0.005551
time: 0.24605345726013184
time: 2.209502935409546
[1, 16086] loss_train: 0.006321, loss_test: 0.005555
time: 0.24505400657653809
time: 2.229498863220215
[1, 16087] loss_train: 0.005537, loss_test: 0.005558
time: 0.2520558834075928
time: 2.216495990753174
[1, 16088] loss_train: 0.005894, loss_test: 0.005560
time: 0.24505400657653809
time: 2.230766534805298
[1, 16089] loss_train: 0.012488, loss_test: 0.005563
time: 0.2470548152923584
time: 2.204493284225464
[1, 16090] loss_train: 0.008515, loss_test: 0.005567
time: 0.25705623626708984
time: 2.241501808166504
[1, 16091] loss_train: 0.005770, loss_test: 0.005568
time: 0.24805545806884766
time: 2.231499195098877
[1, 16092] loss_train: 0.009301, loss_test: 0.005567
time: 0.24805426597595215
time: 2.2084944248199463
[1, 16093] loss_train: 0.002558, loss_test: 0.005561
time: 0.24805450439453125
time: 2.2845115661621094
[1, 16094] loss_train: 0.005914, loss_test: 0.005558
time: 0.24605441093444824
time: 2.229499101638794
[1, 16095] loss_train: 0.006676, loss_test: 0.005558
time: 0.2510557174682617
time: 2.2294986248016357
[1, 16096] loss_train: 0.005616, loss_test: 0.005561
time: 0.24505400657653809
time: 2.20949649810791
[1, 16097] loss_train: 0.008468, loss_test: 0.005565
time: 0.24805498123168945
time: 2.231499433517456
[1, 16098] loss_train: 0.006044, loss_test: 0.005570
time: 0.24505615234375
time: 2.2134995460510254
[1, 16099] loss_train: 0.002037, loss_test: 0.005577
time: 0.2470688819885254
time: 2.2244973182678223
[1, 16100] loss_train: 0.004503, loss_test: 0.005585
time: 0.25505614280700684
time: 2.240530490875244
[1, 16101] loss_train: 0.006842, loss_test: 0.005597
time: 0.2430553436279297
time: 2.2335000038146973
[1, 16102] loss_train: 0.006451, loss_test: 0.005606
time: 0.24605488777160645
time: 2.2351233959198
[1, 16103] loss_train: 0.003945, loss_test: 0.005619
time: 0.24405407905578613
time: 2.2375006675720215
[1, 16104] loss_train: 0.006679, loss_test: 0.005624
time: 0.24605441093444824
time: 2.2495033740997314
[1, 16105] loss_train: 0.006063, loss_test: 0.005628
time: 0.24605488777160645
time: 2.234501838684082
[1, 16106] loss_train: 0.002665, loss_test: 0.005629
time: 0.24405574798583984
time: 2.2234978675842285
[1, 16107] loss_train: 0.004094, loss_test: 0.005631
time: 0.24405431747436523
time: 2.196491241455078
[1, 16108] loss_train: 0.006059, loss_test: 0.005625
time: 0.2470543384552002
time: 2.203495502471924
[1, 16109] loss_train: 0.009349, loss_test: 0.005616
time: 0.24405431747436523
time: 2.2034928798675537
[1, 16110] loss_train: 0.002830, loss_test: 0.005610
time: 0.258056640625
time: 2.2897400856018066
[1, 16111] loss_train: 0.010737, loss_test: 0.005598
time: 0.24605441093444824
time: 2.2195520401000977
[1, 16112] loss_train: 0.009329, loss_test: 0.005594
time: 0.24807286262512207
time: 2.1994924545288086
[1, 16113] loss_train: 0.002963, loss_test: 0.005597
time: 0.24505400657653809
time: 2.242004871368408
[1, 16114] loss_train: 0.002325, loss_test: 0.005605
time: 0.2520561218261719
time: 2.23249888420105
[1, 16115] loss_train: 0.005137, loss_test: 0.005612
time: 0.24405455589294434
time: 2.2465016841888428
[1, 16116] loss_train: 0.003860, loss_test: 0.005609
time: 0.2470541000366211
time: 2.244502544403076
[1, 16117] loss_train: 0.001701, loss_test: 0.005598
time: 0.24605679512023926
time: 2.2335150241851807
[1, 16118] loss_train: 0.006107, loss_test: 0.005588
time: 0.2470552921295166
time: 2.2325022220611572
[1, 16119] loss_train: 0.004841, loss_test: 0.005580
time: 0.24405360221862793
time: 2.2345001697540283
[1, 16120] loss_train: 0.004169, loss_test: 0.005576
time: 0.2600715160369873
time: 2.2905125617980957
[1, 16121] loss_train: 0.003737, loss_test: 0.005577
time: 0.24605488777160645
time: 2.2054927349090576
[1, 16122] loss_train: 0.001368, loss_test: 0.005585
time: 0.24605464935302734
time: 2.2244977951049805
[1, 16123] loss_train: 0.002954, loss_test: 0.005598
time: 0.24606823921203613
time: 2.232499361038208
[1, 16124] loss_train: 0.012461, loss_test: 0.005599
time: 0.24255824089050293
time: 2.230501890182495
[1, 16125] loss_train: 0.008611, loss_test: 0.005594
time: 0.2470550537109375
time: 2.1970059871673584
[1, 16126] loss_train: 0.011095, loss_test: 0.005584
time: 0.24606752395629883
time: 2.229515790939331
[1, 16127] loss_train: 0.006759, loss_test: 0.005576
time: 0.24405360221862793
time: 2.230499267578125
[1, 16128] loss_train: 0.006108, loss_test: 0.005571
time: 0.24505376815795898
time: 2.2225096225738525
[1, 16129] loss_train: 0.003309, loss_test: 0.005568
time: 0.2450551986694336
time: 2.2204957008361816
[1, 16130] loss_train: 0.014322, loss_test: 0.005567
time: 0.25705814361572266
time: 2.2705070972442627
[1, 16131] loss_train: 0.005380, loss_test: 0.005568
time: 0.25005483627319336
time: 2.2274985313415527
[1, 16132] loss_train: 0.006073, loss_test: 0.005571
time: 0.24405503273010254
time: 2.2375011444091797
[1, 16133] loss_train: 0.001601, loss_test: 0.005573
time: 0.2450542449951172
time: 2.2124950885772705
[1, 16134] loss_train: 0.006571, loss_test: 0.005573
time: 0.24605441093444824
time: 2.2084944248199463
[1, 16135] loss_train: 0.003259, loss_test: 0.005572
time: 0.24605393409729004
time: 2.229515314102173
[1, 16136] loss_train: 0.004049, loss_test: 0.005570
time: 0.24505400657653809
time: 2.224454164505005
[1, 16137] loss_train: 0.008130, loss_test: 0.005571
time: 0.2510554790496826
time: 2.21049427986145
[1, 16138] loss_train: 0.008300, loss_test: 0.005573
time: 0.24605464935302734
time: 2.2244975566864014
[1, 16139] loss_train: 0.003230, loss_test: 0.005577
time: 0.2470545768737793
time: 2.2134952545166016
[1, 16140] loss_train: 0.003783, loss_test: 0.005583
time: 0.2560572624206543
time: 2.267009973526001
[1, 16141] loss_train: 0.009578, loss_test: 0.005583
time: 0.24706721305847168
time: 2.2254977226257324
[1, 16142] loss_train: 0.009701, loss_test: 0.005583
time: 0.24805521965026855
time: 2.244502067565918
[1, 16143] loss_train: 0.000686, loss_test: 0.005589
time: 0.24808096885681152
time: 2.2335002422332764
[1, 16144] loss_train: 0.008266, loss_test: 0.005600
time: 0.24505400657653809
time: 2.2455174922943115
[1, 16145] loss_train: 0.002508, loss_test: 0.005615
time: 0.2450547218322754
time: 2.249871015548706
[1, 16146] loss_train: 0.002987, loss_test: 0.005631
time: 0.2450547218322754
time: 2.2290167808532715
[1, 16147] loss_train: 0.008250, loss_test: 0.005638
time: 0.24405336380004883
time: 2.245210647583008
[1, 16148] loss_train: 0.004855, loss_test: 0.005633
time: 0.2470545768737793
time: 2.197507381439209
[1, 16149] loss_train: 0.001765, loss_test: 0.005629
time: 0.24505400657653809
time: 2.23551607131958
[1, 16150] loss_train: 0.007938, loss_test: 0.005620
time: 0.2560567855834961
time: 2.260514259338379
[1, 16151] loss_train: 0.005820, loss_test: 0.005604
time: 0.2450542449951172
time: 2.2124950885772705
[1, 16152] loss_train: 0.005967, loss_test: 0.005591
time: 0.2460613250732422
time: 2.2495033740997314
[1, 16153] loss_train: 0.009671, loss_test: 0.005575
time: 0.2450549602508545
time: 2.2134969234466553
[1, 16154] loss_train: 0.008805, loss_test: 0.005565
time: 0.24305415153503418
time: 2.202511787414551
[1, 16155] loss_train: 0.001202, loss_test: 0.005562
time: 0.24305224418640137
time: 2.2264976501464844
[1, 16156] loss_train: 0.004456, loss_test: 0.005561
time: 0.2450549602508545
time: 2.226012945175171
[1, 16157] loss_train: 0.000751, loss_test: 0.005559
time: 0.24606728553771973
time: 2.221496820449829
[1, 16158] loss_train: 0.004076, loss_test: 0.005560
time: 0.2450542449951172
time: 2.203495502471924
[1, 16159] loss_train: 0.009929, loss_test: 0.005563
time: 0.2470543384552002
time: 2.205493927001953
[1, 16160] loss_train: 0.007555, loss_test: 0.005566
time: 0.25806307792663574
time: 2.245016574859619
[1, 16161] loss_train: 0.007076, loss_test: 0.005568
time: 0.24505400657653809
time: 2.205493927001953
[1, 16162] loss_train: 0.008442, loss_test: 0.005568
time: 0.2450544834136963
time: 2.220506191253662
[1, 16163] loss_train: 0.006984, loss_test: 0.005565
time: 0.24506592750549316
time: 2.221499443054199
[1, 16164] loss_train: 0.007755, loss_test: 0.005565
time: 0.24305415153503418
time: 2.259504795074463
[1, 16165] loss_train: 0.003665, loss_test: 0.005566
time: 0.24405479431152344
time: 2.2294986248016357
[1, 16166] loss_train: 0.013394, loss_test: 0.005565
time: 0.2450544834136963
time: 2.2495033740997314
[1, 16167] loss_train: 0.009871, loss_test: 0.005567
time: 0.24305438995361328
time: 2.249021530151367
[1, 16168] loss_train: 0.002841, loss_test: 0.005567
time: 0.2450542449951172
time: 2.2264978885650635
[1, 16169] loss_train: 0.007395, loss_test: 0.005567
time: 0.24605464935302734
time: 2.2124948501586914
[1, 16170] loss_train: 0.008601, loss_test: 0.005569
time: 0.2560570240020752
time: 2.254504442214966
[1, 16171] loss_train: 0.009580, loss_test: 0.005574
time: 0.24405407905578613
time: 2.24550199508667
[1, 16172] loss_train: 0.007665, loss_test: 0.005579
time: 0.24505400657653809
time: 2.2485036849975586
[1, 16173] loss_train: 0.003202, loss_test: 0.005583
time: 0.24405455589294434
time: 2.238499879837036
[1, 16174] loss_train: 0.008606, loss_test: 0.005588
time: 0.24405407905578613
time: 2.253007173538208
[1, 16175] loss_train: 0.005654, loss_test: 0.005587
time: 0.24405360221862793
time: 2.2154958248138428
[1, 16176] loss_train: 0.008042, loss_test: 0.005587
time: 0.24305367469787598
time: 2.2275068759918213
[1, 16177] loss_train: 0.011447, loss_test: 0.005585
time: 0.2420666217803955
time: 2.247502326965332
[1, 16178] loss_train: 0.005393, loss_test: 0.005583
time: 0.24405455589294434
time: 2.231498956680298
[1, 16179] loss_train: 0.003709, loss_test: 0.005580
time: 0.2470550537109375
time: 2.23249888420105
[1, 16180] loss_train: 0.002641, loss_test: 0.005579
time: 0.2590677738189697
time: 2.2935128211975098
[1, 16181] loss_train: 0.007493, loss_test: 0.005584
time: 0.24305438995361328
time: 2.2274973392486572
[1, 16182] loss_train: 0.008378, loss_test: 0.005591
time: 0.2470548152923584
time: 2.2254977226257324
[1, 16183] loss_train: 0.013831, loss_test: 0.005591
time: 0.24405407905578613
time: 2.1884894371032715
[1, 16184] loss_train: 0.004148, loss_test: 0.005591
time: 0.24605441093444824
time: 2.2495038509368896
[1, 16185] loss_train: 0.012789, loss_test: 0.005590
time: 0.25006890296936035
time: 2.2164952754974365
[1, 16186] loss_train: 0.003220, loss_test: 0.005589
time: 0.2450542449951172
time: 2.243502140045166
[1, 16187] loss_train: 0.003716, loss_test: 0.005587
time: 0.24805450439453125
time: 2.228498935699463
[1, 16188] loss_train: 0.005887, loss_test: 0.005585
time: 0.24405479431152344
time: 2.2360076904296875
[1, 16189] loss_train: 0.011017, loss_test: 0.005582
time: 0.24805545806884766
time: 2.248511791229248
[1, 16190] loss_train: 0.004368, loss_test: 0.005578
time: 0.2600581645965576
time: 2.2875113487243652
[1, 16191] loss_train: 0.000842, loss_test: 0.005575
time: 0.24805450439453125
time: 2.235502243041992
[1, 16192] loss_train: 0.008887, loss_test: 0.005574
time: 0.2490549087524414
time: 2.2505037784576416
[1, 16193] loss_train: 0.013018, loss_test: 0.005574
time: 0.24805545806884766
time: 2.2068870067596436
[1, 16194] loss_train: 0.003616, loss_test: 0.005574
time: 0.24365997314453125
time: 2.2234976291656494
[1, 16195] loss_train: 0.003604, loss_test: 0.005572
time: 0.2450544834136963
time: 2.2134952545166016
[1, 16196] loss_train: 0.010095, loss_test: 0.005574
time: 0.24506711959838867
time: 2.25250506401062
[1, 16197] loss_train: 0.012085, loss_test: 0.005582
time: 0.24305272102355957
time: 2.2114968299865723
[1, 16198] loss_train: 0.006403, loss_test: 0.005585
time: 0.24605441093444824
time: 2.2345163822174072
[1, 16199] loss_train: 0.007982, loss_test: 0.005583
time: 0.24608087539672852
time: 2.2245023250579834
[1, 16200] loss_train: 0.008717, loss_test: 0.005584
time: 0.2560563087463379
time: 2.2655067443847656
[1, 16201] loss_train: 0.003280, loss_test: 0.005587
time: 0.24405455589294434
time: 2.2014944553375244
[1, 16202] loss_train: 0.000570, loss_test: 0.005594
time: 0.24205398559570312
time: 2.249506711959839
[1, 16203] loss_train: 0.005123, loss_test: 0.005590
time: 0.24405360221862793
time: 2.200495481491089
[1, 16204] loss_train: 0.009159, loss_test: 0.005583
time: 0.24205327033996582
time: 2.219496726989746
[1, 16205] loss_train: 0.006344, loss_test: 0.005577
time: 0.2450547218322754
time: 2.2455222606658936
[1, 16206] loss_train: 0.007515, loss_test: 0.005572
time: 0.2470545768737793
time: 2.2254977226257324
[1, 16207] loss_train: 0.012350, loss_test: 0.005564
time: 0.24605512619018555
time: 2.191502571105957
[1, 16208] loss_train: 0.004525, loss_test: 0.005558
time: 0.24805450439453125
time: 2.2214972972869873
[1, 16209] loss_train: 0.012108, loss_test: 0.005556
time: 0.25005531311035156
time: 2.220018148422241
[1, 16210] loss_train: 0.020734, loss_test: 0.005552
time: 0.25905704498291016
time: 2.2455036640167236
[1, 16211] loss_train: 0.008976, loss_test: 0.005550
time: 0.24505281448364258
time: 2.2295143604278564
[1, 16212] loss_train: 0.005078, loss_test: 0.005550
time: 0.25005507469177246
time: 2.2244982719421387
[1, 16213] loss_train: 0.007142, loss_test: 0.005552
time: 0.2450544834136963
time: 2.2435014247894287
[1, 16214] loss_train: 0.006235, loss_test: 0.005554
time: 0.2470552921295166
time: 2.2595043182373047
[1, 16215] loss_train: 0.005466, loss_test: 0.005556
time: 0.24305415153503418
time: 2.2405009269714355
[1, 16216] loss_train: 0.006090, loss_test: 0.005559
time: 0.2470548152923584
time: 2.2385005950927734
[1, 16217] loss_train: 0.006759, loss_test: 0.005557
time: 0.24405550956726074
time: 2.247437000274658
[1, 16218] loss_train: 0.004625, loss_test: 0.005559
time: 0.24430561065673828
time: 2.2024917602539062
[1, 16219] loss_train: 0.006056, loss_test: 0.005560
time: 0.2450547218322754
time: 2.1899945735931396
[1, 16220] loss_train: 0.004529, loss_test: 0.005563
time: 0.2600579261779785
time: 2.256504535675049
[1, 16221] loss_train: 0.005198, loss_test: 0.005566
time: 0.24505400657653809
time: 2.2154958248138428
[1, 16222] loss_train: 0.009975, loss_test: 0.005570
time: 0.24505400657653809
time: 2.239504098892212
[1, 16223] loss_train: 0.005024, loss_test: 0.005575
time: 0.24305438995361328
time: 2.2134950160980225
[1, 16224] loss_train: 0.008663, loss_test: 0.005577
time: 0.24305438995361328
time: 2.2335011959075928
[1, 16225] loss_train: 0.007411, loss_test: 0.005576
time: 0.24509477615356445
time: 2.239549160003662
[1, 16226] loss_train: 0.005675, loss_test: 0.005577
time: 0.24605393409729004
time: 2.231501817703247
[1, 16227] loss_train: 0.010247, loss_test: 0.005577
time: 0.24405527114868164
time: 2.228498697280884
[1, 16228] loss_train: 0.006945, loss_test: 0.005580
time: 0.2450542449951172
time: 2.2285091876983643
[1, 16229] loss_train: 0.006623, loss_test: 0.005588
time: 0.24405360221862793
time: 2.2275454998016357
[1, 16230] loss_train: 0.012916, loss_test: 0.005606
time: 0.2580709457397461
time: 2.2595057487487793
[1, 16231] loss_train: 0.008384, loss_test: 0.005621
time: 0.24605560302734375
time: 2.21929931640625
[1, 16232] loss_train: 0.007642, loss_test: 0.005637
time: 0.2450547218322754
time: 2.1985056400299072
[1, 16233] loss_train: 0.005472, loss_test: 0.005653
time: 0.25005459785461426
time: 2.17399001121521
[1, 16234] loss_train: 0.007241, loss_test: 0.005659
time: 0.24505400657653809
time: 2.2300963401794434
[1, 16235] loss_train: 0.009961, loss_test: 0.005658
time: 0.24305415153503418
time: 2.2575156688690186
[1, 16236] loss_train: 0.003158, loss_test: 0.005645
time: 0.2450563907623291
time: 2.2255001068115234
[1, 16237] loss_train: 0.012291, loss_test: 0.005632
time: 0.2450542449951172
time: 2.219496726989746
[1, 16238] loss_train: 0.007019, loss_test: 0.005617
time: 0.24305462837219238
time: 2.239502191543579
[1, 16239] loss_train: 0.007289, loss_test: 0.005604
time: 0.24306678771972656
time: 2.2244997024536133
[1, 16240] loss_train: 0.012528, loss_test: 0.005598
time: 0.2580578327178955
time: 2.2675065994262695
[1, 16241] loss_train: 0.006159, loss_test: 0.005594
time: 0.24405407905578613
time: 2.2765088081359863
[1, 16242] loss_train: 0.004633, loss_test: 0.005590
time: 0.24305438995361328
time: 2.2019951343536377
[1, 16243] loss_train: 0.004975, loss_test: 0.005591
time: 0.2450542449951172
time: 2.231499671936035
[1, 16244] loss_train: 0.006620, loss_test: 0.005595
time: 0.24405455589294434
time: 2.236515760421753
[1, 16245] loss_train: 0.012687, loss_test: 0.005593
time: 0.24405384063720703
time: 2.2154958248138428
[1, 16246] loss_train: 0.010009, loss_test: 0.005592
time: 0.24405384063720703
time: 2.1875038146972656
[1, 16247] loss_train: 0.005884, loss_test: 0.005593
time: 0.2450847625732422
time: 2.2044947147369385
[1, 16248] loss_train: 0.004589, loss_test: 0.005596
time: 0.24405479431152344
time: 2.2264976501464844
[1, 16249] loss_train: 0.007184, loss_test: 0.005595
time: 0.2450547218322754
time: 2.2495036125183105
[1, 16250] loss_train: 0.013624, loss_test: 0.005596
time: 0.26105785369873047
time: 2.230499029159546
[1, 16251] loss_train: 0.013393, loss_test: 0.005599
time: 0.24405479431152344
time: 2.2254974842071533
[1, 16252] loss_train: 0.005886, loss_test: 0.005600
time: 0.2470550537109375
time: 2.236509323120117
[1, 16253] loss_train: 0.013745, loss_test: 0.005605
time: 0.2470555305480957
time: 2.2405006885528564
[1, 16254] loss_train: 0.007395, loss_test: 0.005609
time: 0.24805545806884766
time: 2.2245137691497803
[1, 16255] loss_train: 0.010755, loss_test: 0.005620
time: 0.24605417251586914
time: 2.2200000286102295
[1, 16256] loss_train: 0.001602, loss_test: 0.005615
time: 0.2450542449951172
time: 2.201364040374756
[1, 16257] loss_train: 0.002185, loss_test: 0.005597
time: 0.2450547218322754
time: 2.219001054763794
[1, 16258] loss_train: 0.005492, loss_test: 0.005585
time: 0.2450544834136963
time: 2.233499526977539
[1, 16259] loss_train: 0.008490, loss_test: 0.005580
time: 0.24505400657653809
time: 2.255521297454834
[1, 16260] loss_train: 0.004049, loss_test: 0.005577
time: 0.25907135009765625
time: 2.2385005950927734
[1, 16261] loss_train: 0.008022, loss_test: 0.005577
time: 0.24405384063720703
time: 2.219496011734009
[1, 16262] loss_train: 0.007923, loss_test: 0.005576
time: 0.24405360221862793
time: 2.2164969444274902
[1, 16263] loss_train: 0.004988, loss_test: 0.005576
time: 0.24305343627929688
time: 2.236499786376953
[1, 16264] loss_train: 0.007769, loss_test: 0.005575
time: 0.24307870864868164
time: 2.23051118850708
[1, 16265] loss_train: 0.011545, loss_test: 0.005566
time: 0.2450549602508545
time: 2.2284979820251465
[1, 16266] loss_train: 0.012320, loss_test: 0.005560
time: 0.24505400657653809
time: 2.215496301651001
[1, 16267] loss_train: 0.003506, loss_test: 0.005556
time: 0.24405312538146973
time: 2.1964938640594482
[1, 16268] loss_train: 0.004860, loss_test: 0.005555
time: 0.24405407905578613
time: 2.2365007400512695
[1, 16269] loss_train: 0.012553, loss_test: 0.005555
time: 0.24806785583496094
time: 2.204511880874634
[1, 16270] loss_train: 0.008918, loss_test: 0.005556
time: 0.2630589008331299
time: 2.2645061016082764
[1, 16271] loss_train: 0.006872, loss_test: 0.005558
time: 0.24805617332458496
time: 2.212515115737915
[1, 16272] loss_train: 0.004784, loss_test: 0.005556
time: 0.24405431747436523
time: 2.220496416091919
[1, 16273] loss_train: 0.001922, loss_test: 0.005555
time: 0.2470550537109375
time: 2.2550172805786133
[1, 16274] loss_train: 0.004706, loss_test: 0.005554
time: 0.24405384063720703
time: 2.2635068893432617
[1, 16275] loss_train: 0.011630, loss_test: 0.005555
time: 0.24505376815795898
time: 2.2665066719055176
[1, 16276] loss_train: 0.004749, loss_test: 0.005554
time: 0.24405431747436523
time: 2.216495990753174
[1, 16277] loss_train: 0.003499, loss_test: 0.005554
time: 0.24805521965026855
time: 2.222496747970581
[1, 16278] loss_train: 0.001366, loss_test: 0.005556
time: 0.24405431747436523
time: 2.2274975776672363
[1, 16279] loss_train: 0.001750, loss_test: 0.005560
time: 0.2450547218322754
time: 2.2530062198638916
[1, 16280] loss_train: 0.005886, loss_test: 0.005566
time: 0.2580578327178955
time: 2.2505035400390625
[1, 16281] loss_train: 0.009469, loss_test: 0.005567
time: 0.2450544834136963
time: 2.2134950160980225
[1, 16282] loss_train: 0.007830, loss_test: 0.005567
time: 0.24405384063720703
time: 2.2134952545166016
[1, 16283] loss_train: 0.001949, loss_test: 0.005566
time: 0.24605512619018555
time: 2.2004919052124023
[1, 16284] loss_train: 0.003080, loss_test: 0.005566
time: 0.2470552921295166
time: 2.214498996734619
[1, 16285] loss_train: 0.009295, loss_test: 0.005564
time: 0.24405384063720703
time: 2.1974921226501465
[1, 16286] loss_train: 0.005690, loss_test: 0.005563
time: 0.24405336380004883
time: 2.217496395111084
[1, 16287] loss_train: 0.006288, loss_test: 0.005565
time: 0.2450544834136963
time: 2.2154955863952637
[1, 16288] loss_train: 0.002474, loss_test: 0.005568
time: 0.24605417251586914
time: 2.2255477905273438
[1, 16289] loss_train: 0.009622, loss_test: 0.005577
time: 0.24605441093444824
time: 2.2124977111816406
[1, 16290] loss_train: 0.004940, loss_test: 0.005584
time: 0.2620577812194824
time: 2.2995142936706543
[1, 16291] loss_train: 0.010373, loss_test: 0.005588
time: 0.24605488777160645
time: 2.229004144668579
[1, 16292] loss_train: 0.003453, loss_test: 0.005593
time: 0.2470541000366211
time: 2.2385008335113525
[1, 16293] loss_train: 0.007462, loss_test: 0.005598
time: 0.24506735801696777
time: 2.231501817703247
[1, 16294] loss_train: 0.000964, loss_test: 0.005602
time: 0.25005483627319336
time: 2.1954915523529053
[1, 16295] loss_train: 0.009404, loss_test: 0.005601
time: 0.2470543384552002
time: 2.239516496658325
[1, 16296] loss_train: 0.007183, loss_test: 0.005595
time: 0.24605441093444824
time: 2.240501642227173
[1, 16297] loss_train: 0.018881, loss_test: 0.005582
time: 0.24605512619018555
time: 2.222498893737793
[1, 16298] loss_train: 0.005348, loss_test: 0.005576
time: 0.24305367469787598
time: 2.230499029159546
[1, 16299] loss_train: 0.003566, loss_test: 0.005577
time: 0.2460322380065918
time: 2.257505178451538
[1, 16300] loss_train: 0.018238, loss_test: 0.005585
time: 0.25505614280700684
time: 2.256507396697998
[1, 16301] loss_train: 0.002471, loss_test: 0.005594
time: 0.2460801601409912
time: 2.2274982929229736
[1, 16302] loss_train: 0.014949, loss_test: 0.005623
time: 0.24405431747436523
time: 2.2314987182617188
[1, 16303] loss_train: 0.003910, loss_test: 0.005649
time: 0.24406695365905762
time: 2.2515034675598145
[1, 16304] loss_train: 0.015042, loss_test: 0.005656
time: 0.24605393409729004
time: 2.2074942588806152
[1, 16305] loss_train: 0.005485, loss_test: 0.005646
time: 0.24605393409729004
time: 2.2395012378692627
[1, 16306] loss_train: 0.003243, loss_test: 0.005618
time: 0.24405384063720703
time: 2.1904962062835693
[1, 16307] loss_train: 0.009462, loss_test: 0.005596
time: 0.2450551986694336
time: 2.2214975357055664
[1, 16308] loss_train: 0.004360, loss_test: 0.005579
time: 0.24605441093444824
time: 2.236499071121216
[1, 16309] loss_train: 0.002425, loss_test: 0.005568
time: 0.24405455589294434
time: 2.2405014038085938
[1, 16310] loss_train: 0.002025, loss_test: 0.005566
time: 0.2580704689025879
time: 2.245664358139038
[1, 16311] loss_train: 0.008325, loss_test: 0.005567
time: 0.2510561943054199
time: 2.277514934539795
[1, 16312] loss_train: 0.001647, loss_test: 0.005571
time: 0.24305438995361328
time: 2.2535037994384766
[1, 16313] loss_train: 0.022661, loss_test: 0.005577
time: 0.24405384063720703
time: 2.2475059032440186
[1, 16314] loss_train: 0.002586, loss_test: 0.005588
time: 0.24805545806884766
time: 2.223496675491333
[1, 16315] loss_train: 0.005085, loss_test: 0.005599
time: 0.24306654930114746
time: 2.1964917182922363
[1, 16316] loss_train: 0.004699, loss_test: 0.005612
time: 0.2450547218322754
time: 2.2274978160858154
[1, 16317] loss_train: 0.001990, loss_test: 0.005628
time: 0.24605441093444824
time: 2.228498935699463
[1, 16318] loss_train: 0.001641, loss_test: 0.005647
time: 0.25005531311035156
time: 2.2275009155273438
[1, 16319] loss_train: 0.003837, loss_test: 0.005664
time: 0.2470545768737793
time: 2.231499433517456
[1, 16320] loss_train: 0.006555, loss_test: 0.005662
time: 0.2560570240020752
time: 2.243506669998169
[1, 16321] loss_train: 0.004605, loss_test: 0.005653
time: 0.24506616592407227
time: 2.2154979705810547
[1, 16322] loss_train: 0.009341, loss_test: 0.005647
time: 0.24605488777160645
time: 2.2626888751983643
[1, 16323] loss_train: 0.002930, loss_test: 0.005640
time: 0.24305343627929688
time: 2.2264981269836426
[1, 16324] loss_train: 0.000761, loss_test: 0.005635
time: 0.2470543384552002
time: 2.2385010719299316
[1, 16325] loss_train: 0.005372, loss_test: 0.005626
time: 0.24405288696289062
time: 2.2405426502227783
[1, 16326] loss_train: 0.007616, loss_test: 0.005606
time: 0.2450544834136963
time: 2.2460098266601562
[1, 16327] loss_train: 0.002938, loss_test: 0.005593
time: 0.2450542449951172
time: 2.2234973907470703
[1, 16328] loss_train: 0.009246, loss_test: 0.005585
time: 0.24405360221862793
time: 2.2480053901672363
[1, 16329] loss_train: 0.008506, loss_test: 0.005576
time: 0.24405479431152344
time: 2.2575223445892334
[1, 16330] loss_train: 0.003776, loss_test: 0.005572
time: 0.2560575008392334
time: 2.277510404586792
[1, 16331] loss_train: 0.008613, loss_test: 0.005571
time: 0.24405527114868164
time: 2.221125841140747
[1, 16332] loss_train: 0.008168, loss_test: 0.005573
time: 0.24405336380004883
time: 2.236515522003174
[1, 16333] loss_train: 0.010945, loss_test: 0.005571
time: 0.24403905868530273
time: 2.2505040168762207
[1, 16334] loss_train: 0.001374, loss_test: 0.005571
time: 0.24405360221862793
time: 2.2375009059906006
[1, 16335] loss_train: 0.000715, loss_test: 0.005573
time: 0.24605464935302734
time: 2.2540066242218018
[1, 16336] loss_train: 0.005501, loss_test: 0.005571
time: 0.24306774139404297
time: 2.232499599456787
[1, 16337] loss_train: 0.003021, loss_test: 0.005570
time: 0.2490544319152832
time: 2.2275006771087646
[1, 16338] loss_train: 0.005893, loss_test: 0.005569
time: 0.2450549602508545
time: 2.2086048126220703
[1, 16339] loss_train: 0.004301, loss_test: 0.005567
time: 0.2450542449951172
time: 2.2495033740997314
[1, 16340] loss_train: 0.003715, loss_test: 0.005565
time: 0.25707387924194336
time: 2.238004446029663
[1, 16341] loss_train: 0.007356, loss_test: 0.005565
time: 0.2440803050994873
time: 2.2435038089752197
[1, 16342] loss_train: 0.004376, loss_test: 0.005567
time: 0.24405384063720703
time: 2.21520733833313
[1, 16343] loss_train: 0.008487, loss_test: 0.005567
time: 0.2450547218322754
time: 2.2535030841827393
[1, 16344] loss_train: 0.001766, loss_test: 0.005570
time: 0.24605512619018555
time: 2.217496156692505
[1, 16345] loss_train: 0.012803, loss_test: 0.005572
time: 0.2450542449951172
time: 2.218496322631836
[1, 16346] loss_train: 0.004394, loss_test: 0.005574
time: 0.24405360221862793
time: 2.2395172119140625
[1, 16347] loss_train: 0.006720, loss_test: 0.005573
time: 0.24405455589294434
time: 2.265181064605713
[1, 16348] loss_train: 0.005491, loss_test: 0.005573
time: 0.24405407905578613
time: 2.234499931335449
[1, 16349] loss_train: 0.013776, loss_test: 0.005570
time: 0.2450554370880127
time: 2.2445008754730225
[1, 16350] loss_train: 0.008547, loss_test: 0.005570
time: 0.2600579261779785
time: 2.2645061016082764
[1, 16351] loss_train: 0.005034, loss_test: 0.005574
time: 0.24605488777160645
time: 2.1949939727783203
[1, 16352] loss_train: 0.005246, loss_test: 0.005576
time: 0.2490546703338623
time: 2.212677240371704
[1, 16353] loss_train: 0.008711, loss_test: 0.005579
time: 0.24405407905578613
time: 2.2385003566741943
[1, 16354] loss_train: 0.004581, loss_test: 0.005579
time: 0.25305652618408203
time: 2.203493356704712
[1, 16355] loss_train: 0.004129, loss_test: 0.005582
time: 0.2450549602508545
time: 2.228508234024048
[1, 16356] loss_train: 0.006375, loss_test: 0.005584
time: 0.2450547218322754
time: 2.23249888420105
[1, 16357] loss_train: 0.003650, loss_test: 0.005581
time: 0.24305415153503418
time: 2.2385003566741943
[1, 16358] loss_train: 0.006082, loss_test: 0.005577
time: 0.24605512619018555
time: 2.2315165996551514
[1, 16359] loss_train: 0.002513, loss_test: 0.005570
time: 0.2450542449951172
time: 2.2335002422332764
[1, 16360] loss_train: 0.005697, loss_test: 0.005561
time: 0.25505709648132324
time: 2.2675070762634277
[1, 16361] loss_train: 0.006878, loss_test: 0.005553
time: 0.24405527114868164
time: 2.2345142364501953
[1, 16362] loss_train: 0.005961, loss_test: 0.005548
time: 0.24405407905578613
time: 2.219496488571167
[1, 16363] loss_train: 0.008712, loss_test: 0.005545
time: 0.2450549602508545
time: 2.2667834758758545
[1, 16364] loss_train: 0.005623, loss_test: 0.005543
time: 0.24806761741638184
time: 2.2024946212768555
[1, 16365] loss_train: 0.005663, loss_test: 0.005542
time: 0.24305415153503418
time: 2.207493543624878
[1, 16366] loss_train: 0.008183, loss_test: 0.005543
time: 0.24405384063720703
time: 2.190779685974121
[1, 16367] loss_train: 0.001677, loss_test: 0.005544
time: 0.24405479431152344
time: 2.201491594314575
[1, 16368] loss_train: 0.007832, loss_test: 0.005547
time: 0.24605441093444824
time: 2.2254984378814697
[1, 16369] loss_train: 0.005186, loss_test: 0.005551
time: 0.2490546703338623
time: 2.2236130237579346
[1, 16370] loss_train: 0.002863, loss_test: 0.005552
time: 0.2579305171966553
time: 2.2649457454681396
[1, 16371] loss_train: 0.006082, loss_test: 0.005553
time: 0.2540562152862549
time: 2.239501476287842
[1, 16372] loss_train: 0.002835, loss_test: 0.005555
time: 0.2450542449951172
time: 2.218496084213257
[1, 16373] loss_train: 0.007936, loss_test: 0.005561
time: 0.2470552921295166
time: 2.235499620437622
[1, 16374] loss_train: 0.005405, loss_test: 0.005567
time: 0.24306511878967285
time: 2.236952066421509
[1, 16375] loss_train: 0.007810, loss_test: 0.005572
time: 0.24605512619018555
time: 2.210493564605713
[1, 16376] loss_train: 0.004295, loss_test: 0.005578
time: 0.24306964874267578
time: 2.2135026454925537
[1, 16377] loss_train: 0.013052, loss_test: 0.005573
time: 0.24405431747436523
time: 2.232499122619629
[1, 16378] loss_train: 0.003932, loss_test: 0.005569
time: 0.2450568675994873
time: 2.2225136756896973
[1, 16379] loss_train: 0.006055, loss_test: 0.005564
time: 0.24405384063720703
time: 2.2260682582855225
[1, 16380] loss_train: 0.006843, loss_test: 0.005561
time: 0.2560579776763916
time: 2.295513153076172
[1, 16381] loss_train: 0.001548, loss_test: 0.005559
time: 0.25005531311035156
time: 2.2475028038024902
[1, 16382] loss_train: 0.002715, loss_test: 0.005557
time: 0.2450542449951172
time: 2.244716167449951
[1, 16383] loss_train: 0.015111, loss_test: 0.005553
time: 0.2450547218322754
time: 2.2445015907287598
[1, 16384] loss_train: 0.001465, loss_test: 0.005550
time: 0.24405384063720703
time: 2.2425148487091064
[1, 16385] loss_train: 0.004286, loss_test: 0.005548
time: 0.24505352973937988
time: 2.2244982719421387
[1, 16386] loss_train: 0.004440, loss_test: 0.005548
time: 0.24505400657653809
time: 2.231499671936035
[1, 16387] loss_train: 0.006616, loss_test: 0.005551
time: 0.24405407905578613
time: 2.247502565383911
[1, 16388] loss_train: 0.008221, loss_test: 0.005551
time: 0.24405407905578613
time: 2.218475103378296
[1, 16389] loss_train: 0.011583, loss_test: 0.005549
time: 0.24406790733337402
time: 2.1934902667999268
[1, 16390] loss_train: 0.003125, loss_test: 0.005548
time: 0.25606465339660645
time: 2.239501476287842
[1, 16391] loss_train: 0.004511, loss_test: 0.005547
time: 0.24605894088745117
time: 2.2365005016326904
[1, 16392] loss_train: 0.001200, loss_test: 0.005548
time: 0.24606847763061523
time: 2.1954903602600098
[1, 16393] loss_train: 0.001734, loss_test: 0.005550
time: 0.24405455589294434
time: 2.237499952316284
[1, 16394] loss_train: 0.002898, loss_test: 0.005553
time: 0.24806427955627441
time: 2.2264978885650635
[1, 16395] loss_train: 0.001861, loss_test: 0.005558
time: 0.24505400657653809
time: 2.235499858856201
[1, 16396] loss_train: 0.002654, loss_test: 0.005565
time: 0.25006937980651855
time: 2.225534439086914
[1, 16397] loss_train: 0.012293, loss_test: 0.005569
time: 0.24701857566833496
time: 2.230536699295044
[1, 16398] loss_train: 0.006833, loss_test: 0.005573
time: 0.25005602836608887
time: 2.2134225368499756
[1, 16399] loss_train: 0.002005, loss_test: 0.005580
time: 0.24405622482299805
time: 2.2034926414489746
[1, 16400] loss_train: 0.001827, loss_test: 0.005588
time: 0.2540566921234131
time: 2.2164952754974365
[1, 16401] loss_train: 0.006777, loss_test: 0.005598
time: 0.24405407905578613
time: 2.2345023155212402
[1, 16402] loss_train: 0.004187, loss_test: 0.005607
time: 0.2450542449951172
time: 2.219496965408325
[1, 16403] loss_train: 0.001227, loss_test: 0.005618
time: 0.24507832527160645
time: 2.2274978160858154
[1, 16404] loss_train: 0.019444, loss_test: 0.005602
time: 0.24605441093444824
time: 2.230501890182495
[1, 16405] loss_train: 0.002099, loss_test: 0.005589
time: 0.2490546703338623
time: 2.233499765396118
[1, 16406] loss_train: 0.004632, loss_test: 0.005580
time: 0.24305462837219238
time: 2.2255125045776367
[1, 16407] loss_train: 0.002816, loss_test: 0.005575
time: 0.24405455589294434
time: 2.2415032386779785
[1, 16408] loss_train: 0.001972, loss_test: 0.005574
time: 0.24505615234375
time: 2.2455027103424072
[1, 16409] loss_train: 0.003156, loss_test: 0.005573
time: 0.24507999420166016
time: 2.237499713897705
[1, 16410] loss_train: 0.009377, loss_test: 0.005572
time: 0.2560572624206543
time: 2.286511182785034
[1, 16411] loss_train: 0.015164, loss_test: 0.005567
time: 0.25005507469177246
time: 2.2214996814727783
[1, 16412] loss_train: 0.004311, loss_test: 0.005564
time: 0.24405431747436523
time: 2.2214953899383545
[1, 16413] loss_train: 0.004374, loss_test: 0.005562
time: 0.24405455589294434
time: 2.20149302482605
[1, 16414] loss_train: 0.001894, loss_test: 0.005562
time: 0.24406671524047852
time: 2.2114953994750977
[1, 16415] loss_train: 0.005603, loss_test: 0.005563
time: 0.25005531311035156
time: 2.215010404586792
[1, 16416] loss_train: 0.006141, loss_test: 0.005566
time: 0.24805474281311035
time: 2.222515106201172
[1, 16417] loss_train: 0.004822, loss_test: 0.005569
time: 0.2490553855895996
time: 2.219505548477173
[1, 16418] loss_train: 0.002699, loss_test: 0.005573
time: 0.24505400657653809
time: 2.2234981060028076
[1, 16419] loss_train: 0.001991, loss_test: 0.005577
time: 0.24605464935302734
time: 2.235499382019043
[1, 16420] loss_train: 0.008777, loss_test: 0.005571
time: 0.2600576877593994
time: 2.2635064125061035
[1, 16421] loss_train: 0.006720, loss_test: 0.005565
time: 0.2450542449951172
time: 2.2405154705047607
[1, 16422] loss_train: 0.003060, loss_test: 0.005567
time: 0.25005578994750977
time: 2.235499620437622
[1, 16423] loss_train: 0.008622, loss_test: 0.005568
time: 0.2450544834136963
time: 2.241502523422241
[1, 16424] loss_train: 0.001553, loss_test: 0.005574
time: 0.24505400657653809
time: 2.2495038509368896
[1, 16425] loss_train: 0.013707, loss_test: 0.005578
time: 0.24205303192138672
time: 2.1994922161102295
[1, 16426] loss_train: 0.004999, loss_test: 0.005585
time: 0.24405455589294434
time: 2.2315356731414795
[1, 16427] loss_train: 0.005369, loss_test: 0.005594
time: 0.24406838417053223
time: 2.2385005950927734
[1, 16428] loss_train: 0.004187, loss_test: 0.005598
time: 0.24305343627929688
time: 2.225499153137207
[1, 16429] loss_train: 0.002211, loss_test: 0.005583
time: 0.24605488777160645
time: 2.2245001792907715
[1, 16430] loss_train: 0.010804, loss_test: 0.005570
time: 0.2540569305419922
time: 2.2675392627716064
[1, 16431] loss_train: 0.001759, loss_test: 0.005561
time: 0.2450547218322754
time: 2.2505035400390625
[1, 16432] loss_train: 0.004388, loss_test: 0.005556
time: 0.2470548152923584
time: 2.2635080814361572
[1, 16433] loss_train: 0.001544, loss_test: 0.005552
time: 0.24405455589294434
time: 2.2495055198669434
[1, 16434] loss_train: 0.016904, loss_test: 0.005552
time: 0.24405407905578613
time: 2.2505745887756348
[1, 16435] loss_train: 0.007121, loss_test: 0.005550
time: 0.24305462837219238
time: 2.2044930458068848
[1, 16436] loss_train: 0.010882, loss_test: 0.005549
time: 0.24405431747436523
time: 2.2304980754852295
[1, 16437] loss_train: 0.001865, loss_test: 0.005548
time: 0.24405384063720703
time: 2.256505250930786
[1, 16438] loss_train: 0.005022, loss_test: 0.005546
time: 0.26605916023254395
time: 2.284510850906372
[1, 16439] loss_train: 0.003002, loss_test: 0.005543
time: 0.24506759643554688
time: 2.2044930458068848
[1, 16440] loss_train: 0.007464, loss_test: 0.005541
time: 0.2560572624206543
time: 2.271509885787964
[1, 16441] loss_train: 0.006884, loss_test: 0.005538
time: 0.2450542449951172
time: 2.262514352798462
[1, 16442] loss_train: 0.006964, loss_test: 0.005537
time: 0.24505376815795898
time: 2.231499671936035
[1, 16443] loss_train: 0.002424, loss_test: 0.005537
time: 0.24405384063720703
time: 2.2325000762939453
[1, 16444] loss_train: 0.010151, loss_test: 0.005538
time: 0.24405479431152344
time: 2.2705278396606445
[1, 16445] loss_train: 0.012073, loss_test: 0.005539
time: 0.2450542449951172
time: 2.247520685195923
[1, 16446] loss_train: 0.005415, loss_test: 0.005538
time: 0.2470543384552002
time: 2.217679500579834
[1, 16447] loss_train: 0.006939, loss_test: 0.005536
time: 0.24305462837219238
time: 2.220520496368408
[1, 16448] loss_train: 0.001922, loss_test: 0.005535
time: 0.24505400657653809
time: 2.1904900074005127
[1, 16449] loss_train: 0.006861, loss_test: 0.005535
time: 0.24605512619018555
time: 2.196491003036499
[1, 16450] loss_train: 0.008490, loss_test: 0.005535
time: 0.26205873489379883
time: 2.2515032291412354
[1, 16451] loss_train: 0.004232, loss_test: 0.005536
time: 0.24505376815795898
time: 2.2335000038146973
[1, 16452] loss_train: 0.002726, loss_test: 0.005536
time: 0.2510554790496826
time: 2.202495574951172
[1, 16453] loss_train: 0.004284, loss_test: 0.005536
time: 0.24305367469787598
time: 2.2395012378692627
[1, 16454] loss_train: 0.002908, loss_test: 0.005537
time: 0.24305367469787598
time: 2.228498697280884
[1, 16455] loss_train: 0.012893, loss_test: 0.005537
time: 0.2450551986694336
time: 2.2455899715423584
[1, 16456] loss_train: 0.005353, loss_test: 0.005538
time: 0.24405431747436523
time: 2.2314987182617188
[1, 16457] loss_train: 0.004770, loss_test: 0.005539
time: 0.24405479431152344
time: 2.23349928855896
[1, 16458] loss_train: 0.002759, loss_test: 0.005540
time: 0.24405360221862793
time: 2.255535125732422
[1, 16459] loss_train: 0.005147, loss_test: 0.005543
time: 0.2450542449951172
time: 2.220496654510498
[1, 16460] loss_train: 0.005024, loss_test: 0.005547
time: 0.2560570240020752
time: 2.267026662826538
[1, 16461] loss_train: 0.000618, loss_test: 0.005555
time: 0.2450551986694336
time: 2.242518186569214
[1, 16462] loss_train: 0.008511, loss_test: 0.005548
time: 0.24805569648742676
time: 2.225497245788574
[1, 16463] loss_train: 0.007161, loss_test: 0.005545
time: 0.24505400657653809
time: 2.1944940090179443
[1, 16464] loss_train: 0.002150, loss_test: 0.005547
time: 0.24605441093444824
time: 2.2405014038085938
[1, 16465] loss_train: 0.003534, loss_test: 0.005553
time: 0.24805498123168945
time: 2.2104945182800293
[1, 16466] loss_train: 0.005346, loss_test: 0.005562
time: 0.24405407905578613
time: 2.211453437805176
[1, 16467] loss_train: 0.006299, loss_test: 0.005568
time: 0.2450549602508545
time: 2.223496913909912
[1, 16468] loss_train: 0.004854, loss_test: 0.005577
time: 0.24405360221862793
time: 2.235499620437622
[1, 16469] loss_train: 0.015898, loss_test: 0.005579
time: 0.25005674362182617
time: 2.220496416091919
[1, 16470] loss_train: 0.002767, loss_test: 0.005574
time: 0.258056640625
time: 2.2615065574645996
[1, 16471] loss_train: 0.001569, loss_test: 0.005569
time: 0.24805450439453125
time: 2.227499008178711
[1, 16472] loss_train: 0.010249, loss_test: 0.005564
time: 0.24405384063720703
time: 2.229001522064209
[1, 16473] loss_train: 0.006934, loss_test: 0.005558
time: 0.2490549087524414
time: 2.2274985313415527
[1, 16474] loss_train: 0.003668, loss_test: 0.005553
time: 0.2450544834136963
time: 2.210496664047241
[1, 16475] loss_train: 0.007436, loss_test: 0.005552
time: 0.24605441093444824
time: 2.2405014038085938
[1, 16476] loss_train: 0.004466, loss_test: 0.005552
time: 0.24805545806884766
time: 2.2415733337402344
[1, 16477] loss_train: 0.002156, loss_test: 0.005555
time: 0.24407029151916504
time: 2.250507354736328
[1, 16478] loss_train: 0.003530, loss_test: 0.005561
time: 0.24405455589294434
time: 2.245537757873535
[1, 16479] loss_train: 0.001616, loss_test: 0.005571
time: 0.2470545768737793
time: 2.2274985313415527
[1, 16480] loss_train: 0.002907, loss_test: 0.005585
time: 0.2600574493408203
time: 2.253173351287842
[1, 16481] loss_train: 0.004250, loss_test: 0.005603
time: 0.24905610084533691
time: 2.2375006675720215
[1, 16482] loss_train: 0.007068, loss_test: 0.005618
time: 0.24305415153503418
time: 2.2174794673919678
[1, 16483] loss_train: 0.007298, loss_test: 0.005621
time: 0.24605441093444824
time: 2.225497007369995
[1, 16484] loss_train: 0.007199, loss_test: 0.005615
time: 0.24405527114868164
time: 2.223497152328491
[1, 16485] loss_train: 0.006738, loss_test: 0.005605
time: 0.24305391311645508
time: 2.2104973793029785
[1, 16486] loss_train: 0.003902, loss_test: 0.005590
time: 0.24506688117980957
time: 2.218496561050415
[1, 16487] loss_train: 0.005052, loss_test: 0.005579
time: 0.24605512619018555
time: 2.195490837097168
[1, 16488] loss_train: 0.005538, loss_test: 0.005571
time: 0.24605417251586914
time: 2.2234976291656494
[1, 16489] loss_train: 0.000934, loss_test: 0.005568
time: 0.24406647682189941
time: 2.2355005741119385
[1, 16490] loss_train: 0.004203, loss_test: 0.005571
time: 0.2560558319091797
time: 2.2725088596343994
[1, 16491] loss_train: 0.006601, loss_test: 0.005575
time: 0.24405384063720703
time: 2.218496084213257
[1, 16492] loss_train: 0.008051, loss_test: 0.005578
time: 0.24605464935302734
time: 2.2465052604675293
[1, 16493] loss_train: 0.003613, loss_test: 0.005581
time: 0.24805498123168945
time: 2.2254979610443115
[1, 16494] loss_train: 0.009466, loss_test: 0.005580
time: 0.24805521965026855
time: 2.2254977226257324
[1, 16495] loss_train: 0.005105, loss_test: 0.005578
time: 0.24605488777160645
time: 2.2435145378112793
[1, 16496] loss_train: 0.014439, loss_test: 0.005579
time: 0.24805450439453125
time: 2.252506732940674
[1, 16497] loss_train: 0.003504, loss_test: 0.005578
time: 0.24505376815795898
time: 2.215496063232422
[1, 16498] loss_train: 0.007312, loss_test: 0.005578
time: 0.24806857109069824
time: 2.2385005950927734
[1, 16499] loss_train: 0.001327, loss_test: 0.005576
time: 0.24405384063720703
time: 2.210036516189575
[1, 16500] loss_train: 0.004450, loss_test: 0.005574
time: 0.25905704498291016
time: 2.277509927749634
[1, 16501] loss_train: 0.004981, loss_test: 0.005573
time: 0.2450542449951172
time: 2.2335073947906494
[1, 16502] loss_train: 0.006209, loss_test: 0.005574
time: 0.24605417251586914
time: 2.2595059871673584
[1, 16503] loss_train: 0.014567, loss_test: 0.005570
time: 0.24605393409729004
time: 2.231499671936035
[1, 16504] loss_train: 0.002327, loss_test: 0.005568
time: 0.24505376815795898
time: 2.2265877723693848
[1, 16505] loss_train: 0.006282, loss_test: 0.005565
time: 0.2450544834136963
time: 2.2165088653564453
[1, 16506] loss_train: 0.005464, loss_test: 0.005564
time: 0.2450544834136963
time: 2.249502182006836
[1, 16507] loss_train: 0.006880, loss_test: 0.005561
time: 0.24405503273010254
time: 2.235499858856201
[1, 16508] loss_train: 0.005742, loss_test: 0.005558
time: 0.2450551986694336
time: 2.2235052585601807
[1, 16509] loss_train: 0.009377, loss_test: 0.005557
time: 0.24405431747436523
time: 2.241004228591919
[1, 16510] loss_train: 0.012337, loss_test: 0.005556
time: 0.2580573558807373
time: 2.2615132331848145
[1, 16511] loss_train: 0.007548, loss_test: 0.005557
time: 0.24505400657653809
time: 2.2375032901763916
[1, 16512] loss_train: 0.003931, loss_test: 0.005560
time: 0.24405455589294434
time: 2.2184979915618896
[1, 16513] loss_train: 0.007107, loss_test: 0.005561
time: 0.24505400657653809
time: 2.2224972248077393
[1, 16514] loss_train: 0.009785, loss_test: 0.005561
time: 0.24405407905578613
time: 2.259505271911621
[1, 16515] loss_train: 0.012599, loss_test: 0.005562
time: 0.24306726455688477
time: 2.2415013313293457
[1, 16516] loss_train: 0.008992, loss_test: 0.005563
time: 0.24305438995361328
time: 2.233515739440918
[1, 16517] loss_train: 0.008322, loss_test: 0.005565
time: 0.24505376815795898
time: 2.2294986248016357
[1, 16518] loss_train: 0.007521, loss_test: 0.005567
time: 0.24405455589294434
time: 2.2034921646118164
[1, 16519] loss_train: 0.004533, loss_test: 0.005568
time: 0.24405407905578613
time: 2.2190089225769043
[1, 16520] loss_train: 0.009893, loss_test: 0.005569
time: 0.25705790519714355
time: 2.225497007369995
[1, 16521] loss_train: 0.003872, loss_test: 0.005568
time: 0.2510559558868408
time: 2.210519313812256
[1, 16522] loss_train: 0.005424, loss_test: 0.005566
time: 0.24605512619018555
time: 2.2264976501464844
[1, 16523] loss_train: 0.002991, loss_test: 0.005561
time: 0.2490546703338623
time: 2.2140016555786133
[1, 16524] loss_train: 0.006772, loss_test: 0.005557
time: 0.24506545066833496
time: 2.2395009994506836
[1, 16525] loss_train: 0.007413, loss_test: 0.005554
time: 0.2470555305480957
time: 2.2014944553375244
[1, 16526] loss_train: 0.002633, loss_test: 0.005551
time: 0.2450544834136963
time: 2.243501901626587
[1, 16527] loss_train: 0.003218, loss_test: 0.005549
time: 0.2450547218322754
time: 2.2515037059783936
[1, 16528] loss_train: 0.012376, loss_test: 0.005548
time: 0.24405431747436523
time: 2.2284979820251465
[1, 16529] loss_train: 0.009126, loss_test: 0.005549
time: 0.2450549602508545
time: 2.1814866065979004
[1, 16530] loss_train: 0.002971, loss_test: 0.005549
time: 0.26006031036376953
time: 2.2655112743377686
[1, 16531] loss_train: 0.007756, loss_test: 0.005551
time: 0.24405407905578613
time: 2.2304985523223877
[1, 16532] loss_train: 0.006175, loss_test: 0.005553
time: 0.24506807327270508
time: 2.2385003566741943
[1, 16533] loss_train: 0.005857, loss_test: 0.005556
time: 0.24305367469787598
time: 2.234499931335449
[1, 16534] loss_train: 0.007244, loss_test: 0.005559
time: 0.24305367469787598
time: 2.2405059337615967
[1, 16535] loss_train: 0.002513, loss_test: 0.005563
time: 0.2450542449951172
time: 2.2004945278167725
[1, 16536] loss_train: 0.007434, loss_test: 0.005566
time: 0.24405360221862793
time: 2.2244999408721924
[1, 16537] loss_train: 0.014307, loss_test: 0.005559
time: 0.24605441093444824
time: 2.21101450920105
[1, 16538] loss_train: 0.016092, loss_test: 0.005552
time: 0.2450547218322754
time: 2.216496467590332
[1, 16539] loss_train: 0.005580, loss_test: 0.005550
time: 0.2470543384552002
time: 2.226498603820801
[1, 16540] loss_train: 0.006693, loss_test: 0.005550
time: 0.26105737686157227
time: 2.3063669204711914
[1, 16541] loss_train: 0.006088, loss_test: 0.005552
time: 0.24605512619018555
time: 2.201493978500366
[1, 16542] loss_train: 0.016633, loss_test: 0.005553
time: 0.2490558624267578
time: 2.2637555599212646
[1, 16543] loss_train: 0.014259, loss_test: 0.005558
time: 0.2450542449951172
time: 2.209510564804077
[1, 16544] loss_train: 0.003195, loss_test: 0.005561
time: 0.24805402755737305
time: 2.214495897293091
[1, 16545] loss_train: 0.005280, loss_test: 0.005561
time: 0.24305343627929688
time: 2.2345001697540283
[1, 16546] loss_train: 0.008932, loss_test: 0.005563
time: 0.2470545768737793
time: 2.2255167961120605
[1, 16547] loss_train: 0.005805, loss_test: 0.005560
time: 0.24605393409729004
time: 2.1874899864196777
[1, 16548] loss_train: 0.006209, loss_test: 0.005555
time: 0.24405384063720703
time: 2.2070086002349854
[1, 16549] loss_train: 0.001231, loss_test: 0.005548
time: 0.2440659999847412
time: 2.213158130645752
[1, 16550] loss_train: 0.004780, loss_test: 0.005545
time: 0.25705718994140625
time: 2.2675065994262695
[1, 16551] loss_train: 0.001678, loss_test: 0.005547
time: 0.24605512619018555
time: 2.2545039653778076
[1, 16552] loss_train: 0.004968, loss_test: 0.005553
time: 0.24405431747436523
time: 2.2405011653900146
[1, 16553] loss_train: 0.013789, loss_test: 0.005553
time: 0.2420663833618164
time: 2.2635059356689453
[1, 16554] loss_train: 0.001208, loss_test: 0.005554
time: 0.24405336380004883
time: 2.2405014038085938
[1, 16555] loss_train: 0.005789, loss_test: 0.005555
time: 0.24405503273010254
time: 2.213496446609497
[1, 16556] loss_train: 0.006123, loss_test: 0.005555
time: 0.24405956268310547
time: 2.2385034561157227
[1, 16557] loss_train: 0.003931, loss_test: 0.005557
time: 0.24705839157104492
time: 2.2375011444091797
[1, 16558] loss_train: 0.007047, loss_test: 0.005558
time: 0.24506735801696777
time: 2.2505037784576416
[1, 16559] loss_train: 0.006448, loss_test: 0.005559
time: 0.24305391311645508
time: 2.206493616104126
[1, 16560] loss_train: 0.001439, loss_test: 0.005565
time: 0.2580583095550537
time: 2.218496561050415
[1, 16561] loss_train: 0.001175, loss_test: 0.005571
time: 0.24505400657653809
time: 2.225510597229004
[1, 16562] loss_train: 0.008590, loss_test: 0.005577
time: 0.2450547218322754
time: 2.2194983959198
[1, 16563] loss_train: 0.005949, loss_test: 0.005577
time: 0.2470545768737793
time: 2.219496726989746
[1, 16564] loss_train: 0.011468, loss_test: 0.005574
time: 0.2470555305480957
time: 2.2805094718933105
[1, 16565] loss_train: 0.006731, loss_test: 0.005572
time: 0.24606657028198242
time: 2.214853048324585
[1, 16566] loss_train: 0.005961, loss_test: 0.005570
time: 0.24505400657653809
time: 2.216496467590332
[1, 16567] loss_train: 0.006218, loss_test: 0.005569
time: 0.2490549087524414
time: 2.1894896030426025
[1, 16568] loss_train: 0.007779, loss_test: 0.005569
time: 0.24405407905578613
time: 2.2195076942443848
[1, 16569] loss_train: 0.005230, loss_test: 0.005569
time: 0.24506640434265137
time: 2.2621467113494873
[1, 16570] loss_train: 0.006585, loss_test: 0.005568
time: 0.256056547164917
time: 2.260518789291382
[1, 16571] loss_train: 0.010946, loss_test: 0.005569
time: 0.2450544834136963
time: 2.1914918422698975
[1, 16572] loss_train: 0.010474, loss_test: 0.005573
time: 0.24507951736450195
time: 2.240504264831543
[1, 16573] loss_train: 0.005332, loss_test: 0.005575
time: 0.24405384063720703
time: 2.238056182861328
[1, 16574] loss_train: 0.008815, loss_test: 0.005576
time: 0.24605488777160645
time: 2.2014927864074707
[1, 16575] loss_train: 0.001670, loss_test: 0.005577
time: 0.24505400657653809
time: 2.2455027103424072
[1, 16576] loss_train: 0.003496, loss_test: 0.005573
time: 0.24405431747436523
time: 2.25850510597229
[1, 16577] loss_train: 0.007159, loss_test: 0.005570
time: 0.24608445167541504
time: 2.2274982929229736
[1, 16578] loss_train: 0.012738, loss_test: 0.005568
time: 0.24405431747436523
time: 2.2405009269714355
[1, 16579] loss_train: 0.004982, loss_test: 0.005566
time: 0.24305438995361328
time: 2.211494207382202
[1, 16580] loss_train: 0.003064, loss_test: 0.005568
time: 0.25505661964416504
time: 2.2662112712860107
[1, 16581] loss_train: 0.007162, loss_test: 0.005571
time: 0.24305367469787598
time: 2.2254981994628906
[1, 16582] loss_train: 0.006343, loss_test: 0.005571
time: 0.24305367469787598
time: 2.206730842590332
[1, 16583] loss_train: 0.002787, loss_test: 0.005573
time: 0.24405360221862793
time: 2.2114951610565186
[1, 16584] loss_train: 0.004130, loss_test: 0.005575
time: 0.24605393409729004
time: 2.198023796081543
[1, 16585] loss_train: 0.001595, loss_test: 0.005578
time: 0.2440659999847412
time: 2.205493927001953
[1, 16586] loss_train: 0.007094, loss_test: 0.005579
time: 0.2490551471710205
time: 2.232499361038208
[1, 16587] loss_train: 0.009102, loss_test: 0.005583
time: 0.24605727195739746
time: 2.2164957523345947
[1, 16588] loss_train: 0.007438, loss_test: 0.005583
time: 0.24305343627929688
time: 2.2185168266296387
[1, 16589] loss_train: 0.007763, loss_test: 0.005579
time: 0.24405431747436523
time: 2.2495126724243164
[1, 16590] loss_train: 0.004057, loss_test: 0.005581
time: 0.25705742835998535
time: 2.272508144378662
[1, 16591] loss_train: 0.005586, loss_test: 0.005579
time: 0.24605751037597656
time: 2.2485039234161377
[1, 16592] loss_train: 0.016414, loss_test: 0.005577
time: 0.2450544834136963
time: 2.2535042762756348
[1, 16593] loss_train: 0.006842, loss_test: 0.005581
time: 0.24505400657653809
time: 2.2134954929351807
[1, 16594] loss_train: 0.004777, loss_test: 0.005588
time: 0.24805521965026855
time: 2.2324984073638916
[1, 16595] loss_train: 0.004992, loss_test: 0.005596
time: 0.24605488777160645
time: 2.244502305984497
[1, 16596] loss_train: 0.005880, loss_test: 0.005604
time: 0.24605441093444824
time: 2.2355003356933594
[1, 16597] loss_train: 0.015245, loss_test: 0.005613
time: 0.2450566291809082
time: 2.1974947452545166
[1, 16598] loss_train: 0.009858, loss_test: 0.005620
time: 0.24505400657653809
time: 2.215496063232422
[1, 16599] loss_train: 0.004459, loss_test: 0.005617
time: 0.24405360221862793
time: 2.255505084991455
[1, 16600] loss_train: 0.006301, loss_test: 0.005611
time: 0.25705671310424805
time: 2.2485032081604004
[1, 16601] loss_train: 0.007977, loss_test: 0.005601
time: 0.24305391311645508
time: 2.244502067565918
[1, 16602] loss_train: 0.008187, loss_test: 0.005590
time: 0.24405384063720703
time: 2.247502088546753
[1, 16603] loss_train: 0.001935, loss_test: 0.005575
time: 0.24605560302734375
time: 2.2174956798553467
[1, 16604] loss_train: 0.016340, loss_test: 0.005569
time: 0.2450542449951172
time: 2.2625062465667725
[1, 16605] loss_train: 0.005784, loss_test: 0.005564
time: 0.24406957626342773
time: 2.193492889404297
[1, 16606] loss_train: 0.007836, loss_test: 0.005561
time: 0.24405384063720703
time: 2.1984922885894775
[1, 16607] loss_train: 0.005276, loss_test: 0.005564
time: 0.24805521965026855
time: 2.2024927139282227
[1, 16608] loss_train: 0.008783, loss_test: 0.005570
time: 0.24405431747436523
time: 2.2154955863952637
[1, 16609] loss_train: 0.005442, loss_test: 0.005576
time: 0.24805474281311035
time: 2.2220427989959717
[1, 16610] loss_train: 0.003396, loss_test: 0.005583
time: 0.25705671310424805
time: 2.2585184574127197
[1, 16611] loss_train: 0.006150, loss_test: 0.005584
time: 0.2480614185333252
time: 2.2515037059783936
[1, 16612] loss_train: 0.006983, loss_test: 0.005581
time: 0.24505400657653809
time: 2.2405035495758057
[1, 16613] loss_train: 0.005194, loss_test: 0.005576
time: 0.2470555305480957
time: 2.2375001907348633
[1, 16614] loss_train: 0.015071, loss_test: 0.005560
time: 0.24305343627929688
time: 2.234499931335449
[1, 16615] loss_train: 0.001962, loss_test: 0.005553
time: 0.24406671524047852
time: 2.2505033016204834
[1, 16616] loss_train: 0.005299, loss_test: 0.005554
time: 0.24305415153503418
time: 2.257504940032959
[1, 16617] loss_train: 0.004865, loss_test: 0.005559
time: 0.24605369567871094
time: 2.2245001792907715
[1, 16618] loss_train: 0.012178, loss_test: 0.005569
time: 0.2450547218322754
time: 2.2284798622131348
[1, 16619] loss_train: 0.006097, loss_test: 0.005583
time: 0.24405360221862793
time: 2.1954915523529053
[1, 16620] loss_train: 0.005434, loss_test: 0.005591
time: 0.2580571174621582
time: 2.2715086936950684
[1, 16621] loss_train: 0.013421, loss_test: 0.005572
time: 0.24405360221862793
time: 2.218003034591675
[1, 16622] loss_train: 0.012305, loss_test: 0.005569
time: 0.24405121803283691
time: 2.2365028858184814
[1, 16623] loss_train: 0.003136, loss_test: 0.005573
time: 0.24505376815795898
time: 2.2365007400512695
[1, 16624] loss_train: 0.012451, loss_test: 0.005580
time: 0.24405479431152344
time: 2.2525055408477783
[1, 16625] loss_train: 0.010324, loss_test: 0.005584
time: 0.2450547218322754
time: 2.235502004623413
[1, 16626] loss_train: 0.003030, loss_test: 0.005590
time: 0.2450542449951172
time: 2.2365169525146484
[1, 16627] loss_train: 0.002154, loss_test: 0.005601
time: 0.2450551986694336
time: 2.2515039443969727
[1, 16628] loss_train: 0.005792, loss_test: 0.005611
time: 0.24405431747436523
time: 2.233499765396118
[1, 16629] loss_train: 0.004593, loss_test: 0.005619
time: 0.24405455589294434
time: 2.2090206146240234
[1, 16630] loss_train: 0.006949, loss_test: 0.005623
time: 0.256056547164917
time: 2.274522066116333
[1, 16631] loss_train: 0.001499, loss_test: 0.005632
time: 0.2450542449951172
time: 2.225519895553589
[1, 16632] loss_train: 0.002531, loss_test: 0.005639
time: 0.24405431747436523
time: 2.21040678024292
[1, 16633] loss_train: 0.005505, loss_test: 0.005641
time: 0.24405384063720703
time: 2.2365009784698486
[1, 16634] loss_train: 0.012928, loss_test: 0.005624
time: 0.24605417251586914
time: 2.2124974727630615
[1, 16635] loss_train: 0.004514, loss_test: 0.005609
time: 0.24406790733337402
time: 2.2261927127838135
[1, 16636] loss_train: 0.001877, loss_test: 0.005600
time: 0.24605393409729004
time: 2.2395126819610596
[1, 16637] loss_train: 0.007842, loss_test: 0.005592
time: 0.24905610084533691
time: 2.2194950580596924
[1, 16638] loss_train: 0.003989, loss_test: 0.005586
time: 0.247056245803833
time: 2.2314984798431396
[1, 16639] loss_train: 0.007075, loss_test: 0.005581
time: 0.24407052993774414
time: 2.2234976291656494
[1, 16640] loss_train: 0.003321, loss_test: 0.005577
time: 0.2580578327178955
time: 2.2745110988616943
[1, 16641] loss_train: 0.005726, loss_test: 0.005572
time: 0.24306058883666992
time: 2.2555043697357178
[1, 16642] loss_train: 0.001563, loss_test: 0.005568
time: 0.24605464935302734
time: 2.2164950370788574
[1, 16643] loss_train: 0.007873, loss_test: 0.005566
time: 0.24405407905578613
time: 2.216496229171753
[1, 16644] loss_train: 0.005663, loss_test: 0.005566
time: 0.24605441093444824
time: 2.2274982929229736
[1, 16645] loss_train: 0.006477, loss_test: 0.005566
time: 0.24306082725524902
time: 2.242518186569214
[1, 16646] loss_train: 0.001812, loss_test: 0.005564
time: 0.24305319786071777
time: 2.208494186401367
[1, 16647] loss_train: 0.003002, loss_test: 0.005563
time: 0.24405384063720703
time: 2.2224974632263184
[1, 16648] loss_train: 0.003305, loss_test: 0.005563
time: 0.24405384063720703
time: 2.2144956588745117
[1, 16649] loss_train: 0.008561, loss_test: 0.005560
time: 0.24405384063720703
time: 2.2228944301605225
[1, 16650] loss_train: 0.005769, loss_test: 0.005559
time: 0.25705742835998535
time: 2.25750470161438
[1, 16651] loss_train: 0.004871, loss_test: 0.005559
time: 0.24305415153503418
time: 2.2405104637145996
[1, 16652] loss_train: 0.009281, loss_test: 0.005565
time: 0.24506711959838867
time: 2.2315001487731934
[1, 16653] loss_train: 0.007250, loss_test: 0.005571
time: 0.2540559768676758
time: 2.246006488800049
[1, 16654] loss_train: 0.003092, loss_test: 0.005578
time: 0.2490549087524414
time: 2.231499433517456
[1, 16655] loss_train: 0.009091, loss_test: 0.005583
time: 0.24505400657653809
time: 2.2014946937561035
[1, 16656] loss_train: 0.008935, loss_test: 0.005585
time: 0.2490546703338623
time: 2.240501642227173
[1, 16657] loss_train: 0.000605, loss_test: 0.005588
time: 0.24605488777160645
time: 2.211493968963623
[1, 16658] loss_train: 0.015280, loss_test: 0.005582
time: 0.2450554370880127
time: 2.1774864196777344
[1, 16659] loss_train: 0.012403, loss_test: 0.005572
time: 0.2470552921295166
time: 2.2184956073760986
[1, 16660] loss_train: 0.010061, loss_test: 0.005563
time: 0.25505709648132324
time: 2.2795095443725586
[1, 16661] loss_train: 0.003590, loss_test: 0.005559
time: 0.25005626678466797
time: 2.2625057697296143
[1, 16662] loss_train: 0.003651, loss_test: 0.005555
time: 0.24506759643554688
time: 2.220499038696289
[1, 16663] loss_train: 0.009430, loss_test: 0.005555
time: 0.2450544834136963
time: 2.2365002632141113
[1, 16664] loss_train: 0.010265, loss_test: 0.005559
time: 0.2470545768737793
time: 2.2264976501464844
[1, 16665] loss_train: 0.018329, loss_test: 0.005570
time: 0.2470552921295166
time: 2.228508472442627
[1, 16666] loss_train: 0.009290, loss_test: 0.005591
time: 0.24405384063720703
time: 2.2044928073883057
[1, 16667] loss_train: 0.005319, loss_test: 0.005613
time: 0.24305343627929688
time: 2.202995777130127
[1, 16668] loss_train: 0.002389, loss_test: 0.005624
time: 0.2450542449951172
time: 2.226498603820801
[1, 16669] loss_train: 0.002815, loss_test: 0.005617
time: 0.2440662384033203
time: 2.1995246410369873
[1, 16670] loss_train: 0.006974, loss_test: 0.005608
time: 0.256058931350708
time: 2.23349928855896
[1, 16671] loss_train: 0.004643, loss_test: 0.005600
time: 0.24405431747436523
time: 2.2164957523345947
[1, 16672] loss_train: 0.007028, loss_test: 0.005587
time: 0.2450571060180664
time: 2.246501922607422
[1, 16673] loss_train: 0.003932, loss_test: 0.005576
time: 0.24505400657653809
time: 2.2094948291778564
[1, 16674] loss_train: 0.006242, loss_test: 0.005565
time: 0.24505400657653809
time: 2.243504285812378
[1, 16675] loss_train: 0.007085, loss_test: 0.005562
time: 0.24506831169128418
time: 2.2475028038024902
[1, 16676] loss_train: 0.004746, loss_test: 0.005564
time: 0.2510545253753662
time: 2.230501413345337
[1, 16677] loss_train: 0.002485, loss_test: 0.005575
time: 0.24606633186340332
time: 2.2094945907592773
[1, 16678] loss_train: 0.013334, loss_test: 0.005582
time: 0.2490553855895996
time: 2.248502492904663
[1, 16679] loss_train: 0.012417, loss_test: 0.005589
time: 0.24405479431152344
time: 2.218496084213257
[1, 16680] loss_train: 0.010378, loss_test: 0.005585
time: 0.2600574493408203
time: 2.253506898880005
[1, 16681] loss_train: 0.011380, loss_test: 0.005580
time: 0.2450544834136963
time: 2.2074968814849854
[1, 16682] loss_train: 0.004841, loss_test: 0.005576
time: 0.24505352973937988
time: 2.228003978729248
[1, 16683] loss_train: 0.011765, loss_test: 0.005572
time: 0.24405336380004883
time: 2.235499620437622
[1, 16684] loss_train: 0.008088, loss_test: 0.005566
time: 0.24405360221862793
time: 2.2475030422210693
[1, 16685] loss_train: 0.005256, loss_test: 0.005569
time: 0.24905610084533691
time: 2.2324986457824707
[1, 16686] loss_train: 0.004758, loss_test: 0.005576
time: 0.24305415153503418
time: 2.2395098209381104
[1, 16687] loss_train: 0.004448, loss_test: 0.005581
time: 0.24405431747436523
time: 2.237499952316284
[1, 16688] loss_train: 0.004582, loss_test: 0.005584
time: 0.24305438995361328
time: 2.231515407562256
[1, 16689] loss_train: 0.006433, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2385005950927734
[1, 16690] loss_train: 0.009684, loss_test: 0.005591
time: 0.25608229637145996
time: 2.244502544403076
[1, 16691] loss_train: 0.009209, loss_test: 0.005590
time: 0.24305367469787598
time: 2.2485034465789795
[1, 16692] loss_train: 0.007307, loss_test: 0.005585
time: 0.24507784843444824
time: 2.2595055103302
[1, 16693] loss_train: 0.004906, loss_test: 0.005581
time: 0.24305343627929688
time: 2.2365057468414307
[1, 16694] loss_train: 0.009114, loss_test: 0.005578
time: 0.24255108833312988
time: 2.2087645530700684
[1, 16695] loss_train: 0.005658, loss_test: 0.005575
time: 0.249068021774292
time: 2.2525033950805664
[1, 16696] loss_train: 0.006656, loss_test: 0.005574
time: 0.24405550956726074
time: 2.254514217376709
[1, 16697] loss_train: 0.009895, loss_test: 0.005575
time: 0.24707961082458496
time: 2.2325026988983154
[1, 16698] loss_train: 0.004109, loss_test: 0.005578
time: 0.24305319786071777
time: 2.241501569747925
[1, 16699] loss_train: 0.000914, loss_test: 0.005577
time: 0.2450544834136963
time: 2.2114949226379395
[1, 16700] loss_train: 0.002495, loss_test: 0.005585
time: 0.2560570240020752
time: 2.248502016067505
[1, 16701] loss_train: 0.006140, loss_test: 0.005594
time: 0.24805617332458496
time: 2.2144951820373535
[1, 16702] loss_train: 0.004190, loss_test: 0.005605
time: 0.2470550537109375
time: 2.2565042972564697
[1, 16703] loss_train: 0.003505, loss_test: 0.005619
time: 0.24406719207763672
time: 2.2254979610443115
[1, 16704] loss_train: 0.002767, loss_test: 0.005633
time: 0.24506688117980957
time: 2.2284984588623047
[1, 16705] loss_train: 0.003696, loss_test: 0.005647
time: 0.2490549087524414
time: 2.2040159702301025
[1, 16706] loss_train: 0.008525, loss_test: 0.005652
time: 0.24505376815795898
time: 2.209494113922119
[1, 16707] loss_train: 0.012491, loss_test: 0.005645
time: 0.24605417251586914
time: 2.213073968887329
[1, 16708] loss_train: 0.008920, loss_test: 0.005632
time: 0.24405527114868164
time: 2.2315008640289307
[1, 16709] loss_train: 0.001596, loss_test: 0.005625
time: 0.24505400657653809
time: 2.2290186882019043
[1, 16710] loss_train: 0.006195, loss_test: 0.005623
time: 0.25467467308044434
time: 2.272508144378662
[1, 16711] loss_train: 0.001390, loss_test: 0.005622
time: 0.24405384063720703
time: 2.228498935699463
[1, 16712] loss_train: 0.016021, loss_test: 0.005609
time: 0.2470552921295166
time: 2.2310054302215576
[1, 16713] loss_train: 0.005452, loss_test: 0.005599
time: 0.24405264854431152
time: 2.217496395111084
[1, 16714] loss_train: 0.006328, loss_test: 0.005589
time: 0.24405384063720703
time: 2.2184958457946777
[1, 16715] loss_train: 0.003273, loss_test: 0.005581
time: 0.24405336380004883
time: 2.2115085124969482
[1, 16716] loss_train: 0.003609, loss_test: 0.005576
time: 0.24405455589294434
time: 2.2555041313171387
[1, 16717] loss_train: 0.007376, loss_test: 0.005572
time: 0.24806928634643555
time: 2.222496747970581
[1, 16718] loss_train: 0.004876, loss_test: 0.005570
time: 0.24405336380004883
time: 2.222031354904175
[1, 16719] loss_train: 0.006754, loss_test: 0.005566
time: 0.25005531311035156
time: 2.2425177097320557
[1, 16720] loss_train: 0.007496, loss_test: 0.005563
time: 0.25505614280700684
time: 2.254504442214966
[1, 16721] loss_train: 0.007879, loss_test: 0.005559
time: 0.24405360221862793
time: 2.2375009059906006
[1, 16722] loss_train: 0.013720, loss_test: 0.005558
time: 0.24405384063720703
time: 2.2075023651123047
[1, 16723] loss_train: 0.004943, loss_test: 0.005557
time: 0.2450549602508545
time: 2.2119970321655273
[1, 16724] loss_train: 0.001435, loss_test: 0.005558
time: 0.24805545806884766
time: 2.2235138416290283
[1, 16725] loss_train: 0.001517, loss_test: 0.005560
time: 0.24506831169128418
time: 2.218496561050415
[1, 16726] loss_train: 0.009103, loss_test: 0.005564
time: 0.25005507469177246
time: 2.2206246852874756
[1, 16727] loss_train: 0.007514, loss_test: 0.005569
time: 0.24409818649291992
time: 2.2375011444091797
[1, 16728] loss_train: 0.005848, loss_test: 0.005572
time: 0.2470543384552002
time: 2.2145068645477295
[1, 16729] loss_train: 0.000666, loss_test: 0.005576
time: 0.24505376815795898
time: 2.233508825302124
[1, 16730] loss_train: 0.001719, loss_test: 0.005582
time: 0.25705671310424805
time: 2.2745087146759033
[1, 16731] loss_train: 0.008985, loss_test: 0.005584
time: 0.24405407905578613
time: 2.2204971313476562
[1, 16732] loss_train: 0.008355, loss_test: 0.005589
time: 0.24305343627929688
time: 2.2460052967071533
[1, 16733] loss_train: 0.009457, loss_test: 0.005591
time: 0.24405384063720703
time: 2.2315011024475098
[1, 16734] loss_train: 0.006701, loss_test: 0.005595
time: 0.24305343627929688
time: 2.229498863220215
[1, 16735] loss_train: 0.007337, loss_test: 0.005594
time: 0.24405407905578613
time: 2.257505178451538
[1, 16736] loss_train: 0.011341, loss_test: 0.005586
time: 0.24504804611206055
time: 2.2455358505249023
[1, 16737] loss_train: 0.005916, loss_test: 0.005582
time: 0.24405574798583984
time: 2.248502254486084
[1, 16738] loss_train: 0.007354, loss_test: 0.005577
time: 0.2450563907623291
time: 2.223497152328491
[1, 16739] loss_train: 0.003373, loss_test: 0.005575
time: 0.24538159370422363
time: 2.2104947566986084
[1, 16740] loss_train: 0.004706, loss_test: 0.005573
time: 0.25705718994140625
time: 2.2655062675476074
[1, 16741] loss_train: 0.005199, loss_test: 0.005571
time: 0.2450542449951172
time: 2.2465031147003174
[1, 16742] loss_train: 0.008969, loss_test: 0.005567
time: 0.24605393409729004
time: 2.228498935699463
[1, 16743] loss_train: 0.013778, loss_test: 0.005560
time: 0.24405407905578613
time: 2.2019968032836914
[1, 16744] loss_train: 0.001016, loss_test: 0.005556
time: 0.24305367469787598
time: 2.221499443054199
[1, 16745] loss_train: 0.006150, loss_test: 0.005553
time: 0.2450549602508545
time: 2.2435011863708496
[1, 16746] loss_train: 0.007376, loss_test: 0.005551
time: 0.24405407905578613
time: 2.2029993534088135
[1, 16747] loss_train: 0.005397, loss_test: 0.005549
time: 0.2450549602508545
time: 2.258504629135132
[1, 16748] loss_train: 0.005031, loss_test: 0.005547
time: 0.24405384063720703
time: 2.2224974632263184
[1, 16749] loss_train: 0.007693, loss_test: 0.005544
time: 0.24905610084533691
time: 2.2395153045654297
[1, 16750] loss_train: 0.003678, loss_test: 0.005542
time: 0.25905752182006836
time: 2.2705078125
[1, 16751] loss_train: 0.007804, loss_test: 0.005541
time: 0.2450549602508545
time: 2.231506586074829
[1, 16752] loss_train: 0.006954, loss_test: 0.005540
time: 0.2470543384552002
time: 2.2370078563690186
[1, 16753] loss_train: 0.006357, loss_test: 0.005539
time: 0.2490687370300293
time: 2.209493637084961
[1, 16754] loss_train: 0.004174, loss_test: 0.005538
time: 0.24405431747436523
time: 2.2304985523223877
[1, 16755] loss_train: 0.002536, loss_test: 0.005538
time: 0.24805521965026855
time: 2.2385005950927734
[1, 16756] loss_train: 0.009759, loss_test: 0.005540
time: 0.24405407905578613
time: 2.232499599456787
[1, 16757] loss_train: 0.007345, loss_test: 0.005543
time: 0.24605417251586914
time: 2.239501476287842
[1, 16758] loss_train: 0.005168, loss_test: 0.005546
time: 0.24505376815795898
time: 2.2385013103485107
[1, 16759] loss_train: 0.011333, loss_test: 0.005552
time: 0.24405431747436523
time: 2.243511199951172
[1, 16760] loss_train: 0.007111, loss_test: 0.005558
time: 0.25705695152282715
time: 2.2855114936828613
[1, 16761] loss_train: 0.005307, loss_test: 0.005565
time: 0.24606657028198242
time: 2.2405173778533936
[1, 16762] loss_train: 0.002811, loss_test: 0.005571
time: 0.24805545806884766
time: 2.217495918273926
[1, 16763] loss_train: 0.005996, loss_test: 0.005573
time: 0.24405479431152344
time: 2.1884889602661133
[1, 16764] loss_train: 0.013708, loss_test: 0.005564
time: 0.24405407905578613
time: 2.2254981994628906
[1, 16765] loss_train: 0.009627, loss_test: 0.005556
time: 0.24305367469787598
time: 2.2405009269714355
[1, 16766] loss_train: 0.005926, loss_test: 0.005552
time: 0.24405431747436523
time: 2.2345006465911865
[1, 16767] loss_train: 0.004443, loss_test: 0.005551
time: 0.24605536460876465
time: 2.2124972343444824
[1, 16768] loss_train: 0.007953, loss_test: 0.005553
time: 0.24406719207763672
time: 2.22249698638916
[1, 16769] loss_train: 0.004897, loss_test: 0.005556
time: 0.2470684051513672
time: 2.273566722869873
[1, 16770] loss_train: 0.005676, loss_test: 0.005557
time: 0.25705647468566895
time: 2.271507740020752
[1, 16771] loss_train: 0.014793, loss_test: 0.005556
time: 0.2450549602508545
time: 2.2184956073760986
[1, 16772] loss_train: 0.003045, loss_test: 0.005553
time: 0.24505376815795898
time: 2.2264983654022217
[1, 16773] loss_train: 0.011718, loss_test: 0.005552
time: 0.24505305290222168
time: 2.2115070819854736
[1, 16774] loss_train: 0.003292, loss_test: 0.005546
time: 0.24606680870056152
time: 2.2134954929351807
[1, 16775] loss_train: 0.004350, loss_test: 0.005541
time: 0.24605417251586914
time: 2.2254974842071533
[1, 16776] loss_train: 0.008533, loss_test: 0.005537
time: 0.2520565986633301
time: 2.1994924545288086
[1, 16777] loss_train: 0.004927, loss_test: 0.005536
time: 0.24505400657653809
time: 2.215496301651001
[1, 16778] loss_train: 0.012460, loss_test: 0.005535
time: 0.24605464935302734
time: 2.218496084213257
[1, 16779] loss_train: 0.011986, loss_test: 0.005538
time: 0.24405431747436523
time: 2.208493232727051
[1, 16780] loss_train: 0.002818, loss_test: 0.005541
time: 0.25705695152282715
time: 2.258009433746338
[1, 16781] loss_train: 0.005564, loss_test: 0.005545
time: 0.24405360221862793
time: 2.222512722015381
[1, 16782] loss_train: 0.011147, loss_test: 0.005547
time: 0.24605464935302734
time: 2.2171459197998047
[1, 16783] loss_train: 0.011943, loss_test: 0.005550
time: 0.24805498123168945
time: 2.2265102863311768
[1, 16784] loss_train: 0.005708, loss_test: 0.005551
time: 0.24305176734924316
time: 2.2465028762817383
[1, 16785] loss_train: 0.004212, loss_test: 0.005551
time: 0.24205398559570312
time: 2.2525036334991455
[1, 16786] loss_train: 0.004776, loss_test: 0.005552
time: 0.2450547218322754
time: 2.2545058727264404
[1, 16787] loss_train: 0.011825, loss_test: 0.005553
time: 0.24305367469787598
time: 2.217496395111084
[1, 16788] loss_train: 0.006020, loss_test: 0.005554
time: 0.24405407905578613
time: 2.220496416091919
[1, 16789] loss_train: 0.001031, loss_test: 0.005559
time: 0.24305462837219238
time: 2.2004919052124023
[1, 16790] loss_train: 0.009355, loss_test: 0.005561
time: 0.2580692768096924
time: 2.269508123397827
[1, 16791] loss_train: 0.005016, loss_test: 0.005564
time: 0.24405455589294434
time: 2.194490432739258
[1, 16792] loss_train: 0.005562, loss_test: 0.005567
time: 0.24605488777160645
time: 2.236501932144165
[1, 16793] loss_train: 0.002256, loss_test: 0.005571
time: 0.24509000778198242
time: 2.2505033016204834
[1, 16794] loss_train: 0.006373, loss_test: 0.005573
time: 0.2450544834136963
time: 2.2264981269836426
[1, 16795] loss_train: 0.006702, loss_test: 0.005571
time: 0.24708008766174316
time: 2.2645232677459717
[1, 16796] loss_train: 0.002133, loss_test: 0.005579
time: 0.24405980110168457
time: 2.1995081901550293
[1, 16797] loss_train: 0.007652, loss_test: 0.005579
time: 0.2510561943054199
time: 2.2324984073638916
[1, 16798] loss_train: 0.006968, loss_test: 0.005576
time: 0.24508070945739746
time: 2.215496063232422
[1, 16799] loss_train: 0.004533, loss_test: 0.005574
time: 0.2470543384552002
time: 2.224510431289673
[1, 16800] loss_train: 0.007689, loss_test: 0.005570
time: 0.25705623626708984
time: 2.2485034465789795
[1, 16801] loss_train: 0.008624, loss_test: 0.005567
time: 0.2470548152923584
time: 2.2014882564544678
[1, 16802] loss_train: 0.008407, loss_test: 0.005568
time: 0.26105737686157227
time: 2.2645070552825928
[1, 16803] loss_train: 0.005168, loss_test: 0.005570
time: 0.24805450439453125
time: 2.2204971313476562
[1, 16804] loss_train: 0.003196, loss_test: 0.005573
time: 0.2450547218322754
time: 2.2345001697540283
[1, 16805] loss_train: 0.014109, loss_test: 0.005576
time: 0.24402236938476562
time: 2.265507221221924
[1, 16806] loss_train: 0.004106, loss_test: 0.005584
time: 0.24306726455688477
time: 2.245502471923828
[1, 16807] loss_train: 0.001707, loss_test: 0.005591
time: 0.24905633926391602
time: 2.230506658554077
[1, 16808] loss_train: 0.005736, loss_test: 0.005595
time: 0.24506497383117676
time: 2.2465052604675293
[1, 16809] loss_train: 0.005308, loss_test: 0.005596
time: 0.24305319786071777
time: 2.2565245628356934
[1, 16810] loss_train: 0.012317, loss_test: 0.005584
time: 0.2580575942993164
time: 2.2525033950805664
[1, 16811] loss_train: 0.002821, loss_test: 0.005570
time: 0.2470550537109375
time: 2.2430059909820557
[1, 16812] loss_train: 0.007577, loss_test: 0.005560
time: 0.24506711959838867
time: 2.245504379272461
[1, 16813] loss_train: 0.003742, loss_test: 0.005554
time: 0.24508380889892578
time: 2.255504846572876
[1, 16814] loss_train: 0.002820, loss_test: 0.005552
time: 0.24405431747436523
time: 2.2264981269836426
[1, 16815] loss_train: 0.003003, loss_test: 0.005555
time: 0.24505376815795898
time: 2.229501247406006
[1, 16816] loss_train: 0.006735, loss_test: 0.005560
time: 0.24405527114868164
time: 2.214495897293091
[1, 16817] loss_train: 0.005470, loss_test: 0.005568
time: 0.2470536231994629
time: 2.2234981060028076
[1, 16818] loss_train: 0.007004, loss_test: 0.005577
time: 0.24405431747436523
time: 2.239511728286743
[1, 16819] loss_train: 0.002622, loss_test: 0.005588
time: 0.24605488777160645
time: 2.2365002632141113
[1, 16820] loss_train: 0.008992, loss_test: 0.005576
time: 0.2560563087463379
time: 2.2875115871429443
[1, 16821] loss_train: 0.007215, loss_test: 0.005563
time: 0.24406814575195312
time: 2.229508876800537
[1, 16822] loss_train: 0.003521, loss_test: 0.005557
time: 0.24305510520935059
time: 2.225497007369995
[1, 16823] loss_train: 0.002731, loss_test: 0.005556
time: 0.24405503273010254
time: 2.2255165576934814
[1, 16824] loss_train: 0.006284, loss_test: 0.005558
time: 0.24407958984375
time: 2.2284996509552
[1, 16825] loss_train: 0.010110, loss_test: 0.005562
time: 0.24405384063720703
time: 2.2034924030303955
[1, 16826] loss_train: 0.004134, loss_test: 0.005566
time: 0.24506783485412598
time: 2.1994919776916504
[1, 16827] loss_train: 0.004434, loss_test: 0.005571
time: 0.2490541934967041
time: 2.2174956798553467
[1, 16828] loss_train: 0.006535, loss_test: 0.005574
time: 0.2490694522857666
time: 2.220496654510498
[1, 16829] loss_train: 0.014375, loss_test: 0.005567
time: 0.24405598640441895
time: 2.2084946632385254
[1, 16830] loss_train: 0.005634, loss_test: 0.005568
time: 0.25705718994140625
time: 2.2625925540924072
[1, 16831] loss_train: 0.009833, loss_test: 0.005573
time: 0.24405455589294434
time: 2.2435038089752197
[1, 16832] loss_train: 0.012764, loss_test: 0.005581
time: 0.2430586814880371
time: 2.2455027103424072
[1, 16833] loss_train: 0.004323, loss_test: 0.005583
time: 0.24305438995361328
time: 2.2385003566741943
[1, 16834] loss_train: 0.005881, loss_test: 0.005583
time: 0.24409079551696777
time: 2.250502824783325
[1, 16835] loss_train: 0.006362, loss_test: 0.005580
time: 0.2440657615661621
time: 2.2004928588867188
[1, 16836] loss_train: 0.007083, loss_test: 0.005578
time: 0.2470543384552002
time: 2.209510087966919
[1, 16837] loss_train: 0.003043, loss_test: 0.005574
time: 0.2520725727081299
time: 2.224496841430664
[1, 16838] loss_train: 0.005287, loss_test: 0.005571
time: 0.24405336380004883
time: 2.206493854522705
[1, 16839] loss_train: 0.006167, loss_test: 0.005567
time: 0.24605727195739746
time: 2.2004926204681396
[1, 16840] loss_train: 0.002063, loss_test: 0.005563
time: 0.2565805912017822
time: 2.2762644290924072
[1, 16841] loss_train: 0.006974, loss_test: 0.005561
time: 0.24405360221862793
time: 2.2134957313537598
[1, 16842] loss_train: 0.003010, loss_test: 0.005563
time: 0.2440659999847412
time: 2.22251033782959
[1, 16843] loss_train: 0.005314, loss_test: 0.005568
time: 0.2450549602508545
time: 2.26950740814209
[1, 16844] loss_train: 0.004446, loss_test: 0.005577
time: 0.24305391311645508
time: 2.2375004291534424
[1, 16845] loss_train: 0.005195, loss_test: 0.005589
time: 0.24605488777160645
time: 2.2154953479766846
[1, 16846] loss_train: 0.005718, loss_test: 0.005598
time: 0.24605488777160645
time: 2.244502305984497
[1, 16847] loss_train: 0.008287, loss_test: 0.005597
time: 0.24706649780273438
time: 2.2244975566864014
[1, 16848] loss_train: 0.005112, loss_test: 0.005595
time: 0.24606728553771973
time: 2.1895084381103516
[1, 16849] loss_train: 0.005657, loss_test: 0.005592
time: 0.24605488777160645
time: 2.2085249423980713
[1, 16850] loss_train: 0.007237, loss_test: 0.005585
time: 0.25705695152282715
time: 2.240504264831543
[1, 16851] loss_train: 0.012300, loss_test: 0.005567
time: 0.2470543384552002
time: 2.2325007915496826
[1, 16852] loss_train: 0.005214, loss_test: 0.005568
time: 0.24506807327270508
time: 2.2375009059906006
[1, 16853] loss_train: 0.004308, loss_test: 0.005588
time: 0.24405455589294434
time: 2.2395119667053223
[1, 16854] loss_train: 0.014557, loss_test: 0.005624
time: 0.24806785583496094
time: 2.234499454498291
[1, 16855] loss_train: 0.005108, loss_test: 0.005644
time: 0.24405407905578613
time: 2.2204971313476562
[1, 16856] loss_train: 0.002911, loss_test: 0.005636
time: 0.24405455589294434
time: 2.243501663208008
[1, 16857] loss_train: 0.005451, loss_test: 0.005608
time: 0.24505352973937988
time: 2.216002941131592
[1, 16858] loss_train: 0.003614, loss_test: 0.005576
time: 0.24405431747436523
time: 2.2100024223327637
[1, 16859] loss_train: 0.002407, loss_test: 0.005559
time: 0.24605536460876465
time: 2.232499122619629
[1, 16860] loss_train: 0.004336, loss_test: 0.005563
time: 0.25705671310424805
time: 2.258505344390869
[1, 16861] loss_train: 0.007732, loss_test: 0.005579
time: 0.2490549087524414
time: 2.2415270805358887
[1, 16862] loss_train: 0.001038, loss_test: 0.005607
time: 0.2450542449951172
time: 2.2124953269958496
[1, 16863] loss_train: 0.001267, loss_test: 0.005642
time: 0.24605965614318848
time: 2.2425098419189453
[1, 16864] loss_train: 0.002824, loss_test: 0.005682
time: 0.24505400657653809
time: 2.208000898361206
[1, 16865] loss_train: 0.005169, loss_test: 0.005706
time: 0.24406695365905762
time: 2.244502305984497
[1, 16866] loss_train: 0.010086, loss_test: 0.005719
time: 0.24606084823608398
time: 2.2014920711517334
[1, 16867] loss_train: 0.002740, loss_test: 0.005727
time: 0.24405407905578613
time: 2.228498935699463
[1, 16868] loss_train: 0.005552, loss_test: 0.005716
time: 0.25005555152893066
time: 2.23689341545105
[1, 16869] loss_train: 0.007140, loss_test: 0.005697
time: 0.2440803050994873
time: 2.227498769760132
[1, 16870] loss_train: 0.013856, loss_test: 0.005673
time: 0.2620575428009033
time: 2.264025926589966
[1, 16871] loss_train: 0.007831, loss_test: 0.005653
time: 0.24905657768249512
time: 2.209510564804077
[1, 16872] loss_train: 0.002455, loss_test: 0.005639
time: 0.24805450439453125
time: 2.23500394821167
[1, 16873] loss_train: 0.005236, loss_test: 0.005627
time: 0.2450544834136963
time: 2.211493968963623
[1, 16874] loss_train: 0.001506, loss_test: 0.005613
time: 0.24605488777160645
time: 2.2345001697540283
[1, 16875] loss_train: 0.005604, loss_test: 0.005605
time: 0.24405384063720703
time: 2.2395005226135254
[1, 16876] loss_train: 0.006383, loss_test: 0.005582
time: 0.24405431747436523
time: 2.2220370769500732
[1, 16877] loss_train: 0.009417, loss_test: 0.005571
time: 0.24305367469787598
time: 2.2455060482025146
[1, 16878] loss_train: 0.000975, loss_test: 0.005567
time: 0.24605441093444824
time: 2.256505012512207
[1, 16879] loss_train: 0.003080, loss_test: 0.005571
time: 0.24305319786071777
time: 2.242501974105835
[1, 16880] loss_train: 0.001556, loss_test: 0.005580
time: 0.2560563087463379
time: 2.314539909362793
[1, 16881] loss_train: 0.010287, loss_test: 0.005589
time: 0.24605417251586914
time: 2.2114951610565186
[1, 16882] loss_train: 0.007578, loss_test: 0.005597
time: 0.24306607246398926
time: 2.231013536453247
[1, 16883] loss_train: 0.007065, loss_test: 0.005606
time: 0.24305391311645508
time: 2.233515501022339
[1, 16884] loss_train: 0.011581, loss_test: 0.005616
time: 0.2470550537109375
time: 2.257640838623047
[1, 16885] loss_train: 0.006831, loss_test: 0.005621
time: 0.24605488777160645
time: 2.2445080280303955
[1, 16886] loss_train: 0.004836, loss_test: 0.005619
time: 0.24605488777160645
time: 2.2134954929351807
[1, 16887] loss_train: 0.001488, loss_test: 0.005613
time: 0.24405384063720703
time: 2.2204997539520264
[1, 16888] loss_train: 0.009306, loss_test: 0.005584
time: 0.2470543384552002
time: 2.2074944972991943
[1, 16889] loss_train: 0.002120, loss_test: 0.005565
time: 0.24505305290222168
time: 2.2214977741241455
[1, 16890] loss_train: 0.006919, loss_test: 0.005553
time: 0.2570681571960449
time: 2.2525112628936768
[1, 16891] loss_train: 0.007458, loss_test: 0.005549
time: 0.2520561218261719
time: 2.254506826400757
[1, 16892] loss_train: 0.002706, loss_test: 0.005550
time: 0.2450547218322754
time: 2.257507085800171
[1, 16893] loss_train: 0.002984, loss_test: 0.005557
time: 0.24305438995361328
time: 2.2455012798309326
[1, 16894] loss_train: 0.005770, loss_test: 0.005566
time: 0.24505376815795898
time: 2.242501735687256
[1, 16895] loss_train: 0.011559, loss_test: 0.005579
time: 0.24606704711914062
time: 2.208493232727051
[1, 16896] loss_train: 0.005963, loss_test: 0.005594
time: 0.24405407905578613
time: 2.2395012378692627
[1, 16897] loss_train: 0.008860, loss_test: 0.005610
time: 0.24505400657653809
time: 2.230499505996704
[1, 16898] loss_train: 0.004839, loss_test: 0.005622
time: 0.2450554370880127
time: 2.212494373321533
[1, 16899] loss_train: 0.005723, loss_test: 0.005634
time: 0.24805474281311035
time: 2.223496913909912
[1, 16900] loss_train: 0.004058, loss_test: 0.005644
time: 0.25705718994140625
time: 2.3085689544677734
[1, 16901] loss_train: 0.001654, loss_test: 0.005645
time: 0.2510566711425781
time: 2.2234976291656494
[1, 16902] loss_train: 0.003780, loss_test: 0.005640
time: 0.24505400657653809
time: 2.2455027103424072
[1, 16903] loss_train: 0.019533, loss_test: 0.005616
time: 0.24805569648742676
time: 2.250502824783325
[1, 16904] loss_train: 0.011740, loss_test: 0.005599
time: 0.24805521965026855
time: 2.25850510597229
[1, 16905] loss_train: 0.010402, loss_test: 0.005567
time: 0.2470550537109375
time: 2.2645063400268555
[1, 16906] loss_train: 0.012420, loss_test: 0.005544
time: 0.2450544834136963
time: 2.2274985313415527
[1, 16907] loss_train: 0.008913, loss_test: 0.005545
time: 0.24805521965026855
time: 2.225497245788574
[1, 16908] loss_train: 0.005618, loss_test: 0.005565
time: 0.2450551986694336
time: 2.2315211296081543
[1, 16909] loss_train: 0.003805, loss_test: 0.005596
time: 0.24605369567871094
time: 2.2225093841552734
[1, 16910] loss_train: 0.002347, loss_test: 0.005631
time: 0.25606727600097656
time: 2.223510980606079
[1, 16911] loss_train: 0.009220, loss_test: 0.005655
time: 0.2670595645904541
time: 2.216495990753174
[1, 16912] loss_train: 0.009679, loss_test: 0.005661
time: 0.2470545768737793
time: 2.258505344390869
[1, 16913] loss_train: 0.001508, loss_test: 0.005664
time: 0.2450549602508545
time: 2.2284979820251465
[1, 16914] loss_train: 0.002785, loss_test: 0.005650
time: 0.2470688819885254
time: 2.228498697280884
[1, 16915] loss_train: 0.004995, loss_test: 0.005648
time: 0.24505376815795898
time: 2.2505037784576416
[1, 16916] loss_train: 0.012484, loss_test: 0.005652
time: 0.24305343627929688
time: 2.211308479309082
[1, 16917] loss_train: 0.000720, loss_test: 0.005667
time: 0.24506640434265137
time: 2.23626971244812
[1, 16918] loss_train: 0.006987, loss_test: 0.005684
time: 0.24605369567871094
time: 2.266507625579834
[1, 16919] loss_train: 0.008480, loss_test: 0.005696
time: 0.24305391311645508
time: 2.2395007610321045
[1, 16920] loss_train: 0.009269, loss_test: 0.005691
time: 0.26105833053588867
time: 2.250732660293579
[1, 16921] loss_train: 0.005964, loss_test: 0.005682
time: 0.24805450439453125
time: 2.238534688949585
[1, 16922] loss_train: 0.006742, loss_test: 0.005665
time: 0.24305367469787598
time: 2.202516794204712
[1, 16923] loss_train: 0.000781, loss_test: 0.005656
time: 0.2440800666809082
time: 2.228499174118042
[1, 16924] loss_train: 0.004036, loss_test: 0.005648
time: 0.2450542449951172
time: 2.2184998989105225
[1, 16925] loss_train: 0.001313, loss_test: 0.005646
time: 0.24405407905578613
time: 2.231499433517456
[1, 16926] loss_train: 0.006487, loss_test: 0.005640
time: 0.24405431747436523
time: 2.2224972248077393
[1, 16927] loss_train: 0.005665, loss_test: 0.005635
time: 0.2450542449951172
time: 2.2144951820373535
[1, 16928] loss_train: 0.001945, loss_test: 0.005635
time: 0.24606776237487793
time: 2.2345001697540283
[1, 16929] loss_train: 0.007471, loss_test: 0.005634
time: 0.24507999420166016
time: 2.2195024490356445
[1, 16930] loss_train: 0.006533, loss_test: 0.005634
time: 0.26105809211730957
time: 2.2665069103240967
[1, 16931] loss_train: 0.003464, loss_test: 0.005636
time: 0.2470552921295166
time: 2.2304983139038086
[1, 16932] loss_train: 0.008704, loss_test: 0.005629
time: 0.2470545768737793
time: 2.229498863220215
[1, 16933] loss_train: 0.006731, loss_test: 0.005626
time: 0.24605488777160645
time: 2.2024927139282227
[1, 16934] loss_train: 0.000986, loss_test: 0.005625
time: 0.24805450439453125
time: 2.1990585327148438
[1, 16935] loss_train: 0.010392, loss_test: 0.005622
time: 0.24605417251586914
time: 2.2385003566741943
[1, 16936] loss_train: 0.006368, loss_test: 0.005618
time: 0.2450547218322754
time: 2.246502637863159
[1, 16937] loss_train: 0.002021, loss_test: 0.005614
time: 0.24607181549072266
time: 2.207493782043457
[1, 16938] loss_train: 0.002808, loss_test: 0.005610
time: 0.2470545768737793
time: 2.234499931335449
[1, 16939] loss_train: 0.006865, loss_test: 0.005605
time: 0.24405384063720703
time: 2.2250211238861084
[1, 16940] loss_train: 0.007887, loss_test: 0.005598
time: 0.256056547164917
time: 2.2760162353515625
[1, 16941] loss_train: 0.002729, loss_test: 0.005591
time: 0.24405360221862793
time: 2.2615058422088623
[1, 16942] loss_train: 0.008865, loss_test: 0.005583
time: 0.2450544834136963
time: 2.224456787109375
[1, 16943] loss_train: 0.009123, loss_test: 0.005577
time: 0.24560022354125977
time: 2.2345004081726074
[1, 16944] loss_train: 0.012205, loss_test: 0.005575
time: 0.24305367469787598
time: 2.206493854522705
[1, 16945] loss_train: 0.002208, loss_test: 0.005574
time: 0.24557042121887207
time: 2.1914925575256348
[1, 16946] loss_train: 0.007315, loss_test: 0.005572
time: 0.24305939674377441
time: 2.220496416091919
[1, 16947] loss_train: 0.005376, loss_test: 0.005569
time: 0.24505400657653809
time: 2.206493854522705
[1, 16948] loss_train: 0.010766, loss_test: 0.005564
time: 0.24605464935302734
time: 2.2395737171173096
[1, 16949] loss_train: 0.001680, loss_test: 0.005556
time: 0.24505376815795898
time: 2.2074942588806152
[1, 16950] loss_train: 0.002638, loss_test: 0.005551
time: 0.25905776023864746
time: 2.248502731323242
[1, 16951] loss_train: 0.002089, loss_test: 0.005551
time: 0.2470545768737793
time: 2.22149658203125
[1, 16952] loss_train: 0.008930, loss_test: 0.005551
time: 0.24605607986450195
time: 2.2695071697235107
[1, 16953] loss_train: 0.009277, loss_test: 0.005553
time: 0.2490553855895996
time: 2.2355024814605713
[1, 16954] loss_train: 0.009690, loss_test: 0.005554
time: 0.24605417251586914
time: 2.2224974632263184
[1, 16955] loss_train: 0.007946, loss_test: 0.005547
time: 0.2490558624267578
time: 2.237499952316284
[1, 16956] loss_train: 0.008203, loss_test: 0.005544
time: 0.24305438995361328
time: 2.2134950160980225
[1, 16957] loss_train: 0.010650, loss_test: 0.005545
time: 0.24605417251586914
time: 2.2224974632263184
[1, 16958] loss_train: 0.008474, loss_test: 0.005549
time: 0.24305343627929688
time: 2.204493522644043
[1, 16959] loss_train: 0.005385, loss_test: 0.005553
time: 0.24305367469787598
time: 2.206494092941284
[1, 16960] loss_train: 0.013145, loss_test: 0.005559
time: 0.2560575008392334
time: 2.271507740020752
[1, 16961] loss_train: 0.011872, loss_test: 0.005566
time: 0.2450542449951172
time: 2.2655069828033447
[1, 16962] loss_train: 0.004829, loss_test: 0.005569
time: 0.24407458305358887
time: 2.253504514694214
[1, 16963] loss_train: 0.006204, loss_test: 0.005567
time: 0.24305343627929688
time: 2.216496467590332
[1, 16964] loss_train: 0.003988, loss_test: 0.005564
time: 0.24405431747436523
time: 2.2294983863830566
[1, 16965] loss_train: 0.006211, loss_test: 0.005560
time: 0.24505400657653809
time: 2.228498935699463
[1, 16966] loss_train: 0.005677, loss_test: 0.005554
time: 0.24405336380004883
time: 2.2475035190582275
[1, 16967] loss_train: 0.009881, loss_test: 0.005550
time: 0.24505376815795898
time: 2.2124972343444824
[1, 16968] loss_train: 0.007500, loss_test: 0.005549
time: 0.24405479431152344
time: 2.222496747970581
[1, 16969] loss_train: 0.002422, loss_test: 0.005548
time: 0.24505400657653809
time: 2.2235865592956543
[1, 16970] loss_train: 0.013865, loss_test: 0.005550
time: 0.2580568790435791
time: 2.2785098552703857
[1, 16971] loss_train: 0.011478, loss_test: 0.005549
time: 0.2450549602508545
time: 2.233513116836548
[1, 16972] loss_train: 0.008670, loss_test: 0.005549
time: 0.24741888046264648
time: 2.2264983654022217
[1, 16973] loss_train: 0.006192, loss_test: 0.005549
time: 0.24707293510437012
time: 2.220496416091919
[1, 16974] loss_train: 0.024637, loss_test: 0.005549
time: 0.24405360221862793
time: 2.2224979400634766
[1, 16975] loss_train: 0.008002, loss_test: 0.005549
time: 0.2440791130065918
time: 2.2035131454467773
[1, 16976] loss_train: 0.002778, loss_test: 0.005551
time: 0.2450547218322754
time: 2.220496654510498
[1, 16977] loss_train: 0.011564, loss_test: 0.005552
time: 0.24405360221862793
time: 2.2385010719299316
[1, 16978] loss_train: 0.006362, loss_test: 0.005556
time: 0.24606680870056152
time: 2.260514259338379
[1, 16979] loss_train: 0.005763, loss_test: 0.005560
time: 0.2450547218322754
time: 2.2375166416168213
[1, 16980] loss_train: 0.004298, loss_test: 0.005561
time: 0.25905704498291016
time: 2.2725088596343994
[1, 16981] loss_train: 0.003237, loss_test: 0.005561
time: 0.24506735801696777
time: 2.2314987182617188
[1, 16982] loss_train: 0.003868, loss_test: 0.005561
time: 0.25005435943603516
time: 2.2124950885772705
[1, 16983] loss_train: 0.009150, loss_test: 0.005560
time: 0.24405384063720703
time: 2.219496726989746
[1, 16984] loss_train: 0.003931, loss_test: 0.005555
time: 0.24506235122680664
time: 2.2385129928588867
[1, 16985] loss_train: 0.006343, loss_test: 0.005553
time: 0.2450542449951172
time: 2.232499361038208
[1, 16986] loss_train: 0.007678, loss_test: 0.005552
time: 0.24506664276123047
time: 2.21811842918396
[1, 16987] loss_train: 0.004333, loss_test: 0.005553
time: 0.24305438995361328
time: 2.2184958457946777
[1, 16988] loss_train: 0.009323, loss_test: 0.005553
time: 0.24405431747436523
time: 2.2315008640289307
[1, 16989] loss_train: 0.003632, loss_test: 0.005556
time: 0.2490556240081787
time: 2.2365243434906006
[1, 16990] loss_train: 0.009013, loss_test: 0.005557
time: 0.256056547164917
time: 2.2598042488098145
[1, 16991] loss_train: 0.007561, loss_test: 0.005556
time: 0.24405407905578613
time: 2.2405035495758057
[1, 16992] loss_train: 0.002909, loss_test: 0.005557
time: 0.24405431747436523
time: 2.2415013313293457
[1, 16993] loss_train: 0.002601, loss_test: 0.005559
time: 0.2450549602508545
time: 2.205493688583374
[1, 16994] loss_train: 0.002161, loss_test: 0.005562
time: 0.2450544834136963
time: 2.199645757675171
[1, 16995] loss_train: 0.007202, loss_test: 0.005564
time: 0.24405360221862793
time: 2.204493761062622
[1, 16996] loss_train: 0.003047, loss_test: 0.005569
time: 0.24805474281311035
time: 2.216515064239502
[1, 16997] loss_train: 0.008418, loss_test: 0.005568
time: 0.25005578994750977
time: 2.233499526977539
[1, 16998] loss_train: 0.001258, loss_test: 0.005570
time: 0.24605441093444824
time: 2.230522871017456
[1, 16999] loss_train: 0.003072, loss_test: 0.005574
time: 0.2490549087524414
time: 2.251514196395874
[1, 17000] loss_train: 0.005382, loss_test: 0.005579
time: 0.2560570240020752
time: 2.261085271835327
[1, 17001] loss_train: 0.004322, loss_test: 0.005582
time: 0.2490556240081787
time: 2.211494207382202
[1, 17002] loss_train: 0.003592, loss_test: 0.005584
time: 0.24405407905578613
time: 2.217496633529663
[1, 17003] loss_train: 0.011503, loss_test: 0.005581
time: 0.24605441093444824
time: 2.221497058868408
[1, 17004] loss_train: 0.003596, loss_test: 0.005578
time: 0.2450547218322754
time: 2.2054927349090576
[1, 17005] loss_train: 0.005468, loss_test: 0.005574
time: 0.24409818649291992
time: 2.2154951095581055
[1, 17006] loss_train: 0.008812, loss_test: 0.005568
time: 0.2454380989074707
time: 2.2224974632263184
[1, 17007] loss_train: 0.006839, loss_test: 0.005565
time: 0.24405479431152344
time: 2.207493305206299
[1, 17008] loss_train: 0.002425, loss_test: 0.005565
time: 0.24405384063720703
time: 2.2115302085876465
[1, 17009] loss_train: 0.003769, loss_test: 0.005568
time: 0.24405407905578613
time: 2.197491407394409
[1, 17010] loss_train: 0.007147, loss_test: 0.005569
time: 0.2580568790435791
time: 2.2415053844451904
[1, 17011] loss_train: 0.003336, loss_test: 0.005570
time: 0.24405384063720703
time: 2.232499837875366
[1, 17012] loss_train: 0.005868, loss_test: 0.005571
time: 0.24505400657653809
time: 2.2224974632263184
[1, 17013] loss_train: 0.006714, loss_test: 0.005573
time: 0.24605417251586914
time: 2.2505040168762207
[1, 17014] loss_train: 0.005050, loss_test: 0.005576
time: 0.24505400657653809
time: 2.2305104732513428
[1, 17015] loss_train: 0.006856, loss_test: 0.005578
time: 0.24605464935302734
time: 2.2555041313171387
[1, 17016] loss_train: 0.010711, loss_test: 0.005584
time: 0.249558687210083
time: 2.2445104122161865
[1, 17017] loss_train: 0.004339, loss_test: 0.005590
time: 0.2450542449951172
time: 2.2214972972869873
[1, 17018] loss_train: 0.003589, loss_test: 0.005590
time: 0.2470550537109375
time: 2.246502161026001
[1, 17019] loss_train: 0.003296, loss_test: 0.005585
time: 0.24505376815795898
time: 2.2385010719299316
[1, 17020] loss_train: 0.016019, loss_test: 0.005579
time: 0.2600574493408203
time: 2.2615063190460205
[1, 17021] loss_train: 0.010795, loss_test: 0.005575
time: 0.24605441093444824
time: 2.2174971103668213
[1, 17022] loss_train: 0.010126, loss_test: 0.005572
time: 0.24605345726013184
time: 2.244502544403076
[1, 17023] loss_train: 0.004808, loss_test: 0.005569
time: 0.24605417251586914
time: 2.2355000972747803
[1, 17024] loss_train: 0.011397, loss_test: 0.005569
time: 0.24605512619018555
time: 2.2445197105407715
[1, 17025] loss_train: 0.002563, loss_test: 0.005570
time: 0.24405431747436523
time: 2.2324986457824707
[1, 17026] loss_train: 0.003830, loss_test: 0.005570
time: 0.2450542449951172
time: 2.210054874420166
[1, 17027] loss_train: 0.008003, loss_test: 0.005568
time: 0.24306678771972656
time: 2.210494041442871
[1, 17028] loss_train: 0.005024, loss_test: 0.005565
time: 0.2450547218322754
time: 2.2114946842193604
[1, 17029] loss_train: 0.004153, loss_test: 0.005564
time: 0.2435760498046875
time: 2.203493118286133
[1, 17030] loss_train: 0.007414, loss_test: 0.005564
time: 0.26105833053588867
time: 2.272508382797241
[1, 17031] loss_train: 0.008821, loss_test: 0.005567
time: 0.2460784912109375
time: 2.2079997062683105
[1, 17032] loss_train: 0.005930, loss_test: 0.005571
time: 0.24405431747436523
time: 2.231501579284668
[1, 17033] loss_train: 0.007755, loss_test: 0.005580
time: 0.24405455589294434
time: 2.213498830795288
[1, 17034] loss_train: 0.002178, loss_test: 0.005589
time: 0.24605512619018555
time: 2.2044928073883057
[1, 17035] loss_train: 0.006557, loss_test: 0.005598
time: 0.24305438995361328
time: 2.255695343017578
[1, 17036] loss_train: 0.001067, loss_test: 0.005610
time: 0.24405336380004883
time: 2.2004928588867188
[1, 17037] loss_train: 0.002101, loss_test: 0.005624
time: 0.2470550537109375
time: 2.210494041442871
[1, 17038] loss_train: 0.004605, loss_test: 0.005629
time: 0.24405455589294434
time: 2.2365002632141113
[1, 17039] loss_train: 0.005374, loss_test: 0.005634
time: 0.2450547218322754
time: 2.2415030002593994
[1, 17040] loss_train: 0.007014, loss_test: 0.005637
time: 0.2580573558807373
time: 2.2955596446990967
[1, 17041] loss_train: 0.003636, loss_test: 0.005636
time: 0.24605536460876465
time: 2.1924901008605957
[1, 17042] loss_train: 0.008285, loss_test: 0.005624
time: 0.24406671524047852
time: 2.215496063232422
[1, 17043] loss_train: 0.008688, loss_test: 0.005603
time: 0.24605393409729004
time: 2.2375009059906006
[1, 17044] loss_train: 0.007269, loss_test: 0.005581
time: 0.24505400657653809
time: 2.210998773574829
[1, 17045] loss_train: 0.000997, loss_test: 0.005570
time: 0.24505400657653809
time: 2.24800968170166
[1, 17046] loss_train: 0.009106, loss_test: 0.005569
time: 0.24406719207763672
time: 2.2385029792785645
[1, 17047] loss_train: 0.008000, loss_test: 0.005574
time: 0.24505400657653809
time: 2.2365007400512695
[1, 17048] loss_train: 0.005768, loss_test: 0.005584
time: 0.24405407905578613
time: 2.230499267578125
[1, 17049] loss_train: 0.003653, loss_test: 0.005589
time: 0.24605512619018555
time: 2.2265002727508545
[1, 17050] loss_train: 0.015449, loss_test: 0.005591
time: 0.258056640625
time: 2.23850154876709
[1, 17051] loss_train: 0.004261, loss_test: 0.005584
time: 0.2470545768737793
time: 2.23403263092041
[1, 17052] loss_train: 0.003924, loss_test: 0.005570
time: 0.24306559562683105
time: 2.230499744415283
[1, 17053] loss_train: 0.006921, loss_test: 0.005560
time: 0.24405431747436523
time: 2.2154951095581055
[1, 17054] loss_train: 0.001049, loss_test: 0.005557
time: 0.2470543384552002
time: 2.2335000038146973
[1, 17055] loss_train: 0.003772, loss_test: 0.005557
time: 0.24605536460876465
time: 2.2135040760040283
[1, 17056] loss_train: 0.004562, loss_test: 0.005564
time: 0.24405384063720703
time: 2.20949649810791
[1, 17057] loss_train: 0.005536, loss_test: 0.005577
time: 0.24564552307128906
time: 2.221497058868408
[1, 17058] loss_train: 0.002379, loss_test: 0.005593
time: 0.2490549087524414
time: 2.2335002422332764
[1, 17059] loss_train: 0.007917, loss_test: 0.005596
time: 0.24405622482299805
time: 2.2295069694519043
[1, 17060] loss_train: 0.002685, loss_test: 0.005601
time: 0.25905847549438477
time: 2.25850510597229
[1, 17061] loss_train: 0.007375, loss_test: 0.005603
time: 0.2470550537109375
time: 2.2470157146453857
[1, 17062] loss_train: 0.006019, loss_test: 0.005595
time: 0.24805474281311035
time: 2.23453426361084
[1, 17063] loss_train: 0.003905, loss_test: 0.005590
time: 0.24405360221862793
time: 2.2435014247894287
[1, 17064] loss_train: 0.003083, loss_test: 0.005588
time: 0.2490546703338623
time: 2.2104949951171875
[1, 17065] loss_train: 0.011374, loss_test: 0.005575
time: 0.24505376815795898
time: 2.2134974002838135
[1, 17066] loss_train: 0.006890, loss_test: 0.005565
time: 0.24405407905578613
time: 2.2104949951171875
[1, 17067] loss_train: 0.011186, loss_test: 0.005551
time: 0.2450547218322754
time: 2.1954925060272217
[1, 17068] loss_train: 0.000903, loss_test: 0.005545
time: 0.24762272834777832
time: 2.2104945182800293
[1, 17069] loss_train: 0.006563, loss_test: 0.005542
time: 0.2440659999847412
time: 2.2094950675964355
[1, 17070] loss_train: 0.005859, loss_test: 0.005545
time: 0.2560560703277588
time: 2.2445015907287598
[1, 17071] loss_train: 0.011138, loss_test: 0.005554
time: 0.24605441093444824
time: 2.2234976291656494
[1, 17072] loss_train: 0.005423, loss_test: 0.005566
time: 0.24305367469787598
time: 2.2345004081726074
[1, 17073] loss_train: 0.004377, loss_test: 0.005573
time: 0.24405455589294434
time: 2.245006799697876
[1, 17074] loss_train: 0.003204, loss_test: 0.005576
time: 0.24205327033996582
time: 2.2385003566741943
[1, 17075] loss_train: 0.000490, loss_test: 0.005576
time: 0.24405360221862793
time: 2.2294983863830566
[1, 17076] loss_train: 0.010007, loss_test: 0.005577
time: 0.24207782745361328
time: 2.20849347114563
[1, 17077] loss_train: 0.005295, loss_test: 0.005567
time: 0.24405407905578613
time: 2.227509021759033
[1, 17078] loss_train: 0.004587, loss_test: 0.005553
time: 0.24405455589294434
time: 2.2525038719177246
[1, 17079] loss_train: 0.005557, loss_test: 0.005543
time: 0.24805545806884766
time: 2.245847225189209
[1, 17080] loss_train: 0.004353, loss_test: 0.005536
time: 0.2580571174621582
time: 2.2495033740997314
[1, 17081] loss_train: 0.004843, loss_test: 0.005537
time: 0.2510557174682617
time: 2.219372034072876
[1, 17082] loss_train: 0.007473, loss_test: 0.005540
time: 0.24405431747436523
time: 2.228501081466675
[1, 17083] loss_train: 0.004738, loss_test: 0.005548
time: 0.2470543384552002
time: 2.2375032901763916
[1, 17084] loss_train: 0.003780, loss_test: 0.005557
time: 0.24505400657653809
time: 2.2715084552764893
[1, 17085] loss_train: 0.005068, loss_test: 0.005568
time: 0.24805545806884766
time: 2.231498956680298
[1, 17086] loss_train: 0.000434, loss_test: 0.005584
time: 0.24605393409729004
time: 2.2385010719299316
[1, 17087] loss_train: 0.003611, loss_test: 0.005603
time: 0.24805498123168945
time: 2.253504514694214
[1, 17088] loss_train: 0.011869, loss_test: 0.005607
time: 0.2450544834136963
time: 2.2244975566864014
[1, 17089] loss_train: 0.010371, loss_test: 0.005596
time: 0.2470557689666748
time: 2.211998224258423
[1, 17090] loss_train: 0.004383, loss_test: 0.005585
time: 0.2560567855834961
time: 2.2585055828094482
[1, 17091] loss_train: 0.002540, loss_test: 0.005578
time: 0.24805545806884766
time: 2.271509885787964
[1, 17092] loss_train: 0.004885, loss_test: 0.005565
time: 0.24505376815795898
time: 2.2274985313415527
[1, 17093] loss_train: 0.014940, loss_test: 0.005552
time: 0.24305510520935059
time: 2.2154953479766846
[1, 17094] loss_train: 0.005494, loss_test: 0.005546
time: 0.24405360221862793
time: 2.2244980335235596
[1, 17095] loss_train: 0.008014, loss_test: 0.005545
time: 0.24405431747436523
time: 2.208282470703125
[1, 17096] loss_train: 0.007777, loss_test: 0.005552
time: 0.24405670166015625
time: 2.215496063232422
[1, 17097] loss_train: 0.010429, loss_test: 0.005561
time: 0.25005578994750977
time: 2.217496156692505
[1, 17098] loss_train: 0.004268, loss_test: 0.005569
time: 0.2470700740814209
time: 2.2355003356933594
[1, 17099] loss_train: 0.005327, loss_test: 0.005576
time: 0.24405360221862793
time: 2.214495897293091
[1, 17100] loss_train: 0.006611, loss_test: 0.005577
time: 0.2565946578979492
time: 2.2715086936950684
[1, 17101] loss_train: 0.001425, loss_test: 0.005574
time: 0.2450542449951172
time: 2.233510971069336
[1, 17102] loss_train: 0.005841, loss_test: 0.005569
time: 0.24606680870056152
time: 2.219496726989746
[1, 17103] loss_train: 0.006702, loss_test: 0.005563
time: 0.2440800666809082
time: 2.2365000247955322
[1, 17104] loss_train: 0.008515, loss_test: 0.005557
time: 0.2450544834136963
time: 2.2154951095581055
[1, 17105] loss_train: 0.008582, loss_test: 0.005552
time: 0.2450542449951172
time: 2.2335000038146973
[1, 17106] loss_train: 0.007295, loss_test: 0.005549
time: 0.24805474281311035
time: 2.2385010719299316
[1, 17107] loss_train: 0.007870, loss_test: 0.005548
time: 0.24406766891479492
time: 2.2595152854919434
[1, 17108] loss_train: 0.001616, loss_test: 0.005547
time: 0.24856209754943848
time: 2.256504774093628
[1, 17109] loss_train: 0.008444, loss_test: 0.005547
time: 0.24509739875793457
time: 2.2234976291656494
[1, 17110] loss_train: 0.006609, loss_test: 0.005548
time: 0.26405811309814453
time: 2.2735085487365723
[1, 17111] loss_train: 0.016484, loss_test: 0.005548
time: 0.2490558624267578
time: 2.2385003566741943
[1, 17112] loss_train: 0.004997, loss_test: 0.005549
time: 0.2490551471710205
time: 2.2234995365142822
[1, 17113] loss_train: 0.001891, loss_test: 0.005551
time: 0.24405360221862793
time: 2.2335002422332764
[1, 17114] loss_train: 0.010054, loss_test: 0.005553
time: 0.2490549087524414
time: 2.2345001697540283
[1, 17115] loss_train: 0.010014, loss_test: 0.005553
time: 0.2450542449951172
time: 2.2153401374816895
[1, 17116] loss_train: 0.012393, loss_test: 0.005551
time: 0.24805450439453125
time: 2.221501111984253
[1, 17117] loss_train: 0.004316, loss_test: 0.005552
time: 0.24605464935302734
time: 2.219496488571167
[1, 17118] loss_train: 0.006974, loss_test: 0.005555
time: 0.24805450439453125
time: 2.229499101638794
[1, 17119] loss_train: 0.004956, loss_test: 0.005557
time: 0.24305343627929688
time: 2.2455027103424072
[1, 17120] loss_train: 0.005009, loss_test: 0.005562
time: 0.25705671310424805
time: 2.252504348754883
[1, 17121] loss_train: 0.006545, loss_test: 0.005564
time: 0.25005507469177246
time: 2.215496301651001
[1, 17122] loss_train: 0.003108, loss_test: 0.005567
time: 0.24505400657653809
time: 2.2505037784576416
[1, 17123] loss_train: 0.004524, loss_test: 0.005569
time: 0.24605512619018555
time: 2.262505292892456
[1, 17124] loss_train: 0.005992, loss_test: 0.005571
time: 0.24605560302734375
time: 2.237499952316284
[1, 17125] loss_train: 0.003027, loss_test: 0.005572
time: 0.24506425857543945
time: 2.209493637084961
[1, 17126] loss_train: 0.005758, loss_test: 0.005569
time: 0.24605536460876465
time: 2.271507740020752
[1, 17127] loss_train: 0.004241, loss_test: 0.005565
time: 0.2910637855529785
time: 2.3575279712677
[1, 17128] loss_train: 0.003354, loss_test: 0.005567
time: 0.26105785369873047
time: 2.2525031566619873
[1, 17129] loss_train: 0.006239, loss_test: 0.005567
time: 0.25005626678466797
time: 2.257580280303955
[1, 17130] loss_train: 0.017636, loss_test: 0.005560
time: 0.2620828151702881
time: 2.238004446029663
[1, 17131] loss_train: 0.008459, loss_test: 0.005552
time: 0.24605417251586914
time: 2.2655069828033447
[1, 17132] loss_train: 0.008553, loss_test: 0.005548
time: 0.25005507469177246
time: 2.2765095233917236
[1, 17133] loss_train: 0.005898, loss_test: 0.005549
time: 0.24805426597595215
time: 2.303515911102295
[1, 17134] loss_train: 0.011092, loss_test: 0.005553
time: 0.24806880950927734
time: 2.282510280609131
[1, 17135] loss_train: 0.005294, loss_test: 0.005557
time: 0.2470552921295166
time: 2.260505199432373
[1, 17136] loss_train: 0.006440, loss_test: 0.005563
time: 0.24405384063720703
time: 2.258504867553711
[1, 17137] loss_train: 0.010084, loss_test: 0.005567
time: 0.24506878852844238
time: 2.276508331298828
[1, 17138] loss_train: 0.003621, loss_test: 0.005567
time: 0.2450549602508545
time: 2.2505102157592773
[1, 17139] loss_train: 0.002020, loss_test: 0.005567
time: 0.252056360244751
time: 2.28251051902771
[1, 17140] loss_train: 0.005365, loss_test: 0.005566
time: 0.2580580711364746
time: 2.19749116897583
[1, 17141] loss_train: 0.005824, loss_test: 0.005564
time: 0.24605488777160645
time: 2.220496654510498
[1, 17142] loss_train: 0.004075, loss_test: 0.005558
time: 0.2580575942993164
time: 2.2755088806152344
[1, 17143] loss_train: 0.008016, loss_test: 0.005553
time: 0.24405360221862793
time: 2.3075168132781982
[1, 17144] loss_train: 0.007806, loss_test: 0.005549
time: 0.26605939865112305
time: 2.2585177421569824
[1, 17145] loss_train: 0.005373, loss_test: 0.005549
time: 0.2580568790435791
time: 2.304515838623047
[1, 17146] loss_train: 0.002333, loss_test: 0.005555
time: 0.25705671310424805
time: 2.2655069828033447
[1, 17147] loss_train: 0.002774, loss_test: 0.005567
time: 0.2540566921234131
time: 2.281015157699585
[1, 17148] loss_train: 0.013316, loss_test: 0.005570
time: 0.2450542449951172
time: 2.22650408744812
[1, 17149] loss_train: 0.006191, loss_test: 0.005575
time: 0.24305438995361328
time: 2.19649076461792
[1, 17150] loss_train: 0.004441, loss_test: 0.005580
time: 0.25705695152282715
time: 2.196504831314087
[1, 17151] loss_train: 0.007293, loss_test: 0.005576
time: 0.24409079551696777
time: 2.204493522644043
[1, 17152] loss_train: 0.005147, loss_test: 0.005567
time: 0.24405384063720703
time: 2.212123394012451
[1, 17153] loss_train: 0.005297, loss_test: 0.005561
time: 0.2450549602508545
time: 2.2254974842071533
[1, 17154] loss_train: 0.002452, loss_test: 0.005556
time: 0.24605417251586914
time: 2.2155048847198486
[1, 17155] loss_train: 0.005460, loss_test: 0.005553
time: 0.24305343627929688
time: 2.228498697280884
[1, 17156] loss_train: 0.002736, loss_test: 0.005551
time: 0.24805474281311035
time: 2.2244982719421387
[1, 17157] loss_train: 0.004662, loss_test: 0.005550
time: 0.24606680870056152
time: 2.2224974632263184
[1, 17158] loss_train: 0.002380, loss_test: 0.005551
time: 0.25005531311035156
time: 2.229498863220215
[1, 17159] loss_train: 0.003251, loss_test: 0.005553
time: 0.24305415153503418
time: 2.220496892929077
[1, 17160] loss_train: 0.005244, loss_test: 0.005555
time: 0.2580568790435791
time: 2.2585229873657227
[1, 17161] loss_train: 0.009441, loss_test: 0.005558
time: 0.24305391311645508
time: 2.1914985179901123
[1, 17162] loss_train: 0.010578, loss_test: 0.005559
time: 0.24405479431152344
time: 2.2154951095581055
[1, 17163] loss_train: 0.004550, loss_test: 0.005560
time: 0.24605441093444824
time: 2.218496084213257
[1, 17164] loss_train: 0.015836, loss_test: 0.005560
time: 0.24605417251586914
time: 2.2425014972686768
[1, 17165] loss_train: 0.002450, loss_test: 0.005562
time: 0.2450547218322754
time: 2.210059404373169
[1, 17166] loss_train: 0.006568, loss_test: 0.005564
time: 0.24305438995361328
time: 2.223496913909912
[1, 17167] loss_train: 0.007430, loss_test: 0.005565
time: 0.24305391311645508
time: 2.2405011653900146
[1, 17168] loss_train: 0.004013, loss_test: 0.005569
time: 0.24405384063720703
time: 2.2395012378692627
[1, 17169] loss_train: 0.008983, loss_test: 0.005569
time: 0.24405384063720703
time: 2.2254984378814697
[1, 17170] loss_train: 0.010656, loss_test: 0.005562
time: 0.25705695152282715
time: 2.244501829147339
[1, 17171] loss_train: 0.006743, loss_test: 0.005556
time: 0.2460949420928955
time: 2.232499361038208
[1, 17172] loss_train: 0.007193, loss_test: 0.005554
time: 0.24605464935302734
time: 2.2312560081481934
[1, 17173] loss_train: 0.006997, loss_test: 0.005551
time: 0.24605441093444824
time: 2.231499433517456
[1, 17174] loss_train: 0.006044, loss_test: 0.005551
time: 0.24405407905578613
time: 2.2280008792877197
[1, 17175] loss_train: 0.005701, loss_test: 0.005551
time: 0.2470560073852539
time: 2.1894893646240234
[1, 17176] loss_train: 0.007904, loss_test: 0.005551
time: 0.24305295944213867
time: 2.2004926204681396
[1, 17177] loss_train: 0.002435, loss_test: 0.005551
time: 0.2450542449951172
time: 2.208494186401367
[1, 17178] loss_train: 0.010610, loss_test: 0.005550
time: 0.24807095527648926
time: 2.225512981414795
[1, 17179] loss_train: 0.012569, loss_test: 0.005550
time: 0.2450549602508545
time: 2.237501621246338
[1, 17180] loss_train: 0.008622, loss_test: 0.005552
time: 0.25705790519714355
time: 2.2284979820251465
[1, 17181] loss_train: 0.003369, loss_test: 0.005554
time: 0.24405479431152344
time: 2.221496343612671
[1, 17182] loss_train: 0.012771, loss_test: 0.005567
time: 0.2450549602508545
time: 2.273413896560669
[1, 17183] loss_train: 0.003942, loss_test: 0.005576
time: 0.26605939865112305
time: 2.2425150871276855
[1, 17184] loss_train: 0.003395, loss_test: 0.005575
time: 0.24405407905578613
time: 2.2465028762817383
[1, 17185] loss_train: 0.003489, loss_test: 0.005563
time: 0.2470548152923584
time: 2.247502565383911
[1, 17186] loss_train: 0.004019, loss_test: 0.005553
time: 0.24405431747436523
time: 2.223497152328491
[1, 17187] loss_train: 0.003656, loss_test: 0.005544
time: 0.24405384063720703
time: 2.238508939743042
[1, 17188] loss_train: 0.005482, loss_test: 0.005541
time: 0.24605512619018555
time: 2.2134947776794434
[1, 17189] loss_train: 0.007560, loss_test: 0.005545
time: 0.24507522583007812
time: 2.2295031547546387
[1, 17190] loss_train: 0.013824, loss_test: 0.005546
time: 0.256056547164917
time: 2.2345023155212402
[1, 17191] loss_train: 0.007362, loss_test: 0.005546
time: 0.24305367469787598
time: 2.227498769760132
[1, 17192] loss_train: 0.003211, loss_test: 0.005546
time: 0.24305367469787598
time: 2.23600697517395
[1, 17193] loss_train: 0.004954, loss_test: 0.005546
time: 0.2450544834136963
time: 2.2004923820495605
[1, 17194] loss_train: 0.004339, loss_test: 0.005547
time: 0.2470545768737793
time: 2.247502565383911
[1, 17195] loss_train: 0.009241, loss_test: 0.005546
time: 0.2470552921295166
time: 2.20749568939209
[1, 17196] loss_train: 0.004709, loss_test: 0.005546
time: 0.24706006050109863
time: 2.206519603729248
[1, 17197] loss_train: 0.006229, loss_test: 0.005545
time: 0.24405360221862793
time: 2.253504514694214
[1, 17198] loss_train: 0.004749, loss_test: 0.005546
time: 0.24505400657653809
time: 2.244502305984497
[1, 17199] loss_train: 0.003570, loss_test: 0.005547
time: 0.24409222602844238
time: 2.228018045425415
[1, 17200] loss_train: 0.014676, loss_test: 0.005547
time: 0.2580578327178955
time: 2.263505220413208
[1, 17201] loss_train: 0.006900, loss_test: 0.005546
time: 0.2450556755065918
time: 2.198491096496582
[1, 17202] loss_train: 0.010320, loss_test: 0.005546
time: 0.24506616592407227
time: 2.214495897293091
[1, 17203] loss_train: 0.001468, loss_test: 0.005547
time: 0.24505400657653809
time: 2.2365024089813232
[1, 17204] loss_train: 0.006015, loss_test: 0.005549
time: 0.24405384063720703
time: 2.2250120639801025
[1, 17205] loss_train: 0.010466, loss_test: 0.005552
time: 0.24605464935302734
time: 2.22049880027771
[1, 17206] loss_train: 0.002453, loss_test: 0.005553
time: 0.2450547218322754
time: 2.2415013313293457
[1, 17207] loss_train: 0.003496, loss_test: 0.005554
time: 0.24505376815795898
time: 2.2014927864074707
[1, 17208] loss_train: 0.005550, loss_test: 0.005553
time: 0.24605393409729004
time: 2.229499101638794
[1, 17209] loss_train: 0.013874, loss_test: 0.005551
time: 0.2470543384552002
time: 2.241018533706665
[1, 17210] loss_train: 0.009960, loss_test: 0.005548
time: 0.25505542755126953
time: 2.2645063400268555
[1, 17211] loss_train: 0.004033, loss_test: 0.005547
time: 0.24605464935302734
time: 2.1904897689819336
[1, 17212] loss_train: 0.003050, loss_test: 0.005548
time: 0.2490551471710205
time: 2.2365005016326904
[1, 17213] loss_train: 0.007590, loss_test: 0.005554
time: 0.24405384063720703
time: 2.243504524230957
[1, 17214] loss_train: 0.012531, loss_test: 0.005562
time: 0.25505661964416504
time: 2.2295005321502686
[1, 17215] loss_train: 0.010723, loss_test: 0.005570
time: 0.24605417251586914
time: 2.371652603149414
[1, 17216] loss_train: 0.005846, loss_test: 0.005579
time: 0.42087769508361816
time: 3.3467345237731934
[1, 17217] loss_train: 0.008236, loss_test: 0.005579
time: 0.3690798282623291
time: 3.288738250732422
[1, 17218] loss_train: 0.005627, loss_test: 0.005579
time: 0.38813185691833496
time: 3.273569345474243
[1, 17219] loss_train: 0.000446, loss_test: 0.005581
time: 0.3740568161010742
time: 3.2979907989501953
[1, 17220] loss_train: 0.008367, loss_test: 0.005583
time: 0.42513513565063477
time: 3.2605373859405518
[1, 17221] loss_train: 0.004618, loss_test: 0.005580
time: 0.37111854553222656
time: 3.2125298976898193
[1, 17222] loss_train: 0.006520, loss_test: 0.005578
time: 0.3780841827392578
time: 3.2423548698425293
[1, 17223] loss_train: 0.004243, loss_test: 0.005578
time: 0.36808013916015625
time: 3.249401807785034
[1, 17224] loss_train: 0.014035, loss_test: 0.005578
time: 0.37700533866882324
time: 3.203606605529785
[1, 17225] loss_train: 0.008701, loss_test: 0.005572
time: 0.3834066390991211
time: 3.207777261734009
[1, 17226] loss_train: 0.006661, loss_test: 0.005567
time: 0.3740818500518799
time: 3.265048027038574
[1, 17227] loss_train: 0.006656, loss_test: 0.005565
time: 0.374586820602417
time: 3.2301275730133057
[1, 17228] loss_train: 0.004480, loss_test: 0.005563
time: 0.3710637092590332
time: 2.8377573490142822
[1, 17229] loss_train: 0.002521, loss_test: 0.005564
time: 0.24505949020385742
time: 2.1974918842315674
[1, 17230] loss_train: 0.002017, loss_test: 0.005566
time: 0.2580573558807373
time: 2.2094943523406982
[1, 17231] loss_train: 0.006125, loss_test: 0.005570
time: 0.24305510520935059
time: 2.2064929008483887
[1, 17232] loss_train: 0.003118, loss_test: 0.005577
time: 0.24505376815795898
time: 2.2445054054260254
[1, 17233] loss_train: 0.003663, loss_test: 0.005586
time: 0.24305438995361328
time: 2.2294986248016357
[1, 17234] loss_train: 0.008158, loss_test: 0.005597
time: 0.24205303192138672
time: 2.2795097827911377
[1, 17235] loss_train: 0.014622, loss_test: 0.005588
time: 0.2490544319152832
time: 2.4025378227233887
[1, 17236] loss_train: 0.007707, loss_test: 0.005580
time: 0.2580571174621582
time: 2.306516170501709
[1, 17237] loss_train: 0.006030, loss_test: 0.005572
time: 0.2600588798522949
time: 2.275012731552124
[1, 17238] loss_train: 0.005663, loss_test: 0.005567
time: 0.2490556240081787
time: 2.303516387939453
[1, 17239] loss_train: 0.002503, loss_test: 0.005563
time: 0.2600560188293457
time: 2.2325048446655273
[1, 17240] loss_train: 0.006903, loss_test: 0.005561
time: 0.25707077980041504
time: 2.244501829147339
[1, 17241] loss_train: 0.003046, loss_test: 0.005561
time: 0.2490556240081787
time: 2.32612681388855
[1, 17242] loss_train: 0.011002, loss_test: 0.005558
time: 0.2510552406311035
time: 2.2975142002105713
[1, 17243] loss_train: 0.007171, loss_test: 0.005558
time: 0.2530558109283447
time: 2.3485257625579834
[1, 17244] loss_train: 0.005663, loss_test: 0.005558
time: 0.25205564498901367
time: 2.306516170501709
[1, 17245] loss_train: 0.001071, loss_test: 0.005558
time: 0.2520558834075928
time: 2.240501642227173
[1, 17246] loss_train: 0.004610, loss_test: 0.005559
time: 0.24605464935302734
time: 2.2915124893188477
[1, 17247] loss_train: 0.012503, loss_test: 0.005556
time: 0.2720606327056885
time: 2.323274612426758
[1, 17248] loss_train: 0.003367, loss_test: 0.005554
time: 0.3000662326812744
time: 2.470564365386963
[1, 17249] loss_train: 0.003229, loss_test: 0.005555
time: 0.24605393409729004
time: 2.290512800216675
[1, 17250] loss_train: 0.006924, loss_test: 0.005553
time: 0.29306554794311523
time: 2.3825323581695557
[1, 17251] loss_train: 0.006140, loss_test: 0.005551
time: 0.29006505012512207
time: 2.446546792984009
[1, 17252] loss_train: 0.003669, loss_test: 0.005554
time: 0.30406737327575684
time: 2.611211061477661
[1, 17253] loss_train: 0.001726, loss_test: 0.005558
time: 0.32910871505737305
time: 2.750215768814087
[1, 17254] loss_train: 0.003965, loss_test: 0.005563
time: 0.6110851764678955
time: 2.7796220779418945
[1, 17255] loss_train: 0.004186, loss_test: 0.005569
time: 0.2990763187408447
time: 2.871629238128662
[1, 17256] loss_train: 0.003072, loss_test: 0.005576
time: 0.28088951110839844
time: 2.6025829315185547
[1, 17257] loss_train: 0.003884, loss_test: 0.005584
time: 0.29906558990478516
time: 2.5135626792907715
[1, 17258] loss_train: 0.011335, loss_test: 0.005588
time: 0.2870635986328125
time: 2.836702585220337
[1, 17259] loss_train: 0.007522, loss_test: 0.005588
time: 0.29306483268737793
time: 2.7862939834594727
[1, 17260] loss_train: 0.002996, loss_test: 0.005590
time: 0.3000667095184326
time: 3.0826897621154785
[1, 17261] loss_train: 0.005155, loss_test: 0.005589
time: 0.2940652370452881
time: 2.4967496395111084
[1, 17262] loss_train: 0.004798, loss_test: 0.005588
time: 0.2980666160583496
time: 2.6644175052642822
[1, 17263] loss_train: 0.007562, loss_test: 0.005584
time: 0.28806400299072266
time: 2.7535622119903564
[1, 17264] loss_train: 0.004789, loss_test: 0.005576
time: 0.2848842144012451
time: 2.5606026649475098
[1, 17265] loss_train: 0.000434, loss_test: 0.005572
time: 0.28406333923339844
time: 2.6415958404541016
[1, 17266] loss_train: 0.004959, loss_test: 0.005567
time: 0.35007762908935547
time: 2.5828514099121094
[1, 17267] loss_train: 0.006717, loss_test: 0.005563
time: 0.2810628414154053
time: 2.5665807723999023
[1, 17268] loss_train: 0.007793, loss_test: 0.005556
time: 0.2725372314453125
time: 2.4693944454193115
[1, 17269] loss_train: 0.003884, loss_test: 0.005553
time: 0.2780618667602539
time: 2.684615135192871
[1, 17270] loss_train: 0.002186, loss_test: 0.005555
time: 0.3317265510559082
time: 2.5174221992492676
[1, 17271] loss_train: 0.010039, loss_test: 0.005553
time: 0.2890639305114746
time: 2.4745538234710693
[1, 17272] loss_train: 0.006335, loss_test: 0.005553
time: 0.27706146240234375
time: 2.750617027282715
[1, 17273] loss_train: 0.009390, loss_test: 0.005557
time: 0.2850635051727295
time: 2.4858739376068115
[1, 17274] loss_train: 0.003130, loss_test: 0.005561
time: 0.2810628414154053
time: 2.6269845962524414
[1, 17275] loss_train: 0.001512, loss_test: 0.005568
time: 0.29503679275512695
time: 2.5303468704223633
[1, 17276] loss_train: 0.007458, loss_test: 0.005573
time: 0.2850630283355713
time: 2.5054032802581787
[1, 17277] loss_train: 0.008233, loss_test: 0.005578
time: 0.27506160736083984
time: 2.5710344314575195
[1, 17278] loss_train: 0.003067, loss_test: 0.005583
time: 0.2800619602203369
time: 2.4635515213012695
[1, 17279] loss_train: 0.004823, loss_test: 0.005591
time: 0.27306127548217773
time: 3.0632874965667725
[1, 17280] loss_train: 0.003517, loss_test: 0.005600
time: 0.3070676326751709
time: 2.470553159713745
[1, 17281] loss_train: 0.005561, loss_test: 0.005607
time: 0.2830629348754883
time: 2.5580008029937744
[1, 17282] loss_train: 0.005475, loss_test: 0.005611
time: 0.2850625514984131
time: 2.608586549758911
[1, 17283] loss_train: 0.013109, loss_test: 0.005608
time: 0.2905747890472412
time: 2.5183842182159424
[1, 17284] loss_train: 0.011201, loss_test: 0.005598
time: 0.2870635986328125
time: 2.5074143409729004
[1, 17285] loss_train: 0.006884, loss_test: 0.005589
time: 0.2830634117126465
time: 2.6496896743774414
[1, 17286] loss_train: 0.009953, loss_test: 0.005579
time: 0.2809736728668213
time: 2.5014655590057373
[1, 17287] loss_train: 0.014679, loss_test: 0.005570
time: 0.2930641174316406
time: 2.523564338684082
[1, 17288] loss_train: 0.003232, loss_test: 0.005568
time: 0.278062105178833
time: 2.5685904026031494
[1, 17289] loss_train: 0.005055, loss_test: 0.005569
time: 0.2780616283416748
time: 2.6615700721740723
[1, 17290] loss_train: 0.002312, loss_test: 0.005570
time: 0.2940835952758789
time: 2.5215799808502197
[1, 17291] loss_train: 0.011654, loss_test: 0.005571
time: 0.2756471633911133
time: 2.615182876586914
[1, 17292] loss_train: 0.004296, loss_test: 0.005568
time: 0.2850637435913086
time: 2.4905569553375244
[1, 17293] loss_train: 0.007236, loss_test: 0.005564
time: 0.28606343269348145
time: 2.522979259490967
[1, 17294] loss_train: 0.005991, loss_test: 0.005559
time: 0.286055326461792
time: 2.554943084716797
[1, 17295] loss_train: 0.000840, loss_test: 0.005552
time: 0.27989959716796875
time: 2.5301289558410645
[1, 17296] loss_train: 0.005730, loss_test: 0.005547
time: 0.28606343269348145
time: 2.543562889099121
[1, 17297] loss_train: 0.010435, loss_test: 0.005545
time: 0.2930641174316406
time: 2.6235806941986084
[1, 17298] loss_train: 0.003978, loss_test: 0.005544
time: 0.2756612300872803
time: 2.5141799449920654
[1, 17299] loss_train: 0.006447, loss_test: 0.005543
time: 0.29506564140319824
time: 2.702943801879883
[1, 17300] loss_train: 0.002415, loss_test: 0.005543
time: 0.2996671199798584
time: 2.5655734539031982
[1, 17301] loss_train: 0.009148, loss_test: 0.005545
time: 0.2960648536682129
time: 2.512850522994995
[1, 17302] loss_train: 0.001346, loss_test: 0.005545
time: 0.27956509590148926
time: 2.586578369140625
[1, 17303] loss_train: 0.003587, loss_test: 0.005549
time: 0.27509403228759766
time: 2.471519947052002
[1, 17304] loss_train: 0.000628, loss_test: 0.005556
time: 0.282062292098999
time: 2.6275880336761475
[1, 17305] loss_train: 0.008690, loss_test: 0.005563
time: 0.28406333923339844
time: 2.4462571144104004
[1, 17306] loss_train: 0.007817, loss_test: 0.005569
time: 0.28676819801330566
time: 2.551091194152832
[1, 17307] loss_train: 0.012615, loss_test: 0.005574
time: 0.29006481170654297
time: 2.7579760551452637
[1, 17308] loss_train: 0.006952, loss_test: 0.005577
time: 0.28106212615966797
time: 2.4931418895721436
[1, 17309] loss_train: 0.008990, loss_test: 0.005574
time: 0.28106236457824707
time: 2.5671210289001465
[1, 17310] loss_train: 0.003691, loss_test: 0.005573
time: 0.30103373527526855
time: 2.534013032913208
[1, 17311] loss_train: 0.003725, loss_test: 0.005571
time: 0.28406405448913574
time: 2.5707459449768066
[1, 17312] loss_train: 0.003124, loss_test: 0.005569
time: 0.28806424140930176
time: 2.616579532623291
[1, 17313] loss_train: 0.004011, loss_test: 0.005567
time: 0.27706098556518555
time: 2.4470534324645996
[1, 17314] loss_train: 0.008873, loss_test: 0.005566
time: 0.28106141090393066
time: 2.543586015701294
[1, 17315] loss_train: 0.000515, loss_test: 0.005567
time: 0.29306483268737793
time: 2.511265277862549
[1, 17316] loss_train: 0.007159, loss_test: 0.005569
time: 0.2890646457672119
time: 2.5913548469543457
[1, 17317] loss_train: 0.007010, loss_test: 0.005570
time: 0.39208221435546875
time: 2.498558759689331
[1, 17318] loss_train: 0.005775, loss_test: 0.005573
time: 0.2820620536804199
time: 2.5295660495758057
[1, 17319] loss_train: 0.009110, loss_test: 0.005575
time: 0.28606343269348145
time: 2.5534708499908447
[1, 17320] loss_train: 0.014074, loss_test: 0.005575
time: 0.29714488983154297
time: 2.5635733604431152
[1, 17321] loss_train: 0.004435, loss_test: 0.005574
time: 0.2830626964569092
time: 2.5501904487609863
[1, 17322] loss_train: 0.010484, loss_test: 0.005572
time: 0.2890636920928955
time: 2.48539662361145
[1, 17323] loss_train: 0.002870, loss_test: 0.005571
time: 0.2861783504486084
time: 2.538522720336914
[1, 17324] loss_train: 0.011655, loss_test: 0.005567
time: 0.27698516845703125
time: 2.5739996433258057
[1, 17325] loss_train: 0.003933, loss_test: 0.005564
time: 0.2980663776397705
time: 2.523564338684082
[1, 17326] loss_train: 0.003408, loss_test: 0.005562
time: 0.27506065368652344
time: 2.7919137477874756
[1, 17327] loss_train: 0.011073, loss_test: 0.005557
time: 0.28806400299072266
time: 2.4941256046295166
[1, 17328] loss_train: 0.005412, loss_test: 0.005553
time: 0.5481092929840088
time: 2.6160221099853516
[1, 17329] loss_train: 0.009513, loss_test: 0.005551
time: 0.2825160026550293
time: 2.604581832885742
[1, 17330] loss_train: 0.009209, loss_test: 0.005552
time: 0.29906702041625977
time: 2.571443557739258
[1, 17331] loss_train: 0.008260, loss_test: 0.005555
time: 0.3480675220489502
time: 2.514002561569214
[1, 17332] loss_train: 0.004252, loss_test: 0.005558
time: 0.2850632667541504
time: 2.8026938438415527
[1, 17333] loss_train: 0.006868, loss_test: 0.005561
time: 0.2910637855529785
time: 2.5204362869262695
[1, 17334] loss_train: 0.003174, loss_test: 0.005563
time: 0.28406357765197754
time: 2.624551296234131
[1, 17335] loss_train: 0.013698, loss_test: 0.005565
time: 0.43208765983581543
time: 2.4995598793029785
[1, 17336] loss_train: 0.001786, loss_test: 0.005561
time: 0.2798285484313965
time: 2.511625051498413
[1, 17337] loss_train: 0.001769, loss_test: 0.005556
time: 0.28606414794921875
time: 2.529099464416504
[1, 17338] loss_train: 0.001432, loss_test: 0.005553
time: 0.2711918354034424
time: 2.4350016117095947
[1, 17339] loss_train: 0.004986, loss_test: 0.005551
time: 0.283341646194458
time: 2.6975293159484863
[1, 17340] loss_train: 0.003882, loss_test: 0.005550
time: 0.29006481170654297
time: 2.473552942276001
[1, 17341] loss_train: 0.006281, loss_test: 0.005550
time: 0.28106212615966797
time: 2.5338611602783203
[1, 17342] loss_train: 0.009326, loss_test: 0.005552
time: 0.28206324577331543
time: 2.6630001068115234
[1, 17343] loss_train: 0.003708, loss_test: 0.005554
time: 0.27506089210510254
time: 2.5881361961364746
[1, 17344] loss_train: 0.002279, loss_test: 0.005559
time: 0.39408302307128906
time: 2.529186725616455
[1, 17345] loss_train: 0.000846, loss_test: 0.005566
time: 0.2720370292663574
time: 2.445833444595337
[1, 17346] loss_train: 0.004525, loss_test: 0.005575
time: 0.27906203269958496
time: 2.4295434951782227
[1, 17347] loss_train: 0.005090, loss_test: 0.005582
time: 0.2780611515045166
time: 2.6021289825439453
[1, 17348] loss_train: 0.005611, loss_test: 0.005590
time: 0.2890636920928955
time: 2.508922815322876
[1, 17349] loss_train: 0.006692, loss_test: 0.005598
time: 0.2730600833892822
time: 2.4495646953582764
[1, 17350] loss_train: 0.005121, loss_test: 0.005608
time: 0.2947218418121338
time: 2.5994670391082764
[1, 17351] loss_train: 0.005015, loss_test: 0.005615
time: 0.3370628356933594
time: 2.51832914352417
[1, 17352] loss_train: 0.002644, loss_test: 0.005620
time: 0.274059534072876
time: 2.4516799449920654
[1, 17353] loss_train: 0.008763, loss_test: 0.005617
time: 0.358079195022583
time: 2.460550308227539
[1, 17354] loss_train: 0.007194, loss_test: 0.005609
time: 0.31708860397338867
time: 2.393033504486084
[1, 17355] loss_train: 0.004918, loss_test: 0.005607
time: 0.26605868339538574
time: 2.2995145320892334
[1, 17356] loss_train: 0.008524, loss_test: 0.005600
time: 0.2740602493286133
time: 2.4665520191192627
[1, 17357] loss_train: 0.002346, loss_test: 0.005594
time: 0.25705718994140625
time: 2.2960188388824463
[1, 17358] loss_train: 0.010601, loss_test: 0.005590
time: 0.26406073570251465
time: 2.297513961791992
[1, 17359] loss_train: 0.013661, loss_test: 0.005579
time: 0.24405431747436523
time: 2.2635066509246826
[1, 17360] loss_train: 0.003622, loss_test: 0.005575
time: 0.27506136894226074
time: 2.2755088806152344
[1, 17361] loss_train: 0.006688, loss_test: 0.005576
time: 0.24805450439453125
time: 2.251291036605835
[1, 17362] loss_train: 0.006881, loss_test: 0.005578
time: 0.26605939865112305
time: 2.426542282104492
[1, 17363] loss_train: 0.005587, loss_test: 0.005579
time: 0.2560572624206543
time: 2.411539316177368
[1, 17364] loss_train: 0.005330, loss_test: 0.005580
time: 0.2540559768676758
time: 2.3545258045196533
[1, 17365] loss_train: 0.006970, loss_test: 0.005579
time: 0.2730600833892822
time: 2.4597527980804443
[1, 17366] loss_train: 0.004086, loss_test: 0.005576
time: 0.27327656745910645
time: 2.4824767112731934
[1, 17367] loss_train: 0.011213, loss_test: 0.005574
time: 0.2850630283355713
time: 2.5275228023529053
[1, 17368] loss_train: 0.003704, loss_test: 0.005569
time: 0.2871851921081543
time: 2.5137319564819336
[1, 17369] loss_train: 0.002621, loss_test: 0.005568
time: 0.30606842041015625
time: 2.3515336513519287
[1, 17370] loss_train: 0.005319, loss_test: 0.005568
time: 0.2600595951080322
time: 2.328169822692871
[1, 17371] loss_train: 0.009060, loss_test: 0.005569
time: 0.2630579471588135
time: 2.279020309448242
[1, 17372] loss_train: 0.006855, loss_test: 0.005570
time: 0.2548329830169678
time: 2.25850510597229
[1, 17373] loss_train: 0.010833, loss_test: 0.005568
time: 0.2510554790496826
time: 2.29296612739563
[1, 17374] loss_train: 0.007618, loss_test: 0.005565
time: 0.2768571376800537
time: 2.35375714302063
[1, 17375] loss_train: 0.002089, loss_test: 0.005563
time: 0.2890639305114746
time: 2.4035379886627197
[1, 17376] loss_train: 0.004518, loss_test: 0.005563
time: 0.25005483627319336
time: 2.2809205055236816
[1, 17377] loss_train: 0.005474, loss_test: 0.005566
time: 0.2510552406311035
time: 2.2540910243988037
[1, 17378] loss_train: 0.006037, loss_test: 0.005566
time: 0.25705695152282715
time: 2.294098138809204
[1, 17379] loss_train: 0.002241, loss_test: 0.005570
time: 0.24605464935302734
time: 2.295417547225952
[1, 17380] loss_train: 0.004967, loss_test: 0.005574
time: 0.26061081886291504
time: 2.2632997035980225
[1, 17381] loss_train: 0.005943, loss_test: 0.005577
time: 0.24712538719177246
time: 2.2482638359069824
[1, 17382] loss_train: 0.003081, loss_test: 0.005582
time: 0.24545907974243164
time: 2.2578914165496826
[1, 17383] loss_train: 0.007861, loss_test: 0.005583
time: 0.24605488777160645
time: 2.2950282096862793
[1, 17384] loss_train: 0.006959, loss_test: 0.005579
time: 0.24405384063720703
time: 2.271198034286499
[1, 17385] loss_train: 0.006816, loss_test: 0.005577
time: 0.24405455589294434
time: 2.2545061111450195
[1, 17386] loss_train: 0.004023, loss_test: 0.005574
time: 0.24405384063720703
time: 2.239191770553589
[1, 17387] loss_train: 0.005072, loss_test: 0.005573
time: 0.24305391311645508
time: 2.2351014614105225
[1, 17388] loss_train: 0.002535, loss_test: 0.005571
time: 0.24991321563720703
time: 2.2790892124176025
[1, 17389] loss_train: 0.005649, loss_test: 0.005566
time: 0.24503612518310547
time: 2.29482364654541
[1, 17390] loss_train: 0.011308, loss_test: 0.005562
time: 0.25505661964416504
time: 2.263989210128784
[1, 17391] loss_train: 0.002545, loss_test: 0.005558
time: 0.24605393409729004
time: 2.5771660804748535
[1, 17392] loss_train: 0.005411, loss_test: 0.005557
time: 0.27005982398986816
time: 2.29062819480896
[1, 17393] loss_train: 0.003445, loss_test: 0.005558
time: 0.24457144737243652
time: 2.2857117652893066
[1, 17394] loss_train: 0.004443, loss_test: 0.005562
time: 0.24805545806884766
time: 2.2523787021636963
[1, 17395] loss_train: 0.002987, loss_test: 0.005566
time: 0.2470545768737793
time: 2.2254436016082764
[1, 17396] loss_train: 0.007196, loss_test: 0.005567
time: 0.24855899810791016
time: 2.2785098552703857
[1, 17397] loss_train: 0.005172, loss_test: 0.005569
time: 0.2450542449951172
time: 2.2254979610443115
[1, 17398] loss_train: 0.006681, loss_test: 0.005571
time: 0.2470545768737793
time: 2.2770116329193115
[1, 17399] loss_train: 0.011397, loss_test: 0.005572
time: 0.25005435943603516
time: 2.330522060394287
[1, 17400] loss_train: 0.004380, loss_test: 0.005570
time: 0.25705623626708984
time: 2.2676358222961426
[1, 17401] loss_train: 0.005030, loss_test: 0.005570
time: 0.24805593490600586
time: 2.2579054832458496
[1, 17402] loss_train: 0.006190, loss_test: 0.005570
time: 0.24389123916625977
time: 2.2921271324157715
[1, 17403] loss_train: 0.002414, loss_test: 0.005572
time: 0.24805617332458496
time: 2.273508310317993
[1, 17404] loss_train: 0.001644, loss_test: 0.005574
time: 0.2470555305480957
time: 2.292512893676758
[1, 17405] loss_train: 0.005549, loss_test: 0.005577
time: 0.2520561218261719
time: 2.3165180683135986
[1, 17406] loss_train: 0.001532, loss_test: 0.005582
time: 0.2490549087524414
time: 2.3095171451568604
[1, 17407] loss_train: 0.002295, loss_test: 0.005587
time: 0.2650585174560547
time: 2.3505260944366455
[1, 17408] loss_train: 0.001935, loss_test: 0.005595
time: 0.2600574493408203
time: 2.370530843734741
[1, 17409] loss_train: 0.001065, loss_test: 0.005603
time: 0.24305343627929688
time: 2.246013641357422
[1, 17410] loss_train: 0.002171, loss_test: 0.005612
time: 0.26155543327331543
time: 2.2720401287078857
[1, 17411] loss_train: 0.006493, loss_test: 0.005616
time: 0.24305343627929688
time: 2.297846794128418
[1, 17412] loss_train: 0.002799, loss_test: 0.005623
time: 0.24342870712280273
time: 2.2785415649414062
[1, 17413] loss_train: 0.009848, loss_test: 0.005623
time: 0.2450566291809082
time: 2.2545063495635986
[1, 17414] loss_train: 0.000714, loss_test: 0.005628
time: 0.2409532070159912
time: 2.293515205383301
[1, 17415] loss_train: 0.009195, loss_test: 0.005634
time: 0.2470552921295166
time: 2.2895114421844482
[1, 17416] loss_train: 0.009643, loss_test: 0.005628
time: 0.24405407905578613
time: 2.256863594055176
[1, 17417] loss_train: 0.002318, loss_test: 0.005627
time: 0.2514629364013672
time: 2.2547807693481445
[1, 17418] loss_train: 0.003714, loss_test: 0.005627
time: 0.24805641174316406
time: 2.2690303325653076
[1, 17419] loss_train: 0.008385, loss_test: 0.005624
time: 0.2470557689666748
time: 2.2555184364318848
[1, 17420] loss_train: 0.006665, loss_test: 0.005620
time: 0.25705671310424805
time: 2.246511220932007
[1, 17421] loss_train: 0.003898, loss_test: 0.005617
time: 0.24405384063720703
time: 2.27051043510437
[1, 17422] loss_train: 0.004730, loss_test: 0.005607
time: 0.2520561218261719
time: 2.247502565383911
[1, 17423] loss_train: 0.011427, loss_test: 0.005588
time: 0.2470567226409912
time: 2.265505075454712
[1, 17424] loss_train: 0.005174, loss_test: 0.005571
time: 0.2490551471710205
time: 2.2566745281219482
[1, 17425] loss_train: 0.005285, loss_test: 0.005560
time: 0.24405384063720703
time: 2.261261224746704
[1, 17426] loss_train: 0.007097, loss_test: 0.005553
time: 0.24762988090515137
time: 2.25551176071167
[1, 17427] loss_train: 0.002585, loss_test: 0.005552
time: 0.25005602836608887
time: 2.2495312690734863
[1, 17428] loss_train: 0.011522, loss_test: 0.005553
time: 0.2470541000366211
time: 2.242504119873047
[1, 17429] loss_train: 0.001197, loss_test: 0.005554
time: 0.2430558204650879
time: 2.2555043697357178
[1, 17430] loss_train: 0.004550, loss_test: 0.005557
time: 0.25705766677856445
time: 2.2259509563446045
[1, 17431] loss_train: 0.002411, loss_test: 0.005561
time: 0.24525165557861328
time: 2.2765183448791504
[1, 17432] loss_train: 0.003662, loss_test: 0.005566
time: 0.24405407905578613
time: 2.2538108825683594
[1, 17433] loss_train: 0.002570, loss_test: 0.005567
time: 0.2450544834136963
time: 2.255410671234131
[1, 17434] loss_train: 0.007027, loss_test: 0.005570
time: 0.24473214149475098
time: 2.2914834022521973
[1, 17435] loss_train: 0.004058, loss_test: 0.005571
time: 0.24805593490600586
time: 2.267948627471924
[1, 17436] loss_train: 0.007066, loss_test: 0.005569
time: 0.24391579627990723
time: 2.263754367828369
[1, 17437] loss_train: 0.006437, loss_test: 0.005563
time: 0.2920644283294678
time: 2.316340923309326
[1, 17438] loss_train: 0.010897, loss_test: 0.005552
time: 0.25705766677856445
time: 2.278348445892334
[1, 17439] loss_train: 0.006874, loss_test: 0.005546
time: 0.25305604934692383
time: 2.288022756576538
[1, 17440] loss_train: 0.007601, loss_test: 0.005543
time: 0.25505757331848145
time: 2.256528615951538
[1, 17441] loss_train: 0.002022, loss_test: 0.005545
time: 0.24605417251586914
time: 2.260810136795044
[1, 17442] loss_train: 0.006829, loss_test: 0.005550
time: 0.24718356132507324
time: 2.348310947418213
[1, 17443] loss_train: 0.006265, loss_test: 0.005559
time: 0.2465806007385254
time: 2.2658870220184326
[1, 17444] loss_train: 0.005429, loss_test: 0.005568
time: 0.2450542449951172
time: 2.242767572402954
[1, 17445] loss_train: 0.008203, loss_test: 0.005571
time: 0.25505995750427246
time: 2.242614269256592
[1, 17446] loss_train: 0.003868, loss_test: 0.005573
time: 0.24305415153503418
time: 2.2873775959014893
[1, 17447] loss_train: 0.007332, loss_test: 0.005571
time: 0.24605464935302734
time: 2.3025143146514893
[1, 17448] loss_train: 0.002132, loss_test: 0.005569
time: 0.2450542449951172
time: 2.280015707015991
[1, 17449] loss_train: 0.009415, loss_test: 0.005561
time: 0.24505376815795898
time: 2.2495033740997314
[1, 17450] loss_train: 0.001968, loss_test: 0.005548
time: 0.25505685806274414
time: 2.2525179386138916
[1, 17451] loss_train: 0.000699, loss_test: 0.005541
time: 0.2470545768737793
time: 2.2375009059906006
[1, 17452] loss_train: 0.011750, loss_test: 0.005535
time: 0.24305510520935059
time: 2.2727620601654053
[1, 17453] loss_train: 0.002975, loss_test: 0.005532
time: 0.24405622482299805
time: 2.2745397090911865
[1, 17454] loss_train: 0.007712, loss_test: 0.005531
time: 0.2560570240020752
time: 2.286653995513916
[1, 17455] loss_train: 0.012028, loss_test: 0.005530
time: 0.2418839931488037
time: 2.273615598678589
[1, 17456] loss_train: 0.006546, loss_test: 0.005529
time: 0.247056245803833
time: 2.24369740486145
[1, 17457] loss_train: 0.007588, loss_test: 0.005528
time: 0.24205303192138672
time: 2.4505484104156494
[1, 17458] loss_train: 0.010543, loss_test: 0.005528
time: 0.24405455589294434
time: 2.2510077953338623
[1, 17459] loss_train: 0.004241, loss_test: 0.005528
time: 0.2585625648498535
time: 2.2860209941864014
[1, 17460] loss_train: 0.004159, loss_test: 0.005529
time: 0.2650580406188965
time: 2.310516595840454
[1, 17461] loss_train: 0.007651, loss_test: 0.005531
time: 0.25705742835998535
time: 2.314765214920044
[1, 17462] loss_train: 0.003552, loss_test: 0.005531
time: 0.24305367469787598
time: 2.2709977626800537
[1, 17463] loss_train: 0.016924, loss_test: 0.005530
time: 0.24405360221862793
time: 2.2765121459960938
[1, 17464] loss_train: 0.008686, loss_test: 0.005536
time: 0.24905800819396973
time: 2.2614073753356934
[1, 17465] loss_train: 0.007657, loss_test: 0.005544
time: 0.24305343627929688
time: 2.2424521446228027
[1, 17466] loss_train: 0.003923, loss_test: 0.005548
time: 0.24805498123168945
time: 2.276790142059326
[1, 17467] loss_train: 0.004530, loss_test: 0.005548
time: 0.24205350875854492
time: 2.255291700363159
[1, 17468] loss_train: 0.005157, loss_test: 0.005542
time: 0.24655866622924805
time: 2.233389139175415
[1, 17469] loss_train: 0.008606, loss_test: 0.005536
time: 0.24405670166015625
time: 2.2453055381774902
[1, 17470] loss_train: 0.006183, loss_test: 0.005533
time: 0.25905656814575195
time: 2.2595107555389404
[1, 17471] loss_train: 0.008451, loss_test: 0.005531
time: 0.24405622482299805
time: 2.3016295433044434
[1, 17472] loss_train: 0.006186, loss_test: 0.005531
time: 0.24456024169921875
time: 2.316920280456543
[1, 17473] loss_train: 0.006561, loss_test: 0.005535
time: 0.2470545768737793
time: 2.2940196990966797
[1, 17474] loss_train: 0.004999, loss_test: 0.005540
time: 0.24305343627929688
time: 2.243502140045166
[1, 17475] loss_train: 0.005630, loss_test: 0.005545
time: 0.24605441093444824
time: 2.268507719039917
[1, 17476] loss_train: 0.006948, loss_test: 0.005549
time: 0.2470548152923584
time: 2.390834093093872
[1, 17477] loss_train: 0.003163, loss_test: 0.005555
time: 0.2490551471710205
time: 2.3129947185516357
[1, 17478] loss_train: 0.006744, loss_test: 0.005560
time: 0.2450542449951172
time: 2.4435489177703857
[1, 17479] loss_train: 0.007103, loss_test: 0.005559
time: 0.2450547218322754
time: 2.3197884559631348
[1, 17480] loss_train: 0.008890, loss_test: 0.005557
time: 0.2650582790374756
time: 2.2555158138275146
[1, 17481] loss_train: 0.005447, loss_test: 0.005557
time: 0.24605441093444824
time: 2.2655069828033447
[1, 17482] loss_train: 0.002374, loss_test: 0.005557
time: 0.2470560073852539
time: 2.319517135620117
[1, 17483] loss_train: 0.004336, loss_test: 0.005559
time: 0.2560572624206543
time: 2.2520110607147217
[1, 17484] loss_train: 0.003349, loss_test: 0.005559
time: 0.25705695152282715
time: 2.2935125827789307
[1, 17485] loss_train: 0.003679, loss_test: 0.005559
time: 0.24605512619018555
time: 2.2514567375183105
[1, 17486] loss_train: 0.009091, loss_test: 0.005557
time: 0.24257516860961914
time: 2.277122735977173
[1, 17487] loss_train: 0.005596, loss_test: 0.005558
time: 0.24405574798583984
time: 2.2350833415985107
[1, 17488] loss_train: 0.002253, loss_test: 0.005559
time: 0.2560570240020752
time: 2.2515151500701904
[1, 17489] loss_train: 0.006396, loss_test: 0.005560
time: 0.24307727813720703
time: 2.2572011947631836
[1, 17490] loss_train: 0.003152, loss_test: 0.005562
time: 0.25705647468566895
time: 2.2910172939300537
[1, 17491] loss_train: 0.010378, loss_test: 0.005564
time: 0.2560570240020752
time: 2.296515703201294
[1, 17492] loss_train: 0.000964, loss_test: 0.005570
time: 0.24805521965026855
time: 2.34647274017334
[1, 17493] loss_train: 0.004506, loss_test: 0.005578
time: 0.2600579261779785
time: 2.2837319374084473
[1, 17494] loss_train: 0.007807, loss_test: 0.005575
time: 0.24305367469787598
time: 2.287019968032837
[1, 17495] loss_train: 0.005949, loss_test: 0.005571
time: 0.2713503837585449
time: 2.3462905883789062
[1, 17496] loss_train: 0.009965, loss_test: 0.005563
time: 0.29706549644470215
time: 2.271514415740967
[1, 17497] loss_train: 0.007309, loss_test: 0.005554
time: 0.25205564498901367
time: 2.2274980545043945
[1, 17498] loss_train: 0.004367, loss_test: 0.005548
time: 0.24305391311645508
time: 2.266507387161255
[1, 17499] loss_train: 0.008029, loss_test: 0.005543
time: 0.2470548152923584
time: 2.23449969291687
[1, 17500] loss_train: 0.003656, loss_test: 0.005538
time: 0.26805853843688965
time: 2.2780237197875977
[1, 17501] loss_train: 0.010651, loss_test: 0.005537
time: 0.25205540657043457
time: 2.30086350440979
[1, 17502] loss_train: 0.017118, loss_test: 0.005537
time: 0.24405646324157715
time: 2.4381613731384277
[1, 17503] loss_train: 0.007957, loss_test: 0.005542
time: 0.3250713348388672
time: 2.407393217086792
[1, 17504] loss_train: 0.015784, loss_test: 0.005548
time: 0.2720484733581543
time: 2.30256724357605
[1, 17505] loss_train: 0.008950, loss_test: 0.005551
time: 0.2510554790496826
time: 2.2505385875701904
[1, 17506] loss_train: 0.015405, loss_test: 0.005559
time: 0.24205350875854492
time: 2.267010450363159
[1, 17507] loss_train: 0.002657, loss_test: 0.005562
time: 0.2470555305480957
time: 2.2525150775909424
[1, 17508] loss_train: 0.004138, loss_test: 0.005560
time: 0.24405503273010254
time: 2.2375025749206543
[1, 17509] loss_train: 0.012141, loss_test: 0.005559
time: 0.24356532096862793
time: 2.2412121295928955
[1, 17510] loss_train: 0.002847, loss_test: 0.005550
time: 0.2630581855773926
time: 2.238187551498413
[1, 17511] loss_train: 0.009114, loss_test: 0.005541
time: 0.24305438995361328
time: 2.2695038318634033
[1, 17512] loss_train: 0.006366, loss_test: 0.005536
time: 0.2570779323577881
time: 2.3014185428619385
[1, 17513] loss_train: 0.005848, loss_test: 0.005531
time: 0.24405455589294434
time: 2.24001407623291
[1, 17514] loss_train: 0.005321, loss_test: 0.005531
time: 0.2498795986175537
time: 2.269507884979248
[1, 17515] loss_train: 0.008923, loss_test: 0.005538
time: 0.24605536460876465
time: 2.2631723880767822
[1, 17516] loss_train: 0.003849, loss_test: 0.005550
time: 0.24305343627929688
time: 2.315021514892578
[1, 17517] loss_train: 0.005007, loss_test: 0.005565
time: 0.2490546703338623
time: 2.255645751953125
[1, 17518] loss_train: 0.002096, loss_test: 0.005586
time: 0.2450864315032959
time: 2.249492645263672
[1, 17519] loss_train: 0.006875, loss_test: 0.005600
time: 0.24709463119506836
time: 2.294022560119629
[1, 17520] loss_train: 0.002973, loss_test: 0.005611
time: 0.27306103706359863
time: 2.2918570041656494
[1, 17521] loss_train: 0.002894, loss_test: 0.005620
time: 0.2505605220794678
time: 2.270174026489258
[1, 17522] loss_train: 0.008778, loss_test: 0.005618
time: 0.24562692642211914
time: 2.2600314617156982
[1, 17523] loss_train: 0.009814, loss_test: 0.005601
time: 0.24786067008972168
time: 2.261514902114868
[1, 17524] loss_train: 0.002522, loss_test: 0.005586
time: 0.25005555152893066
time: 2.3043601512908936
[1, 17525] loss_train: 0.003751, loss_test: 0.005574
time: 0.2496662139892578
time: 2.2914557456970215
[1, 17526] loss_train: 0.002707, loss_test: 0.005567
time: 0.2510559558868408
time: 2.268192768096924
[1, 17527] loss_train: 0.002245, loss_test: 0.005562
time: 0.24605441093444824
time: 2.2643909454345703
[1, 17528] loss_train: 0.008061, loss_test: 0.005558
time: 0.2560560703277588
time: 2.2765090465545654
[1, 17529] loss_train: 0.005917, loss_test: 0.005556
time: 0.2581355571746826
time: 2.235020875930786
[1, 17530] loss_train: 0.004198, loss_test: 0.005556
time: 0.28406238555908203
time: 2.256504774093628
[1, 17531] loss_train: 0.004473, loss_test: 0.005558
time: 0.2650589942932129
time: 2.385040521621704
[1, 17532] loss_train: 0.003548, loss_test: 0.005562
time: 0.247053861618042
time: 2.296983480453491
[1, 17533] loss_train: 0.005780, loss_test: 0.005566
time: 0.24305462837219238
time: 2.2991323471069336
[1, 17534] loss_train: 0.008545, loss_test: 0.005570
time: 0.2786867618560791
time: 2.247532606124878
[1, 17535] loss_train: 0.003841, loss_test: 0.005574
time: 0.24405598640441895
time: 2.28269100189209
[1, 17536] loss_train: 0.009750, loss_test: 0.005580
time: 0.2490544319152832
time: 2.3005154132843018
[1, 17537] loss_train: 0.008928, loss_test: 0.005579
time: 0.2470550537109375
time: 2.231001377105713
[1, 17538] loss_train: 0.007627, loss_test: 0.005577
time: 0.25005531311035156
time: 2.2485034465789795
[1, 17539] loss_train: 0.007079, loss_test: 0.005574
time: 0.24405384063720703
time: 2.239501953125
[1, 17540] loss_train: 0.005426, loss_test: 0.005570
time: 0.2620577812194824
time: 2.246511459350586
[1, 17541] loss_train: 0.016918, loss_test: 0.005561
time: 0.2457294464111328
time: 2.288794994354248
[1, 17542] loss_train: 0.003423, loss_test: 0.005556
time: 0.2520561218261719
time: 2.2339353561401367
[1, 17543] loss_train: 0.002514, loss_test: 0.005554
time: 0.24605512619018555
time: 2.248504400253296
[1, 17544] loss_train: 0.012685, loss_test: 0.005554
time: 0.2520558834075928
time: 2.2228004932403564
[1, 17545] loss_train: 0.008774, loss_test: 0.005558
time: 0.24487543106079102
time: 2.24045729637146
[1, 17546] loss_train: 0.003337, loss_test: 0.005561
time: 0.25005507469177246
time: 2.3115286827087402
[1, 17547] loss_train: 0.006194, loss_test: 0.005563
time: 0.24405455589294434
time: 2.2954940795898438
[1, 17548] loss_train: 0.003527, loss_test: 0.005559
time: 0.2530691623687744
time: 2.225083589553833
[1, 17549] loss_train: 0.007512, loss_test: 0.005554
time: 0.24506592750549316
time: 2.2485175132751465
[1, 17550] loss_train: 0.011184, loss_test: 0.005552
time: 0.2620580196380615
time: 2.258366584777832
[1, 17551] loss_train: 0.002451, loss_test: 0.005550
time: 0.24405384063720703
time: 2.2460179328918457
[1, 17552] loss_train: 0.009038, loss_test: 0.005550
time: 0.25005531311035156
time: 2.2765181064605713
[1, 17553] loss_train: 0.006472, loss_test: 0.005552
time: 0.24505400657653809
time: 2.2985148429870605
[1, 17554] loss_train: 0.005124, loss_test: 0.005553
time: 0.24956560134887695
time: 2.258043050765991
[1, 17555] loss_train: 0.004087, loss_test: 0.005557
time: 0.24406051635742188
time: 2.2252326011657715
[1, 17556] loss_train: 0.008788, loss_test: 0.005560
time: 0.24605464935302734
time: 2.247526168823242
[1, 17557] loss_train: 0.006824, loss_test: 0.005562
time: 0.23905563354492188
time: 2.2238807678222656
[1, 17558] loss_train: 0.006513, loss_test: 0.005563
time: 0.2490553855895996
time: 2.2525033950805664
[1, 17559] loss_train: 0.010548, loss_test: 0.005562
time: 0.24405574798583984
time: 2.2295186519622803
[1, 17560] loss_train: 0.007295, loss_test: 0.005561
time: 0.27506113052368164
time: 2.256514072418213
[1, 17561] loss_train: 0.006906, loss_test: 0.005557
time: 0.26105833053588867
time: 2.2835099697113037
[1, 17562] loss_train: 0.001138, loss_test: 0.005556
time: 0.2490553855895996
time: 2.2790215015411377
[1, 17563] loss_train: 0.004761, loss_test: 0.005554
time: 0.24405360221862793
time: 2.281559944152832
[1, 17564] loss_train: 0.002821, loss_test: 0.005555
time: 0.2450575828552246
time: 2.222968101501465
[1, 17565] loss_train: 0.006670, loss_test: 0.005555
time: 0.24407696723937988
time: 2.264331817626953
[1, 17566] loss_train: 0.001500, loss_test: 0.005555
time: 0.2760615348815918
time: 2.2645206451416016
[1, 17567] loss_train: 0.008338, loss_test: 0.005555
time: 0.2450544834136963
time: 2.248518943786621
[1, 17568] loss_train: 0.003444, loss_test: 0.005552
time: 0.24505400657653809
time: 2.2074947357177734
[1, 17569] loss_train: 0.017689, loss_test: 0.005547
time: 0.24605369567871094
time: 2.2618565559387207
[1, 17570] loss_train: 0.014577, loss_test: 0.005551
time: 0.2670586109161377
time: 2.268205404281616
[1, 17571] loss_train: 0.010015, loss_test: 0.005561
time: 0.24405360221862793
time: 2.253241539001465
[1, 17572] loss_train: 0.004100, loss_test: 0.005574
time: 0.24506020545959473
time: 2.2860331535339355
[1, 17573] loss_train: 0.006569, loss_test: 0.005584
time: 0.2589454650878906
time: 2.2897865772247314
[1, 17574] loss_train: 0.002648, loss_test: 0.005593
time: 0.24374151229858398
time: 2.236499786376953
[1, 17575] loss_train: 0.010016, loss_test: 0.005599
time: 0.24305367469787598
time: 2.2540082931518555
[1, 17576] loss_train: 0.007996, loss_test: 0.005602
time: 0.2490556240081787
time: 2.3055191040039062
[1, 17577] loss_train: 0.010853, loss_test: 0.005607
time: 0.24405384063720703
time: 2.26950740814209
[1, 17578] loss_train: 0.015825, loss_test: 0.005594
time: 0.2670578956604004
time: 2.4080429077148438
[1, 17579] loss_train: 0.003975, loss_test: 0.005584
time: 0.2600574493408203
time: 2.31951904296875
[1, 17580] loss_train: 0.001649, loss_test: 0.005573
time: 0.25705647468566895
time: 2.325643301010132
[1, 17581] loss_train: 0.007434, loss_test: 0.005562
time: 0.2760610580444336
time: 2.3307251930236816
[1, 17582] loss_train: 0.002138, loss_test: 0.005556
time: 0.27655458450317383
time: 2.2419612407684326
[1, 17583] loss_train: 0.005202, loss_test: 0.005556
time: 0.24404263496398926
time: 2.2549502849578857
[1, 17584] loss_train: 0.006827, loss_test: 0.005559
time: 0.244032621383667
time: 2.2459681034088135
[1, 17585] loss_train: 0.008496, loss_test: 0.005562
time: 0.24502325057983398
time: 2.2544686794281006
[1, 17586] loss_train: 0.008923, loss_test: 0.005566
time: 0.24405503273010254
time: 2.259505271911621
[1, 17587] loss_train: 0.007823, loss_test: 0.005571
time: 0.24255800247192383
time: 2.238510847091675
[1, 17588] loss_train: 0.007834, loss_test: 0.005577
time: 0.24305295944213867
time: 2.2225048542022705
[1, 17589] loss_train: 0.010794, loss_test: 0.005579
time: 0.25005459785461426
time: 2.283889055252075
[1, 17590] loss_train: 0.005734, loss_test: 0.005578
time: 0.25705742835998535
time: 2.2452666759490967
[1, 17591] loss_train: 0.003322, loss_test: 0.005572
time: 0.24558186531066895
time: 2.256490707397461
[1, 17592] loss_train: 0.006267, loss_test: 0.005564
time: 0.24496245384216309
time: 2.2472152709960938
[1, 17593] loss_train: 0.005573, loss_test: 0.005557
time: 0.24355697631835938
time: 2.22149658203125
[1, 17594] loss_train: 0.001132, loss_test: 0.005558
time: 0.24305486679077148
time: 2.25750470161438
[1, 17595] loss_train: 0.006517, loss_test: 0.005561
time: 0.24506783485412598
time: 2.213998556137085
[1, 17596] loss_train: 0.008119, loss_test: 0.005565
time: 0.24605441093444824
time: 2.2450649738311768
[1, 17597] loss_train: 0.006529, loss_test: 0.005564
time: 0.27373242378234863
time: 2.2478747367858887
[1, 17598] loss_train: 0.004448, loss_test: 0.005568
time: 0.2510683536529541
time: 2.234499216079712
[1, 17599] loss_train: 0.004888, loss_test: 0.005572
time: 0.24605464935302734
time: 2.2783029079437256
[1, 17600] loss_train: 0.009112, loss_test: 0.005572
time: 0.2585604190826416
time: 2.26652455329895
[1, 17601] loss_train: 0.003678, loss_test: 0.005574
time: 0.2470543384552002
time: 2.2266669273376465
[1, 17602] loss_train: 0.002357, loss_test: 0.005579
time: 0.2450547218322754
time: 2.246502161026001
[1, 17603] loss_train: 0.010132, loss_test: 0.005577
time: 0.24605536460876465
time: 2.244570732116699
[1, 17604] loss_train: 0.007922, loss_test: 0.005573
time: 0.24605441093444824
time: 2.250871419906616
[1, 17605] loss_train: 0.008099, loss_test: 0.005571
time: 0.2450549602508545
time: 2.244501829147339
[1, 17606] loss_train: 0.006815, loss_test: 0.005570
time: 0.2450544834136963
time: 2.266284465789795
[1, 17607] loss_train: 0.011679, loss_test: 0.005568
time: 0.24406838417053223
time: 2.2443904876708984
[1, 17608] loss_train: 0.001334, loss_test: 0.005569
time: 0.24306654930114746
time: 2.2355008125305176
[1, 17609] loss_train: 0.003083, loss_test: 0.005571
time: 0.24505376815795898
time: 2.229006052017212
[1, 17610] loss_train: 0.005462, loss_test: 0.005573
time: 0.25705671310424805
time: 2.240006923675537
[1, 17611] loss_train: 0.009720, loss_test: 0.005569
time: 0.24406743049621582
time: 2.2375009059906006
[1, 17612] loss_train: 0.004473, loss_test: 0.005566
time: 0.25505661964416504
time: 2.4383645057678223
[1, 17613] loss_train: 0.001487, loss_test: 0.005558
time: 0.2676541805267334
time: 2.358211040496826
[1, 17614] loss_train: 0.004213, loss_test: 0.005554
time: 0.2470548152923584
time: 2.2524261474609375
[1, 17615] loss_train: 0.005828, loss_test: 0.005551
time: 0.24263954162597656
time: 2.2500059604644775
[1, 17616] loss_train: 0.004671, loss_test: 0.005552
time: 0.24305367469787598
time: 2.2860171794891357
[1, 17617] loss_train: 0.003875, loss_test: 0.005556
time: 0.24305367469787598
time: 2.254504680633545
[1, 17618] loss_train: 0.004786, loss_test: 0.005561
time: 0.2463057041168213
time: 2.2673003673553467
[1, 17619] loss_train: 0.012283, loss_test: 0.005561
time: 0.24457836151123047
time: 2.2654614448547363
[1, 17620] loss_train: 0.001300, loss_test: 0.005564
time: 0.2650587558746338
time: 2.2195146083831787
[1, 17621] loss_train: 0.003061, loss_test: 0.005568
time: 0.244523286819458
time: 2.2484097480773926
[1, 17622] loss_train: 0.001718, loss_test: 0.005574
time: 0.24605417251586914
time: 2.2440149784088135
[1, 17623] loss_train: 0.002785, loss_test: 0.005582
time: 0.24406743049621582
time: 2.248505115509033
[1, 17624] loss_train: 0.009403, loss_test: 0.005588
time: 0.2450549602508545
time: 2.2485382556915283
[1, 17625] loss_train: 0.009534, loss_test: 0.005579
time: 0.24405431747436523
time: 2.25850510597229
[1, 17626] loss_train: 0.003588, loss_test: 0.005574
time: 0.24405407905578613
time: 2.268306255340576
[1, 17627] loss_train: 0.011051, loss_test: 0.005569
time: 0.24577879905700684
time: 2.268994092941284
[1, 17628] loss_train: 0.001372, loss_test: 0.005570
time: 0.24708080291748047
time: 2.2559261322021484
[1, 17629] loss_train: 0.007123, loss_test: 0.005579
time: 0.24288439750671387
time: 2.224585771560669
[1, 17630] loss_train: 0.001956, loss_test: 0.005596
time: 0.2600572109222412
time: 2.2585089206695557
[1, 17631] loss_train: 0.005439, loss_test: 0.005603
time: 0.24405407905578613
time: 2.228001356124878
[1, 17632] loss_train: 0.003123, loss_test: 0.005611
time: 0.24805521965026855
time: 2.268012523651123
[1, 17633] loss_train: 0.006848, loss_test: 0.005611
time: 0.24305367469787598
time: 2.242502212524414
[1, 17634] loss_train: 0.010186, loss_test: 0.005601
time: 0.2470545768737793
time: 2.242501735687256
[1, 17635] loss_train: 0.003038, loss_test: 0.005592
time: 0.24305319786071777
time: 2.2415342330932617
[1, 17636] loss_train: 0.006387, loss_test: 0.005576
time: 0.24305391311645508
time: 2.2586400508880615
[1, 17637] loss_train: 0.010234, loss_test: 0.005566
time: 0.2437152862548828
time: 2.2624378204345703
[1, 17638] loss_train: 0.004267, loss_test: 0.005562
time: 0.24486613273620605
time: 2.257096767425537
[1, 17639] loss_train: 0.003771, loss_test: 0.005562
time: 0.24392366409301758
time: 2.2844431400299072
[1, 17640] loss_train: 0.003169, loss_test: 0.005564
time: 0.2980656623840332
time: 2.3324015140533447
[1, 17641] loss_train: 0.007537, loss_test: 0.005567
time: 0.2850630283355713
time: 2.3725337982177734
[1, 17642] loss_train: 0.006798, loss_test: 0.005569
time: 0.24905729293823242
time: 2.2700119018554688
[1, 17643] loss_train: 0.002111, loss_test: 0.005568
time: 0.2450556755065918
time: 2.2915127277374268
[1, 17644] loss_train: 0.003547, loss_test: 0.005564
time: 0.2720603942871094
time: 2.4355721473693848
[1, 17645] loss_train: 0.002081, loss_test: 0.005557
time: 0.28485727310180664
time: 2.3301210403442383
[1, 17646] loss_train: 0.002861, loss_test: 0.005550
time: 0.2625925540924072
time: 2.2555532455444336
[1, 17647] loss_train: 0.010039, loss_test: 0.005545
time: 0.24605393409729004
time: 2.2449584007263184
[1, 17648] loss_train: 0.001805, loss_test: 0.005543
time: 0.24999094009399414
time: 2.246567487716675
[1, 17649] loss_train: 0.002594, loss_test: 0.005546
time: 0.2450699806213379
time: 2.270010232925415
[1, 17650] loss_train: 0.000618, loss_test: 0.005555
time: 0.25905728340148926
time: 2.234499931335449
[1, 17651] loss_train: 0.004852, loss_test: 0.005568
time: 0.24355840682983398
time: 2.262009859085083
[1, 17652] loss_train: 0.000880, loss_test: 0.005587
time: 0.2450547218322754
time: 2.27052640914917
[1, 17653] loss_train: 0.003897, loss_test: 0.005608
time: 0.2526509761810303
time: 2.267660617828369
[1, 17654] loss_train: 0.012654, loss_test: 0.005624
time: 0.2470567226409912
time: 2.2807211875915527
[1, 17655] loss_train: 0.004056, loss_test: 0.005634
time: 0.24805498123168945
time: 2.259007692337036
[1, 17656] loss_train: 0.010116, loss_test: 0.005637
time: 0.2470548152923584
time: 2.279013156890869
[1, 17657] loss_train: 0.002643, loss_test: 0.005640
time: 0.24305438995361328
time: 2.3085172176361084
[1, 17658] loss_train: 0.003879, loss_test: 0.005636
time: 0.2510554790496826
time: 2.3145313262939453
[1, 17659] loss_train: 0.008308, loss_test: 0.005622
time: 0.24605536460876465
time: 2.2815613746643066
[1, 17660] loss_train: 0.007611, loss_test: 0.005598
time: 0.26405787467956543
time: 2.2639801502227783
[1, 17661] loss_train: 0.010142, loss_test: 0.005580
time: 0.24393606185913086
time: 2.2682735919952393
[1, 17662] loss_train: 0.010644, loss_test: 0.005569
time: 0.2540571689605713
time: 2.262324571609497
[1, 17663] loss_train: 0.007491, loss_test: 0.005567
time: 0.24700474739074707
time: 2.2658047676086426
[1, 17664] loss_train: 0.006248, loss_test: 0.005570
time: 0.2470543384552002
time: 2.2445027828216553
[1, 17665] loss_train: 0.003275, loss_test: 0.005577
time: 0.24305415153503418
time: 2.2669758796691895
[1, 17666] loss_train: 0.008350, loss_test: 0.005587
time: 0.24805426597595215
time: 2.2720279693603516
[1, 17667] loss_train: 0.003154, loss_test: 0.005591
time: 0.2450542449951172
time: 2.233156681060791
[1, 17668] loss_train: 0.007847, loss_test: 0.005591
time: 0.24805283546447754
time: 2.2820169925689697
[1, 17669] loss_train: 0.011415, loss_test: 0.005588
time: 0.24506735801696777
time: 2.259507179260254
[1, 17670] loss_train: 0.006937, loss_test: 0.005582
time: 0.2630610466003418
time: 2.2596683502197266
[1, 17671] loss_train: 0.009650, loss_test: 0.005575
time: 0.24330520629882812
time: 2.266507148742676
[1, 17672] loss_train: 0.005188, loss_test: 0.005567
time: 0.2470543384552002
time: 2.251513719558716
[1, 17673] loss_train: 0.006414, loss_test: 0.005559
time: 0.24405384063720703
time: 2.2535064220428467
[1, 17674] loss_train: 0.001235, loss_test: 0.005558
time: 0.25005507469177246
time: 2.283522129058838
[1, 17675] loss_train: 0.002616, loss_test: 0.005560
time: 0.24405503273010254
time: 2.2520434856414795
[1, 17676] loss_train: 0.001864, loss_test: 0.005568
time: 0.2495594024658203
time: 2.237246513366699
[1, 17677] loss_train: 0.006657, loss_test: 0.005579
time: 0.24305367469787598
time: 2.2364652156829834
[1, 17678] loss_train: 0.007678, loss_test: 0.005588
time: 0.24892735481262207
time: 2.261857509613037
[1, 17679] loss_train: 0.004021, loss_test: 0.005597
time: 0.24305367469787598
time: 2.229499101638794
[1, 17680] loss_train: 0.005870, loss_test: 0.005603
time: 0.27005982398986816
time: 2.257505178451538
[1, 17681] loss_train: 0.008426, loss_test: 0.005593
time: 0.24605417251586914
time: 2.290512800216675
[1, 17682] loss_train: 0.015955, loss_test: 0.005564
time: 0.24948525428771973
time: 2.253511905670166
[1, 17683] loss_train: 0.004925, loss_test: 0.005560
time: 0.2470543384552002
time: 2.274029016494751
[1, 17684] loss_train: 0.017846, loss_test: 0.005580
time: 0.25005507469177246
time: 2.2813520431518555
[1, 17685] loss_train: 0.004455, loss_test: 0.005608
time: 0.24605441093444824
time: 2.2507317066192627
[1, 17686] loss_train: 0.007508, loss_test: 0.005629
time: 0.24405550956726074
time: 2.2787623405456543
[1, 17687] loss_train: 0.008665, loss_test: 0.005643
time: 0.24805665016174316
time: 2.30952787399292
[1, 17688] loss_train: 0.003005, loss_test: 0.005639
time: 0.25705671310424805
time: 2.273513078689575
[1, 17689] loss_train: 0.004018, loss_test: 0.005632
time: 0.2490546703338623
time: 2.2695086002349854
[1, 17690] loss_train: 0.009703, loss_test: 0.005612
time: 0.26595091819763184
time: 2.315980911254883
[1, 17691] loss_train: 0.001632, loss_test: 0.005596
time: 0.24917078018188477
time: 2.308493137359619
[1, 17692] loss_train: 0.010252, loss_test: 0.005580
time: 0.2527797222137451
time: 2.2633116245269775
[1, 17693] loss_train: 0.012391, loss_test: 0.005568
time: 0.2515594959259033
time: 2.2795188426971436
[1, 17694] loss_train: 0.002962, loss_test: 0.005557
time: 0.25005555152893066
time: 2.266514539718628
[1, 17695] loss_train: 0.002383, loss_test: 0.005552
time: 0.24805498123168945
time: 2.2635059356689453
[1, 17696] loss_train: 0.004546, loss_test: 0.005554
time: 0.2490556240081787
time: 2.27215838432312
[1, 17697] loss_train: 0.006344, loss_test: 0.005560
time: 0.2501082420349121
time: 2.266075611114502
[1, 17698] loss_train: 0.005182, loss_test: 0.005567
time: 0.24405527114868164
time: 2.298900604248047
[1, 17699] loss_train: 0.004730, loss_test: 0.005571
time: 0.25005555152893066
time: 2.3076701164245605
[1, 17700] loss_train: 0.004806, loss_test: 0.005575
time: 0.2600588798522949
time: 2.2710208892822266
[1, 17701] loss_train: 0.008984, loss_test: 0.005572
time: 0.2450544834136963
time: 2.261012554168701
[1, 17702] loss_train: 0.004745, loss_test: 0.005569
time: 0.2530553340911865
time: 2.244311809539795
[1, 17703] loss_train: 0.005605, loss_test: 0.005564
time: 0.25205540657043457
time: 2.257505416870117
[1, 17704] loss_train: 0.009223, loss_test: 0.005556
time: 0.25005578994750977
time: 2.2658348083496094
[1, 17705] loss_train: 0.000590, loss_test: 0.005552
time: 0.2450542449951172
time: 2.221008062362671
[1, 17706] loss_train: 0.004206, loss_test: 0.005550
time: 0.24405765533447266
time: 2.257124900817871
[1, 17707] loss_train: 0.002936, loss_test: 0.005550
time: 0.2450542449951172
time: 2.2114951610565186
[1, 17708] loss_train: 0.015090, loss_test: 0.005546
time: 0.24331283569335938
time: 2.251911163330078
[1, 17709] loss_train: 0.004540, loss_test: 0.005544
time: 0.24505329132080078
time: 2.244502305984497
[1, 17710] loss_train: 0.007172, loss_test: 0.005541
time: 0.2670595645904541
time: 2.3165180683135986
[1, 17711] loss_train: 0.008700, loss_test: 0.005540
time: 0.2560570240020752
time: 2.362527847290039
[1, 17712] loss_train: 0.004121, loss_test: 0.005539
time: 0.29306507110595703
time: 2.3185184001922607
[1, 17713] loss_train: 0.001833, loss_test: 0.005538
time: 0.2470550537109375
time: 2.245509147644043
[1, 17714] loss_train: 0.009632, loss_test: 0.005540
time: 0.2430553436279297
time: 2.255023717880249
[1, 17715] loss_train: 0.002262, loss_test: 0.005543
time: 0.2445228099822998
time: 2.268515110015869
[1, 17716] loss_train: 0.011011, loss_test: 0.005545
time: 0.25355100631713867
time: 2.252033233642578
[1, 17717] loss_train: 0.000578, loss_test: 0.005546
time: 0.2450542449951172
time: 2.2250161170959473
[1, 17718] loss_train: 0.004049, loss_test: 0.005545
time: 0.24405741691589355
time: 2.2575149536132812
[1, 17719] loss_train: 0.005063, loss_test: 0.005544
time: 0.25005602836608887
time: 2.2610080242156982
[1, 17720] loss_train: 0.002282, loss_test: 0.005542
time: 0.2580580711364746
time: 2.2435126304626465
[1, 17721] loss_train: 0.003970, loss_test: 0.005543
time: 0.24405384063720703
time: 2.2520127296447754
[1, 17722] loss_train: 0.004035, loss_test: 0.005545
time: 0.24405360221862793
time: 2.2345035076141357
[1, 17723] loss_train: 0.013936, loss_test: 0.005546
time: 0.24455952644348145
time: 2.2541067600250244
[1, 17724] loss_train: 0.005720, loss_test: 0.005550
time: 0.24605369567871094
time: 2.215951919555664
[1, 17725] loss_train: 0.002128, loss_test: 0.005558
time: 0.2440657615661621
time: 2.2362968921661377
[1, 17726] loss_train: 0.009413, loss_test: 0.005566
time: 0.2449665069580078
time: 2.2599308490753174
[1, 17727] loss_train: 0.000582, loss_test: 0.005580
time: 0.24502110481262207
time: 2.2429707050323486
[1, 17728] loss_train: 0.003078, loss_test: 0.005595
time: 0.24655890464782715
time: 2.220029592514038
[1, 17729] loss_train: 0.005508, loss_test: 0.005603
time: 0.24405455589294434
time: 2.2144968509674072
[1, 17730] loss_train: 0.009519, loss_test: 0.005605
time: 0.2560563087463379
time: 2.242215633392334
[1, 17731] loss_train: 0.008580, loss_test: 0.005614
time: 0.24405312538146973
time: 2.254011631011963
[1, 17732] loss_train: 0.008691, loss_test: 0.005611
time: 0.24405360221862793
time: 2.2794909477233887
[1, 17733] loss_train: 0.005977, loss_test: 0.005605
time: 0.2450544834136963
time: 2.2629239559173584
[1, 17734] loss_train: 0.003204, loss_test: 0.005597
time: 0.24300456047058105
time: 2.255640983581543
[1, 17735] loss_train: 0.003932, loss_test: 0.005590
time: 0.2450554370880127
time: 2.2470054626464844
[1, 17736] loss_train: 0.008028, loss_test: 0.005579
time: 0.2470552921295166
time: 2.2670114040374756
[1, 17737] loss_train: 0.000480, loss_test: 0.005572
time: 0.2450542449951172
time: 2.2635066509246826
[1, 17738] loss_train: 0.005385, loss_test: 0.005567
time: 0.2470550537109375
time: 2.344524383544922
[1, 17739] loss_train: 0.005862, loss_test: 0.005562
time: 0.25362062454223633
time: 2.2959675788879395
[1, 17740] loss_train: 0.006602, loss_test: 0.005556
time: 0.25905776023864746
time: 2.2460081577301025
[1, 17741] loss_train: 0.006250, loss_test: 0.005553
time: 0.24405479431152344
time: 2.2799346446990967
[1, 17742] loss_train: 0.003903, loss_test: 0.005554
time: 0.2630586624145508
time: 2.3245203495025635
[1, 17743] loss_train: 0.009383, loss_test: 0.005553
time: 0.25705790519714355
time: 2.252504587173462
[1, 17744] loss_train: 0.007185, loss_test: 0.005554
time: 0.25505709648132324
time: 2.2435011863708496
[1, 17745] loss_train: 0.007818, loss_test: 0.005555
time: 0.24505400657653809
time: 2.2800235748291016
[1, 17746] loss_train: 0.002386, loss_test: 0.005555
time: 0.2420673370361328
time: 2.272510290145874
[1, 17747] loss_train: 0.002802, loss_test: 0.005554
time: 0.24305438995361328
time: 2.240504503250122
[1, 17748] loss_train: 0.004276, loss_test: 0.005551
time: 0.253054141998291
time: 2.3029122352600098
[1, 17749] loss_train: 0.002576, loss_test: 0.005548
time: 0.24805498123168945
time: 2.3191871643066406
[1, 17750] loss_train: 0.007188, loss_test: 0.005546
time: 0.26405811309814453
time: 2.3155486583709717
[1, 17751] loss_train: 0.001554, loss_test: 0.005547
time: 0.2491462230682373
time: 2.3735787868499756
[1, 17752] loss_train: 0.002073, loss_test: 0.005550
time: 0.25751209259033203
time: 2.3965365886688232
[1, 17753] loss_train: 0.009179, loss_test: 0.005555
time: 0.27506065368652344
time: 2.4595508575439453
[1, 17754] loss_train: 0.003489, loss_test: 0.005561
time: 0.2540557384490967
time: 2.41854190826416
[1, 17755] loss_train: 0.003785, loss_test: 0.005567
time: 0.2710597515106201
time: 2.329521417617798
[1, 17756] loss_train: 0.005804, loss_test: 0.005572
time: 0.265059232711792
time: 2.3125176429748535
[1, 17757] loss_train: 0.007992, loss_test: 0.005571
time: 0.3020670413970947
time: 2.283018112182617
[1, 17758] loss_train: 0.000479, loss_test: 0.005575
time: 0.25205540657043457
time: 2.391986608505249
[1, 17759] loss_train: 0.005802, loss_test: 0.005579
time: 0.3030824661254883
time: 2.630403518676758
[1, 17760] loss_train: 0.006261, loss_test: 0.005580
time: 0.3000671863555908
time: 2.484586238861084
[1, 17761] loss_train: 0.005307, loss_test: 0.005582
time: 0.2780606746673584
time: 2.3985416889190674
[1, 17762] loss_train: 0.006370, loss_test: 0.005587
time: 0.265059232711792
time: 2.4939496517181396
[1, 17763] loss_train: 0.005331, loss_test: 0.005590
time: 0.2820618152618408
time: 2.506429433822632
[1, 17764] loss_train: 0.002875, loss_test: 0.005587
time: 0.28649282455444336
time: 2.591238021850586
[1, 17765] loss_train: 0.009889, loss_test: 0.005580
time: 0.2866523265838623
time: 2.5442821979522705
[1, 17766] loss_train: 0.008962, loss_test: 0.005572
time: 0.24805665016174316
time: 2.388401746749878
[1, 17767] loss_train: 0.001943, loss_test: 0.005570
time: 0.25505661964416504
time: 2.3843331336975098
[1, 17768] loss_train: 0.004399, loss_test: 0.005568
time: 0.3553485870361328
time: 2.473418951034546
[1, 17769] loss_train: 0.008081, loss_test: 0.005559
time: 0.25307130813598633
time: 2.39540433883667
[1, 17770] loss_train: 0.006422, loss_test: 0.005550
time: 0.25705957412719727
time: 2.286076784133911
[1, 17771] loss_train: 0.004678, loss_test: 0.005542
time: 0.248060941696167
time: 2.4062952995300293
[1, 17772] loss_train: 0.003777, loss_test: 0.005542
time: 0.24557876586914062
time: 2.2769296169281006
[1, 17773] loss_train: 0.003882, loss_test: 0.005547
time: 0.247056245803833
time: 2.266117572784424
[1, 17774] loss_train: 0.003734, loss_test: 0.005555
time: 0.2465672492980957
time: 2.2588064670562744
[1, 17775] loss_train: 0.003313, loss_test: 0.005564
time: 0.2509334087371826
time: 2.2922072410583496
[1, 17776] loss_train: 0.009238, loss_test: 0.005575
time: 0.25264501571655273
time: 2.2565510272979736
[1, 17777] loss_train: 0.011849, loss_test: 0.005587
time: 0.24505615234375
time: 2.3106040954589844
[1, 17778] loss_train: 0.004190, loss_test: 0.005596
time: 0.2450551986694336
time: 2.3221077919006348
[1, 17779] loss_train: 0.006061, loss_test: 0.005605
time: 0.25307273864746094
time: 2.329789638519287
[1, 17780] loss_train: 0.011010, loss_test: 0.005611
time: 0.2590603828430176
time: 2.273075580596924
[1, 17781] loss_train: 0.004545, loss_test: 0.005604
time: 0.2500956058502197
time: 2.2835891246795654
[1, 17782] loss_train: 0.002643, loss_test: 0.005593
time: 0.25505590438842773
time: 2.339106559753418
[1, 17783] loss_train: 0.003982, loss_test: 0.005584
time: 0.24353361129760742
time: 2.275829553604126
[1, 17784] loss_train: 0.008938, loss_test: 0.005575
time: 0.252077579498291
time: 2.3956730365753174
[1, 17785] loss_train: 0.008267, loss_test: 0.005563
time: 0.2450716495513916
time: 2.256870746612549
[1, 17786] loss_train: 0.015450, loss_test: 0.005543
time: 0.24455904960632324
time: 2.2433810234069824
[1, 17787] loss_train: 0.008800, loss_test: 0.005535
time: 0.24190068244934082
time: 2.2842559814453125
[1, 17788] loss_train: 0.006995, loss_test: 0.005538
time: 0.2478623390197754
time: 2.3244974613189697
[1, 17789] loss_train: 0.004275, loss_test: 0.005551
time: 0.2593061923980713
time: 2.2571959495544434
[1, 17790] loss_train: 0.008769, loss_test: 0.005568
time: 0.25885009765625
time: 2.376748561859131
[1, 17791] loss_train: 0.010789, loss_test: 0.005587
time: 0.2452852725982666
time: 2.3621275424957275
[1, 17792] loss_train: 0.007498, loss_test: 0.005593
time: 0.24515581130981445
time: 2.325836658477783
[1, 17793] loss_train: 0.003926, loss_test: 0.005592
time: 0.24905824661254883
time: 2.2825255393981934
[1, 17794] loss_train: 0.003596, loss_test: 0.005576
time: 0.24457359313964844
time: 2.304212808609009
[1, 17795] loss_train: 0.005104, loss_test: 0.005556
time: 0.2445671558380127
time: 2.3283753395080566
[1, 17796] loss_train: 0.006793, loss_test: 0.005539
time: 0.2470552921295166
time: 2.3295998573303223
[1, 17797] loss_train: 0.001283, loss_test: 0.005538
time: 0.24605679512023926
time: 2.26511287689209
[1, 17798] loss_train: 0.008116, loss_test: 0.005547
time: 0.24500536918640137
time: 2.3479509353637695
[1, 17799] loss_train: 0.007278, loss_test: 0.005558
time: 0.24407386779785156
time: 2.292482376098633
[1, 17800] loss_train: 0.012122, loss_test: 0.005569
time: 0.2669804096221924
time: 2.3612866401672363
[1, 17801] loss_train: 0.004400, loss_test: 0.005577
time: 0.24356532096862793
time: 2.2638988494873047
[1, 17802] loss_train: 0.010732, loss_test: 0.005578
time: 0.24672961235046387
time: 2.2420642375946045
[1, 17803] loss_train: 0.008044, loss_test: 0.005572
time: 0.2443540096282959
time: 2.3574438095092773
[1, 17804] loss_train: 0.002235, loss_test: 0.005569
time: 0.2449507713317871
time: 2.3991756439208984
[1, 17805] loss_train: 0.010104, loss_test: 0.005561
time: 0.24506926536560059
time: 2.2400588989257812
[1, 17806] loss_train: 0.007620, loss_test: 0.005554
time: 0.24556899070739746
time: 2.4503467082977295
[1, 17807] loss_train: 0.004278, loss_test: 0.005551
time: 0.2470567226409912
time: 2.3518877029418945
[1, 17808] loss_train: 0.013986, loss_test: 0.005544
time: 0.2520573139190674
time: 2.3057823181152344
[1, 17809] loss_train: 0.014520, loss_test: 0.005538
time: 0.2456190586090088
time: 2.229581117630005
[1, 17810] loss_train: 0.011982, loss_test: 0.005538
time: 0.25658464431762695
time: 2.2873151302337646
[1, 17811] loss_train: 0.007627, loss_test: 0.005542
time: 0.24406123161315918
time: 2.2598960399627686
[1, 17812] loss_train: 0.018999, loss_test: 0.005549
time: 0.24924898147583008
time: 2.5444459915161133
[1, 17813] loss_train: 0.009478, loss_test: 0.005557
time: 0.25257015228271484
time: 2.2828238010406494
[1, 17814] loss_train: 0.000933, loss_test: 0.005565
time: 0.24774742126464844
time: 2.4594459533691406
[1, 17815] loss_train: 0.005031, loss_test: 0.005573
time: 0.24355792999267578
time: 2.2866530418395996
[1, 17816] loss_train: 0.008091, loss_test: 0.005581
time: 0.24607181549072266
time: 2.3175501823425293
[1, 17817] loss_train: 0.013450, loss_test: 0.005589
time: 0.24405670166015625
time: 2.420684814453125
[1, 17818] loss_train: 0.002306, loss_test: 0.005594
time: 0.24458718299865723
time: 2.2545228004455566
[1, 17819] loss_train: 0.015482, loss_test: 0.005596
time: 0.248077392578125
time: 2.2999794483184814
[1, 17820] loss_train: 0.005459, loss_test: 0.005588
time: 0.25757527351379395
time: 2.398141860961914
[1, 17821] loss_train: 0.011878, loss_test: 0.005583
time: 0.2619190216064453
time: 2.302987575531006
[1, 17822] loss_train: 0.006503, loss_test: 0.005573
time: 0.24606585502624512
time: 2.264892339706421
[1, 17823] loss_train: 0.006706, loss_test: 0.005564
time: 0.24405431747436523
time: 2.3010501861572266
[1, 17824] loss_train: 0.000778, loss_test: 0.005559
time: 0.250943660736084
time: 2.4080986976623535
[1, 17825] loss_train: 0.007302, loss_test: 0.005559
time: 0.24561119079589844
time: 2.2788078784942627
[1, 17826] loss_train: 0.004225, loss_test: 0.005556
time: 0.24856233596801758
time: 2.3516628742218018
[1, 17827] loss_train: 0.010395, loss_test: 0.005555
time: 0.25458836555480957
time: 2.388944387435913
[1, 17828] loss_train: 0.005430, loss_test: 0.005554
time: 0.24766802787780762
time: 2.2465901374816895
[1, 17829] loss_train: 0.003723, loss_test: 0.005556
time: 0.24606561660766602
time: 2.246628522872925
[1, 17830] loss_train: 0.003548, loss_test: 0.005559
time: 0.2744464874267578
time: 2.3573262691497803
[1, 17831] loss_train: 0.006061, loss_test: 0.005564
time: 0.24514436721801758
time: 2.291706085205078
[1, 17832] loss_train: 0.004594, loss_test: 0.005571
time: 0.2450881004333496
time: 2.289971113204956
[1, 17833] loss_train: 0.014327, loss_test: 0.005570
time: 0.2493424415588379
time: 2.2545063495635986
[1, 17834] loss_train: 0.005614, loss_test: 0.005567
time: 0.24328947067260742
time: 2.2697291374206543
[1, 17835] loss_train: 0.002098, loss_test: 0.005567
time: 0.2463233470916748
time: 2.3382556438446045
[1, 17836] loss_train: 0.005010, loss_test: 0.005567
time: 0.24479365348815918
time: 2.4004909992218018
[1, 17837] loss_train: 0.006060, loss_test: 0.005564
time: 0.2446460723876953
time: 2.3422939777374268
[1, 17838] loss_train: 0.001519, loss_test: 0.005563
time: 0.24506378173828125
time: 2.3322508335113525
[1, 17839] loss_train: 0.002304, loss_test: 0.005563
time: 0.2450566291809082
time: 2.262094497680664
[1, 17840] loss_train: 0.009909, loss_test: 0.005559
time: 0.25956273078918457
time: 2.2396860122680664
[1, 17841] loss_train: 0.008073, loss_test: 0.005552
time: 0.24405694007873535
time: 2.252432346343994
[1, 17842] loss_train: 0.007980, loss_test: 0.005546
time: 0.24746942520141602
time: 2.2340521812438965
[1, 17843] loss_train: 0.006332, loss_test: 0.005541
time: 0.24805641174316406
time: 2.2903966903686523
[1, 17844] loss_train: 0.006646, loss_test: 0.005538
time: 0.2480607032775879
time: 2.3412811756134033
[1, 17845] loss_train: 0.010193, loss_test: 0.005537
time: 0.24505949020385742
time: 2.3884170055389404
[1, 17846] loss_train: 0.007411, loss_test: 0.005537
time: 0.2472221851348877
time: 2.26045823097229
[1, 17847] loss_train: 0.003269, loss_test: 0.005539
time: 0.24455857276916504
time: 2.409342050552368
[1, 17848] loss_train: 0.006896, loss_test: 0.005541
time: 0.24515128135681152
time: 2.3886990547180176
[1, 17849] loss_train: 0.003008, loss_test: 0.005543
time: 0.2690591812133789
time: 2.2965140342712402
[1, 17850] loss_train: 0.006322, loss_test: 0.005544
time: 0.2830626964569092
time: 2.283511161804199
[1, 17851] loss_train: 0.003583, loss_test: 0.005544
time: 0.2470545768737793
time: 2.2375030517578125
[1, 17852] loss_train: 0.014732, loss_test: 0.005546
time: 0.24605441093444824
time: 2.30751633644104
[1, 17853] loss_train: 0.010511, loss_test: 0.005547
time: 0.2490556240081787
time: 2.280510187149048
[1, 17854] loss_train: 0.010553, loss_test: 0.005548
time: 0.2470543384552002
time: 2.2765097618103027
[1, 17855] loss_train: 0.006094, loss_test: 0.005549
time: 0.24805498123168945
time: 2.2565040588378906
[1, 17856] loss_train: 0.005631, loss_test: 0.005551
time: 0.24405336380004883
time: 2.230501174926758
[1, 17857] loss_train: 0.007395, loss_test: 0.005551
time: 0.2450544834136963
time: 2.258507013320923
[1, 17858] loss_train: 0.004790, loss_test: 0.005552
time: 0.2580580711364746
time: 2.322519063949585
[1, 17859] loss_train: 0.006763, loss_test: 0.005551
time: 0.2470545768737793
time: 2.315518617630005
[1, 17860] loss_train: 0.012078, loss_test: 0.005552
time: 0.2630584239959717
time: 2.2885117530822754
[1, 17861] loss_train: 0.006082, loss_test: 0.005552
time: 0.2450568675994873
time: 2.2865114212036133
[1, 17862] loss_train: 0.001990, loss_test: 0.005551
time: 0.2510559558868408
time: 2.2937541007995605
[1, 17863] loss_train: 0.012586, loss_test: 0.005550
time: 0.24005436897277832
time: 2.289511203765869
[1, 17864] loss_train: 0.006327, loss_test: 0.005549
time: 0.24805521965026855
time: 2.2525036334991455
[1, 17865] loss_train: 0.002561, loss_test: 0.005549
time: 0.24605441093444824
time: 2.2895123958587646
[1, 17866] loss_train: 0.002881, loss_test: 0.005549
time: 0.24605488777160645
time: 2.2885146141052246
[1, 17867] loss_train: 0.005137, loss_test: 0.005548
time: 0.24405431747436523
time: 2.270509958267212
[1, 17868] loss_train: 0.004547, loss_test: 0.005547
time: 0.2470543384552002
time: 2.243502378463745
[1, 17869] loss_train: 0.004152, loss_test: 0.005545
time: 0.2530558109283447
time: 2.2475030422210693
[1, 17870] loss_train: 0.009911, loss_test: 0.005544
time: 0.2600574493408203
time: 2.2605061531066895
[1, 17871] loss_train: 0.004650, loss_test: 0.005547
time: 0.2450542449951172
time: 2.2705078125
[1, 17872] loss_train: 0.011206, loss_test: 0.005549
time: 0.24805569648742676
time: 2.2800137996673584
[1, 17873] loss_train: 0.004425, loss_test: 0.005552
time: 0.24605512619018555
time: 2.2495200634002686
[1, 17874] loss_train: 0.009919, loss_test: 0.005555
time: 0.2510559558868408
time: 2.2655069828033447
[1, 17875] loss_train: 0.009268, loss_test: 0.005558
time: 0.24605464935302734
time: 2.2395005226135254
[1, 17876] loss_train: 0.001654, loss_test: 0.005561
time: 0.2520558834075928
time: 2.243502378463745
[1, 17877] loss_train: 0.005440, loss_test: 0.005564
time: 0.24405479431152344
time: 2.2465012073516846
[1, 17878] loss_train: 0.005650, loss_test: 0.005565
time: 0.2490556240081787
time: 2.280510663986206
[1, 17879] loss_train: 0.010459, loss_test: 0.005561
time: 0.24305391311645508
time: 2.319519519805908
[1, 17880] loss_train: 0.002369, loss_test: 0.005558
time: 0.2580571174621582
time: 2.28351092338562
[1, 17881] loss_train: 0.003472, loss_test: 0.005555
time: 0.24405336380004883
time: 2.2725086212158203
[1, 17882] loss_train: 0.005163, loss_test: 0.005553
time: 0.24305343627929688
time: 2.2625064849853516
[1, 17883] loss_train: 0.012698, loss_test: 0.005552
time: 0.251056432723999
time: 2.274383068084717
[1, 17884] loss_train: 0.003822, loss_test: 0.005550
time: 0.24305415153503418
time: 2.2705068588256836
[1, 17885] loss_train: 0.009419, loss_test: 0.005551
time: 0.24605560302734375
time: 2.288510799407959
[1, 17886] loss_train: 0.009573, loss_test: 0.005552
time: 0.2450542449951172
time: 2.258505344390869
[1, 17887] loss_train: 0.006464, loss_test: 0.005553
time: 0.24405360221862793
time: 2.234499931335449
[1, 17888] loss_train: 0.007603, loss_test: 0.005555
time: 0.24305367469787598
time: 2.2455177307128906
[1, 17889] loss_train: 0.005811, loss_test: 0.005557
time: 0.24405407905578613
time: 2.253504514694214
[1, 17890] loss_train: 0.003253, loss_test: 0.005560
time: 0.258056640625
time: 2.2585055828094482
[1, 17891] loss_train: 0.012170, loss_test: 0.005566
time: 0.24405431747436523
time: 2.2565085887908936
[1, 17892] loss_train: 0.007675, loss_test: 0.005569
time: 0.24305510520935059
time: 2.251502275466919
[1, 17893] loss_train: 0.010011, loss_test: 0.005573
time: 0.2450556755065918
time: 2.2455012798309326
[1, 17894] loss_train: 0.004653, loss_test: 0.005570
time: 0.24605584144592285
time: 2.2590138912200928
[1, 17895] loss_train: 0.012987, loss_test: 0.005571
time: 0.24405431747436523
time: 2.267508029937744
[1, 17896] loss_train: 0.011212, loss_test: 0.005575
time: 0.24405360221862793
time: 2.265507221221924
[1, 17897] loss_train: 0.005051, loss_test: 0.005576
time: 0.24505400657653809
time: 2.266507148742676
[1, 17898] loss_train: 0.006971, loss_test: 0.005576
time: 0.24406766891479492
time: 2.242513418197632
[1, 17899] loss_train: 0.004847, loss_test: 0.005574
time: 0.2450544834136963
time: 2.2755088806152344
[1, 17900] loss_train: 0.002476, loss_test: 0.005570
time: 0.2560560703277588
time: 2.2365005016326904
[1, 17901] loss_train: 0.002384, loss_test: 0.005567
time: 0.24405407905578613
time: 2.2615058422088623
[1, 17902] loss_train: 0.004857, loss_test: 0.005569
time: 0.251056432723999
time: 2.234499216079712
[1, 17903] loss_train: 0.010486, loss_test: 0.005579
time: 0.2450549602508545
time: 2.299513578414917
[1, 17904] loss_train: 0.003574, loss_test: 0.005595
time: 0.24605441093444824
time: 2.270508289337158
[1, 17905] loss_train: 0.007752, loss_test: 0.005611
time: 0.2490546703338623
time: 2.316023349761963
[1, 17906] loss_train: 0.008603, loss_test: 0.005629
time: 0.2470545768737793
time: 2.22749924659729
[1, 17907] loss_train: 0.009284, loss_test: 0.005641
time: 0.24505376815795898
time: 2.242501735687256
[1, 17908] loss_train: 0.010486, loss_test: 0.005649
time: 0.24405384063720703
time: 2.279510259628296
[1, 17909] loss_train: 0.008235, loss_test: 0.005632
time: 0.24405407905578613
time: 2.281322479248047
[1, 17910] loss_train: 0.008366, loss_test: 0.005617
time: 0.2580571174621582
time: 2.237502336502075
[1, 17911] loss_train: 0.006454, loss_test: 0.005615
time: 0.24805498123168945
time: 2.25750470161438
[1, 17912] loss_train: 0.002630, loss_test: 0.005619
time: 0.24305343627929688
time: 2.248504638671875
[1, 17913] loss_train: 0.004239, loss_test: 0.005627
time: 0.24205446243286133
time: 2.2665061950683594
[1, 17914] loss_train: 0.011794, loss_test: 0.005638
time: 0.24405312538146973
time: 2.2635068893432617
[1, 17915] loss_train: 0.003011, loss_test: 0.005647
time: 0.24405407905578613
time: 2.267507314682007
[1, 17916] loss_train: 0.004866, loss_test: 0.005651
time: 0.2430579662322998
time: 2.2475063800811768
[1, 17917] loss_train: 0.007307, loss_test: 0.005648
time: 0.2470545768737793
time: 2.2515039443969727
[1, 17918] loss_train: 0.005350, loss_test: 0.005634
time: 0.24805498123168945
time: 2.251504898071289
[1, 17919] loss_train: 0.008552, loss_test: 0.005622
time: 0.247053861618042
time: 2.2385010719299316
[1, 17920] loss_train: 0.002895, loss_test: 0.005605
time: 0.2580592632293701
time: 2.2435050010681152
[1, 17921] loss_train: 0.001866, loss_test: 0.005592
time: 0.24405384063720703
time: 2.24100661277771
[1, 17922] loss_train: 0.010311, loss_test: 0.005586
time: 0.24405455589294434
time: 2.248502254486084
[1, 17923] loss_train: 0.006531, loss_test: 0.005584
time: 0.24405479431152344
time: 2.2665090560913086
[1, 17924] loss_train: 0.015491, loss_test: 0.005581
time: 0.24305343627929688
time: 2.263507127761841
[1, 17925] loss_train: 0.004901, loss_test: 0.005576
time: 0.25205540657043457
time: 2.2605056762695312
[1, 17926] loss_train: 0.003902, loss_test: 0.005576
time: 0.24405455589294434
time: 2.2405014038085938
[1, 17927] loss_train: 0.007021, loss_test: 0.005574
time: 0.24405336380004883
time: 2.2475028038024902
[1, 17928] loss_train: 0.010896, loss_test: 0.005573
time: 0.24205398559570312
time: 2.2635083198547363
[1, 17929] loss_train: 0.007300, loss_test: 0.005572
time: 0.24505400657653809
time: 2.258504867553711
[1, 17930] loss_train: 0.006844, loss_test: 0.005569
time: 0.2580568790435791
time: 2.241501808166504
[1, 17931] loss_train: 0.006600, loss_test: 0.005564
time: 0.2730600833892822
time: 2.2405011653900146
[1, 17932] loss_train: 0.001023, loss_test: 0.005563
time: 0.2510559558868408
time: 2.2515029907226562
[1, 17933] loss_train: 0.018897, loss_test: 0.005549
time: 0.24405407905578613
time: 2.2605061531066895
[1, 17934] loss_train: 0.005851, loss_test: 0.005543
time: 0.24305343627929688
time: 2.2405006885528564
[1, 17935] loss_train: 0.002157, loss_test: 0.005544
time: 0.24605393409729004
time: 2.2375004291534424
[1, 17936] loss_train: 0.001486, loss_test: 0.005549
time: 0.24405956268310547
time: 2.268507719039917
[1, 17937] loss_train: 0.001246, loss_test: 0.005554
time: 0.24405336380004883
time: 2.244518995285034
[1, 17938] loss_train: 0.002635, loss_test: 0.005560
time: 0.24305486679077148
time: 2.23249888420105
[1, 17939] loss_train: 0.002598, loss_test: 0.005564
time: 0.24605464935302734
time: 2.2365007400512695
[1, 17940] loss_train: 0.006900, loss_test: 0.005567
time: 0.2580571174621582
time: 2.2725086212158203
[1, 17941] loss_train: 0.006450, loss_test: 0.005567
time: 0.2450547218322754
time: 2.2415008544921875
[1, 17942] loss_train: 0.002932, loss_test: 0.005567
time: 0.24405384063720703
time: 2.2605085372924805
[1, 17943] loss_train: 0.001761, loss_test: 0.005568
time: 0.24405384063720703
time: 2.2755095958709717
[1, 17944] loss_train: 0.004265, loss_test: 0.005572
time: 0.24205374717712402
time: 2.2405011653900146
[1, 17945] loss_train: 0.005944, loss_test: 0.005578
time: 0.24505376815795898
time: 2.242501735687256
[1, 17946] loss_train: 0.009817, loss_test: 0.005590
time: 0.24305343627929688
time: 2.265507459640503
[1, 17947] loss_train: 0.004559, loss_test: 0.005603
time: 0.24405431747436523
time: 2.234499216079712
[1, 17948] loss_train: 0.005832, loss_test: 0.005621
time: 0.24305367469787598
time: 2.226498603820801
[1, 17949] loss_train: 0.005693, loss_test: 0.005641
time: 0.24605464935302734
time: 2.264514684677124
[1, 17950] loss_train: 0.002562, loss_test: 0.005664
time: 0.25905752182006836
time: 2.25850510597229
[1, 17951] loss_train: 0.002220, loss_test: 0.005686
time: 0.24405455589294434
time: 2.246511459350586
[1, 17952] loss_train: 0.003860, loss_test: 0.005696
time: 0.2450544834136963
time: 2.243501663208008
[1, 17953] loss_train: 0.004715, loss_test: 0.005702
time: 0.24406743049621582
time: 2.2365005016326904
[1, 17954] loss_train: 0.004606, loss_test: 0.005700
time: 0.24805474281311035
time: 2.2355005741119385
[1, 17955] loss_train: 0.006093, loss_test: 0.005674
time: 0.24205374717712402
time: 2.2875113487243652
[1, 17956] loss_train: 0.009227, loss_test: 0.005633
time: 0.24405407905578613
time: 2.245502471923828
[1, 17957] loss_train: 0.005078, loss_test: 0.005600
time: 0.24405455589294434
time: 2.2294983863830566
[1, 17958] loss_train: 0.008891, loss_test: 0.005572
time: 0.24805521965026855
time: 2.2425014972686768
[1, 17959] loss_train: 0.001151, loss_test: 0.005557
time: 0.24405431747436523
time: 2.2256369590759277
[1, 17960] loss_train: 0.004651, loss_test: 0.005552
time: 0.25705647468566895
time: 2.253504514694214
[1, 17961] loss_train: 0.011949, loss_test: 0.005552
time: 0.25005602836608887
time: 2.2264974117279053
[1, 17962] loss_train: 0.001730, loss_test: 0.005555
time: 0.25005626678466797
time: 2.235499382019043
[1, 17963] loss_train: 0.008408, loss_test: 0.005559
time: 0.24305415153503418
time: 2.2525033950805664
[1, 17964] loss_train: 0.005737, loss_test: 0.005562
time: 0.24305343627929688
time: 2.2355003356933594
[1, 17965] loss_train: 0.004659, loss_test: 0.005562
time: 0.24505400657653809
time: 2.2505040168762207
[1, 17966] loss_train: 0.009835, loss_test: 0.005564
time: 0.24505400657653809
time: 2.2635066509246826
[1, 17967] loss_train: 0.009677, loss_test: 0.005566
time: 0.24405622482299805
time: 2.2855117321014404
[1, 17968] loss_train: 0.009344, loss_test: 0.005570
time: 0.24405384063720703
time: 2.235502243041992
[1, 17969] loss_train: 0.015176, loss_test: 0.005582
time: 0.2450542449951172
time: 2.228498697280884
[1, 17970] loss_train: 0.007489, loss_test: 0.005589
time: 0.25705671310424805
time: 2.2385013103485107
[1, 17971] loss_train: 0.005687, loss_test: 0.005599
time: 0.24305367469787598
time: 2.254504919052124
[1, 17972] loss_train: 0.004488, loss_test: 0.005607
time: 0.2450544834136963
time: 2.2845098972320557
[1, 17973] loss_train: 0.009772, loss_test: 0.005613
time: 0.2470550537109375
time: 2.2615060806274414
[1, 17974] loss_train: 0.008502, loss_test: 0.005605
time: 0.24205398559570312
time: 2.261505365371704
[1, 17975] loss_train: 0.002495, loss_test: 0.005596
time: 0.24405503273010254
time: 2.248502731323242
[1, 17976] loss_train: 0.005234, loss_test: 0.005583
time: 0.24405360221862793
time: 2.231499671936035
[1, 17977] loss_train: 0.008217, loss_test: 0.005571
time: 0.24405360221862793
time: 2.2405006885528564
[1, 17978] loss_train: 0.009059, loss_test: 0.005560
time: 0.24105310440063477
time: 2.2415013313293457
[1, 17979] loss_train: 0.004349, loss_test: 0.005556
time: 0.243056058883667
time: 2.2475032806396484
[1, 17980] loss_train: 0.007580, loss_test: 0.005559
time: 0.2620580196380615
time: 2.255504608154297
[1, 17981] loss_train: 0.008006, loss_test: 0.005568
time: 0.24405479431152344
time: 2.2415010929107666
[1, 17982] loss_train: 0.001229, loss_test: 0.005575
time: 0.24205303192138672
time: 2.2505056858062744
[1, 17983] loss_train: 0.006298, loss_test: 0.005585
time: 0.24205470085144043
time: 2.236499786376953
[1, 17984] loss_train: 0.008349, loss_test: 0.005587
time: 0.24605441093444824
time: 2.2290024757385254
[1, 17985] loss_train: 0.005334, loss_test: 0.005594
time: 0.2430558204650879
time: 2.2260019779205322
[1, 17986] loss_train: 0.005611, loss_test: 0.005599
time: 0.24405407905578613
time: 2.2425014972686768
[1, 17987] loss_train: 0.002838, loss_test: 0.005604
time: 0.24506688117980957
time: 2.2345001697540283
[1, 17988] loss_train: 0.003336, loss_test: 0.005605
time: 0.24305415153503418
time: 2.235024929046631
[1, 17989] loss_train: 0.005341, loss_test: 0.005607
time: 0.24305415153503418
time: 2.2195048332214355
[1, 17990] loss_train: 0.009424, loss_test: 0.005596
time: 0.26105785369873047
time: 2.2525033950805664
[1, 17991] loss_train: 0.006457, loss_test: 0.005587
time: 0.2490556240081787
time: 2.256505250930786
[1, 17992] loss_train: 0.006613, loss_test: 0.005572
time: 0.24605512619018555
time: 2.240499973297119
[1, 17993] loss_train: 0.005568, loss_test: 0.005561
time: 0.24305391311645508
time: 2.2525036334991455
[1, 17994] loss_train: 0.004567, loss_test: 0.005557
time: 0.24605417251586914
time: 2.2214977741241455
[1, 17995] loss_train: 0.003289, loss_test: 0.005560
time: 0.24805450439453125
time: 2.240501642227173
[1, 17996] loss_train: 0.004099, loss_test: 0.005570
time: 0.2470550537109375
time: 2.238013982772827
[1, 17997] loss_train: 0.009114, loss_test: 0.005574
time: 0.24305415153503418
time: 2.228508472442627
[1, 17998] loss_train: 0.004729, loss_test: 0.005577
time: 0.24605488777160645
time: 2.2545039653778076
[1, 17999] loss_train: 0.011582, loss_test: 0.005573
time: 0.24205422401428223
time: 2.235499143600464
[1, 18000] loss_train: 0.009906, loss_test: 0.005567
time: 0.25905728340148926
time: 2.252504348754883
[1, 18001] loss_train: 0.001634, loss_test: 0.005565
time: 0.24305391311645508
time: 2.281510353088379
[1, 18002] loss_train: 0.004524, loss_test: 0.005562
time: 0.24605536460876465
time: 2.2645044326782227
[1, 18003] loss_train: 0.000666, loss_test: 0.005563
time: 0.24205398559570312
time: 2.243501901626587
[1, 18004] loss_train: 0.002411, loss_test: 0.005566
time: 0.24605488777160645
time: 2.286511182785034
[1, 18005] loss_train: 0.007447, loss_test: 0.005563
time: 0.24805593490600586
time: 2.222496509552002
[1, 18006] loss_train: 0.007327, loss_test: 0.005557
time: 0.24605536460876465
time: 2.245501756668091
[1, 18007] loss_train: 0.005007, loss_test: 0.005553
time: 0.24305510520935059
time: 2.234499216079712
[1, 18008] loss_train: 0.019072, loss_test: 0.005544
time: 0.2450542449951172
time: 2.2505149841308594
[1, 18009] loss_train: 0.003251, loss_test: 0.005538
time: 0.24605488777160645
time: 2.2395002841949463
[1, 18010] loss_train: 0.005610, loss_test: 0.005536
time: 0.25705647468566895
time: 2.2565057277679443
[1, 18011] loss_train: 0.007499, loss_test: 0.005535
time: 0.24505352973937988
time: 2.218496084213257
[1, 18012] loss_train: 0.006288, loss_test: 0.005534
time: 0.24305415153503418
time: 2.2495031356811523
[1, 18013] loss_train: 0.001680, loss_test: 0.005533
time: 0.24205327033996582
time: 2.247501850128174
[1, 18014] loss_train: 0.006765, loss_test: 0.005533
time: 0.2450547218322754
time: 2.2380223274230957
[1, 18015] loss_train: 0.001181, loss_test: 0.005533
time: 0.24305510520935059
time: 2.2525033950805664
[1, 18016] loss_train: 0.007035, loss_test: 0.005534
time: 0.24405384063720703
time: 2.270508289337158
[1, 18017] loss_train: 0.011066, loss_test: 0.005534
time: 0.24405407905578613
time: 2.234499216079712
[1, 18018] loss_train: 0.012458, loss_test: 0.005535
time: 0.24405527114868164
time: 2.2655060291290283
[1, 18019] loss_train: 0.011324, loss_test: 0.005536
time: 0.24405384063720703
time: 2.2515029907226562
[1, 18020] loss_train: 0.010710, loss_test: 0.005538
time: 0.25705742835998535
time: 2.2635064125061035
[1, 18021] loss_train: 0.015192, loss_test: 0.005540
time: 0.2450544834136963
time: 2.2855112552642822
[1, 18022] loss_train: 0.016390, loss_test: 0.005544
time: 0.24405407905578613
time: 2.256504535675049
[1, 18023] loss_train: 0.006359, loss_test: 0.005545
time: 0.24405479431152344
time: 2.2304983139038086
[1, 18024] loss_train: 0.010203, loss_test: 0.005550
time: 0.24405360221862793
time: 2.239501476287842
[1, 18025] loss_train: 0.004866, loss_test: 0.005557
time: 0.2450554370880127
time: 2.2430074214935303
[1, 18026] loss_train: 0.005880, loss_test: 0.005563
time: 0.24405407905578613
time: 2.2615063190460205
[1, 18027] loss_train: 0.005686, loss_test: 0.005563
time: 0.2450551986694336
time: 2.247502326965332
[1, 18028] loss_train: 0.001799, loss_test: 0.005560
time: 0.24305415153503418
time: 2.259504795074463
[1, 18029] loss_train: 0.003104, loss_test: 0.005552
time: 0.2450547218322754
time: 2.2385001182556152
[1, 18030] loss_train: 0.001372, loss_test: 0.005546
time: 0.2620580196380615
time: 2.268510103225708
[1, 18031] loss_train: 0.011016, loss_test: 0.005544
time: 0.24605441093444824
time: 2.2385008335113525
[1, 18032] loss_train: 0.008112, loss_test: 0.005542
time: 0.24405407905578613
time: 2.2465031147003174
[1, 18033] loss_train: 0.005797, loss_test: 0.005541
time: 0.24605441093444824
time: 2.2495031356811523
[1, 18034] loss_train: 0.002608, loss_test: 0.005541
time: 0.24205350875854492
time: 2.256021022796631
[1, 18035] loss_train: 0.007216, loss_test: 0.005542
time: 0.24505400657653809
time: 2.260505437850952
[1, 18036] loss_train: 0.010640, loss_test: 0.005544
time: 0.24305415153503418
time: 2.2370171546936035
[1, 18037] loss_train: 0.009609, loss_test: 0.005545
time: 0.2470545768737793
time: 2.2495033740997314
[1, 18038] loss_train: 0.006268, loss_test: 0.005546
time: 0.24305438995361328
time: 2.2825205326080322
[1, 18039] loss_train: 0.004349, loss_test: 0.005551
time: 0.24405384063720703
time: 2.2625064849853516
[1, 18040] loss_train: 0.005742, loss_test: 0.005556
time: 0.2600572109222412
time: 2.260514974594116
[1, 18041] loss_train: 0.013254, loss_test: 0.005555
time: 0.2450542449951172
time: 2.256504774093628
[1, 18042] loss_train: 0.002610, loss_test: 0.005556
time: 0.24305367469787598
time: 2.2715089321136475
[1, 18043] loss_train: 0.006363, loss_test: 0.005561
time: 0.24305319786071777
time: 2.2455027103424072
[1, 18044] loss_train: 0.006690, loss_test: 0.005566
time: 0.24405360221862793
time: 2.2505035400390625
[1, 18045] loss_train: 0.006168, loss_test: 0.005573
time: 0.24405527114868164
time: 2.2314982414245605
[1, 18046] loss_train: 0.009227, loss_test: 0.005580
time: 0.24305343627929688
time: 2.219508647918701
[1, 18047] loss_train: 0.007210, loss_test: 0.005577
time: 0.24305462837219238
time: 2.2324986457824707
[1, 18048] loss_train: 0.005984, loss_test: 0.005575
time: 0.24305319786071777
time: 2.2345004081726074
[1, 18049] loss_train: 0.004689, loss_test: 0.005572
time: 0.2540559768676758
time: 2.2525033950805664
[1, 18050] loss_train: 0.006738, loss_test: 0.005571
time: 0.2560572624206543
time: 2.260505437850952
[1, 18051] loss_train: 0.006682, loss_test: 0.005570
time: 0.25205540657043457
time: 2.2495057582855225
[1, 18052] loss_train: 0.004450, loss_test: 0.005570
time: 0.2450547218322754
time: 2.294513702392578
[1, 18053] loss_train: 0.002588, loss_test: 0.005571
time: 0.24305343627929688
time: 2.233506441116333
[1, 18054] loss_train: 0.009848, loss_test: 0.005572
time: 0.2450542449951172
time: 2.25850510597229
[1, 18055] loss_train: 0.008282, loss_test: 0.005573
time: 0.2450542449951172
time: 2.241502046585083
[1, 18056] loss_train: 0.001568, loss_test: 0.005574
time: 0.24305319786071777
time: 2.2595059871673584
[1, 18057] loss_train: 0.002439, loss_test: 0.005572
time: 0.2520570755004883
time: 2.22849702835083
[1, 18058] loss_train: 0.009893, loss_test: 0.005570
time: 0.247056245803833
time: 2.250511884689331
[1, 18059] loss_train: 0.005514, loss_test: 0.005567
time: 0.24405384063720703
time: 2.255497694015503
[1, 18060] loss_train: 0.003135, loss_test: 0.005563
time: 0.2580580711364746
time: 2.2675065994262695
[1, 18061] loss_train: 0.001682, loss_test: 0.005562
time: 0.24205327033996582
time: 2.2735090255737305
[1, 18062] loss_train: 0.009021, loss_test: 0.005559
time: 0.24205327033996582
time: 2.254504680633545
[1, 18063] loss_train: 0.002212, loss_test: 0.005559
time: 0.24305462837219238
time: 2.23349928855896
[1, 18064] loss_train: 0.002966, loss_test: 0.005559
time: 0.24305438995361328
time: 2.2645082473754883
[1, 18065] loss_train: 0.002231, loss_test: 0.005564
time: 0.24605512619018555
time: 2.273508071899414
[1, 18066] loss_train: 0.003435, loss_test: 0.005568
time: 0.24305391311645508
time: 2.2615058422088623
[1, 18067] loss_train: 0.004338, loss_test: 0.005573
time: 0.24305438995361328
time: 2.261505126953125
[1, 18068] loss_train: 0.004451, loss_test: 0.005579
time: 0.24305438995361328
time: 2.2425014972686768
[1, 18069] loss_train: 0.008774, loss_test: 0.005583
time: 0.2450551986694336
time: 2.2455012798309326
[1, 18070] loss_train: 0.002577, loss_test: 0.005589
time: 0.25705790519714355
time: 2.259504556655884
[1, 18071] loss_train: 0.008396, loss_test: 0.005590
time: 0.24305391311645508
time: 2.372530937194824
[1, 18072] loss_train: 0.007842, loss_test: 0.005581
time: 0.2670598030090332
time: 2.2805099487304688
[1, 18073] loss_train: 0.018028, loss_test: 0.005564
time: 0.24805450439453125
time: 2.2355003356933594
[1, 18074] loss_train: 0.004009, loss_test: 0.005551
time: 0.26205968856811523
time: 2.2615067958831787
[1, 18075] loss_train: 0.012753, loss_test: 0.005545
time: 0.24805498123168945
time: 2.2555038928985596
[1, 18076] loss_train: 0.002517, loss_test: 0.005544
time: 0.26105785369873047
time: 2.269507884979248
[1, 18077] loss_train: 0.001663, loss_test: 0.005548
time: 0.2470550537109375
time: 2.2324984073638916
[1, 18078] loss_train: 0.011871, loss_test: 0.005553
time: 0.24905681610107422
time: 2.236499309539795
[1, 18079] loss_train: 0.001583, loss_test: 0.005560
time: 0.2520558834075928
time: 2.268507719039917
[1, 18080] loss_train: 0.005506, loss_test: 0.005563
time: 0.2620584964752197
time: 2.2655065059661865
[1, 18081] loss_train: 0.003677, loss_test: 0.005564
time: 0.24605512619018555
time: 2.2425014972686768
[1, 18082] loss_train: 0.003251, loss_test: 0.005564
time: 0.2490551471710205
time: 2.242511749267578
[1, 18083] loss_train: 0.011391, loss_test: 0.005560
time: 0.24605441093444824
time: 2.265009641647339
[1, 18084] loss_train: 0.006296, loss_test: 0.005553
time: 0.2470548152923584
time: 2.2665064334869385
[1, 18085] loss_train: 0.008252, loss_test: 0.005541
time: 0.2470552921295166
time: 2.252520799636841
[1, 18086] loss_train: 0.003922, loss_test: 0.005542
time: 0.25205492973327637
time: 2.27150821685791
[1, 18087] loss_train: 0.006279, loss_test: 0.005552
time: 0.2510552406311035
time: 2.2385096549987793
[1, 18088] loss_train: 0.002212, loss_test: 0.005568
time: 0.24405407905578613
time: 2.266507148742676
[1, 18089] loss_train: 0.002153, loss_test: 0.005589
time: 0.2470557689666748
time: 2.2555031776428223
[1, 18090] loss_train: 0.004779, loss_test: 0.005608
time: 0.258056640625
time: 2.2895123958587646
[1, 18091] loss_train: 0.006357, loss_test: 0.005623
time: 0.24605393409729004
time: 2.2645070552825928
[1, 18092] loss_train: 0.005709, loss_test: 0.005630
time: 0.24505400657653809
time: 2.2595059871673584
[1, 18093] loss_train: 0.002756, loss_test: 0.005639
time: 0.25005507469177246
time: 2.280510663986206
[1, 18094] loss_train: 0.006305, loss_test: 0.005635
time: 0.2470541000366211
time: 2.2355005741119385
[1, 18095] loss_train: 0.010110, loss_test: 0.005625
time: 0.24605417251586914
time: 2.2505037784576416
[1, 18096] loss_train: 0.007346, loss_test: 0.005606
time: 0.24605441093444824
time: 2.2605056762695312
[1, 18097] loss_train: 0.010853, loss_test: 0.005582
time: 0.24805545806884766
time: 2.2254977226257324
[1, 18098] loss_train: 0.002053, loss_test: 0.005566
time: 0.24605464935302734
time: 2.2675068378448486
[1, 18099] loss_train: 0.017120, loss_test: 0.005553
time: 0.2450542449951172
time: 2.2525036334991455
[1, 18100] loss_train: 0.008582, loss_test: 0.005547
time: 0.26205921173095703
time: 2.283510684967041
[1, 18101] loss_train: 0.005392, loss_test: 0.005545
time: 0.2450551986694336
time: 2.2455015182495117
[1, 18102] loss_train: 0.005759, loss_test: 0.005545
time: 0.24805569648742676
time: 2.2675068378448486
[1, 18103] loss_train: 0.004432, loss_test: 0.005550
time: 0.24805545806884766
time: 2.252502918243408
[1, 18104] loss_train: 0.010063, loss_test: 0.005555
time: 0.2510566711425781
time: 2.235499858856201
[1, 18105] loss_train: 0.009744, loss_test: 0.005562
time: 0.24605441093444824
time: 2.2635087966918945
[1, 18106] loss_train: 0.002091, loss_test: 0.005563
time: 0.24405407905578613
time: 2.2671291828155518
[1, 18107] loss_train: 0.005379, loss_test: 0.005559
time: 0.24805450439453125
time: 2.256505012512207
[1, 18108] loss_train: 0.005881, loss_test: 0.005553
time: 0.25005578994750977
time: 2.334521532058716
[1, 18109] loss_train: 0.014012, loss_test: 0.005548
time: 0.2510557174682617
time: 2.2995150089263916
[1, 18110] loss_train: 0.003270, loss_test: 0.005542
time: 0.26631975173950195
time: 2.3670339584350586
[1, 18111] loss_train: 0.002045, loss_test: 0.005537
time: 0.2510566711425781
time: 2.2875144481658936
[1, 18112] loss_train: 0.004546, loss_test: 0.005534
time: 0.256056547164917
time: 2.295516014099121
[1, 18113] loss_train: 0.006966, loss_test: 0.005536
time: 0.2490553855895996
time: 2.2885115146636963
[1, 18114] loss_train: 0.002153, loss_test: 0.005539
time: 0.254056453704834
time: 2.2815098762512207
[1, 18115] loss_train: 0.008360, loss_test: 0.005545
time: 0.25005602836608887
time: 2.2745115756988525
[1, 18116] loss_train: 0.004755, loss_test: 0.005551
time: 0.2470543384552002
time: 2.266507387161255
[1, 18117] loss_train: 0.003041, loss_test: 0.005559
time: 0.2490553855895996
time: 2.256504535675049
[1, 18118] loss_train: 0.012446, loss_test: 0.005557
time: 0.24605488777160645
time: 2.2254979610443115
[1, 18119] loss_train: 0.012657, loss_test: 0.005550
time: 0.24605417251586914
time: 2.25850772857666
[1, 18120] loss_train: 0.005253, loss_test: 0.005540
time: 0.25905799865722656
time: 2.3125195503234863
[1, 18121] loss_train: 0.003859, loss_test: 0.005535
time: 0.24805545806884766
time: 2.2895116806030273
[1, 18122] loss_train: 0.007927, loss_test: 0.005532
time: 0.24505400657653809
time: 2.2495033740997314
[1, 18123] loss_train: 0.001427, loss_test: 0.005531
time: 0.24605536460876465
time: 2.2585041522979736
[1, 18124] loss_train: 0.005502, loss_test: 0.005531
time: 0.24805521965026855
time: 2.259505271911621
[1, 18125] loss_train: 0.005303, loss_test: 0.005530
time: 0.24605488777160645
time: 2.2535042762756348
[1, 18126] loss_train: 0.005696, loss_test: 0.005530
time: 0.24507927894592285
time: 2.229499101638794
[1, 18127] loss_train: 0.000785, loss_test: 0.005530
time: 0.2450547218322754
time: 2.250502347946167
[1, 18128] loss_train: 0.003641, loss_test: 0.005532
time: 0.2560570240020752
time: 2.2300665378570557
[1, 18129] loss_train: 0.003432, loss_test: 0.005537
time: 0.2450556755065918
time: 2.2430052757263184
[1, 18130] loss_train: 0.005011, loss_test: 0.005544
time: 0.2600584030151367
time: 2.2765085697174072
[1, 18131] loss_train: 0.005520, loss_test: 0.005552
time: 0.2470548152923584
time: 2.245502233505249
[1, 18132] loss_train: 0.004422, loss_test: 0.005559
time: 0.2470548152923584
time: 2.255504846572876
[1, 18133] loss_train: 0.004362, loss_test: 0.005564
time: 0.24605393409729004
time: 2.2335002422332764
[1, 18134] loss_train: 0.004537, loss_test: 0.005571
time: 0.24605488777160645
time: 2.2625060081481934
[1, 18135] loss_train: 0.003556, loss_test: 0.005576
time: 0.2470543384552002
time: 2.244502544403076
[1, 18136] loss_train: 0.010931, loss_test: 0.005579
time: 0.24605417251586914
time: 2.266507148742676
[1, 18137] loss_train: 0.005281, loss_test: 0.005579
time: 0.24605441093444824
time: 2.2385008335113525
[1, 18138] loss_train: 0.009193, loss_test: 0.005578
time: 0.2470555305480957
time: 2.2625057697296143
[1, 18139] loss_train: 0.007851, loss_test: 0.005572
time: 0.25305628776550293
time: 2.258505344390869
[1, 18140] loss_train: 0.007572, loss_test: 0.005566
time: 0.25905799865722656
time: 2.288510322570801
[1, 18141] loss_train: 0.001674, loss_test: 0.005562
time: 0.24905657768249512
time: 2.284510374069214
[1, 18142] loss_train: 0.005323, loss_test: 0.005561
time: 0.24805426597595215
time: 2.2515034675598145
[1, 18143] loss_train: 0.000977, loss_test: 0.005560
time: 0.24605441093444824
time: 2.2765097618103027
[1, 18144] loss_train: 0.006089, loss_test: 0.005557
time: 0.2470550537109375
time: 2.249502182006836
[1, 18145] loss_train: 0.007133, loss_test: 0.005551
time: 0.24605488777160645
time: 2.2595057487487793
[1, 18146] loss_train: 0.007108, loss_test: 0.005546
time: 0.2470552921295166
time: 2.2515029907226562
[1, 18147] loss_train: 0.005944, loss_test: 0.005542
time: 0.24605441093444824
time: 2.2715089321136475
[1, 18148] loss_train: 0.007732, loss_test: 0.005540
time: 0.24405384063720703
time: 2.2545034885406494
[1, 18149] loss_train: 0.008725, loss_test: 0.005537
time: 0.24805593490600586
time: 2.2785096168518066
[1, 18150] loss_train: 0.003562, loss_test: 0.005535
time: 0.2630589008331299
time: 2.298517942428589
[1, 18151] loss_train: 0.008609, loss_test: 0.005534
time: 0.2470533847808838
time: 2.277510166168213
[1, 18152] loss_train: 0.005692, loss_test: 0.005533
time: 0.25205516815185547
time: 2.2715086936950684
[1, 18153] loss_train: 0.012603, loss_test: 0.005532
time: 0.2470543384552002
time: 2.2410054206848145
[1, 18154] loss_train: 0.010493, loss_test: 0.005531
time: 0.2530558109283447
time: 2.256507158279419
[1, 18155] loss_train: 0.005856, loss_test: 0.005531
time: 0.2450551986694336
time: 2.2455015182495117
[1, 18156] loss_train: 0.000842, loss_test: 0.005534
time: 0.25905704498291016
time: 2.265021324157715
[1, 18157] loss_train: 0.002343, loss_test: 0.005540
time: 0.24605441093444824
time: 2.2755115032196045
[1, 18158] loss_train: 0.009973, loss_test: 0.005546
time: 0.24605441093444824
time: 2.2465028762817383
[1, 18159] loss_train: 0.021872, loss_test: 0.005553
time: 0.24605488777160645
time: 2.2640762329101562
[1, 18160] loss_train: 0.003009, loss_test: 0.005565
time: 0.2580573558807373
time: 2.286520004272461
[1, 18161] loss_train: 0.006673, loss_test: 0.005579
time: 0.25005626678466797
time: 2.2294981479644775
[1, 18162] loss_train: 0.008573, loss_test: 0.005591
time: 0.24605417251586914
time: 2.2895123958587646
[1, 18163] loss_train: 0.001630, loss_test: 0.005609
time: 0.24805450439453125
time: 2.2465028762817383
[1, 18164] loss_train: 0.008620, loss_test: 0.005628
time: 0.24505376815795898
time: 2.265010118484497
[1, 18165] loss_train: 0.006207, loss_test: 0.005646
time: 0.2470548152923584
time: 2.218505620956421
[1, 18166] loss_train: 0.002901, loss_test: 0.005663
time: 0.24605441093444824
time: 2.265507221221924
[1, 18167] loss_train: 0.010723, loss_test: 0.005676
time: 0.24605393409729004
time: 2.218498945236206
[1, 18168] loss_train: 0.007935, loss_test: 0.005686
time: 0.2470548152923584
time: 2.305515766143799
[1, 18169] loss_train: 0.004144, loss_test: 0.005664
time: 0.2470557689666748
time: 2.26950740814209
[1, 18170] loss_train: 0.006069, loss_test: 0.005644
time: 0.2650585174560547
time: 2.284511089324951
[1, 18171] loss_train: 0.003451, loss_test: 0.005628
time: 0.24605393409729004
time: 2.278510093688965
[1, 18172] loss_train: 0.002175, loss_test: 0.005614
time: 0.24605417251586914
time: 2.2795138359069824
[1, 18173] loss_train: 0.013181, loss_test: 0.005604
time: 0.25205206871032715
time: 2.299527168273926
[1, 18174] loss_train: 0.007050, loss_test: 0.005595
time: 0.25205564498901367
time: 2.3075156211853027
[1, 18175] loss_train: 0.011010, loss_test: 0.005580
time: 0.2543628215789795
time: 2.2815098762512207
[1, 18176] loss_train: 0.002425, loss_test: 0.005567
time: 0.2470548152923584
time: 2.2675070762634277
[1, 18177] loss_train: 0.012207, loss_test: 0.005552
time: 0.2490544319152832
time: 2.256504774093628
[1, 18178] loss_train: 0.006854, loss_test: 0.005546
time: 0.24805498123168945
time: 2.2655062675476074
[1, 18179] loss_train: 0.005802, loss_test: 0.005547
time: 0.24905633926391602
time: 2.2445013523101807
[1, 18180] loss_train: 0.004660, loss_test: 0.005552
time: 0.2630581855773926
time: 2.270508289337158
[1, 18181] loss_train: 0.005185, loss_test: 0.005559
time: 0.25305604934692383
time: 2.2745089530944824
[1, 18182] loss_train: 0.005480, loss_test: 0.005564
time: 0.24505376815795898
time: 2.2625067234039307
[1, 18183] loss_train: 0.008817, loss_test: 0.005569
time: 0.2510552406311035
time: 2.277517795562744
[1, 18184] loss_train: 0.012107, loss_test: 0.005565
time: 0.2470557689666748
time: 2.2675065994262695
[1, 18185] loss_train: 0.003080, loss_test: 0.005559
time: 0.2490551471710205
time: 2.2725088596343994
[1, 18186] loss_train: 0.005329, loss_test: 0.005549
time: 0.24605369567871094
time: 2.2475032806396484
[1, 18187] loss_train: 0.008129, loss_test: 0.005543
time: 0.2520565986633301
time: 2.258504629135132
[1, 18188] loss_train: 0.003813, loss_test: 0.005538
time: 0.2450542449951172
time: 2.2535130977630615
[1, 18189] loss_train: 0.006594, loss_test: 0.005540
time: 0.24905633926391602
time: 2.2245068550109863
[1, 18190] loss_train: 0.008583, loss_test: 0.005546
time: 0.25905823707580566
time: 2.2915117740631104
[1, 18191] loss_train: 0.008856, loss_test: 0.005555
time: 0.2470545768737793
time: 2.2465028762817383
[1, 18192] loss_train: 0.010376, loss_test: 0.005558
time: 0.2470548152923584
time: 2.2855112552642822
[1, 18193] loss_train: 0.008988, loss_test: 0.005560
time: 0.24605441093444824
time: 2.277509927749634
[1, 18194] loss_train: 0.010112, loss_test: 0.005560
time: 0.24805521965026855
time: 2.2625057697296143
[1, 18195] loss_train: 0.013337, loss_test: 0.005566
time: 0.24605536460876465
time: 2.273373603820801
[1, 18196] loss_train: 0.005581, loss_test: 0.005578
time: 0.2620584964752197
time: 2.284512996673584
[1, 18197] loss_train: 0.003410, loss_test: 0.005591
time: 0.24605464935302734
time: 2.297513961791992
[1, 18198] loss_train: 0.000896, loss_test: 0.005599
time: 0.24605417251586914
time: 2.2365007400512695
[1, 18199] loss_train: 0.003970, loss_test: 0.005602
time: 0.24605584144592285
time: 2.2475054264068604
[1, 18200] loss_train: 0.006160, loss_test: 0.005605
time: 0.26105809211730957
time: 2.3095169067382812
[1, 18201] loss_train: 0.006530, loss_test: 0.005610
time: 0.25505614280700684
time: 2.232499599456787
[1, 18202] loss_train: 0.009836, loss_test: 0.005619
time: 0.2450542449951172
time: 2.2785098552703857
[1, 18203] loss_train: 0.004606, loss_test: 0.005624
time: 0.24605488777160645
time: 2.2445015907287598
[1, 18204] loss_train: 0.012566, loss_test: 0.005626
time: 0.2490553855895996
time: 2.2635064125061035
[1, 18205] loss_train: 0.007511, loss_test: 0.005626
time: 0.2470545768737793
time: 2.2585058212280273
[1, 18206] loss_train: 0.008285, loss_test: 0.005604
time: 0.24605417251586914
time: 2.2785098552703857
[1, 18207] loss_train: 0.005548, loss_test: 0.005588
time: 0.2470550537109375
time: 2.23449969291687
[1, 18208] loss_train: 0.008899, loss_test: 0.005576
time: 0.25005602836608887
time: 2.260505199432373
[1, 18209] loss_train: 0.007680, loss_test: 0.005569
time: 0.2470552921295166
time: 2.248507022857666
[1, 18210] loss_train: 0.003000, loss_test: 0.005566
time: 0.2580573558807373
time: 2.3065176010131836
[1, 18211] loss_train: 0.012042, loss_test: 0.005563
time: 0.2470550537109375
time: 2.2455012798309326
[1, 18212] loss_train: 0.005838, loss_test: 0.005558
time: 0.2490556240081787
time: 2.228498935699463
[1, 18213] loss_train: 0.006077, loss_test: 0.005559
time: 0.24605441093444824
time: 2.2530276775360107
[1, 18214] loss_train: 0.005772, loss_test: 0.005561
time: 0.24605417251586914
time: 2.283511161804199
[1, 18215] loss_train: 0.011719, loss_test: 0.005561
time: 0.25005507469177246
time: 2.255504608154297
[1, 18216] loss_train: 0.005333, loss_test: 0.005563
time: 0.252056360244751
time: 2.2385003566741943
[1, 18217] loss_train: 0.007669, loss_test: 0.005564
time: 0.24605417251586914
time: 2.250504732131958
[1, 18218] loss_train: 0.005457, loss_test: 0.005563
time: 0.2490549087524414
time: 2.2695069313049316
[1, 18219] loss_train: 0.006090, loss_test: 0.005564
time: 0.24605488777160645
time: 2.2540128231048584
[1, 18220] loss_train: 0.009961, loss_test: 0.005564
time: 0.2630584239959717
time: 2.306518077850342
[1, 18221] loss_train: 0.002235, loss_test: 0.005563
time: 0.2470550537109375
time: 2.241978406906128
[1, 18222] loss_train: 0.006199, loss_test: 0.005566
time: 0.25505638122558594
time: 2.2755093574523926
[1, 18223] loss_train: 0.018731, loss_test: 0.005568
time: 0.24605488777160645
time: 2.2525036334991455
[1, 18224] loss_train: 0.003618, loss_test: 0.005573
time: 0.2540557384490967
time: 2.25850510597229
[1, 18225] loss_train: 0.007439, loss_test: 0.005582
time: 0.24605536460876465
time: 2.259505271911621
[1, 18226] loss_train: 0.007032, loss_test: 0.005592
time: 0.25205564498901367
time: 2.3005149364471436
[1, 18227] loss_train: 0.009196, loss_test: 0.005595
time: 0.24605488777160645
time: 2.224497079849243
[1, 18228] loss_train: 0.010130, loss_test: 0.005596
time: 0.25005531311035156
time: 2.2475028038024902
[1, 18229] loss_train: 0.011254, loss_test: 0.005597
time: 0.25005531311035156
time: 2.2765095233917236
[1, 18230] loss_train: 0.013841, loss_test: 0.005592
time: 0.25705671310424805
time: 2.2735087871551514
[1, 18231] loss_train: 0.015685, loss_test: 0.005588
time: 0.24805355072021484
time: 2.2365002632141113
[1, 18232] loss_train: 0.006108, loss_test: 0.005586
time: 0.24405312538146973
time: 2.240501642227173
[1, 18233] loss_train: 0.009368, loss_test: 0.005586
time: 0.24605393409729004
time: 2.2615065574645996
[1, 18234] loss_train: 0.006759, loss_test: 0.005587
time: 0.24605393409729004
time: 2.253504514694214
[1, 18235] loss_train: 0.009664, loss_test: 0.005589
time: 0.2450542449951172
time: 2.2485032081604004
[1, 18236] loss_train: 0.001923, loss_test: 0.005586
time: 0.25005531311035156
time: 2.216496229171753
[1, 18237] loss_train: 0.007442, loss_test: 0.005585
time: 0.24505400657653809
time: 2.2345070838928223
[1, 18238] loss_train: 0.010142, loss_test: 0.005588
time: 0.25005650520324707
time: 2.236499547958374
[1, 18239] loss_train: 0.004356, loss_test: 0.005587
time: 0.24505376815795898
time: 2.230499267578125
[1, 18240] loss_train: 0.003940, loss_test: 0.005580
time: 0.26805973052978516
time: 2.2925126552581787
[1, 18241] loss_train: 0.002088, loss_test: 0.005568
time: 0.2470545768737793
time: 2.240501642227173
[1, 18242] loss_train: 0.017825, loss_test: 0.005562
time: 0.2470548152923584
time: 2.247502565383911
[1, 18243] loss_train: 0.005267, loss_test: 0.005553
time: 0.2450547218322754
time: 2.2655062675476074
[1, 18244] loss_train: 0.006242, loss_test: 0.005547
time: 0.2490549087524414
time: 2.2455027103424072
[1, 18245] loss_train: 0.006816, loss_test: 0.005544
time: 0.24605512619018555
time: 2.2365036010742188
[1, 18246] loss_train: 0.005587, loss_test: 0.005542
time: 0.2520558834075928
time: 2.247502326965332
[1, 18247] loss_train: 0.004180, loss_test: 0.005543
time: 0.2470543384552002
time: 2.2465028762817383
[1, 18248] loss_train: 0.006818, loss_test: 0.005546
time: 0.25205540657043457
time: 2.2370119094848633
[1, 18249] loss_train: 0.010937, loss_test: 0.005550
time: 0.2470543384552002
time: 2.25850510597229
[1, 18250] loss_train: 0.006220, loss_test: 0.005557
time: 0.26606011390686035
time: 2.263009548187256
[1, 18251] loss_train: 0.007525, loss_test: 0.005563
time: 0.24605512619018555
time: 2.2246439456939697
[1, 18252] loss_train: 0.001083, loss_test: 0.005571
time: 0.25705695152282715
time: 2.243501901626587
[1, 18253] loss_train: 0.005678, loss_test: 0.005577
time: 0.24605441093444824
time: 2.243504285812378
[1, 18254] loss_train: 0.017760, loss_test: 0.005567
time: 0.256056547164917
time: 2.227898359298706
[1, 18255] loss_train: 0.007834, loss_test: 0.005559
time: 0.24805521965026855
time: 2.2134950160980225
[1, 18256] loss_train: 0.009146, loss_test: 0.005552
time: 0.25205540657043457
time: 2.241501808166504
[1, 18257] loss_train: 0.012628, loss_test: 0.005549
time: 0.2470552921295166
time: 2.223497152328491
[1, 18258] loss_train: 0.004707, loss_test: 0.005550
time: 0.25005459785461426
time: 2.267507791519165
[1, 18259] loss_train: 0.002449, loss_test: 0.005552
time: 0.24605488777160645
time: 2.2525038719177246
[1, 18260] loss_train: 0.005610, loss_test: 0.005555
time: 0.2620573043823242
time: 2.279510498046875
[1, 18261] loss_train: 0.010441, loss_test: 0.005557
time: 0.25205540657043457
time: 2.230499267578125
[1, 18262] loss_train: 0.006835, loss_test: 0.005558
time: 0.2510554790496826
time: 2.2234976291656494
[1, 18263] loss_train: 0.003876, loss_test: 0.005556
time: 0.2470545768737793
time: 2.240501880645752
[1, 18264] loss_train: 0.005676, loss_test: 0.005556
time: 0.25005578994750977
time: 2.2655060291290283
[1, 18265] loss_train: 0.004590, loss_test: 0.005558
time: 0.2470545768737793
time: 2.2575056552886963
[1, 18266] loss_train: 0.006714, loss_test: 0.005562
time: 0.2510561943054199
time: 2.224497079849243
[1, 18267] loss_train: 0.008404, loss_test: 0.005567
time: 0.24505400657653809
time: 2.2204971313476562
[1, 18268] loss_train: 0.011078, loss_test: 0.005566
time: 0.2510561943054199
time: 2.250502586364746
[1, 18269] loss_train: 0.007752, loss_test: 0.005565
time: 0.2470545768737793
time: 2.228498935699463
[1, 18270] loss_train: 0.013831, loss_test: 0.005557
time: 0.25905680656433105
time: 2.279510259628296
[1, 18271] loss_train: 0.005411, loss_test: 0.005552
time: 0.24605441093444824
time: 2.232499599456787
[1, 18272] loss_train: 0.006624, loss_test: 0.005549
time: 0.2490553855895996
time: 2.2665059566497803
[1, 18273] loss_train: 0.005682, loss_test: 0.005547
time: 0.2470545768737793
time: 2.2475030422210693
[1, 18274] loss_train: 0.009856, loss_test: 0.005545
time: 0.24805474281311035
time: 2.2535042762756348
[1, 18275] loss_train: 0.008189, loss_test: 0.005545
time: 0.24805474281311035
time: 2.2244982719421387
[1, 18276] loss_train: 0.006984, loss_test: 0.005547
time: 0.24605393409729004
time: 2.2405037879943848
[1, 18277] loss_train: 0.001865, loss_test: 0.005548
time: 0.2490549087524414
time: 2.244502544403076
[1, 18278] loss_train: 0.003948, loss_test: 0.005549
time: 0.24605464935302734
time: 2.2755088806152344
[1, 18279] loss_train: 0.004582, loss_test: 0.005549
time: 0.24805498123168945
time: 2.2775092124938965
[1, 18280] loss_train: 0.005418, loss_test: 0.005549
time: 0.2600574493408203
time: 2.2535037994384766
[1, 18281] loss_train: 0.002017, loss_test: 0.005547
time: 0.2490553855895996
time: 2.253504514694214
[1, 18282] loss_train: 0.011824, loss_test: 0.005547
time: 0.2490553855895996
time: 2.235499620437622
[1, 18283] loss_train: 0.005479, loss_test: 0.005546
time: 0.24605441093444824
time: 2.2385013103485107
[1, 18284] loss_train: 0.004637, loss_test: 0.005546
time: 0.2470541000366211
time: 2.2555043697357178
[1, 18285] loss_train: 0.011654, loss_test: 0.005545
time: 0.24605393409729004
time: 2.2505035400390625
[1, 18286] loss_train: 0.008942, loss_test: 0.005543
time: 0.251056432723999
time: 2.2525041103363037
[1, 18287] loss_train: 0.004479, loss_test: 0.005543
time: 0.2470541000366211
time: 2.2505035400390625
[1, 18288] loss_train: 0.002408, loss_test: 0.005544
time: 0.2470550537109375
time: 2.2385003566741943
[1, 18289] loss_train: 0.001035, loss_test: 0.005547
time: 0.24605393409729004
time: 2.2375011444091797
[1, 18290] loss_train: 0.016946, loss_test: 0.005546
time: 0.2620575428009033
time: 2.265507459640503
[1, 18291] loss_train: 0.009674, loss_test: 0.005542
time: 0.24605441093444824
time: 2.2715084552764893
[1, 18292] loss_train: 0.007726, loss_test: 0.005540
time: 0.2490549087524414
time: 2.232499837875366
[1, 18293] loss_train: 0.010520, loss_test: 0.005539
time: 0.24805474281311035
time: 2.2505040168762207
[1, 18294] loss_train: 0.003821, loss_test: 0.005539
time: 0.24805450439453125
time: 2.253504514694214
[1, 18295] loss_train: 0.009685, loss_test: 0.005538
time: 0.24605441093444824
time: 2.2274982929229736
[1, 18296] loss_train: 0.007952, loss_test: 0.005537
time: 0.24605464935302734
time: 2.267507314682007
[1, 18297] loss_train: 0.001861, loss_test: 0.005536
time: 0.2510554790496826
time: 2.2244982719421387
[1, 18298] loss_train: 0.008862, loss_test: 0.005535
time: 0.24505376815795898
time: 2.2545039653778076
[1, 18299] loss_train: 0.002998, loss_test: 0.005537
time: 0.2470548152923584
time: 2.267507791519165
[1, 18300] loss_train: 0.002190, loss_test: 0.005540
time: 0.25905776023864746
time: 2.286510705947876
[1, 18301] loss_train: 0.010428, loss_test: 0.005542
time: 0.2470552921295166
time: 2.2695069313049316
[1, 18302] loss_train: 0.007444, loss_test: 0.005544
time: 0.2490551471710205
time: 2.2555038928985596
[1, 18303] loss_train: 0.010728, loss_test: 0.005543
time: 0.24605488777160645
time: 2.2645063400268555
[1, 18304] loss_train: 0.007656, loss_test: 0.005542
time: 0.26105833053588867
time: 2.2515032291412354
[1, 18305] loss_train: 0.002475, loss_test: 0.005541
time: 0.2470545768737793
time: 2.2214972972869873
[1, 18306] loss_train: 0.003393, loss_test: 0.005541
time: 0.2510561943054199
time: 2.2535037994384766
[1, 18307] loss_train: 0.004300, loss_test: 0.005541
time: 0.2470550537109375
time: 2.2425012588500977
[1, 18308] loss_train: 0.002377, loss_test: 0.005541
time: 0.2560560703277588
time: 2.2355005741119385
[1, 18309] loss_train: 0.009236, loss_test: 0.005539
time: 0.24605441093444824
time: 2.2305033206939697
[1, 18310] loss_train: 0.003098, loss_test: 0.005539
time: 0.2620575428009033
time: 2.270508289337158
[1, 18311] loss_train: 0.005607, loss_test: 0.005539
time: 0.24805521965026855
time: 2.2765095233917236
[1, 18312] loss_train: 0.000682, loss_test: 0.005540
time: 0.25005531311035156
time: 2.259504556655884
[1, 18313] loss_train: 0.002477, loss_test: 0.005544
time: 0.247056245803833
time: 2.2445013523101807
[1, 18314] loss_train: 0.007863, loss_test: 0.005548
time: 0.24805498123168945
time: 2.2485034465789795
[1, 18315] loss_train: 0.008143, loss_test: 0.005549
time: 0.26405882835388184
time: 2.229498863220215
[1, 18316] loss_train: 0.004594, loss_test: 0.005551
time: 0.2510552406311035
time: 2.240501642227173
[1, 18317] loss_train: 0.006013, loss_test: 0.005544
time: 0.24505376815795898
time: 2.236499547958374
[1, 18318] loss_train: 0.007195, loss_test: 0.005540
time: 0.25005602836608887
time: 2.2565042972564697
[1, 18319] loss_train: 0.008768, loss_test: 0.005536
time: 0.25005531311035156
time: 2.2375009059906006
[1, 18320] loss_train: 0.007618, loss_test: 0.005533
time: 0.26105833053588867
time: 2.296513319015503
[1, 18321] loss_train: 0.006334, loss_test: 0.005534
time: 0.24805474281311035
time: 2.2395012378692627
[1, 18322] loss_train: 0.002533, loss_test: 0.005538
time: 0.2530558109283447
time: 2.269508123397827
[1, 18323] loss_train: 0.005954, loss_test: 0.005543
time: 0.24805521965026855
time: 2.234006881713867
[1, 18324] loss_train: 0.004670, loss_test: 0.005547
time: 0.254056453704834
time: 2.2495033740997314
[1, 18325] loss_train: 0.003145, loss_test: 0.005547
time: 0.24605417251586914
time: 2.2565054893493652
[1, 18326] loss_train: 0.003125, loss_test: 0.005543
time: 0.2600579261779785
time: 2.2785098552703857
[1, 18327] loss_train: 0.005818, loss_test: 0.005540
time: 0.247053861618042
time: 2.2635066509246826
[1, 18328] loss_train: 0.011180, loss_test: 0.005539
time: 0.25005531311035156
time: 2.2345001697540283
[1, 18329] loss_train: 0.005460, loss_test: 0.005540
time: 0.2450544834136963
time: 2.2385005950927734
[1, 18330] loss_train: 0.007415, loss_test: 0.005541
time: 0.2650589942932129
time: 2.2545032501220703
[1, 18331] loss_train: 0.003041, loss_test: 0.005543
time: 0.25005507469177246
time: 2.232499361038208
[1, 18332] loss_train: 0.005736, loss_test: 0.005547
time: 0.25005578994750977
time: 2.2495033740997314
[1, 18333] loss_train: 0.008754, loss_test: 0.005550
time: 0.2490551471710205
time: 2.2645068168640137
[1, 18334] loss_train: 0.008044, loss_test: 0.005552
time: 0.25005531311035156
time: 2.2064931392669678
[1, 18335] loss_train: 0.002697, loss_test: 0.005556
time: 0.24605417251586914
time: 2.2140190601348877
[1, 18336] loss_train: 0.011385, loss_test: 0.005556
time: 0.2490546703338623
time: 2.2605056762695312
[1, 18337] loss_train: 0.001579, loss_test: 0.005556
time: 0.25505638122558594
time: 2.2425050735473633
[1, 18338] loss_train: 0.003865, loss_test: 0.005554
time: 0.25005602836608887
time: 2.2415008544921875
[1, 18339] loss_train: 0.004605, loss_test: 0.005552
time: 0.24605417251586914
time: 2.245502471923828
[1, 18340] loss_train: 0.001564, loss_test: 0.005553
time: 0.2630584239959717
time: 2.257505178451538
[1, 18341] loss_train: 0.002616, loss_test: 0.005557
time: 0.2470545768737793
time: 2.2365002632141113
[1, 18342] loss_train: 0.002535, loss_test: 0.005562
time: 0.2510559558868408
time: 2.2615060806274414
[1, 18343] loss_train: 0.006719, loss_test: 0.005567
time: 0.2470548152923584
time: 2.2425014972686768
[1, 18344] loss_train: 0.006125, loss_test: 0.005567
time: 0.25205516815185547
time: 2.2074944972991943
[1, 18345] loss_train: 0.009280, loss_test: 0.005567
time: 0.2470543384552002
time: 2.2635183334350586
[1, 18346] loss_train: 0.005705, loss_test: 0.005563
time: 0.2490551471710205
time: 2.252504348754883
[1, 18347] loss_train: 0.005361, loss_test: 0.005559
time: 0.2470545768737793
time: 2.25907301902771
[1, 18348] loss_train: 0.002643, loss_test: 0.005554
time: 0.2540566921234131
time: 2.2595062255859375
[1, 18349] loss_train: 0.011706, loss_test: 0.005547
time: 0.24805450439453125
time: 2.257521152496338
[1, 18350] loss_train: 0.013274, loss_test: 0.005542
time: 0.2610585689544678
time: 2.284510374069214
[1, 18351] loss_train: 0.008013, loss_test: 0.005541
time: 0.2490558624267578
time: 2.2685070037841797
[1, 18352] loss_train: 0.004806, loss_test: 0.005542
time: 0.2500574588775635
time: 2.247102737426758
[1, 18353] loss_train: 0.008347, loss_test: 0.005544
time: 0.2470550537109375
time: 2.2675070762634277
[1, 18354] loss_train: 0.005571, loss_test: 0.005548
time: 0.2510561943054199
time: 2.270509719848633
[1, 18355] loss_train: 0.005925, loss_test: 0.005549
time: 0.2470545768737793
time: 2.2895123958587646
[1, 18356] loss_train: 0.003065, loss_test: 0.005546
time: 0.24805569648742676
time: 2.2475051879882812
[1, 18357] loss_train: 0.004429, loss_test: 0.005545
time: 0.24605441093444824
time: 2.2525041103363037
[1, 18358] loss_train: 0.009566, loss_test: 0.005542
time: 0.25205540657043457
time: 2.255504846572876
[1, 18359] loss_train: 0.005348, loss_test: 0.005541
time: 0.24605441093444824
time: 2.229498863220215
[1, 18360] loss_train: 0.007047, loss_test: 0.005536
time: 0.2590596675872803
time: 2.281510829925537
[1, 18361] loss_train: 0.009414, loss_test: 0.005533
time: 0.2470541000366211
time: 2.255505084991455
[1, 18362] loss_train: 0.012393, loss_test: 0.005532
time: 0.2490549087524414
time: 2.2605059146881104
[1, 18363] loss_train: 0.001184, loss_test: 0.005532
time: 0.2470560073852539
time: 2.2805089950561523
[1, 18364] loss_train: 0.002718, loss_test: 0.005533
time: 0.2510552406311035
time: 2.245502471923828
[1, 18365] loss_train: 0.018172, loss_test: 0.005533
time: 0.2470557689666748
time: 2.294523239135742
[1, 18366] loss_train: 0.001939, loss_test: 0.005537
time: 0.2540562152862549
time: 2.2815134525299072
[1, 18367] loss_train: 0.006796, loss_test: 0.005542
time: 0.24605417251586914
time: 2.23449969291687
[1, 18368] loss_train: 0.006984, loss_test: 0.005547
time: 0.25005507469177246
time: 2.2345001697540283
[1, 18369] loss_train: 0.004455, loss_test: 0.005550
time: 0.2470543384552002
time: 2.2695083618164062
[1, 18370] loss_train: 0.000403, loss_test: 0.005558
time: 0.2580571174621582
time: 2.293513059616089
[1, 18371] loss_train: 0.008193, loss_test: 0.005557
time: 0.2470545768737793
time: 2.2525036334991455
[1, 18372] loss_train: 0.006751, loss_test: 0.005553
time: 0.2470552921295166
time: 2.2415008544921875
[1, 18373] loss_train: 0.010528, loss_test: 0.005548
time: 0.24805545806884766
time: 2.2435011863708496
[1, 18374] loss_train: 0.002816, loss_test: 0.005545
time: 0.2450544834136963
time: 2.2395007610321045
[1, 18375] loss_train: 0.001789, loss_test: 0.005542
time: 0.24805521965026855
time: 2.230499267578125
[1, 18376] loss_train: 0.010621, loss_test: 0.005539
time: 0.2470545768737793
time: 2.2545039653778076
[1, 18377] loss_train: 0.007687, loss_test: 0.005536
time: 0.24605417251586914
time: 2.269516944885254
[1, 18378] loss_train: 0.003535, loss_test: 0.005535
time: 0.2520565986633301
time: 2.2545042037963867
[1, 18379] loss_train: 0.008490, loss_test: 0.005534
time: 0.25205564498901367
time: 2.2475028038024902
[1, 18380] loss_train: 0.006760, loss_test: 0.005534
time: 0.25905847549438477
time: 2.2565040588378906
[1, 18381] loss_train: 0.008067, loss_test: 0.005533
time: 0.24605417251586914
time: 2.265509843826294
[1, 18382] loss_train: 0.003156, loss_test: 0.005534
time: 0.2470552921295166
time: 2.2425036430358887
[1, 18383] loss_train: 0.006101, loss_test: 0.005536
time: 0.24605441093444824
time: 2.2334988117218018
[1, 18384] loss_train: 0.006195, loss_test: 0.005540
time: 0.2470555305480957
time: 2.2635059356689453
[1, 18385] loss_train: 0.014896, loss_test: 0.005540
time: 0.24505376815795898
time: 2.2134957313537598
[1, 18386] loss_train: 0.005187, loss_test: 0.005543
time: 0.2510559558868408
time: 2.2735092639923096
[1, 18387] loss_train: 0.005803, loss_test: 0.005544
time: 0.2470541000366211
time: 2.2605085372924805
[1, 18388] loss_train: 0.018662, loss_test: 0.005542
time: 0.24605417251586914
time: 2.2224974632263184
[1, 18389] loss_train: 0.000531, loss_test: 0.005540
time: 0.2450551986694336
time: 2.2405002117156982
[1, 18390] loss_train: 0.001691, loss_test: 0.005540
time: 0.26405835151672363
time: 2.2905125617980957
[1, 18391] loss_train: 0.007169, loss_test: 0.005540
time: 0.2470550537109375
time: 2.2395007610321045
[1, 18392] loss_train: 0.005285, loss_test: 0.005540
time: 0.24605512619018555
time: 2.2535030841827393
[1, 18393] loss_train: 0.003858, loss_test: 0.005542
time: 0.24605464935302734
time: 2.2295114994049072
[1, 18394] loss_train: 0.004226, loss_test: 0.005545
time: 0.2470555305480957
time: 2.2545037269592285
[1, 18395] loss_train: 0.010091, loss_test: 0.005548
time: 0.24605512619018555
time: 2.2264981269836426
[1, 18396] loss_train: 0.005237, loss_test: 0.005553
time: 0.25005555152893066
time: 2.233499050140381
[1, 18397] loss_train: 0.008545, loss_test: 0.005555
time: 0.25305604934692383
time: 2.2164952754974365
[1, 18398] loss_train: 0.009550, loss_test: 0.005555
time: 0.2510552406311035
time: 2.2294983863830566
[1, 18399] loss_train: 0.009972, loss_test: 0.005555
time: 0.24505400657653809
time: 2.2380125522613525
[1, 18400] loss_train: 0.008083, loss_test: 0.005553
time: 0.25905680656433105
time: 2.283511161804199
[1, 18401] loss_train: 0.005250, loss_test: 0.005553
time: 0.25005578994750977
time: 2.2655065059661865
[1, 18402] loss_train: 0.011910, loss_test: 0.005555
time: 0.2490556240081787
time: 2.2525033950805664
[1, 18403] loss_train: 0.001865, loss_test: 0.005556
time: 0.2470545768737793
time: 2.219496726989746
[1, 18404] loss_train: 0.009786, loss_test: 0.005560
time: 0.24805569648742676
time: 2.272508144378662
[1, 18405] loss_train: 0.010633, loss_test: 0.005563
time: 0.24605488777160645
time: 2.2365005016326904
[1, 18406] loss_train: 0.004095, loss_test: 0.005566
time: 0.24605417251586914
time: 2.263517141342163
[1, 18407] loss_train: 0.002912, loss_test: 0.005568
time: 0.2450549602508545
time: 2.2425012588500977
[1, 18408] loss_train: 0.006637, loss_test: 0.005574
time: 0.25205540657043457
time: 2.25201678276062
[1, 18409] loss_train: 0.004585, loss_test: 0.005581
time: 0.2450544834136963
time: 2.2385008335113525
[1, 18410] loss_train: 0.007978, loss_test: 0.005586
time: 0.2580564022064209
time: 2.3025152683258057
[1, 18411] loss_train: 0.003456, loss_test: 0.005581
time: 0.2470545768737793
time: 2.2405009269714355
[1, 18412] loss_train: 0.004155, loss_test: 0.005578
time: 0.2490558624267578
time: 2.2665069103240967
[1, 18413] loss_train: 0.001672, loss_test: 0.005578
time: 0.24505352973937988
time: 2.2335000038146973
[1, 18414] loss_train: 0.007633, loss_test: 0.005578
time: 0.24805426597595215
time: 2.240499973297119
[1, 18415] loss_train: 0.009844, loss_test: 0.005573
time: 0.2490549087524414
time: 2.26950740814209
[1, 18416] loss_train: 0.003926, loss_test: 0.005571
time: 0.2490553855895996
time: 2.2345004081726074
[1, 18417] loss_train: 0.011386, loss_test: 0.005568
time: 0.24505400657653809
time: 2.243502378463745
[1, 18418] loss_train: 0.003899, loss_test: 0.005566
time: 0.24805474281311035
time: 2.231499433517456
[1, 18419] loss_train: 0.005395, loss_test: 0.005563
time: 0.2510559558868408
time: 2.2274975776672363
[1, 18420] loss_train: 0.005984, loss_test: 0.005562
time: 0.2630596160888672
time: 2.259504556655884
[1, 18421] loss_train: 0.000613, loss_test: 0.005563
time: 0.24605488777160645
time: 2.2480063438415527
[1, 18422] loss_train: 0.004164, loss_test: 0.005564
time: 0.24805498123168945
time: 2.2705111503601074
[1, 18423] loss_train: 0.007270, loss_test: 0.005565
time: 0.2450549602508545
time: 2.2385003566741943
[1, 18424] loss_train: 0.004957, loss_test: 0.005568
time: 0.24605417251586914
time: 2.230499267578125
[1, 18425] loss_train: 0.003446, loss_test: 0.005573
time: 0.2490551471710205
time: 2.231499195098877
[1, 18426] loss_train: 0.001696, loss_test: 0.005582
time: 0.2490546703338623
time: 2.256505012512207
[1, 18427] loss_train: 0.007779, loss_test: 0.005584
time: 0.24605417251586914
time: 2.231499433517456
[1, 18428] loss_train: 0.004752, loss_test: 0.005585
time: 0.24805498123168945
time: 2.229499101638794
[1, 18429] loss_train: 0.003235, loss_test: 0.005586
time: 0.2450547218322754
time: 2.2495031356811523
[1, 18430] loss_train: 0.007067, loss_test: 0.005584
time: 0.2620575428009033
time: 2.2495059967041016
[1, 18431] loss_train: 0.006780, loss_test: 0.005578
time: 0.24605464935302734
time: 2.2675070762634277
[1, 18432] loss_train: 0.001050, loss_test: 0.005574
time: 0.2470550537109375
time: 2.24650239944458
[1, 18433] loss_train: 0.001627, loss_test: 0.005573
time: 0.24605417251586914
time: 2.254504680633545
[1, 18434] loss_train: 0.005163, loss_test: 0.005575
time: 0.24605464935302734
time: 2.23349928855896
[1, 18435] loss_train: 0.005629, loss_test: 0.005576
time: 0.24605512619018555
time: 2.27351975440979
[1, 18436] loss_train: 0.006513, loss_test: 0.005578
time: 0.27306103706359863
time: 2.3415260314941406
[1, 18437] loss_train: 0.007801, loss_test: 0.005581
time: 0.2540566921234131
time: 2.2815101146698
[1, 18438] loss_train: 0.004531, loss_test: 0.005582
time: 0.2490553855895996
time: 2.256504535675049
[1, 18439] loss_train: 0.006605, loss_test: 0.005584
time: 0.27506089210510254
time: 2.297513961791992
[1, 18440] loss_train: 0.008289, loss_test: 0.005583
time: 0.2720606327056885
time: 2.3275201320648193
[1, 18441] loss_train: 0.002657, loss_test: 0.005582
time: 0.2450549602508545
time: 2.3175179958343506
[1, 18442] loss_train: 0.008422, loss_test: 0.005576
time: 0.2530558109283447
time: 2.30651593208313
[1, 18443] loss_train: 0.007010, loss_test: 0.005569
time: 0.2620575428009033
time: 2.359528064727783
[1, 18444] loss_train: 0.007788, loss_test: 0.005559
time: 0.25005578994750977
time: 2.3355228900909424
[1, 18445] loss_train: 0.000781, loss_test: 0.005554
time: 0.2490551471710205
time: 2.3405325412750244
[1, 18446] loss_train: 0.012495, loss_test: 0.005547
time: 0.25305604934692383
time: 2.2905125617980957
[1, 18447] loss_train: 0.000388, loss_test: 0.005544
time: 0.2890644073486328
time: 2.3055150508880615
[1, 18448] loss_train: 0.007954, loss_test: 0.005543
time: 0.25105786323547363
time: 2.3015153408050537
[1, 18449] loss_train: 0.005336, loss_test: 0.005544
time: 0.28406262397766113
time: 2.301515579223633
[1, 18450] loss_train: 0.003574, loss_test: 0.005546
time: 0.25705695152282715
time: 2.234499216079712
[1, 18451] loss_train: 0.001109, loss_test: 0.005548
time: 0.24405407905578613
time: 2.239501476287842
[1, 18452] loss_train: 0.003032, loss_test: 0.005549
time: 0.24405384063720703
time: 2.230499029159546
[1, 18453] loss_train: 0.004983, loss_test: 0.005550
time: 0.24805474281311035
time: 2.2385168075561523
[1, 18454] loss_train: 0.004649, loss_test: 0.005551
time: 0.24805569648742676
time: 2.232499361038208
[1, 18455] loss_train: 0.021582, loss_test: 0.005555
time: 0.26605892181396484
time: 2.3145177364349365
[1, 18456] loss_train: 0.007701, loss_test: 0.005561
time: 0.25005483627319336
time: 2.346525192260742
[1, 18457] loss_train: 0.001195, loss_test: 0.005570
time: 0.24305343627929688
time: 2.385533571243286
[1, 18458] loss_train: 0.005228, loss_test: 0.005578
time: 0.24805545806884766
time: 2.2675070762634277
[1, 18459] loss_train: 0.003946, loss_test: 0.005581
time: 0.24305438995361328
time: 2.2580089569091797
[1, 18460] loss_train: 0.012585, loss_test: 0.005579
time: 0.2710604667663574
time: 2.2795095443725586
[1, 18461] loss_train: 0.008930, loss_test: 0.005573
time: 0.24305462837219238
time: 2.250502586364746
[1, 18462] loss_train: 0.006518, loss_test: 0.005569
time: 0.24805498123168945
time: 2.2755112648010254
[1, 18463] loss_train: 0.003322, loss_test: 0.005566
time: 0.24805521965026855
time: 2.2585055828094482
[1, 18464] loss_train: 0.005063, loss_test: 0.005566
time: 0.2450549602508545
time: 2.2895138263702393
[1, 18465] loss_train: 0.010774, loss_test: 0.005565
time: 0.24805498123168945
time: 2.2234976291656494
[1, 18466] loss_train: 0.008614, loss_test: 0.005564
time: 0.25005555152893066
time: 2.403536319732666
[1, 18467] loss_train: 0.003407, loss_test: 0.005564
time: 0.2490549087524414
time: 2.237502336502075
[1, 18468] loss_train: 0.003324, loss_test: 0.005565
time: 0.24405455589294434
time: 2.243501901626587
[1, 18469] loss_train: 0.007369, loss_test: 0.005564
time: 0.24605417251586914
time: 2.2725088596343994
[1, 18470] loss_train: 0.006846, loss_test: 0.005564
time: 0.2560563087463379
time: 2.2515041828155518
[1, 18471] loss_train: 0.004544, loss_test: 0.005564
time: 0.24305391311645508
time: 2.2335050106048584
[1, 18472] loss_train: 0.001125, loss_test: 0.005565
time: 0.24305367469787598
time: 2.236511468887329
[1, 18473] loss_train: 0.008055, loss_test: 0.005565
time: 0.24745583534240723
time: 2.246502161026001
[1, 18474] loss_train: 0.015166, loss_test: 0.005558
time: 0.24405431747436523
time: 2.244502067565918
[1, 18475] loss_train: 0.002349, loss_test: 0.005553
time: 0.24805521965026855
time: 2.2324986457824707
[1, 18476] loss_train: 0.001225, loss_test: 0.005551
time: 0.24405479431152344
time: 2.250502824783325
[1, 18477] loss_train: 0.005288, loss_test: 0.005549
time: 0.2490553855895996
time: 2.2525036334991455
[1, 18478] loss_train: 0.009065, loss_test: 0.005549
time: 0.2490553855895996
time: 2.2625057697296143
[1, 18479] loss_train: 0.002636, loss_test: 0.005549
time: 0.24605441093444824
time: 2.2575056552886963
[1, 18480] loss_train: 0.005842, loss_test: 0.005549
time: 0.258056640625
time: 2.2595059871673584
[1, 18481] loss_train: 0.007531, loss_test: 0.005549
time: 0.24805450439453125
time: 2.269507646560669
[1, 18482] loss_train: 0.003379, loss_test: 0.005548
time: 0.2450544834136963
time: 2.245502233505249
[1, 18483] loss_train: 0.001513, loss_test: 0.005547
time: 0.24805521965026855
time: 2.254507064819336
[1, 18484] loss_train: 0.005486, loss_test: 0.005546
time: 0.24305391311645508
time: 2.233499765396118
[1, 18485] loss_train: 0.007937, loss_test: 0.005544
time: 0.24905776977539062
time: 2.248502492904663
[1, 18486] loss_train: 0.005079, loss_test: 0.005543
time: 0.24405431747436523
time: 2.256504535675049
[1, 18487] loss_train: 0.007285, loss_test: 0.005542
time: 0.2510554790496826
time: 2.262504816055298
[1, 18488] loss_train: 0.013134, loss_test: 0.005540
time: 0.2470552921295166
time: 2.2545042037963867
[1, 18489] loss_train: 0.003670, loss_test: 0.005541
time: 0.251056432723999
time: 2.231501340866089
[1, 18490] loss_train: 0.005968, loss_test: 0.005545
time: 0.2560567855834961
time: 2.250049591064453
[1, 18491] loss_train: 0.002557, loss_test: 0.005549
time: 0.2490544319152832
time: 2.2345001697540283
[1, 18492] loss_train: 0.002271, loss_test: 0.005551
time: 0.24405336380004883
time: 2.257505416870117
[1, 18493] loss_train: 0.004833, loss_test: 0.005551
time: 0.2560567855834961
time: 2.2625062465667725
[1, 18494] loss_train: 0.009769, loss_test: 0.005551
time: 0.24205327033996582
time: 2.253504514694214
[1, 18495] loss_train: 0.007398, loss_test: 0.005552
time: 0.2490558624267578
time: 2.2375001907348633
[1, 18496] loss_train: 0.022153, loss_test: 0.005557
time: 0.24405360221862793
time: 2.2515039443969727
[1, 18497] loss_train: 0.014968, loss_test: 0.005567
time: 0.2690601348876953
time: 2.361528158187866
[1, 18498] loss_train: 0.006142, loss_test: 0.005574
time: 0.2760612964630127
time: 2.788623094558716
[1, 18499] loss_train: 0.007078, loss_test: 0.005579
time: 0.24505329132080078
time: 2.244502544403076
[1, 18500] loss_train: 0.000995, loss_test: 0.005577
time: 0.2580578327178955
time: 2.234499216079712
[1, 18501] loss_train: 0.004034, loss_test: 0.005574
time: 0.24405384063720703
time: 2.240504264831543
[1, 18502] loss_train: 0.005511, loss_test: 0.005569
time: 0.24405312538146973
time: 2.265507459640503
[1, 18503] loss_train: 0.005155, loss_test: 0.005562
time: 0.24405407905578613
time: 2.2815098762512207
[1, 18504] loss_train: 0.001821, loss_test: 0.005555
time: 0.24405479431152344
time: 2.2605068683624268
[1, 18505] loss_train: 0.005860, loss_test: 0.005552
time: 0.24305343627929688
time: 2.229498863220215
[1, 18506] loss_train: 0.004214, loss_test: 0.005555
time: 0.25005507469177246
time: 2.2795095443725586
[1, 18507] loss_train: 0.012886, loss_test: 0.005558
time: 0.2450542449951172
time: 2.2455027103424072
[1, 18508] loss_train: 0.002038, loss_test: 0.005556
time: 0.24405455589294434
time: 2.2675065994262695
[1, 18509] loss_train: 0.007595, loss_test: 0.005556
time: 0.25905776023864746
time: 2.3415236473083496
[1, 18510] loss_train: 0.011540, loss_test: 0.005559
time: 0.48410797119140625
time: 2.459550380706787
[1, 18511] loss_train: 0.002523, loss_test: 0.005565
time: 0.2530553340911865
time: 2.290513038635254
[1, 18512] loss_train: 0.013063, loss_test: 0.005569
time: 0.2850630283355713
time: 2.346525192260742
[1, 18513] loss_train: 0.012109, loss_test: 0.005555
time: 0.24805450439453125
time: 2.3045191764831543
[1, 18514] loss_train: 0.008581, loss_test: 0.005544
time: 0.2560567855834961
time: 2.323521137237549
[1, 18515] loss_train: 0.009512, loss_test: 0.005537
time: 0.2580597400665283
time: 2.397536039352417
[1, 18516] loss_train: 0.004340, loss_test: 0.005536
time: 0.25005578994750977
time: 2.393535614013672
[1, 18517] loss_train: 0.004365, loss_test: 0.005537
time: 0.2630581855773926
time: 2.3375229835510254
[1, 18518] loss_train: 0.006336, loss_test: 0.005538
time: 0.26805949211120605
time: 2.30651593208313
[1, 18519] loss_train: 0.004998, loss_test: 0.005538
time: 0.25305652618408203
time: 2.3045151233673096
[1, 18520] loss_train: 0.009185, loss_test: 0.005539
time: 0.25905704498291016
time: 2.277509927749634
[1, 18521] loss_train: 0.003135, loss_test: 0.005541
time: 0.2470545768737793
time: 2.273508071899414
[1, 18522] loss_train: 0.009884, loss_test: 0.005542
time: 0.2490551471710205
time: 2.260505437850952
[1, 18523] loss_train: 0.006638, loss_test: 0.005543
time: 0.2450544834136963
time: 2.268507719039917
[1, 18524] loss_train: 0.009868, loss_test: 0.005545
time: 0.24405431747436523
time: 2.262505531311035
[1, 18525] loss_train: 0.008662, loss_test: 0.005545
time: 0.2520558834075928
time: 2.255507469177246
[1, 18526] loss_train: 0.003466, loss_test: 0.005545
time: 0.2630586624145508
time: 2.3156895637512207
[1, 18527] loss_train: 0.006452, loss_test: 0.005543
time: 0.24805355072021484
time: 2.3285207748413086
[1, 18528] loss_train: 0.007339, loss_test: 0.005543
time: 0.2530558109283447
time: 2.315518379211426
[1, 18529] loss_train: 0.007744, loss_test: 0.005542
time: 0.25705647468566895
time: 2.289513349533081
[1, 18530] loss_train: 0.005712, loss_test: 0.005540
time: 0.2630577087402344
time: 2.2515039443969727
[1, 18531] loss_train: 0.007368, loss_test: 0.005540
time: 0.24605441093444824
time: 2.2835116386413574
[1, 18532] loss_train: 0.002871, loss_test: 0.005539
time: 0.25005459785461426
time: 2.2755093574523926
[1, 18533] loss_train: 0.003586, loss_test: 0.005540
time: 0.2450542449951172
time: 2.26601243019104
[1, 18534] loss_train: 0.005445, loss_test: 0.005543
time: 0.2450547218322754
time: 2.273508071899414
[1, 18535] loss_train: 0.010049, loss_test: 0.005542
time: 0.24505352973937988
time: 2.2945315837860107
[1, 18536] loss_train: 0.005135, loss_test: 0.005543
time: 0.2490544319152832
time: 2.2495036125183105
[1, 18537] loss_train: 0.007469, loss_test: 0.005543
time: 0.24405431747436523
time: 2.2254979610443115
[1, 18538] loss_train: 0.005795, loss_test: 0.005543
time: 0.25005507469177246
time: 2.249502658843994
[1, 18539] loss_train: 0.013280, loss_test: 0.005538
time: 0.2490556240081787
time: 2.244501829147339
[1, 18540] loss_train: 0.002020, loss_test: 0.005538
time: 0.26105785369873047
time: 2.2493395805358887
[1, 18541] loss_train: 0.003402, loss_test: 0.005540
time: 0.2450547218322754
time: 2.2590088844299316
[1, 18542] loss_train: 0.002752, loss_test: 0.005540
time: 0.24605417251586914
time: 2.244502544403076
[1, 18543] loss_train: 0.004706, loss_test: 0.005538
time: 0.24305319786071777
time: 2.2585060596466064
[1, 18544] loss_train: 0.008581, loss_test: 0.005536
time: 0.24405336380004883
time: 2.2605059146881104
[1, 18545] loss_train: 0.004151, loss_test: 0.005534
time: 0.2450544834136963
time: 2.2495038509368896
[1, 18546] loss_train: 0.007330, loss_test: 0.005533
time: 0.24405336380004883
time: 2.252504587173462
[1, 18547] loss_train: 0.011438, loss_test: 0.005534
time: 0.24605417251586914
time: 2.2510170936584473
[1, 18548] loss_train: 0.005089, loss_test: 0.005535
time: 0.24805521965026855
time: 2.2665064334869385
[1, 18549] loss_train: 0.008145, loss_test: 0.005537
time: 0.24405527114868164
time: 2.25850510597229
[1, 18550] loss_train: 0.004962, loss_test: 0.005539
time: 0.25905680656433105
time: 2.2765095233917236
[1, 18551] loss_train: 0.004227, loss_test: 0.005541
time: 0.24605417251586914
time: 2.267507314682007
[1, 18552] loss_train: 0.006978, loss_test: 0.005543
time: 0.24405384063720703
time: 2.2475030422210693
[1, 18553] loss_train: 0.000800, loss_test: 0.005545
time: 0.2450542449951172
time: 2.2615063190460205
[1, 18554] loss_train: 0.005359, loss_test: 0.005548
time: 0.24405360221862793
time: 2.2525041103363037
[1, 18555] loss_train: 0.007700, loss_test: 0.005551
time: 0.2470552921295166
time: 2.2144949436187744
[1, 18556] loss_train: 0.002701, loss_test: 0.005555
time: 0.24405455589294434
time: 2.2525033950805664
[1, 18557] loss_train: 0.005340, loss_test: 0.005557
time: 0.24405384063720703
time: 2.2875120639801025
[1, 18558] loss_train: 0.006598, loss_test: 0.005557
time: 0.24405503273010254
time: 2.2645061016082764
[1, 18559] loss_train: 0.010104, loss_test: 0.005559
time: 0.2490546703338623
time: 2.292513370513916
[1, 18560] loss_train: 0.005373, loss_test: 0.005561
time: 0.2670588493347168
time: 2.253504514694214
[1, 18561] loss_train: 0.014076, loss_test: 0.005560
time: 0.24605512619018555
time: 2.284510612487793
[1, 18562] loss_train: 0.007277, loss_test: 0.005551
time: 0.24305343627929688
time: 2.275509834289551
[1, 18563] loss_train: 0.008789, loss_test: 0.005546
time: 0.25005507469177246
time: 2.2615060806274414
[1, 18564] loss_train: 0.005413, loss_test: 0.005548
time: 0.24605417251586914
time: 2.253504514694214
[1, 18565] loss_train: 0.004814, loss_test: 0.005553
time: 0.24405407905578613
time: 2.2635066509246826
[1, 18566] loss_train: 0.009373, loss_test: 0.005557
time: 0.2490549087524414
time: 2.2845101356506348
[1, 18567] loss_train: 0.008277, loss_test: 0.005561
time: 0.2470541000366211
time: 2.2735087871551514
[1, 18568] loss_train: 0.008133, loss_test: 0.005565
time: 0.2470548152923584
time: 2.2915127277374268
[1, 18569] loss_train: 0.000858, loss_test: 0.005560
time: 0.24805402755737305
time: 2.2895126342773438
[1, 18570] loss_train: 0.018282, loss_test: 0.005564
time: 0.26405787467956543
time: 2.2765095233917236
[1, 18571] loss_train: 0.005112, loss_test: 0.005563
time: 0.2520558834075928
time: 2.268507957458496
[1, 18572] loss_train: 0.010943, loss_test: 0.005567
time: 0.2470543384552002
time: 2.2985146045684814
[1, 18573] loss_train: 0.004549, loss_test: 0.005568
time: 0.2560563087463379
time: 2.2655069828033447
[1, 18574] loss_train: 0.003570, loss_test: 0.005561
time: 0.24505400657653809
time: 2.2985143661499023
[1, 18575] loss_train: 0.007369, loss_test: 0.005556
time: 0.2490551471710205
time: 2.28351092338562
[1, 18576] loss_train: 0.009719, loss_test: 0.005550
time: 0.24605488777160645
time: 2.3015146255493164
[1, 18577] loss_train: 0.007232, loss_test: 0.005546
time: 0.24805498123168945
time: 2.2625062465667725
[1, 18578] loss_train: 0.005360, loss_test: 0.005541
time: 0.24805498123168945
time: 2.2805099487304688
[1, 18579] loss_train: 0.005774, loss_test: 0.005540
time: 0.2450547218322754
time: 2.2705180644989014
[1, 18580] loss_train: 0.001100, loss_test: 0.005543
time: 0.26405835151672363
time: 2.2645070552825928
[1, 18581] loss_train: 0.004546, loss_test: 0.005552
time: 0.2450549602508545
time: 2.275508403778076
[1, 18582] loss_train: 0.010810, loss_test: 0.005559
time: 0.25005507469177246
time: 2.3135178089141846
[1, 18583] loss_train: 0.002286, loss_test: 0.005569
time: 0.24605560302734375
time: 2.2955121994018555
[1, 18584] loss_train: 0.005728, loss_test: 0.005575
time: 0.24605488777160645
time: 2.272508382797241
[1, 18585] loss_train: 0.004050, loss_test: 0.005578
time: 0.24405384063720703
time: 2.232499599456787
[1, 18586] loss_train: 0.003419, loss_test: 0.005580
time: 0.24505400657653809
time: 2.252504587173462
[1, 18587] loss_train: 0.008035, loss_test: 0.005577
time: 0.24805450439453125
time: 2.2595055103302
[1, 18588] loss_train: 0.004384, loss_test: 0.005568
time: 0.2470541000366211
time: 2.264509439468384
[1, 18589] loss_train: 0.005023, loss_test: 0.005562
time: 0.2450542449951172
time: 2.255514144897461
[1, 18590] loss_train: 0.006346, loss_test: 0.005557
time: 0.2600569725036621
time: 2.259505033493042
[1, 18591] loss_train: 0.008386, loss_test: 0.005553
time: 0.2490558624267578
time: 2.2585058212280273
[1, 18592] loss_train: 0.010784, loss_test: 0.005553
time: 0.24505376815795898
time: 2.2625067234039307
[1, 18593] loss_train: 0.007990, loss_test: 0.005552
time: 0.24405384063720703
time: 2.2395007610321045
[1, 18594] loss_train: 0.012469, loss_test: 0.005554
time: 0.247053861618042
time: 2.2475037574768066
[1, 18595] loss_train: 0.000952, loss_test: 0.005556
time: 0.2470550537109375
time: 2.242502212524414
[1, 18596] loss_train: 0.007425, loss_test: 0.005561
time: 0.2470541000366211
time: 2.2525076866149902
[1, 18597] loss_train: 0.006296, loss_test: 0.005566
time: 0.24405384063720703
time: 2.2395012378692627
[1, 18598] loss_train: 0.011921, loss_test: 0.005572
time: 0.2470548152923584
time: 2.2605056762695312
[1, 18599] loss_train: 0.009519, loss_test: 0.005577
time: 0.24305367469787598
time: 2.2575154304504395
[1, 18600] loss_train: 0.005325, loss_test: 0.005578
time: 0.2610588073730469
time: 2.293410301208496
[1, 18601] loss_train: 0.010337, loss_test: 0.005574
time: 0.247053861618042
time: 2.2775118350982666
[1, 18602] loss_train: 0.002925, loss_test: 0.005571
time: 0.24905681610107422
time: 2.273507595062256
[1, 18603] loss_train: 0.009237, loss_test: 0.005567
time: 0.24305415153503418
time: 2.262505054473877
[1, 18604] loss_train: 0.003736, loss_test: 0.005565
time: 0.24305510520935059
time: 2.2566423416137695
[1, 18605] loss_train: 0.003682, loss_test: 0.005563
time: 0.2450547218322754
time: 2.265528678894043
[1, 18606] loss_train: 0.013695, loss_test: 0.005556
time: 0.24405407905578613
time: 2.258504629135132
[1, 18607] loss_train: 0.005076, loss_test: 0.005550
time: 0.24605584144592285
time: 2.2515032291412354
[1, 18608] loss_train: 0.008241, loss_test: 0.005548
time: 0.24305391311645508
time: 2.2475032806396484
[1, 18609] loss_train: 0.005612, loss_test: 0.005546
time: 0.2530555725097656
time: 2.2605059146881104
[1, 18610] loss_train: 0.006138, loss_test: 0.005545
time: 0.26105761528015137
time: 2.237004280090332
[1, 18611] loss_train: 0.018097, loss_test: 0.005544
time: 0.24505400657653809
time: 2.279510259628296
[1, 18612] loss_train: 0.005986, loss_test: 0.005546
time: 0.24205350875854492
time: 2.2835114002227783
[1, 18613] loss_train: 0.010580, loss_test: 0.005551
time: 0.24605488777160645
time: 2.2535035610198975
[1, 18614] loss_train: 0.012122, loss_test: 0.005561
time: 0.24405384063720703
time: 2.253504753112793
[1, 18615] loss_train: 0.002021, loss_test: 0.005563
time: 0.2470541000366211
time: 2.26250958442688
[1, 18616] loss_train: 0.002220, loss_test: 0.005559
time: 0.24405431747436523
time: 2.268507719039917
[1, 18617] loss_train: 0.006068, loss_test: 0.005553
time: 0.24805521965026855
time: 2.262505292892456
[1, 18618] loss_train: 0.008216, loss_test: 0.005543
time: 0.2450547218322754
time: 2.2485032081604004
[1, 18619] loss_train: 0.008572, loss_test: 0.005533
time: 0.24605417251586914
time: 2.277509927749634
[1, 18620] loss_train: 0.005837, loss_test: 0.005525
time: 0.26605916023254395
time: 2.2855112552642822
[1, 18621] loss_train: 0.017705, loss_test: 0.005520
time: 0.2470545768737793
time: 2.235377073287964
[1, 18622] loss_train: 0.011362, loss_test: 0.005516
time: 0.2450549602508545
time: 2.244501829147339
[1, 18623] loss_train: 0.009390, loss_test: 0.005516
time: 0.24505400657653809
time: 2.2485029697418213
[1, 18624] loss_train: 0.004178, loss_test: 0.005519
time: 0.24405407905578613
time: 2.257505416870117
[1, 18625] loss_train: 0.002459, loss_test: 0.005525
time: 0.24505376815795898
time: 2.2585055828094482
[1, 18626] loss_train: 0.000699, loss_test: 0.005530
time: 0.24305486679077148
time: 2.271507501602173
[1, 18627] loss_train: 0.012324, loss_test: 0.005532
time: 0.2530558109283447
time: 2.2525041103363037
[1, 18628] loss_train: 0.007490, loss_test: 0.005535
time: 0.24405503273010254
time: 2.2495017051696777
[1, 18629] loss_train: 0.005445, loss_test: 0.005537
time: 0.24405479431152344
time: 2.2515060901641846
[1, 18630] loss_train: 0.000765, loss_test: 0.005538
time: 0.25705695152282715
time: 2.254507064819336
[1, 18631] loss_train: 0.008113, loss_test: 0.005533
time: 0.24805402755737305
time: 2.284511089324951
[1, 18632] loss_train: 0.005010, loss_test: 0.005532
time: 0.24405479431152344
time: 2.2675068378448486
[1, 18633] loss_train: 0.004371, loss_test: 0.005532
time: 0.24405384063720703
time: 2.2755091190338135
[1, 18634] loss_train: 0.001583, loss_test: 0.005535
time: 0.2470545768737793
time: 2.2745091915130615
[1, 18635] loss_train: 0.004649, loss_test: 0.005538
time: 0.2450547218322754
time: 2.2645065784454346
[1, 18636] loss_train: 0.007530, loss_test: 0.005536
time: 0.24505376815795898
time: 2.2605061531066895
[1, 18637] loss_train: 0.010376, loss_test: 0.005530
time: 0.24305343627929688
time: 2.2505133152008057
[1, 18638] loss_train: 0.003637, loss_test: 0.005527
time: 0.2450547218322754
time: 2.256504535675049
[1, 18639] loss_train: 0.007962, loss_test: 0.005526
time: 0.24305343627929688
time: 2.262505531311035
[1, 18640] loss_train: 0.009148, loss_test: 0.005524
time: 0.265059232711792
time: 2.2885119915008545
[1, 18641] loss_train: 0.008170, loss_test: 0.005522
time: 0.25005483627319336
time: 2.2855117321014404
[1, 18642] loss_train: 0.003464, loss_test: 0.005521
time: 0.2470550537109375
time: 2.2805099487304688
[1, 18643] loss_train: 0.002866, loss_test: 0.005522
time: 0.2490558624267578
time: 2.2705078125
[1, 18644] loss_train: 0.008475, loss_test: 0.005524
time: 0.24505352973937988
time: 2.2495033740997314
[1, 18645] loss_train: 0.005158, loss_test: 0.005527
time: 0.24805474281311035
time: 2.255504608154297
[1, 18646] loss_train: 0.008003, loss_test: 0.005533
time: 0.2470541000366211
time: 2.2725088596343994
[1, 18647] loss_train: 0.004112, loss_test: 0.005532
time: 0.247053861618042
time: 2.257505416870117
[1, 18648] loss_train: 0.007502, loss_test: 0.005531
time: 0.24505376815795898
time: 2.2485034465789795
[1, 18649] loss_train: 0.002078, loss_test: 0.005531
time: 0.2470543384552002
time: 2.259505271911621
[1, 18650] loss_train: 0.005303, loss_test: 0.005529
time: 0.260059118270874
time: 2.227497100830078
[1, 18651] loss_train: 0.002204, loss_test: 0.005527
time: 0.24805569648742676
time: 2.2735085487365723
[1, 18652] loss_train: 0.014153, loss_test: 0.005526
time: 0.2540566921234131
time: 2.261505603790283
[1, 18653] loss_train: 0.006325, loss_test: 0.005524
time: 0.24805474281311035
time: 2.244502544403076
[1, 18654] loss_train: 0.011572, loss_test: 0.005523
time: 0.2490549087524414
time: 2.2495055198669434
[1, 18655] loss_train: 0.010003, loss_test: 0.005521
time: 0.24805450439453125
time: 2.229499340057373
[1, 18656] loss_train: 0.007726, loss_test: 0.005522
time: 0.24905705451965332
time: 2.2555034160614014
[1, 18657] loss_train: 0.008386, loss_test: 0.005524
time: 0.2470560073852539
time: 2.245502233505249
[1, 18658] loss_train: 0.007765, loss_test: 0.005526
time: 0.2470555305480957
time: 2.2505040168762207
[1, 18659] loss_train: 0.010726, loss_test: 0.005528
time: 0.2490549087524414
time: 2.255504608154297
[1, 18660] loss_train: 0.005728, loss_test: 0.005529
time: 0.2630584239959717
time: 2.232499837875366
[1, 18661] loss_train: 0.009977, loss_test: 0.005532
time: 0.25005507469177246
time: 2.2535042762756348
[1, 18662] loss_train: 0.009983, loss_test: 0.005534
time: 0.2490546703338623
time: 2.239501476287842
[1, 18663] loss_train: 0.001946, loss_test: 0.005537
time: 0.2470545768737793
time: 2.279510259628296
[1, 18664] loss_train: 0.006743, loss_test: 0.005538
time: 0.2510559558868408
time: 2.260505199432373
[1, 18665] loss_train: 0.002400, loss_test: 0.005537
time: 0.24605369567871094
time: 2.2765188217163086
[1, 18666] loss_train: 0.008774, loss_test: 0.005534
time: 0.24805617332458496
time: 2.2355005741119385
[1, 18667] loss_train: 0.005814, loss_test: 0.005530
time: 0.25005412101745605
time: 2.2635068893432617
[1, 18668] loss_train: 0.005370, loss_test: 0.005524
time: 0.2470550537109375
time: 2.2385001182556152
[1, 18669] loss_train: 0.000374, loss_test: 0.005520
time: 0.24605441093444824
time: 2.2665162086486816
[1, 18670] loss_train: 0.011022, loss_test: 0.005521
time: 0.2600579261779785
time: 2.2445015907287598
[1, 18671] loss_train: 0.002616, loss_test: 0.005523
time: 0.25005531311035156
time: 2.24650239944458
[1, 18672] loss_train: 0.006937, loss_test: 0.005526
time: 0.2490556240081787
time: 2.2695071697235107
[1, 18673] loss_train: 0.005671, loss_test: 0.005529
time: 0.24605464935302734
time: 2.2735090255737305
[1, 18674] loss_train: 0.007979, loss_test: 0.005530
time: 0.2470545768737793
time: 2.2715086936950684
[1, 18675] loss_train: 0.005040, loss_test: 0.005535
time: 0.2470550537109375
time: 2.2445013523101807
[1, 18676] loss_train: 0.009246, loss_test: 0.005542
time: 0.24805641174316406
time: 2.233499765396118
[1, 18677] loss_train: 0.003529, loss_test: 0.005551
time: 0.24405384063720703
time: 2.278510570526123
[1, 18678] loss_train: 0.006946, loss_test: 0.005557
time: 0.24805474281311035
time: 2.2585055828094482
[1, 18679] loss_train: 0.004607, loss_test: 0.005564
time: 0.24305415153503418
time: 2.273508071899414
[1, 18680] loss_train: 0.001985, loss_test: 0.005571
time: 0.2600581645965576
time: 2.2760140895843506
[1, 18681] loss_train: 0.006492, loss_test: 0.005568
time: 0.24405360221862793
time: 2.269510269165039
[1, 18682] loss_train: 0.005200, loss_test: 0.005567
time: 0.25305676460266113
time: 2.274508237838745
[1, 18683] loss_train: 0.002334, loss_test: 0.005562
time: 0.2450547218322754
time: 2.2575042247772217
[1, 18684] loss_train: 0.000906, loss_test: 0.005565
time: 0.24605536460876465
time: 2.2535035610198975
[1, 18685] loss_train: 0.001753, loss_test: 0.005568
time: 0.24605512619018555
time: 2.2405009269714355
[1, 18686] loss_train: 0.003393, loss_test: 0.005574
time: 0.2450547218322754
time: 2.2515039443969727
[1, 18687] loss_train: 0.001888, loss_test: 0.005585
time: 0.24305343627929688
time: 2.239508867263794
[1, 18688] loss_train: 0.002895, loss_test: 0.005597
time: 0.24305367469787598
time: 2.2830162048339844
[1, 18689] loss_train: 0.003925, loss_test: 0.005609
time: 0.24305367469787598
time: 2.2525038719177246
[1, 18690] loss_train: 0.000870, loss_test: 0.005617
time: 0.2580571174621582
time: 2.232499837875366
[1, 18691] loss_train: 0.010340, loss_test: 0.005618
time: 0.24505400657653809
time: 2.2765095233917236
[1, 18692] loss_train: 0.007199, loss_test: 0.005609
time: 0.24405407905578613
time: 2.268507480621338
[1, 18693] loss_train: 0.000608, loss_test: 0.005603
time: 0.24805498123168945
time: 2.233004331588745
[1, 18694] loss_train: 0.002501, loss_test: 0.005599
time: 0.24405431747436523
time: 2.250502586364746
[1, 18695] loss_train: 0.007167, loss_test: 0.005595
time: 0.2450544834136963
time: 2.2755095958709717
[1, 18696] loss_train: 0.002680, loss_test: 0.005594
time: 0.24305367469787598
time: 2.246502637863159
[1, 18697] loss_train: 0.006140, loss_test: 0.005592
time: 0.24905610084533691
time: 2.2500224113464355
[1, 18698] loss_train: 0.005868, loss_test: 0.005588
time: 0.24405479431152344
time: 2.2605056762695312
[1, 18699] loss_train: 0.003710, loss_test: 0.005582
time: 0.2510561943054199
time: 2.271507501602173
[1, 18700] loss_train: 0.006410, loss_test: 0.005577
time: 0.25705695152282715
time: 2.252734661102295
[1, 18701] loss_train: 0.009434, loss_test: 0.005569
time: 0.24305415153503418
time: 2.2645061016082764
[1, 18702] loss_train: 0.007218, loss_test: 0.005557
time: 0.24805521965026855
time: 2.254504680633545
[1, 18703] loss_train: 0.015053, loss_test: 0.005549
time: 0.2470545768737793
time: 2.2715086936950684
[1, 18704] loss_train: 0.006082, loss_test: 0.005543
time: 0.25305604934692383
time: 2.287510871887207
[1, 18705] loss_train: 0.007769, loss_test: 0.005541
time: 0.2450556755065918
time: 2.263009548187256
[1, 18706] loss_train: 0.006726, loss_test: 0.005540
time: 0.24505352973937988
time: 2.2675094604492188
[1, 18707] loss_train: 0.003433, loss_test: 0.005541
time: 0.2470543384552002
time: 2.2865114212036133
[1, 18708] loss_train: 0.010402, loss_test: 0.005540
time: 0.25305652618408203
time: 2.2755091190338135
[1, 18709] loss_train: 0.002266, loss_test: 0.005541
time: 0.24405336380004883
time: 2.2665083408355713
[1, 18710] loss_train: 0.002503, loss_test: 0.005542
time: 0.25905680656433105
time: 2.277510166168213
[1, 18711] loss_train: 0.002088, loss_test: 0.005542
time: 0.252056360244751
time: 2.275510787963867
[1, 18712] loss_train: 0.013038, loss_test: 0.005539
time: 0.24605464935302734
time: 2.2635064125061035
[1, 18713] loss_train: 0.001393, loss_test: 0.005539
time: 0.24405431747436523
time: 2.281510353088379
[1, 18714] loss_train: 0.010935, loss_test: 0.005541
time: 0.24605512619018555
time: 2.30251407623291
[1, 18715] loss_train: 0.011322, loss_test: 0.005541
time: 0.2510559558868408
time: 2.293513536453247
[1, 18716] loss_train: 0.004181, loss_test: 0.005541
time: 0.2470543384552002
time: 2.3005151748657227
[1, 18717] loss_train: 0.001560, loss_test: 0.005541
time: 0.24605536460876465
time: 2.2545058727264404
[1, 18718] loss_train: 0.008866, loss_test: 0.005542
time: 0.24605393409729004
time: 2.242502212524414
[1, 18719] loss_train: 0.003521, loss_test: 0.005543
time: 0.24505400657653809
time: 2.2775096893310547
[1, 18720] loss_train: 0.001150, loss_test: 0.005544
time: 0.2560572624206543
time: 2.268507242202759
[1, 18721] loss_train: 0.005570, loss_test: 0.005551
time: 0.24405407905578613
time: 2.289512872695923
[1, 18722] loss_train: 0.006404, loss_test: 0.005553
time: 0.24805450439453125
time: 2.274508476257324
[1, 18723] loss_train: 0.011229, loss_test: 0.005548
time: 0.2510554790496826
time: 2.2725088596343994
[1, 18724] loss_train: 0.002946, loss_test: 0.005548
time: 0.24305415153503418
time: 2.2655062675476074
[1, 18725] loss_train: 0.009326, loss_test: 0.005545
time: 0.25005602836608887
time: 2.2495031356811523
[1, 18726] loss_train: 0.013368, loss_test: 0.005543
time: 0.24205327033996582
time: 2.244502544403076
[1, 18727] loss_train: 0.002896, loss_test: 0.005547
time: 0.24605488777160645
time: 2.2505035400390625
[1, 18728] loss_train: 0.004937, loss_test: 0.005552
time: 0.25305628776550293
time: 2.270507574081421
[1, 18729] loss_train: 0.006169, loss_test: 0.005557
time: 0.24605488777160645
time: 2.2800145149230957
[1, 18730] loss_train: 0.003263, loss_test: 0.005559
time: 0.25505685806274414
time: 2.2875115871429443
[1, 18731] loss_train: 0.005040, loss_test: 0.005556
time: 0.24605441093444824
time: 2.2495028972625732
[1, 18732] loss_train: 0.006245, loss_test: 0.005550
time: 0.2490551471710205
time: 2.281510591506958
[1, 18733] loss_train: 0.009211, loss_test: 0.005547
time: 0.24405407905578613
time: 2.257504940032959
[1, 18734] loss_train: 0.014647, loss_test: 0.005548
time: 0.24405407905578613
time: 2.2695083618164062
[1, 18735] loss_train: 0.008913, loss_test: 0.005552
time: 0.24405407905578613
time: 2.2600080966949463
[1, 18736] loss_train: 0.017698, loss_test: 0.005560
time: 0.2470541000366211
time: 2.2735087871551514
[1, 18737] loss_train: 0.003305, loss_test: 0.005569
time: 0.2470548152923584
time: 2.2515039443969727
[1, 18738] loss_train: 0.004099, loss_test: 0.005577
time: 0.24305391311645508
time: 2.253504514694214
[1, 18739] loss_train: 0.007479, loss_test: 0.005587
time: 0.2470543384552002
time: 2.259010076522827
[1, 18740] loss_train: 0.006739, loss_test: 0.005591
time: 0.2580571174621582
time: 2.254504442214966
[1, 18741] loss_train: 0.016404, loss_test: 0.005592
time: 0.251056432723999
time: 2.2475156784057617
[1, 18742] loss_train: 0.002353, loss_test: 0.005590
time: 0.24405384063720703
time: 2.256505012512207
[1, 18743] loss_train: 0.003456, loss_test: 0.005584
time: 0.2520565986633301
time: 2.2805097103118896
[1, 18744] loss_train: 0.008032, loss_test: 0.005576
time: 0.24305367469787598
time: 2.269507884979248
[1, 18745] loss_train: 0.007361, loss_test: 0.005564
time: 0.24805426597595215
time: 2.2705204486846924
[1, 18746] loss_train: 0.007337, loss_test: 0.005556
time: 0.24305343627929688
time: 2.280513286590576
[1, 18747] loss_train: 0.008391, loss_test: 0.005552
time: 0.2450542449951172
time: 2.2895448207855225
[1, 18748] loss_train: 0.006905, loss_test: 0.005548
time: 0.24305343627929688
time: 2.2625064849853516
[1, 18749] loss_train: 0.003472, loss_test: 0.005546
time: 0.24405384063720703
time: 2.2665066719055176
[1, 18750] loss_train: 0.011276, loss_test: 0.005540
time: 0.26605939865112305
time: 2.2715084552764893
[1, 18751] loss_train: 0.004553, loss_test: 0.005535
time: 0.24305129051208496
time: 2.2345001697540283
[1, 18752] loss_train: 0.006828, loss_test: 0.005533
time: 0.24405431747436523
time: 2.2425012588500977
[1, 18753] loss_train: 0.002324, loss_test: 0.005533
time: 0.24405384063720703
time: 2.2415013313293457
[1, 18754] loss_train: 0.005868, loss_test: 0.005532
time: 0.24605464935302734
time: 2.265507221221924
[1, 18755] loss_train: 0.009442, loss_test: 0.005532
time: 0.25505661964416504
time: 2.28251051902771
[1, 18756] loss_train: 0.007502, loss_test: 0.005534
time: 0.2600572109222412
time: 2.304516315460205
[1, 18757] loss_train: 0.005469, loss_test: 0.005536
time: 0.309067964553833
time: 2.2885119915008545
[1, 18758] loss_train: 0.005883, loss_test: 0.005540
time: 0.2600572109222412
time: 2.303515672683716
[1, 18759] loss_train: 0.007676, loss_test: 0.005542
time: 0.24605464935302734
time: 2.2655067443847656
[1, 18760] loss_train: 0.010634, loss_test: 0.005544
time: 0.26105737686157227
time: 2.2505037784576416
[1, 18761] loss_train: 0.012639, loss_test: 0.005544
time: 0.24305367469787598
time: 2.2385008335113525
[1, 18762] loss_train: 0.006050, loss_test: 0.005546
time: 0.24405455589294434
time: 2.256504774093628
[1, 18763] loss_train: 0.009336, loss_test: 0.005550
time: 0.24205493927001953
time: 2.287510871887207
[1, 18764] loss_train: 0.007240, loss_test: 0.005554
time: 0.2490553855895996
time: 2.294512987136841
[1, 18765] loss_train: 0.005872, loss_test: 0.005557
time: 0.24205327033996582
time: 2.2675065994262695
[1, 18766] loss_train: 0.003614, loss_test: 0.005557
time: 0.2450563907623291
time: 2.278510093688965
[1, 18767] loss_train: 0.006258, loss_test: 0.005556
time: 0.25005555152893066
time: 2.3165175914764404
[1, 18768] loss_train: 0.009372, loss_test: 0.005555
time: 0.251056432723999
time: 2.342524290084839
[1, 18769] loss_train: 0.002614, loss_test: 0.005551
time: 0.24805545806884766
time: 2.305513858795166
[1, 18770] loss_train: 0.006963, loss_test: 0.005549
time: 0.2580568790435791
time: 2.266507148742676
[1, 18771] loss_train: 0.005609, loss_test: 0.005549
time: 0.2450544834136963
time: 2.2645068168640137
[1, 18772] loss_train: 0.002986, loss_test: 0.005552
time: 0.24505400657653809
time: 2.2765095233917236
[1, 18773] loss_train: 0.001187, loss_test: 0.005558
time: 0.25505638122558594
time: 2.302018165588379
[1, 18774] loss_train: 0.007532, loss_test: 0.005568
time: 0.24805521965026855
time: 2.265009641647339
[1, 18775] loss_train: 0.002736, loss_test: 0.005581
time: 0.2450542449951172
time: 2.2635066509246826
[1, 18776] loss_train: 0.010931, loss_test: 0.005595
time: 0.2470543384552002
time: 2.2625062465667725
[1, 18777] loss_train: 0.011748, loss_test: 0.005597
time: 0.24305391311645508
time: 2.2775096893310547
[1, 18778] loss_train: 0.002023, loss_test: 0.005598
time: 0.24405503273010254
time: 2.260504961013794
[1, 18779] loss_train: 0.003288, loss_test: 0.005603
time: 0.24305343627929688
time: 2.238511085510254
[1, 18780] loss_train: 0.001349, loss_test: 0.005606
time: 0.26105737686157227
time: 2.266507625579834
[1, 18781] loss_train: 0.011142, loss_test: 0.005609
time: 0.24205303192138672
time: 2.2575061321258545
[1, 18782] loss_train: 0.000997, loss_test: 0.005616
time: 0.24205255508422852
time: 2.2485127449035645
[1, 18783] loss_train: 0.004115, loss_test: 0.005621
time: 0.24305343627929688
time: 2.2715084552764893
[1, 18784] loss_train: 0.008822, loss_test: 0.005624
time: 0.24305367469787598
time: 2.2375009059906006
[1, 18785] loss_train: 0.008453, loss_test: 0.005615
time: 0.24205303192138672
time: 2.2585151195526123
[1, 18786] loss_train: 0.003627, loss_test: 0.005606
time: 0.24305319786071777
time: 2.246502161026001
[1, 18787] loss_train: 0.009223, loss_test: 0.005594
time: 0.24305438995361328
time: 2.2395012378692627
[1, 18788] loss_train: 0.005303, loss_test: 0.005586
time: 0.24305391311645508
time: 2.2855114936828613
[1, 18789] loss_train: 0.004619, loss_test: 0.005581
time: 0.24505376815795898
time: 2.241502285003662
[1, 18790] loss_train: 0.002011, loss_test: 0.005578
time: 0.2560563087463379
time: 2.2585055828094482
[1, 18791] loss_train: 0.017966, loss_test: 0.005569
time: 0.24305415153503418
time: 2.2785091400146484
[1, 18792] loss_train: 0.010179, loss_test: 0.005564
time: 0.24205374717712402
time: 2.2505040168762207
[1, 18793] loss_train: 0.007326, loss_test: 0.005564
time: 0.24405384063720703
time: 2.320521354675293
[1, 18794] loss_train: 0.006504, loss_test: 0.005564
time: 0.25005555152893066
time: 2.2645063400268555
[1, 18795] loss_train: 0.000928, loss_test: 0.005565
time: 0.24405431747436523
time: 2.2665066719055176
[1, 18796] loss_train: 0.007064, loss_test: 0.005566
time: 0.24805498123168945
time: 2.2645068168640137
[1, 18797] loss_train: 0.003851, loss_test: 0.005568
time: 0.2470543384552002
time: 2.277510166168213
[1, 18798] loss_train: 0.000812, loss_test: 0.005567
time: 0.24305343627929688
time: 2.2325034141540527
[1, 18799] loss_train: 0.004171, loss_test: 0.005566
time: 0.24605417251586914
time: 2.230499267578125
[1, 18800] loss_train: 0.009183, loss_test: 0.005567
time: 0.2620577812194824
time: 2.2345001697540283
[1, 18801] loss_train: 0.001477, loss_test: 0.005570
time: 0.24605441093444824
time: 2.2475032806396484
[1, 18802] loss_train: 0.007191, loss_test: 0.005576
time: 0.24305343627929688
time: 2.2825112342834473
[1, 18803] loss_train: 0.001057, loss_test: 0.005583
time: 0.24505400657653809
time: 2.283511161804199
[1, 18804] loss_train: 0.005239, loss_test: 0.005591
time: 0.24644017219543457
time: 2.287126302719116
[1, 18805] loss_train: 0.020365, loss_test: 0.005586
time: 0.24306988716125488
time: 2.2395009994506836
[1, 18806] loss_train: 0.004526, loss_test: 0.005583
time: 0.24305415153503418
time: 2.250502347946167
[1, 18807] loss_train: 0.006822, loss_test: 0.005583
time: 0.2450554370880127
time: 2.247502326965332
[1, 18808] loss_train: 0.006734, loss_test: 0.005582
time: 0.24405384063720703
time: 2.267510175704956
[1, 18809] loss_train: 0.007158, loss_test: 0.005582
time: 0.24505376815795898
time: 2.268507957458496
[1, 18810] loss_train: 0.005334, loss_test: 0.005585
time: 0.25505638122558594
time: 2.265509605407715
[1, 18811] loss_train: 0.004974, loss_test: 0.005589
time: 0.2470543384552002
time: 2.266507625579834
[1, 18812] loss_train: 0.005454, loss_test: 0.005589
time: 0.24405360221862793
time: 2.2625062465667725
[1, 18813] loss_train: 0.006916, loss_test: 0.005580
time: 0.24405407905578613
time: 2.2525041103363037
[1, 18814] loss_train: 0.007360, loss_test: 0.005570
time: 0.24205327033996582
time: 2.282510995864868
[1, 18815] loss_train: 0.013888, loss_test: 0.005558
time: 0.2450544834136963
time: 2.2485029697418213
[1, 18816] loss_train: 0.004908, loss_test: 0.005550
time: 0.24305343627929688
time: 2.254504680633545
[1, 18817] loss_train: 0.006709, loss_test: 0.005545
time: 0.24405455589294434
time: 2.2655065059661865
[1, 18818] loss_train: 0.003334, loss_test: 0.005541
time: 0.24205374717712402
time: 2.2605059146881104
[1, 18819] loss_train: 0.005892, loss_test: 0.005537
time: 0.24405407905578613
time: 2.257505178451538
[1, 18820] loss_train: 0.003974, loss_test: 0.005535
time: 0.256056547164917
time: 2.217496395111084
[1, 18821] loss_train: 0.002947, loss_test: 0.005534
time: 0.24405455589294434
time: 2.2375094890594482
[1, 18822] loss_train: 0.003148, loss_test: 0.005535
time: 0.24805569648742676
time: 2.2515032291412354
[1, 18823] loss_train: 0.003183, loss_test: 0.005538
time: 0.24305367469787598
time: 2.3405237197875977
[1, 18824] loss_train: 0.009308, loss_test: 0.005544
time: 0.258056640625
time: 2.3095169067382812
[1, 18825] loss_train: 0.006837, loss_test: 0.005551
time: 0.2450542449951172
time: 2.267507314682007
[1, 18826] loss_train: 0.004885, loss_test: 0.005558
time: 0.2620580196380615
time: 2.2975144386291504
[1, 18827] loss_train: 0.008287, loss_test: 0.005563
time: 0.24605488777160645
time: 2.285510540008545
[1, 18828] loss_train: 0.003659, loss_test: 0.005572
time: 0.2450549602508545
time: 2.272507905960083
[1, 18829] loss_train: 0.003067, loss_test: 0.005581
time: 0.2450549602508545
time: 2.257505178451538
[1, 18830] loss_train: 0.010460, loss_test: 0.005584
time: 0.278062105178833
time: 2.2765090465545654
[1, 18831] loss_train: 0.001291, loss_test: 0.005591
time: 0.24605441093444824
time: 2.2635087966918945
[1, 18832] loss_train: 0.001864, loss_test: 0.005600
time: 0.24505400657653809
time: 2.243504285812378
[1, 18833] loss_train: 0.009554, loss_test: 0.005597
time: 0.24605417251586914
time: 2.2545039653778076
[1, 18834] loss_train: 0.010303, loss_test: 0.005589
time: 0.24805569648742676
time: 2.264507293701172
[1, 18835] loss_train: 0.008867, loss_test: 0.005582
time: 0.24205398559570312
time: 2.2505030632019043
[1, 18836] loss_train: 0.003713, loss_test: 0.005577
time: 0.2450542449951172
time: 2.2694034576416016
[1, 18837] loss_train: 0.012062, loss_test: 0.005572
time: 0.254056453704834
time: 2.299514055252075
[1, 18838] loss_train: 0.007436, loss_test: 0.005565
time: 0.251056432723999
time: 2.2765088081359863
[1, 18839] loss_train: 0.008305, loss_test: 0.005560
time: 0.2530555725097656
time: 2.253504514694214
[1, 18840] loss_train: 0.005521, loss_test: 0.005559
time: 0.2630577087402344
time: 2.290512800216675
[1, 18841] loss_train: 0.002979, loss_test: 0.005559
time: 0.24805474281311035
time: 2.2650973796844482
[1, 18842] loss_train: 0.000813, loss_test: 0.005560
time: 0.24205636978149414
time: 2.2274975776672363
[1, 18843] loss_train: 0.006602, loss_test: 0.005561
time: 0.2450542449951172
time: 2.241501808166504
[1, 18844] loss_train: 0.006789, loss_test: 0.005559
time: 0.2490556240081787
time: 2.2545042037963867
[1, 18845] loss_train: 0.004731, loss_test: 0.005556
time: 0.25005483627319336
time: 2.285513162612915
[1, 18846] loss_train: 0.005611, loss_test: 0.005555
time: 0.2470548152923584
time: 2.267507314682007
[1, 18847] loss_train: 0.005616, loss_test: 0.005553
time: 0.24405407905578613
time: 2.243501901626587
[1, 18848] loss_train: 0.008587, loss_test: 0.005547
time: 0.25005555152893066
time: 2.2605059146881104
[1, 18849] loss_train: 0.010928, loss_test: 0.005543
time: 0.24505400657653809
time: 2.2485032081604004
[1, 18850] loss_train: 0.009971, loss_test: 0.005540
time: 0.25705671310424805
time: 2.2720112800598145
[1, 18851] loss_train: 0.005503, loss_test: 0.005538
time: 0.24405431747436523
time: 2.292512893676758
[1, 18852] loss_train: 0.003013, loss_test: 0.005536
time: 0.24305343627929688
time: 2.2515041828155518
[1, 18853] loss_train: 0.002828, loss_test: 0.005536
time: 0.2450542449951172
time: 2.2645089626312256
[1, 18854] loss_train: 0.003659, loss_test: 0.005537
time: 0.25505685806274414
time: 2.296513319015503
[1, 18855] loss_train: 0.005406, loss_test: 0.005539
time: 0.2540559768676758
time: 2.270507574081421
[1, 18856] loss_train: 0.004941, loss_test: 0.005543
time: 0.2470552921295166
time: 2.264508008956909
[1, 18857] loss_train: 0.009458, loss_test: 0.005546
time: 0.2450542449951172
time: 2.261505603790283
[1, 18858] loss_train: 0.006865, loss_test: 0.005548
time: 0.24405407905578613
time: 2.2234997749328613
[1, 18859] loss_train: 0.013687, loss_test: 0.005546
time: 0.2580571174621582
time: 2.3085169792175293
[1, 18860] loss_train: 0.007828, loss_test: 0.005542
time: 0.2600572109222412
time: 2.2845120429992676
[1, 18861] loss_train: 0.006295, loss_test: 0.005539
time: 0.2490549087524414
time: 2.309516668319702
[1, 18862] loss_train: 0.007810, loss_test: 0.005539
time: 0.2520558834075928
time: 2.3105173110961914
[1, 18863] loss_train: 0.005291, loss_test: 0.005540
time: 0.252056360244751
time: 2.286510944366455
[1, 18864] loss_train: 0.011091, loss_test: 0.005540
time: 0.24805450439453125
time: 2.2745089530944824
[1, 18865] loss_train: 0.000583, loss_test: 0.005539
time: 0.25005507469177246
time: 2.3005149364471436
[1, 18866] loss_train: 0.009718, loss_test: 0.005538
time: 0.25005531311035156
time: 2.293513298034668
[1, 18867] loss_train: 0.007532, loss_test: 0.005536
time: 0.2470552921295166
time: 2.261505365371704
[1, 18868] loss_train: 0.009552, loss_test: 0.005536
time: 0.24605441093444824
time: 2.242004632949829
[1, 18869] loss_train: 0.004485, loss_test: 0.005536
time: 0.24805521965026855
time: 2.2565042972564697
[1, 18870] loss_train: 0.006628, loss_test: 0.005534
time: 0.2580575942993164
time: 2.2775115966796875
[1, 18871] loss_train: 0.007943, loss_test: 0.005533
time: 0.24805521965026855
time: 2.284510850906372
[1, 18872] loss_train: 0.012219, loss_test: 0.005534
time: 0.24405360221862793
time: 2.268507719039917
[1, 18873] loss_train: 0.002989, loss_test: 0.005534
time: 0.24305391311645508
time: 2.2605059146881104
[1, 18874] loss_train: 0.003777, loss_test: 0.005534
time: 0.24505400657653809
time: 2.2345004081726074
[1, 18875] loss_train: 0.012820, loss_test: 0.005534
time: 0.24505376815795898
time: 2.277509927749634
[1, 18876] loss_train: 0.007608, loss_test: 0.005534
time: 0.2520558834075928
time: 2.313516616821289
[1, 18877] loss_train: 0.004955, loss_test: 0.005533
time: 0.24405574798583984
time: 2.279517412185669
[1, 18878] loss_train: 0.004256, loss_test: 0.005534
time: 0.24605441093444824
time: 2.2855112552642822
[1, 18879] loss_train: 0.006099, loss_test: 0.005535
time: 0.2450547218322754
time: 2.271507501602173
[1, 18880] loss_train: 0.005319, loss_test: 0.005536
time: 0.2580580711364746
time: 2.264026403427124
[1, 18881] loss_train: 0.007457, loss_test: 0.005535
time: 0.24305367469787598
time: 2.25850510597229
[1, 18882] loss_train: 0.008402, loss_test: 0.005535
time: 0.24305438995361328
time: 2.2304985523223877
[1, 18883] loss_train: 0.005235, loss_test: 0.005536
time: 0.24405360221862793
time: 2.255504846572876
[1, 18884] loss_train: 0.014917, loss_test: 0.005538
time: 0.24305486679077148
time: 2.263505220413208
[1, 18885] loss_train: 0.006998, loss_test: 0.005541
time: 0.24405407905578613
time: 2.2274980545043945
[1, 18886] loss_train: 0.007304, loss_test: 0.005543
time: 0.24305438995361328
time: 2.2975234985351562
[1, 18887] loss_train: 0.003222, loss_test: 0.005545
time: 0.2510557174682617
time: 2.27340030670166
[1, 18888] loss_train: 0.012466, loss_test: 0.005548
time: 0.24605488777160645
time: 2.2985141277313232
[1, 18889] loss_train: 0.001399, loss_test: 0.005545
time: 0.2470543384552002
time: 2.278510332107544
[1, 18890] loss_train: 0.007839, loss_test: 0.005543
time: 0.2760608196258545
time: 2.2815101146698
[1, 18891] loss_train: 0.002629, loss_test: 0.005537
time: 0.24305415153503418
time: 2.292513370513916
[1, 18892] loss_train: 0.003391, loss_test: 0.005532
time: 0.24605464935302734
time: 2.2730259895324707
[1, 18893] loss_train: 0.009006, loss_test: 0.005529
time: 0.24305415153503418
time: 2.258504629135132
[1, 18894] loss_train: 0.010917, loss_test: 0.005529
time: 0.2540557384490967
time: 2.321519136428833
[1, 18895] loss_train: 0.007584, loss_test: 0.005531
time: 0.24605464935302734
time: 2.258504867553711
[1, 18896] loss_train: 0.005966, loss_test: 0.005532
time: 0.24305367469787598
time: 2.2645063400268555
[1, 18897] loss_train: 0.001112, loss_test: 0.005536
time: 0.24305319786071777
time: 2.2715086936950684
[1, 18898] loss_train: 0.004092, loss_test: 0.005540
time: 0.2530558109283447
time: 2.2920289039611816
[1, 18899] loss_train: 0.006969, loss_test: 0.005546
time: 0.2490551471710205
time: 2.2965216636657715
[1, 18900] loss_train: 0.011233, loss_test: 0.005545
time: 0.25705671310424805
time: 2.408538818359375
[1, 18901] loss_train: 0.002199, loss_test: 0.005548
time: 0.252056360244751
time: 2.363032102584839
[1, 18902] loss_train: 0.003705, loss_test: 0.005551
time: 0.2490551471710205
time: 2.4055373668670654
[1, 18903] loss_train: 0.013258, loss_test: 0.005549
time: 0.29906654357910156
time: 2.302018642425537
[1, 18904] loss_train: 0.005000, loss_test: 0.005548
time: 0.24505400657653809
time: 2.266507625579834
[1, 18905] loss_train: 0.009622, loss_test: 0.005549
time: 0.25005483627319336
time: 2.266507387161255
[1, 18906] loss_train: 0.009702, loss_test: 0.005550
time: 0.24605488777160645
time: 2.25850510597229
[1, 18907] loss_train: 0.003375, loss_test: 0.005551
time: 0.2470543384552002
time: 2.2375028133392334
[1, 18908] loss_train: 0.009235, loss_test: 0.005549
time: 0.24505400657653809
time: 2.2505037784576416
[1, 18909] loss_train: 0.007425, loss_test: 0.005544
time: 0.24405479431152344
time: 2.2905118465423584
[1, 18910] loss_train: 0.014062, loss_test: 0.005540
time: 0.2560563087463379
time: 2.282510995864868
[1, 18911] loss_train: 0.001952, loss_test: 0.005541
time: 0.24405479431152344
time: 2.2535040378570557
[1, 18912] loss_train: 0.011314, loss_test: 0.005545
time: 0.24405360221862793
time: 2.2595057487487793
[1, 18913] loss_train: 0.001961, loss_test: 0.005548
time: 0.24405431747436523
time: 2.2765088081359863
[1, 18914] loss_train: 0.006532, loss_test: 0.005549
time: 0.2510561943054199
time: 2.247502088546753
[1, 18915] loss_train: 0.006287, loss_test: 0.005549
time: 0.24305367469787598
time: 2.2595057487487793
[1, 18916] loss_train: 0.002494, loss_test: 0.005544
time: 0.2450544834136963
time: 2.259505033493042
[1, 18917] loss_train: 0.005848, loss_test: 0.005540
time: 0.24405384063720703
time: 2.252504348754883
[1, 18918] loss_train: 0.007051, loss_test: 0.005537
time: 0.25705671310424805
time: 2.4001810550689697
[1, 18919] loss_train: 0.002553, loss_test: 0.005537
time: 0.267059326171875
time: 2.306515693664551
[1, 18920] loss_train: 0.004038, loss_test: 0.005542
time: 0.26405835151672363
time: 2.3344476222991943
[1, 18921] loss_train: 0.010301, loss_test: 0.005546
time: 0.2620584964752197
time: 2.2995142936706543
[1, 18922] loss_train: 0.005069, loss_test: 0.005553
time: 0.24805545806884766
time: 2.2875113487243652
[1, 18923] loss_train: 0.002674, loss_test: 0.005558
time: 0.25005578994750977
time: 2.298513889312744
[1, 18924] loss_train: 0.006701, loss_test: 0.005561
time: 0.26806020736694336
time: 2.3135173320770264
[1, 18925] loss_train: 0.003225, loss_test: 0.005565
time: 0.2490546703338623
time: 2.268507719039917
[1, 18926] loss_train: 0.009377, loss_test: 0.005565
time: 0.2450542449951172
time: 2.2700140476226807
[1, 18927] loss_train: 0.001791, loss_test: 0.005567
time: 0.25305604934692383
time: 2.278510093688965
[1, 18928] loss_train: 0.009604, loss_test: 0.005570
time: 0.24505400657653809
time: 2.362531900405884
[1, 18929] loss_train: 0.007423, loss_test: 0.005571
time: 0.2650594711303711
time: 2.633589744567871
[1, 18930] loss_train: 0.002704, loss_test: 0.005575
time: 0.2690610885620117
time: 2.3565409183502197
[1, 18931] loss_train: 0.003461, loss_test: 0.005576
time: 0.249053955078125
time: 2.3255202770233154
[1, 18932] loss_train: 0.001870, loss_test: 0.005578
time: 0.2470555305480957
time: 2.2925124168395996
[1, 18933] loss_train: 0.003058, loss_test: 0.005580
time: 0.24805474281311035
time: 2.2715089321136475
[1, 18934] loss_train: 0.010823, loss_test: 0.005580
time: 0.2730598449707031
time: 2.3440282344818115
[1, 18935] loss_train: 0.001217, loss_test: 0.005581
time: 0.25005578994750977
time: 2.2645063400268555
[1, 18936] loss_train: 0.007024, loss_test: 0.005584
time: 0.24405360221862793
time: 2.3225202560424805
[1, 18937] loss_train: 0.008734, loss_test: 0.005586
time: 0.269059419631958
time: 2.28351092338562
[1, 18938] loss_train: 0.006569, loss_test: 0.005590
time: 0.2540571689605713
time: 2.301514148712158
[1, 18939] loss_train: 0.006540, loss_test: 0.005595
time: 0.2490551471710205
time: 2.2605061531066895
[1, 18940] loss_train: 0.000890, loss_test: 0.005599
time: 0.25905704498291016
time: 2.281510591506958
[1, 18941] loss_train: 0.013077, loss_test: 0.005587
time: 0.29906630516052246
time: 2.2885122299194336
[1, 18942] loss_train: 0.009588, loss_test: 0.005574
time: 0.24405360221862793
time: 2.270508289337158
[1, 18943] loss_train: 0.005075, loss_test: 0.005565
time: 0.26205897331237793
time: 2.299514055252075
[1, 18944] loss_train: 0.012711, loss_test: 0.005558
time: 0.24605488777160645
time: 2.334522008895874
[1, 18945] loss_train: 0.004681, loss_test: 0.005558
time: 0.24405407905578613
time: 2.283513307571411
[1, 18946] loss_train: 0.011182, loss_test: 0.005563
time: 0.2780616283416748
time: 2.357527494430542
[1, 18947] loss_train: 0.005044, loss_test: 0.005567
time: 0.2540566921234131
time: 2.284510612487793
[1, 18948] loss_train: 0.008042, loss_test: 0.005570
time: 0.2650594711303711
time: 2.3015146255493164
[1, 18949] loss_train: 0.005784, loss_test: 0.005564
time: 0.2450547218322754
time: 2.2795095443725586
[1, 18950] loss_train: 0.006866, loss_test: 0.005559
time: 0.2600572109222412
time: 2.4225423336029053
[1, 18951] loss_train: 0.002386, loss_test: 0.005551
time: 0.26405811309814453
time: 2.3015153408050537
[1, 18952] loss_train: 0.014055, loss_test: 0.005546
time: 0.24405431747436523
time: 2.279405117034912
[1, 18953] loss_train: 0.006718, loss_test: 0.005541
time: 0.25205492973327637
time: 2.2665069103240967
[1, 18954] loss_train: 0.017676, loss_test: 0.005536
time: 0.25505590438842773
time: 2.2705078125
[1, 18955] loss_train: 0.005269, loss_test: 0.005533
time: 0.24605417251586914
time: 2.2525064945220947
[1, 18956] loss_train: 0.007965, loss_test: 0.005530
time: 0.2450547218322754
time: 2.2715084552764893
[1, 18957] loss_train: 0.009683, loss_test: 0.005528
time: 0.25205540657043457
time: 2.2645068168640137
[1, 18958] loss_train: 0.015580, loss_test: 0.005527
time: 0.2450542449951172
time: 2.27150821685791
[1, 18959] loss_train: 0.004266, loss_test: 0.005530
time: 0.24405455589294434
time: 2.286511182785034
[1, 18960] loss_train: 0.008967, loss_test: 0.005535
time: 0.25705742835998535
time: 2.256504535675049
[1, 18961] loss_train: 0.008764, loss_test: 0.005540
time: 0.24305391311645508
time: 2.2525033950805664
[1, 18962] loss_train: 0.003446, loss_test: 0.005547
time: 0.2520558834075928
time: 2.263504981994629
[1, 18963] loss_train: 0.001653, loss_test: 0.005558
time: 0.2540566921234131
time: 2.2540080547332764
[1, 18964] loss_train: 0.004358, loss_test: 0.005567
time: 0.24405360221862793
time: 2.2385010719299316
[1, 18965] loss_train: 0.005666, loss_test: 0.005578
time: 0.25505614280700684
time: 2.2485034465789795
[1, 18966] loss_train: 0.005045, loss_test: 0.005586
time: 0.24605512619018555
time: 2.2385001182556152
[1, 18967] loss_train: 0.008082, loss_test: 0.005587
time: 0.2450551986694336
time: 2.274508237838745
[1, 18968] loss_train: 0.002184, loss_test: 0.005585
time: 0.24405479431152344
time: 2.2765095233917236
[1, 18969] loss_train: 0.005633, loss_test: 0.005580
time: 0.2544596195220947
time: 2.304515838623047
[1, 18970] loss_train: 0.002838, loss_test: 0.005577
time: 0.25705671310424805
time: 2.297513723373413
[1, 18971] loss_train: 0.008455, loss_test: 0.005577
time: 0.2450542449951172
time: 2.254504442214966
[1, 18972] loss_train: 0.008676, loss_test: 0.005573
time: 0.24305438995361328
time: 2.233499050140381
[1, 18973] loss_train: 0.007090, loss_test: 0.005577
time: 0.24405431747436523
time: 2.242501974105835
[1, 18974] loss_train: 0.001039, loss_test: 0.005586
time: 0.24405455589294434
time: 2.249502658843994
[1, 18975] loss_train: 0.010985, loss_test: 0.005588
time: 0.24405384063720703
time: 2.2775094509124756
[1, 18976] loss_train: 0.008361, loss_test: 0.005588
time: 0.2450542449951172
time: 2.2395007610321045
[1, 18977] loss_train: 0.010848, loss_test: 0.005586
time: 0.24305319786071777
time: 2.2395012378692627
[1, 18978] loss_train: 0.006450, loss_test: 0.005586
time: 0.24405407905578613
time: 2.268510103225708
[1, 18979] loss_train: 0.008979, loss_test: 0.005586
time: 0.2450542449951172
time: 2.2485032081604004
[1, 18980] loss_train: 0.002592, loss_test: 0.005589
time: 0.2630577087402344
time: 2.2765095233917236
[1, 18981] loss_train: 0.003605, loss_test: 0.005590
time: 0.24620318412780762
time: 2.2975146770477295
[1, 18982] loss_train: 0.004643, loss_test: 0.005586
time: 0.24305415153503418
time: 2.2515032291412354
[1, 18983] loss_train: 0.005875, loss_test: 0.005577
time: 0.2450542449951172
time: 2.256504535675049
[1, 18984] loss_train: 0.002680, loss_test: 0.005566
time: 0.2450542449951172
time: 2.2735085487365723
[1, 18985] loss_train: 0.003455, loss_test: 0.005559
time: 0.2620582580566406
time: 2.282510995864868
[1, 18986] loss_train: 0.008732, loss_test: 0.005554
time: 0.24505376815795898
time: 2.241501808166504
[1, 18987] loss_train: 0.013621, loss_test: 0.005551
time: 0.24505400657653809
time: 2.268507480621338
[1, 18988] loss_train: 0.005769, loss_test: 0.005550
time: 0.2470548152923584
time: 2.226032257080078
[1, 18989] loss_train: 0.004896, loss_test: 0.005551
time: 0.24605488777160645
time: 2.2775094509124756
[1, 18990] loss_train: 0.002438, loss_test: 0.005555
time: 0.265059232711792
time: 2.281510353088379
[1, 18991] loss_train: 0.005639, loss_test: 0.005561
time: 0.2490551471710205
time: 2.2805099487304688
[1, 18992] loss_train: 0.005502, loss_test: 0.005568
time: 0.2510554790496826
time: 2.279510498046875
[1, 18993] loss_train: 0.012796, loss_test: 0.005568
time: 0.24805545806884766
time: 2.2815101146698
[1, 18994] loss_train: 0.002495, loss_test: 0.005570
time: 0.24805474281311035
time: 2.3455252647399902
[1, 18995] loss_train: 0.000997, loss_test: 0.005576
time: 0.2870631217956543
time: 2.286510705947876
[1, 18996] loss_train: 0.000521, loss_test: 0.005586
time: 0.24405312538146973
time: 2.2655117511749268
[1, 18997] loss_train: 0.003609, loss_test: 0.005595
time: 0.24405431747436523
time: 2.2575042247772217
[1, 18998] loss_train: 0.001528, loss_test: 0.005608
time: 0.2450549602508545
time: 2.2395007610321045
[1, 18999] loss_train: 0.008089, loss_test: 0.005611
time: 0.2450547218322754
time: 2.260505199432373
[1, 19000] loss_train: 0.009334, loss_test: 0.005607
time: 0.25705718994140625
time: 2.2475028038024902
[1, 19001] loss_train: 0.006869, loss_test: 0.005596
time: 0.25505614280700684
time: 2.417541027069092
[1, 19002] loss_train: 0.002322, loss_test: 0.005586
time: 0.26605868339538574
time: 2.418541669845581
[1, 19003] loss_train: 0.007644, loss_test: 0.005570
time: 0.24505376815795898
time: 2.258504867553711
[1, 19004] loss_train: 0.004093, loss_test: 0.005556
time: 0.2450547218322754
time: 2.2725090980529785
[1, 19005] loss_train: 0.003981, loss_test: 0.005547
time: 0.24605393409729004
time: 2.2825114727020264
[1, 19006] loss_train: 0.010868, loss_test: 0.005541
time: 0.24605369567871094
time: 2.306516170501709
[1, 19007] loss_train: 0.010499, loss_test: 0.005538
time: 0.2470545768737793
time: 2.2885122299194336
[1, 19008] loss_train: 0.004847, loss_test: 0.005537
time: 0.2450547218322754
time: 2.2915122509002686
[1, 19009] loss_train: 0.006377, loss_test: 0.005533
time: 0.2510554790496826
time: 2.2975168228149414
[1, 19010] loss_train: 0.001003, loss_test: 0.005532
time: 0.26805877685546875
time: 2.2725088596343994
[1, 19011] loss_train: 0.008889, loss_test: 0.005533
time: 0.25205516815185547
time: 2.2845115661621094
[1, 19012] loss_train: 0.013231, loss_test: 0.005532
time: 0.24405360221862793
time: 2.2595062255859375
[1, 19013] loss_train: 0.009150, loss_test: 0.005532
time: 0.24505352973937988
time: 2.241501808166504
[1, 19014] loss_train: 0.001398, loss_test: 0.005531
time: 0.24305391311645508
time: 2.2805097103118896
[1, 19015] loss_train: 0.009390, loss_test: 0.005538
time: 0.2450542449951172
time: 2.269508123397827
[1, 19016] loss_train: 0.003247, loss_test: 0.005547
time: 0.24605417251586914
time: 2.2725086212158203
[1, 19017] loss_train: 0.006484, loss_test: 0.005555
time: 0.24805450439453125
time: 2.2779078483581543
[1, 19018] loss_train: 0.005640, loss_test: 0.005559
time: 0.252056360244751
time: 2.308516263961792
[1, 19019] loss_train: 0.003236, loss_test: 0.005555
time: 0.2450547218322754
time: 2.321519136428833
[1, 19020] loss_train: 0.006913, loss_test: 0.005549
time: 0.26405906677246094
time: 2.2705061435699463
[1, 19021] loss_train: 0.006219, loss_test: 0.005546
time: 0.24405431747436523
time: 2.2635059356689453
[1, 19022] loss_train: 0.002557, loss_test: 0.005549
time: 0.24805474281311035
time: 2.2765121459960938
[1, 19023] loss_train: 0.004733, loss_test: 0.005556
time: 0.24305391311645508
time: 2.2720654010772705
[1, 19024] loss_train: 0.005738, loss_test: 0.005571
time: 0.24405455589294434
time: 2.2585043907165527
[1, 19025] loss_train: 0.004618, loss_test: 0.005588
time: 0.24405360221862793
time: 2.266706705093384
[1, 19026] loss_train: 0.006116, loss_test: 0.005602
time: 0.24805569648742676
time: 2.293513059616089
[1, 19027] loss_train: 0.008873, loss_test: 0.005609
time: 0.2510557174682617
time: 2.2985146045684814
[1, 19028] loss_train: 0.003505, loss_test: 0.005617
time: 0.25305795669555664
time: 2.2865114212036133
[1, 19029] loss_train: 0.015760, loss_test: 0.005603
time: 0.25005626678466797
time: 2.336521863937378
[1, 19030] loss_train: 0.015948, loss_test: 0.005577
time: 0.2620584964752197
time: 2.3045172691345215
[1, 19031] loss_train: 0.010026, loss_test: 0.005565
time: 0.25705981254577637
time: 2.274508237838745
[1, 19032] loss_train: 0.004044, loss_test: 0.005573
time: 0.24605417251586914
time: 2.303515672683716
[1, 19033] loss_train: 0.006091, loss_test: 0.005589
time: 0.25705718994140625
time: 2.244502305984497
[1, 19034] loss_train: 0.006233, loss_test: 0.005605
time: 0.2490546703338623
time: 2.278510332107544
[1, 19035] loss_train: 0.006419, loss_test: 0.005615
time: 0.24605417251586914
time: 2.3055179119110107
[1, 19036] loss_train: 0.004162, loss_test: 0.005623
time: 0.24805617332458496
time: 2.270507335662842
[1, 19037] loss_train: 0.008288, loss_test: 0.005618
time: 0.24605441093444824
time: 2.283510446548462
[1, 19038] loss_train: 0.010996, loss_test: 0.005610
time: 0.24605417251586914
time: 2.2765097618103027
[1, 19039] loss_train: 0.006237, loss_test: 0.005597
time: 0.26105833053588867
time: 2.310516595840454
[1, 19040] loss_train: 0.007678, loss_test: 0.005584
time: 0.2580568790435791
time: 2.2825114727020264
[1, 19041] loss_train: 0.001228, loss_test: 0.005578
time: 0.2470548152923584
time: 2.294513463973999
[1, 19042] loss_train: 0.004403, loss_test: 0.005583
time: 0.24605536460876465
time: 2.290511131286621
[1, 19043] loss_train: 0.007607, loss_test: 0.005591
time: 0.24805545806884766
time: 2.293513774871826
[1, 19044] loss_train: 0.001955, loss_test: 0.005604
time: 0.25005507469177246
time: 2.256519317626953
[1, 19045] loss_train: 0.006434, loss_test: 0.005614
time: 0.2450547218322754
time: 2.2775087356567383
[1, 19046] loss_train: 0.007292, loss_test: 0.005621
time: 0.25305652618408203
time: 2.3010191917419434
[1, 19047] loss_train: 0.006108, loss_test: 0.005621
time: 0.24405431747436523
time: 2.2655062675476074
[1, 19048] loss_train: 0.003712, loss_test: 0.005621
time: 0.24805569648742676
time: 2.2415008544921875
[1, 19049] loss_train: 0.004974, loss_test: 0.005620
time: 0.27506136894226074
time: 2.320518970489502
[1, 19050] loss_train: 0.009155, loss_test: 0.005613
time: 0.2710599899291992
time: 2.28851318359375
[1, 19051] loss_train: 0.001703, loss_test: 0.005609
time: 0.26405858993530273
time: 2.5189130306243896
[1, 19052] loss_train: 0.018049, loss_test: 0.005598
time: 0.2450542449951172
time: 2.381532669067383
[1, 19053] loss_train: 0.008012, loss_test: 0.005592
time: 0.24405455589294434
time: 2.3505258560180664
[1, 19054] loss_train: 0.011300, loss_test: 0.005594
time: 0.24305319786071777
time: 2.2475051879882812
[1, 19055] loss_train: 0.013680, loss_test: 0.005618
time: 0.2450544834136963
time: 2.2895119190216064
[1, 19056] loss_train: 0.007490, loss_test: 0.005653
time: 0.2530558109283447
time: 2.2715108394622803
[1, 19057] loss_train: 0.014210, loss_test: 0.005670
time: 0.24305367469787598
time: 2.256505250930786
[1, 19058] loss_train: 0.007492, loss_test: 0.005640
time: 0.24405384063720703
time: 2.2725088596343994
[1, 19059] loss_train: 0.012527, loss_test: 0.005610
time: 0.24505400657653809
time: 2.240501642227173
[1, 19060] loss_train: 0.016048, loss_test: 0.005592
time: 0.278062105178833
time: 2.272507429122925
[1, 19061] loss_train: 0.010359, loss_test: 0.005579
time: 0.25005674362182617
time: 2.315516948699951
[1, 19062] loss_train: 0.006865, loss_test: 0.005577
time: 0.24805521965026855
time: 2.296513795852661
[1, 19063] loss_train: 0.005270, loss_test: 0.005581
time: 0.2450542449951172
time: 2.2895119190216064
[1, 19064] loss_train: 0.007449, loss_test: 0.005588
time: 0.25505733489990234
time: 2.284511089324951
[1, 19065] loss_train: 0.008045, loss_test: 0.005596
time: 0.24605464935302734
time: 2.3015148639678955
[1, 19066] loss_train: 0.007375, loss_test: 0.005597
time: 0.25305676460266113
time: 2.2758936882019043
[1, 19067] loss_train: 0.003894, loss_test: 0.005598
time: 0.252056360244751
time: 2.289510726928711
[1, 19068] loss_train: 0.004922, loss_test: 0.005603
time: 0.2510559558868408
time: 2.2695083618164062
[1, 19069] loss_train: 0.003816, loss_test: 0.005613
time: 0.24205374717712402
time: 2.2365002632141113
[1, 19070] loss_train: 0.005225, loss_test: 0.005625
time: 0.25905752182006836
time: 2.2515037059783936
[1, 19071] loss_train: 0.000892, loss_test: 0.005643
time: 0.24305415153503418
time: 2.260505199432373
[1, 19072] loss_train: 0.006032, loss_test: 0.005659
time: 0.24605417251586914
time: 2.2635066509246826
[1, 19073] loss_train: 0.007865, loss_test: 0.005662
time: 0.2450542449951172
time: 2.2600083351135254
[1, 19074] loss_train: 0.009477, loss_test: 0.005649
time: 0.2530558109283447
time: 2.2965140342712402
[1, 19075] loss_train: 0.008784, loss_test: 0.005626
time: 0.24605417251586914
time: 2.269507646560669
[1, 19076] loss_train: 0.006857, loss_test: 0.005602
time: 0.2560570240020752
time: 2.2905125617980957
[1, 19077] loss_train: 0.007795, loss_test: 0.005583
time: 0.24805521965026855
time: 2.295513391494751
[1, 19078] loss_train: 0.007716, loss_test: 0.005566
time: 0.2530555725097656
time: 2.2785122394561768
[1, 19079] loss_train: 0.002087, loss_test: 0.005558
time: 0.2470550537109375
time: 2.2935123443603516
[1, 19080] loss_train: 0.004312, loss_test: 0.005554
time: 0.26806068420410156
time: 2.287510633468628
[1, 19081] loss_train: 0.010629, loss_test: 0.005554
time: 0.2470548152923584
time: 2.241502046585083
[1, 19082] loss_train: 0.003912, loss_test: 0.005559
time: 0.2450544834136963
time: 2.273508310317993
[1, 19083] loss_train: 0.002477, loss_test: 0.005567
time: 0.2470550537109375
time: 2.2795097827911377
[1, 19084] loss_train: 0.005201, loss_test: 0.005576
time: 0.24605441093444824
time: 2.2665066719055176
[1, 19085] loss_train: 0.005478, loss_test: 0.005581
time: 0.30406761169433594
time: 2.409539222717285
[1, 19086] loss_train: 0.005467, loss_test: 0.005581
time: 0.2470545768737793
time: 2.3655292987823486
[1, 19087] loss_train: 0.007415, loss_test: 0.005582
time: 0.2470545768737793
time: 2.3225197792053223
[1, 19088] loss_train: 0.000576, loss_test: 0.005586
time: 0.3670811653137207
time: 2.3385233879089355
[1, 19089] loss_train: 0.011628, loss_test: 0.005587
time: 0.2490553855895996
time: 2.3925344944000244
[1, 19090] loss_train: 0.007918, loss_test: 0.005588
time: 0.26510095596313477
time: 2.6400108337402344
[1, 19091] loss_train: 0.003895, loss_test: 0.005589
time: 0.2510550022125244
time: 2.2745091915130615
[1, 19092] loss_train: 0.002940, loss_test: 0.005585
time: 0.2470543384552002
time: 2.2995142936706543
[1, 19093] loss_train: 0.007230, loss_test: 0.005583
time: 0.2450542449951172
time: 2.2495038509368896
[1, 19094] loss_train: 0.007838, loss_test: 0.005581
time: 0.24305415153503418
time: 2.239501476287842
[1, 19095] loss_train: 0.001565, loss_test: 0.005584
time: 0.2450542449951172
time: 2.2284984588623047
[1, 19096] loss_train: 0.006489, loss_test: 0.005578
time: 0.24505400657653809
time: 2.2515039443969727
[1, 19097] loss_train: 0.009988, loss_test: 0.005562
time: 0.2470543384552002
time: 2.241501808166504
[1, 19098] loss_train: 0.008057, loss_test: 0.005554
time: 0.24405360221862793
time: 2.2635068893432617
[1, 19099] loss_train: 0.006498, loss_test: 0.005550
time: 0.247053861618042
time: 2.2835116386413574
[1, 19100] loss_train: 0.007584, loss_test: 0.005552
time: 0.25905728340148926
time: 2.282015085220337
[1, 19101] loss_train: 0.007274, loss_test: 0.005556
time: 0.24605441093444824
time: 2.2365007400512695
[1, 19102] loss_train: 0.002171, loss_test: 0.005560
time: 0.24805545806884766
time: 2.259505271911621
[1, 19103] loss_train: 0.005102, loss_test: 0.005562
time: 0.24505400657653809
time: 2.2365005016326904
[1, 19104] loss_train: 0.003309, loss_test: 0.005564
time: 0.24605417251586914
time: 2.2605063915252686
[1, 19105] loss_train: 0.003167, loss_test: 0.005565
time: 0.24405431747436523
time: 2.2665066719055176
[1, 19106] loss_train: 0.004131, loss_test: 0.005568
time: 0.24405479431152344
time: 2.2515029907226562
[1, 19107] loss_train: 0.004743, loss_test: 0.005570
time: 0.2450542449951172
time: 2.239143133163452
[1, 19108] loss_train: 0.000783, loss_test: 0.005576
time: 0.24605441093444824
time: 2.231499195098877
[1, 19109] loss_train: 0.002277, loss_test: 0.005582
time: 0.24405384063720703
time: 2.2455027103424072
[1, 19110] loss_train: 0.004455, loss_test: 0.005591
time: 0.2580568790435791
time: 2.2965164184570312
[1, 19111] loss_train: 0.007487, loss_test: 0.005596
time: 0.24405312538146973
time: 2.2475035190582275
[1, 19112] loss_train: 0.000780, loss_test: 0.005604
time: 0.25505638122558594
time: 2.3035149574279785
[1, 19113] loss_train: 0.003676, loss_test: 0.005612
time: 0.2600581645965576
time: 2.433544158935547
[1, 19114] loss_train: 0.005408, loss_test: 0.005617
time: 0.25005578994750977
time: 2.2535040378570557
[1, 19115] loss_train: 0.005142, loss_test: 0.005613
time: 0.2470545768737793
time: 2.267507553100586
[1, 19116] loss_train: 0.003668, loss_test: 0.005610
time: 0.2490549087524414
time: 2.2715086936950684
[1, 19117] loss_train: 0.002438, loss_test: 0.005605
time: 0.26605916023254395
time: 2.2675065994262695
[1, 19118] loss_train: 0.004535, loss_test: 0.005599
time: 0.252056360244751
time: 2.2560184001922607
[1, 19119] loss_train: 0.002976, loss_test: 0.005594
time: 0.24605488777160645
time: 2.2445037364959717
[1, 19120] loss_train: 0.008545, loss_test: 0.005585
time: 0.26105761528015137
time: 2.2485244274139404
[1, 19121] loss_train: 0.003015, loss_test: 0.005579
time: 0.2450544834136963
time: 2.2885117530822754
[1, 19122] loss_train: 0.005608, loss_test: 0.005573
time: 0.25005602836608887
time: 2.273508310317993
[1, 19123] loss_train: 0.012795, loss_test: 0.005562
time: 0.24305343627929688
time: 2.2725088596343994
[1, 19124] loss_train: 0.006798, loss_test: 0.005555
time: 0.2430570125579834
time: 2.2895147800445557
[1, 19125] loss_train: 0.008633, loss_test: 0.005545
time: 0.24405407905578613
time: 2.260507822036743
[1, 19126] loss_train: 0.014300, loss_test: 0.005538
time: 0.2450544834136963
time: 2.258504867553711
[1, 19127] loss_train: 0.003276, loss_test: 0.005537
time: 0.24405431747436523
time: 2.248502731323242
[1, 19128] loss_train: 0.004418, loss_test: 0.005540
time: 0.24305367469787598
time: 2.2395009994506836
[1, 19129] loss_train: 0.003133, loss_test: 0.005541
time: 0.2450544834136963
time: 2.2686519622802734
[1, 19130] loss_train: 0.008365, loss_test: 0.005545
time: 0.25905752182006836
time: 2.2405014038085938
[1, 19131] loss_train: 0.004997, loss_test: 0.005548
time: 0.24505400657653809
time: 2.279510259628296
[1, 19132] loss_train: 0.002574, loss_test: 0.005551
time: 0.2450542449951172
time: 2.2475028038024902
[1, 19133] loss_train: 0.004305, loss_test: 0.005554
time: 0.24805545806884766
time: 2.271507740020752
[1, 19134] loss_train: 0.005382, loss_test: 0.005558
time: 0.24505400657653809
time: 2.2635068893432617
[1, 19135] loss_train: 0.009428, loss_test: 0.005559
time: 0.24405336380004883
time: 2.282015323638916
[1, 19136] loss_train: 0.004084, loss_test: 0.005560
time: 0.24605417251586914
time: 2.2725086212158203
[1, 19137] loss_train: 0.002390, loss_test: 0.005557
time: 0.24505400657653809
time: 2.3255207538604736
[1, 19138] loss_train: 0.007622, loss_test: 0.005558
time: 0.24405360221862793
time: 2.284511089324951
[1, 19139] loss_train: 0.009525, loss_test: 0.005563
time: 0.24805712699890137
time: 2.29551362991333
[1, 19140] loss_train: 0.004948, loss_test: 0.005569
time: 0.27006053924560547
time: 2.2925121784210205
[1, 19141] loss_train: 0.005472, loss_test: 0.005569
time: 0.24805665016174316
time: 2.2755095958709717
[1, 19142] loss_train: 0.003084, loss_test: 0.005570
time: 0.24605488777160645
time: 2.256505012512207
[1, 19143] loss_train: 0.008793, loss_test: 0.005565
time: 0.25005483627319336
time: 2.281510591506958
[1, 19144] loss_train: 0.003098, loss_test: 0.005562
time: 0.24405479431152344
time: 2.270507574081421
[1, 19145] loss_train: 0.003176, loss_test: 0.005561
time: 0.2490556240081787
time: 2.337522506713867
[1, 19146] loss_train: 0.009606, loss_test: 0.005557
time: 0.25205564498901367
time: 2.280510663986206
[1, 19147] loss_train: 0.013771, loss_test: 0.005553
time: 0.25305652618408203
time: 2.2785096168518066
[1, 19148] loss_train: 0.004259, loss_test: 0.005554
time: 0.24616718292236328
time: 2.26950740814209
[1, 19149] loss_train: 0.009106, loss_test: 0.005557
time: 0.24605441093444824
time: 2.281510591506958
[1, 19150] loss_train: 0.005970, loss_test: 0.005562
time: 0.25905942916870117
time: 2.265507221221924
[1, 19151] loss_train: 0.014366, loss_test: 0.005566
time: 0.24505400657653809
time: 2.2915124893188477
[1, 19152] loss_train: 0.006007, loss_test: 0.005565
time: 0.2560567855834961
time: 2.294512987136841
[1, 19153] loss_train: 0.005862, loss_test: 0.005560
time: 0.24505329132080078
time: 2.2715084552764893
[1, 19154] loss_train: 0.007726, loss_test: 0.005556
time: 0.2490556240081787
time: 2.2795097827911377
[1, 19155] loss_train: 0.008004, loss_test: 0.005551
time: 0.24605607986450195
time: 2.2755091190338135
[1, 19156] loss_train: 0.007944, loss_test: 0.005548
time: 0.2560563087463379
time: 2.256505250930786
[1, 19157] loss_train: 0.006951, loss_test: 0.005545
time: 0.2450551986694336
time: 2.272507667541504
[1, 19158] loss_train: 0.002642, loss_test: 0.005541
time: 0.2490553855895996
time: 2.2475056648254395
[1, 19159] loss_train: 0.009632, loss_test: 0.005539
time: 0.24405431747436523
time: 2.259505033493042
[1, 19160] loss_train: 0.002727, loss_test: 0.005537
time: 0.2600581645965576
time: 2.2655065059661865
[1, 19161] loss_train: 0.008889, loss_test: 0.005536
time: 0.25005555152893066
time: 2.275508403778076
[1, 19162] loss_train: 0.003961, loss_test: 0.005536
time: 0.25705742835998535
time: 2.319519281387329
[1, 19163] loss_train: 0.005713, loss_test: 0.005536
time: 0.24805521965026855
time: 2.297513484954834
[1, 19164] loss_train: 0.003078, loss_test: 0.005537
time: 0.2490558624267578
time: 2.287522077560425
[1, 19165] loss_train: 0.007015, loss_test: 0.005537
time: 0.2520561218261719
time: 2.254504442214966
[1, 19166] loss_train: 0.013383, loss_test: 0.005534
time: 0.24605464935302734
time: 2.2645061016082764
[1, 19167] loss_train: 0.003112, loss_test: 0.005533
time: 0.2470555305480957
time: 2.3015146255493164
[1, 19168] loss_train: 0.004446, loss_test: 0.005532
time: 0.2490546703338623
time: 2.303515672683716
[1, 19169] loss_train: 0.012837, loss_test: 0.005533
time: 0.2510561943054199
time: 2.2665064334869385
[1, 19170] loss_train: 0.011805, loss_test: 0.005540
time: 0.2580578327178955
time: 2.2830135822296143
[1, 19171] loss_train: 0.009189, loss_test: 0.005551
time: 0.2490549087524414
time: 2.2735090255737305
[1, 19172] loss_train: 0.003627, loss_test: 0.005558
time: 0.25005602836608887
time: 2.298513650894165
[1, 19173] loss_train: 0.003982, loss_test: 0.005557
time: 0.26105761528015137
time: 2.3174378871917725
[1, 19174] loss_train: 0.006898, loss_test: 0.005554
time: 0.24905729293823242
time: 2.298516035079956
[1, 19175] loss_train: 0.002239, loss_test: 0.005545
time: 0.2540555000305176
time: 2.2985146045684814
[1, 19176] loss_train: 0.002251, loss_test: 0.005538
time: 0.2470548152923584
time: 2.300513505935669
[1, 19177] loss_train: 0.002587, loss_test: 0.005535
time: 0.24605512619018555
time: 2.2765092849731445
[1, 19178] loss_train: 0.009416, loss_test: 0.005538
time: 0.24305415153503418
time: 2.2895119190216064
[1, 19179] loss_train: 0.012043, loss_test: 0.005544
time: 0.2740612030029297
time: 2.275522470474243
[1, 19180] loss_train: 0.006818, loss_test: 0.005547
time: 0.2720615863800049
time: 2.3215205669403076
[1, 19181] loss_train: 0.003298, loss_test: 0.005552
time: 0.24605393409729004
time: 2.3025147914886475
[1, 19182] loss_train: 0.005621, loss_test: 0.005553
time: 0.2450542449951172
time: 2.2855138778686523
[1, 19183] loss_train: 0.001852, loss_test: 0.005556
time: 0.24605464935302734
time: 2.2675070762634277
[1, 19184] loss_train: 0.002151, loss_test: 0.005561
time: 0.24805521965026855
time: 2.247507095336914
[1, 19185] loss_train: 0.005658, loss_test: 0.005565
time: 0.24305343627929688
time: 2.2585055828094482
[1, 19186] loss_train: 0.009321, loss_test: 0.005563
time: 0.25005578994750977
time: 2.3315207958221436
[1, 19187] loss_train: 0.006729, loss_test: 0.005561
time: 0.2510561943054199
time: 2.2425014972686768
[1, 19188] loss_train: 0.004696, loss_test: 0.005559
time: 0.25005483627319336
time: 2.291513204574585
[1, 19189] loss_train: 0.006092, loss_test: 0.005554
time: 0.2490553855895996
time: 2.286511182785034
[1, 19190] loss_train: 0.008417, loss_test: 0.005546
time: 0.26605892181396484
time: 2.289522886276245
[1, 19191] loss_train: 0.011242, loss_test: 0.005539
time: 0.24605417251586914
time: 2.2785120010375977
[1, 19192] loss_train: 0.005987, loss_test: 0.005535
time: 0.2510559558868408
time: 2.3655288219451904
[1, 19193] loss_train: 0.004176, loss_test: 0.005533
time: 0.24605512619018555
time: 2.335522174835205
[1, 19194] loss_train: 0.004802, loss_test: 0.005532
time: 0.2450554370880127
time: 2.338522434234619
[1, 19195] loss_train: 0.004912, loss_test: 0.005533
time: 0.2670590877532959
time: 2.270508289337158
[1, 19196] loss_train: 0.003839, loss_test: 0.005535
time: 0.2470543384552002
time: 2.278510332107544
[1, 19197] loss_train: 0.011429, loss_test: 0.005536
time: 0.2490546703338623
time: 2.282510995864868
[1, 19198] loss_train: 0.001604, loss_test: 0.005538
time: 0.24405431747436523
time: 2.275186538696289
[1, 19199] loss_train: 0.004238, loss_test: 0.005539
time: 0.2470545768737793
time: 2.2600107192993164
[1, 19200] loss_train: 0.001587, loss_test: 0.005539
time: 0.2600576877593994
time: 2.2505033016204834
[1, 19201] loss_train: 0.007381, loss_test: 0.005538
time: 0.24405479431152344
time: 2.248502492904663
[1, 19202] loss_train: 0.002946, loss_test: 0.005533
time: 0.2450542449951172
time: 2.287510871887207
[1, 19203] loss_train: 0.007753, loss_test: 0.005528
time: 0.24605584144592285
time: 2.246501922607422
[1, 19204] loss_train: 0.003985, loss_test: 0.005525
time: 0.24605417251586914
time: 2.266507625579834
[1, 19205] loss_train: 0.007660, loss_test: 0.005525
time: 0.25505638122558594
time: 2.2925124168395996
[1, 19206] loss_train: 0.005016, loss_test: 0.005529
time: 0.2530555725097656
time: 2.290513038635254
[1, 19207] loss_train: 0.001527, loss_test: 0.005538
time: 0.24605417251586914
time: 2.2525036334991455
[1, 19208] loss_train: 0.005679, loss_test: 0.005548
time: 0.24305295944213867
time: 2.282510757446289
[1, 19209] loss_train: 0.005586, loss_test: 0.005559
time: 0.24405360221862793
time: 2.2595057487487793
[1, 19210] loss_train: 0.005004, loss_test: 0.005572
time: 0.2580573558807373
time: 2.293513059616089
[1, 19211] loss_train: 0.005127, loss_test: 0.005583
time: 0.2470550537109375
time: 2.2795097827911377
[1, 19212] loss_train: 0.000679, loss_test: 0.005588
time: 0.2470555305480957
time: 2.324519634246826
[1, 19213] loss_train: 0.006950, loss_test: 0.005580
time: 0.24805474281311035
time: 2.2950174808502197
[1, 19214] loss_train: 0.004693, loss_test: 0.005574
time: 0.24805498123168945
time: 2.281510353088379
[1, 19215] loss_train: 0.004858, loss_test: 0.005564
time: 0.24805569648742676
time: 2.2680463790893555
[1, 19216] loss_train: 0.006959, loss_test: 0.005544
time: 0.2530558109283447
time: 2.3065168857574463
[1, 19217] loss_train: 0.001496, loss_test: 0.005534
time: 0.24605369567871094
time: 2.272517204284668
[1, 19218] loss_train: 0.003561, loss_test: 0.005531
time: 0.2450547218322754
time: 2.2485032081604004
[1, 19219] loss_train: 0.014018, loss_test: 0.005532
time: 0.24305343627929688
time: 2.2405011653900146
[1, 19220] loss_train: 0.005053, loss_test: 0.005543
time: 0.2650594711303711
time: 2.273508310317993
[1, 19221] loss_train: 0.003915, loss_test: 0.005559
time: 0.26105785369873047
time: 2.3265204429626465
[1, 19222] loss_train: 0.007816, loss_test: 0.005571
time: 0.24605441093444824
time: 2.2785091400146484
[1, 19223] loss_train: 0.012100, loss_test: 0.005579
time: 0.24605488777160645
time: 2.293513298034668
[1, 19224] loss_train: 0.000518, loss_test: 0.005589
time: 0.2520568370819092
time: 2.263505220413208
[1, 19225] loss_train: 0.004417, loss_test: 0.005589
time: 0.2450544834136963
time: 2.2565042972564697
[1, 19226] loss_train: 0.005833, loss_test: 0.005581
time: 0.2470550537109375
time: 2.2995142936706543
[1, 19227] loss_train: 0.007932, loss_test: 0.005573
time: 0.2540562152862549
time: 2.2830140590667725
[1, 19228] loss_train: 0.010052, loss_test: 0.005562
time: 0.24805426597595215
time: 2.290513038635254
[1, 19229] loss_train: 0.000765, loss_test: 0.005555
time: 0.24805498123168945
time: 2.3025152683258057
[1, 19230] loss_train: 0.010707, loss_test: 0.005552
time: 0.26105809211730957
time: 2.311516284942627
[1, 19231] loss_train: 0.011415, loss_test: 0.005553
time: 0.2540574073791504
time: 2.2805092334747314
[1, 19232] loss_train: 0.009235, loss_test: 0.005553
time: 0.24405384063720703
time: 2.2625062465667725
[1, 19233] loss_train: 0.003119, loss_test: 0.005550
time: 0.24605441093444824
time: 2.249006509780884
[1, 19234] loss_train: 0.002139, loss_test: 0.005544
time: 0.25005507469177246
time: 2.2688791751861572
[1, 19235] loss_train: 0.014275, loss_test: 0.005543
time: 0.2470552921295166
time: 2.261505365371704
[1, 19236] loss_train: 0.004618, loss_test: 0.005540
time: 0.2470550537109375
time: 2.2675068378448486
[1, 19237] loss_train: 0.001997, loss_test: 0.005534
time: 0.2450544834136963
time: 2.2825098037719727
[1, 19238] loss_train: 0.001784, loss_test: 0.005531
time: 0.2470552921295166
time: 2.2635059356689453
[1, 19239] loss_train: 0.006142, loss_test: 0.005533
time: 0.24505376815795898
time: 2.275141954421997
[1, 19240] loss_train: 0.007045, loss_test: 0.005538
time: 0.2600581645965576
time: 2.293513536453247
[1, 19241] loss_train: 0.004122, loss_test: 0.005543
time: 0.2520565986633301
time: 2.259504795074463
[1, 19242] loss_train: 0.005038, loss_test: 0.005549
time: 0.24405479431152344
time: 2.245501756668091
[1, 19243] loss_train: 0.005783, loss_test: 0.005553
time: 0.24405455589294434
time: 2.2895162105560303
[1, 19244] loss_train: 0.009341, loss_test: 0.005550
time: 0.2520561218261719
time: 2.234499931335449
[1, 19245] loss_train: 0.011631, loss_test: 0.005546
time: 0.24405479431152344
time: 2.2555148601531982
[1, 19246] loss_train: 0.005725, loss_test: 0.005543
time: 0.24405217170715332
time: 2.270508289337158
[1, 19247] loss_train: 0.012112, loss_test: 0.005540
time: 0.24405336380004883
time: 2.2675070762634277
[1, 19248] loss_train: 0.009043, loss_test: 0.005538
time: 0.24505376815795898
time: 2.2655067443847656
[1, 19249] loss_train: 0.003808, loss_test: 0.005537
time: 0.24805545806884766
time: 2.2615058422088623
[1, 19250] loss_train: 0.006869, loss_test: 0.005537
time: 0.25705671310424805
time: 2.332521915435791
[1, 19251] loss_train: 0.000768, loss_test: 0.005539
time: 0.2470545768737793
time: 2.320519208908081
[1, 19252] loss_train: 0.000664, loss_test: 0.005539
time: 0.2540562152862549
time: 2.2605056762695312
[1, 19253] loss_train: 0.003423, loss_test: 0.005541
time: 0.2490553855895996
time: 2.296513795852661
[1, 19254] loss_train: 0.004080, loss_test: 0.005542
time: 0.2470545768737793
time: 2.2645065784454346
[1, 19255] loss_train: 0.006632, loss_test: 0.005542
time: 0.26605844497680664
time: 2.4115402698516846
[1, 19256] loss_train: 0.004019, loss_test: 0.005543
time: 0.25205540657043457
time: 2.308516025543213
[1, 19257] loss_train: 0.009311, loss_test: 0.005544
time: 0.24405527114868164
time: 2.2695071697235107
[1, 19258] loss_train: 0.005517, loss_test: 0.005543
time: 0.2560577392578125
time: 2.2955126762390137
[1, 19259] loss_train: 0.006920, loss_test: 0.005543
time: 0.25705647468566895
time: 2.3205196857452393
[1, 19260] loss_train: 0.004599, loss_test: 0.005544
time: 0.2580568790435791
time: 2.2745089530944824
[1, 19261] loss_train: 0.007409, loss_test: 0.005543
time: 0.2470552921295166
time: 2.308516263961792
[1, 19262] loss_train: 0.007469, loss_test: 0.005544
time: 0.2540559768676758
time: 2.283510446548462
[1, 19263] loss_train: 0.004618, loss_test: 0.005548
time: 0.3030664920806885
time: 2.437544822692871
[1, 19264] loss_train: 0.005196, loss_test: 0.005552
time: 0.2520565986633301
time: 2.395536184310913
[1, 19265] loss_train: 0.003275, loss_test: 0.005557
time: 0.27205967903137207
time: 2.2775096893310547
[1, 19266] loss_train: 0.002619, loss_test: 0.005564
time: 0.24805808067321777
time: 2.2795116901397705
[1, 19267] loss_train: 0.009675, loss_test: 0.005567
time: 0.24405360221862793
time: 2.3235199451446533
[1, 19268] loss_train: 0.010059, loss_test: 0.005568
time: 0.29506516456604004
time: 2.3885345458984375
[1, 19269] loss_train: 0.003256, loss_test: 0.005572
time: 0.25005626678466797
time: 2.2565042972564697
[1, 19270] loss_train: 0.013325, loss_test: 0.005569
time: 0.2580575942993164
time: 2.2775115966796875
[1, 19271] loss_train: 0.012427, loss_test: 0.005565
time: 0.25705742835998535
time: 2.3985366821289062
[1, 19272] loss_train: 0.010776, loss_test: 0.005564
time: 0.24805545806884766
time: 2.256504535675049
[1, 19273] loss_train: 0.007867, loss_test: 0.005567
time: 0.2510554790496826
time: 2.27510404586792
[1, 19274] loss_train: 0.004545, loss_test: 0.005569
time: 0.2600579261779785
time: 2.575575828552246
[1, 19275] loss_train: 0.005614, loss_test: 0.005566
time: 0.3200714588165283
time: 2.474553108215332
[1, 19276] loss_train: 0.007895, loss_test: 0.005564
time: 0.2450554370880127
time: 2.262505054473877
[1, 19277] loss_train: 0.008715, loss_test: 0.005555
time: 0.2450542449951172
time: 2.242501974105835
[1, 19278] loss_train: 0.000937, loss_test: 0.005545
time: 0.2490553855895996
time: 2.2685065269470215
[1, 19279] loss_train: 0.003596, loss_test: 0.005538
time: 0.24605488777160645
time: 2.244006395339966
[1, 19280] loss_train: 0.007389, loss_test: 0.005530
time: 0.2580575942993164
time: 2.272507905960083
[1, 19281] loss_train: 0.004658, loss_test: 0.005529
time: 0.24605417251586914
time: 2.2535042762756348
[1, 19282] loss_train: 0.008960, loss_test: 0.005531
time: 0.24505400657653809
time: 2.254504680633545
[1, 19283] loss_train: 0.003876, loss_test: 0.005538
time: 0.2450547218322754
time: 2.2154951095581055
[1, 19284] loss_train: 0.007123, loss_test: 0.005544
time: 0.25005507469177246
time: 2.2465031147003174
[1, 19285] loss_train: 0.007417, loss_test: 0.005551
time: 0.2450547218322754
time: 2.2675065994262695
[1, 19286] loss_train: 0.001482, loss_test: 0.005562
time: 0.2450554370880127
time: 2.273508310317993
[1, 19287] loss_train: 0.014115, loss_test: 0.005559
time: 0.24305343627929688
time: 2.2805097103118896
[1, 19288] loss_train: 0.002770, loss_test: 0.005558
time: 0.24605441093444824
time: 2.2745091915130615
[1, 19289] loss_train: 0.005328, loss_test: 0.005554
time: 0.2470552921295166
time: 2.287511110305786
[1, 19290] loss_train: 0.009127, loss_test: 0.005544
time: 0.25905704498291016
time: 2.2755091190338135
[1, 19291] loss_train: 0.015208, loss_test: 0.005535
time: 0.2450544834136963
time: 2.233499526977539
[1, 19292] loss_train: 0.006182, loss_test: 0.005535
time: 0.2450542449951172
time: 2.272508382797241
[1, 19293] loss_train: 0.008025, loss_test: 0.005543
time: 0.2450547218322754
time: 2.2655091285705566
[1, 19294] loss_train: 0.004981, loss_test: 0.005554
time: 0.24605488777160645
time: 2.2765092849731445
[1, 19295] loss_train: 0.015301, loss_test: 0.005568
time: 0.25005555152893066
time: 2.2845115661621094
[1, 19296] loss_train: 0.003720, loss_test: 0.005576
time: 0.24605393409729004
time: 2.3405234813690186
[1, 19297] loss_train: 0.009869, loss_test: 0.005578
time: 0.24605464935302734
time: 2.257504940032959
[1, 19298] loss_train: 0.013645, loss_test: 0.005574
time: 0.2450542449951172
time: 2.2505054473876953
[1, 19299] loss_train: 0.010857, loss_test: 0.005568
time: 0.24405336380004883
time: 2.2885124683380127
[1, 19300] loss_train: 0.005220, loss_test: 0.005559
time: 0.26605844497680664
time: 2.315518617630005
[1, 19301] loss_train: 0.004786, loss_test: 0.005552
time: 0.2470543384552002
time: 2.311516523361206
[1, 19302] loss_train: 0.004403, loss_test: 0.005544
time: 0.24605464935302734
time: 2.2735087871551514
[1, 19303] loss_train: 0.009318, loss_test: 0.005541
time: 0.24305415153503418
time: 2.2895116806030273
[1, 19304] loss_train: 0.007114, loss_test: 0.005539
time: 0.24305367469787598
time: 2.3235201835632324
[1, 19305] loss_train: 0.000672, loss_test: 0.005541
time: 0.2490556240081787
time: 2.284510612487793
[1, 19306] loss_train: 0.007533, loss_test: 0.005552
time: 0.24605417251586914
time: 2.3765311241149902
[1, 19307] loss_train: 0.000887, loss_test: 0.005567
time: 0.25305604934692383
time: 2.313023328781128
[1, 19308] loss_train: 0.004640, loss_test: 0.005589
time: 0.27006006240844727
time: 2.360527753829956
[1, 19309] loss_train: 0.003139, loss_test: 0.005615
time: 0.24605441093444824
time: 2.3075172901153564
[1, 19310] loss_train: 0.006444, loss_test: 0.005630
time: 0.25705623626708984
time: 2.282510757446289
[1, 19311] loss_train: 0.004931, loss_test: 0.005641
time: 0.24405479431152344
time: 2.3385231494903564
[1, 19312] loss_train: 0.002459, loss_test: 0.005648
time: 0.2450549602508545
time: 2.318519353866577
[1, 19313] loss_train: 0.002762, loss_test: 0.005656
time: 0.2740604877471924
time: 2.308516025543213
[1, 19314] loss_train: 0.005189, loss_test: 0.005663
time: 0.24605441093444824
time: 2.293513059616089
[1, 19315] loss_train: 0.007449, loss_test: 0.005663
time: 0.2470543384552002
time: 2.268507957458496
[1, 19316] loss_train: 0.008788, loss_test: 0.005657
time: 0.24405384063720703
time: 2.268507242202759
[1, 19317] loss_train: 0.003069, loss_test: 0.005654
time: 0.24805545806884766
time: 2.296513319015503
[1, 19318] loss_train: 0.010987, loss_test: 0.005623
time: 0.25005602836608887
time: 2.2665059566497803
[1, 19319] loss_train: 0.011183, loss_test: 0.005589
time: 0.2490553855895996
time: 2.2785096168518066
[1, 19320] loss_train: 0.005235, loss_test: 0.005572
time: 0.2580578327178955
time: 2.2645063400268555
[1, 19321] loss_train: 0.005100, loss_test: 0.005570
time: 0.24605512619018555
time: 2.3650577068328857
[1, 19322] loss_train: 0.003675, loss_test: 0.005581
time: 0.2470552921295166
time: 2.263505220413208
[1, 19323] loss_train: 0.012316, loss_test: 0.005600
time: 0.24405360221862793
time: 2.2935125827789307
[1, 19324] loss_train: 0.014105, loss_test: 0.005640
time: 0.24305272102355957
time: 2.303515672683716
[1, 19325] loss_train: 0.005691, loss_test: 0.005669
time: 0.24805760383605957
time: 2.3125171661376953
[1, 19326] loss_train: 0.004875, loss_test: 0.005691
time: 0.24805521965026855
time: 2.2925126552581787
[1, 19327] loss_train: 0.006554, loss_test: 0.005697
time: 0.24805450439453125
time: 2.408538341522217
[1, 19328] loss_train: 0.009660, loss_test: 0.005648
time: 0.27306151390075684
time: 2.297513484954834
[1, 19329] loss_train: 0.006572, loss_test: 0.005598
time: 0.25005555152893066
time: 2.2870147228240967
[1, 19330] loss_train: 0.009054, loss_test: 0.005567
time: 0.2620575428009033
time: 2.2795090675354004
[1, 19331] loss_train: 0.003301, loss_test: 0.005552
time: 0.24685001373291016
time: 2.308516502380371
[1, 19332] loss_train: 0.005183, loss_test: 0.005552
time: 0.24605631828308105
time: 2.2895126342773438
[1, 19333] loss_train: 0.012425, loss_test: 0.005561
time: 0.24305343627929688
time: 2.2575082778930664
[1, 19334] loss_train: 0.016013, loss_test: 0.005579
time: 0.24605417251586914
time: 2.2865118980407715
[1, 19335] loss_train: 0.004297, loss_test: 0.005601
time: 0.2450551986694336
time: 2.2825121879577637
[1, 19336] loss_train: 0.016926, loss_test: 0.005624
time: 0.24805474281311035
time: 2.294513702392578
[1, 19337] loss_train: 0.009200, loss_test: 0.005619
time: 0.24605488777160645
time: 2.298513174057007
[1, 19338] loss_train: 0.009684, loss_test: 0.005613
time: 0.2510569095611572
time: 2.271510124206543
[1, 19339] loss_train: 0.001467, loss_test: 0.005615
time: 0.2510557174682617
time: 2.272508144378662
[1, 19340] loss_train: 0.003960, loss_test: 0.005609
time: 0.2580568790435791
time: 2.2845115661621094
[1, 19341] loss_train: 0.005071, loss_test: 0.005593
time: 0.25005531311035156
time: 2.246502637863159
[1, 19342] loss_train: 0.001755, loss_test: 0.005581
time: 0.24606108665466309
time: 2.2625060081481934
[1, 19343] loss_train: 0.006896, loss_test: 0.005568
time: 0.24805474281311035
time: 2.2995152473449707
[1, 19344] loss_train: 0.002029, loss_test: 0.005559
time: 0.2540555000305176
time: 2.305516004562378
[1, 19345] loss_train: 0.009861, loss_test: 0.005543
time: 0.2490558624267578
time: 2.2625057697296143
[1, 19346] loss_train: 0.001939, loss_test: 0.005534
time: 0.2450544834136963
time: 2.261505603790283
[1, 19347] loss_train: 0.011087, loss_test: 0.005530
time: 0.24605512619018555
time: 2.258507013320923
[1, 19348] loss_train: 0.010999, loss_test: 0.005530
time: 0.24605607986450195
time: 2.3035120964050293
[1, 19349] loss_train: 0.007423, loss_test: 0.005536
time: 0.24805521965026855
time: 2.2515034675598145
[1, 19350] loss_train: 0.006657, loss_test: 0.005545
time: 0.2580571174621582
time: 2.2525031566619873
[1, 19351] loss_train: 0.003708, loss_test: 0.005548
time: 0.2450547218322754
time: 2.282510280609131
[1, 19352] loss_train: 0.008618, loss_test: 0.005547
time: 0.2470552921295166
time: 2.287511110305786
[1, 19353] loss_train: 0.001562, loss_test: 0.005539
time: 0.24405455589294434
time: 2.2995223999023438
[1, 19354] loss_train: 0.009963, loss_test: 0.005535
time: 0.2450542449951172
time: 2.2765090465545654
[1, 19355] loss_train: 0.008498, loss_test: 0.005537
time: 0.24505400657653809
time: 2.2865142822265625
[1, 19356] loss_train: 0.004786, loss_test: 0.005540
time: 0.25005531311035156
time: 2.2745089530944824
[1, 19357] loss_train: 0.004449, loss_test: 0.005541
time: 0.24405431747436523
time: 2.272507905960083
[1, 19358] loss_train: 0.002274, loss_test: 0.005545
time: 0.2470543384552002
time: 2.265010356903076
[1, 19359] loss_train: 0.005017, loss_test: 0.005550
time: 0.24305415153503418
time: 2.3335230350494385
[1, 19360] loss_train: 0.003745, loss_test: 0.005553
time: 0.2620580196380615
time: 2.257505416870117
[1, 19361] loss_train: 0.006163, loss_test: 0.005559
time: 0.24305343627929688
time: 2.2725086212158203
[1, 19362] loss_train: 0.005940, loss_test: 0.005562
time: 0.2470548152923584
time: 2.2755091190338135
[1, 19363] loss_train: 0.003195, loss_test: 0.005566
time: 0.2510559558868408
time: 2.2755115032196045
[1, 19364] loss_train: 0.001425, loss_test: 0.005575
time: 0.24505376815795898
time: 2.2885122299194336
[1, 19365] loss_train: 0.002585, loss_test: 0.005579
time: 0.24405479431152344
time: 2.266507863998413
[1, 19366] loss_train: 0.010272, loss_test: 0.005572
time: 0.2470543384552002
time: 2.281510591506958
[1, 19367] loss_train: 0.012199, loss_test: 0.005560
time: 0.2450549602508545
time: 2.263505697250366
[1, 19368] loss_train: 0.001211, loss_test: 0.005554
time: 0.2450542449951172
time: 2.2595055103302
[1, 19369] loss_train: 0.002803, loss_test: 0.005550
time: 0.24305415153503418
time: 2.2885117530822754
[1, 19370] loss_train: 0.008321, loss_test: 0.005542
time: 0.26105833053588867
time: 2.277012348175049
[1, 19371] loss_train: 0.003973, loss_test: 0.005539
time: 0.24605512619018555
time: 2.2785086631774902
[1, 19372] loss_train: 0.007677, loss_test: 0.005539
time: 0.24405431747436523
time: 2.2765097618103027
[1, 19373] loss_train: 0.008892, loss_test: 0.005541
time: 0.25705718994140625
time: 2.286511182785034
[1, 19374] loss_train: 0.007809, loss_test: 0.005546
time: 0.24405384063720703
time: 2.2875118255615234
[1, 19375] loss_train: 0.004558, loss_test: 0.005550
time: 0.2440485954284668
time: 2.2745094299316406
[1, 19376] loss_train: 0.002627, loss_test: 0.005552
time: 0.24505376815795898
time: 2.2625088691711426
[1, 19377] loss_train: 0.004313, loss_test: 0.005554
time: 0.2490551471710205
time: 2.266507387161255
[1, 19378] loss_train: 0.007344, loss_test: 0.005553
time: 0.24405503273010254
time: 2.3625288009643555
[1, 19379] loss_train: 0.009194, loss_test: 0.005550
time: 0.25005531311035156
time: 2.2525038719177246
[1, 19380] loss_train: 0.009558, loss_test: 0.005549
time: 0.2600576877593994
time: 2.2657032012939453
[1, 19381] loss_train: 0.003099, loss_test: 0.005545
time: 0.2450549602508545
time: 2.295516014099121
[1, 19382] loss_train: 0.007142, loss_test: 0.005541
time: 0.24605393409729004
time: 2.3125176429748535
[1, 19383] loss_train: 0.002266, loss_test: 0.005537
time: 0.2490551471710205
time: 2.2955148220062256
[1, 19384] loss_train: 0.002208, loss_test: 0.005536
time: 0.2540547847747803
time: 2.2975144386291504
[1, 19385] loss_train: 0.003643, loss_test: 0.005541
time: 0.24605464935302734
time: 2.2905125617980957
[1, 19386] loss_train: 0.006318, loss_test: 0.005552
time: 0.24605464935302734
time: 2.3115172386169434
[1, 19387] loss_train: 0.000753, loss_test: 0.005565
time: 0.2510547637939453
time: 2.2995150089263916
[1, 19388] loss_train: 0.013478, loss_test: 0.005567
time: 0.24605512619018555
time: 2.274508237838745
[1, 19389] loss_train: 0.004326, loss_test: 0.005569
time: 0.24405574798583984
time: 2.2855112552642822
[1, 19390] loss_train: 0.007216, loss_test: 0.005568
time: 0.2630584239959717
time: 2.308515787124634
[1, 19391] loss_train: 0.008635, loss_test: 0.005559
time: 0.24378681182861328
time: 2.2375011444091797
[1, 19392] loss_train: 0.013896, loss_test: 0.005548
time: 0.25005507469177246
time: 2.2855117321014404
[1, 19393] loss_train: 0.001322, loss_test: 0.005540
time: 0.24405407905578613
time: 2.285511016845703
[1, 19394] loss_train: 0.005138, loss_test: 0.005536
time: 0.25005602836608887
time: 2.2745182514190674
[1, 19395] loss_train: 0.007117, loss_test: 0.005536
time: 0.24305367469787598
time: 2.252504348754883
[1, 19396] loss_train: 0.004623, loss_test: 0.005537
time: 0.24405384063720703
time: 2.2525041103363037
[1, 19397] loss_train: 0.010649, loss_test: 0.005541
time: 0.24405384063720703
time: 2.2505035400390625
[1, 19398] loss_train: 0.007129, loss_test: 0.005544
time: 0.2450542449951172
time: 2.2645163536071777
[1, 19399] loss_train: 0.002464, loss_test: 0.005544
time: 0.24405455589294434
time: 2.2655062675476074
[1, 19400] loss_train: 0.009786, loss_test: 0.005543
time: 0.2580568790435791
time: 2.24550199508667
[1, 19401] loss_train: 0.008242, loss_test: 0.005542
time: 0.2470552921295166
time: 2.234499454498291
[1, 19402] loss_train: 0.008808, loss_test: 0.005546
time: 0.24405503273010254
time: 2.264505386352539
[1, 19403] loss_train: 0.008045, loss_test: 0.005551
time: 0.24405431747436523
time: 2.2695066928863525
[1, 19404] loss_train: 0.006469, loss_test: 0.005555
time: 0.24805426597595215
time: 2.2555041313171387
[1, 19405] loss_train: 0.002179, loss_test: 0.005554
time: 0.24605584144592285
time: 2.260505437850952
[1, 19406] loss_train: 0.009464, loss_test: 0.005552
time: 0.2450542449951172
time: 2.2680115699768066
[1, 19407] loss_train: 0.009151, loss_test: 0.005552
time: 0.2450547218322754
time: 2.2545039653778076
[1, 19408] loss_train: 0.008591, loss_test: 0.005556
time: 0.24605488777160645
time: 2.2665064334869385
[1, 19409] loss_train: 0.006831, loss_test: 0.005563
time: 0.24305415153503418
time: 2.256504535675049
[1, 19410] loss_train: 0.009682, loss_test: 0.005570
time: 0.25705742835998535
time: 2.261505365371704
[1, 19411] loss_train: 0.002336, loss_test: 0.005581
time: 0.24506759643554688
time: 2.271507740020752
[1, 19412] loss_train: 0.004293, loss_test: 0.005591
time: 0.2470543384552002
time: 2.3005151748657227
[1, 19413] loss_train: 0.006462, loss_test: 0.005596
time: 0.2450547218322754
time: 2.4858851432800293
[1, 19414] loss_train: 0.010705, loss_test: 0.005588
time: 0.25005555152893066
time: 2.619260787963867
[1, 19415] loss_train: 0.005768, loss_test: 0.005583
time: 0.3270723819732666
time: 2.450194835662842
[1, 19416] loss_train: 0.003683, loss_test: 0.005579
time: 0.24605488777160645
time: 2.4265427589416504
[1, 19417] loss_train: 0.005908, loss_test: 0.005577
time: 0.25005531311035156
time: 2.2915127277374268
[1, 19418] loss_train: 0.009512, loss_test: 0.005569
time: 0.24805712699890137
time: 2.279510021209717
[1, 19419] loss_train: 0.002929, loss_test: 0.005567
time: 0.2490546703338623
time: 2.278510332107544
[1, 19420] loss_train: 0.005518, loss_test: 0.005564
time: 0.25705718994140625
time: 2.2525036334991455
[1, 19421] loss_train: 0.005047, loss_test: 0.005565
time: 0.2470541000366211
time: 2.2895121574401855
[1, 19422] loss_train: 0.010242, loss_test: 0.005567
time: 0.24405169486999512
time: 2.3145177364349365
[1, 19423] loss_train: 0.005463, loss_test: 0.005565
time: 0.25005507469177246
time: 2.2755095958709717
[1, 19424] loss_train: 0.011062, loss_test: 0.005567
time: 0.24405360221862793
time: 2.2565054893493652
[1, 19425] loss_train: 0.009584, loss_test: 0.005566
time: 0.2483384609222412
time: 2.248502731323242
[1, 19426] loss_train: 0.004678, loss_test: 0.005563
time: 0.2450547218322754
time: 2.272508144378662
[1, 19427] loss_train: 0.002680, loss_test: 0.005558
time: 0.24605441093444824
time: 2.270508289337158
[1, 19428] loss_train: 0.003107, loss_test: 0.005555
time: 0.2450544834136963
time: 2.2635064125061035
[1, 19429] loss_train: 0.005544, loss_test: 0.005554
time: 0.2450547218322754
time: 2.3015143871307373
[1, 19430] loss_train: 0.005576, loss_test: 0.005555
time: 0.25907349586486816
time: 2.2755088806152344
[1, 19431] loss_train: 0.009521, loss_test: 0.005556
time: 0.24505376815795898
time: 2.2745094299316406
[1, 19432] loss_train: 0.007264, loss_test: 0.005557
time: 0.24405360221862793
time: 2.2995150089263916
[1, 19433] loss_train: 0.001504, loss_test: 0.005560
time: 0.25005555152893066
time: 2.2725107669830322
[1, 19434] loss_train: 0.007684, loss_test: 0.005560
time: 0.2450542449951172
time: 2.2860255241394043
[1, 19435] loss_train: 0.006838, loss_test: 0.005560
time: 0.24605441093444824
time: 2.28351092338562
[1, 19436] loss_train: 0.008608, loss_test: 0.005558
time: 0.25005578994750977
time: 2.2785096168518066
[1, 19437] loss_train: 0.003381, loss_test: 0.005558
time: 0.24605417251586914
time: 2.254504919052124
[1, 19438] loss_train: 0.001621, loss_test: 0.005560
time: 0.2450547218322754
time: 2.2645063400268555
[1, 19439] loss_train: 0.002951, loss_test: 0.005563
time: 0.2470552921295166
time: 2.288511276245117
[1, 19440] loss_train: 0.008655, loss_test: 0.005566
time: 0.26605963706970215
time: 2.260505437850952
[1, 19441] loss_train: 0.001926, loss_test: 0.005570
time: 0.2450551986694336
time: 2.272507905960083
[1, 19442] loss_train: 0.003836, loss_test: 0.005577
time: 0.25005578994750977
time: 2.3765320777893066
[1, 19443] loss_train: 0.002527, loss_test: 0.005584
time: 0.2580585479736328
time: 2.320518970489502
[1, 19444] loss_train: 0.002704, loss_test: 0.005594
time: 0.24405455589294434
time: 2.268507242202759
[1, 19445] loss_train: 0.009835, loss_test: 0.005597
time: 0.24405431747436523
time: 2.2535040378570557
[1, 19446] loss_train: 0.002670, loss_test: 0.005602
time: 0.2470552921295166
time: 2.2805097103118896
[1, 19447] loss_train: 0.008105, loss_test: 0.005597
time: 0.24405431747436523
time: 2.265507221221924
[1, 19448] loss_train: 0.007439, loss_test: 0.005595
time: 0.24305415153503418
time: 2.2625060081481934
[1, 19449] loss_train: 0.011056, loss_test: 0.005592
time: 0.2470552921295166
time: 2.2720131874084473
[1, 19450] loss_train: 0.007981, loss_test: 0.005594
time: 0.2630579471588135
time: 2.2895126342773438
[1, 19451] loss_train: 0.000670, loss_test: 0.005603
time: 0.2450549602508545
time: 2.299513816833496
[1, 19452] loss_train: 0.008065, loss_test: 0.005611
time: 0.24405384063720703
time: 2.268507957458496
[1, 19453] loss_train: 0.014115, loss_test: 0.005606
time: 0.24505400657653809
time: 2.3115174770355225
[1, 19454] loss_train: 0.005010, loss_test: 0.005600
time: 0.2450551986694336
time: 2.2795116901397705
[1, 19455] loss_train: 0.009012, loss_test: 0.005588
time: 0.24805593490600586
time: 2.2965128421783447
[1, 19456] loss_train: 0.003372, loss_test: 0.005576
time: 0.24405336380004883
time: 2.2735111713409424
[1, 19457] loss_train: 0.006269, loss_test: 0.005564
time: 0.25505638122558594
time: 2.278510093688965
[1, 19458] loss_train: 0.012501, loss_test: 0.005553
time: 0.24305343627929688
time: 2.254504919052124
[1, 19459] loss_train: 0.006118, loss_test: 0.005548
time: 0.25305604934692383
time: 2.2645103931427
[1, 19460] loss_train: 0.006599, loss_test: 0.005544
time: 0.2600586414337158
time: 2.2885117530822754
[1, 19461] loss_train: 0.007099, loss_test: 0.005543
time: 0.2450544834136963
time: 2.280510187149048
[1, 19462] loss_train: 0.004623, loss_test: 0.005543
time: 0.24405407905578613
time: 2.2605063915252686
[1, 19463] loss_train: 0.009985, loss_test: 0.005543
time: 0.2470552921295166
time: 2.2805120944976807
[1, 19464] loss_train: 0.008748, loss_test: 0.005544
time: 0.2490551471710205
time: 2.291513681411743
[1, 19465] loss_train: 0.009722, loss_test: 0.005542
time: 0.25905585289001465
time: 2.406283140182495
[1, 19466] loss_train: 0.007478, loss_test: 0.005538
time: 0.2450544834136963
time: 2.2985143661499023
[1, 19467] loss_train: 0.001288, loss_test: 0.005535
time: 0.2510550022125244
time: 2.2715084552764893
[1, 19468] loss_train: 0.003183, loss_test: 0.005531
time: 0.2450551986694336
time: 2.286512613296509
[1, 19469] loss_train: 0.010219, loss_test: 0.005529
time: 0.2510566711425781
time: 2.286511182785034
[1, 19470] loss_train: 0.002555, loss_test: 0.005530
time: 0.2620582580566406
time: 2.295513391494751
[1, 19471] loss_train: 0.005500, loss_test: 0.005532
time: 0.2490553855895996
time: 2.372532606124878
[1, 19472] loss_train: 0.001428, loss_test: 0.005537
time: 0.24605512619018555
time: 2.284510850906372
[1, 19473] loss_train: 0.002353, loss_test: 0.005545
time: 0.2600572109222412
time: 2.2755093574523926
[1, 19474] loss_train: 0.004268, loss_test: 0.005554
time: 0.24405360221862793
time: 2.277510404586792
[1, 19475] loss_train: 0.002769, loss_test: 0.005561
time: 0.24405384063720703
time: 2.2875118255615234
[1, 19476] loss_train: 0.004146, loss_test: 0.005571
time: 0.24205446243286133
time: 2.298513650894165
[1, 19477] loss_train: 0.006200, loss_test: 0.005575
time: 0.25205564498901367
time: 2.266507148742676
[1, 19478] loss_train: 0.001815, loss_test: 0.005576
time: 0.24805474281311035
time: 2.2745094299316406
[1, 19479] loss_train: 0.009356, loss_test: 0.005568
time: 0.2450551986694336
time: 2.263505458831787
[1, 19480] loss_train: 0.002387, loss_test: 0.005564
time: 0.25905823707580566
time: 2.2875118255615234
[1, 19481] loss_train: 0.011830, loss_test: 0.005553
time: 0.24605512619018555
time: 2.2875113487243652
[1, 19482] loss_train: 0.005427, loss_test: 0.005543
time: 0.25205516815185547
time: 2.3235201835632324
[1, 19483] loss_train: 0.007957, loss_test: 0.005541
time: 0.2510557174682617
time: 2.294512987136841
[1, 19484] loss_train: 0.003475, loss_test: 0.005545
time: 0.26405835151672363
time: 2.3365232944488525
[1, 19485] loss_train: 0.006896, loss_test: 0.005552
time: 0.24405360221862793
time: 2.294513702392578
[1, 19486] loss_train: 0.006004, loss_test: 0.005561
time: 0.2470548152923584
time: 2.2890825271606445
[1, 19487] loss_train: 0.003918, loss_test: 0.005573
time: 0.25005626678466797
time: 2.308515787124634
[1, 19488] loss_train: 0.007775, loss_test: 0.005578
time: 0.2540569305419922
time: 2.3095169067382812
[1, 19489] loss_train: 0.003836, loss_test: 0.005580
time: 0.24805545806884766
time: 2.2655062675476074
[1, 19490] loss_train: 0.013489, loss_test: 0.005576
time: 0.2740602493286133
time: 2.32051944732666
[1, 19491] loss_train: 0.004387, loss_test: 0.005567
time: 0.24305295944213867
time: 2.2896032333374023
[1, 19492] loss_train: 0.015036, loss_test: 0.005552
time: 0.24805569648742676
time: 2.29451322555542
[1, 19493] loss_train: 0.008604, loss_test: 0.005543
time: 0.24405479431152344
time: 2.2735073566436768
[1, 19494] loss_train: 0.005375, loss_test: 0.005536
time: 0.2490558624267578
time: 2.2765090465545654
[1, 19495] loss_train: 0.009055, loss_test: 0.005533
time: 0.24805521965026855
time: 2.2715084552764893
[1, 19496] loss_train: 0.010740, loss_test: 0.005533
time: 0.24657893180847168
time: 2.264507293701172
[1, 19497] loss_train: 0.002633, loss_test: 0.005536
time: 0.24405360221862793
time: 2.273508071899414
[1, 19498] loss_train: 0.005395, loss_test: 0.005539
time: 0.24605393409729004
time: 2.281512975692749
[1, 19499] loss_train: 0.003384, loss_test: 0.005535
time: 0.2450547218322754
time: 2.299513578414917
[1, 19500] loss_train: 0.004121, loss_test: 0.005532
time: 0.25705766677856445
time: 2.297513723373413
[1, 19501] loss_train: 0.003671, loss_test: 0.005525
time: 0.24505400657653809
time: 2.278510093688965
[1, 19502] loss_train: 0.004431, loss_test: 0.005523
time: 0.24605441093444824
time: 2.29451322555542
[1, 19503] loss_train: 0.009448, loss_test: 0.005526
time: 0.2470557689666748
time: 2.272507429122925
[1, 19504] loss_train: 0.003555, loss_test: 0.005533
time: 0.2470550537109375
time: 2.295513391494751
[1, 19505] loss_train: 0.005742, loss_test: 0.005542
time: 0.24605488777160645
time: 2.2955129146575928
[1, 19506] loss_train: 0.002539, loss_test: 0.005554
time: 0.24305415153503418
time: 2.2835099697113037
[1, 19507] loss_train: 0.010207, loss_test: 0.005563
time: 0.2470548152923584
time: 2.271507978439331
[1, 19508] loss_train: 0.000602, loss_test: 0.005573
time: 0.2450549602508545
time: 2.281517505645752
[1, 19509] loss_train: 0.009958, loss_test: 0.005574
time: 0.25205564498901367
time: 2.2625062465667725
[1, 19510] loss_train: 0.000756, loss_test: 0.005576
time: 0.25705647468566895
time: 2.2635068893432617
[1, 19511] loss_train: 0.004468, loss_test: 0.005575
time: 0.2540562152862549
time: 2.260009765625
[1, 19512] loss_train: 0.000572, loss_test: 0.005575
time: 0.2450549602508545
time: 2.2925119400024414
[1, 19513] loss_train: 0.003493, loss_test: 0.005574
time: 0.24405479431152344
time: 2.2905118465423584
[1, 19514] loss_train: 0.006411, loss_test: 0.005571
time: 0.24405431747436523
time: 2.2765090465545654
[1, 19515] loss_train: 0.011538, loss_test: 0.005564
time: 0.24605417251586914
time: 2.282510995864868
[1, 19516] loss_train: 0.006268, loss_test: 0.005555
time: 0.2450547218322754
time: 2.2935128211975098
[1, 19517] loss_train: 0.004387, loss_test: 0.005546
time: 0.24505400657653809
time: 2.268507957458496
[1, 19518] loss_train: 0.014747, loss_test: 0.005529
time: 0.24805545806884766
time: 2.246501922607422
[1, 19519] loss_train: 0.006407, loss_test: 0.005520
time: 0.24405431747436523
time: 2.2395005226135254
[1, 19520] loss_train: 0.005541, loss_test: 0.005518
time: 0.26605987548828125
time: 2.2525041103363037
[1, 19521] loss_train: 0.001885, loss_test: 0.005519
time: 0.24505352973937988
time: 2.2895123958587646
[1, 19522] loss_train: 0.002676, loss_test: 0.005522
time: 0.24405407905578613
time: 2.2775166034698486
[1, 19523] loss_train: 0.020199, loss_test: 0.005528
time: 0.24405431747436523
time: 2.2785091400146484
[1, 19524] loss_train: 0.006923, loss_test: 0.005536
time: 0.24305438995361328
time: 2.284510612487793
[1, 19525] loss_train: 0.012998, loss_test: 0.005541
time: 0.2510559558868408
time: 2.2915170192718506
[1, 19526] loss_train: 0.011882, loss_test: 0.005543
time: 0.24805498123168945
time: 2.2745089530944824
[1, 19527] loss_train: 0.000671, loss_test: 0.005540
time: 0.24405407905578613
time: 2.2815165519714355
[1, 19528] loss_train: 0.002925, loss_test: 0.005537
time: 0.2490549087524414
time: 2.2995152473449707
[1, 19529] loss_train: 0.005366, loss_test: 0.005532
time: 0.25505828857421875
time: 2.3445234298706055
[1, 19530] loss_train: 0.008313, loss_test: 0.005529
time: 0.26405930519104004
time: 2.304514169692993
[1, 19531] loss_train: 0.006998, loss_test: 0.005529
time: 0.25505685806274414
time: 2.2755095958709717
[1, 19532] loss_train: 0.003687, loss_test: 0.005533
time: 0.2510557174682617
time: 2.310516595840454
[1, 19533] loss_train: 0.005809, loss_test: 0.005541
time: 0.2470550537109375
time: 2.2935128211975098
[1, 19534] loss_train: 0.003838, loss_test: 0.005552
time: 0.24405360221862793
time: 2.4015374183654785
[1, 19535] loss_train: 0.001537, loss_test: 0.005566
time: 0.2610588073730469
time: 2.3145172595977783
[1, 19536] loss_train: 0.005337, loss_test: 0.005574
time: 0.2450547218322754
time: 2.3505258560180664
[1, 19537] loss_train: 0.003934, loss_test: 0.005580
time: 0.25705695152282715
time: 2.2885115146636963
[1, 19538] loss_train: 0.006103, loss_test: 0.005581
time: 0.24605417251586914
time: 2.327521324157715
[1, 19539] loss_train: 0.003578, loss_test: 0.005581
time: 0.2450547218322754
time: 2.2695090770721436
[1, 19540] loss_train: 0.007854, loss_test: 0.005573
time: 0.2580580711364746
time: 2.273508071899414
[1, 19541] loss_train: 0.006353, loss_test: 0.005561
time: 0.2450547218322754
time: 2.2885217666625977
[1, 19542] loss_train: 0.005025, loss_test: 0.005554
time: 0.24605393409729004
time: 2.292513608932495
[1, 19543] loss_train: 0.011368, loss_test: 0.005546
time: 0.2690596580505371
time: 2.380532741546631
[1, 19544] loss_train: 0.001067, loss_test: 0.005548
time: 0.24605417251586914
time: 2.3185245990753174
[1, 19545] loss_train: 0.014154, loss_test: 0.005551
time: 0.26105809211730957
time: 2.2625062465667725
[1, 19546] loss_train: 0.007577, loss_test: 0.005555
time: 0.24605417251586914
time: 2.3145182132720947
[1, 19547] loss_train: 0.006873, loss_test: 0.005558
time: 0.24605441093444824
time: 2.272508382797241
[1, 19548] loss_train: 0.007408, loss_test: 0.005562
time: 0.2450542449951172
time: 2.3385233879089355
[1, 19549] loss_train: 0.010876, loss_test: 0.005565
time: 0.24605417251586914
time: 2.291513204574585
[1, 19550] loss_train: 0.003920, loss_test: 0.005564
time: 0.2600595951080322
time: 2.2755086421966553
[1, 19551] loss_train: 0.000953, loss_test: 0.005562
time: 0.24405360221862793
time: 2.406538486480713
[1, 19552] loss_train: 0.006464, loss_test: 0.005559
time: 0.27006030082702637
time: 2.323521614074707
[1, 19553] loss_train: 0.008320, loss_test: 0.005557
time: 0.2760610580444336
time: 2.395535945892334
[1, 19554] loss_train: 0.002631, loss_test: 0.005552
time: 0.2470552921295166
time: 2.28251051902771
[1, 19555] loss_train: 0.003028, loss_test: 0.005550
time: 0.24305462837219238
time: 2.238502025604248
[1, 19556] loss_train: 0.008962, loss_test: 0.005544
time: 0.24305391311645508
time: 2.2545042037963867
[1, 19557] loss_train: 0.003267, loss_test: 0.005539
time: 0.2470555305480957
time: 2.257504463195801
[1, 19558] loss_train: 0.005959, loss_test: 0.005534
time: 0.2470555305480957
time: 2.2795097827911377
[1, 19559] loss_train: 0.005239, loss_test: 0.005535
time: 0.24305367469787598
time: 2.2635064125061035
[1, 19560] loss_train: 0.006319, loss_test: 0.005539
time: 0.2560563087463379
time: 2.2895121574401855
[1, 19561] loss_train: 0.013009, loss_test: 0.005549
time: 0.2580580711364746
time: 2.2785096168518066
[1, 19562] loss_train: 0.007230, loss_test: 0.005567
time: 0.2540562152862549
time: 2.3665292263031006
[1, 19563] loss_train: 0.006292, loss_test: 0.005589
time: 0.2520561218261719
time: 2.30851674079895
[1, 19564] loss_train: 0.008140, loss_test: 0.005614
time: 0.25305652618408203
time: 2.273508071899414
[1, 19565] loss_train: 0.001282, loss_test: 0.005639
time: 0.24405455589294434
time: 2.234501600265503
[1, 19566] loss_train: 0.010382, loss_test: 0.005656
time: 0.24405479431152344
time: 2.2525038719177246
[1, 19567] loss_train: 0.001878, loss_test: 0.005677
time: 0.24405407905578613
time: 2.2495033740997314
[1, 19568] loss_train: 0.002134, loss_test: 0.005657
time: 0.2490551471710205
time: 2.244502305984497
[1, 19569] loss_train: 0.007583, loss_test: 0.005634
time: 0.24305343627929688
time: 2.246502637863159
[1, 19570] loss_train: 0.006204, loss_test: 0.005617
time: 0.2650582790374756
time: 2.307516574859619
[1, 19571] loss_train: 0.015724, loss_test: 0.005558
time: 0.30406713485717773
time: 2.5016443729400635
[1, 19572] loss_train: 0.008710, loss_test: 0.005530
time: 0.27706170082092285
time: 2.3385226726531982
[1, 19573] loss_train: 0.003773, loss_test: 0.005534
time: 0.25005626678466797
time: 2.311403274536133
[1, 19574] loss_train: 0.004235, loss_test: 0.005560
time: 0.24605417251586914
time: 2.283512830734253
[1, 19575] loss_train: 0.005717, loss_test: 0.005595
time: 0.24405479431152344
time: 2.2943432331085205
[1, 19576] loss_train: 0.006277, loss_test: 0.005634
time: 0.24205350875854492
time: 2.2637856006622314
[1, 19577] loss_train: 0.002821, loss_test: 0.005668
time: 0.24505400657653809
time: 2.251570463180542
[1, 19578] loss_train: 0.006641, loss_test: 0.005681
time: 0.24905610084533691
time: 2.2555038928985596
[1, 19579] loss_train: 0.006907, loss_test: 0.005675
time: 0.2490549087524414
time: 2.282047986984253
[1, 19580] loss_train: 0.003586, loss_test: 0.005651
time: 0.26105809211730957
time: 2.3015170097351074
[1, 19581] loss_train: 0.003109, loss_test: 0.005602
time: 0.24505376815795898
time: 2.366534948348999
[1, 19582] loss_train: 0.014855, loss_test: 0.005564
time: 0.24605417251586914
time: 2.2845113277435303
[1, 19583] loss_train: 0.011672, loss_test: 0.005546
time: 0.24405455589294434
time: 2.2745087146759033
[1, 19584] loss_train: 0.007688, loss_test: 0.005541
time: 0.2530553340911865
time: 2.2745094299316406
[1, 19585] loss_train: 0.008122, loss_test: 0.005549
time: 0.24405384063720703
time: 2.2590160369873047
[1, 19586] loss_train: 0.002532, loss_test: 0.005564
time: 0.24805450439453125
time: 2.2785098552703857
[1, 19587] loss_train: 0.004481, loss_test: 0.005584
time: 0.24405336380004883
time: 2.302518129348755
[1, 19588] loss_train: 0.002672, loss_test: 0.005608
time: 0.24605488777160645
time: 2.258504867553711
[1, 19589] loss_train: 0.004525, loss_test: 0.005621
time: 0.24205446243286133
time: 2.259505033493042
[1, 19590] loss_train: 0.014831, loss_test: 0.005629
time: 0.27005934715270996
time: 2.282510995864868
[1, 19591] loss_train: 0.005763, loss_test: 0.005629
time: 0.24405455589294434
time: 2.2765092849731445
[1, 19592] loss_train: 0.004379, loss_test: 0.005622
time: 0.24805521965026855
time: 2.3417439460754395
[1, 19593] loss_train: 0.008009, loss_test: 0.005609
time: 0.24405598640441895
time: 2.2485082149505615
[1, 19594] loss_train: 0.006188, loss_test: 0.005597
time: 0.24605584144592285
time: 2.310515880584717
[1, 19595] loss_train: 0.004000, loss_test: 0.005585
time: 0.25505661964416504
time: 2.3485257625579834
[1, 19596] loss_train: 0.004891, loss_test: 0.005571
time: 0.2510554790496826
time: 2.342212438583374
[1, 19597] loss_train: 0.003661, loss_test: 0.005564
time: 0.24805450439453125
time: 2.282510757446289
[1, 19598] loss_train: 0.002239, loss_test: 0.005560
time: 0.2560560703277588
time: 2.2485036849975586
[1, 19599] loss_train: 0.011739, loss_test: 0.005552
time: 0.2490553855895996
time: 2.277519941329956
[1, 19600] loss_train: 0.001768, loss_test: 0.005550
time: 0.2580575942993164
time: 2.291512966156006
[1, 19601] loss_train: 0.007224, loss_test: 0.005548
time: 0.2490546703338623
time: 2.2635066509246826
[1, 19602] loss_train: 0.011330, loss_test: 0.005548
time: 0.2520558834075928
time: 2.268507719039917
[1, 19603] loss_train: 0.005287, loss_test: 0.005549
time: 0.24605488777160645
time: 2.2565038204193115
[1, 19604] loss_train: 0.005076, loss_test: 0.005551
time: 0.2470552921295166
time: 2.2765097618103027
[1, 19605] loss_train: 0.002147, loss_test: 0.005554
time: 0.2490544319152832
time: 2.2725112438201904
[1, 19606] loss_train: 0.003131, loss_test: 0.005553
time: 0.2450549602508545
time: 2.271507740020752
[1, 19607] loss_train: 0.003355, loss_test: 0.005552
time: 0.25305628776550293
time: 2.2915117740631104
[1, 19608] loss_train: 0.019833, loss_test: 0.005544
time: 0.2450551986694336
time: 2.292512893676758
[1, 19609] loss_train: 0.005834, loss_test: 0.005539
time: 0.2470545768737793
time: 2.2765095233917236
[1, 19610] loss_train: 0.012741, loss_test: 0.005538
time: 0.2580595016479492
time: 2.2765090465545654
[1, 19611] loss_train: 0.009323, loss_test: 0.005539
time: 0.24405360221862793
time: 2.2815120220184326
[1, 19612] loss_train: 0.005627, loss_test: 0.005538
time: 0.24605393409729004
time: 2.2895126342773438
[1, 19613] loss_train: 0.003307, loss_test: 0.005535
time: 0.25305700302124023
time: 2.2845101356506348
[1, 19614] loss_train: 0.001971, loss_test: 0.005532
time: 0.2490556240081787
time: 2.2795097827911377
[1, 19615] loss_train: 0.008628, loss_test: 0.005532
time: 0.24305415153503418
time: 2.25750470161438
[1, 19616] loss_train: 0.005656, loss_test: 0.005532
time: 0.2530555725097656
time: 2.2635059356689453
[1, 19617] loss_train: 0.006200, loss_test: 0.005530
time: 0.24605441093444824
time: 2.268507719039917
[1, 19618] loss_train: 0.016142, loss_test: 0.005529
time: 0.2490549087524414
time: 2.292513132095337
[1, 19619] loss_train: 0.008172, loss_test: 0.005529
time: 0.2470550537109375
time: 2.292512893676758
[1, 19620] loss_train: 0.008665, loss_test: 0.005529
time: 0.25705718994140625
time: 2.2625060081481934
[1, 19621] loss_train: 0.012644, loss_test: 0.005532
time: 0.2470550537109375
time: 2.2945258617401123
[1, 19622] loss_train: 0.008874, loss_test: 0.005535
time: 0.2470550537109375
time: 2.3135170936584473
[1, 19623] loss_train: 0.005966, loss_test: 0.005538
time: 0.24305415153503418
time: 2.32804536819458
[1, 19624] loss_train: 0.001893, loss_test: 0.005537
time: 0.24405407905578613
time: 2.2825098037719727
[1, 19625] loss_train: 0.005190, loss_test: 0.005537
time: 0.24305510520935059
time: 2.335522174835205
[1, 19626] loss_train: 0.005114, loss_test: 0.005536
time: 0.24605488777160645
time: 2.283510684967041
[1, 19627] loss_train: 0.005767, loss_test: 0.005535
time: 0.24805426597595215
time: 2.3015148639678955
[1, 19628] loss_train: 0.003731, loss_test: 0.005536
time: 0.24405503273010254
time: 2.2915117740631104
[1, 19629] loss_train: 0.004721, loss_test: 0.005540
time: 0.25505614280700684
time: 2.2865121364593506
[1, 19630] loss_train: 0.010973, loss_test: 0.005547
time: 0.26105761528015137
time: 2.2715084552764893
[1, 19631] loss_train: 0.008990, loss_test: 0.005554
time: 0.24305415153503418
time: 2.283510684967041
[1, 19632] loss_train: 0.002563, loss_test: 0.005560
time: 0.24605512619018555
time: 2.316516876220703
[1, 19633] loss_train: 0.010869, loss_test: 0.005564
time: 0.24405384063720703
time: 2.285513401031494
[1, 19634] loss_train: 0.006942, loss_test: 0.005567
time: 0.24405455589294434
time: 2.2895116806030273
[1, 19635] loss_train: 0.008053, loss_test: 0.005569
time: 0.24805450439453125
time: 2.305516481399536
[1, 19636] loss_train: 0.005684, loss_test: 0.005572
time: 0.2470550537109375
time: 2.2905116081237793
[1, 19637] loss_train: 0.004583, loss_test: 0.005574
time: 0.24405431747436523
time: 2.2655067443847656
[1, 19638] loss_train: 0.013303, loss_test: 0.005563
time: 0.24505400657653809
time: 2.2705085277557373
[1, 19639] loss_train: 0.003331, loss_test: 0.005559
time: 0.2650594711303711
time: 2.3140206336975098
[1, 19640] loss_train: 0.002114, loss_test: 0.005559
time: 0.25905704498291016
time: 2.2825136184692383
[1, 19641] loss_train: 0.015855, loss_test: 0.005558
time: 0.2450544834136963
time: 2.3015148639678955
[1, 19642] loss_train: 0.004728, loss_test: 0.005557
time: 0.2470543384552002
time: 2.2785098552703857
[1, 19643] loss_train: 0.004771, loss_test: 0.005557
time: 0.24505400657653809
time: 2.289512872695923
[1, 19644] loss_train: 0.010341, loss_test: 0.005559
time: 0.24405431747436523
time: 2.2985174655914307
[1, 19645] loss_train: 0.003394, loss_test: 0.005560
time: 0.24305415153503418
time: 2.2785096168518066
[1, 19646] loss_train: 0.002738, loss_test: 0.005553
time: 0.24605512619018555
time: 2.301696300506592
[1, 19647] loss_train: 0.002846, loss_test: 0.005543
time: 0.24805498123168945
time: 2.3025147914886475
[1, 19648] loss_train: 0.008477, loss_test: 0.005537
time: 0.24405407905578613
time: 2.303515911102295
[1, 19649] loss_train: 0.006859, loss_test: 0.005532
time: 0.24305391311645508
time: 2.285511016845703
[1, 19650] loss_train: 0.005040, loss_test: 0.005527
time: 0.2690620422363281
time: 2.3055148124694824
[1, 19651] loss_train: 0.003184, loss_test: 0.005524
time: 0.2450551986694336
time: 2.2785115242004395
[1, 19652] loss_train: 0.004297, loss_test: 0.005525
time: 0.25105738639831543
time: 2.2605056762695312
[1, 19653] loss_train: 0.005187, loss_test: 0.005532
time: 0.25205516815185547
time: 2.3005154132843018
[1, 19654] loss_train: 0.006809, loss_test: 0.005540
time: 0.24305319786071777
time: 2.293515682220459
[1, 19655] loss_train: 0.000680, loss_test: 0.005554
time: 0.24905610084533691
time: 2.2945127487182617
[1, 19656] loss_train: 0.008394, loss_test: 0.005546
time: 0.2470548152923584
time: 2.306516170501709
[1, 19657] loss_train: 0.001183, loss_test: 0.005543
time: 0.2470548152923584
time: 2.2765090465545654
[1, 19658] loss_train: 0.013695, loss_test: 0.005537
time: 0.2470543384552002
time: 2.2745096683502197
[1, 19659] loss_train: 0.006745, loss_test: 0.005529
time: 0.24305319786071777
time: 2.2615063190460205
[1, 19660] loss_train: 0.001913, loss_test: 0.005525
time: 0.2630584239959717
time: 2.266507387161255
[1, 19661] loss_train: 0.001831, loss_test: 0.005523
time: 0.25005483627319336
time: 2.291015863418579
[1, 19662] loss_train: 0.009914, loss_test: 0.005523
time: 0.2450547218322754
time: 2.3045177459716797
[1, 19663] loss_train: 0.010282, loss_test: 0.005523
time: 0.24605536460876465
time: 2.2535033226013184
[1, 19664] loss_train: 0.006839, loss_test: 0.005526
time: 0.2510559558868408
time: 2.2722384929656982
[1, 19665] loss_train: 0.004715, loss_test: 0.005530
time: 0.24305319786071777
time: 2.2825112342834473
[1, 19666] loss_train: 0.002991, loss_test: 0.005532
time: 0.24405360221862793
time: 2.2920172214508057
[1, 19667] loss_train: 0.005492, loss_test: 0.005531
time: 0.24605703353881836
time: 2.295513391494751
[1, 19668] loss_train: 0.005283, loss_test: 0.005530
time: 0.2470543384552002
time: 2.2715084552764893
[1, 19669] loss_train: 0.004859, loss_test: 0.005530
time: 0.2560572624206543
time: 2.274519205093384
[1, 19670] loss_train: 0.002326, loss_test: 0.005532
time: 0.27006077766418457
time: 2.273507595062256
[1, 19671] loss_train: 0.003040, loss_test: 0.005538
time: 0.24305486679077148
time: 2.2785089015960693
[1, 19672] loss_train: 0.000498, loss_test: 0.005550
time: 0.24605631828308105
time: 2.3005154132843018
[1, 19673] loss_train: 0.003221, loss_test: 0.005566
time: 0.2470543384552002
time: 2.3783717155456543
[1, 19674] loss_train: 0.005939, loss_test: 0.005575
time: 0.2470545768737793
time: 2.3685302734375
[1, 19675] loss_train: 0.006244, loss_test: 0.005587
time: 0.2470543384552002
time: 2.2975144386291504
[1, 19676] loss_train: 0.008123, loss_test: 0.005591
time: 0.24605441093444824
time: 2.381535291671753
[1, 19677] loss_train: 0.004863, loss_test: 0.005596
time: 0.2830619812011719
time: 2.346524715423584
[1, 19678] loss_train: 0.005181, loss_test: 0.005596
time: 0.24405360221862793
time: 2.2745091915130615
[1, 19679] loss_train: 0.008701, loss_test: 0.005585
time: 0.24805498123168945
time: 2.3045156002044678
[1, 19680] loss_train: 0.007637, loss_test: 0.005566
time: 0.2600572109222412
time: 2.3155205249786377
[1, 19681] loss_train: 0.001663, loss_test: 0.005556
time: 0.2710609436035156
time: 2.4175405502319336
[1, 19682] loss_train: 0.003373, loss_test: 0.005549
time: 0.2470548152923584
time: 2.471552610397339
[1, 19683] loss_train: 0.004444, loss_test: 0.005547
time: 0.24805521965026855
time: 2.3445241451263428
[1, 19684] loss_train: 0.002376, loss_test: 0.005549
time: 0.24605417251586914
time: 2.3375227451324463
[1, 19685] loss_train: 0.003245, loss_test: 0.005555
time: 0.24605512619018555
time: 2.284510612487793
[1, 19686] loss_train: 0.005378, loss_test: 0.005562
time: 0.24805569648742676
time: 2.3405227661132812
[1, 19687] loss_train: 0.007398, loss_test: 0.005569
time: 0.3030672073364258
time: 2.290512800216675
[1, 19688] loss_train: 0.003192, loss_test: 0.005575
time: 0.2450547218322754
time: 2.2905123233795166
[1, 19689] loss_train: 0.001581, loss_test: 0.005577
time: 0.26405882835388184
time: 2.237513303756714
[1, 19690] loss_train: 0.005828, loss_test: 0.005574
time: 0.25905704498291016
time: 2.256504774093628
[1, 19691] loss_train: 0.005414, loss_test: 0.005566
time: 0.249068021774292
time: 2.3315210342407227
[1, 19692] loss_train: 0.010449, loss_test: 0.005558
time: 0.26105809211730957
time: 2.3040196895599365
[1, 19693] loss_train: 0.000694, loss_test: 0.005554
time: 0.24605441093444824
time: 2.248969793319702
[1, 19694] loss_train: 0.008155, loss_test: 0.005550
time: 0.24405431747436523
time: 2.2655060291290283
[1, 19695] loss_train: 0.011942, loss_test: 0.005548
time: 0.24605488777160645
time: 2.286510944366455
[1, 19696] loss_train: 0.006132, loss_test: 0.005548
time: 0.2470545768737793
time: 2.290510892868042
[1, 19697] loss_train: 0.009723, loss_test: 0.005550
time: 0.2470560073852539
time: 2.257504463195801
[1, 19698] loss_train: 0.005742, loss_test: 0.005553
time: 0.2450547218322754
time: 2.283886432647705
[1, 19699] loss_train: 0.004660, loss_test: 0.005557
time: 0.24505376815795898
time: 2.2675070762634277
[1, 19700] loss_train: 0.008924, loss_test: 0.005563
time: 0.2600588798522949
time: 2.271507501602173
[1, 19701] loss_train: 0.004192, loss_test: 0.005570
time: 0.24605417251586914
time: 2.279510498046875
[1, 19702] loss_train: 0.002998, loss_test: 0.005576
time: 0.24805521965026855
time: 2.3015143871307373
[1, 19703] loss_train: 0.002982, loss_test: 0.005581
time: 0.25005626678466797
time: 2.2705063819885254
[1, 19704] loss_train: 0.004197, loss_test: 0.005585
time: 0.24605464935302734
time: 2.2625062465667725
[1, 19705] loss_train: 0.000721, loss_test: 0.005580
time: 0.24805498123168945
time: 2.319518804550171
[1, 19706] loss_train: 0.001955, loss_test: 0.005575
time: 0.2450547218322754
time: 2.2775092124938965
[1, 19707] loss_train: 0.006284, loss_test: 0.005569
time: 0.2510554790496826
time: 2.2565114498138428
[1, 19708] loss_train: 0.007415, loss_test: 0.005568
time: 0.24405455589294434
time: 2.260514736175537
[1, 19709] loss_train: 0.003838, loss_test: 0.005569
time: 0.24505376815795898
time: 2.2615065574645996
[1, 19710] loss_train: 0.007865, loss_test: 0.005571
time: 0.2740609645843506
time: 2.280510187149048
[1, 19711] loss_train: 0.003728, loss_test: 0.005574
time: 0.2450542449951172
time: 2.272510051727295
[1, 19712] loss_train: 0.004943, loss_test: 0.005579
time: 0.24505400657653809
time: 2.3255202770233154
[1, 19713] loss_train: 0.004540, loss_test: 0.005582
time: 0.2450547218322754
time: 2.2365000247955322
[1, 19714] loss_train: 0.003170, loss_test: 0.005589
time: 0.24605488777160645
time: 2.283513307571411
[1, 19715] loss_train: 0.003156, loss_test: 0.005596
time: 0.24605488777160645
time: 2.2785089015960693
[1, 19716] loss_train: 0.004922, loss_test: 0.005599
time: 0.24605441093444824
time: 2.268507957458496
[1, 19717] loss_train: 0.000960, loss_test: 0.005604
time: 0.251056432723999
time: 2.2695064544677734
[1, 19718] loss_train: 0.009129, loss_test: 0.005603
time: 0.24605464935302734
time: 2.2915124893188477
[1, 19719] loss_train: 0.007958, loss_test: 0.005599
time: 0.24505400657653809
time: 2.2725090980529785
[1, 19720] loss_train: 0.006209, loss_test: 0.005597
time: 0.2580568790435791
time: 2.2895119190216064
[1, 19721] loss_train: 0.002499, loss_test: 0.005598
time: 0.24805498123168945
time: 2.283511161804199
[1, 19722] loss_train: 0.003392, loss_test: 0.005599
time: 0.24405550956726074
time: 2.253504514694214
[1, 19723] loss_train: 0.010127, loss_test: 0.005595
time: 0.25005483627319336
time: 2.2885124683380127
[1, 19724] loss_train: 0.013778, loss_test: 0.005587
time: 0.25005483627319336
time: 2.27051043510437
[1, 19725] loss_train: 0.009985, loss_test: 0.005582
time: 0.24605417251586914
time: 2.278510093688965
[1, 19726] loss_train: 0.006440, loss_test: 0.005579
time: 0.2450544834136963
time: 2.287015199661255
[1, 19727] loss_train: 0.004968, loss_test: 0.005578
time: 0.24405407905578613
time: 2.2635059356689453
[1, 19728] loss_train: 0.005380, loss_test: 0.005579
time: 0.24506115913391113
time: 2.2850167751312256
[1, 19729] loss_train: 0.008389, loss_test: 0.005579
time: 0.2450544834136963
time: 2.2635061740875244
[1, 19730] loss_train: 0.012114, loss_test: 0.005579
time: 0.2580575942993164
time: 2.2395212650299072
[1, 19731] loss_train: 0.008380, loss_test: 0.005575
time: 0.25005555152893066
time: 2.255031108856201
[1, 19732] loss_train: 0.004630, loss_test: 0.005570
time: 0.24505352973937988
time: 2.2765092849731445
[1, 19733] loss_train: 0.001705, loss_test: 0.005567
time: 0.2560563087463379
time: 2.414566993713379
[1, 19734] loss_train: 0.003580, loss_test: 0.005566
time: 0.24805474281311035
time: 2.268507957458496
[1, 19735] loss_train: 0.007549, loss_test: 0.005566
time: 0.24405479431152344
time: 2.2555038928985596
[1, 19736] loss_train: 0.006104, loss_test: 0.005565
time: 0.2450547218322754
time: 2.282510280609131
[1, 19737] loss_train: 0.008123, loss_test: 0.005563
time: 0.24305438995361328
time: 2.243004560470581
[1, 19738] loss_train: 0.011791, loss_test: 0.005562
time: 0.24889707565307617
time: 2.313508987426758
[1, 19739] loss_train: 0.006883, loss_test: 0.005555
time: 0.25505709648132324
time: 2.2795119285583496
[1, 19740] loss_train: 0.011856, loss_test: 0.005550
time: 0.26105761528015137
time: 2.2875139713287354
[1, 19741] loss_train: 0.010856, loss_test: 0.005549
time: 0.256056547164917
time: 2.3145182132720947
[1, 19742] loss_train: 0.000524, loss_test: 0.005546
time: 0.26105690002441406
time: 2.2865121364593506
[1, 19743] loss_train: 0.007166, loss_test: 0.005541
time: 0.24605464935302734
time: 2.2755162715911865
[1, 19744] loss_train: 0.005610, loss_test: 0.005538
time: 0.24405527114868164
time: 2.2785091400146484
[1, 19745] loss_train: 0.006258, loss_test: 0.005534
time: 0.24405479431152344
time: 2.3025145530700684
[1, 19746] loss_train: 0.001794, loss_test: 0.005532
time: 0.24505615234375
time: 2.2655065059661865
[1, 19747] loss_train: 0.004019, loss_test: 0.005532
time: 0.24305391311645508
time: 2.2765092849731445
[1, 19748] loss_train: 0.004962, loss_test: 0.005535
time: 0.25205540657043457
time: 2.2765095233917236
[1, 19749] loss_train: 0.005090, loss_test: 0.005538
time: 0.24505400657653809
time: 2.2625064849853516
[1, 19750] loss_train: 0.003384, loss_test: 0.005544
time: 0.2690601348876953
time: 2.2925217151641846
[1, 19751] loss_train: 0.005223, loss_test: 0.005551
time: 0.24905633926391602
time: 2.2755088806152344
[1, 19752] loss_train: 0.004444, loss_test: 0.005558
time: 0.25505661964416504
time: 2.337522268295288
[1, 19753] loss_train: 0.007883, loss_test: 0.005561
time: 0.25005555152893066
time: 2.2958505153656006
[1, 19754] loss_train: 0.003003, loss_test: 0.005565
time: 0.2510550022125244
time: 2.2755093574523926
[1, 19755] loss_train: 0.002156, loss_test: 0.005570
time: 0.2490556240081787
time: 2.257504463195801
[1, 19756] loss_train: 0.004812, loss_test: 0.005575
time: 0.2450542449951172
time: 2.2440080642700195
[1, 19757] loss_train: 0.004886, loss_test: 0.005577
time: 0.24405336380004883
time: 2.261507749557495
[1, 19758] loss_train: 0.002947, loss_test: 0.005584
time: 0.2510566711425781
time: 2.2535059452056885
[1, 19759] loss_train: 0.006493, loss_test: 0.005587
time: 0.24605488777160645
time: 2.272507667541504
[1, 19760] loss_train: 0.007848, loss_test: 0.005579
time: 0.25705766677856445
time: 2.283510684967041
[1, 19761] loss_train: 0.005115, loss_test: 0.005572
time: 0.24305415153503418
time: 2.261505126953125
[1, 19762] loss_train: 0.008806, loss_test: 0.005568
time: 0.2470564842224121
time: 2.3115158081054688
[1, 19763] loss_train: 0.002062, loss_test: 0.005567
time: 0.2510566711425781
time: 2.2989542484283447
[1, 19764] loss_train: 0.007541, loss_test: 0.005566
time: 0.24405407905578613
time: 2.3005146980285645
[1, 19765] loss_train: 0.001452, loss_test: 0.005564
time: 0.24805474281311035
time: 2.255505323410034
[1, 19766] loss_train: 0.004237, loss_test: 0.005565
time: 0.2510547637939453
time: 2.2765097618103027
[1, 19767] loss_train: 0.003061, loss_test: 0.005565
time: 0.24645519256591797
time: 2.2721076011657715
[1, 19768] loss_train: 0.003448, loss_test: 0.005565
time: 0.24405384063720703
time: 2.3125181198120117
[1, 19769] loss_train: 0.002523, loss_test: 0.005567
time: 0.24405336380004883
time: 2.2575056552886963
[1, 19770] loss_train: 0.005411, loss_test: 0.005568
time: 0.26106905937194824
time: 2.269508123397827
[1, 19771] loss_train: 0.002067, loss_test: 0.005572
time: 0.24305415153503418
time: 2.25850510597229
[1, 19772] loss_train: 0.002175, loss_test: 0.005579
time: 0.24605488777160645
time: 2.2885117530822754
[1, 19773] loss_train: 0.007260, loss_test: 0.005582
time: 0.2530558109283447
time: 2.2745091915130615
[1, 19774] loss_train: 0.001757, loss_test: 0.005588
time: 0.2470555305480957
time: 2.2905118465423584
[1, 19775] loss_train: 0.001517, loss_test: 0.005596
time: 0.24405479431152344
time: 2.2805087566375732
[1, 19776] loss_train: 0.012119, loss_test: 0.005605
time: 0.24305486679077148
time: 2.2995123863220215
[1, 19777] loss_train: 0.004352, loss_test: 0.005614
time: 0.2470545768737793
time: 2.256505250930786
[1, 19778] loss_train: 0.011358, loss_test: 0.005616
time: 0.24505400657653809
time: 2.280510663986206
[1, 19779] loss_train: 0.013338, loss_test: 0.005614
time: 0.2520558834075928
time: 2.2655091285705566
[1, 19780] loss_train: 0.009704, loss_test: 0.005611
time: 0.26606059074401855
time: 2.2985167503356934
[1, 19781] loss_train: 0.007317, loss_test: 0.005607
time: 0.2470543384552002
time: 2.293513536453247
[1, 19782] loss_train: 0.004681, loss_test: 0.005605
time: 0.2540569305419922
time: 2.294016122817993
[1, 19783] loss_train: 0.010606, loss_test: 0.005598
time: 0.24805569648742676
time: 2.2655060291290283
[1, 19784] loss_train: 0.005154, loss_test: 0.005578
time: 0.2450542449951172
time: 2.2915122509002686
[1, 19785] loss_train: 0.006578, loss_test: 0.005565
time: 0.2450549602508545
time: 2.282510280609131
[1, 19786] loss_train: 0.015728, loss_test: 0.005554
time: 0.2510557174682617
time: 2.317518472671509
[1, 19787] loss_train: 0.004977, loss_test: 0.005544
time: 0.265059232711792
time: 2.2825100421905518
[1, 19788] loss_train: 0.009820, loss_test: 0.005542
time: 0.2450544834136963
time: 2.2675070762634277
[1, 19789] loss_train: 0.002027, loss_test: 0.005539
time: 0.24405479431152344
time: 2.307516098022461
[1, 19790] loss_train: 0.010406, loss_test: 0.005536
time: 0.25905680656433105
time: 2.2877302169799805
[1, 19791] loss_train: 0.007083, loss_test: 0.005531
time: 0.24405384063720703
time: 2.272508382797241
[1, 19792] loss_train: 0.001251, loss_test: 0.005524
time: 0.24605464935302734
time: 2.333521842956543
[1, 19793] loss_train: 0.007525, loss_test: 0.005520
time: 0.24405384063720703
time: 2.2355008125305176
[1, 19794] loss_train: 0.004593, loss_test: 0.005520
time: 0.2540559768676758
time: 2.294515371322632
[1, 19795] loss_train: 0.009142, loss_test: 0.005522
time: 0.24405527114868164
time: 2.30251407623291
[1, 19796] loss_train: 0.004322, loss_test: 0.005525
time: 0.2510561943054199
time: 2.3035147190093994
[1, 19797] loss_train: 0.002443, loss_test: 0.005528
time: 0.27205991744995117
time: 2.2965140342712402
[1, 19798] loss_train: 0.003849, loss_test: 0.005532
time: 0.24805569648742676
time: 2.287513017654419
[1, 19799] loss_train: 0.008470, loss_test: 0.005535
time: 0.2450547218322754
time: 2.285510540008545
[1, 19800] loss_train: 0.003460, loss_test: 0.005538
time: 0.26805925369262695
time: 2.2820303440093994
[1, 19801] loss_train: 0.003167, loss_test: 0.005540
time: 0.24805521965026855
time: 2.329523801803589
[1, 19802] loss_train: 0.002385, loss_test: 0.005544
time: 0.24305295944213867
time: 2.2585065364837646
[1, 19803] loss_train: 0.005940, loss_test: 0.005548
time: 0.24505400657653809
time: 2.2815091609954834
[1, 19804] loss_train: 0.004480, loss_test: 0.005550
time: 0.2490551471710205
time: 2.306516408920288
[1, 19805] loss_train: 0.007625, loss_test: 0.005551
time: 0.24405431747436523
time: 2.298513650894165
[1, 19806] loss_train: 0.006328, loss_test: 0.005547
time: 0.25005626678466797
time: 2.2885115146636963
[1, 19807] loss_train: 0.004726, loss_test: 0.005537
time: 0.24505376815795898
time: 2.252504348754883
[1, 19808] loss_train: 0.007372, loss_test: 0.005527
time: 0.24605512619018555
time: 2.2935123443603516
[1, 19809] loss_train: 0.004786, loss_test: 0.005525
time: 0.24605512619018555
time: 2.2760555744171143
[1, 19810] loss_train: 0.015289, loss_test: 0.005526
time: 0.2580568790435791
time: 2.243502140045166
[1, 19811] loss_train: 0.004601, loss_test: 0.005534
time: 0.2490551471710205
time: 2.292512893676758
[1, 19812] loss_train: 0.007835, loss_test: 0.005546
time: 0.24805569648742676
time: 2.262505531311035
[1, 19813] loss_train: 0.007410, loss_test: 0.005558
time: 0.24805474281311035
time: 2.2640109062194824
[1, 19814] loss_train: 0.004261, loss_test: 0.005567
time: 0.24405360221862793
time: 2.2761640548706055
[1, 19815] loss_train: 0.007600, loss_test: 0.005572
time: 0.2490544319152832
time: 2.2455027103424072
[1, 19816] loss_train: 0.002414, loss_test: 0.005573
time: 0.24405479431152344
time: 2.2665066719055176
[1, 19817] loss_train: 0.005056, loss_test: 0.005567
time: 0.25005483627319336
time: 2.2755095958709717
[1, 19818] loss_train: 0.006269, loss_test: 0.005561
time: 0.24805474281311035
time: 2.2375011444091797
[1, 19819] loss_train: 0.006943, loss_test: 0.005555
time: 0.25005531311035156
time: 2.264505624771118
[1, 19820] loss_train: 0.000682, loss_test: 0.005540
time: 0.25705814361572266
time: 2.2675068378448486
[1, 19821] loss_train: 0.002943, loss_test: 0.005525
time: 0.2490556240081787
time: 2.289513111114502
[1, 19822] loss_train: 0.001126, loss_test: 0.005518
time: 0.24805641174316406
time: 2.261505603790283
[1, 19823] loss_train: 0.009438, loss_test: 0.005522
time: 0.24605488777160645
time: 2.2825100421905518
[1, 19824] loss_train: 0.007729, loss_test: 0.005535
time: 0.2470543384552002
time: 2.2755095958709717
[1, 19825] loss_train: 0.004451, loss_test: 0.005549
time: 0.25005507469177246
time: 2.2595062255859375
[1, 19826] loss_train: 0.005899, loss_test: 0.005569
time: 0.2450542449951172
time: 2.241501569747925
[1, 19827] loss_train: 0.009720, loss_test: 0.005588
time: 0.2450544834136963
time: 2.2725086212158203
[1, 19828] loss_train: 0.017767, loss_test: 0.005576
time: 0.24405336380004883
time: 2.253504514694214
[1, 19829] loss_train: 0.003614, loss_test: 0.005563
time: 0.24605441093444824
time: 2.247502326965332
[1, 19830] loss_train: 0.002984, loss_test: 0.005551
time: 0.2580578327178955
time: 2.2865142822265625
[1, 19831] loss_train: 0.001659, loss_test: 0.005543
time: 0.2450542449951172
time: 2.2995145320892334
[1, 19832] loss_train: 0.003556, loss_test: 0.005541
time: 0.24805450439453125
time: 2.330521583557129
[1, 19833] loss_train: 0.000927, loss_test: 0.005540
time: 0.2450542449951172
time: 2.29551362991333
[1, 19834] loss_train: 0.003688, loss_test: 0.005541
time: 0.24305438995361328
time: 2.2905118465423584
[1, 19835] loss_train: 0.009035, loss_test: 0.005541
time: 0.24805498123168945
time: 2.303029775619507
[1, 19836] loss_train: 0.009302, loss_test: 0.005541
time: 0.24805355072021484
time: 2.3230397701263428
[1, 19837] loss_train: 0.008606, loss_test: 0.005540
time: 0.25005507469177246
time: 2.2735087871551514
[1, 19838] loss_train: 0.003986, loss_test: 0.005541
time: 0.2490553855895996
time: 2.2775089740753174
[1, 19839] loss_train: 0.008309, loss_test: 0.005540
time: 0.24505400657653809
time: 2.281510353088379
[1, 19840] loss_train: 0.002707, loss_test: 0.005541
time: 0.25905847549438477
time: 2.286513566970825
[1, 19841] loss_train: 0.001640, loss_test: 0.005542
time: 0.2470552921295166
time: 2.3115174770355225
[1, 19842] loss_train: 0.013234, loss_test: 0.005544
time: 0.2510554790496826
time: 2.300513982772827
[1, 19843] loss_train: 0.009548, loss_test: 0.005545
time: 0.24405455589294434
time: 2.268507480621338
[1, 19844] loss_train: 0.014450, loss_test: 0.005549
time: 0.24605464935302734
time: 2.2645063400268555
[1, 19845] loss_train: 0.008179, loss_test: 0.005553
time: 0.24505352973937988
time: 2.2865142822265625
[1, 19846] loss_train: 0.010666, loss_test: 0.005559
time: 0.24405384063720703
time: 2.2875115871429443
[1, 19847] loss_train: 0.002358, loss_test: 0.005566
time: 0.24405503273010254
time: 2.297513961791992
[1, 19848] loss_train: 0.003173, loss_test: 0.005567
time: 0.2470541000366211
time: 2.2965142726898193
[1, 19849] loss_train: 0.003299, loss_test: 0.005564
time: 0.24605369567871094
time: 2.2995145320892334
[1, 19850] loss_train: 0.004790, loss_test: 0.005560
time: 0.2580571174621582
time: 2.3145179748535156
[1, 19851] loss_train: 0.003821, loss_test: 0.005557
time: 0.24805545806884766
time: 2.300516366958618
[1, 19852] loss_train: 0.005685, loss_test: 0.005554
time: 0.2490551471710205
time: 2.267507314682007
[1, 19853] loss_train: 0.003672, loss_test: 0.005553
time: 0.24605441093444824
time: 2.282510757446289
[1, 19854] loss_train: 0.004686, loss_test: 0.005553
time: 0.24205374717712402
time: 2.2905142307281494
[1, 19855] loss_train: 0.001309, loss_test: 0.005557
time: 0.24505376815795898
time: 2.5286977291107178
[1, 19856] loss_train: 0.003131, loss_test: 0.005564
time: 0.3400752544403076
time: 2.5119261741638184
[1, 19857] loss_train: 0.005474, loss_test: 0.005569
time: 0.25005507469177246
time: 2.2985146045684814
[1, 19858] loss_train: 0.006400, loss_test: 0.005567
time: 0.24605512619018555
time: 2.4015369415283203
[1, 19859] loss_train: 0.002894, loss_test: 0.005568
time: 0.2510559558868408
time: 2.288511276245117
[1, 19860] loss_train: 0.007390, loss_test: 0.005571
time: 0.2630605697631836
time: 2.284511089324951
[1, 19861] loss_train: 0.008357, loss_test: 0.005572
time: 0.2450549602508545
time: 2.2435014247894287
[1, 19862] loss_train: 0.018494, loss_test: 0.005566
time: 0.2450542449951172
time: 2.3495254516601562
[1, 19863] loss_train: 0.007434, loss_test: 0.005567
time: 0.2450547218322754
time: 2.2615158557891846
[1, 19864] loss_train: 0.006492, loss_test: 0.005574
time: 0.26805830001831055
time: 2.244501829147339
[1, 19865] loss_train: 0.007617, loss_test: 0.005586
time: 0.24505400657653809
time: 2.2615063190460205
[1, 19866] loss_train: 0.009654, loss_test: 0.005600
time: 0.24505400657653809
time: 2.2635068893432617
[1, 19867] loss_train: 0.003565, loss_test: 0.005600
time: 0.24805521965026855
time: 2.271507978439331
[1, 19868] loss_train: 0.008693, loss_test: 0.005593
time: 0.24405455589294434
time: 2.259503126144409
[1, 19869] loss_train: 0.013877, loss_test: 0.005584
time: 0.2450549602508545
time: 2.269508123397827
[1, 19870] loss_train: 0.009375, loss_test: 0.005568
time: 0.25705671310424805
time: 2.2745118141174316
[1, 19871] loss_train: 0.007834, loss_test: 0.005554
time: 0.2490556240081787
time: 2.289513349533081
[1, 19872] loss_train: 0.003714, loss_test: 0.005540
time: 0.24305415153503418
time: 2.272507667541504
[1, 19873] loss_train: 0.008623, loss_test: 0.005535
time: 0.2450549602508545
time: 2.2385003566741943
[1, 19874] loss_train: 0.000762, loss_test: 0.005537
time: 0.24505400657653809
time: 2.255505084991455
[1, 19875] loss_train: 0.006965, loss_test: 0.005546
time: 0.24405407905578613
time: 2.2825114727020264
[1, 19876] loss_train: 0.003034, loss_test: 0.005561
time: 0.24605464935302734
time: 2.2625062465667725
[1, 19877] loss_train: 0.005307, loss_test: 0.005580
time: 0.24505400657653809
time: 2.2525036334991455
[1, 19878] loss_train: 0.005325, loss_test: 0.005603
time: 0.2490549087524414
time: 2.256505250930786
[1, 19879] loss_train: 0.007689, loss_test: 0.005618
time: 0.24505352973937988
time: 2.263507127761841
[1, 19880] loss_train: 0.000805, loss_test: 0.005637
time: 0.25705671310424805
time: 2.2775187492370605
[1, 19881] loss_train: 0.007129, loss_test: 0.005629
time: 0.24505400657653809
time: 2.2635068893432617
[1, 19882] loss_train: 0.003899, loss_test: 0.005619
time: 0.24605393409729004
time: 2.299020290374756
[1, 19883] loss_train: 0.003184, loss_test: 0.005611
time: 0.24405455589294434
time: 2.2935128211975098
[1, 19884] loss_train: 0.009143, loss_test: 0.005599
time: 0.2490556240081787
time: 2.259506940841675
[1, 19885] loss_train: 0.001840, loss_test: 0.005592
time: 0.24605464935302734
time: 2.2655067443847656
[1, 19886] loss_train: 0.002046, loss_test: 0.005587
time: 0.2490553855895996
time: 2.259575128555298
[1, 19887] loss_train: 0.011150, loss_test: 0.005582
time: 0.24305391311645508
time: 2.234499931335449
[1, 19888] loss_train: 0.005164, loss_test: 0.005580
time: 0.33520960807800293
time: 2.2575063705444336
[1, 19889] loss_train: 0.005349, loss_test: 0.005579
time: 0.2450549602508545
time: 2.2475028038024902
[1, 19890] loss_train: 0.005729, loss_test: 0.005583
time: 0.2580571174621582
time: 2.294512987136841
[1, 19891] loss_train: 0.004610, loss_test: 0.005589
time: 0.24405360221862793
time: 2.2765092849731445
[1, 19892] loss_train: 0.002336, loss_test: 0.005597
time: 0.25005555152893066
time: 2.2745089530944824
[1, 19893] loss_train: 0.010173, loss_test: 0.005594
time: 0.24405431747436523
time: 2.2665061950683594
[1, 19894] loss_train: 0.002170, loss_test: 0.005595
time: 0.24205327033996582
time: 2.2304985523223877
[1, 19895] loss_train: 0.005405, loss_test: 0.005588
time: 0.24305391311645508
time: 2.2505037784576416
[1, 19896] loss_train: 0.007126, loss_test: 0.005581
time: 0.2510561943054199
time: 2.24550199508667
[1, 19897] loss_train: 0.008296, loss_test: 0.005572
time: 0.24505376815795898
time: 2.2765097618103027
[1, 19898] loss_train: 0.006778, loss_test: 0.005560
time: 0.24405360221862793
time: 2.2475032806396484
[1, 19899] loss_train: 0.002537, loss_test: 0.005553
time: 0.24405360221862793
time: 2.2745091915130615
[1, 19900] loss_train: 0.005255, loss_test: 0.005547
time: 0.2690601348876953
time: 2.261505365371704
[1, 19901] loss_train: 0.004571, loss_test: 0.005541
time: 0.24405384063720703
time: 2.256505012512207
[1, 19902] loss_train: 0.008577, loss_test: 0.005535
time: 0.2450544834136963
time: 2.255505084991455
[1, 19903] loss_train: 0.002876, loss_test: 0.005533
time: 0.24605345726013184
time: 2.2755091190338135
[1, 19904] loss_train: 0.003122, loss_test: 0.005533
time: 0.2450544834136963
time: 2.2755095958709717
[1, 19905] loss_train: 0.004758, loss_test: 0.005532
time: 0.24505352973937988
time: 2.2565054893493652
[1, 19906] loss_train: 0.005626, loss_test: 0.005532
time: 0.24405503273010254
time: 2.274507761001587
[1, 19907] loss_train: 0.006931, loss_test: 0.005533
time: 0.24505615234375
time: 2.2935128211975098
[1, 19908] loss_train: 0.001560, loss_test: 0.005532
time: 0.24305343627929688
time: 2.2525033950805664
[1, 19909] loss_train: 0.004935, loss_test: 0.005531
time: 0.24305391311645508
time: 2.2585055828094482
[1, 19910] loss_train: 0.014077, loss_test: 0.005529
time: 0.25905799865722656
time: 2.267507314682007
[1, 19911] loss_train: 0.002957, loss_test: 0.005528
time: 0.2450547218322754
time: 2.2435038089752197
[1, 19912] loss_train: 0.010981, loss_test: 0.005528
time: 0.24305319786071777
time: 2.2715084552764893
[1, 19913] loss_train: 0.016073, loss_test: 0.005527
time: 0.24405479431152344
time: 2.2815098762512207
[1, 19914] loss_train: 0.004576, loss_test: 0.005530
time: 0.25005602836608887
time: 2.2795090675354004
[1, 19915] loss_train: 0.000971, loss_test: 0.005536
time: 0.24605536460876465
time: 2.2645058631896973
[1, 19916] loss_train: 0.004129, loss_test: 0.005543
time: 0.24405479431152344
time: 2.249502658843994
[1, 19917] loss_train: 0.009936, loss_test: 0.005543
time: 0.24605441093444824
time: 2.268507719039917
[1, 19918] loss_train: 0.008773, loss_test: 0.005544
time: 0.24605488777160645
time: 2.260507345199585
[1, 19919] loss_train: 0.008734, loss_test: 0.005543
time: 0.24605393409729004
time: 2.279510259628296
[1, 19920] loss_train: 0.003221, loss_test: 0.005543
time: 0.2630589008331299
time: 2.26950740814209
[1, 19921] loss_train: 0.006737, loss_test: 0.005543
time: 0.2560563087463379
time: 2.2605061531066895
[1, 19922] loss_train: 0.006937, loss_test: 0.005542
time: 0.24805498123168945
time: 2.3315210342407227
[1, 19923] loss_train: 0.005219, loss_test: 0.005541
time: 0.24605441093444824
time: 2.263516664505005
[1, 19924] loss_train: 0.005535, loss_test: 0.005539
time: 0.2450551986694336
time: 2.248504400253296
[1, 19925] loss_train: 0.004315, loss_test: 0.005537
time: 0.24505376815795898
time: 2.2375009059906006
[1, 19926] loss_train: 0.009364, loss_test: 0.005537
time: 0.2450542449951172
time: 2.2485029697418213
[1, 19927] loss_train: 0.011548, loss_test: 0.005537
time: 0.2470543384552002
time: 2.2635068893432617
[1, 19928] loss_train: 0.009426, loss_test: 0.005538
time: 0.24405407905578613
time: 2.258505344390869
[1, 19929] loss_train: 0.002196, loss_test: 0.005542
time: 0.2450571060180664
time: 2.261505126953125
[1, 19930] loss_train: 0.003729, loss_test: 0.005546
time: 0.2580573558807373
time: 2.2775094509124756
[1, 19931] loss_train: 0.010849, loss_test: 0.005547
time: 0.24205231666564941
time: 2.254505157470703
[1, 19932] loss_train: 0.006506, loss_test: 0.005546
time: 0.24505400657653809
time: 2.254504442214966
[1, 19933] loss_train: 0.005412, loss_test: 0.005547
time: 0.24405384063720703
time: 2.243504285812378
[1, 19934] loss_train: 0.005629, loss_test: 0.005550
time: 0.24305415153503418
time: 2.2395009994506836
[1, 19935] loss_train: 0.005403, loss_test: 0.005555
time: 0.24205279350280762
time: 2.2745094299316406
[1, 19936] loss_train: 0.008092, loss_test: 0.005559
time: 0.2490556240081787
time: 2.2455015182495117
[1, 19937] loss_train: 0.004626, loss_test: 0.005563
time: 0.24405384063720703
time: 2.271510601043701
[1, 19938] loss_train: 0.015587, loss_test: 0.005560
time: 0.24605464935302734
time: 2.2505033016204834
[1, 19939] loss_train: 0.007806, loss_test: 0.005557
time: 0.24505400657653809
time: 2.2765095233917236
[1, 19940] loss_train: 0.004036, loss_test: 0.005554
time: 0.2600579261779785
time: 2.256504535675049
[1, 19941] loss_train: 0.007840, loss_test: 0.005550
time: 0.24405336380004883
time: 2.267507553100586
[1, 19942] loss_train: 0.006724, loss_test: 0.005545
time: 0.24405455589294434
time: 2.2655062675476074
[1, 19943] loss_train: 0.000855, loss_test: 0.005542
time: 0.2490549087524414
time: 2.253504514694214
[1, 19944] loss_train: 0.008097, loss_test: 0.005541
time: 0.24405455589294434
time: 2.2555038928985596
[1, 19945] loss_train: 0.001623, loss_test: 0.005543
time: 0.2470545768737793
time: 2.2485032081604004
[1, 19946] loss_train: 0.003669, loss_test: 0.005546
time: 0.24405384063720703
time: 2.2735111713409424
[1, 19947] loss_train: 0.011540, loss_test: 0.005548
time: 0.2450547218322754
time: 2.2445015907287598
[1, 19948] loss_train: 0.008028, loss_test: 0.005543
time: 0.24605441093444824
time: 2.254504680633545
[1, 19949] loss_train: 0.007014, loss_test: 0.005536
time: 0.24405455589294434
time: 2.2785093784332275
[1, 19950] loss_train: 0.004610, loss_test: 0.005533
time: 0.2580568790435791
time: 2.2495033740997314
[1, 19951] loss_train: 0.008921, loss_test: 0.005531
time: 0.24405479431152344
time: 2.2655065059661865
[1, 19952] loss_train: 0.014900, loss_test: 0.005529
time: 0.2510561943054199
time: 2.2665066719055176
[1, 19953] loss_train: 0.006687, loss_test: 0.005526
time: 0.24405455589294434
time: 2.272507905960083
[1, 19954] loss_train: 0.004537, loss_test: 0.005525
time: 0.2470550537109375
time: 2.2665069103240967
[1, 19955] loss_train: 0.010107, loss_test: 0.005525
time: 0.24405431747436523
time: 2.2835097312927246
[1, 19956] loss_train: 0.011824, loss_test: 0.005523
time: 0.24405455589294434
time: 2.2725090980529785
[1, 19957] loss_train: 0.002489, loss_test: 0.005523
time: 0.24605369567871094
time: 2.268507957458496
[1, 19958] loss_train: 0.005427, loss_test: 0.005523
time: 0.24405455589294434
time: 2.255035638809204
[1, 19959] loss_train: 0.008998, loss_test: 0.005526
time: 0.24305438995361328
time: 2.259504795074463
[1, 19960] loss_train: 0.003108, loss_test: 0.005530
time: 0.26405835151672363
time: 2.272516965866089
[1, 19961] loss_train: 0.009773, loss_test: 0.005532
time: 0.24806785583496094
time: 2.292515277862549
[1, 19962] loss_train: 0.001539, loss_test: 0.005535
time: 0.2470545768737793
time: 2.2525031566619873
[1, 19963] loss_train: 0.002940, loss_test: 0.005539
time: 0.24405431747436523
time: 2.2635061740875244
[1, 19964] loss_train: 0.002456, loss_test: 0.005544
time: 0.2470550537109375
time: 2.3085203170776367
[1, 19965] loss_train: 0.003284, loss_test: 0.005549
time: 0.25205564498901367
time: 2.3125176429748535
[1, 19966] loss_train: 0.009408, loss_test: 0.005552
time: 0.2490549087524414
time: 2.2645082473754883
[1, 19967] loss_train: 0.003051, loss_test: 0.005552
time: 0.24505329132080078
time: 2.267507314682007
[1, 19968] loss_train: 0.001320, loss_test: 0.005558
time: 0.24605393409729004
time: 2.247006893157959
[1, 19969] loss_train: 0.001717, loss_test: 0.005567
time: 0.24605417251586914
time: 2.228123426437378
[1, 19970] loss_train: 0.005762, loss_test: 0.005572
time: 0.25905776023864746
time: 2.2685070037841797
[1, 19971] loss_train: 0.006259, loss_test: 0.005576
time: 0.24805521965026855
time: 2.2535037994384766
[1, 19972] loss_train: 0.004136, loss_test: 0.005580
time: 0.2450547218322754
time: 2.2405009269714355
[1, 19973] loss_train: 0.004847, loss_test: 0.005585
time: 0.2435588836669922
time: 2.256504774093628
[1, 19974] loss_train: 0.007822, loss_test: 0.005586
time: 0.24605393409729004
time: 2.2405014038085938
[1, 19975] loss_train: 0.012831, loss_test: 0.005576
time: 0.2510552406311035
time: 2.269507646560669
[1, 19976] loss_train: 0.003754, loss_test: 0.005566
time: 0.2470567226409912
time: 2.256505012512207
[1, 19977] loss_train: 0.005313, loss_test: 0.005557
time: 0.24405431747436523
time: 2.233499526977539
[1, 19978] loss_train: 0.006219, loss_test: 0.005548
time: 0.24505400657653809
time: 2.280510663986206
[1, 19979] loss_train: 0.007985, loss_test: 0.005542
time: 0.24505400657653809
time: 2.2515056133270264
[1, 19980] loss_train: 0.003956, loss_test: 0.005539
time: 0.280062198638916
time: 2.2575042247772217
[1, 19981] loss_train: 0.005805, loss_test: 0.005537
time: 0.2450551986694336
time: 2.2750117778778076
[1, 19982] loss_train: 0.011334, loss_test: 0.005536
time: 0.24805521965026855
time: 2.2655069828033447
[1, 19983] loss_train: 0.008879, loss_test: 0.005536
time: 0.24405360221862793
time: 2.270507574081421
[1, 19984] loss_train: 0.006993, loss_test: 0.005536
time: 0.24605488777160645
time: 2.267507314682007
[1, 19985] loss_train: 0.004637, loss_test: 0.005536
time: 0.2450542449951172
time: 2.247502088546753
[1, 19986] loss_train: 0.007756, loss_test: 0.005534
time: 0.24805474281311035
time: 2.272010564804077
[1, 19987] loss_train: 0.002228, loss_test: 0.005531
time: 0.2450547218322754
time: 2.254507064819336
[1, 19988] loss_train: 0.005537, loss_test: 0.005530
time: 0.2450542449951172
time: 2.2735087871551514
[1, 19989] loss_train: 0.007201, loss_test: 0.005529
time: 0.24405407905578613
time: 2.255504608154297
[1, 19990] loss_train: 0.003726, loss_test: 0.005528
time: 0.25705671310424805
time: 2.26051664352417
[1, 19991] loss_train: 0.005946, loss_test: 0.005528
time: 0.24405384063720703
time: 2.265507459640503
[1, 19992] loss_train: 0.001223, loss_test: 0.005529
time: 0.24405360221862793
time: 2.2625179290771484
[1, 19993] loss_train: 0.009220, loss_test: 0.005530
time: 0.2490546703338623
time: 2.263822078704834
[1, 19994] loss_train: 0.005112, loss_test: 0.005531
time: 0.24405407905578613
time: 2.2750120162963867
[1, 19995] loss_train: 0.002875, loss_test: 0.005534
time: 0.24405384063720703
time: 2.247502565383911
[1, 19996] loss_train: 0.011997, loss_test: 0.005535
time: 0.2470550537109375
time: 2.267507791519165
[1, 19997] loss_train: 0.006857, loss_test: 0.005534
time: 0.24505376815795898
time: 2.258505344390869
[1, 19998] loss_train: 0.014438, loss_test: 0.005530
time: 0.24455952644348145
time: 2.2946298122406006
[1, 19999] loss_train: 0.004036, loss_test: 0.005528
time: 0.24305319786071777
time: 2.261505126953125
[1, 20000] loss_train: 0.005213, loss_test: 0.005527
time: 0.2700612545013428
time: 2.288511037826538
[1, 20001] loss_train: 0.010056, loss_test: 0.005526
time: 0.2470555305480957
time: 2.271510124206543
[1, 20002] loss_train: 0.009008, loss_test: 0.005526
time: 0.24405384063720703
time: 2.255504846572876
[1, 20003] loss_train: 0.011391, loss_test: 0.005529
time: 0.2470552921295166
time: 2.2775089740753174
[1, 20004] loss_train: 0.002878, loss_test: 0.005535
time: 0.25005578994750977
time: 2.2490148544311523
[1, 20005] loss_train: 0.005070, loss_test: 0.005533
time: 0.24805521965026855
time: 2.2635059356689453
[1, 20006] loss_train: 0.005759, loss_test: 0.005532
time: 0.24405407905578613
time: 2.2625062465667725
[1, 20007] loss_train: 0.008867, loss_test: 0.005529
time: 0.2530558109283447
time: 2.2635066509246826
[1, 20008] loss_train: 0.004786, loss_test: 0.005525
time: 0.24605488777160645
time: 2.2555041313171387
[1, 20009] loss_train: 0.003701, loss_test: 0.005523
time: 0.25005555152893066
time: 2.285510778427124
[1, 20010] loss_train: 0.001333, loss_test: 0.005528
time: 0.25705671310424805
time: 2.256505250930786
[1, 20011] loss_train: 0.007697, loss_test: 0.005535
time: 0.25005578994750977
time: 2.270507574081421
[1, 20012] loss_train: 0.012043, loss_test: 0.005556
time: 0.25305604934692383
time: 2.282513380050659
[1, 20013] loss_train: 0.012850, loss_test: 0.005577
time: 0.24405407905578613
time: 2.2495033740997314
[1, 20014] loss_train: 0.008183, loss_test: 0.005594
time: 0.2450549602508545
time: 2.2505030632019043
[1, 20015] loss_train: 0.004174, loss_test: 0.005610
time: 0.24405455589294434
time: 2.2230002880096436
[1, 20016] loss_train: 0.005744, loss_test: 0.005623
time: 0.24405479431152344
time: 2.2775120735168457
[1, 20017] loss_train: 0.008474, loss_test: 0.005629
time: 0.24605536460876465
time: 2.2685065269470215
[1, 20018] loss_train: 0.002204, loss_test: 0.005638
time: 0.2490551471710205
time: 2.2485029697418213
[1, 20019] loss_train: 0.004259, loss_test: 0.005645
time: 0.24405360221862793
time: 2.267507553100586
[1, 20020] loss_train: 0.007209, loss_test: 0.005647
time: 0.2580580711364746
time: 2.262507200241089
[1, 20021] loss_train: 0.012942, loss_test: 0.005623
time: 0.24405646324157715
time: 2.23349928855896
[1, 20022] loss_train: 0.002500, loss_test: 0.005605
time: 0.24494671821594238
time: 2.2395036220550537
[1, 20023] loss_train: 0.008291, loss_test: 0.005581
time: 0.24505400657653809
time: 2.267507553100586
[1, 20024] loss_train: 0.004805, loss_test: 0.005565
time: 0.24506735801696777
time: 2.273507833480835
[1, 20025] loss_train: 0.006934, loss_test: 0.005558
time: 0.2470548152923584
time: 2.270508050918579
[1, 20026] loss_train: 0.011921, loss_test: 0.005562
time: 0.24305415153503418
time: 2.272510528564453
[1, 20027] loss_train: 0.006165, loss_test: 0.005578
time: 0.24405384063720703
time: 2.269507884979248
[1, 20028] loss_train: 0.015811, loss_test: 0.005620
time: 0.24405264854431152
time: 2.2074942588806152
[1, 20029] loss_train: 0.007126, loss_test: 0.005660
time: 0.25005531311035156
time: 2.252504348754883
[1, 20030] loss_train: 0.011398, loss_test: 0.005699
time: 0.25714612007141113
time: 2.2805213928222656
[1, 20031] loss_train: 0.007394, loss_test: 0.005723
time: 0.24605393409729004
time: 2.255505323410034
[1, 20032] loss_train: 0.009489, loss_test: 0.005728
time: 0.24405336380004883
time: 2.3105173110961914
[1, 20033] loss_train: 0.005850, loss_test: 0.005684
time: 0.24205350875854492
time: 2.275508165359497
[1, 20034] loss_train: 0.002516, loss_test: 0.005641
time: 0.24405455589294434
time: 2.2735092639923096
[1, 20035] loss_train: 0.000957, loss_test: 0.005578
time: 0.24405407905578613
time: 2.2805097103118896
[1, 20036] loss_train: 0.002873, loss_test: 0.005543
time: 0.2450542449951172
time: 2.2605061531066895
[1, 20037] loss_train: 0.004826, loss_test: 0.005528
time: 0.2450547218322754
time: 2.243352174758911
[1, 20038] loss_train: 0.006398, loss_test: 0.005533
time: 0.24405431747436523
time: 2.2775089740753174
[1, 20039] loss_train: 0.002249, loss_test: 0.005552
time: 0.2470550537109375
time: 2.273508071899414
[1, 20040] loss_train: 0.006521, loss_test: 0.005573
time: 0.2580575942993164
time: 2.281510353088379
[1, 20041] loss_train: 0.004439, loss_test: 0.005594
time: 0.2450551986694336
time: 2.2685065269470215
[1, 20042] loss_train: 0.010596, loss_test: 0.005605
time: 0.24405407905578613
time: 2.2915124893188477
[1, 20043] loss_train: 0.010018, loss_test: 0.005606
time: 0.2450542449951172
time: 2.257505416870117
[1, 20044] loss_train: 0.008447, loss_test: 0.005607
time: 0.2470552921295166
time: 2.3385229110717773
[1, 20045] loss_train: 0.010225, loss_test: 0.005607
time: 0.24805450439453125
time: 2.2715084552764893
[1, 20046] loss_train: 0.003516, loss_test: 0.005608
time: 0.25205564498901367
time: 2.2765095233917236
[1, 20047] loss_train: 0.008957, loss_test: 0.005604
time: 0.24505400657653809
time: 2.2855119705200195
[1, 20048] loss_train: 0.000960, loss_test: 0.005601
time: 0.24305367469787598
time: 2.2725205421447754
[1, 20049] loss_train: 0.000708, loss_test: 0.005600
time: 0.24405407905578613
time: 2.3140347003936768
[1, 20050] loss_train: 0.010140, loss_test: 0.005583
time: 0.2560575008392334
time: 2.2885117530822754
[1, 20051] loss_train: 0.008978, loss_test: 0.005566
time: 0.24405336380004883
time: 2.2680211067199707
[1, 20052] loss_train: 0.008713, loss_test: 0.005550
time: 0.24405384063720703
time: 2.2885115146636963
[1, 20053] loss_train: 0.009828, loss_test: 0.005539
time: 0.24605464935302734
time: 2.26850962638855
[1, 20054] loss_train: 0.005982, loss_test: 0.005532
time: 0.24405503273010254
time: 2.245501756668091
[1, 20055] loss_train: 0.013093, loss_test: 0.005524
time: 0.24405431747436523
time: 2.2555036544799805
[1, 20056] loss_train: 0.002313, loss_test: 0.005526
time: 0.24405431747436523
time: 2.2675070762634277
[1, 20057] loss_train: 0.005465, loss_test: 0.005532
time: 0.24605512619018555
time: 2.2715208530426025
[1, 20058] loss_train: 0.003895, loss_test: 0.005541
time: 0.24405407905578613
time: 2.274508237838745
[1, 20059] loss_train: 0.004015, loss_test: 0.005542
time: 0.2450547218322754
time: 2.2865121364593506
[1, 20060] loss_train: 0.008916, loss_test: 0.005535
time: 0.2670588493347168
time: 2.296513795852661
[1, 20061] loss_train: 0.003484, loss_test: 0.005529
time: 0.24405479431152344
time: 2.2805097103118896
[1, 20062] loss_train: 0.006189, loss_test: 0.005523
time: 0.24405360221862793
time: 2.2840194702148438
[1, 20063] loss_train: 0.006736, loss_test: 0.005518
time: 0.24805450439453125
time: 2.2845113277435303
[1, 20064] loss_train: 0.005595, loss_test: 0.005516
time: 0.24405360221862793
time: 2.257513999938965
[1, 20065] loss_train: 0.003435, loss_test: 0.005518
time: 0.25005602836608887
time: 2.2655067443847656
[1, 20066] loss_train: 0.002962, loss_test: 0.005522
time: 0.25205516815185547
time: 2.229499578475952
[1, 20067] loss_train: 0.008686, loss_test: 0.005526
time: 0.2520565986633301
time: 2.2665066719055176
[1, 20068] loss_train: 0.010286, loss_test: 0.005530
time: 0.24805450439453125
time: 2.2475030422210693
[1, 20069] loss_train: 0.011805, loss_test: 0.005534
time: 0.24805474281311035
time: 2.255505084991455
[1, 20070] loss_train: 0.006144, loss_test: 0.005534
time: 0.2560563087463379
time: 2.2855122089385986
[1, 20071] loss_train: 0.008116, loss_test: 0.005533
time: 0.24505400657653809
time: 2.254504919052124
[1, 20072] loss_train: 0.004243, loss_test: 0.005532
time: 0.2450542449951172
time: 2.2675094604492188
[1, 20073] loss_train: 0.005839, loss_test: 0.005533
time: 0.24405431747436523
time: 2.2655065059661865
[1, 20074] loss_train: 0.001659, loss_test: 0.005535
time: 0.2470555305480957
time: 2.2515029907226562
[1, 20075] loss_train: 0.003131, loss_test: 0.005538
time: 0.2450549602508545
time: 2.2305023670196533
[1, 20076] loss_train: 0.001040, loss_test: 0.005542
time: 0.24405431747436523
time: 2.2605063915252686
[1, 20077] loss_train: 0.003587, loss_test: 0.005547
time: 0.24505376815795898
time: 2.232499122619629
[1, 20078] loss_train: 0.008835, loss_test: 0.005552
time: 0.24405431747436523
time: 2.248528003692627
[1, 20079] loss_train: 0.010508, loss_test: 0.005557
time: 0.2510561943054199
time: 2.2505030632019043
[1, 20080] loss_train: 0.009857, loss_test: 0.005561
time: 0.2580578327178955
time: 2.244006633758545
[1, 20081] loss_train: 0.006524, loss_test: 0.005564
time: 0.24805474281311035
time: 2.2505042552948
[1, 20082] loss_train: 0.001520, loss_test: 0.005566
time: 0.25005483627319336
time: 2.278510093688965
[1, 20083] loss_train: 0.010033, loss_test: 0.005564
time: 0.2450547218322754
time: 2.2775089740753174
[1, 20084] loss_train: 0.002169, loss_test: 0.005562
time: 0.24505400657653809
time: 2.241395950317383
[1, 20085] loss_train: 0.004671, loss_test: 0.005560
time: 0.24405384063720703
time: 2.252507448196411
[1, 20086] loss_train: 0.004800, loss_test: 0.005555
time: 0.2490553855895996
time: 2.2635059356689453
[1, 20087] loss_train: 0.008423, loss_test: 0.005550
time: 0.2450542449951172
time: 2.255504846572876
[1, 20088] loss_train: 0.001014, loss_test: 0.005546
time: 0.24405407905578613
time: 2.2985141277313232
[1, 20089] loss_train: 0.002513, loss_test: 0.005543
time: 0.2470548152923584
time: 2.26051664352417
[1, 20090] loss_train: 0.009402, loss_test: 0.005541
time: 0.25705599784851074
time: 2.2775096893310547
[1, 20091] loss_train: 0.005353, loss_test: 0.005539
time: 0.24605488777160645
time: 2.232499361038208
[1, 20092] loss_train: 0.005636, loss_test: 0.005539
time: 0.24405455589294434
time: 2.2805097103118896
[1, 20093] loss_train: 0.007524, loss_test: 0.005536
time: 0.25005483627319336
time: 2.2605056762695312
[1, 20094] loss_train: 0.000546, loss_test: 0.005535
time: 0.24305319786071777
time: 2.2745113372802734
[1, 20095] loss_train: 0.002126, loss_test: 0.005534
time: 0.2560563087463379
time: 2.318519353866577
[1, 20096] loss_train: 0.010296, loss_test: 0.005530
time: 0.24505400657653809
time: 2.2825100421905518
[1, 20097] loss_train: 0.004785, loss_test: 0.005527
time: 0.25305604934692383
time: 2.2635064125061035
[1, 20098] loss_train: 0.008087, loss_test: 0.005524
time: 0.24405431747436523
time: 2.243501663208008
[1, 20099] loss_train: 0.005574, loss_test: 0.005522
time: 0.24405384063720703
time: 2.277509927749634
[1, 20100] loss_train: 0.005727, loss_test: 0.005520
time: 0.2600581645965576
time: 2.2865102291107178
[1, 20101] loss_train: 0.001033, loss_test: 0.005518
time: 0.24405431747436523
time: 2.2825093269348145
[1, 20102] loss_train: 0.009355, loss_test: 0.005517
time: 0.24605631828308105
time: 2.2835092544555664
[1, 20103] loss_train: 0.004794, loss_test: 0.005516
time: 0.2470560073852539
time: 2.310516119003296
[1, 20104] loss_train: 0.008659, loss_test: 0.005516
time: 0.25305604934692383
time: 2.290512800216675
[1, 20105] loss_train: 0.006951, loss_test: 0.005515
time: 0.2450544834136963
time: 2.2775092124938965
[1, 20106] loss_train: 0.013479, loss_test: 0.005516
time: 0.2450542449951172
time: 2.271507740020752
[1, 20107] loss_train: 0.002414, loss_test: 0.005516
time: 0.24405479431152344
time: 2.272507429122925
[1, 20108] loss_train: 0.003247, loss_test: 0.005516
time: 0.2450549602508545
time: 2.2535040378570557
[1, 20109] loss_train: 0.004900, loss_test: 0.005516
time: 0.24405431747436523
time: 2.2615163326263428
[1, 20110] loss_train: 0.005136, loss_test: 0.005516
time: 0.26105713844299316
time: 2.271522283554077
[1, 20111] loss_train: 0.010597, loss_test: 0.005518
time: 0.2450551986694336
time: 2.224497079849243
[1, 20112] loss_train: 0.006343, loss_test: 0.005520
time: 0.2450542449951172
time: 2.275508165359497
[1, 20113] loss_train: 0.008212, loss_test: 0.005523
time: 0.2450542449951172
time: 2.2590107917785645
[1, 20114] loss_train: 0.007003, loss_test: 0.005526
time: 0.24805498123168945
time: 2.2845137119293213
[1, 20115] loss_train: 0.001570, loss_test: 0.005528
time: 0.24405384063720703
time: 2.254504442214966
[1, 20116] loss_train: 0.007019, loss_test: 0.005529
time: 0.2490549087524414
time: 2.2635068893432617
[1, 20117] loss_train: 0.005649, loss_test: 0.005530
time: 0.24505400657653809
time: 2.2715108394622803
[1, 20118] loss_train: 0.002281, loss_test: 0.005530
time: 0.24405407905578613
time: 2.2830145359039307
[1, 20119] loss_train: 0.006492, loss_test: 0.005530
time: 0.24505400657653809
time: 2.2715084552764893
[1, 20120] loss_train: 0.002868, loss_test: 0.005531
time: 0.25705718994140625
time: 2.2745203971862793
[1, 20121] loss_train: 0.006519, loss_test: 0.005533
time: 0.2470548152923584
time: 2.244501829147339
[1, 20122] loss_train: 0.005500, loss_test: 0.005534
time: 0.24405455589294434
time: 2.281013250350952
[1, 20123] loss_train: 0.002345, loss_test: 0.005535
time: 0.24305343627929688
time: 2.2355005741119385
[1, 20124] loss_train: 0.004976, loss_test: 0.005538
time: 0.24605417251586914
time: 2.2625062465667725
[1, 20125] loss_train: 0.007697, loss_test: 0.005539
time: 0.2458629608154297
time: 2.2735092639923096
[1, 20126] loss_train: 0.003634, loss_test: 0.005540
time: 0.2450549602508545
time: 2.2945122718811035
[1, 20127] loss_train: 0.001065, loss_test: 0.005541
time: 0.24605488777160645
time: 2.2545039653778076
[1, 20128] loss_train: 0.002414, loss_test: 0.005543
time: 0.24605441093444824
time: 2.277510166168213
[1, 20129] loss_train: 0.009371, loss_test: 0.005544
time: 0.24105429649353027
time: 2.2815101146698
[1, 20130] loss_train: 0.010414, loss_test: 0.005541
time: 0.25705695152282715
time: 2.2505030632019043
[1, 20131] loss_train: 0.005526, loss_test: 0.005542
time: 0.2450544834136963
time: 2.261505365371704
[1, 20132] loss_train: 0.005019, loss_test: 0.005541
time: 0.2490558624267578
time: 2.252504348754883
[1, 20133] loss_train: 0.002046, loss_test: 0.005543
time: 0.24605441093444824
time: 2.2595155239105225
[1, 20134] loss_train: 0.007367, loss_test: 0.005544
time: 0.24405384063720703
time: 2.2505176067352295
[1, 20135] loss_train: 0.006464, loss_test: 0.005542
time: 0.24605464935302734
time: 2.2294983863830566
[1, 20136] loss_train: 0.006600, loss_test: 0.005540
time: 0.24405407905578613
time: 2.272371768951416
[1, 20137] loss_train: 0.009742, loss_test: 0.005538
time: 0.24605512619018555
time: 2.272507905960083
[1, 20138] loss_train: 0.005047, loss_test: 0.005537
time: 0.2450547218322754
time: 2.2510085105895996
[1, 20139] loss_train: 0.004226, loss_test: 0.005535
time: 0.2490556240081787
time: 2.237499952316284
[1, 20140] loss_train: 0.009826, loss_test: 0.005534
time: 0.25905728340148926
time: 2.279510259628296
[1, 20141] loss_train: 0.007424, loss_test: 0.005533
time: 0.24605536460876465
time: 2.258504867553711
[1, 20142] loss_train: 0.001598, loss_test: 0.005534
time: 0.2450544834136963
time: 2.2775089740753174
[1, 20143] loss_train: 0.007182, loss_test: 0.005534
time: 0.2490551471710205
time: 2.2446634769439697
[1, 20144] loss_train: 0.007724, loss_test: 0.005535
time: 0.24405431747436523
time: 2.273508071899414
[1, 20145] loss_train: 0.002997, loss_test: 0.005538
time: 0.24805617332458496
time: 2.261094093322754
[1, 20146] loss_train: 0.004148, loss_test: 0.005541
time: 0.2450544834136963
time: 2.247502088546753
[1, 20147] loss_train: 0.013788, loss_test: 0.005539
time: 0.24805498123168945
time: 2.2635066509246826
[1, 20148] loss_train: 0.006452, loss_test: 0.005536
time: 0.24405360221862793
time: 2.2435123920440674
[1, 20149] loss_train: 0.005129, loss_test: 0.005534
time: 0.2490549087524414
time: 2.2645068168640137
[1, 20150] loss_train: 0.002147, loss_test: 0.005533
time: 0.26205873489379883
time: 2.2625060081481934
[1, 20151] loss_train: 0.009201, loss_test: 0.005531
time: 0.24805521965026855
time: 2.2334988117218018
[1, 20152] loss_train: 0.010462, loss_test: 0.005529
time: 0.24305391311645508
time: 2.244504451751709
[1, 20153] loss_train: 0.007819, loss_test: 0.005528
time: 0.24805474281311035
time: 2.2875146865844727
[1, 20154] loss_train: 0.002798, loss_test: 0.005526
time: 0.24305415153503418
time: 2.2855112552642822
[1, 20155] loss_train: 0.007084, loss_test: 0.005527
time: 0.24405384063720703
time: 2.26950740814209
[1, 20156] loss_train: 0.009837, loss_test: 0.005531
time: 0.24305391311645508
time: 2.2505228519439697
[1, 20157] loss_train: 0.012779, loss_test: 0.005537
time: 0.2490556240081787
time: 2.2655065059661865
[1, 20158] loss_train: 0.004213, loss_test: 0.005543
time: 0.2450547218322754
time: 2.2785096168518066
[1, 20159] loss_train: 0.005362, loss_test: 0.005547
time: 0.24405360221862793
time: 2.2725088596343994
[1, 20160] loss_train: 0.011330, loss_test: 0.005549
time: 0.25705671310424805
time: 2.2840163707733154
[1, 20161] loss_train: 0.005535, loss_test: 0.005549
time: 0.2450542449951172
time: 2.2645065784454346
[1, 20162] loss_train: 0.004388, loss_test: 0.005549
time: 0.24405407905578613
time: 2.244502305984497
[1, 20163] loss_train: 0.015133, loss_test: 0.005549
time: 0.24505400657653809
time: 2.2755091190338135
[1, 20164] loss_train: 0.012625, loss_test: 0.005549
time: 0.24605417251586914
time: 2.2650113105773926
[1, 20165] loss_train: 0.005232, loss_test: 0.005550
time: 0.2450549602508545
time: 2.2885117530822754
[1, 20166] loss_train: 0.010692, loss_test: 0.005550
time: 0.24505376815795898
time: 2.2695116996765137
[1, 20167] loss_train: 0.007967, loss_test: 0.005550
time: 0.2450544834136963
time: 2.257504463195801
[1, 20168] loss_train: 0.004978, loss_test: 0.005547
time: 0.25005602836608887
time: 2.2635183334350586
[1, 20169] loss_train: 0.010163, loss_test: 0.005550
time: 0.24405360221862793
time: 2.293513298034668
[1, 20170] loss_train: 0.002422, loss_test: 0.005551
time: 0.2560563087463379
time: 2.2385003566741943
[1, 20171] loss_train: 0.002624, loss_test: 0.005551
time: 0.2450547218322754
time: 2.2385013103485107
[1, 20172] loss_train: 0.006465, loss_test: 0.005547
time: 0.2450547218322754
time: 2.2650182247161865
[1, 20173] loss_train: 0.003799, loss_test: 0.005542
time: 0.24405312538146973
time: 2.2515034675598145
[1, 20174] loss_train: 0.002976, loss_test: 0.005539
time: 0.24305415153503418
time: 2.2795205116271973
[1, 20175] loss_train: 0.013819, loss_test: 0.005537
time: 0.2450549602508545
time: 2.257505416870117
[1, 20176] loss_train: 0.001769, loss_test: 0.005536
time: 0.24446582794189453
time: 2.263507127761841
[1, 20177] loss_train: 0.003483, loss_test: 0.005537
time: 0.24205374717712402
time: 2.2645063400268555
[1, 20178] loss_train: 0.002656, loss_test: 0.005539
time: 0.24405384063720703
time: 2.254504919052124
[1, 20179] loss_train: 0.001384, loss_test: 0.005544
time: 0.2490553855895996
time: 2.2665066719055176
[1, 20180] loss_train: 0.005643, loss_test: 0.005551
time: 0.25705671310424805
time: 2.2725090980529785
[1, 20181] loss_train: 0.009517, loss_test: 0.005556
time: 0.24305438995361328
time: 2.256505012512207
[1, 20182] loss_train: 0.000690, loss_test: 0.005563
time: 0.24405407905578613
time: 2.2445015907287598
[1, 20183] loss_train: 0.005337, loss_test: 0.005565
time: 0.2450542449951172
time: 2.2274985313415527
[1, 20184] loss_train: 0.005877, loss_test: 0.005567
time: 0.24405384063720703
time: 2.2455060482025146
[1, 20185] loss_train: 0.007234, loss_test: 0.005566
time: 0.24505376815795898
time: 2.25750470161438
[1, 20186] loss_train: 0.017605, loss_test: 0.005548
time: 0.2450547218322754
time: 2.288513660430908
[1, 20187] loss_train: 0.001907, loss_test: 0.005537
time: 0.24405455589294434
time: 2.286510467529297
[1, 20188] loss_train: 0.010546, loss_test: 0.005528
time: 0.2461237907409668
time: 2.2875118255615234
[1, 20189] loss_train: 0.004089, loss_test: 0.005525
time: 0.24405479431152344
time: 2.2775092124938965
[1, 20190] loss_train: 0.009202, loss_test: 0.005525
time: 0.26105737686157227
time: 2.292513370513916
[1, 20191] loss_train: 0.007085, loss_test: 0.005528
time: 0.24805545806884766
time: 2.242509365081787
[1, 20192] loss_train: 0.001014, loss_test: 0.005530
time: 0.24805140495300293
time: 2.279510021209717
[1, 20193] loss_train: 0.003013, loss_test: 0.005535
time: 0.24605488777160645
time: 2.297513246536255
[1, 20194] loss_train: 0.004986, loss_test: 0.005540
time: 0.24405503273010254
time: 2.2660202980041504
[1, 20195] loss_train: 0.002715, loss_test: 0.005545
time: 0.24405431747436523
time: 2.2520053386688232
[1, 20196] loss_train: 0.003888, loss_test: 0.005551
time: 0.2450547218322754
time: 2.2865123748779297
[1, 20197] loss_train: 0.014524, loss_test: 0.005549
time: 0.24305343627929688
time: 2.2615060806274414
[1, 20198] loss_train: 0.006512, loss_test: 0.005543
time: 0.24405455589294434
time: 2.2555038928985596
[1, 20199] loss_train: 0.006158, loss_test: 0.005536
time: 0.24405431747436523
time: 2.246501922607422
[1, 20200] loss_train: 0.010118, loss_test: 0.005530
time: 0.2580578327178955
time: 2.246502637863159
[1, 20201] loss_train: 0.001694, loss_test: 0.005528
time: 0.24405407905578613
time: 2.268507719039917
[1, 20202] loss_train: 0.006683, loss_test: 0.005528
time: 0.2470545768737793
time: 2.257504940032959
[1, 20203] loss_train: 0.002510, loss_test: 0.005531
time: 0.24405455589294434
time: 2.260505437850952
[1, 20204] loss_train: 0.005645, loss_test: 0.005536
time: 0.24805450439453125
time: 2.2835118770599365
[1, 20205] loss_train: 0.004930, loss_test: 0.005544
time: 0.24405336380004883
time: 2.2885122299194336
[1, 20206] loss_train: 0.003985, loss_test: 0.005553
time: 0.24405455589294434
time: 2.2565042972564697
[1, 20207] loss_train: 0.015705, loss_test: 0.005562
time: 0.2440497875213623
time: 2.2580080032348633
[1, 20208] loss_train: 0.011986, loss_test: 0.005572
time: 0.24405360221862793
time: 2.2735090255737305
[1, 20209] loss_train: 0.002340, loss_test: 0.005571
time: 0.2450542449951172
time: 2.2635066509246826
[1, 20210] loss_train: 0.001923, loss_test: 0.005572
time: 0.2560563087463379
time: 2.2712152004241943
[1, 20211] loss_train: 0.003098, loss_test: 0.005568
time: 0.24805545806884766
time: 2.274508237838745
[1, 20212] loss_train: 0.011808, loss_test: 0.005565
time: 0.24405431747436523
time: 2.273508071899414
[1, 20213] loss_train: 0.010673, loss_test: 0.005563
time: 0.24405431747436523
time: 2.2745094299316406
[1, 20214] loss_train: 0.012840, loss_test: 0.005547
time: 0.24305343627929688
time: 2.2615368366241455
[1, 20215] loss_train: 0.007096, loss_test: 0.005536
time: 0.24402379989624023
time: 2.3065152168273926
[1, 20216] loss_train: 0.003323, loss_test: 0.005530
time: 0.24405360221862793
time: 2.261505365371704
[1, 20217] loss_train: 0.003766, loss_test: 0.005530
time: 0.2450542449951172
time: 2.2505040168762207
[1, 20218] loss_train: 0.012869, loss_test: 0.005532
time: 0.25005483627319336
time: 2.2480218410491943
[1, 20219] loss_train: 0.002608, loss_test: 0.005538
time: 0.24505400657653809
time: 2.246504783630371
[1, 20220] loss_train: 0.008669, loss_test: 0.005546
time: 0.2560570240020752
time: 2.258505344390869
[1, 20221] loss_train: 0.003958, loss_test: 0.005553
time: 0.24605417251586914
time: 2.2345001697540283
[1, 20222] loss_train: 0.006380, loss_test: 0.005559
time: 0.25205564498901367
time: 2.269510269165039
[1, 20223] loss_train: 0.002702, loss_test: 0.005565
time: 0.24305343627929688
time: 2.270508289337158
[1, 20224] loss_train: 0.003569, loss_test: 0.005564
time: 0.2450544834136963
time: 2.256504774093628
[1, 20225] loss_train: 0.003821, loss_test: 0.005564
time: 0.2560563087463379
time: 2.255506992340088
[1, 20226] loss_train: 0.009776, loss_test: 0.005560
time: 0.24305462837219238
time: 2.286510944366455
[1, 20227] loss_train: 0.002441, loss_test: 0.005559
time: 0.24805569648742676
time: 2.2905118465423584
[1, 20228] loss_train: 0.004580, loss_test: 0.005560
time: 0.24305343627929688
time: 2.267508029937744
[1, 20229] loss_train: 0.007835, loss_test: 0.005554
time: 0.25705647468566895
time: 2.244502544403076
[1, 20230] loss_train: 0.004549, loss_test: 0.005550
time: 0.2580571174621582
time: 2.273524045944214
[1, 20231] loss_train: 0.008408, loss_test: 0.005541
time: 0.2490558624267578
time: 2.246502161026001
[1, 20232] loss_train: 0.013228, loss_test: 0.005528
time: 0.24405479431152344
time: 2.2685065269470215
[1, 20233] loss_train: 0.003453, loss_test: 0.005520
time: 0.2490553855895996
time: 2.250511884689331
[1, 20234] loss_train: 0.004850, loss_test: 0.005515
time: 0.24505400657653809
time: 2.262009620666504
[1, 20235] loss_train: 0.005644, loss_test: 0.005514
time: 0.24605464935302734
time: 2.2765090465545654
[1, 20236] loss_train: 0.003337, loss_test: 0.005512
time: 0.2470545768737793
time: 2.2635185718536377
[1, 20237] loss_train: 0.006986, loss_test: 0.005512
time: 0.24505400657653809
time: 2.2855114936828613
[1, 20238] loss_train: 0.003234, loss_test: 0.005513
time: 0.24305272102355957
time: 2.2735087871551514
[1, 20239] loss_train: 0.014735, loss_test: 0.005514
time: 0.24405384063720703
time: 2.2505221366882324
[1, 20240] loss_train: 0.001169, loss_test: 0.005515
time: 0.2580564022064209
time: 2.2865118980407715
[1, 20241] loss_train: 0.006778, loss_test: 0.005515
time: 0.24405431747436523
time: 2.255504846572876
[1, 20242] loss_train: 0.005817, loss_test: 0.005517
time: 0.24505400657653809
time: 2.2745089530944824
[1, 20243] loss_train: 0.008561, loss_test: 0.005517
time: 0.24605560302734375
time: 2.2585060596466064
[1, 20244] loss_train: 0.007401, loss_test: 0.005519
time: 0.24405384063720703
time: 2.2419047355651855
[1, 20245] loss_train: 0.003730, loss_test: 0.005521
time: 0.24605607986450195
time: 2.262019634246826
[1, 20246] loss_train: 0.010107, loss_test: 0.005524
time: 0.2450544834136963
time: 2.2795095443725586
[1, 20247] loss_train: 0.008606, loss_test: 0.005528
time: 0.24405360221862793
time: 2.261505126953125
[1, 20248] loss_train: 0.002006, loss_test: 0.005533
time: 0.2440633773803711
time: 2.27150821685791
[1, 20249] loss_train: 0.001250, loss_test: 0.005535
time: 0.24405479431152344
time: 2.2875115871429443
[1, 20250] loss_train: 0.004678, loss_test: 0.005533
time: 0.2650585174560547
time: 2.243501901626587
[1, 20251] loss_train: 0.006614, loss_test: 0.005530
time: 0.2450551986694336
time: 2.3055174350738525
[1, 20252] loss_train: 0.008393, loss_test: 0.005530
time: 0.24305343627929688
time: 2.2755095958709717
[1, 20253] loss_train: 0.004278, loss_test: 0.005528
time: 0.24405431747436523
time: 2.285510778427124
[1, 20254] loss_train: 0.009424, loss_test: 0.005526
time: 0.24405479431152344
time: 2.2645061016082764
[1, 20255] loss_train: 0.006082, loss_test: 0.005526
time: 0.24305343627929688
time: 2.250180244445801
[1, 20256] loss_train: 0.013437, loss_test: 0.005523
time: 0.24305438995361328
time: 2.2825098037719727
[1, 20257] loss_train: 0.006476, loss_test: 0.005519
time: 0.24805474281311035
time: 2.265507459640503
[1, 20258] loss_train: 0.010530, loss_test: 0.005516
time: 0.2470550537109375
time: 2.2785096168518066
[1, 20259] loss_train: 0.001395, loss_test: 0.005513
time: 0.24405407905578613
time: 2.2765092849731445
[1, 20260] loss_train: 0.005183, loss_test: 0.005512
time: 0.2600576877593994
time: 2.2585055828094482
[1, 20261] loss_train: 0.010757, loss_test: 0.005512
time: 0.25005555152893066
time: 2.256505012512207
[1, 20262] loss_train: 0.005693, loss_test: 0.005514
time: 0.24805450439453125
time: 2.2735087871551514
[1, 20263] loss_train: 0.004216, loss_test: 0.005518
time: 0.24305367469787598
time: 2.269508123397827
[1, 20264] loss_train: 0.002000, loss_test: 0.005521
time: 0.25205564498901367
time: 2.2715201377868652
[1, 20265] loss_train: 0.003631, loss_test: 0.005527
time: 0.24405574798583984
time: 2.27551007270813
[1, 20266] loss_train: 0.004411, loss_test: 0.005532
time: 0.24405384063720703
time: 2.2525036334991455
[1, 20267] loss_train: 0.002586, loss_test: 0.005539
time: 0.24605417251586914
time: 2.257505178451538
[1, 20268] loss_train: 0.007033, loss_test: 0.005539
time: 0.24305391311645508
time: 2.279510021209717
[1, 20269] loss_train: 0.006802, loss_test: 0.005536
time: 0.2450544834136963
time: 2.261505126953125
[1, 20270] loss_train: 0.003713, loss_test: 0.005528
time: 0.25705742835998535
time: 2.269509792327881
[1, 20271] loss_train: 0.007057, loss_test: 0.005523
time: 0.24805569648742676
time: 2.253523588180542
[1, 20272] loss_train: 0.006300, loss_test: 0.005518
time: 0.24405431747436523
time: 2.273508310317993
[1, 20273] loss_train: 0.005198, loss_test: 0.005516
time: 0.24505400657653809
time: 2.2635066509246826
[1, 20274] loss_train: 0.016694, loss_test: 0.005514
time: 0.24205446243286133
time: 2.284510612487793
[1, 20275] loss_train: 0.008338, loss_test: 0.005513
time: 0.2450544834136963
time: 2.271507978439331
[1, 20276] loss_train: 0.008164, loss_test: 0.005514
time: 0.24405455589294434
time: 2.2655088901519775
[1, 20277] loss_train: 0.008054, loss_test: 0.005517
time: 0.2450554370880127
time: 2.255504846572876
[1, 20278] loss_train: 0.004179, loss_test: 0.005519
time: 0.25005674362182617
time: 2.2874085903167725
[1, 20279] loss_train: 0.012435, loss_test: 0.005523
time: 0.24605441093444824
time: 2.270508050918579
[1, 20280] loss_train: 0.009456, loss_test: 0.005524
time: 0.25905680656433105
time: 2.255504846572876
[1, 20281] loss_train: 0.003182, loss_test: 0.005523
time: 0.2470545768737793
time: 2.279510259628296
[1, 20282] loss_train: 0.004191, loss_test: 0.005521
time: 0.24605417251586914
time: 2.2735087871551514
[1, 20283] loss_train: 0.006056, loss_test: 0.005520
time: 0.2470548152923584
time: 2.278510093688965
[1, 20284] loss_train: 0.002255, loss_test: 0.005519
time: 0.24405431747436523
time: 2.2755091190338135
[1, 20285] loss_train: 0.005735, loss_test: 0.005520
time: 0.24805593490600586
time: 2.286510705947876
[1, 20286] loss_train: 0.004926, loss_test: 0.005522
time: 0.24205327033996582
time: 2.265507221221924
[1, 20287] loss_train: 0.009366, loss_test: 0.005527
time: 0.24805498123168945
time: 2.2675070762634277
[1, 20288] loss_train: 0.004002, loss_test: 0.005534
time: 0.24405479431152344
time: 2.271507978439331
[1, 20289] loss_train: 0.003078, loss_test: 0.005542
time: 0.2470550537109375
time: 2.274508237838745
[1, 20290] loss_train: 0.006705, loss_test: 0.005551
time: 0.25705742835998535
time: 2.273508310317993
[1, 20291] loss_train: 0.009121, loss_test: 0.005556
time: 0.24805474281311035
time: 2.2535042762756348
[1, 20292] loss_train: 0.011140, loss_test: 0.005561
time: 0.24605488777160645
time: 2.274509906768799
[1, 20293] loss_train: 0.006242, loss_test: 0.005560
time: 0.24605512619018555
time: 2.2985146045684814
[1, 20294] loss_train: 0.010430, loss_test: 0.005555
time: 0.24405431747436523
time: 2.2765097618103027
[1, 20295] loss_train: 0.004200, loss_test: 0.005552
time: 0.2470545768737793
time: 2.2755088806152344
[1, 20296] loss_train: 0.015558, loss_test: 0.005546
time: 0.24405384063720703
time: 2.2545042037963867
[1, 20297] loss_train: 0.004423, loss_test: 0.005544
time: 0.24405407905578613
time: 2.245504379272461
[1, 20298] loss_train: 0.007531, loss_test: 0.005544
time: 0.24405360221862793
time: 2.255504846572876
[1, 20299] loss_train: 0.005737, loss_test: 0.005542
time: 0.24805712699890137
time: 2.2695069313049316
[1, 20300] loss_train: 0.003779, loss_test: 0.005542
time: 0.25905728340148926
time: 2.268507957458496
[1, 20301] loss_train: 0.002268, loss_test: 0.005542
time: 0.24405455589294434
time: 2.276510715484619
[1, 20302] loss_train: 0.003595, loss_test: 0.005541
time: 0.24405360221862793
time: 2.278510332107544
[1, 20303] loss_train: 0.007183, loss_test: 0.005539
time: 0.24305415153503418
time: 2.2805094718933105
[1, 20304] loss_train: 0.015043, loss_test: 0.005538
time: 0.24405407905578613
time: 2.2925124168395996
[1, 20305] loss_train: 0.013874, loss_test: 0.005540
time: 0.24405407905578613
time: 2.27201247215271
[1, 20306] loss_train: 0.011606, loss_test: 0.005542
time: 0.24505376815795898
time: 2.265507221221924
[1, 20307] loss_train: 0.005074, loss_test: 0.005545
time: 0.24405360221862793
time: 2.2745091915130615
[1, 20308] loss_train: 0.006792, loss_test: 0.005546
time: 0.2450544834136963
time: 2.268507480621338
[1, 20309] loss_train: 0.007427, loss_test: 0.005544
time: 0.24405360221862793
time: 2.3025155067443848
[1, 20310] loss_train: 0.007221, loss_test: 0.005534
time: 0.2580575942993164
time: 2.280510187149048
[1, 20311] loss_train: 0.010092, loss_test: 0.005524
time: 0.24505400657653809
time: 2.28351092338562
[1, 20312] loss_train: 0.005981, loss_test: 0.005518
time: 0.2450542449951172
time: 2.304515838623047
[1, 20313] loss_train: 0.004031, loss_test: 0.005515
time: 0.24505400657653809
time: 2.2565054893493652
[1, 20314] loss_train: 0.000547, loss_test: 0.005515
time: 0.24658751487731934
time: 2.27150821685791
[1, 20315] loss_train: 0.004786, loss_test: 0.005519
time: 0.24405455589294434
time: 2.2284979820251465
[1, 20316] loss_train: 0.014432, loss_test: 0.005517
time: 0.25005578994750977
time: 2.2555038928985596
[1, 20317] loss_train: 0.011860, loss_test: 0.005515
time: 0.24405527114868164
time: 2.2775089740753174
[1, 20318] loss_train: 0.003794, loss_test: 0.005515
time: 0.2450547218322754
time: 2.25300669670105
[1, 20319] loss_train: 0.009609, loss_test: 0.005516
time: 0.24305391311645508
time: 2.2640490531921387
[1, 20320] loss_train: 0.002944, loss_test: 0.005518
time: 0.2580575942993164
time: 2.274508476257324
[1, 20321] loss_train: 0.004461, loss_test: 0.005518
time: 0.24405479431152344
time: 2.2535037994384766
[1, 20322] loss_train: 0.011804, loss_test: 0.005520
time: 0.24305367469787598
time: 2.2745091915130615
[1, 20323] loss_train: 0.016600, loss_test: 0.005521
time: 0.25705718994140625
time: 2.2755091190338135
[1, 20324] loss_train: 0.002054, loss_test: 0.005523
time: 0.24405384063720703
time: 2.255504846572876
[1, 20325] loss_train: 0.010960, loss_test: 0.005526
time: 0.24405455589294434
time: 2.2760119438171387
[1, 20326] loss_train: 0.004498, loss_test: 0.005528
time: 0.24605417251586914
time: 2.264509677886963
[1, 20327] loss_train: 0.001694, loss_test: 0.005529
time: 0.24605488777160645
time: 2.24650239944458
[1, 20328] loss_train: 0.002918, loss_test: 0.005527
time: 0.24305438995361328
time: 2.2555041313171387
[1, 20329] loss_train: 0.008491, loss_test: 0.005526
time: 0.24405431747436523
time: 2.2635061740875244
[1, 20330] loss_train: 0.008472, loss_test: 0.005525
time: 0.25705671310424805
time: 2.281510591506958
[1, 20331] loss_train: 0.008575, loss_test: 0.005523
time: 0.24405527114868164
time: 2.2795088291168213
[1, 20332] loss_train: 0.007240, loss_test: 0.005522
time: 0.24305391311645508
time: 2.2386326789855957
[1, 20333] loss_train: 0.001984, loss_test: 0.005520
time: 0.24305415153503418
time: 2.2605056762695312
[1, 20334] loss_train: 0.011205, loss_test: 0.005518
time: 0.24805450439453125
time: 2.278508424758911
[1, 20335] loss_train: 0.004133, loss_test: 0.005518
time: 0.24405407905578613
time: 2.234499931335449
[1, 20336] loss_train: 0.006386, loss_test: 0.005521
time: 0.24405455589294434
time: 2.284511089324951
[1, 20337] loss_train: 0.008105, loss_test: 0.005527
time: 0.2450547218322754
time: 2.2615058422088623
[1, 20338] loss_train: 0.006812, loss_test: 0.005534
time: 0.2450549602508545
time: 2.2755086421966553
[1, 20339] loss_train: 0.002918, loss_test: 0.005541
time: 0.24305343627929688
time: 2.279510259628296
[1, 20340] loss_train: 0.004869, loss_test: 0.005544
time: 0.25705671310424805
time: 2.2655413150787354
[1, 20341] loss_train: 0.007287, loss_test: 0.005547
time: 0.24605393409729004
time: 2.280510663986206
[1, 20342] loss_train: 0.005483, loss_test: 0.005545
time: 0.24405407905578613
time: 2.2435038089752197
[1, 20343] loss_train: 0.000538, loss_test: 0.005545
time: 0.2450547218322754
time: 2.257504940032959
[1, 20344] loss_train: 0.007802, loss_test: 0.005545
time: 0.24405384063720703
time: 2.326521396636963
[1, 20345] loss_train: 0.010080, loss_test: 0.005541
time: 0.25005435943603516
time: 2.285510540008545
[1, 20346] loss_train: 0.003012, loss_test: 0.005540
time: 0.24305367469787598
time: 2.2965166568756104
[1, 20347] loss_train: 0.003685, loss_test: 0.005542
time: 0.2470548152923584
time: 2.261505603790283
[1, 20348] loss_train: 0.006030, loss_test: 0.005544
time: 0.24605417251586914
time: 2.2579543590545654
[1, 20349] loss_train: 0.003611, loss_test: 0.005546
time: 0.24605512619018555
time: 2.248018264770508
[1, 20350] loss_train: 0.006245, loss_test: 0.005549
time: 0.2580571174621582
time: 2.258505344390869
[1, 20351] loss_train: 0.009727, loss_test: 0.005549
time: 0.24405384063720703
time: 2.2415013313293457
[1, 20352] loss_train: 0.003571, loss_test: 0.005552
time: 0.2490546703338623
time: 2.2715096473693848
[1, 20353] loss_train: 0.005019, loss_test: 0.005557
time: 0.2470548152923584
time: 2.2445027828216553
[1, 20354] loss_train: 0.009942, loss_test: 0.005559
time: 0.24305343627929688
time: 2.28251051902771
[1, 20355] loss_train: 0.001674, loss_test: 0.005560
time: 0.2530558109283447
time: 2.2805099487304688
[1, 20356] loss_train: 0.003134, loss_test: 0.005561
time: 0.24505329132080078
time: 2.304515838623047
[1, 20357] loss_train: 0.008326, loss_test: 0.005563
time: 0.24405407905578613
time: 2.252504348754883
[1, 20358] loss_train: 0.000899, loss_test: 0.005566
time: 0.24405360221862793
time: 2.2745184898376465
[1, 20359] loss_train: 0.004586, loss_test: 0.005568
time: 0.2520573139190674
time: 2.2825100421905518
[1, 20360] loss_train: 0.009863, loss_test: 0.005569
time: 0.2580571174621582
time: 2.241501569747925
[1, 20361] loss_train: 0.006889, loss_test: 0.005566
time: 0.24405360221862793
time: 2.2645061016082764
[1, 20362] loss_train: 0.007876, loss_test: 0.005560
time: 0.24305415153503418
time: 2.221553087234497
[1, 20363] loss_train: 0.005690, loss_test: 0.005557
time: 0.24405360221862793
time: 2.2535064220428467
[1, 20364] loss_train: 0.003917, loss_test: 0.005560
time: 0.2450556755065918
time: 2.246504068374634
[1, 20365] loss_train: 0.010178, loss_test: 0.005562
time: 0.24605441093444824
time: 2.2525060176849365
[1, 20366] loss_train: 0.002477, loss_test: 0.005566
time: 0.2450547218322754
time: 2.2575087547302246
[1, 20367] loss_train: 0.006543, loss_test: 0.005568
time: 0.24405407905578613
time: 2.257505416870117
[1, 20368] loss_train: 0.007221, loss_test: 0.005566
time: 0.24405431747436523
time: 2.2405006885528564
[1, 20369] loss_train: 0.004525, loss_test: 0.005563
time: 0.2450542449951172
time: 2.275508403778076
[1, 20370] loss_train: 0.013254, loss_test: 0.005548
time: 0.2620577812194824
time: 2.2615063190460205
[1, 20371] loss_train: 0.008266, loss_test: 0.005544
time: 0.24405384063720703
time: 2.249342679977417
[1, 20372] loss_train: 0.007048, loss_test: 0.005548
time: 0.24505376815795898
time: 2.2665085792541504
[1, 20373] loss_train: 0.009321, loss_test: 0.005557
time: 0.24305510520935059
time: 2.284513473510742
[1, 20374] loss_train: 0.006846, loss_test: 0.005568
time: 0.2490553855895996
time: 2.2675065994262695
[1, 20375] loss_train: 0.007634, loss_test: 0.005575
time: 0.24405407905578613
time: 2.2505033016204834
[1, 20376] loss_train: 0.003881, loss_test: 0.005577
time: 0.24405431747436523
time: 2.254504919052124
[1, 20377] loss_train: 0.007816, loss_test: 0.005571
time: 0.24405407905578613
time: 2.2425010204315186
[1, 20378] loss_train: 0.013657, loss_test: 0.005568
time: 0.2450542449951172
time: 2.2595057487487793
[1, 20379] loss_train: 0.005005, loss_test: 0.005563
time: 0.2450547218322754
time: 2.281020402908325
[1, 20380] loss_train: 0.007938, loss_test: 0.005551
time: 0.2580573558807373
time: 2.2745087146759033
[1, 20381] loss_train: 0.011048, loss_test: 0.005541
time: 0.24605393409729004
time: 2.2795112133026123
[1, 20382] loss_train: 0.013223, loss_test: 0.005536
time: 0.24505305290222168
time: 2.267508029937744
[1, 20383] loss_train: 0.007661, loss_test: 0.005533
time: 0.24305343627929688
time: 2.2585055828094482
[1, 20384] loss_train: 0.003662, loss_test: 0.005529
time: 0.24605512619018555
time: 2.2555038928985596
[1, 20385] loss_train: 0.007536, loss_test: 0.005530
time: 0.24305367469787598
time: 2.257356643676758
[1, 20386] loss_train: 0.005760, loss_test: 0.005532
time: 0.2450542449951172
time: 2.2525036334991455
[1, 20387] loss_train: 0.014642, loss_test: 0.005539
time: 0.24405384063720703
time: 2.257505178451538
[1, 20388] loss_train: 0.004182, loss_test: 0.005548
time: 0.2470550537109375
time: 2.2535042762756348
[1, 20389] loss_train: 0.003723, loss_test: 0.005556
time: 0.24405336380004883
time: 2.2495036125183105
[1, 20390] loss_train: 0.011420, loss_test: 0.005565
time: 0.2580568790435791
time: 2.2775089740753174
[1, 20391] loss_train: 0.007402, loss_test: 0.005570
time: 0.24605512619018555
time: 2.2785091400146484
[1, 20392] loss_train: 0.003274, loss_test: 0.005575
time: 0.24505400657653809
time: 2.252504587173462
[1, 20393] loss_train: 0.002098, loss_test: 0.005579
time: 0.24405384063720703
time: 2.2845113277435303
[1, 20394] loss_train: 0.003644, loss_test: 0.005581
time: 0.2450547218322754
time: 2.26651930809021
[1, 20395] loss_train: 0.006447, loss_test: 0.005578
time: 0.2470555305480957
time: 2.2540063858032227
[1, 20396] loss_train: 0.004470, loss_test: 0.005574
time: 0.2450542449951172
time: 2.244525671005249
[1, 20397] loss_train: 0.003277, loss_test: 0.005558
time: 0.24405431747436523
time: 2.2765090465545654
[1, 20398] loss_train: 0.009621, loss_test: 0.005549
time: 0.2470550537109375
time: 2.2795093059539795
[1, 20399] loss_train: 0.004520, loss_test: 0.005545
time: 0.24505376815795898
time: 2.2425014972686768
[1, 20400] loss_train: 0.004392, loss_test: 0.005546
time: 0.2580564022064209
time: 2.2715184688568115
[1, 20401] loss_train: 0.010693, loss_test: 0.005551
time: 0.24405384063720703
time: 2.265507459640503
[1, 20402] loss_train: 0.010743, loss_test: 0.005558
time: 0.2470541000366211
time: 2.2735211849212646
[1, 20403] loss_train: 0.004062, loss_test: 0.005567
time: 0.24405407905578613
time: 2.2720119953155518
[1, 20404] loss_train: 0.005123, loss_test: 0.005577
time: 0.24605441093444824
time: 2.2585055828094482
[1, 20405] loss_train: 0.008353, loss_test: 0.005586
time: 0.24305462837219238
time: 2.246501922607422
[1, 20406] loss_train: 0.003756, loss_test: 0.005594
time: 0.25005531311035156
time: 2.2645068168640137
[1, 20407] loss_train: 0.001413, loss_test: 0.005602
time: 0.2450547218322754
time: 2.250502824783325
[1, 20408] loss_train: 0.002884, loss_test: 0.005608
time: 0.2450544834136963
time: 2.2785093784332275
[1, 20409] loss_train: 0.004467, loss_test: 0.005613
time: 0.2450549602508545
time: 2.266507148742676
[1, 20410] loss_train: 0.002940, loss_test: 0.005620
time: 0.256056547164917
time: 2.241501569747925
[1, 20411] loss_train: 0.001724, loss_test: 0.005629
time: 0.24305343627929688
time: 2.285015344619751
[1, 20412] loss_train: 0.012274, loss_test: 0.005626
time: 0.24405384063720703
time: 2.339524030685425
[1, 20413] loss_train: 0.003740, loss_test: 0.005618
time: 0.24305319786071777
time: 2.2605059146881104
[1, 20414] loss_train: 0.006156, loss_test: 0.005602
time: 0.24305438995361328
time: 2.2144980430603027
[1, 20415] loss_train: 0.004124, loss_test: 0.005589
time: 0.24305438995361328
time: 2.2535040378570557
[1, 20416] loss_train: 0.008417, loss_test: 0.005572
time: 0.24805450439453125
time: 2.24302339553833
[1, 20417] loss_train: 0.002779, loss_test: 0.005561
time: 0.24305367469787598
time: 2.228498935699463
[1, 20418] loss_train: 0.005328, loss_test: 0.005552
time: 0.24405384063720703
time: 2.265519857406616
[1, 20419] loss_train: 0.008386, loss_test: 0.005545
time: 0.24305438995361328
time: 2.249502658843994
[1, 20420] loss_train: 0.002057, loss_test: 0.005540
time: 0.25905823707580566
time: 2.26950740814209
[1, 20421] loss_train: 0.007606, loss_test: 0.005538
time: 0.24405407905578613
time: 2.274508476257324
[1, 20422] loss_train: 0.001399, loss_test: 0.005538
time: 0.24405455589294434
time: 2.2565040588378906
[1, 20423] loss_train: 0.008857, loss_test: 0.005536
time: 0.2450544834136963
time: 2.269507884979248
[1, 20424] loss_train: 0.001070, loss_test: 0.005536
time: 0.24505376815795898
time: 2.2465031147003174
[1, 20425] loss_train: 0.003090, loss_test: 0.005535
time: 0.24405407905578613
time: 2.2555036544799805
[1, 20426] loss_train: 0.001165, loss_test: 0.005535
time: 0.2470550537109375
time: 2.2365007400512695
[1, 20427] loss_train: 0.013440, loss_test: 0.005535
time: 0.24305462837219238
time: 2.2535035610198975
[1, 20428] loss_train: 0.008716, loss_test: 0.005529
time: 0.24405503273010254
time: 2.2685060501098633
[1, 20429] loss_train: 0.002929, loss_test: 0.005524
time: 0.2450547218322754
time: 2.2535054683685303
[1, 20430] loss_train: 0.003431, loss_test: 0.005520
time: 0.25905632972717285
time: 2.277509927749634
[1, 20431] loss_train: 0.003777, loss_test: 0.005518
time: 0.24805450439453125
time: 2.263507127761841
[1, 20432] loss_train: 0.003161, loss_test: 0.005516
time: 0.24105334281921387
time: 2.255504846572876
[1, 20433] loss_train: 0.012693, loss_test: 0.005514
time: 0.24505400657653809
time: 2.241501808166504
[1, 20434] loss_train: 0.001453, loss_test: 0.005513
time: 0.24505400657653809
time: 2.243502378463745
[1, 20435] loss_train: 0.008366, loss_test: 0.005513
time: 0.25205516815185547
time: 2.244501829147339
[1, 20436] loss_train: 0.005358, loss_test: 0.005510
time: 0.24405503273010254
time: 2.2350127696990967
[1, 20437] loss_train: 0.004294, loss_test: 0.005510
time: 0.24405455589294434
time: 2.234499454498291
[1, 20438] loss_train: 0.008876, loss_test: 0.005509
time: 0.24505400657653809
time: 2.2405011653900146
[1, 20439] loss_train: 0.008011, loss_test: 0.005507
time: 0.2490558624267578
time: 2.2405006885528564
[1, 20440] loss_train: 0.006658, loss_test: 0.005506
time: 0.2600574493408203
time: 2.2605066299438477
[1, 20441] loss_train: 0.006996, loss_test: 0.005508
time: 0.24305295944213867
time: 2.2495031356811523
[1, 20442] loss_train: 0.005903, loss_test: 0.005512
time: 0.24405360221862793
time: 2.2765095233917236
[1, 20443] loss_train: 0.001866, loss_test: 0.005516
time: 0.24605393409729004
time: 2.280510663986206
[1, 20444] loss_train: 0.009384, loss_test: 0.005518
time: 0.24405384063720703
time: 2.226498603820801
[1, 20445] loss_train: 0.005807, loss_test: 0.005519
time: 0.2450544834136963
time: 2.259505271911621
[1, 20446] loss_train: 0.008807, loss_test: 0.005520
time: 0.24405479431152344
time: 2.2395009994506836
[1, 20447] loss_train: 0.004250, loss_test: 0.005519
time: 0.24505329132080078
time: 2.2355000972747803
[1, 20448] loss_train: 0.007529, loss_test: 0.005518
time: 0.24305343627929688
time: 2.2425014972686768
[1, 20449] loss_train: 0.003897, loss_test: 0.005516
time: 0.24405360221862793
time: 2.2625064849853516
[1, 20450] loss_train: 0.000594, loss_test: 0.005518
time: 0.25905776023864746
time: 2.2375009059906006
[1, 20451] loss_train: 0.005368, loss_test: 0.005526
time: 0.24305295944213867
time: 2.232499122619629
[1, 20452] loss_train: 0.007719, loss_test: 0.005531
time: 0.24405503273010254
time: 2.2365005016326904
[1, 20453] loss_train: 0.004251, loss_test: 0.005538
time: 0.24305343627929688
time: 2.2735087871551514
[1, 20454] loss_train: 0.009780, loss_test: 0.005543
time: 0.2470550537109375
time: 2.2555043697357178
[1, 20455] loss_train: 0.010177, loss_test: 0.005543
time: 0.24405384063720703
time: 2.256505012512207
[1, 20456] loss_train: 0.002836, loss_test: 0.005544
time: 0.24505400657653809
time: 2.2485029697418213
[1, 20457] loss_train: 0.014990, loss_test: 0.005540
time: 0.24405288696289062
time: 2.230499505996704
[1, 20458] loss_train: 0.002139, loss_test: 0.005539
time: 0.24605417251586914
time: 2.2465028762817383
[1, 20459] loss_train: 0.000808, loss_test: 0.005539
time: 0.24305343627929688
time: 2.2365005016326904
[1, 20460] loss_train: 0.008321, loss_test: 0.005541
time: 0.2600576877593994
time: 2.2785098552703857
[1, 20461] loss_train: 0.008978, loss_test: 0.005545
time: 0.2510554790496826
time: 2.2530064582824707
[1, 20462] loss_train: 0.006057, loss_test: 0.005548
time: 0.2490551471710205
time: 2.2485032081604004
[1, 20463] loss_train: 0.003936, loss_test: 0.005548
time: 0.24405360221862793
time: 2.2425010204315186
[1, 20464] loss_train: 0.003137, loss_test: 0.005547
time: 0.24405455589294434
time: 2.2665066719055176
[1, 20465] loss_train: 0.005039, loss_test: 0.005545
time: 0.24605488777160645
time: 2.2835118770599365
[1, 20466] loss_train: 0.005322, loss_test: 0.005546
time: 0.24605441093444824
time: 2.260504961013794
[1, 20467] loss_train: 0.013599, loss_test: 0.005543
time: 0.24605536460876465
time: 2.231498956680298
[1, 20468] loss_train: 0.007466, loss_test: 0.005543
time: 0.24405455589294434
time: 2.2765085697174072
[1, 20469] loss_train: 0.002271, loss_test: 0.005544
time: 0.24605464935302734
time: 2.230499505996704
[1, 20470] loss_train: 0.005619, loss_test: 0.005545
time: 0.25505638122558594
time: 2.2595062255859375
[1, 20471] loss_train: 0.006922, loss_test: 0.005543
time: 0.24405360221862793
time: 2.2605044841766357
[1, 20472] loss_train: 0.010964, loss_test: 0.005540
time: 0.2450544834136963
time: 2.2515172958374023
[1, 20473] loss_train: 0.006523, loss_test: 0.005538
time: 0.24605441093444824
time: 2.237445831298828
[1, 20474] loss_train: 0.004991, loss_test: 0.005537
time: 0.24205398559570312
time: 2.25750470161438
[1, 20475] loss_train: 0.003629, loss_test: 0.005538
time: 0.2450544834136963
time: 2.2365005016326904
[1, 20476] loss_train: 0.003099, loss_test: 0.005540
time: 0.24405455589294434
time: 2.2685067653656006
[1, 20477] loss_train: 0.006901, loss_test: 0.005542
time: 0.25005531311035156
time: 2.2355000972747803
[1, 20478] loss_train: 0.004248, loss_test: 0.005545
time: 0.24405479431152344
time: 2.2535033226013184
[1, 20479] loss_train: 0.002655, loss_test: 0.005548
time: 0.24505400657653809
time: 2.254504919052124
[1, 20480] loss_train: 0.011639, loss_test: 0.005551
time: 0.25705647468566895
time: 2.232499837875366
[1, 20481] loss_train: 0.003192, loss_test: 0.005553
time: 0.24805474281311035
time: 2.238004684448242
[1, 20482] loss_train: 0.002767, loss_test: 0.005557
time: 0.24505376815795898
time: 2.2635066509246826
[1, 20483] loss_train: 0.006212, loss_test: 0.005560
time: 0.24305391311645508
time: 2.2164957523345947
[1, 20484] loss_train: 0.001577, loss_test: 0.005565
time: 0.24605369567871094
time: 2.2485034465789795
[1, 20485] loss_train: 0.013675, loss_test: 0.005567
time: 0.24605417251586914
time: 2.2625064849853516
[1, 20486] loss_train: 0.018925, loss_test: 0.005556
time: 0.24805498123168945
time: 2.2495033740997314
[1, 20487] loss_train: 0.004971, loss_test: 0.005550
time: 0.24305367469787598
time: 2.240501880645752
[1, 20488] loss_train: 0.003247, loss_test: 0.005549
time: 0.24605488777160645
time: 2.2505033016204834
[1, 20489] loss_train: 0.011688, loss_test: 0.005550
time: 0.2510554790496826
time: 2.2505037784576416
[1, 20490] loss_train: 0.002743, loss_test: 0.005552
time: 0.25905728340148926
time: 2.25750470161438
[1, 20491] loss_train: 0.005111, loss_test: 0.005555
time: 0.24405407905578613
time: 2.2535042762756348
[1, 20492] loss_train: 0.007783, loss_test: 0.005559
time: 0.2470543384552002
time: 2.2655088901519775
[1, 20493] loss_train: 0.011227, loss_test: 0.005560
time: 0.24805521965026855
time: 2.2635068893432617
[1, 20494] loss_train: 0.003548, loss_test: 0.005559
time: 0.24505400657653809
time: 2.2595057487487793
[1, 20495] loss_train: 0.002710, loss_test: 0.005554
time: 0.24305438995361328
time: 2.250502824783325
[1, 20496] loss_train: 0.005981, loss_test: 0.005548
time: 0.2450551986694336
time: 2.2695071697235107
[1, 20497] loss_train: 0.011929, loss_test: 0.005546
time: 0.2450551986694336
time: 2.263505697250366
[1, 20498] loss_train: 0.003335, loss_test: 0.005548
time: 0.24405455589294434
time: 2.260504722595215
[1, 20499] loss_train: 0.006131, loss_test: 0.005550
time: 0.24405407905578613
time: 2.244502544403076
[1, 20500] loss_train: 0.001277, loss_test: 0.005555
time: 0.2580580711364746
time: 2.264504909515381
[1, 20501] loss_train: 0.002989, loss_test: 0.005560
time: 0.24405431747436523
time: 2.273510217666626
[1, 20502] loss_train: 0.007171, loss_test: 0.005563
time: 0.24405384063720703
time: 2.269507884979248
[1, 20503] loss_train: 0.008732, loss_test: 0.005562
time: 0.24505400657653809
time: 2.266507387161255
[1, 20504] loss_train: 0.004787, loss_test: 0.005562
time: 0.24905610084533691
time: 2.285510540008545
[1, 20505] loss_train: 0.009407, loss_test: 0.005557
time: 0.24405431747436523
time: 2.2555158138275146
[1, 20506] loss_train: 0.003778, loss_test: 0.005554
time: 0.24405360221862793
time: 2.2645087242126465
[1, 20507] loss_train: 0.007493, loss_test: 0.005552
time: 0.24405455589294434
time: 2.26950740814209
[1, 20508] loss_train: 0.004175, loss_test: 0.005552
time: 0.2450549602508545
time: 2.2274980545043945
[1, 20509] loss_train: 0.024717, loss_test: 0.005547
time: 0.24405455589294434
time: 2.235502004623413
[1, 20510] loss_train: 0.009033, loss_test: 0.005545
time: 0.2580573558807373
time: 2.2755088806152344
[1, 20511] loss_train: 0.005958, loss_test: 0.005543
time: 0.24305319786071777
time: 2.297513484954834
[1, 20512] loss_train: 0.010450, loss_test: 0.005542
time: 0.24505376815795898
time: 2.2605061531066895
[1, 20513] loss_train: 0.008600, loss_test: 0.005542
time: 0.24305367469787598
time: 2.2595059871673584
[1, 20514] loss_train: 0.007424, loss_test: 0.005543
time: 0.24405455589294434
time: 2.2515058517456055
[1, 20515] loss_train: 0.008811, loss_test: 0.005552
time: 0.2510550022125244
time: 2.2345025539398193
[1, 20516] loss_train: 0.003112, loss_test: 0.005562
time: 0.24205422401428223
time: 2.2515032291412354
[1, 20517] loss_train: 0.009018, loss_test: 0.005575
time: 0.24405407905578613
time: 2.2535042762756348
[1, 20518] loss_train: 0.002838, loss_test: 0.005587
time: 0.2450551986694336
time: 2.258504629135132
[1, 20519] loss_train: 0.003169, loss_test: 0.005584
time: 0.2470545768737793
time: 2.247504472732544
[1, 20520] loss_train: 0.003562, loss_test: 0.005573
time: 0.25905728340148926
time: 2.2455027103424072
[1, 20521] loss_train: 0.005082, loss_test: 0.005556
time: 0.24405431747436523
time: 2.2605056762695312
[1, 20522] loss_train: 0.008636, loss_test: 0.005543
time: 0.24605417251586914
time: 2.2365007400512695
[1, 20523] loss_train: 0.009904, loss_test: 0.005535
time: 0.24605417251586914
time: 2.262507677078247
[1, 20524] loss_train: 0.014454, loss_test: 0.005533
time: 0.24405384063720703
time: 2.2585058212280273
[1, 20525] loss_train: 0.006049, loss_test: 0.005536
time: 0.24605464935302734
time: 2.2535064220428467
[1, 20526] loss_train: 0.005304, loss_test: 0.005543
time: 0.24805474281311035
time: 2.266507387161255
[1, 20527] loss_train: 0.002977, loss_test: 0.005551
time: 0.2520580291748047
time: 2.295513391494751
[1, 20528] loss_train: 0.006753, loss_test: 0.005562
time: 0.24405479431152344
time: 2.2395005226135254
[1, 20529] loss_train: 0.006523, loss_test: 0.005573
time: 0.24505376815795898
time: 2.2625067234039307
[1, 20530] loss_train: 0.003375, loss_test: 0.005586
time: 0.258056640625
time: 2.2735092639923096
[1, 20531] loss_train: 0.003843, loss_test: 0.005601
time: 0.2450547218322754
time: 2.2685067653656006
[1, 20532] loss_train: 0.007493, loss_test: 0.005609
time: 0.24405407905578613
time: 2.2585058212280273
[1, 20533] loss_train: 0.009155, loss_test: 0.005604
time: 0.2490546703338623
time: 2.2635059356689453
[1, 20534] loss_train: 0.008130, loss_test: 0.005597
time: 0.24605488777160645
time: 2.2460079193115234
[1, 20535] loss_train: 0.003002, loss_test: 0.005592
time: 0.24405431747436523
time: 2.2815098762512207
[1, 20536] loss_train: 0.004415, loss_test: 0.005585
time: 0.24205899238586426
time: 2.2765088081359863
[1, 20537] loss_train: 0.003508, loss_test: 0.005575
time: 0.24605464935302734
time: 2.250502347946167
[1, 20538] loss_train: 0.002943, loss_test: 0.005567
time: 0.24405455589294434
time: 2.2635068893432617
[1, 20539] loss_train: 0.002071, loss_test: 0.005563
time: 0.24405407905578613
time: 2.2645063400268555
[1, 20540] loss_train: 0.004691, loss_test: 0.005561
time: 0.25705742835998535
time: 2.2655067443847656
[1, 20541] loss_train: 0.005210, loss_test: 0.005562
time: 0.24605488777160645
time: 2.2695140838623047
[1, 20542] loss_train: 0.000729, loss_test: 0.005565
time: 0.24405431747436523
time: 2.223508358001709
[1, 20543] loss_train: 0.014409, loss_test: 0.005552
time: 0.24405479431152344
time: 2.2385001182556152
[1, 20544] loss_train: 0.013172, loss_test: 0.005547
time: 0.24605512619018555
time: 2.2575042247772217
[1, 20545] loss_train: 0.009403, loss_test: 0.005553
time: 0.24305391311645508
time: 2.2485032081604004
[1, 20546] loss_train: 0.007164, loss_test: 0.005573
time: 0.24405384063720703
time: 2.2565042972564697
[1, 20547] loss_train: 0.001433, loss_test: 0.005584
time: 0.24405431747436523
time: 2.266507148742676
[1, 20548] loss_train: 0.001419, loss_test: 0.005600
time: 0.25005578994750977
time: 2.2385010719299316
[1, 20549] loss_train: 0.004871, loss_test: 0.005599
time: 0.24405407905578613
time: 2.282510757446289
[1, 20550] loss_train: 0.003715, loss_test: 0.005583
time: 0.2580578327178955
time: 2.2535035610198975
[1, 20551] loss_train: 0.010706, loss_test: 0.005568
time: 0.24305367469787598
time: 2.2575056552886963
[1, 20552] loss_train: 0.002629, loss_test: 0.005553
time: 0.24405431747436523
time: 2.2875115871429443
[1, 20553] loss_train: 0.003503, loss_test: 0.005547
time: 0.24505400657653809
time: 2.2625062465667725
[1, 20554] loss_train: 0.002052, loss_test: 0.005547
time: 0.2450542449951172
time: 2.2635066509246826
[1, 20555] loss_train: 0.005442, loss_test: 0.005554
time: 0.25005483627319336
time: 2.2735092639923096
[1, 20556] loss_train: 0.011069, loss_test: 0.005564
time: 0.24405479431152344
time: 2.247502326965332
[1, 20557] loss_train: 0.007321, loss_test: 0.005576
time: 0.2450544834136963
time: 2.2585043907165527
[1, 20558] loss_train: 0.003893, loss_test: 0.005593
time: 0.24505400657653809
time: 2.329522132873535
[1, 20559] loss_train: 0.005326, loss_test: 0.005599
time: 0.26605844497680664
time: 2.3375229835510254
[1, 20560] loss_train: 0.003299, loss_test: 0.005606
time: 0.26105833053588867
time: 2.3800525665283203
[1, 20561] loss_train: 0.006681, loss_test: 0.005612
time: 0.24505305290222168
time: 2.2755112648010254
[1, 20562] loss_train: 0.004315, loss_test: 0.005618
time: 0.2510559558868408
time: 2.3535265922546387
[1, 20563] loss_train: 0.004682, loss_test: 0.005623
time: 0.24605536460876465
time: 2.3005144596099854
[1, 20564] loss_train: 0.006622, loss_test: 0.005624
time: 0.25305676460266113
time: 2.293513059616089
[1, 20565] loss_train: 0.001433, loss_test: 0.005623
time: 0.27506113052368164
time: 2.336522340774536
[1, 20566] loss_train: 0.001364, loss_test: 0.005622
time: 0.25505709648132324
time: 2.6160006523132324
[1, 20567] loss_train: 0.008060, loss_test: 0.005599
time: 0.2746701240539551
time: 2.507563591003418
[1, 20568] loss_train: 0.003570, loss_test: 0.005582
time: 0.2730598449707031
time: 2.4276092052459717
[1, 20569] loss_train: 0.012523, loss_test: 0.005573
time: 0.2830629348754883
time: 2.621090888977051
[1, 20570] loss_train: 0.002915, loss_test: 0.005568
time: 0.30606794357299805
time: 2.6256184577941895
[1, 20571] loss_train: 0.001681, loss_test: 0.005570
time: 0.43004703521728516
time: 2.606581926345825
[1, 20572] loss_train: 0.002639, loss_test: 0.005573
time: 0.29906606674194336
time: 2.649618148803711
[1, 20573] loss_train: 0.008794, loss_test: 0.005572
time: 0.9797449111938477
time: 2.565819501876831
[1, 20574] loss_train: 0.004222, loss_test: 0.005572
time: 0.312070369720459
time: 2.850024938583374
[1, 20575] loss_train: 0.012514, loss_test: 0.005563
time: 0.3020665645599365
time: 2.75789737701416
[1, 20576] loss_train: 0.008309, loss_test: 0.005560
time: 0.29655909538269043
time: 2.8453400135040283
[1, 20577] loss_train: 0.003057, loss_test: 0.005559
time: 0.2915973663330078
time: 2.5375449657440186
[1, 20578] loss_train: 0.001641, loss_test: 0.005557
time: 0.30206751823425293
time: 2.9411723613739014
[1, 20579] loss_train: 0.010387, loss_test: 0.005555
time: 0.29805922508239746
time: 2.759150981903076
[1, 20580] loss_train: 0.007675, loss_test: 0.005552
time: 0.7778201103210449
time: 2.8629627227783203
[1, 20581] loss_train: 0.004672, loss_test: 0.005550
time: 0.40908288955688477
time: 3.125203847885132
[1, 20582] loss_train: 0.006075, loss_test: 0.005549
time: 0.2620582580566406
time: 2.8218157291412354
[1, 20583] loss_train: 0.003902, loss_test: 0.005549
time: 0.2897834777832031
time: 2.713611125946045
[1, 20584] loss_train: 0.014117, loss_test: 0.005548
time: 0.3016037940979004
time: 2.8281681537628174
[1, 20585] loss_train: 0.005704, loss_test: 0.005545
time: 0.7955458164215088
time: 2.972160816192627
[1, 20586] loss_train: 0.004668, loss_test: 0.005543
time: 0.29909539222717285
time: 2.930690288543701
[1, 20587] loss_train: 0.005843, loss_test: 0.005541
time: 0.29357028007507324
time: 2.8732402324676514
[1, 20588] loss_train: 0.009573, loss_test: 0.005540
time: 0.29306459426879883
time: 2.5826964378356934
[1, 20589] loss_train: 0.003127, loss_test: 0.005539
time: 0.29706811904907227
time: 2.534238338470459
[1, 20590] loss_train: 0.004731, loss_test: 0.005537
time: 0.3030674457550049
time: 2.8336873054504395
[1, 20591] loss_train: 0.006742, loss_test: 0.005535
time: 0.2900674343109131
time: 2.553072929382324
[1, 20592] loss_train: 0.006647, loss_test: 0.005533
time: 0.29506587982177734
time: 2.835434675216675
[1, 20593] loss_train: 0.013382, loss_test: 0.005536
time: 0.28106260299682617
time: 2.848501205444336
[1, 20594] loss_train: 0.005028, loss_test: 0.005541
time: 0.30406761169433594
time: 2.654710054397583
[1, 20595] loss_train: 0.002184, loss_test: 0.005546
time: 0.2890646457672119
time: 2.5306344032287598
[1, 20596] loss_train: 0.004311, loss_test: 0.005551
time: 0.29706573486328125
time: 2.685328722000122
[1, 20597] loss_train: 0.007793, loss_test: 0.005555
time: 0.309063196182251
time: 2.573552131652832
[1, 20598] loss_train: 0.002696, loss_test: 0.005557
time: 0.30107545852661133
time: 2.6300830841064453
[1, 20599] loss_train: 0.007915, loss_test: 0.005558
time: 0.30106663703918457
time: 2.639500141143799
[1, 20600] loss_train: 0.005928, loss_test: 0.005560
time: 0.2920646667480469
time: 2.5245578289031982
[1, 20601] loss_train: 0.002984, loss_test: 0.005561
time: 0.30406785011291504
time: 2.4925570487976074
[1, 20602] loss_train: 0.006275, loss_test: 0.005560
time: 0.276059627532959
time: 2.3225197792053223
[1, 20603] loss_train: 0.007742, loss_test: 0.005559
time: 0.2720611095428467
time: 2.3405232429504395
[1, 20604] loss_train: 0.004660, loss_test: 0.005559
time: 0.25505566596984863
time: 2.378535270690918
[1, 20605] loss_train: 0.009087, loss_test: 0.005558
time: 0.26405906677246094
time: 2.3515255451202393
[1, 20606] loss_train: 0.003118, loss_test: 0.005558
time: 0.2490546703338623
time: 2.2960188388824463
[1, 20607] loss_train: 0.007524, loss_test: 0.005557
time: 0.25705790519714355
time: 2.3345212936401367
[1, 20608] loss_train: 0.004671, loss_test: 0.005558
time: 0.29306459426879883
time: 2.3245203495025635
[1, 20609] loss_train: 0.007120, loss_test: 0.005558
time: 0.3120691776275635
time: 2.3355226516723633
[1, 20610] loss_train: 0.004289, loss_test: 0.005559
time: 0.2620577812194824
time: 2.363743543624878
[1, 20611] loss_train: 0.004838, loss_test: 0.005559
time: 0.2650597095489502
time: 2.4923696517944336
[1, 20612] loss_train: 0.002024, loss_test: 0.005560
time: 0.28832197189331055
time: 3.1897690296173096
[1, 20613] loss_train: 0.005605, loss_test: 0.005562
time: 0.2940652370452881
time: 2.490751266479492
[1, 20614] loss_train: 0.010460, loss_test: 0.005561
time: 0.2800629138946533
time: 2.5175652503967285
[1, 20615] loss_train: 0.005857, loss_test: 0.005563
time: 0.2870633602142334
time: 2.5788283348083496
[1, 20616] loss_train: 0.007371, loss_test: 0.005563
time: 0.2796764373779297
time: 2.524888753890991
[1, 20617] loss_train: 0.004707, loss_test: 0.005564
time: 0.2560572624206543
time: 2.327558755874634
[1, 20618] loss_train: 0.005330, loss_test: 0.005564
time: 0.24805545806884766
time: 2.4708590507507324
[1, 20619] loss_train: 0.008353, loss_test: 0.005564
time: 0.299072265625
time: 2.43609619140625
[1, 20620] loss_train: 0.007356, loss_test: 0.005563
time: 0.26805949211120605
time: 2.3828792572021484
[1, 20621] loss_train: 0.003300, loss_test: 0.005561
time: 0.28324460983276367
time: 2.6856534481048584
[1, 20622] loss_train: 0.000606, loss_test: 0.005560
time: 0.29706621170043945
time: 2.5711073875427246
[1, 20623] loss_train: 0.004579, loss_test: 0.005558
time: 0.2950723171234131
time: 2.517186164855957
[1, 20624] loss_train: 0.011581, loss_test: 0.005554
time: 0.2901015281677246
time: 2.960109233856201
[1, 20625] loss_train: 0.014845, loss_test: 0.005550
time: 0.2815709114074707
time: 2.488617420196533
[1, 20626] loss_train: 0.005075, loss_test: 0.005547
time: 0.2900834083557129
time: 2.9778594970703125
[1, 20627] loss_train: 0.004167, loss_test: 0.005543
time: 0.2835688591003418
time: 2.7441554069519043
[1, 20628] loss_train: 0.005686, loss_test: 0.005540
time: 0.37508296966552734
time: 2.56007719039917
[1, 20629] loss_train: 0.010243, loss_test: 0.005538
time: 0.2890639305114746
time: 2.532566785812378
[1, 20630] loss_train: 0.004804, loss_test: 0.005536
time: 0.2960655689239502
time: 2.8360676765441895
[1, 20631] loss_train: 0.000859, loss_test: 0.005533
time: 0.282062292098999
time: 2.611325263977051
[1, 20632] loss_train: 0.003174, loss_test: 0.005532
time: 0.2889368534088135
time: 2.622750759124756
[1, 20633] loss_train: 0.012116, loss_test: 0.005535
time: 0.2980666160583496
time: 2.470586061477661
[1, 20634] loss_train: 0.006323, loss_test: 0.005535
time: 0.27904558181762695
time: 2.4983437061309814
[1, 20635] loss_train: 0.007814, loss_test: 0.005533
time: 0.29006481170654297
time: 2.666823625564575
[1, 20636] loss_train: 0.001839, loss_test: 0.005534
time: 0.2830634117126465
time: 2.5062096118927
[1, 20637] loss_train: 0.011958, loss_test: 0.005540
time: 0.28606295585632324
time: 2.590388536453247
[1, 20638] loss_train: 0.006348, loss_test: 0.005545
time: 0.283062219619751
time: 3.000426769256592
[1, 20639] loss_train: 0.003110, loss_test: 0.005552
time: 0.2870638370513916
time: 2.5155625343322754
[1, 20640] loss_train: 0.003257, loss_test: 0.005559
time: 0.303067684173584
time: 2.5075125694274902
[1, 20641] loss_train: 0.006385, loss_test: 0.005564
time: 0.2820618152618408
time: 2.580159902572632
[1, 20642] loss_train: 0.016056, loss_test: 0.005560
time: 0.29300451278686523
time: 2.5924174785614014
[1, 20643] loss_train: 0.005401, loss_test: 0.005552
time: 0.2890641689300537
time: 2.9001359939575195
[1, 20644] loss_train: 0.011145, loss_test: 0.005543
time: 0.28886866569519043
time: 2.5621211528778076
[1, 20645] loss_train: 0.003793, loss_test: 0.005541
time: 0.28606390953063965
time: 2.8616397380828857
[1, 20646] loss_train: 0.011881, loss_test: 0.005542
time: 0.2870635986328125
time: 2.7416293621063232
[1, 20647] loss_train: 0.006145, loss_test: 0.005547
time: 0.28907132148742676
time: 2.550114393234253
[1, 20648] loss_train: 0.006057, loss_test: 0.005554
time: 0.28583836555480957
time: 2.9326562881469727
[1, 20649] loss_train: 0.003114, loss_test: 0.005558
time: 0.28606295585632324
time: 2.564213752746582
[1, 20650] loss_train: 0.009490, loss_test: 0.005562
time: 0.29506444931030273
time: 2.5020792484283447
[1, 20651] loss_train: 0.004154, loss_test: 0.005564
time: 0.27506160736083984
time: 2.4783451557159424
[1, 20652] loss_train: 0.003617, loss_test: 0.005563
time: 0.28856754302978516
time: 2.5284528732299805
[1, 20653] loss_train: 0.009628, loss_test: 0.005558
time: 0.2890639305114746
time: 2.5240161418914795
[1, 20654] loss_train: 0.002872, loss_test: 0.005552
time: 0.2910642623901367
time: 2.4860596656799316
[1, 20655] loss_train: 0.012546, loss_test: 0.005548
time: 0.2980666160583496
time: 2.5082952976226807
[1, 20656] loss_train: 0.009406, loss_test: 0.005543
time: 0.3160700798034668
time: 2.4722931385040283
[1, 20657] loss_train: 0.007872, loss_test: 0.005540
time: 0.2910640239715576
time: 2.4915528297424316
[1, 20658] loss_train: 0.007427, loss_test: 0.005537
time: 0.30243730545043945
time: 2.5208802223205566
[1, 20659] loss_train: 0.002423, loss_test: 0.005536
time: 0.30206727981567383
time: 2.536543607711792
[1, 20660] loss_train: 0.005398, loss_test: 0.005535
time: 0.31107020378112793
time: 2.5351312160491943
[1, 20661] loss_train: 0.006918, loss_test: 0.005534
time: 0.2960662841796875
time: 2.5584399700164795
[1, 20662] loss_train: 0.003174, loss_test: 0.005535
time: 0.309525728225708
time: 2.5293703079223633
[1, 20663] loss_train: 0.004784, loss_test: 0.005534
time: 0.30106687545776367
time: 2.5201334953308105
[1, 20664] loss_train: 0.007015, loss_test: 0.005533
time: 0.3030674457550049
time: 2.5078847408294678
[1, 20665] loss_train: 0.007959, loss_test: 0.005530
time: 0.285067081451416
time: 2.5429189205169678
[1, 20666] loss_train: 0.006994, loss_test: 0.005527
time: 0.2890636920928955
time: 2.4658758640289307
[1, 20667] loss_train: 0.006948, loss_test: 0.005525
time: 0.29506611824035645
time: 2.500152349472046
[1, 20668] loss_train: 0.003002, loss_test: 0.005524
time: 0.2901120185852051
time: 2.4930708408355713
[1, 20669] loss_train: 0.007671, loss_test: 0.005522
time: 0.2870628833770752
time: 2.5312047004699707
[1, 20670] loss_train: 0.007141, loss_test: 0.005521
time: 0.30806779861450195
time: 2.5301878452301025
[1, 20671] loss_train: 0.003310, loss_test: 0.005521
time: 0.29006505012512207
time: 2.5090770721435547
[1, 20672] loss_train: 0.003441, loss_test: 0.005522
time: 0.29157018661499023
time: 2.401695728302002
[1, 20673] loss_train: 0.001072, loss_test: 0.005524
time: 0.24471282958984375
time: 2.3000168800354004
[1, 20674] loss_train: 0.004359, loss_test: 0.005529
time: 0.24306035041809082
time: 2.293060064315796
[1, 20675] loss_train: 0.013890, loss_test: 0.005533
time: 0.24305367469787598
time: 2.292513608932495
[1, 20676] loss_train: 0.009738, loss_test: 0.005541
time: 0.24605321884155273
time: 2.2969400882720947
[1, 20677] loss_train: 0.005648, loss_test: 0.005553
time: 0.24805521965026855
time: 2.2510552406311035
[1, 20678] loss_train: 0.004553, loss_test: 0.005563
time: 0.24605536460876465
time: 2.449596643447876
[1, 20679] loss_train: 0.004147, loss_test: 0.005575
time: 0.2860736846923828
time: 2.5168633460998535
[1, 20680] loss_train: 0.009178, loss_test: 0.005580
time: 0.3130605220794678
time: 2.324552536010742
[1, 20681] loss_train: 0.002051, loss_test: 0.005584
time: 0.24405336380004883
time: 2.298018217086792
[1, 20682] loss_train: 0.008306, loss_test: 0.005588
time: 0.24305438995361328
time: 2.270507574081421
[1, 20683] loss_train: 0.006090, loss_test: 0.005590
time: 0.2470541000366211
time: 2.2840240001678467
[1, 20684] loss_train: 0.004631, loss_test: 0.005593
time: 0.25505661964416504
time: 2.2674407958984375
[1, 20685] loss_train: 0.005046, loss_test: 0.005590
time: 0.2450549602508545
time: 2.284510612487793
[1, 20686] loss_train: 0.002970, loss_test: 0.005589
time: 0.24405384063720703
time: 2.4271631240844727
[1, 20687] loss_train: 0.001049, loss_test: 0.005591
time: 0.3048875331878662
time: 3.1726930141448975
[1, 20688] loss_train: 0.004486, loss_test: 0.005594
time: 0.2990751266479492
time: 2.8380532264709473
[1, 20689] loss_train: 0.017765, loss_test: 0.005585
time: 0.29006361961364746
time: 2.569080114364624
[1, 20690] loss_train: 0.004624, loss_test: 0.005580
time: 0.29906558990478516
time: 2.7252893447875977
[1, 20691] loss_train: 0.002023, loss_test: 0.005575
time: 0.8319971561431885
time: 2.76914381980896
[1, 20692] loss_train: 0.008455, loss_test: 0.005570
time: 0.2939894199371338
time: 2.7208704948425293
[1, 20693] loss_train: 0.005278, loss_test: 0.005564
time: 0.30406785011291504
time: 2.6325886249542236
[1, 20694] loss_train: 0.003356, loss_test: 0.005559
time: 0.3140695095062256
time: 3.198715925216675
[1, 20695] loss_train: 0.002381, loss_test: 0.005554
time: 0.29506540298461914
time: 2.6242096424102783
[1, 20696] loss_train: 0.010359, loss_test: 0.005548
time: 0.29506540298461914
time: 2.495558738708496
[1, 20697] loss_train: 0.003092, loss_test: 0.005546
time: 0.28789305686950684
time: 2.5058391094207764
[1, 20698] loss_train: 0.007346, loss_test: 0.005541
time: 0.2989656925201416
time: 2.453094244003296
[1, 20699] loss_train: 0.008984, loss_test: 0.005536
time: 0.30294060707092285
time: 2.4656026363372803
[1, 20700] loss_train: 0.009541, loss_test: 0.005532
time: 0.3000664710998535
time: 2.464055299758911
[1, 20701] loss_train: 0.007945, loss_test: 0.005531
time: 0.2910654544830322
time: 2.479473114013672
[1, 20702] loss_train: 0.002455, loss_test: 0.005534
time: 0.29906702041625977
time: 2.484523296356201
[1, 20703] loss_train: 0.010075, loss_test: 0.005536
time: 0.27945733070373535
time: 2.4814648628234863
[1, 20704] loss_train: 0.012648, loss_test: 0.005542
time: 0.285569429397583
time: 2.5752313137054443
[1, 20705] loss_train: 0.004909, loss_test: 0.005548
time: 0.2610585689544678
time: 2.384532928466797
[1, 20706] loss_train: 0.015977, loss_test: 0.005548
time: 0.3107028007507324
time: 2.4036760330200195
[1, 20707] loss_train: 0.010755, loss_test: 0.005550
time: 0.2780613899230957
time: 2.4630565643310547
[1, 20708] loss_train: 0.002635, loss_test: 0.005545
time: 0.3007218837738037
time: 2.509065628051758
[1, 20709] loss_train: 0.003532, loss_test: 0.005537
time: 0.2850627899169922
time: 2.4752814769744873
[1, 20710] loss_train: 0.005825, loss_test: 0.005529
time: 0.30806922912597656
time: 2.497558116912842
[1, 20711] loss_train: 0.008103, loss_test: 0.005524
time: 0.30606865882873535
time: 2.49375057220459
[1, 20712] loss_train: 0.001122, loss_test: 0.005522
time: 0.3070681095123291
time: 2.4839634895324707
[1, 20713] loss_train: 0.009233, loss_test: 0.005523
time: 0.279205322265625
time: 2.4921021461486816
[1, 20714] loss_train: 0.007274, loss_test: 0.005527
time: 0.2940683364868164
time: 2.5035758018493652
[1, 20715] loss_train: 0.002119, loss_test: 0.005532
time: 0.2884674072265625
time: 2.475677013397217
[1, 20716] loss_train: 0.007050, loss_test: 0.005537
time: 0.27706098556518555
time: 2.4864251613616943
[1, 20717] loss_train: 0.010236, loss_test: 0.005541
time: 0.30251502990722656
time: 2.503786563873291
[1, 20718] loss_train: 0.010941, loss_test: 0.005545
time: 0.3190755844116211
time: 2.513446569442749
[1, 20719] loss_train: 0.004112, loss_test: 0.005548
time: 0.30406761169433594
time: 2.5393316745758057
[1, 20720] loss_train: 0.002228, loss_test: 0.005545
time: 0.31339359283447266
time: 2.480825185775757
[1, 20721] loss_train: 0.009186, loss_test: 0.005542
time: 0.3050680160522461
time: 2.4771411418914795
[1, 20722] loss_train: 0.000954, loss_test: 0.005543
time: 0.2940659523010254
time: 2.5216076374053955
[1, 20723] loss_train: 0.009486, loss_test: 0.005541
time: 0.3030681610107422
time: 2.502185106277466
[1, 20724] loss_train: 0.015229, loss_test: 0.005530
time: 0.27807116508483887
time: 2.509906530380249
[1, 20725] loss_train: 0.000934, loss_test: 0.005529
time: 0.2960667610168457
time: 2.4826481342315674
[1, 20726] loss_train: 0.004705, loss_test: 0.005533
time: 0.2841031551361084
time: 2.46506404876709
[1, 20727] loss_train: 0.004970, loss_test: 0.005541
time: 0.2850625514984131
time: 2.481516122817993
[1, 20728] loss_train: 0.006551, loss_test: 0.005553
time: 0.2830624580383301
time: 2.4597978591918945
[1, 20729] loss_train: 0.010787, loss_test: 0.005561
time: 0.2830634117126465
time: 2.476365327835083
[1, 20730] loss_train: 0.009849, loss_test: 0.005565
time: 0.29607200622558594
time: 2.4607858657836914
[1, 20731] loss_train: 0.007976, loss_test: 0.005563
time: 0.2823913097381592
time: 2.4904661178588867
[1, 20732] loss_train: 0.009834, loss_test: 0.005558
time: 0.273510217666626
time: 2.4105753898620605
[1, 20733] loss_train: 0.000889, loss_test: 0.005552
time: 0.2830636501312256
time: 2.497380256652832
[1, 20734] loss_train: 0.002549, loss_test: 0.005545
time: 0.31506967544555664
time: 2.481778383255005
[1, 20735] loss_train: 0.006136, loss_test: 0.005539
time: 0.2890653610229492
time: 2.5061066150665283
[1, 20736] loss_train: 0.007694, loss_test: 0.005536
time: 0.2980661392211914
time: 2.478052854537964
[1, 20737] loss_train: 0.007190, loss_test: 0.005534
time: 0.29706716537475586
time: 2.4811959266662598
[1, 20738] loss_train: 0.006981, loss_test: 0.005533
time: 0.2815365791320801
time: 2.459071159362793
[1, 20739] loss_train: 0.006582, loss_test: 0.005533
time: 0.28624463081359863
time: 2.472553253173828
[1, 20740] loss_train: 0.008374, loss_test: 0.005534
time: 0.30406951904296875
time: 2.5212180614471436
[1, 20741] loss_train: 0.009728, loss_test: 0.005536
time: 0.2920651435852051
time: 2.493602752685547
[1, 20742] loss_train: 0.008404, loss_test: 0.005537
time: 0.27759718894958496
time: 2.646597385406494
[1, 20743] loss_train: 0.001537, loss_test: 0.005539
time: 0.2799828052520752
time: 2.4707443714141846
[1, 20744] loss_train: 0.000929, loss_test: 0.005538
time: 0.2752976417541504
time: 2.4480478763580322
[1, 20745] loss_train: 0.006297, loss_test: 0.005538
time: 0.2851901054382324
time: 2.437298536300659
[1, 20746] loss_train: 0.005846, loss_test: 0.005537
time: 0.27833008766174316
time: 2.525583505630493
[1, 20747] loss_train: 0.004282, loss_test: 0.005537
time: 0.2800619602203369
time: 2.3175220489501953
[1, 20748] loss_train: 0.011284, loss_test: 0.005542
time: 0.2830619812011719
time: 2.48336124420166
[1, 20749] loss_train: 0.006427, loss_test: 0.005547
time: 0.28496694564819336
time: 2.4535510540008545
[1, 20750] loss_train: 0.007020, loss_test: 0.005550
time: 0.32607316970825195
time: 2.5525271892547607
[1, 20751] loss_train: 0.005319, loss_test: 0.005547
time: 0.303070068359375
time: 2.5800535678863525
[1, 20752] loss_train: 0.006463, loss_test: 0.005541
time: 0.32207179069519043
time: 2.543644428253174
[1, 20753] loss_train: 0.008083, loss_test: 0.005543
time: 0.3140687942504883
time: 2.5395681858062744
[1, 20754] loss_train: 0.006099, loss_test: 0.005548
time: 0.30257248878479004
time: 2.5984139442443848
[1, 20755] loss_train: 0.008919, loss_test: 0.005558
time: 0.3060493469238281
time: 2.5693447589874268
[1, 20756] loss_train: 0.005874, loss_test: 0.005565
time: 0.3052501678466797
time: 2.5495193004608154
[1, 20757] loss_train: 0.009238, loss_test: 0.005574
time: 0.2994532585144043
time: 2.6015520095825195
[1, 20758] loss_train: 0.005016, loss_test: 0.005577
time: 0.32507753372192383
time: 2.5995287895202637
[1, 20759] loss_train: 0.004576, loss_test: 0.005574
time: 0.330519437789917
time: 2.5558648109436035
[1, 20760] loss_train: 0.001824, loss_test: 0.005576
time: 0.3400745391845703
time: 2.6319425106048584
[1, 20761] loss_train: 0.005693, loss_test: 0.005566
time: 0.33007359504699707
time: 2.5775763988494873
[1, 20762] loss_train: 0.000852, loss_test: 0.005550
time: 0.327073335647583
time: 2.6098501682281494
[1, 20763] loss_train: 0.005723, loss_test: 0.005541
time: 0.32407259941101074
time: 2.6000261306762695
[1, 20764] loss_train: 0.005394, loss_test: 0.005544
time: 0.3186216354370117
time: 2.575580596923828
[1, 20765] loss_train: 0.006740, loss_test: 0.005553
time: 0.3120696544647217
time: 2.5884246826171875
[1, 20766] loss_train: 0.003111, loss_test: 0.005569
time: 0.31193017959594727
time: 2.5763232707977295
[1, 20767] loss_train: 0.008115, loss_test: 0.005584
time: 0.3030667304992676
time: 2.5706286430358887
[1, 20768] loss_train: 0.005924, loss_test: 0.005596
time: 0.3180711269378662
time: 2.5603346824645996
[1, 20769] loss_train: 0.002327, loss_test: 0.005609
time: 0.3050813674926758
time: 2.5637028217315674
[1, 20770] loss_train: 0.000555, loss_test: 0.005624
time: 0.3260626792907715
time: 2.585132360458374
[1, 20771] loss_train: 0.008059, loss_test: 0.005629
time: 0.3220705986022949
time: 2.5663743019104004
[1, 20772] loss_train: 0.002608, loss_test: 0.005633
time: 0.3310723304748535
time: 2.5876142978668213
[1, 20773] loss_train: 0.011107, loss_test: 0.005620
time: 0.3030660152435303
time: 2.595580816268921
[1, 20774] loss_train: 0.002957, loss_test: 0.005608
time: 0.3070683479309082
time: 2.538996934890747
[1, 20775] loss_train: 0.003584, loss_test: 0.005599
time: 0.2980659008026123
time: 2.5535802841186523
[1, 20776] loss_train: 0.001828, loss_test: 0.005590
time: 0.2980661392211914
time: 2.5573172569274902
[1, 20777] loss_train: 0.007231, loss_test: 0.005582
time: 0.3020656108856201
time: 2.5399200916290283
[1, 20778] loss_train: 0.007992, loss_test: 0.005572
time: 0.30852389335632324
time: 2.538726806640625
[1, 20779] loss_train: 0.002093, loss_test: 0.005564
time: 0.30307626724243164
time: 2.5739192962646484
[1, 20780] loss_train: 0.009544, loss_test: 0.005553
time: 0.3250727653503418
time: 2.8546512126922607
[1, 20781] loss_train: 0.004205, loss_test: 0.005545
time: 0.31306958198547363
time: 2.6091182231903076
[1, 20782] loss_train: 0.006965, loss_test: 0.005535
time: 0.30706787109375
time: 2.6058247089385986
[1, 20783] loss_train: 0.001198, loss_test: 0.005532
time: 0.3063826560974121
time: 2.519524097442627
[1, 20784] loss_train: 0.010037, loss_test: 0.005528
time: 0.28802919387817383
time: 2.4401588439941406
[1, 20785] loss_train: 0.004351, loss_test: 0.005529
time: 0.28098082542419434
time: 2.589970350265503
[1, 20786] loss_train: 0.007148, loss_test: 0.005531
time: 0.2960655689239502
time: 2.474238872528076
[1, 20787] loss_train: 0.001916, loss_test: 0.005534
time: 0.292069673538208
time: 2.594268321990967
[1, 20788] loss_train: 0.012963, loss_test: 0.005537
time: 0.3610696792602539
time: 2.4826364517211914
[1, 20789] loss_train: 0.004025, loss_test: 0.005537
time: 0.2980661392211914
time: 2.4885928630828857
[1, 20790] loss_train: 0.003791, loss_test: 0.005535
time: 0.32407188415527344
time: 2.975062608718872
[1, 20791] loss_train: 0.008487, loss_test: 0.005525
time: 0.3070697784423828
time: 2.511697292327881
[1, 20792] loss_train: 0.012093, loss_test: 0.005521
time: 0.29006433486938477
time: 2.6539723873138428
[1, 20793] loss_train: 0.010378, loss_test: 0.005520
time: 0.29006385803222656
time: 2.4283649921417236
[1, 20794] loss_train: 0.003140, loss_test: 0.005520
time: 0.2834045886993408
time: 2.68463134765625
[1, 20795] loss_train: 0.013924, loss_test: 0.005520
time: 0.28606224060058594
time: 2.5071861743927
[1, 20796] loss_train: 0.011893, loss_test: 0.005519
time: 0.30706787109375
time: 2.4841384887695312
[1, 20797] loss_train: 0.005118, loss_test: 0.005519
time: 0.301410436630249
time: 2.433147668838501
[1, 20798] loss_train: 0.005498, loss_test: 0.005521
time: 0.27731871604919434
time: 2.449185848236084
[1, 20799] loss_train: 0.016534, loss_test: 0.005521
time: 0.27706170082092285
time: 2.450568437576294
[1, 20800] loss_train: 0.008322, loss_test: 0.005522
time: 0.3070685863494873
time: 2.477362871170044
[1, 20801] loss_train: 0.011193, loss_test: 0.005524
time: 0.27906274795532227
time: 2.4295248985290527
[1, 20802] loss_train: 0.001795, loss_test: 0.005526
time: 0.2890632152557373
time: 2.4543139934539795
[1, 20803] loss_train: 0.014502, loss_test: 0.005533
time: 0.2678077220916748
time: 2.6577115058898926
[1, 20804] loss_train: 0.003004, loss_test: 0.005544
time: 0.2912898063659668
time: 2.5718801021575928
[1, 20805] loss_train: 0.005874, loss_test: 0.005558
time: 0.26307106018066406
time: 2.41864013671875
[1, 20806] loss_train: 0.005539, loss_test: 0.005562
time: 0.27106213569641113
time: 2.4306602478027344
[1, 20807] loss_train: 0.000531, loss_test: 0.005562
time: 0.2785661220550537
time: 3.1650679111480713
[1, 20808] loss_train: 0.006113, loss_test: 0.005562
time: 0.2830629348754883
time: 2.5185892581939697
[1, 20809] loss_train: 0.012605, loss_test: 0.005560
time: 0.28806400299072266
time: 2.8216521739959717
[1, 20810] loss_train: 0.010181, loss_test: 0.005560
time: 0.3310737609863281
time: 2.319518566131592
[1, 20811] loss_train: 0.002563, loss_test: 0.005555
time: 0.2450547218322754
time: 2.2925162315368652
[1, 20812] loss_train: 0.005511, loss_test: 0.005550
time: 0.2470545768737793
time: 2.2765092849731445
[1, 20813] loss_train: 0.011003, loss_test: 0.005548
time: 0.24405407905578613
time: 2.3005154132843018
[1, 20814] loss_train: 0.003019, loss_test: 0.005545
time: 0.2740607261657715
time: 2.462162733078003
[1, 20815] loss_train: 0.001480, loss_test: 0.005542
time: 0.3770899772644043
time: 2.5642261505126953
[1, 20816] loss_train: 0.005144, loss_test: 0.005542
time: 0.29407620429992676
time: 2.5047571659088135
[1, 20817] loss_train: 0.009921, loss_test: 0.005543
time: 0.2903916835784912
time: 2.613919973373413
[1, 20818] loss_train: 0.008080, loss_test: 0.005542
time: 0.2940666675567627
time: 2.5417566299438477
[1, 20819] loss_train: 0.005203, loss_test: 0.005541
time: 0.29706668853759766
time: 2.548569679260254
[1, 20820] loss_train: 0.005554, loss_test: 0.005543
time: 0.32407188415527344
time: 2.5956099033355713
[1, 20821] loss_train: 0.001938, loss_test: 0.005549
time: 0.2910640239715576
time: 2.548839807510376
[1, 20822] loss_train: 0.003964, loss_test: 0.005558
time: 0.32807135581970215
time: 2.577805519104004
[1, 20823] loss_train: 0.001316, loss_test: 0.005570
time: 0.31107020378112793
time: 2.5679070949554443
[1, 20824] loss_train: 0.001672, loss_test: 0.005584
time: 0.2930636405944824
time: 2.549569606781006
[1, 20825] loss_train: 0.005592, loss_test: 0.005600
time: 0.30857157707214355
time: 2.560406446456909
[1, 20826] loss_train: 0.009404, loss_test: 0.005611
time: 0.2920675277709961
time: 2.5197629928588867
[1, 20827] loss_train: 0.008295, loss_test: 0.005613
time: 0.3040659427642822
time: 2.5418283939361572
[1, 20828] loss_train: 0.005253, loss_test: 0.005611
time: 0.3047153949737549
time: 2.575143814086914
[1, 20829] loss_train: 0.005651, loss_test: 0.005603
time: 0.30406737327575684
time: 2.543240785598755
[1, 20830] loss_train: 0.003569, loss_test: 0.005594
time: 0.3130669593811035
time: 2.588092088699341
[1, 20831] loss_train: 0.005809, loss_test: 0.005580
time: 0.2870640754699707
time: 2.5640780925750732
[1, 20832] loss_train: 0.007350, loss_test: 0.005567
time: 0.3090689182281494
time: 2.583627223968506
[1, 20833] loss_train: 0.010246, loss_test: 0.005553
time: 0.3290688991546631
time: 2.6241273880004883
[1, 20834] loss_train: 0.003669, loss_test: 0.005546
time: 0.32407069206237793
time: 2.6037280559539795
[1, 20835] loss_train: 0.006117, loss_test: 0.005544
time: 0.33007287979125977
time: 2.602085590362549
[1, 20836] loss_train: 0.004482, loss_test: 0.005545
time: 0.30606770515441895
time: 2.564795970916748
[1, 20837] loss_train: 0.001582, loss_test: 0.005548
time: 0.3030672073364258
time: 2.580723762512207
[1, 20838] loss_train: 0.005609, loss_test: 0.005553
time: 0.30526018142700195
time: 2.5660207271575928
[1, 20839] loss_train: 0.006016, loss_test: 0.005557
time: 0.3160703182220459
time: 2.552583932876587
[1, 20840] loss_train: 0.011228, loss_test: 0.005561
time: 0.33007335662841797
time: 2.587989091873169
[1, 20841] loss_train: 0.008882, loss_test: 0.005560
time: 0.2920646667480469
time: 2.529468536376953
[1, 20842] loss_train: 0.006392, loss_test: 0.005557
time: 0.3090682029724121
time: 2.5431020259857178
[1, 20843] loss_train: 0.004730, loss_test: 0.005555
time: 0.3074479103088379
time: 2.5813910961151123
[1, 20844] loss_train: 0.002352, loss_test: 0.005552
time: 0.29306459426879883
time: 2.530508279800415
[1, 20845] loss_train: 0.001745, loss_test: 0.005549
time: 0.29906678199768066
time: 2.4801456928253174
[1, 20846] loss_train: 0.003859, loss_test: 0.005545
time: 0.29612231254577637
time: 2.5321767330169678
[1, 20847] loss_train: 0.003741, loss_test: 0.005540
time: 0.28806447982788086
time: 2.5026350021362305
[1, 20848] loss_train: 0.004172, loss_test: 0.005537
time: 0.28945064544677734
time: 2.5217506885528564
[1, 20849] loss_train: 0.006687, loss_test: 0.005536
time: 0.2860686779022217
time: 2.551131010055542
[1, 20850] loss_train: 0.007136, loss_test: 0.005538
time: 0.32383108139038086
time: 2.5346155166625977
[1, 20851] loss_train: 0.015850, loss_test: 0.005532
time: 0.29306459426879883
time: 2.6206557750701904
[1, 20852] loss_train: 0.005281, loss_test: 0.005527
time: 0.30206751823425293
time: 2.629286050796509
[1, 20853] loss_train: 0.005463, loss_test: 0.005524
time: 0.3030672073364258
time: 2.592440605163574
[1, 20854] loss_train: 0.003255, loss_test: 0.005525
time: 0.30707216262817383
time: 2.5953495502471924
[1, 20855] loss_train: 0.004930, loss_test: 0.005528
time: 0.3000667095184326
time: 2.5851752758026123
[1, 20856] loss_train: 0.019214, loss_test: 0.005539
time: 0.2980659008026123
time: 2.625034809112549
[1, 20857] loss_train: 0.010081, loss_test: 0.005553
time: 0.3030669689178467
time: 2.5295019149780273
[1, 20858] loss_train: 0.008157, loss_test: 0.005558
time: 0.27706074714660645
time: 2.5805447101593018
[1, 20859] loss_train: 0.004962, loss_test: 0.005555
time: 0.3020670413970947
time: 2.4665517807006836
[1, 20860] loss_train: 0.005102, loss_test: 0.005547
time: 0.29906725883483887
time: 2.5125255584716797
[1, 20861] loss_train: 0.006265, loss_test: 0.005537
time: 0.28606319427490234
time: 2.462852954864502
[1, 20862] loss_train: 0.010781, loss_test: 0.005531
time: 0.2960660457611084
time: 2.5100719928741455
[1, 20863] loss_train: 0.003502, loss_test: 0.005525
time: 0.2920651435852051
time: 2.527280807495117
[1, 20864] loss_train: 0.003819, loss_test: 0.005524
time: 0.3110692501068115
time: 2.5226950645446777
[1, 20865] loss_train: 0.006320, loss_test: 0.005526
time: 0.31006884574890137
time: 2.486905336380005
[1, 20866] loss_train: 0.001672, loss_test: 0.005533
time: 0.28806328773498535
time: 2.4529082775115967
[1, 20867] loss_train: 0.004117, loss_test: 0.005542
time: 0.28806376457214355
time: 2.4905569553375244
[1, 20868] loss_train: 0.002952, loss_test: 0.005555
time: 0.28606271743774414
time: 2.4925577640533447
[1, 20869] loss_train: 0.000602, loss_test: 0.005572
time: 0.30406832695007324
time: 2.520565986633301
[1, 20870] loss_train: 0.004771, loss_test: 0.005588
time: 0.3140697479248047
time: 2.4699692726135254
[1, 20871] loss_train: 0.005602, loss_test: 0.005600
time: 0.28606319427490234
time: 2.4895436763763428
[1, 20872] loss_train: 0.009167, loss_test: 0.005601
time: 0.29257965087890625
time: 2.943067789077759
[1, 20873] loss_train: 0.008545, loss_test: 0.005599
time: 0.2993505001068115
time: 2.488309383392334
[1, 20874] loss_train: 0.010253, loss_test: 0.005592
time: 0.28129148483276367
time: 2.494004964828491
[1, 20875] loss_train: 0.014192, loss_test: 0.005572
time: 0.3290729522705078
time: 2.615295886993408
[1, 20876] loss_train: 0.008058, loss_test: 0.005555
time: 0.2960648536682129
time: 2.6954286098480225
[1, 20877] loss_train: 0.012308, loss_test: 0.005541
time: 0.2897329330444336
time: 2.8561410903930664
[1, 20878] loss_train: 0.001254, loss_test: 0.005536
time: 0.2930643558502197
time: 3.309166193008423
[1, 20879] loss_train: 0.005081, loss_test: 0.005534
time: 0.2920644283294678
time: 2.541132688522339
[1, 20880] loss_train: 0.008617, loss_test: 0.005535
time: 0.29306626319885254
time: 2.4846746921539307
[1, 20881] loss_train: 0.007247, loss_test: 0.005540
time: 0.3000810146331787
time: 3.018864631652832
[1, 20882] loss_train: 0.014333, loss_test: 0.005550
time: 0.32906508445739746
time: 2.490842819213867
[1, 20883] loss_train: 0.003045, loss_test: 0.005563
time: 0.2830626964569092
time: 2.51015305519104
[1, 20884] loss_train: 0.009477, loss_test: 0.005576
time: 0.27906060218811035
time: 2.6177213191986084
[1, 20885] loss_train: 0.014917, loss_test: 0.005581
time: 0.3135378360748291
time: 2.5045599937438965
[1, 20886] loss_train: 0.010147, loss_test: 0.005580
time: 0.2850627899169922
time: 2.4838147163391113
[1, 20887] loss_train: 0.011344, loss_test: 0.005573
time: 0.30089473724365234
time: 2.439657211303711
[1, 20888] loss_train: 0.000625, loss_test: 0.005570
time: 0.29106569290161133
time: 2.4757349491119385
[1, 20889] loss_train: 0.003929, loss_test: 0.005566
time: 0.29512643814086914
time: 2.483628273010254
[1, 20890] loss_train: 0.007678, loss_test: 0.005562
time: 0.3240809440612793
time: 2.4918720722198486
[1, 20891] loss_train: 0.006805, loss_test: 0.005555
time: 0.2870640754699707
time: 2.542579412460327
[1, 20892] loss_train: 0.005511, loss_test: 0.005550
time: 0.32206225395202637
time: 2.4965569972991943
[1, 20893] loss_train: 0.002990, loss_test: 0.005544
time: 0.3100707530975342
time: 2.473984718322754
[1, 20894] loss_train: 0.002960, loss_test: 0.005541
time: 0.29265332221984863
time: 2.558704376220703
[1, 20895] loss_train: 0.005788, loss_test: 0.005543
time: 0.5861499309539795
time: 2.5429656505584717
[1, 20896] loss_train: 0.002631, loss_test: 0.005550
time: 0.28807950019836426
time: 2.506702423095703
[1, 20897] loss_train: 0.003374, loss_test: 0.005562
time: 0.28806400299072266
time: 2.508117437362671
[1, 20898] loss_train: 0.004118, loss_test: 0.005575
time: 0.291064977645874
time: 2.9503703117370605
[1, 20899] loss_train: 0.008737, loss_test: 0.005586
time: 0.2830634117126465
time: 2.852660894393921
[1, 20900] loss_train: 0.003087, loss_test: 0.005595
time: 0.25905799865722656
time: 2.270507574081421
[1, 20901] loss_train: 0.015135, loss_test: 0.005577
time: 0.2620577812194824
time: 2.3235204219818115
[1, 20902] loss_train: 0.002565, loss_test: 0.005561
time: 0.24605369567871094
time: 2.394089937210083
[1, 20903] loss_train: 0.002140, loss_test: 0.005549
time: 0.32141661643981934
time: 2.530078649520874
[1, 20904] loss_train: 0.004540, loss_test: 0.005541
time: 0.30106663703918457
time: 2.49558424949646
[1, 20905] loss_train: 0.006088, loss_test: 0.005534
time: 0.33907508850097656
time: 2.5415797233581543
[1, 20906] loss_train: 0.007543, loss_test: 0.005527
time: 0.3050680160522461
time: 2.5425117015838623
[1, 20907] loss_train: 0.009616, loss_test: 0.005522
time: 0.33007383346557617
time: 2.5508501529693604
[1, 20908] loss_train: 0.001824, loss_test: 0.005521
time: 0.3235795497894287
time: 2.593555212020874
[1, 20909] loss_train: 0.007524, loss_test: 0.005522
time: 0.31307196617126465
time: 2.558182954788208
[1, 20910] loss_train: 0.006144, loss_test: 0.005526
time: 0.3160707950592041
time: 2.592289686203003
[1, 20911] loss_train: 0.007711, loss_test: 0.005529
time: 0.30106592178344727
time: 2.6126887798309326
[1, 20912] loss_train: 0.007264, loss_test: 0.005531
time: 0.31706953048706055
time: 2.5956852436065674
[1, 20913] loss_train: 0.004212, loss_test: 0.005533
time: 0.30107879638671875
time: 2.615809202194214
[1, 20914] loss_train: 0.001702, loss_test: 0.005532
time: 0.3030667304992676
time: 2.6044859886169434
[1, 20915] loss_train: 0.003936, loss_test: 0.005529
time: 0.3069791793823242
time: 2.53688383102417
[1, 20916] loss_train: 0.004139, loss_test: 0.005528
time: 0.3180718421936035
time: 2.578578472137451
[1, 20917] loss_train: 0.002591, loss_test: 0.005529
time: 0.31907057762145996
time: 2.583085298538208
[1, 20918] loss_train: 0.007165, loss_test: 0.005530
time: 0.32106971740722656
time: 2.554591655731201
[1, 20919] loss_train: 0.006061, loss_test: 0.005533
time: 0.32107114791870117
time: 2.565495729446411
[1, 20920] loss_train: 0.010062, loss_test: 0.005536
time: 0.34207630157470703
time: 2.553558588027954
[1, 20921] loss_train: 0.008930, loss_test: 0.005539
time: 0.29506969451904297
time: 2.548835515975952
[1, 20922] loss_train: 0.003533, loss_test: 0.005541
time: 0.3193984031677246
time: 2.539994716644287
[1, 20923] loss_train: 0.002383, loss_test: 0.005545
time: 0.2933669090270996
time: 2.522435188293457
[1, 20924] loss_train: 0.008368, loss_test: 0.005545
time: 0.3140702247619629
time: 2.587578535079956
[1, 20925] loss_train: 0.005605, loss_test: 0.005548
time: 0.3070688247680664
time: 2.5759167671203613
[1, 20926] loss_train: 0.005298, loss_test: 0.005548
time: 0.29724931716918945
time: 2.555581569671631
[1, 20927] loss_train: 0.004816, loss_test: 0.005551
time: 0.30196046829223633
time: 2.5635931491851807
[1, 20928] loss_train: 0.010955, loss_test: 0.005549
time: 0.30206751823425293
time: 2.5580310821533203
[1, 20929] loss_train: 0.008063, loss_test: 0.005544
time: 0.30106687545776367
time: 2.554457426071167
[1, 20930] loss_train: 0.005220, loss_test: 0.005539
time: 0.32007288932800293
time: 2.546210527420044
[1, 20931] loss_train: 0.005448, loss_test: 0.005535
time: 0.30206727981567383
time: 2.59694242477417
[1, 20932] loss_train: 0.003412, loss_test: 0.005534
time: 0.3020670413970947
time: 2.5409719944000244
[1, 20933] loss_train: 0.007850, loss_test: 0.005534
time: 0.29006361961364746
time: 2.571091651916504
[1, 20934] loss_train: 0.003707, loss_test: 0.005533
time: 0.3010678291320801
time: 2.584578037261963
[1, 20935] loss_train: 0.006796, loss_test: 0.005533
time: 0.3410780429840088
time: 2.5548603534698486
[1, 20936] loss_train: 0.003099, loss_test: 0.005534
time: 0.33602428436279297
time: 2.427319288253784
[1, 20937] loss_train: 0.002609, loss_test: 0.005537
time: 0.24805498123168945
time: 2.2725086212158203
[1, 20938] loss_train: 0.004576, loss_test: 0.005540
time: 0.261061429977417
time: 2.3265199661254883
[1, 20939] loss_train: 0.012017, loss_test: 0.005537
time: 0.25505614280700684
time: 2.3125171661376953
[1, 20940] loss_train: 0.003790, loss_test: 0.005535
time: 0.26205873489379883
time: 2.3515255451202393
[1, 20941] loss_train: 0.002837, loss_test: 0.005535
time: 0.25005578994750977
time: 2.357078790664673
[1, 20942] loss_train: 0.004594, loss_test: 0.005536
time: 0.29014039039611816
time: 2.5133297443389893
[1, 20943] loss_train: 0.002818, loss_test: 0.005536
time: 0.28893280029296875
time: 2.5680246353149414
[1, 20944] loss_train: 0.001871, loss_test: 0.005536
time: 0.29706621170043945
time: 2.5295653343200684
[1, 20945] loss_train: 0.002978, loss_test: 0.005537
time: 0.2920646667480469
time: 2.5680782794952393
[1, 20946] loss_train: 0.004348, loss_test: 0.005540
time: 0.2940647602081299
time: 2.5848121643066406
[1, 20947] loss_train: 0.005893, loss_test: 0.005543
time: 0.30606770515441895
time: 2.5214834213256836
[1, 20948] loss_train: 0.004233, loss_test: 0.005546
time: 0.3110687732696533
time: 2.5279948711395264
[1, 20949] loss_train: 0.003241, loss_test: 0.005548
time: 0.31237053871154785
time: 2.5293846130371094
[1, 20950] loss_train: 0.016113, loss_test: 0.005547
time: 0.33307433128356934
time: 2.5535714626312256
[1, 20951] loss_train: 0.013995, loss_test: 0.005545
time: 0.31907176971435547
time: 2.545443058013916
[1, 20952] loss_train: 0.008291, loss_test: 0.005547
time: 0.2920653820037842
time: 2.512564182281494
[1, 20953] loss_train: 0.006450, loss_test: 0.005552
time: 0.3005704879760742
time: 2.5435006618499756
[1, 20954] loss_train: 0.005632, loss_test: 0.005555
time: 0.28806471824645996
time: 2.52409029006958
[1, 20955] loss_train: 0.003345, loss_test: 0.005557
time: 0.28970956802368164
time: 2.559861898422241
[1, 20956] loss_train: 0.008513, loss_test: 0.005556
time: 0.320080041885376
time: 2.5362024307250977
[1, 20957] loss_train: 0.005117, loss_test: 0.005556
time: 0.31507039070129395
time: 2.552825450897217
[1, 20958] loss_train: 0.013579, loss_test: 0.005549
time: 0.2870640754699707
time: 2.501497507095337
[1, 20959] loss_train: 0.010085, loss_test: 0.005541
time: 0.28606462478637695
time: 2.514564275741577
[1, 20960] loss_train: 0.007748, loss_test: 0.005539
time: 0.3250720500946045
time: 2.5366148948669434
[1, 20961] loss_train: 0.008011, loss_test: 0.005538
time: 0.3110692501068115
time: 2.5231730937957764
[1, 20962] loss_train: 0.003124, loss_test: 0.005537
time: 0.3050675392150879
time: 2.546398162841797
[1, 20963] loss_train: 0.006887, loss_test: 0.005536
time: 0.28606390953063965
time: 2.476555585861206
[1, 20964] loss_train: 0.015221, loss_test: 0.005541
time: 0.29557108879089355
time: 2.5210821628570557
[1, 20965] loss_train: 0.004480, loss_test: 0.005547
time: 0.2920656204223633
time: 2.4739487171173096
[1, 20966] loss_train: 0.011422, loss_test: 0.005555
time: 0.2830631732940674
time: 2.4929490089416504
[1, 20967] loss_train: 0.006818, loss_test: 0.005557
time: 0.2910647392272949
time: 2.4765870571136475
[1, 20968] loss_train: 0.005776, loss_test: 0.005551
time: 0.3070685863494873
time: 2.489168643951416
[1, 20969] loss_train: 0.009780, loss_test: 0.005542
time: 0.2870638370513916
time: 2.51857328414917
[1, 20970] loss_train: 0.004200, loss_test: 0.005534
time: 0.34607601165771484
time: 2.505443572998047
[1, 20971] loss_train: 0.001440, loss_test: 0.005527
time: 0.2960655689239502
time: 2.5415687561035156
[1, 20972] loss_train: 0.007892, loss_test: 0.005520
time: 0.29706573486328125
time: 2.5400753021240234
[1, 20973] loss_train: 0.004099, loss_test: 0.005518
time: 0.29306507110595703
time: 2.715545654296875
[1, 20974] loss_train: 0.005283, loss_test: 0.005522
time: 0.2910645008087158
time: 2.490842342376709
[1, 20975] loss_train: 0.006327, loss_test: 0.005532
time: 0.2890641689300537
time: 2.5878231525421143
[1, 20976] loss_train: 0.010559, loss_test: 0.005544
time: 0.28041625022888184
time: 2.4265663623809814
[1, 20977] loss_train: 0.005025, loss_test: 0.005552
time: 0.27621006965637207
time: 2.4234848022460938
[1, 20978] loss_train: 0.009325, loss_test: 0.005558
time: 0.2820625305175781
time: 2.5472095012664795
[1, 20979] loss_train: 0.011205, loss_test: 0.005560
time: 0.28657007217407227
time: 2.577064275741577
[1, 20980] loss_train: 0.003222, loss_test: 0.005562
time: 0.3290724754333496
time: 2.5499773025512695
[1, 20981] loss_train: 0.008812, loss_test: 0.005550
time: 0.28406357765197754
time: 2.475787401199341
[1, 20982] loss_train: 0.003538, loss_test: 0.005543
time: 0.28806376457214355
time: 2.560281276702881
[1, 20983] loss_train: 0.000894, loss_test: 0.005540
time: 0.277268648147583
time: 2.4965646266937256
[1, 20984] loss_train: 0.012109, loss_test: 0.005535
time: 0.2780647277832031
time: 2.4767184257507324
[1, 20985] loss_train: 0.003623, loss_test: 0.005532
time: 0.27706217765808105
time: 2.4005422592163086
[1, 20986] loss_train: 0.004507, loss_test: 0.005531
time: 0.2942202091217041
time: 2.419555187225342
[1, 20987] loss_train: 0.012652, loss_test: 0.005530
time: 0.247053861618042
time: 2.358530282974243
[1, 20988] loss_train: 0.009981, loss_test: 0.005532
time: 0.2540550231933594
time: 2.3625288009643555
[1, 20989] loss_train: 0.008919, loss_test: 0.005535
time: 0.27706170082092285
time: 2.4290900230407715
[1, 20990] loss_train: 0.016823, loss_test: 0.005539
time: 0.3053395748138428
time: 2.451314687728882
[1, 20991] loss_train: 0.006084, loss_test: 0.005542
time: 0.27664828300476074
time: 2.408885955810547
[1, 20992] loss_train: 0.004878, loss_test: 0.005543
time: 0.2856762409210205
time: 2.6284873485565186
[1, 20993] loss_train: 0.012923, loss_test: 0.005545
time: 0.2800624370574951
time: 2.475745916366577
[1, 20994] loss_train: 0.003767, loss_test: 0.005559
time: 0.2870638370513916
time: 2.718247413635254
[1, 20995] loss_train: 0.010472, loss_test: 0.005574
time: 0.2809133529663086
time: 2.595158338546753
[1, 20996] loss_train: 0.001550, loss_test: 0.005593
time: 0.2850632667541504
time: 2.4558749198913574
[1, 20997] loss_train: 0.004639, loss_test: 0.005613
time: 0.2810630798339844
time: 2.427175521850586
[1, 20998] loss_train: 0.002986, loss_test: 0.005638
time: 0.2910752296447754
time: 2.4298248291015625
[1, 20999] loss_train: 0.001675, loss_test: 0.005664
time: 0.27306079864501953
time: 2.4484305381774902
[1, 21000] loss_train: 0.006193, loss_test: 0.005685
time: 0.2890636920928955
time: 2.440479278564453
[1, 21001] loss_train: 0.008287, loss_test: 0.005690
time: 0.2823011875152588
time: 2.4462549686431885
[1, 21002] loss_train: 0.004259, loss_test: 0.005696
time: 0.28106093406677246
time: 2.482938766479492
[1, 21003] loss_train: 0.007339, loss_test: 0.005689
time: 0.28406310081481934
time: 2.4487693309783936
[1, 21004] loss_train: 0.006600, loss_test: 0.005674
time: 0.2782714366912842
time: 2.417940855026245
[1, 21005] loss_train: 0.003401, loss_test: 0.005653
time: 0.2710602283477783
time: 2.4046504497528076
[1, 21006] loss_train: 0.004011, loss_test: 0.005636
time: 0.2940654754638672
time: 2.5261809825897217
[1, 21007] loss_train: 0.015909, loss_test: 0.005600
time: 0.27306103706359863
time: 2.5469417572021484
[1, 21008] loss_train: 0.005859, loss_test: 0.005575
time: 0.280062198638916
time: 2.4499332904815674
[1, 21009] loss_train: 0.001916, loss_test: 0.005563
time: 0.27987241744995117
time: 2.44301700592041
[1, 21010] loss_train: 0.007011, loss_test: 0.005554
time: 0.2980663776397705
time: 2.417358160018921
[1, 21011] loss_train: 0.012696, loss_test: 0.005553
time: 0.27407264709472656
time: 2.467566967010498
[1, 21012] loss_train: 0.001948, loss_test: 0.005558
time: 0.2710597515106201
time: 2.4228336811065674
[1, 21013] loss_train: 0.004595, loss_test: 0.005561
time: 0.28315234184265137
time: 2.412656784057617
[1, 21014] loss_train: 0.003387, loss_test: 0.005564
time: 0.2730088233947754
time: 2.4386203289031982
[1, 21015] loss_train: 0.004031, loss_test: 0.005566
time: 0.26903247833251953
time: 2.4412593841552734
[1, 21016] loss_train: 0.005192, loss_test: 0.005564
time: 0.27506136894226074
time: 2.4282431602478027
[1, 21017] loss_train: 0.002844, loss_test: 0.005560
time: 0.272066593170166
time: 2.410320281982422
[1, 21018] loss_train: 0.009402, loss_test: 0.005554
time: 0.2830636501312256
time: 2.464127779006958
[1, 21019] loss_train: 0.003982, loss_test: 0.005545
time: 0.2720601558685303
time: 2.4204399585723877
[1, 21020] loss_train: 0.001026, loss_test: 0.005537
time: 0.2910637855529785
time: 2.4483673572540283
[1, 21021] loss_train: 0.010245, loss_test: 0.005534
time: 0.2831251621246338
time: 2.401399850845337
[1, 21022] loss_train: 0.005322, loss_test: 0.005533
time: 0.290067195892334
time: 2.428414821624756
[1, 21023] loss_train: 0.002790, loss_test: 0.005537
time: 0.2673320770263672
time: 2.3977901935577393
[1, 21024] loss_train: 0.009389, loss_test: 0.005544
time: 0.27985715866088867
time: 2.4611425399780273
[1, 21025] loss_train: 0.003987, loss_test: 0.005553
time: 0.2776968479156494
time: 2.417959451675415
[1, 21026] loss_train: 0.008352, loss_test: 0.005558
time: 0.2740159034729004
time: 2.4325456619262695
[1, 21027] loss_train: 0.004506, loss_test: 0.005564
time: 0.27507472038269043
time: 2.4596972465515137
[1, 21028] loss_train: 0.010513, loss_test: 0.005568
time: 0.27103543281555176
time: 2.4509904384613037
[1, 21029] loss_train: 0.011982, loss_test: 0.005560
time: 0.280062198638916
time: 2.427870035171509
[1, 21030] loss_train: 0.006007, loss_test: 0.005544
time: 0.3320732116699219
time: 2.4547746181488037
[1, 21031] loss_train: 0.000876, loss_test: 0.005534
time: 0.2890942096710205
time: 2.4359681606292725
[1, 21032] loss_train: 0.009775, loss_test: 0.005533
time: 0.28306102752685547
time: 2.517181873321533
[1, 21033] loss_train: 0.004814, loss_test: 0.005537
time: 0.27393150329589844
time: 2.4362752437591553
[1, 21034] loss_train: 0.002244, loss_test: 0.005539
time: 0.26840949058532715
time: 2.479484796524048
[1, 21035] loss_train: 0.004331, loss_test: 0.005544
time: 0.2870640754699707
time: 2.4298689365386963
[1, 21036] loss_train: 0.004139, loss_test: 0.005549
time: 0.2750108242034912
time: 2.515249252319336
[1, 21037] loss_train: 0.004131, loss_test: 0.005554
time: 0.26990437507629395
time: 2.543923854827881
[1, 21038] loss_train: 0.001643, loss_test: 0.005560
time: 0.2764627933502197
time: 2.5245025157928467
[1, 21039] loss_train: 0.002740, loss_test: 0.005563
time: 0.2810628414154053
time: 2.435847520828247
[1, 21040] loss_train: 0.004705, loss_test: 0.005566
time: 0.28706836700439453
time: 2.4740519523620605
[1, 21041] loss_train: 0.011725, loss_test: 0.005566
time: 0.2870638370513916
time: 2.500095844268799
[1, 21042] loss_train: 0.010921, loss_test: 0.005557
time: 0.27306175231933594
time: 2.4588370323181152
[1, 21043] loss_train: 0.000333, loss_test: 0.005551
time: 0.27706146240234375
time: 2.420799970626831
[1, 21044] loss_train: 0.004883, loss_test: 0.005548
time: 0.27205967903137207
time: 2.4037156105041504
[1, 21045] loss_train: 0.004262, loss_test: 0.005544
time: 0.2890639305114746
time: 2.4098761081695557
[1, 21046] loss_train: 0.002079, loss_test: 0.005542
time: 0.2790670394897461
time: 2.3969690799713135
[1, 21047] loss_train: 0.006719, loss_test: 0.005541
time: 0.2690601348876953
time: 2.422541856765747
[1, 21048] loss_train: 0.003663, loss_test: 0.005541
time: 0.285062313079834
time: 2.4555976390838623
[1, 21049] loss_train: 0.011628, loss_test: 0.005533
time: 0.2675447463989258
time: 2.4883475303649902
[1, 21050] loss_train: 0.007878, loss_test: 0.005524
time: 0.2943732738494873
time: 2.4534051418304443
[1, 21051] loss_train: 0.008236, loss_test: 0.005520
time: 0.2866699695587158
time: 2.4597182273864746
[1, 21052] loss_train: 0.004905, loss_test: 0.005520
time: 0.27425694465637207
time: 2.4775218963623047
[1, 21053] loss_train: 0.006858, loss_test: 0.005523
time: 0.3101041316986084
time: 2.5571329593658447
[1, 21054] loss_train: 0.005902, loss_test: 0.005528
time: 0.2740609645843506
time: 2.347524404525757
[1, 21055] loss_train: 0.005046, loss_test: 0.005534
time: 0.2560567855834961
time: 2.3275210857391357
[1, 21056] loss_train: 0.004122, loss_test: 0.005536
time: 0.25505614280700684
time: 2.332521915435791
[1, 21057] loss_train: 0.006657, loss_test: 0.005537
time: 0.2870643138885498
time: 2.299514055252075
[1, 21058] loss_train: 0.009513, loss_test: 0.005538
time: 0.254058837890625
time: 2.329026699066162
[1, 21059] loss_train: 0.007993, loss_test: 0.005540
time: 0.24405455589294434
time: 2.30851674079895
[1, 21060] loss_train: 0.004139, loss_test: 0.005541
time: 0.3120706081390381
time: 2.4413249492645264
[1, 21061] loss_train: 0.006840, loss_test: 0.005545
time: 0.25705695152282715
time: 2.4497227668762207
[1, 21062] loss_train: 0.007437, loss_test: 0.005549
time: 0.2800617218017578
time: 2.519937515258789
[1, 21063] loss_train: 0.008105, loss_test: 0.005549
time: 0.28307032585144043
time: 2.529585361480713
[1, 21064] loss_train: 0.009536, loss_test: 0.005547
time: 0.2985861301422119
time: 2.5457699298858643
[1, 21065] loss_train: 0.004752, loss_test: 0.005547
time: 0.28413820266723633
time: 2.4886984825134277
[1, 21066] loss_train: 0.005641, loss_test: 0.005548
time: 0.28173375129699707
time: 2.497972249984741
[1, 21067] loss_train: 0.001866, loss_test: 0.005550
time: 0.291029691696167
time: 2.499462366104126
[1, 21068] loss_train: 0.004783, loss_test: 0.005553
time: 0.30507445335388184
time: 2.5338447093963623
[1, 21069] loss_train: 0.010618, loss_test: 0.005551
time: 0.29996156692504883
time: 2.7009851932525635
[1, 21070] loss_train: 0.007530, loss_test: 0.005551
time: 0.3128962516784668
time: 2.638517379760742
[1, 21071] loss_train: 0.005709, loss_test: 0.005553
time: 0.29006409645080566
time: 2.5621068477630615
[1, 21072] loss_train: 0.011082, loss_test: 0.005553
time: 0.29009294509887695
time: 2.4913907051086426
[1, 21073] loss_train: 0.003376, loss_test: 0.005555
time: 0.29475879669189453
time: 2.5303897857666016
[1, 21074] loss_train: 0.004328, loss_test: 0.005559
time: 0.28806543350219727
time: 2.53778338432312
[1, 21075] loss_train: 0.007456, loss_test: 0.005559
time: 0.2950751781463623
time: 2.478512763977051
[1, 21076] loss_train: 0.005188, loss_test: 0.005559
time: 0.2876420021057129
time: 2.476876735687256
[1, 21077] loss_train: 0.007582, loss_test: 0.005558
time: 0.27777600288391113
time: 2.5504097938537598
[1, 21078] loss_train: 0.009996, loss_test: 0.005559
time: 0.28326892852783203
time: 2.8102822303771973
[1, 21079] loss_train: 0.003853, loss_test: 0.005559
time: 0.2890646457672119
time: 2.6240041255950928
[1, 21080] loss_train: 0.003703, loss_test: 0.005559
time: 0.3111708164215088
time: 2.5453829765319824
[1, 21081] loss_train: 0.008538, loss_test: 0.005559
time: 0.2910642623901367
time: 2.5330183506011963
[1, 21082] loss_train: 0.008116, loss_test: 0.005557
time: 0.285811185836792
time: 2.7927558422088623
[1, 21083] loss_train: 0.009902, loss_test: 0.005556
time: 0.3000664710998535
time: 2.5825397968292236
[1, 21084] loss_train: 0.003046, loss_test: 0.005549
time: 0.29535341262817383
time: 2.524515151977539
[1, 21085] loss_train: 0.008546, loss_test: 0.005545
time: 0.30052900314331055
time: 2.4715874195098877
[1, 21086] loss_train: 0.000762, loss_test: 0.005541
time: 0.28627681732177734
time: 2.6270878314971924
[1, 21087] loss_train: 0.013405, loss_test: 0.005537
time: 0.45209670066833496
time: 2.6297643184661865
[1, 21088] loss_train: 0.002509, loss_test: 0.005534
time: 0.2870638370513916
time: 2.5837955474853516
[1, 21089] loss_train: 0.000636, loss_test: 0.005532
time: 0.30626773834228516
time: 2.7618565559387207
[1, 21090] loss_train: 0.004713, loss_test: 0.005532
time: 0.721142053604126
time: 2.56269907951355
[1, 21091] loss_train: 0.001417, loss_test: 0.005533
time: 0.2910652160644531
time: 2.5395290851593018
[1, 21092] loss_train: 0.015646, loss_test: 0.005538
time: 0.3070683479309082
time: 2.574463129043579
[1, 21093] loss_train: 0.005048, loss_test: 0.005544
time: 0.28606390953063965
time: 2.4603400230407715
[1, 21094] loss_train: 0.013712, loss_test: 0.005550
time: 0.3000679016113281
time: 2.5059731006622314
[1, 21095] loss_train: 0.004951, loss_test: 0.005554
time: 0.28321337699890137
time: 2.469801902770996
[1, 21096] loss_train: 0.002157, loss_test: 0.005560
time: 0.2982311248779297
time: 2.4673714637756348
[1, 21097] loss_train: 0.008731, loss_test: 0.005563
time: 0.2870635986328125
time: 2.5073659420013428
[1, 21098] loss_train: 0.011477, loss_test: 0.005561
time: 0.2962486743927002
time: 2.464972972869873
[1, 21099] loss_train: 0.006816, loss_test: 0.005557
time: 0.28806400299072266
time: 2.5508272647857666
[1, 21100] loss_train: 0.005642, loss_test: 0.005556
time: 0.31420469284057617
time: 2.502737045288086
[1, 21101] loss_train: 0.006546, loss_test: 0.005551
time: 0.29642701148986816
time: 2.477562665939331
[1, 21102] loss_train: 0.005117, loss_test: 0.005546
time: 0.28406310081481934
time: 2.490638256072998
[1, 21103] loss_train: 0.001584, loss_test: 0.005540
time: 0.2855677604675293
time: 2.457883358001709
[1, 21104] loss_train: 0.016053, loss_test: 0.005538
time: 0.2852942943572998
time: 2.469388008117676
[1, 21105] loss_train: 0.011781, loss_test: 0.005537
time: 0.28806376457214355
time: 2.5130817890167236
[1, 21106] loss_train: 0.003003, loss_test: 0.005539
time: 0.28606319427490234
time: 2.5594582557678223
[1, 21107] loss_train: 0.004139, loss_test: 0.005545
time: 0.287064790725708
time: 2.5666604042053223
[1, 21108] loss_train: 0.002225, loss_test: 0.005552
time: 0.28806424140930176
time: 2.524563789367676
[1, 21109] loss_train: 0.009407, loss_test: 0.005558
time: 0.28647541999816895
time: 2.515437126159668
[1, 21110] loss_train: 0.004388, loss_test: 0.005556
time: 0.3140697479248047
time: 2.510228395462036
[1, 21111] loss_train: 0.004483, loss_test: 0.005556
time: 0.28842735290527344
time: 2.5484237670898438
[1, 21112] loss_train: 0.007695, loss_test: 0.005556
time: 0.3007802963256836
time: 2.5601563453674316
[1, 21113] loss_train: 0.000547, loss_test: 0.005561
time: 0.2874784469604492
time: 2.7660071849823
[1, 21114] loss_train: 0.004002, loss_test: 0.005563
time: 0.2910652160644531
time: 2.674283266067505
[1, 21115] loss_train: 0.007673, loss_test: 0.005568
time: 0.2910606861114502
time: 2.5889010429382324
[1, 21116] loss_train: 0.003708, loss_test: 0.005571
time: 0.2870659828186035
time: 2.449063301086426
[1, 21117] loss_train: 0.014284, loss_test: 0.005567
time: 0.28575634956359863
time: 2.422922372817993
[1, 21118] loss_train: 0.003737, loss_test: 0.005562
time: 0.28606581687927246
time: 2.4345171451568604
[1, 21119] loss_train: 0.002335, loss_test: 0.005559
time: 0.2940659523010254
time: 2.436053514480591
[1, 21120] loss_train: 0.006071, loss_test: 0.005557
time: 0.30806827545166016
time: 2.4758927822113037
[1, 21121] loss_train: 0.002967, loss_test: 0.005555
time: 0.28534936904907227
time: 2.4544014930725098
[1, 21122] loss_train: 0.002856, loss_test: 0.005554
time: 0.2889549732208252
time: 2.43422269821167
[1, 21123] loss_train: 0.005802, loss_test: 0.005553
time: 0.2808401584625244
time: 2.422886371612549
[1, 21124] loss_train: 0.006439, loss_test: 0.005546
time: 0.28806400299072266
time: 2.4437694549560547
[1, 21125] loss_train: 0.007567, loss_test: 0.005539
time: 0.29271554946899414
time: 2.8660168647766113
[1, 21126] loss_train: 0.010397, loss_test: 0.005531
time: 0.306887149810791
time: 2.55686092376709
[1, 21127] loss_train: 0.006643, loss_test: 0.005525
time: 0.28965163230895996
time: 2.48568058013916
[1, 21128] loss_train: 0.001527, loss_test: 0.005527
time: 0.30440521240234375
time: 2.8412346839904785
[1, 21129] loss_train: 0.006931, loss_test: 0.005530
time: 0.44708943367004395
time: 2.566570997238159
[1, 21130] loss_train: 0.009109, loss_test: 0.005537
time: 0.31107020378112793
time: 2.6206889152526855
[1, 21131] loss_train: 0.010490, loss_test: 0.005542
time: 0.3480684757232666
time: 2.5849392414093018
[1, 21132] loss_train: 0.014094, loss_test: 0.005553
time: 0.292064905166626
time: 2.571162700653076
[1, 21133] loss_train: 0.007544, loss_test: 0.005562
time: 0.5728974342346191
time: 2.604487180709839
[1, 21134] loss_train: 0.004689, loss_test: 0.005558
time: 0.2910490036010742
time: 2.5197594165802
[1, 21135] loss_train: 0.017069, loss_test: 0.005557
time: 0.2960665225982666
time: 2.5095102787017822
[1, 21136] loss_train: 0.004347, loss_test: 0.005553
time: 0.28810834884643555
time: 2.504479169845581
[1, 21137] loss_train: 0.002544, loss_test: 0.005545
time: 0.29526424407958984
time: 2.475285053253174
[1, 21138] loss_train: 0.006812, loss_test: 0.005537
time: 0.2957267761230469
time: 2.5171353816986084
[1, 21139] loss_train: 0.003156, loss_test: 0.005528
time: 0.30106496810913086
time: 2.5285098552703857
[1, 21140] loss_train: 0.006578, loss_test: 0.005522
time: 0.3179924488067627
time: 2.5224356651306152
[1, 21141] loss_train: 0.007097, loss_test: 0.005524
time: 0.2864534854888916
time: 2.608867883682251
[1, 21142] loss_train: 0.004899, loss_test: 0.005533
time: 0.2800619602203369
time: 2.4733645915985107
[1, 21143] loss_train: 0.005355, loss_test: 0.005545
time: 0.2878420352935791
time: 3.4581851959228516
[1, 21144] loss_train: 0.004840, loss_test: 0.005558
time: 0.29007863998413086
time: 2.508561372756958
[1, 21145] loss_train: 0.010868, loss_test: 0.005563
time: 0.29006385803222656
time: 2.569328546524048
[1, 21146] loss_train: 0.007095, loss_test: 0.005567
time: 0.2895791530609131
time: 2.522076368331909
[1, 21147] loss_train: 0.007715, loss_test: 0.005567
time: 0.28836703300476074
time: 2.5107028484344482
[1, 21148] loss_train: 0.005037, loss_test: 0.005571
time: 0.3012814521789551
time: 2.4978201389312744
[1, 21149] loss_train: 0.002187, loss_test: 0.005573
time: 0.29033899307250977
time: 2.456193447113037
[1, 21150] loss_train: 0.007638, loss_test: 0.005577
time: 0.3026144504547119
time: 2.4753341674804688
[1, 21151] loss_train: 0.009383, loss_test: 0.005583
time: 0.29566431045532227
time: 2.4810478687286377
[1, 21152] loss_train: 0.003637, loss_test: 0.005590
time: 0.28606200218200684
time: 2.467247247695923
[1, 21153] loss_train: 0.009535, loss_test: 0.005588
time: 0.2914121150970459
time: 2.4708411693573
[1, 21154] loss_train: 0.007250, loss_test: 0.005584
time: 0.2904205322265625
time: 2.5852513313293457
[1, 21155] loss_train: 0.011259, loss_test: 0.005577
time: 0.28606319427490234
time: 2.4762096405029297
[1, 21156] loss_train: 0.007540, loss_test: 0.005558
time: 0.2769613265991211
time: 2.4845967292785645
[1, 21157] loss_train: 0.004909, loss_test: 0.005546
time: 0.2834455966949463
time: 2.7005646228790283
[1, 21158] loss_train: 0.005970, loss_test: 0.005542
time: 0.2863175868988037
time: 2.545531749725342
[1, 21159] loss_train: 0.005272, loss_test: 0.005545
time: 0.29372477531433105
time: 2.838273048400879
[1, 21160] loss_train: 0.007621, loss_test: 0.005553
time: 0.3090691566467285
time: 2.5544707775115967
[1, 21161] loss_train: 0.004369, loss_test: 0.005560
time: 0.29837489128112793
time: 2.8007330894470215
[1, 21162] loss_train: 0.011098, loss_test: 0.005561
time: 0.288543701171875
time: 2.6070327758789062
[1, 21163] loss_train: 0.001829, loss_test: 0.005558
time: 0.29958438873291016
time: 2.661817789077759
[1, 21164] loss_train: 0.003699, loss_test: 0.005555
time: 0.2910645008087158
time: 2.551182508468628
[1, 21165] loss_train: 0.006792, loss_test: 0.005549
time: 0.2884640693664551
time: 2.6044936180114746
[1, 21166] loss_train: 0.011033, loss_test: 0.005544
time: 0.2877371311187744
time: 2.459925413131714
[1, 21167] loss_train: 0.003894, loss_test: 0.005534
time: 0.27506136894226074
time: 2.418344020843506
[1, 21168] loss_train: 0.003695, loss_test: 0.005524
time: 0.28206396102905273
time: 2.4214980602264404
[1, 21169] loss_train: 0.005563, loss_test: 0.005521
time: 0.2960677146911621
time: 2.4526054859161377
[1, 21170] loss_train: 0.008293, loss_test: 0.005522
time: 0.3019883632659912
time: 2.5234599113464355
[1, 21171] loss_train: 0.002358, loss_test: 0.005530
time: 0.28757452964782715
time: 2.5149788856506348
[1, 21172] loss_train: 0.002885, loss_test: 0.005543
time: 0.2826375961303711
time: 2.5129754543304443
[1, 21173] loss_train: 0.001817, loss_test: 0.005557
time: 0.2931811809539795
time: 2.499490261077881
[1, 21174] loss_train: 0.006715, loss_test: 0.005570
time: 0.29106569290161133
time: 2.4443602561950684
[1, 21175] loss_train: 0.010046, loss_test: 0.005569
time: 0.2792820930480957
time: 2.712691307067871
[1, 21176] loss_train: 0.018360, loss_test: 0.005559
time: 0.2870643138885498
time: 2.496181011199951
[1, 21177] loss_train: 0.000840, loss_test: 0.005556
time: 0.27760863304138184
time: 2.45084810256958
[1, 21178] loss_train: 0.005709, loss_test: 0.005556
time: 0.27906107902526855
time: 2.474614143371582
[1, 21179] loss_train: 0.002884, loss_test: 0.005555
time: 0.2866699695587158
time: 2.401339054107666
[1, 21180] loss_train: 0.002895, loss_test: 0.005548
time: 0.31306886672973633
time: 2.438112258911133
[1, 21181] loss_train: 0.003522, loss_test: 0.005537
time: 0.2800557613372803
time: 2.4604852199554443
[1, 21182] loss_train: 0.004012, loss_test: 0.005527
time: 0.2815120220184326
time: 2.6449203491210938
[1, 21183] loss_train: 0.003230, loss_test: 0.005520
time: 0.536649227142334
time: 2.582484722137451
[1, 21184] loss_train: 0.006480, loss_test: 0.005518
time: 0.2890665531158447
time: 2.5793135166168213
[1, 21185] loss_train: 0.006780, loss_test: 0.005522
time: 0.30106616020202637
time: 2.541416645050049
[1, 21186] loss_train: 0.006521, loss_test: 0.005529
time: 0.2820625305175781
time: 2.48020601272583
[1, 21187] loss_train: 0.003912, loss_test: 0.005534
time: 0.2857167720794678
time: 2.495681047439575
[1, 21188] loss_train: 0.003574, loss_test: 0.005538
time: 0.2850029468536377
time: 2.5509989261627197
[1, 21189] loss_train: 0.002827, loss_test: 0.005540
time: 0.28610706329345703
time: 2.6549298763275146
[1, 21190] loss_train: 0.005975, loss_test: 0.005542
time: 0.30606770515441895
time: 2.4752755165100098
[1, 21191] loss_train: 0.004578, loss_test: 0.005543
time: 0.28543639183044434
time: 2.566408634185791
[1, 21192] loss_train: 0.009208, loss_test: 0.005538
time: 0.28606343269348145
time: 2.5921385288238525
[1, 21193] loss_train: 0.001637, loss_test: 0.005536
time: 0.28806447982788086
time: 2.46742582321167
[1, 21194] loss_train: 0.004053, loss_test: 0.005536
time: 0.28606486320495605
time: 2.459373950958252
[1, 21195] loss_train: 0.006181, loss_test: 0.005536
time: 0.28806376457214355
time: 2.4876129627227783
[1, 21196] loss_train: 0.004139, loss_test: 0.005536
time: 0.2968711853027344
time: 2.5374436378479004
[1, 21197] loss_train: 0.002500, loss_test: 0.005537
time: 0.30759596824645996
time: 2.477764129638672
[1, 21198] loss_train: 0.020725, loss_test: 0.005529
time: 0.28894662857055664
time: 2.48661732673645
[1, 21199] loss_train: 0.003726, loss_test: 0.005530
time: 0.29332423210144043
time: 2.471416473388672
[1, 21200] loss_train: 0.000582, loss_test: 0.005540
time: 0.29607295989990234
time: 2.6063451766967773
[1, 21201] loss_train: 0.006475, loss_test: 0.005553
time: 0.3265974521636963
time: 2.474008083343506
[1, 21202] loss_train: 0.004028, loss_test: 0.005570
time: 0.2764275074005127
time: 2.4505977630615234
[1, 21203] loss_train: 0.007512, loss_test: 0.005581
time: 0.27391934394836426
time: 2.5270941257476807
[1, 21204] loss_train: 0.003257, loss_test: 0.005587
time: 0.28515005111694336
time: 2.556492805480957
[1, 21205] loss_train: 0.010663, loss_test: 0.005588
time: 0.30406761169433594
time: 2.5576844215393066
[1, 21206] loss_train: 0.001408, loss_test: 0.005593
time: 0.28039026260375977
time: 2.5617520809173584
[1, 21207] loss_train: 0.001010, loss_test: 0.005598
time: 0.31307005882263184
time: 2.526404619216919
[1, 21208] loss_train: 0.002097, loss_test: 0.005602
time: 0.29506707191467285
time: 2.5419564247131348
[1, 21209] loss_train: 0.007853, loss_test: 0.005580
time: 0.28106188774108887
time: 2.527078151702881
[1, 21210] loss_train: 0.014761, loss_test: 0.005558
time: 0.30706787109375
time: 2.54524564743042
[1, 21211] loss_train: 0.008603, loss_test: 0.005535
time: 0.30011963844299316
time: 2.5495710372924805
[1, 21212] loss_train: 0.007004, loss_test: 0.005521
time: 0.29471659660339355
time: 2.571829319000244
[1, 21213] loss_train: 0.004699, loss_test: 0.005515
time: 0.30907177925109863
time: 2.547412633895874
[1, 21214] loss_train: 0.006828, loss_test: 0.005516
time: 0.32407259941101074
time: 2.531602144241333
[1, 21215] loss_train: 0.008665, loss_test: 0.005517
time: 0.3160696029663086
time: 2.5856056213378906
[1, 21216] loss_train: 0.004651, loss_test: 0.005521
time: 0.31507158279418945
time: 2.5876259803771973
[1, 21217] loss_train: 0.004500, loss_test: 0.005525
time: 0.3220710754394531
time: 2.596359968185425
[1, 21218] loss_train: 0.003537, loss_test: 0.005530
time: 0.31006789207458496
time: 2.533337354660034
[1, 21219] loss_train: 0.004823, loss_test: 0.005536
time: 0.30062174797058105
time: 2.5344417095184326
[1, 21220] loss_train: 0.002938, loss_test: 0.005542
time: 0.3160688877105713
time: 2.5786445140838623
[1, 21221] loss_train: 0.006191, loss_test: 0.005547
time: 0.3000807762145996
time: 2.6140780448913574
[1, 21222] loss_train: 0.007738, loss_test: 0.005552
time: 0.30606698989868164
time: 2.54617977142334
[1, 21223] loss_train: 0.001005, loss_test: 0.005559
time: 0.2835683822631836
time: 2.552079200744629
[1, 21224] loss_train: 0.006560, loss_test: 0.005565
time: 0.2900824546813965
time: 2.5228641033172607
[1, 21225] loss_train: 0.001345, loss_test: 0.005571
time: 0.2970716953277588
time: 2.5013630390167236
[1, 21226] loss_train: 0.002235, loss_test: 0.005580
time: 0.30806803703308105
time: 2.5470776557922363
[1, 21227] loss_train: 0.000772, loss_test: 0.005592
time: 0.30406951904296875
time: 2.532468318939209
[1, 21228] loss_train: 0.003186, loss_test: 0.005607
time: 0.29306459426879883
time: 2.5353310108184814
[1, 21229] loss_train: 0.008982, loss_test: 0.005626
time: 0.2940680980682373
time: 2.5418009757995605
[1, 21230] loss_train: 0.006100, loss_test: 0.005641
time: 0.30362415313720703
time: 2.4769182205200195
[1, 21231] loss_train: 0.009755, loss_test: 0.005640
time: 0.28606319427490234
time: 2.5222065448760986
[1, 21232] loss_train: 0.005298, loss_test: 0.005638
time: 0.31707072257995605
time: 2.5575735569000244
[1, 21233] loss_train: 0.009982, loss_test: 0.005612
time: 0.2967722415924072
time: 2.485011339187622
[1, 21234] loss_train: 0.012947, loss_test: 0.005574
time: 0.29893946647644043
time: 2.5848021507263184
[1, 21235] loss_train: 0.005659, loss_test: 0.005548
time: 0.3080720901489258
time: 2.568873882293701
[1, 21236] loss_train: 0.002916, loss_test: 0.005534
time: 0.28324460983276367
time: 2.521916389465332
[1, 21237] loss_train: 0.005664, loss_test: 0.005527
time: 0.2993199825286865
time: 2.5377557277679443
[1, 21238] loss_train: 0.005000, loss_test: 0.005528
time: 0.3050684928894043
time: 2.52681040763855
[1, 21239] loss_train: 0.000688, loss_test: 0.005536
time: 0.289675235748291
time: 2.5472424030303955
[1, 21240] loss_train: 0.006834, loss_test: 0.005551
time: 0.30406713485717773
time: 2.5032613277435303
[1, 21241] loss_train: 0.008166, loss_test: 0.005568
time: 0.3000671863555908
time: 2.502183675765991
[1, 21242] loss_train: 0.005569, loss_test: 0.005584
time: 0.30452799797058105
time: 2.550844430923462
[1, 21243] loss_train: 0.001772, loss_test: 0.005586
time: 0.30206775665283203
time: 2.5106637477874756
[1, 21244] loss_train: 0.010759, loss_test: 0.005577
time: 0.2859537601470947
time: 2.547680377960205
[1, 21245] loss_train: 0.016300, loss_test: 0.005565
time: 0.30106687545776367
time: 2.483872175216675
[1, 21246] loss_train: 0.007636, loss_test: 0.005553
time: 0.2980673313140869
time: 2.5075604915618896
[1, 21247] loss_train: 0.006247, loss_test: 0.005542
time: 0.32607173919677734
time: 2.508603096008301
[1, 21248] loss_train: 0.005731, loss_test: 0.005532
time: 0.2980663776397705
time: 2.5112626552581787
[1, 21249] loss_train: 0.005181, loss_test: 0.005522
time: 0.301724910736084
time: 2.5357627868652344
[1, 21250] loss_train: 0.002514, loss_test: 0.005518
time: 0.3211812973022461
time: 2.52347993850708
[1, 21251] loss_train: 0.008811, loss_test: 0.005520
time: 0.3200714588165283
time: 2.543560266494751
[1, 21252] loss_train: 0.004576, loss_test: 0.005526
time: 0.2899892330169678
time: 2.526853322982788
[1, 21253] loss_train: 0.007984, loss_test: 0.005532
time: 0.29506468772888184
time: 2.5151612758636475
[1, 21254] loss_train: 0.001842, loss_test: 0.005542
time: 0.30481433868408203
time: 2.489884614944458
[1, 21255] loss_train: 0.006625, loss_test: 0.005552
time: 0.28406357765197754
time: 2.544156789779663
[1, 21256] loss_train: 0.005798, loss_test: 0.005563
time: 0.2923543453216553
time: 2.498619794845581
[1, 21257] loss_train: 0.003035, loss_test: 0.005575
time: 0.3070681095123291
time: 2.517561674118042
[1, 21258] loss_train: 0.022520, loss_test: 0.005591
time: 0.3030674457550049
time: 2.5067100524902344
[1, 21259] loss_train: 0.003301, loss_test: 0.005604
time: 0.3200702667236328
time: 2.555575370788574
[1, 21260] loss_train: 0.007471, loss_test: 0.005603
time: 0.33461952209472656
time: 2.492342472076416
[1, 21261] loss_train: 0.006517, loss_test: 0.005594
time: 0.3084526062011719
time: 2.509341239929199
[1, 21262] loss_train: 0.007609, loss_test: 0.005573
time: 0.3030672073364258
time: 2.5397961139678955
[1, 21263] loss_train: 0.006311, loss_test: 0.005549
time: 0.334073543548584
time: 2.5727219581604004
[1, 21264] loss_train: 0.008836, loss_test: 0.005535
time: 0.3099396228790283
time: 2.5165634155273438
[1, 21265] loss_train: 0.001339, loss_test: 0.005530
time: 0.29006385803222656
time: 2.5317037105560303
[1, 21266] loss_train: 0.001044, loss_test: 0.005528
time: 0.2920699119567871
time: 2.513854503631592
[1, 21267] loss_train: 0.004942, loss_test: 0.005527
time: 0.3020670413970947
time: 2.5444421768188477
[1, 21268] loss_train: 0.005535, loss_test: 0.005526
time: 0.3110697269439697
time: 2.49772047996521
[1, 21269] loss_train: 0.003410, loss_test: 0.005525
time: 0.29706645011901855
time: 2.518374443054199
[1, 21270] loss_train: 0.011853, loss_test: 0.005524
time: 0.32050132751464844
time: 2.518710136413574
[1, 21271] loss_train: 0.003245, loss_test: 0.005522
time: 0.3140690326690674
time: 2.5161144733428955
[1, 21272] loss_train: 0.006075, loss_test: 0.005521
time: 0.3090684413909912
time: 2.522094964981079
[1, 21273] loss_train: 0.013763, loss_test: 0.005520
time: 0.2820100784301758
time: 2.5257439613342285
[1, 21274] loss_train: 0.006531, loss_test: 0.005520
time: 0.29407525062561035
time: 2.5055625438690186
[1, 21275] loss_train: 0.005238, loss_test: 0.005521
time: 0.31525635719299316
time: 2.4750053882598877
[1, 21276] loss_train: 0.005644, loss_test: 0.005523
time: 0.29308032989501953
time: 2.5292394161224365
[1, 21277] loss_train: 0.008977, loss_test: 0.005526
time: 0.3000659942626953
time: 2.524878740310669
[1, 21278] loss_train: 0.003541, loss_test: 0.005528
time: 0.30406689643859863
time: 2.527773141860962
[1, 21279] loss_train: 0.005163, loss_test: 0.005528
time: 0.31951141357421875
time: 2.47167706489563
[1, 21280] loss_train: 0.006203, loss_test: 0.005528
time: 0.32107067108154297
time: 2.5037264823913574
[1, 21281] loss_train: 0.007626, loss_test: 0.005527
time: 0.30406808853149414
time: 2.4999148845672607
[1, 21282] loss_train: 0.005196, loss_test: 0.005526
time: 0.3261241912841797
time: 2.5272345542907715
[1, 21283] loss_train: 0.003921, loss_test: 0.005526
time: 0.31612348556518555
time: 2.485323429107666
[1, 21284] loss_train: 0.011654, loss_test: 0.005525
time: 0.2870643138885498
time: 2.486504316329956
[1, 21285] loss_train: 0.005621, loss_test: 0.005525
time: 0.2980656623840332
time: 2.5225718021392822
[1, 21286] loss_train: 0.011514, loss_test: 0.005524
time: 0.309067964553833
time: 2.538163185119629
[1, 21287] loss_train: 0.010539, loss_test: 0.005522
time: 0.2870633602142334
time: 2.514631509780884
[1, 21288] loss_train: 0.008410, loss_test: 0.005524
time: 0.2830638885498047
time: 2.5325193405151367
[1, 21289] loss_train: 0.006857, loss_test: 0.005530
time: 0.327073335647583
time: 2.5566437244415283
[1, 21290] loss_train: 0.005649, loss_test: 0.005541
time: 0.3100697994232178
time: 2.5185625553131104
[1, 21291] loss_train: 0.002302, loss_test: 0.005553
time: 0.29706597328186035
time: 2.5215847492218018
[1, 21292] loss_train: 0.002473, loss_test: 0.005559
time: 0.28806424140930176
time: 2.5204737186431885
[1, 21293] loss_train: 0.005835, loss_test: 0.005563
time: 0.30406713485717773
time: 2.5222103595733643
[1, 21294] loss_train: 0.003583, loss_test: 0.005564
time: 0.2960383892059326
time: 2.5472614765167236
[1, 21295] loss_train: 0.001045, loss_test: 0.005561
time: 0.28406739234924316
time: 2.5335164070129395
[1, 21296] loss_train: 0.002703, loss_test: 0.005555
time: 0.30106639862060547
time: 2.509899139404297
[1, 21297] loss_train: 0.010654, loss_test: 0.005548
time: 0.2870631217956543
time: 2.453106164932251
[1, 21298] loss_train: 0.003729, loss_test: 0.005539
time: 0.30806851387023926
time: 2.5233893394470215
[1, 21299] loss_train: 0.001104, loss_test: 0.005532
time: 0.28134608268737793
time: 2.4678499698638916
[1, 21300] loss_train: 0.006010, loss_test: 0.005528
time: 0.31907129287719727
time: 2.5691051483154297
[1, 21301] loss_train: 0.005491, loss_test: 0.005529
time: 0.3200709819793701
time: 2.5545778274536133
[1, 21302] loss_train: 0.014481, loss_test: 0.005531
time: 0.31907033920288086
time: 2.4824254512786865
[1, 21303] loss_train: 0.004466, loss_test: 0.005535
time: 0.281353235244751
time: 2.546832323074341
[1, 21304] loss_train: 0.003984, loss_test: 0.005542
time: 0.2830638885498047
time: 2.5035898685455322
[1, 21305] loss_train: 0.010142, loss_test: 0.005544
time: 0.292064905166626
time: 2.4934048652648926
[1, 21306] loss_train: 0.006611, loss_test: 0.005544
time: 0.28349733352661133
time: 2.481844902038574
[1, 21307] loss_train: 0.002126, loss_test: 0.005545
time: 0.2920653820037842
time: 2.490709066390991
[1, 21308] loss_train: 0.008316, loss_test: 0.005545
time: 0.2874457836151123
time: 2.502678871154785
[1, 21309] loss_train: 0.010451, loss_test: 0.005543
time: 0.31808042526245117
time: 2.520778179168701
[1, 21310] loss_train: 0.011081, loss_test: 0.005535
time: 0.3060767650604248
time: 2.541857957839966
[1, 21311] loss_train: 0.006337, loss_test: 0.005532
time: 0.3130683898925781
time: 2.519298791885376
[1, 21312] loss_train: 0.001618, loss_test: 0.005530
time: 0.31306958198547363
time: 2.5698516368865967
[1, 21313] loss_train: 0.005349, loss_test: 0.005528
time: 0.3180704116821289
time: 2.527211904525757
[1, 21314] loss_train: 0.003164, loss_test: 0.005527
time: 0.29006457328796387
time: 2.5052356719970703
[1, 21315] loss_train: 0.008930, loss_test: 0.005527
time: 0.29906654357910156
time: 2.514650821685791
[1, 21316] loss_train: 0.011261, loss_test: 0.005529
time: 0.2953341007232666
time: 2.556363105773926
[1, 21317] loss_train: 0.001499, loss_test: 0.005530
time: 0.2850635051727295
time: 2.485915184020996
[1, 21318] loss_train: 0.007495, loss_test: 0.005531
time: 0.30106687545776367
time: 2.5331408977508545
[1, 21319] loss_train: 0.004685, loss_test: 0.005531
time: 0.30406689643859863
time: 2.5384140014648438
[1, 21320] loss_train: 0.015051, loss_test: 0.005532
time: 0.3160707950592041
time: 2.528412342071533
[1, 21321] loss_train: 0.006685, loss_test: 0.005531
time: 0.2923593521118164
time: 2.5103023052215576
[1, 21322] loss_train: 0.005911, loss_test: 0.005529
time: 0.3110694885253906
time: 2.5350804328918457
[1, 21323] loss_train: 0.011166, loss_test: 0.005529
time: 0.3090689182281494
time: 2.469322919845581
[1, 21324] loss_train: 0.010956, loss_test: 0.005528
time: 0.29807233810424805
time: 2.502774477005005
[1, 21325] loss_train: 0.004083, loss_test: 0.005528
time: 0.3095893859863281
time: 2.5345816612243652
[1, 21326] loss_train: 0.003574, loss_test: 0.005526
time: 0.28197741508483887
time: 2.514545440673828
[1, 21327] loss_train: 0.014358, loss_test: 0.005526
time: 0.32907652854919434
time: 2.519390106201172
[1, 21328] loss_train: 0.005582, loss_test: 0.005526
time: 0.30107545852661133
time: 2.505589485168457
[1, 21329] loss_train: 0.004925, loss_test: 0.005526
time: 0.2939877510070801
time: 2.516580581665039
[1, 21330] loss_train: 0.001967, loss_test: 0.005526
time: 0.3130788803100586
time: 2.5279974937438965
[1, 21331] loss_train: 0.001018, loss_test: 0.005527
time: 0.31206822395324707
time: 2.5464260578155518
[1, 21332] loss_train: 0.003628, loss_test: 0.005531
time: 0.2870633602142334
time: 2.525773525238037
[1, 21333] loss_train: 0.001193, loss_test: 0.005536
time: 0.3250718116760254
time: 2.5318801403045654
[1, 21334] loss_train: 0.006603, loss_test: 0.005544
time: 0.30606842041015625
time: 2.5165345668792725
[1, 21335] loss_train: 0.006029, loss_test: 0.005550
time: 0.30806946754455566
time: 2.560044765472412
[1, 21336] loss_train: 0.004245, loss_test: 0.005556
time: 0.291064977645874
time: 2.5494885444641113
[1, 21337] loss_train: 0.011386, loss_test: 0.005558
time: 0.31907129287719727
time: 2.4977004528045654
[1, 21338] loss_train: 0.009028, loss_test: 0.005559
time: 0.2890634536743164
time: 2.4833106994628906
[1, 21339] loss_train: 0.001432, loss_test: 0.005562
time: 0.2980661392211914
time: 2.483229637145996
[1, 21340] loss_train: 0.000544, loss_test: 0.005566
time: 0.31507015228271484
time: 2.53024959564209
[1, 21341] loss_train: 0.012881, loss_test: 0.005556
time: 0.2960660457611084
time: 2.4781808853149414
[1, 21342] loss_train: 0.010148, loss_test: 0.005541
time: 0.2930622100830078
time: 2.5234568119049072
[1, 21343] loss_train: 0.003488, loss_test: 0.005532
time: 0.29506516456604004
time: 2.550034761428833
[1, 21344] loss_train: 0.003298, loss_test: 0.005528
time: 0.2910642623901367
time: 2.545858144760132
[1, 21345] loss_train: 0.009024, loss_test: 0.005531
time: 0.2973778247833252
time: 2.5440099239349365
[1, 21346] loss_train: 0.004326, loss_test: 0.005537
time: 0.2965705394744873
time: 2.5160443782806396
[1, 21347] loss_train: 0.009568, loss_test: 0.005546
time: 0.296065092086792
time: 2.4991443157196045
[1, 21348] loss_train: 0.005843, loss_test: 0.005557
time: 0.2848043441772461
time: 2.4867727756500244
[1, 21349] loss_train: 0.000572, loss_test: 0.005567
time: 0.28406214714050293
time: 2.520489454269409
[1, 21350] loss_train: 0.003464, loss_test: 0.005577
time: 0.31498098373413086
time: 2.515446424484253
[1, 21351] loss_train: 0.003894, loss_test: 0.005585
time: 0.28206300735473633
time: 2.5079550743103027
[1, 21352] loss_train: 0.001874, loss_test: 0.005593
time: 0.3020660877227783
time: 2.470726251602173
[1, 21353] loss_train: 0.005270, loss_test: 0.005597
time: 0.29927873611450195
time: 2.4832704067230225
[1, 21354] loss_train: 0.006606, loss_test: 0.005595
time: 0.3020665645599365
time: 2.5138766765594482
[1, 21355] loss_train: 0.004991, loss_test: 0.005588
time: 0.3010671138763428
time: 2.5562222003936768
[1, 21356] loss_train: 0.004673, loss_test: 0.005581
time: 0.2960050106048584
time: 2.5189731121063232
[1, 21357] loss_train: 0.005873, loss_test: 0.005571
time: 0.33197712898254395
time: 2.562002420425415
[1, 21358] loss_train: 0.007703, loss_test: 0.005559
time: 0.2991514205932617
time: 2.5038323402404785
[1, 21359] loss_train: 0.003428, loss_test: 0.005549
time: 0.2890636920928955
time: 2.545581102371216
[1, 21360] loss_train: 0.004606, loss_test: 0.005542
time: 0.3027784824371338
time: 2.5335865020751953
[1, 21361] loss_train: 0.007462, loss_test: 0.005537
time: 0.29895997047424316
time: 2.5384938716888428
[1, 21362] loss_train: 0.001171, loss_test: 0.005535
time: 0.2980666160583496
time: 2.552440643310547
[1, 21363] loss_train: 0.005458, loss_test: 0.005535
time: 0.290569543838501
time: 2.525958299636841
[1, 21364] loss_train: 0.004906, loss_test: 0.005537
time: 0.30803894996643066
time: 2.510068416595459
[1, 21365] loss_train: 0.002129, loss_test: 0.005540
time: 0.3090682029724121
time: 2.5175766944885254
[1, 21366] loss_train: 0.012271, loss_test: 0.005541
time: 0.29755544662475586
time: 2.4995880126953125
[1, 21367] loss_train: 0.004743, loss_test: 0.005543
time: 0.28406190872192383
time: 2.5350847244262695
[1, 21368] loss_train: 0.002930, loss_test: 0.005545
time: 0.3040733337402344
time: 2.524799346923828
[1, 21369] loss_train: 0.009383, loss_test: 0.005545
time: 0.2980673313140869
time: 2.518972635269165
[1, 21370] loss_train: 0.014987, loss_test: 0.005535
time: 0.3030667304992676
time: 2.51096773147583
[1, 21371] loss_train: 0.008205, loss_test: 0.005534
time: 0.28841614723205566
time: 2.5664215087890625
[1, 21372] loss_train: 0.003793, loss_test: 0.005542
time: 0.2890639305114746
time: 2.520580291748047
[1, 21373] loss_train: 0.006491, loss_test: 0.005557
time: 0.2990391254425049
time: 2.506441354751587
[1, 21374] loss_train: 0.008906, loss_test: 0.005570
time: 0.3120694160461426
time: 2.5113368034362793
[1, 21375] loss_train: 0.006449, loss_test: 0.005585
time: 0.30565428733825684
time: 2.5134494304656982
[1, 21376] loss_train: 0.003671, loss_test: 0.005600
time: 0.30606842041015625
time: 2.5502657890319824
[1, 21377] loss_train: 0.003553, loss_test: 0.005611
time: 0.30341339111328125
time: 2.497934341430664
[1, 21378] loss_train: 0.003338, loss_test: 0.005614
time: 0.29006385803222656
time: 2.4526329040527344
[1, 21379] loss_train: 0.015878, loss_test: 0.005602
time: 0.2870633602142334
time: 2.5015599727630615
[1, 21380] loss_train: 0.002159, loss_test: 0.005585
time: 0.31707119941711426
time: 2.5076420307159424
[1, 21381] loss_train: 0.003946, loss_test: 0.005573
time: 0.2870676517486572
time: 2.4880523681640625
[1, 21382] loss_train: 0.000921, loss_test: 0.005564
time: 0.3084447383880615
time: 2.524563789367676
[1, 21383] loss_train: 0.009928, loss_test: 0.005557
time: 0.28406214714050293
time: 2.6134514808654785
[1, 21384] loss_train: 0.002291, loss_test: 0.005550
time: 0.278062105178833
time: 2.529822587966919
[1, 21385] loss_train: 0.001497, loss_test: 0.005546
time: 0.30606794357299805
time: 2.6612844467163086
[1, 21386] loss_train: 0.009471, loss_test: 0.005541
time: 0.29506516456604004
time: 2.4871790409088135
[1, 21387] loss_train: 0.005951, loss_test: 0.005535
time: 0.3270723819732666
time: 2.5411577224731445
[1, 21388] loss_train: 0.005479, loss_test: 0.005533
time: 0.2881033420562744
time: 2.5319881439208984
[1, 21389] loss_train: 0.009117, loss_test: 0.005533
time: 0.3090682029724121
time: 2.4875810146331787
[1, 21390] loss_train: 0.010764, loss_test: 0.005535
time: 0.29831695556640625
time: 2.5512855052948
[1, 21391] loss_train: 0.003807, loss_test: 0.005540
time: 0.2910640239715576
time: 2.514343500137329
[1, 21392] loss_train: 0.004903, loss_test: 0.005546
time: 0.3050670623779297
time: 2.518218517303467
[1, 21393] loss_train: 0.006626, loss_test: 0.005557
time: 0.28154587745666504
time: 2.4927265644073486
[1, 21394] loss_train: 0.013423, loss_test: 0.005563
time: 0.2819054126739502
time: 2.4980850219726562
[1, 21395] loss_train: 0.009057, loss_test: 0.005569
time: 0.2850630283355713
time: 2.5059564113616943
[1, 21396] loss_train: 0.007211, loss_test: 0.005572
time: 0.30106687545776367
time: 2.51507306098938
[1, 21397] loss_train: 0.009785, loss_test: 0.005576
time: 0.31306934356689453
time: 2.5900678634643555
[1, 21398] loss_train: 0.012218, loss_test: 0.005578
time: 0.2731294631958008
time: 2.4469997882843018
[1, 21399] loss_train: 0.007909, loss_test: 0.005579
time: 0.2740616798400879
time: 2.4314510822296143
[1, 21400] loss_train: 0.009656, loss_test: 0.005580
time: 0.30988359451293945
time: 2.4626617431640625
[1, 21401] loss_train: 0.006179, loss_test: 0.005572
time: 0.27806687355041504
time: 2.712153196334839
[1, 21402] loss_train: 0.009892, loss_test: 0.005564
time: 0.2760629653930664
time: 2.474940061569214
[1, 21403] loss_train: 0.003312, loss_test: 0.005558
time: 0.27506136894226074
time: 2.4726450443267822
[1, 21404] loss_train: 0.002751, loss_test: 0.005544
time: 0.2610602378845215
time: 2.4192259311676025
[1, 21405] loss_train: 0.004222, loss_test: 0.005534
time: 0.2780580520629883
time: 2.4307467937469482
[1, 21406] loss_train: 0.014806, loss_test: 0.005528
time: 0.2660861015319824
time: 2.6069631576538086
[1, 21407] loss_train: 0.004982, loss_test: 0.005524
time: 0.27413392066955566
time: 2.456627368927002
[1, 21408] loss_train: 0.005057, loss_test: 0.005520
time: 0.27550315856933594
time: 2.4597203731536865
[1, 21409] loss_train: 0.003069, loss_test: 0.005519
time: 0.26721858978271484
time: 2.458390474319458
[1, 21410] loss_train: 0.010272, loss_test: 0.005520
time: 0.29805564880371094
time: 2.4364421367645264
[1, 21411] loss_train: 0.006647, loss_test: 0.005524
time: 0.2868471145629883
time: 2.4400899410247803
[1, 21412] loss_train: 0.003660, loss_test: 0.005530
time: 0.2752797603607178
time: 2.5917270183563232
[1, 21413] loss_train: 0.013174, loss_test: 0.005535
time: 0.3413820266723633
time: 2.7389719486236572
[1, 21414] loss_train: 0.005197, loss_test: 0.005539
time: 0.28106260299682617
time: 2.560973882675171
[1, 21415] loss_train: 0.004046, loss_test: 0.005545
time: 0.2755763530731201
time: 2.4611077308654785
[1, 21416] loss_train: 0.014635, loss_test: 0.005538
time: 0.28906798362731934
time: 2.391615390777588
[1, 21417] loss_train: 0.002794, loss_test: 0.005531
time: 0.25736427307128906
time: 2.8659563064575195
[1, 21418] loss_train: 0.007023, loss_test: 0.005525
time: 0.3144500255584717
time: 2.447547435760498
[1, 21419] loss_train: 0.009911, loss_test: 0.005524
time: 0.2700612545013428
time: 2.5439934730529785
[1, 21420] loss_train: 0.008998, loss_test: 0.005529
time: 0.26405954360961914
time: 2.7107620239257812
[1, 21421] loss_train: 0.003162, loss_test: 0.005533
time: 0.2552361488342285
time: 2.4075675010681152
[1, 21422] loss_train: 0.003494, loss_test: 0.005538
time: 0.48710060119628906
time: 2.5415799617767334
[1, 21423] loss_train: 0.009569, loss_test: 0.005547
time: 0.26306724548339844
time: 2.647247076034546
[1, 21424] loss_train: 0.012705, loss_test: 0.005564
time: 0.2760605812072754
time: 2.7047815322875977
[1, 21425] loss_train: 0.013464, loss_test: 0.005588
time: 0.3160698413848877
time: 2.5087358951568604
[1, 21426] loss_train: 0.002292, loss_test: 0.005594
time: 0.26206254959106445
time: 2.4764339923858643
[1, 21427] loss_train: 0.012177, loss_test: 0.005597
time: 0.35920166969299316
time: 2.5525712966918945
[1, 21428] loss_train: 0.010493, loss_test: 0.005592
time: 0.2760612964630127
time: 2.4740560054779053
[1, 21429] loss_train: 0.006681, loss_test: 0.005581
time: 0.27506089210510254
time: 2.656597137451172
[1, 21430] loss_train: 0.009789, loss_test: 0.005573
time: 0.3000659942626953
time: 2.5566091537475586
[1, 21431] loss_train: 0.003274, loss_test: 0.005557
time: 0.33606553077697754
time: 2.719621419906616
[1, 21432] loss_train: 0.001496, loss_test: 0.005547
time: 0.7336599826812744
time: 3.0112967491149902
[1, 21433] loss_train: 0.000773, loss_test: 0.005533
time: 0.27274537086486816
time: 2.562272310256958
[1, 21434] loss_train: 0.011862, loss_test: 0.005528
time: 0.2740499973297119
time: 2.52482271194458
[1, 21435] loss_train: 0.009096, loss_test: 0.005526
time: 0.27094435691833496
time: 2.4775540828704834
[1, 21436] loss_train: 0.002957, loss_test: 0.005523
time: 0.2940695285797119
time: 2.8670997619628906
[1, 21437] loss_train: 0.006143, loss_test: 0.005525
time: 0.2910647392272949
time: 2.560572862625122
[1, 21438] loss_train: 0.001152, loss_test: 0.005527
time: 0.280062198638916
time: 2.4315524101257324
[1, 21439] loss_train: 0.004376, loss_test: 0.005532
time: 0.2880716323852539
time: 2.404531717300415
[1, 21440] loss_train: 0.003219, loss_test: 0.005538
time: 0.2800617218017578
time: 2.727020740509033
[1, 21441] loss_train: 0.000565, loss_test: 0.005547
time: 0.27402234077453613
time: 2.5937066078186035
[1, 21442] loss_train: 0.005638, loss_test: 0.005554
time: 0.27675557136535645
time: 2.3665294647216797
[1, 21443] loss_train: 0.005044, loss_test: 0.005556
time: 0.2620582580566406
time: 2.7565689086914062
[1, 21444] loss_train: 0.012737, loss_test: 0.005544
time: 0.2670602798461914
time: 2.452880620956421
[1, 21445] loss_train: 0.004830, loss_test: 0.005529
time: 0.272411584854126
time: 2.455052375793457
[1, 21446] loss_train: 0.009470, loss_test: 0.005516
time: 0.27006006240844727
time: 2.4370694160461426
[1, 21447] loss_train: 0.004331, loss_test: 0.005510
time: 0.2750523090362549
time: 2.653104066848755
[1, 21448] loss_train: 0.007478, loss_test: 0.005509
time: 0.257568359375
time: 2.4196560382843018
[1, 21449] loss_train: 0.011634, loss_test: 0.005510
time: 0.2711782455444336
time: 2.413595676422119
[1, 21450] loss_train: 0.004356, loss_test: 0.005515
time: 0.27506256103515625
time: 2.3950393199920654
[1, 21451] loss_train: 0.005131, loss_test: 0.005520
time: 0.2600572109222412
time: 2.4725534915924072
[1, 21452] loss_train: 0.014633, loss_test: 0.005526
time: 0.26605963706970215
time: 2.4560558795928955
[1, 21453] loss_train: 0.004064, loss_test: 0.005533
time: 0.2605607509613037
time: 2.4665613174438477
[1, 21454] loss_train: 0.005916, loss_test: 0.005540
time: 0.25906991958618164
time: 2.4235503673553467
[1, 21455] loss_train: 0.002875, loss_test: 0.005547
time: 0.26406121253967285
time: 2.3915462493896484
[1, 21456] loss_train: 0.003977, loss_test: 0.005540
time: 0.26305246353149414
time: 2.4225587844848633
[1, 21457] loss_train: 0.007223, loss_test: 0.005534
time: 0.2699713706970215
time: 2.5285580158233643
[1, 21458] loss_train: 0.009858, loss_test: 0.005528
time: 0.267564058303833
time: 2.5767197608947754
[1, 21459] loss_train: 0.008163, loss_test: 0.005525
time: 0.26404547691345215
time: 2.428105592727661
[1, 21460] loss_train: 0.009707, loss_test: 0.005518
time: 0.2759249210357666
time: 2.501354217529297
[1, 21461] loss_train: 0.005250, loss_test: 0.005516
time: 0.26960229873657227
time: 2.3975372314453125
[1, 21462] loss_train: 0.005204, loss_test: 0.005519
time: 0.2650623321533203
time: 2.5081663131713867
[1, 21463] loss_train: 0.014447, loss_test: 0.005526
time: 0.26500916481018066
time: 2.384183406829834
[1, 21464] loss_train: 0.020333, loss_test: 0.005535
time: 0.2600576877593994
time: 2.3795461654663086
[1, 21465] loss_train: 0.007401, loss_test: 0.005543
time: 0.25905752182006836
time: 2.4295461177825928
[1, 21466] loss_train: 0.007417, loss_test: 0.005552
time: 0.2690596580505371
time: 2.379533052444458
[1, 21467] loss_train: 0.003365, loss_test: 0.005561
time: 0.25905704498291016
time: 2.4025559425354004
[1, 21468] loss_train: 0.004407, loss_test: 0.005569
time: 0.2602579593658447
time: 2.498171329498291
[1, 21469] loss_train: 0.005619, loss_test: 0.005574
time: 0.2666149139404297
time: 2.3723995685577393
[1, 21470] loss_train: 0.007667, loss_test: 0.005577
time: 0.3258938789367676
time: 2.4599006175994873
[1, 21471] loss_train: 0.009419, loss_test: 0.005577
time: 0.26616597175598145
time: 2.4350759983062744
[1, 21472] loss_train: 0.006586, loss_test: 0.005577
time: 0.2600572109222412
time: 2.5245652198791504
[1, 21473] loss_train: 0.008756, loss_test: 0.005577
time: 0.2710592746734619
time: 2.4230282306671143
[1, 21474] loss_train: 0.007078, loss_test: 0.005576
time: 0.2600588798522949
time: 2.542590618133545
[1, 21475] loss_train: 0.005807, loss_test: 0.005573
time: 0.2580575942993164
time: 2.427675724029541
[1, 21476] loss_train: 0.005740, loss_test: 0.005567
time: 0.2600581645965576
time: 2.375652551651001
[1, 21477] loss_train: 0.002252, loss_test: 0.005562
time: 0.2600579261779785
time: 2.382309913635254
[1, 21478] loss_train: 0.001653, loss_test: 0.005561
time: 0.2670598030090332
time: 2.480070114135742
[1, 21479] loss_train: 0.001918, loss_test: 0.005564
time: 0.25705718994140625
time: 2.446547269821167
[1, 21480] loss_train: 0.004909, loss_test: 0.005567
time: 0.2780616283416748
time: 2.5170681476593018
[1, 21481] loss_train: 0.003558, loss_test: 0.005569
time: 0.2600579261779785
time: 2.4595494270324707
[1, 21482] loss_train: 0.005187, loss_test: 0.005571
time: 0.25905871391296387
time: 2.440702199935913
[1, 21483] loss_train: 0.018235, loss_test: 0.005554
time: 0.27167654037475586
time: 2.481825351715088
[1, 21484] loss_train: 0.012308, loss_test: 0.005537
time: 0.2620582580566406
time: 2.5055606365203857
[1, 21485] loss_train: 0.001127, loss_test: 0.005533
time: 0.2710607051849365
time: 2.3855268955230713
[1, 21486] loss_train: 0.010038, loss_test: 0.005537
time: 0.2630589008331299
time: 2.4714467525482178
[1, 21487] loss_train: 0.007734, loss_test: 0.005550
time: 0.2630584239959717
time: 2.4280481338500977
[1, 21488] loss_train: 0.004907, loss_test: 0.005566
time: 0.26105809211730957
time: 2.4871082305908203
[1, 21489] loss_train: 0.010469, loss_test: 0.005580
time: 0.25806379318237305
time: 2.466156482696533
[1, 21490] loss_train: 0.011647, loss_test: 0.005595
time: 0.27606201171875
time: 2.4032342433929443
[1, 21491] loss_train: 0.007415, loss_test: 0.005594
time: 0.2600574493408203
time: 2.4154834747314453
[1, 21492] loss_train: 0.013626, loss_test: 0.005588
time: 0.26006507873535156
time: 2.4467825889587402
[1, 21493] loss_train: 0.005555, loss_test: 0.005568
time: 0.2620673179626465
time: 2.473059892654419
[1, 21494] loss_train: 0.004293, loss_test: 0.005548
time: 0.2690596580505371
time: 2.396040201187134
[1, 21495] loss_train: 0.005507, loss_test: 0.005536
time: 0.27506208419799805
time: 2.407540798187256
[1, 21496] loss_train: 0.001396, loss_test: 0.005531
time: 0.25905752182006836
time: 2.4515480995178223
[1, 21497] loss_train: 0.008907, loss_test: 0.005535
time: 0.269059419631958
time: 2.4790163040161133
[1, 21498] loss_train: 0.004901, loss_test: 0.005546
time: 0.26009106636047363
time: 2.474778175354004
[1, 21499] loss_train: 0.006710, loss_test: 0.005557
time: 0.26477742195129395
time: 2.3825325965881348
[1, 21500] loss_train: 0.007833, loss_test: 0.005565
time: 0.27606201171875
time: 2.431997776031494
[1, 21501] loss_train: 0.008817, loss_test: 0.005566
time: 0.2890002727508545
time: 2.3794620037078857
[1, 21502] loss_train: 0.012586, loss_test: 0.005562
time: 0.2630589008331299
time: 2.3805348873138428
[1, 21503] loss_train: 0.004763, loss_test: 0.005557
time: 0.26405882835388184
time: 2.4835543632507324
[1, 21504] loss_train: 0.004608, loss_test: 0.005551
time: 0.26205873489379883
time: 2.384036064147949
[1, 21505] loss_train: 0.005538, loss_test: 0.005547
time: 0.2650589942932129
time: 2.4825541973114014
[1, 21506] loss_train: 0.005860, loss_test: 0.005535
time: 0.27906250953674316
time: 2.4655544757843018
[1, 21507] loss_train: 0.018638, loss_test: 0.005532
time: 0.26563382148742676
time: 2.6214871406555176
[1, 21508] loss_train: 0.001571, loss_test: 0.005531
time: 0.26160526275634766
time: 2.419543504714966
[1, 21509] loss_train: 0.009788, loss_test: 0.005529
time: 0.26006007194519043
time: 2.39438533782959
[1, 21510] loss_train: 0.007762, loss_test: 0.005528
time: 0.27506113052368164
time: 2.6090872287750244
[1, 21511] loss_train: 0.003945, loss_test: 0.005526
time: 0.2600572109222412
time: 2.6486008167266846
[1, 21512] loss_train: 0.000999, loss_test: 0.005523
time: 0.2710607051849365
time: 2.5995676517486572
[1, 21513] loss_train: 0.004520, loss_test: 0.005522
time: 0.26105761528015137
time: 2.5011000633239746
[1, 21514] loss_train: 0.002352, loss_test: 0.005519
time: 0.26605892181396484
time: 2.4915568828582764
[1, 21515] loss_train: 0.008717, loss_test: 0.005518
time: 0.26105833053588867
time: 2.358034133911133
[1, 21516] loss_train: 0.004188, loss_test: 0.005518
time: 0.2630581855773926
time: 2.3495254516601562
[1, 21517] loss_train: 0.002017, loss_test: 0.005518
time: 0.27506160736083984
time: 2.4181761741638184
[1, 21518] loss_train: 0.008501, loss_test: 0.005520
time: 0.25819993019104004
time: 2.54556941986084
[1, 21519] loss_train: 0.004493, loss_test: 0.005524
time: 0.2710604667663574
time: 2.4277737140655518
[1, 21520] loss_train: 0.010091, loss_test: 0.005526
time: 0.2740614414215088
time: 2.4008233547210693
[1, 21521] loss_train: 0.008971, loss_test: 0.005527
time: 0.263059139251709
time: 2.5295684337615967
[1, 21522] loss_train: 0.004626, loss_test: 0.005528
time: 0.2600572109222412
time: 2.544076442718506
[1, 21523] loss_train: 0.008063, loss_test: 0.005528
time: 0.26105785369873047
time: 2.4245424270629883
[1, 21524] loss_train: 0.001604, loss_test: 0.005529
time: 0.25905871391296387
time: 2.5437629222869873
[1, 21525] loss_train: 0.006680, loss_test: 0.005531
time: 0.2600572109222412
time: 2.4741392135620117
[1, 21526] loss_train: 0.005488, loss_test: 0.005532
time: 0.25905752182006836
time: 2.416959524154663
[1, 21527] loss_train: 0.006197, loss_test: 0.005531
time: 0.26206016540527344
time: 2.4168474674224854
[1, 21528] loss_train: 0.004711, loss_test: 0.005532
time: 0.2670588493347168
time: 2.452341079711914
[1, 21529] loss_train: 0.008566, loss_test: 0.005531
time: 0.25905680656433105
time: 2.533567190170288
[1, 21530] loss_train: 0.014863, loss_test: 0.005529
time: 0.33957958221435547
time: 2.419321298599243
[1, 21531] loss_train: 0.003493, loss_test: 0.005528
time: 0.2635633945465088
time: 2.424294948577881
[1, 21532] loss_train: 0.005525, loss_test: 0.005530
time: 0.27706146240234375
time: 2.367919683456421
[1, 21533] loss_train: 0.007773, loss_test: 0.005532
time: 0.30406785011291504
time: 2.4480552673339844
[1, 21534] loss_train: 0.005372, loss_test: 0.005535
time: 0.2470548152923584
time: 2.4398434162139893
[1, 21535] loss_train: 0.001436, loss_test: 0.005538
time: 0.25005602836608887
time: 2.3005268573760986
[1, 21536] loss_train: 0.009880, loss_test: 0.005543
time: 0.2450556755065918
time: 2.3115170001983643
[1, 21537] loss_train: 0.002384, loss_test: 0.005547
time: 0.24505400657653809
time: 2.3215198516845703
[1, 21538] loss_train: 0.001724, loss_test: 0.005552
time: 0.2630577087402344
time: 2.3120224475860596
[1, 21539] loss_train: 0.003719, loss_test: 0.005558
time: 0.289064884185791
time: 2.338524103164673
[1, 21540] loss_train: 0.003933, loss_test: 0.005563
time: 0.2650599479675293
time: 2.313516855239868
[1, 21541] loss_train: 0.005613, loss_test: 0.005566
time: 0.2470543384552002
time: 2.28251314163208
[1, 21542] loss_train: 0.018135, loss_test: 0.005565
time: 0.2470550537109375
time: 2.270508289337158
[1, 21543] loss_train: 0.002643, loss_test: 0.005564
time: 0.24405431747436523
time: 2.3145174980163574
[1, 21544] loss_train: 0.005099, loss_test: 0.005562
time: 0.2450549602508545
time: 2.3525280952453613
[1, 21545] loss_train: 0.014373, loss_test: 0.005554
time: 0.25005578994750977
time: 2.3125200271606445
[1, 21546] loss_train: 0.011307, loss_test: 0.005544
time: 0.2490546703338623
time: 2.2643580436706543
[1, 21547] loss_train: 0.009809, loss_test: 0.005532
time: 0.2450549602508545
time: 2.2885115146636963
[1, 21548] loss_train: 0.004557, loss_test: 0.005524
time: 0.2510554790496826
time: 2.360541820526123
[1, 21549] loss_train: 0.017196, loss_test: 0.005519
time: 0.28606319427490234
time: 2.2865114212036133
[1, 21550] loss_train: 0.002515, loss_test: 0.005520
time: 0.2620584964752197
time: 2.5415687561035156
[1, 21551] loss_train: 0.003495, loss_test: 0.005524
time: 0.31306910514831543
time: 2.3650259971618652
[1, 21552] loss_train: 0.008866, loss_test: 0.005529
time: 0.31006908416748047
time: 2.473464250564575
[1, 21553] loss_train: 0.003602, loss_test: 0.005531
time: 0.4594266414642334
time: 2.4825406074523926
[1, 21554] loss_train: 0.001735, loss_test: 0.005533
time: 0.30776143074035645
time: 2.4582955837249756
[1, 21555] loss_train: 0.003476, loss_test: 0.005534
time: 0.2714419364929199
time: 2.5280699729919434
[1, 21556] loss_train: 0.008436, loss_test: 0.005532
time: 0.2630586624145508
time: 2.6225996017456055
[1, 21557] loss_train: 0.002143, loss_test: 0.005525
time: 0.2690460681915283
time: 2.4545490741729736
[1, 21558] loss_train: 0.004477, loss_test: 0.005518
time: 0.2780647277832031
time: 2.5633604526519775
[1, 21559] loss_train: 0.005971, loss_test: 0.005514
time: 0.7422373294830322
time: 2.7583227157592773
[1, 21560] loss_train: 0.004867, loss_test: 0.005512
time: 0.29106712341308594
time: 2.4495484828948975
[1, 21561] loss_train: 0.010276, loss_test: 0.005514
time: 0.28406286239624023
time: 2.5471253395080566
[1, 21562] loss_train: 0.000801, loss_test: 0.005522
time: 0.32660603523254395
time: 2.4210543632507324
[1, 21563] loss_train: 0.002209, loss_test: 0.005533
time: 0.34706711769104004
time: 2.4741787910461426
[1, 21564] loss_train: 0.010100, loss_test: 0.005545
time: 0.25708794593811035
time: 2.631852865219116
[1, 21565] loss_train: 0.004057, loss_test: 0.005562
time: 0.2600581645965576
time: 2.5190865993499756
[1, 21566] loss_train: 0.001645, loss_test: 0.005579
time: 0.2560567855834961
time: 2.401543140411377
[1, 21567] loss_train: 0.009431, loss_test: 0.005597
time: 0.2630574703216553
time: 2.6105947494506836
[1, 21568] loss_train: 0.004285, loss_test: 0.005614
time: 0.2690596580505371
time: 2.7123773097991943
[1, 21569] loss_train: 0.008154, loss_test: 0.005627
time: 0.31856441497802734
time: 2.418663740158081
[1, 21570] loss_train: 0.007482, loss_test: 0.005637
time: 0.2891659736633301
time: 2.3668854236602783
[1, 21571] loss_train: 0.005961, loss_test: 0.005637
time: 0.2610597610473633
time: 2.6525967121124268
[1, 21572] loss_train: 0.010870, loss_test: 0.005632
time: 0.2670600414276123
time: 2.36403489112854
[1, 21573] loss_train: 0.001814, loss_test: 0.005628
time: 0.2540566921234131
time: 2.462064266204834
[1, 21574] loss_train: 0.009804, loss_test: 0.005610
time: 0.27706193923950195
time: 2.446547031402588
[1, 21575] loss_train: 0.005607, loss_test: 0.005592
time: 0.2620584964752197
time: 2.3960509300231934
[1, 21576] loss_train: 0.016382, loss_test: 0.005566
time: 0.256056547164917
time: 2.504652500152588
[1, 21577] loss_train: 0.002157, loss_test: 0.005561
time: 0.27005958557128906
time: 2.4334843158721924
[1, 21578] loss_train: 0.008583, loss_test: 0.005567
time: 0.26058125495910645
time: 2.3514697551727295
[1, 21579] loss_train: 0.000426, loss_test: 0.005586
time: 0.26199817657470703
time: 2.4725217819213867
[1, 21580] loss_train: 0.005918, loss_test: 0.005609
time: 0.2720606327056885
time: 2.365032911300659
[1, 21581] loss_train: 0.008356, loss_test: 0.005632
time: 0.27005982398986816
time: 2.484555721282959
[1, 21582] loss_train: 0.006755, loss_test: 0.005651
time: 0.257739782333374
time: 2.360527992248535
[1, 21583] loss_train: 0.004443, loss_test: 0.005660
time: 0.27506041526794434
time: 2.3578271865844727
[1, 21584] loss_train: 0.002905, loss_test: 0.005661
time: 0.2591404914855957
time: 2.42254638671875
[1, 21585] loss_train: 0.004124, loss_test: 0.005655
time: 0.2580568790435791
time: 2.3531646728515625
[1, 21586] loss_train: 0.005304, loss_test: 0.005640
time: 0.2657608985900879
time: 2.3808865547180176
[1, 21587] loss_train: 0.008600, loss_test: 0.005619
time: 0.256058931350708
time: 2.3485262393951416
[1, 21588] loss_train: 0.008652, loss_test: 0.005601
time: 0.2620065212249756
time: 2.399536371231079
[1, 21589] loss_train: 0.005885, loss_test: 0.005579
time: 0.24805521965026855
time: 2.3115172386169434
[1, 21590] loss_train: 0.004170, loss_test: 0.005557
time: 0.25905823707580566
time: 2.303018569946289
[1, 21591] loss_train: 0.015297, loss_test: 0.005545
time: 0.2450544834136963
time: 2.3468403816223145
[1, 21592] loss_train: 0.004361, loss_test: 0.005537
time: 0.2920656204223633
time: 2.469956874847412
[1, 21593] loss_train: 0.000941, loss_test: 0.005533
time: 0.2630605697631836
time: 2.391245126724243
[1, 21594] loss_train: 0.005715, loss_test: 0.005533
time: 0.2819337844848633
time: 2.602738380432129
[1, 21595] loss_train: 0.002359, loss_test: 0.005539
time: 0.26605916023254395
time: 2.4062912464141846
[1, 21596] loss_train: 0.006174, loss_test: 0.005546
time: 0.2560570240020752
time: 2.3755311965942383
[1, 21597] loss_train: 0.004769, loss_test: 0.005554
time: 0.2740607261657715
time: 2.519563913345337
[1, 21598] loss_train: 0.006649, loss_test: 0.005563
time: 0.2910637855529785
time: 2.477555274963379
[1, 21599] loss_train: 0.011631, loss_test: 0.005571
time: 0.2718312740325928
time: 2.934168815612793
[1, 21600] loss_train: 0.002745, loss_test: 0.005584
time: 0.3275926113128662
time: 2.361077070236206
[1, 21601] loss_train: 0.007876, loss_test: 0.005596
time: 0.25705742835998535
time: 2.4220449924468994
[1, 21602] loss_train: 0.004271, loss_test: 0.005606
time: 0.25505590438842773
time: 2.410043478012085
[1, 21603] loss_train: 0.005264, loss_test: 0.005606
time: 0.28406238555908203
time: 2.6073575019836426
[1, 21604] loss_train: 0.013857, loss_test: 0.005590
time: 0.2790653705596924
time: 2.504560708999634
[1, 21605] loss_train: 0.004087, loss_test: 0.005580
time: 0.27306127548217773
time: 2.607008218765259
[1, 21606] loss_train: 0.001607, loss_test: 0.005576
time: 0.26104283332824707
time: 2.982870578765869
[1, 21607] loss_train: 0.012582, loss_test: 0.005572
time: 0.2830626964569092
time: 2.4635536670684814
[1, 21608] loss_train: 0.002854, loss_test: 0.005572
time: 0.2630581855773926
time: 2.445549488067627
[1, 21609] loss_train: 0.004024, loss_test: 0.005567
time: 0.26094722747802734
time: 2.511568546295166
[1, 21610] loss_train: 0.012679, loss_test: 0.005560
time: 0.4231448173522949
time: 2.470555067062378
[1, 21611] loss_train: 0.006138, loss_test: 0.005560
time: 0.26405763626098633
time: 2.347036361694336
[1, 21612] loss_train: 0.006669, loss_test: 0.005567
time: 0.2600595951080322
time: 2.4009389877319336
[1, 21613] loss_train: 0.009836, loss_test: 0.005580
time: 0.28406357765197754
time: 2.4065377712249756
[1, 21614] loss_train: 0.009478, loss_test: 0.005592
time: 0.26605987548828125
time: 2.4212400913238525
[1, 21615] loss_train: 0.003946, loss_test: 0.005594
time: 0.2510552406311035
time: 2.538325786590576
[1, 21616] loss_train: 0.006715, loss_test: 0.005589
time: 0.2490549087524414
time: 2.573652744293213
[1, 21617] loss_train: 0.005643, loss_test: 0.005579
time: 0.24805474281311035
time: 2.3910675048828125
[1, 21618] loss_train: 0.008488, loss_test: 0.005567
time: 0.2620584964752197
time: 2.346524953842163
[1, 21619] loss_train: 0.002310, loss_test: 0.005554
time: 0.25205540657043457
time: 2.434544563293457
[1, 21620] loss_train: 0.007738, loss_test: 0.005545
time: 0.2780623435974121
time: 2.389554500579834
[1, 21621] loss_train: 0.007069, loss_test: 0.005538
time: 0.2610602378845215
time: 2.418205499649048
[1, 21622] loss_train: 0.011629, loss_test: 0.005531
time: 0.26206040382385254
time: 2.470876693725586
[1, 21623] loss_train: 0.003996, loss_test: 0.005525
time: 0.4010810852050781
time: 2.516343355178833
[1, 21624] loss_train: 0.008785, loss_test: 0.005523
time: 0.2610585689544678
time: 2.485556125640869
[1, 21625] loss_train: 0.002191, loss_test: 0.005519
time: 0.26305723190307617
time: 2.382051706314087
[1, 21626] loss_train: 0.003188, loss_test: 0.005518
time: 0.259563684463501
time: 2.492957353591919
[1, 21627] loss_train: 0.005895, loss_test: 0.005518
time: 0.26105809211730957
time: 2.555572271347046
[1, 21628] loss_train: 0.008769, loss_test: 0.005521
time: 0.26605916023254395
time: 2.500579833984375
[1, 21629] loss_train: 0.005275, loss_test: 0.005525
time: 0.2960658073425293
time: 2.9456605911254883
[1, 21630] loss_train: 0.006853, loss_test: 0.005528
time: 0.2810640335083008
time: 2.4045398235321045
[1, 21631] loss_train: 0.008719, loss_test: 0.005527
time: 0.2600569725036621
time: 2.3643290996551514
[1, 21632] loss_train: 0.007567, loss_test: 0.005523
time: 0.2650589942932129
time: 2.7303364276885986
[1, 21633] loss_train: 0.002253, loss_test: 0.005519
time: 0.3060612678527832
time: 2.5460565090179443
[1, 21634] loss_train: 0.004430, loss_test: 0.005518
time: 0.2578434944152832
time: 2.399841070175171
[1, 21635] loss_train: 0.006386, loss_test: 0.005518
time: 0.2600572109222412
time: 2.3980414867401123
[1, 21636] loss_train: 0.006983, loss_test: 0.005518
time: 0.25806164741516113
time: 2.363527536392212
[1, 21637] loss_train: 0.008692, loss_test: 0.005518
time: 0.25705671310424805
time: 2.4155406951904297
[1, 21638] loss_train: 0.004529, loss_test: 0.005517
time: 0.2628486156463623
time: 2.4965715408325195
[1, 21639] loss_train: 0.005662, loss_test: 0.005517
time: 0.6557528972625732
time: 2.4913089275360107
[1, 21640] loss_train: 0.004568, loss_test: 0.005519
time: 0.2910633087158203
time: 2.58257794380188
[1, 21641] loss_train: 0.009453, loss_test: 0.005518
time: 0.2830631732940674
time: 2.4225564002990723
[1, 21642] loss_train: 0.017387, loss_test: 0.005517
time: 0.2608623504638672
time: 2.4032678604125977
[1, 21643] loss_train: 0.005554, loss_test: 0.005516
time: 0.2560548782348633
time: 2.3604533672332764
[1, 21644] loss_train: 0.009918, loss_test: 0.005518
time: 0.26285624504089355
time: 2.4408676624298096
[1, 21645] loss_train: 0.000924, loss_test: 0.005519
time: 0.25706028938293457
time: 2.3995361328125
[1, 21646] loss_train: 0.007743, loss_test: 0.005518
time: 0.2560567855834961
time: 2.5415751934051514
[1, 21647] loss_train: 0.007867, loss_test: 0.005519
time: 0.2800562381744385
time: 2.4795546531677246
[1, 21648] loss_train: 0.010672, loss_test: 0.005519
time: 0.2760612964630127
time: 2.5815775394439697
[1, 21649] loss_train: 0.007229, loss_test: 0.005518
time: 0.2910642623901367
time: 2.50811505317688
[1, 21650] loss_train: 0.008341, loss_test: 0.005519
time: 0.2940661907196045
time: 2.4896912574768066
[1, 21651] loss_train: 0.003258, loss_test: 0.005516
time: 0.26205873489379883
time: 2.58436918258667
[1, 21652] loss_train: 0.005610, loss_test: 0.005512
time: 0.25905752182006836
time: 2.5165627002716064
[1, 21653] loss_train: 0.006574, loss_test: 0.005511
time: 0.25505828857421875
time: 2.460162401199341
[1, 21654] loss_train: 0.003433, loss_test: 0.005510
time: 0.3370673656463623
time: 2.3691515922546387
[1, 21655] loss_train: 0.005454, loss_test: 0.005508
time: 0.2670583724975586
time: 2.371975898742676
[1, 21656] loss_train: 0.012932, loss_test: 0.005508
time: 0.2720308303833008
time: 2.4618685245513916
[1, 21657] loss_train: 0.009615, loss_test: 0.005508
time: 0.27506208419799805
time: 2.790696144104004
[1, 21658] loss_train: 0.004341, loss_test: 0.005508
time: 0.25905847549438477
time: 2.681105852127075
[1, 21659] loss_train: 0.009585, loss_test: 0.005508
time: 0.26861572265625
time: 2.4445481300354004
[1, 21660] loss_train: 0.006572, loss_test: 0.005508
time: 0.2800626754760742
time: 2.6018383502960205
[1, 21661] loss_train: 0.012306, loss_test: 0.005509
time: 0.25706052780151367
time: 2.543557643890381
[1, 21662] loss_train: 0.007205, loss_test: 0.005510
time: 0.2653636932373047
time: 2.5475692749023438
[1, 21663] loss_train: 0.007223, loss_test: 0.005511
time: 0.2690603733062744
time: 2.5762956142425537
[1, 21664] loss_train: 0.002621, loss_test: 0.005512
time: 0.28264379501342773
time: 2.698338270187378
[1, 21665] loss_train: 0.005808, loss_test: 0.005513
time: 0.2720601558685303
time: 2.4961204528808594
[1, 21666] loss_train: 0.004887, loss_test: 0.005514
time: 0.2724478244781494
time: 2.418055772781372
[1, 21667] loss_train: 0.009049, loss_test: 0.005515
time: 0.49700140953063965
time: 2.43515944480896
[1, 21668] loss_train: 0.009279, loss_test: 0.005517
time: 0.2690601348876953
time: 2.4854583740234375
[1, 21669] loss_train: 0.004203, loss_test: 0.005518
time: 0.25505709648132324
time: 2.4475486278533936
[1, 21670] loss_train: 0.011192, loss_test: 0.005518
time: 0.2740600109100342
time: 2.499096393585205
[1, 21671] loss_train: 0.006952, loss_test: 0.005520
time: 0.25505614280700684
time: 2.527930736541748
[1, 21672] loss_train: 0.008057, loss_test: 0.005520
time: 0.2580568790435791
time: 2.5306131839752197
[1, 21673] loss_train: 0.002442, loss_test: 0.005520
time: 0.2620582580566406
time: 2.6421101093292236
[1, 21674] loss_train: 0.005372, loss_test: 0.005519
time: 0.2620580196380615
time: 2.522610664367676
[1, 21675] loss_train: 0.008201, loss_test: 0.005519
time: 0.25589776039123535
time: 2.420276165008545
[1, 21676] loss_train: 0.008572, loss_test: 0.005518
time: 0.25505661964416504
time: 2.343524217605591
[1, 21677] loss_train: 0.003863, loss_test: 0.005518
time: 0.2620582580566406
time: 2.4245426654815674
[1, 21678] loss_train: 0.007903, loss_test: 0.005520
time: 0.2560575008392334
time: 2.57511305809021
[1, 21679] loss_train: 0.001421, loss_test: 0.005525
time: 0.2600572109222412
time: 2.3654210567474365
[1, 21680] loss_train: 0.005013, loss_test: 0.005529
time: 0.27306079864501953
time: 2.362156391143799
[1, 21681] loss_train: 0.005863, loss_test: 0.005530
time: 0.25705742835998535
time: 2.4134528636932373
[1, 21682] loss_train: 0.003661, loss_test: 0.005529
time: 0.25806474685668945
time: 2.409271478652954
[1, 21683] loss_train: 0.002709, loss_test: 0.005529
time: 0.25905823707580566
time: 2.499459743499756
[1, 21684] loss_train: 0.005147, loss_test: 0.005528
time: 0.25505590438842773
time: 2.4035465717315674
[1, 21685] loss_train: 0.009060, loss_test: 0.005525
time: 0.258056640625
time: 2.432072639465332
[1, 21686] loss_train: 0.008551, loss_test: 0.005525
time: 0.25905776023864746
time: 2.412899971008301
[1, 21687] loss_train: 0.002518, loss_test: 0.005526
time: 0.2670588493347168
time: 2.551570415496826
[1, 21688] loss_train: 0.006616, loss_test: 0.005525
time: 0.28507208824157715
time: 2.617067813873291
[1, 21689] loss_train: 0.003992, loss_test: 0.005526
time: 0.30806565284729004
time: 2.5519988536834717
[1, 21690] loss_train: 0.005246, loss_test: 0.005529
time: 0.27006030082702637
time: 2.4971046447753906
[1, 21691] loss_train: 0.004768, loss_test: 0.005530
time: 0.2830629348754883
time: 2.5180819034576416
[1, 21692] loss_train: 0.012482, loss_test: 0.005527
time: 0.2760608196258545
time: 2.989668846130371
[1, 21693] loss_train: 0.007412, loss_test: 0.005526
time: 0.2850632667541504
time: 2.4669201374053955
[1, 21694] loss_train: 0.000602, loss_test: 0.005526
time: 0.3776400089263916
time: 2.4455759525299072
[1, 21695] loss_train: 0.006979, loss_test: 0.005528
time: 0.2640571594238281
time: 2.5588676929473877
[1, 21696] loss_train: 0.006795, loss_test: 0.005530
time: 0.2740604877471924
time: 2.714022636413574
[1, 21697] loss_train: 0.013790, loss_test: 0.005528
time: 0.37207531929016113
time: 2.6728615760803223
[1, 21698] loss_train: 0.002649, loss_test: 0.005531
time: 0.2710597515106201
time: 2.693082571029663
[1, 21699] loss_train: 0.003669, loss_test: 0.005534
time: 0.31005287170410156
time: 2.9073808193206787
[1, 21700] loss_train: 0.011285, loss_test: 0.005538
time: 0.27306079864501953
time: 2.4784202575683594
[1, 21701] loss_train: 0.006607, loss_test: 0.005541
time: 0.26405858993530273
time: 2.571575403213501
[1, 21702] loss_train: 0.005760, loss_test: 0.005542
time: 0.2740604877471924
time: 2.840883493423462
[1, 21703] loss_train: 0.004002, loss_test: 0.005541
time: 0.2560567855834961
time: 2.4360480308532715
[1, 21704] loss_train: 0.004263, loss_test: 0.005540
time: 0.26105809211730957
time: 2.7417125701904297
[1, 21705] loss_train: 0.006077, loss_test: 0.005538
time: 0.2580571174621582
time: 2.3532543182373047
[1, 21706] loss_train: 0.007695, loss_test: 0.005534
time: 0.2897629737854004
time: 2.372178316116333
[1, 21707] loss_train: 0.003844, loss_test: 0.005532
time: 0.2720603942871094
time: 2.410541296005249
[1, 21708] loss_train: 0.006662, loss_test: 0.005532
time: 0.254061222076416
time: 2.519465684890747
[1, 21709] loss_train: 0.009618, loss_test: 0.005531
time: 0.2669968605041504
time: 2.638612747192383
[1, 21710] loss_train: 0.005035, loss_test: 0.005529
time: 0.37607431411743164
time: 2.392536163330078
[1, 21711] loss_train: 0.013947, loss_test: 0.005526
time: 0.2580568790435791
time: 2.522306203842163
[1, 21712] loss_train: 0.009329, loss_test: 0.005526
time: 0.25705671310424805
time: 2.4828624725341797
[1, 21713] loss_train: 0.001332, loss_test: 0.005523
time: 0.2680623531341553
time: 2.4030470848083496
[1, 21714] loss_train: 0.010084, loss_test: 0.005520
time: 0.2670586109161377
time: 2.6822686195373535
[1, 21715] loss_train: 0.010659, loss_test: 0.005518
time: 0.2690596580505371
time: 2.416543483734131
[1, 21716] loss_train: 0.002124, loss_test: 0.005516
time: 0.2720601558685303
time: 2.4922385215759277
[1, 21717] loss_train: 0.007053, loss_test: 0.005514
time: 0.25905704498291016
time: 2.413142204284668
[1, 21718] loss_train: 0.003356, loss_test: 0.005513
time: 0.2579920291900635
time: 2.376530885696411
[1, 21719] loss_train: 0.003965, loss_test: 0.005513
time: 0.256056547164917
time: 2.3832507133483887
[1, 21720] loss_train: 0.004166, loss_test: 0.005513
time: 0.27006030082702637
time: 2.405932664871216
[1, 21721] loss_train: 0.007202, loss_test: 0.005513
time: 0.26456236839294434
time: 2.3552565574645996
[1, 21722] loss_train: 0.011578, loss_test: 0.005512
time: 0.26805973052978516
time: 2.457550048828125
[1, 21723] loss_train: 0.011613, loss_test: 0.005513
time: 0.26105761528015137
time: 2.439270496368408
[1, 21724] loss_train: 0.000537, loss_test: 0.005516
time: 0.2540576457977295
time: 2.4760308265686035
[1, 21725] loss_train: 0.009145, loss_test: 0.005519
time: 0.2600564956665039
time: 2.406717538833618
[1, 21726] loss_train: 0.008446, loss_test: 0.005523
time: 0.2560606002807617
time: 2.4884793758392334
[1, 21727] loss_train: 0.006819, loss_test: 0.005524
time: 0.2600569725036621
time: 2.373530626296997
[1, 21728] loss_train: 0.007308, loss_test: 0.005525
time: 0.27506041526794434
time: 2.3620827198028564
[1, 21729] loss_train: 0.003840, loss_test: 0.005524
time: 0.26405882835388184
time: 2.411641836166382
[1, 21730] loss_train: 0.005070, loss_test: 0.005524
time: 0.27106380462646484
time: 2.3533565998077393
[1, 21731] loss_train: 0.004514, loss_test: 0.005524
time: 0.26605963706970215
time: 2.4761369228363037
[1, 21732] loss_train: 0.006881, loss_test: 0.005524
time: 0.2605624198913574
time: 2.414792060852051
[1, 21733] loss_train: 0.012887, loss_test: 0.005525
time: 0.26105737686157227
time: 2.3966548442840576
[1, 21734] loss_train: 0.007511, loss_test: 0.005526
time: 0.3034536838531494
time: 2.5020930767059326
[1, 21735] loss_train: 0.003105, loss_test: 0.005528
time: 0.2600584030151367
time: 2.4614150524139404
[1, 21736] loss_train: 0.005906, loss_test: 0.005528
time: 0.31206250190734863
time: 2.342534065246582
[1, 21737] loss_train: 0.007257, loss_test: 0.005527
time: 0.27706122398376465
time: 2.491061210632324
[1, 21738] loss_train: 0.000613, loss_test: 0.005527
time: 0.25905728340148926
time: 2.3446245193481445
[1, 21739] loss_train: 0.007692, loss_test: 0.005528
time: 0.2568354606628418
time: 2.379533290863037
[1, 21740] loss_train: 0.007106, loss_test: 0.005528
time: 0.2720601558685303
time: 2.4360475540161133
[1, 21741] loss_train: 0.006080, loss_test: 0.005527
time: 0.28897953033447266
time: 2.408702850341797
[1, 21742] loss_train: 0.007881, loss_test: 0.005527
time: 0.2630579471588135
time: 2.493574380874634
[1, 21743] loss_train: 0.004227, loss_test: 0.005529
time: 0.26105785369873047
time: 2.4205429553985596
[1, 21744] loss_train: 0.008396, loss_test: 0.005531
time: 0.2600550651550293
time: 2.6215884685516357
[1, 21745] loss_train: 0.005069, loss_test: 0.005532
time: 0.2580602169036865
time: 2.676698923110962
[1, 21746] loss_train: 0.009219, loss_test: 0.005537
time: 0.2650587558746338
time: 2.432981252670288
[1, 21747] loss_train: 0.011632, loss_test: 0.005540
time: 0.25706052780151367
time: 2.4061977863311768
[1, 21748] loss_train: 0.007273, loss_test: 0.005542
time: 0.256056547164917
time: 2.514163017272949
[1, 21749] loss_train: 0.009387, loss_test: 0.005545
time: 0.2560572624206543
time: 2.3795323371887207
[1, 21750] loss_train: 0.007021, loss_test: 0.005551
time: 0.2720601558685303
time: 2.367539167404175
[1, 21751] loss_train: 0.001355, loss_test: 0.005548
time: 0.25705623626708984
time: 2.571575403213501
[1, 21752] loss_train: 0.015312, loss_test: 0.005543
time: 0.2670598030090332
time: 2.4925546646118164
[1, 21753] loss_train: 0.007022, loss_test: 0.005538
time: 0.25505685806274414
time: 2.524564743041992
[1, 21754] loss_train: 0.007445, loss_test: 0.005534
time: 0.2580564022064209
time: 2.3964781761169434
[1, 21755] loss_train: 0.006108, loss_test: 0.005530
time: 0.2580604553222656
time: 2.3581950664520264
[1, 21756] loss_train: 0.008844, loss_test: 0.005526
time: 0.25505995750427246
time: 2.3481414318084717
[1, 21757] loss_train: 0.006982, loss_test: 0.005523
time: 0.26149988174438477
time: 2.427541494369507
[1, 21758] loss_train: 0.014348, loss_test: 0.005523
time: 0.25905704498291016
time: 2.3985488414764404
[1, 21759] loss_train: 0.005644, loss_test: 0.005524
time: 0.25705718994140625
time: 2.5165040493011475
[1, 21760] loss_train: 0.006725, loss_test: 0.005527
time: 0.27005910873413086
time: 2.454052686691284
[1, 21761] loss_train: 0.003807, loss_test: 0.005531
time: 0.2600584030151367
time: 2.4002318382263184
[1, 21762] loss_train: 0.014726, loss_test: 0.005537
time: 0.26405930519104004
time: 2.5527172088623047
[1, 21763] loss_train: 0.003714, loss_test: 0.005543
time: 0.2540569305419922
time: 2.4177122116088867
[1, 21764] loss_train: 0.008051, loss_test: 0.005542
time: 0.25505828857421875
time: 2.5190749168395996
[1, 21765] loss_train: 0.008722, loss_test: 0.005542
time: 0.2570178508758545
time: 2.58261775970459
[1, 21766] loss_train: 0.000949, loss_test: 0.005542
time: 0.26906490325927734
time: 2.5316896438598633
[1, 21767] loss_train: 0.005689, loss_test: 0.005544
time: 0.2705667018890381
time: 2.436051368713379
[1, 21768] loss_train: 0.001364, loss_test: 0.005547
time: 0.26205873489379883
time: 2.6665961742401123
[1, 21769] loss_train: 0.001305, loss_test: 0.005551
time: 0.256056547164917
time: 2.3916614055633545
[1, 21770] loss_train: 0.007639, loss_test: 0.005552
time: 0.3020601272583008
time: 2.450529098510742
[1, 21771] loss_train: 0.003907, loss_test: 0.005552
time: 0.2560904026031494
time: 2.43084716796875
[1, 21772] loss_train: 0.006296, loss_test: 0.005553
time: 0.25705647468566895
time: 2.3575377464294434
[1, 21773] loss_train: 0.002423, loss_test: 0.005556
time: 0.2580568790435791
time: 2.404538631439209
[1, 21774] loss_train: 0.001796, loss_test: 0.005562
time: 0.2580575942993164
time: 2.3671743869781494
[1, 21775] loss_train: 0.009492, loss_test: 0.005559
time: 0.2600564956665039
time: 2.557652711868286
[1, 21776] loss_train: 0.009251, loss_test: 0.005548
time: 0.26206040382385254
time: 2.578028678894043
[1, 21777] loss_train: 0.003403, loss_test: 0.005540
time: 0.2630579471588135
time: 2.4756081104278564
[1, 21778] loss_train: 0.000887, loss_test: 0.005537
time: 0.27904415130615234
time: 2.8414864540100098
[1, 21779] loss_train: 0.007676, loss_test: 0.005532
time: 0.2630612850189209
time: 2.55609393119812
[1, 21780] loss_train: 0.003570, loss_test: 0.005529
time: 0.6471309661865234
time: 2.572737216949463
[1, 21781] loss_train: 0.013443, loss_test: 0.005526
time: 0.25705718994140625
time: 2.6035330295562744
[1, 21782] loss_train: 0.011224, loss_test: 0.005529
time: 0.2600586414337158
time: 2.5912418365478516
[1, 21783] loss_train: 0.008034, loss_test: 0.005533
time: 0.2740597724914551
time: 2.391211986541748
[1, 21784] loss_train: 0.006707, loss_test: 0.005531
time: 0.2540574073791504
time: 2.4149746894836426
[1, 21785] loss_train: 0.005531, loss_test: 0.005528
time: 0.2572927474975586
time: 2.3415307998657227
[1, 21786] loss_train: 0.004905, loss_test: 0.005525
time: 0.2560563087463379
time: 2.4525489807128906
[1, 21787] loss_train: 0.007661, loss_test: 0.005524
time: 0.2600579261779785
time: 2.372529983520508
[1, 21788] loss_train: 0.005634, loss_test: 0.005520
time: 0.2850639820098877
time: 2.3655316829681396
[1, 21789] loss_train: 0.004302, loss_test: 0.005519
time: 0.2600576877593994
time: 2.550074815750122
[1, 21790] loss_train: 0.006531, loss_test: 0.005520
time: 0.27206921577453613
time: 2.485551118850708
[1, 21791] loss_train: 0.006368, loss_test: 0.005525
time: 0.2600579261779785
time: 2.3949637413024902
[1, 21792] loss_train: 0.010896, loss_test: 0.005527
time: 0.256056547164917
time: 2.4342658519744873
[1, 21793] loss_train: 0.006140, loss_test: 0.005528
time: 0.25505590438842773
time: 2.6701009273529053
[1, 21794] loss_train: 0.011394, loss_test: 0.005530
time: 0.27625441551208496
time: 2.845259428024292
[1, 21795] loss_train: 0.007114, loss_test: 0.005529
time: 0.2780606746673584
time: 2.7319583892822266
[1, 21796] loss_train: 0.005818, loss_test: 0.005526
time: 0.25800275802612305
time: 2.3655221462249756
[1, 21797] loss_train: 0.003083, loss_test: 0.005522
time: 0.2692098617553711
time: 2.5496363639831543
[1, 21798] loss_train: 0.006142, loss_test: 0.005518
time: 0.25505590438842773
time: 2.446049928665161
[1, 21799] loss_train: 0.011263, loss_test: 0.005516
time: 0.254056453704834
time: 2.6396820545196533
[1, 21800] loss_train: 0.009851, loss_test: 0.005514
time: 0.26405858993530273
time: 2.337036609649658
[1, 21801] loss_train: 0.002809, loss_test: 0.005511
time: 0.25905752182006836
time: 2.350632667541504
[1, 21802] loss_train: 0.009287, loss_test: 0.005510
time: 0.24805450439453125
time: 2.3205318450927734
[1, 21803] loss_train: 0.008256, loss_test: 0.005509
time: 0.24605441093444824
time: 2.2812716960906982
[1, 21804] loss_train: 0.000727, loss_test: 0.005509
time: 0.2650582790374756
time: 2.5495707988739014
[1, 21805] loss_train: 0.013271, loss_test: 0.005509
time: 0.27306079864501953
time: 2.535567045211792
[1, 21806] loss_train: 0.005671, loss_test: 0.005511
time: 0.2580573558807373
time: 2.469092845916748
[1, 21807] loss_train: 0.007030, loss_test: 0.005515
time: 0.27006077766418457
time: 2.4146385192871094
[1, 21808] loss_train: 0.003936, loss_test: 0.005518
time: 0.2628629207611084
time: 2.378761053085327
[1, 21809] loss_train: 0.004432, loss_test: 0.005522
time: 0.26105761528015137
time: 2.36148738861084
[1, 21810] loss_train: 0.006218, loss_test: 0.005526
time: 0.28806447982788086
time: 2.3845441341400146
[1, 21811] loss_train: 0.004191, loss_test: 0.005530
time: 0.25705671310424805
time: 2.3807270526885986
[1, 21812] loss_train: 0.006052, loss_test: 0.005533
time: 0.25905752182006836
time: 2.3875625133514404
[1, 21813] loss_train: 0.008368, loss_test: 0.005535
time: 0.2650587558746338
time: 2.512955904006958
[1, 21814] loss_train: 0.008890, loss_test: 0.005536
time: 0.2566545009613037
time: 2.6744320392608643
[1, 21815] loss_train: 0.011669, loss_test: 0.005537
time: 0.26605868339538574
time: 2.4715535640716553
[1, 21816] loss_train: 0.002791, loss_test: 0.005538
time: 0.2580575942993164
time: 2.534569501876831
[1, 21817] loss_train: 0.007863, loss_test: 0.005539
time: 0.2630581855773926
time: 2.4223833084106445
[1, 21818] loss_train: 0.013709, loss_test: 0.005544
time: 0.2600576877593994
time: 2.4620373249053955
[1, 21819] loss_train: 0.003735, loss_test: 0.005547
time: 0.2620580196380615
time: 2.381605625152588
[1, 21820] loss_train: 0.007784, loss_test: 0.005550
time: 0.28406333923339844
time: 2.4205410480499268
[1, 21821] loss_train: 0.007216, loss_test: 0.005552
time: 0.26605868339538574
time: 2.354393243789673
[1, 21822] loss_train: 0.009251, loss_test: 0.005549
time: 0.2690608501434326
time: 2.423543691635132
[1, 21823] loss_train: 0.003741, loss_test: 0.005544
time: 0.26305723190307617
time: 2.3847992420196533
[1, 21824] loss_train: 0.002501, loss_test: 0.005537
time: 0.2630579471588135
time: 2.4510531425476074
[1, 21825] loss_train: 0.006511, loss_test: 0.005534
time: 0.2620580196380615
time: 2.369321584701538
[1, 21826] loss_train: 0.005008, loss_test: 0.005533
time: 0.2580587863922119
time: 2.4102158546447754
[1, 21827] loss_train: 0.002349, loss_test: 0.005534
time: 0.265059232711792
time: 2.3905909061431885
[1, 21828] loss_train: 0.008354, loss_test: 0.005538
time: 0.26352930068969727
time: 2.517610549926758
[1, 21829] loss_train: 0.010556, loss_test: 0.005544
time: 0.25905704498291016
time: 2.5485708713531494
[1, 21830] loss_train: 0.006569, loss_test: 0.005549
time: 0.28606295585632324
time: 2.468559503555298
[1, 21831] loss_train: 0.002910, loss_test: 0.005556
time: 0.281055212020874
time: 2.7006306648254395
[1, 21832] loss_train: 0.006270, loss_test: 0.005563
time: 0.2680628299713135
time: 2.640510082244873
[1, 21833] loss_train: 0.008561, loss_test: 0.005567
time: 0.25853562355041504
time: 2.5015690326690674
[1, 21834] loss_train: 0.010992, loss_test: 0.005572
time: 0.2610588073730469
time: 2.463550567626953
[1, 21835] loss_train: 0.001983, loss_test: 0.005581
time: 0.25905704498291016
time: 2.3890559673309326
[1, 21836] loss_train: 0.008692, loss_test: 0.005587
time: 0.3300645351409912
time: 2.672597885131836
[1, 21837] loss_train: 0.006319, loss_test: 0.005583
time: 0.26105809211730957
time: 2.4571335315704346
[1, 21838] loss_train: 0.003945, loss_test: 0.005577
time: 0.28705787658691406
time: 2.537294387817383
[1, 21839] loss_train: 0.004706, loss_test: 0.005572
time: 0.2610511779785156
time: 2.4209015369415283
[1, 21840] loss_train: 0.014085, loss_test: 0.005565
time: 0.27178025245666504
time: 2.5031673908233643
[1, 21841] loss_train: 0.002049, loss_test: 0.005563
time: 0.2627248764038086
time: 2.3953285217285156
[1, 21842] loss_train: 0.001838, loss_test: 0.005560
time: 0.7461564540863037
time: 2.4525442123413086
[1, 21843] loss_train: 0.003504, loss_test: 0.005557
time: 0.2580687999725342
time: 2.5971620082855225
[1, 21844] loss_train: 0.005477, loss_test: 0.005552
time: 0.26206398010253906
time: 2.5686585903167725
[1, 21845] loss_train: 0.004971, loss_test: 0.005548
time: 0.25905799865722656
time: 2.3755383491516113
[1, 21846] loss_train: 0.007560, loss_test: 0.005547
time: 0.25705814361572266
time: 2.3750367164611816
[1, 21847] loss_train: 0.004935, loss_test: 0.005543
time: 0.2630579471588135
time: 2.4950027465820312
[1, 21848] loss_train: 0.009230, loss_test: 0.005540
time: 0.2600572109222412
time: 2.3915350437164307
[1, 21849] loss_train: 0.004093, loss_test: 0.005537
time: 0.327073335647583
time: 2.608710765838623
[1, 21850] loss_train: 0.008944, loss_test: 0.005535
time: 0.5947458744049072
time: 2.499558210372925
[1, 21851] loss_train: 0.001493, loss_test: 0.005535
time: 0.27706122398376465
time: 2.3655292987823486
[1, 21852] loss_train: 0.002279, loss_test: 0.005537
time: 0.2600574493408203
time: 2.500558853149414
[1, 21853] loss_train: 0.005991, loss_test: 0.005538
time: 0.26205873489379883
time: 2.373035430908203
[1, 21854] loss_train: 0.004915, loss_test: 0.005538
time: 0.26405882835388184
time: 2.395552396774292
[1, 21855] loss_train: 0.003607, loss_test: 0.005538
time: 0.3020668029785156
time: 2.7668440341949463
[1, 21856] loss_train: 0.003956, loss_test: 0.005538
time: 0.29706716537475586
time: 2.493204355239868
[1, 21857] loss_train: 0.007768, loss_test: 0.005537
time: 0.2570638656616211
time: 2.5126593112945557
[1, 21858] loss_train: 0.004535, loss_test: 0.005539
time: 0.25505685806274414
time: 2.355526924133301
[1, 21859] loss_train: 0.002028, loss_test: 0.005542
time: 0.28106164932250977
time: 2.4015371799468994
[1, 21860] loss_train: 0.007659, loss_test: 0.005543
time: 0.25705623626708984
time: 2.317519187927246
[1, 21861] loss_train: 0.006475, loss_test: 0.005542
time: 0.27205967903137207
time: 2.302919864654541
[1, 21862] loss_train: 0.000959, loss_test: 0.005542
time: 0.2610585689544678
time: 2.3065185546875
[1, 21863] loss_train: 0.008053, loss_test: 0.005541
time: 0.26805973052978516
time: 2.476038694381714
[1, 21864] loss_train: 0.009467, loss_test: 0.005537
time: 0.29298996925354004
time: 2.547933578491211
[1, 21865] loss_train: 0.009747, loss_test: 0.005530
time: 0.280062198638916
time: 2.720689058303833
[1, 21866] loss_train: 0.008088, loss_test: 0.005524
time: 0.27198004722595215
time: 3.740629196166992
[1, 21867] loss_train: 0.006569, loss_test: 0.005523
time: 0.2980661392211914
time: 2.6435911655426025
[1, 21868] loss_train: 0.008053, loss_test: 0.005525
time: 0.2980659008026123
time: 2.5421864986419678
[1, 21869] loss_train: 0.002736, loss_test: 0.005525
time: 0.28545498847961426
time: 2.518685817718506
[1, 21870] loss_train: 0.008053, loss_test: 0.005524
time: 0.294064998626709
time: 2.554572582244873
[1, 21871] loss_train: 0.004487, loss_test: 0.005524
time: 0.28106212615966797
time: 2.986755847930908
[1, 21872] loss_train: 0.010564, loss_test: 0.005527
time: 0.2910645008087158
time: 2.586087465286255
[1, 21873] loss_train: 0.009053, loss_test: 0.005532
time: 0.2835683822631836
time: 2.523848533630371
[1, 21874] loss_train: 0.003894, loss_test: 0.005529
time: 0.28682947158813477
time: 2.571591377258301
[1, 21875] loss_train: 0.007628, loss_test: 0.005526
time: 0.34270620346069336
time: 2.942657709121704
[1, 21876] loss_train: 0.002283, loss_test: 0.005519
time: 0.2820618152618408
time: 2.5305662155151367
[1, 21877] loss_train: 0.007047, loss_test: 0.005514
time: 0.27706217765808105
time: 2.5070698261260986
[1, 21878] loss_train: 0.002724, loss_test: 0.005511
time: 0.2798759937286377
time: 2.651421070098877
[1, 21879] loss_train: 0.007446, loss_test: 0.005511
time: 0.28806519508361816
time: 2.4548959732055664
[1, 21880] loss_train: 0.009594, loss_test: 0.005511
time: 0.303635835647583
time: 2.5295650959014893
[1, 21881] loss_train: 0.012621, loss_test: 0.005511
time: 0.29006457328796387
time: 2.8456385135650635
[1, 21882] loss_train: 0.005683, loss_test: 0.005511
time: 0.28806471824645996
time: 2.6122994422912598
[1, 21883] loss_train: 0.002006, loss_test: 0.005514
time: 0.28806376457214355
time: 2.6758387088775635
[1, 21884] loss_train: 0.004831, loss_test: 0.005518
time: 0.2850627899169922
time: 2.9157979488372803
[1, 21885] loss_train: 0.001490, loss_test: 0.005522
time: 0.2905707359313965
time: 2.465458393096924
[1, 21886] loss_train: 0.013124, loss_test: 0.005526
time: 0.2890644073486328
time: 2.5373942852020264
[1, 21887] loss_train: 0.003318, loss_test: 0.005531
time: 0.28496456146240234
time: 2.603346347808838
[1, 21888] loss_train: 0.009003, loss_test: 0.005536
time: 0.2760612964630127
time: 3.1056947708129883
[1, 21889] loss_train: 0.005627, loss_test: 0.005540
time: 0.2870640754699707
time: 2.535970687866211
[1, 21890] loss_train: 0.006028, loss_test: 0.005540
time: 0.29906606674194336
time: 2.514970064163208
[1, 21891] loss_train: 0.006972, loss_test: 0.005540
time: 0.27706217765808105
time: 2.665445566177368
[1, 21892] loss_train: 0.001971, loss_test: 0.005539
time: 0.2752659320831299
time: 2.4653079509735107
[1, 21893] loss_train: 0.001398, loss_test: 0.005537
time: 0.292064905166626
time: 2.4690744876861572
[1, 21894] loss_train: 0.002028, loss_test: 0.005537
time: 0.29006457328796387
time: 2.5214836597442627
[1, 21895] loss_train: 0.007921, loss_test: 0.005536
time: 0.31707000732421875
time: 2.492149591445923
[1, 21896] loss_train: 0.010795, loss_test: 0.005533
time: 0.2760610580444336
time: 2.432729482650757
[1, 21897] loss_train: 0.002436, loss_test: 0.005532
time: 0.291013240814209
time: 2.934959888458252
[1, 21898] loss_train: 0.004104, loss_test: 0.005533
time: 0.2830634117126465
time: 2.5146591663360596
[1, 21899] loss_train: 0.004441, loss_test: 0.005534
time: 0.2980661392211914
time: 2.4335081577301025
[1, 21900] loss_train: 0.000588, loss_test: 0.005536
time: 0.29906535148620605
time: 2.7148571014404297
[1, 21901] loss_train: 0.005019, loss_test: 0.005536
time: 0.28106260299682617
time: 2.6859054565429688
[1, 21902] loss_train: 0.011923, loss_test: 0.005532
time: 0.31606292724609375
time: 2.7209842205047607
[1, 21903] loss_train: 0.009577, loss_test: 0.005528
time: 0.28406357765197754
time: 2.4729442596435547
[1, 21904] loss_train: 0.007384, loss_test: 0.005525
time: 0.28406596183776855
time: 3.0312297344207764
[1, 21905] loss_train: 0.007625, loss_test: 0.005526
time: 0.2800626754760742
time: 2.4355580806732178
[1, 21906] loss_train: 0.006766, loss_test: 0.005531
time: 0.28606390953063965
time: 2.478891372680664
[1, 21907] loss_train: 0.005480, loss_test: 0.005537
time: 0.2919189929962158
time: 2.7506697177886963
[1, 21908] loss_train: 0.004587, loss_test: 0.005543
time: 0.28106236457824707
time: 2.4318079948425293
[1, 21909] loss_train: 0.009404, loss_test: 0.005544
time: 0.2840616703033447
time: 2.5702714920043945
[1, 21910] loss_train: 0.006503, loss_test: 0.005540
time: 0.3380563259124756
time: 2.6001245975494385
[1, 21911] loss_train: 0.000771, loss_test: 0.005530
time: 0.2877542972564697
time: 2.695985794067383
[1, 21912] loss_train: 0.011149, loss_test: 0.005520
time: 0.27906155586242676
time: 2.710606336593628
[1, 21913] loss_train: 0.002154, loss_test: 0.005513
time: 0.2760617733001709
time: 2.4373841285705566
[1, 21914] loss_train: 0.000744, loss_test: 0.005507
time: 0.292064905166626
time: 2.499951124191284
[1, 21915] loss_train: 0.004752, loss_test: 0.005506
time: 0.27906203269958496
time: 2.483907461166382
[1, 21916] loss_train: 0.005659, loss_test: 0.005509
time: 0.27506041526794434
time: 2.602109432220459
[1, 21917] loss_train: 0.004327, loss_test: 0.005512
time: 0.27306151390075684
time: 2.687969207763672
[1, 21918] loss_train: 0.006898, loss_test: 0.005517
time: 0.29006433486938477
time: 2.408539295196533
[1, 21919] loss_train: 0.009445, loss_test: 0.005518
time: 0.27005887031555176
time: 2.448057174682617
[1, 21920] loss_train: 0.005367, loss_test: 0.005520
time: 0.34906721115112305
time: 2.6748249530792236
[1, 21921] loss_train: 0.006402, loss_test: 0.005521
time: 0.2671084403991699
time: 2.466156244277954
[1, 21922] loss_train: 0.003767, loss_test: 0.005523
time: 0.26605916023254395
time: 2.4069418907165527
[1, 21923] loss_train: 0.008819, loss_test: 0.005524
time: 0.26605939865112305
time: 2.368604898452759
[1, 21924] loss_train: 0.005122, loss_test: 0.005526
time: 0.2674214839935303
time: 2.3702502250671387
[1, 21925] loss_train: 0.012896, loss_test: 0.005528
time: 0.26405787467956543
time: 2.413411855697632
[1, 21926] loss_train: 0.003458, loss_test: 0.005531
time: 0.2780613899230957
time: 2.540076971054077
[1, 21927] loss_train: 0.003858, loss_test: 0.005533
time: 0.27706241607666016
time: 2.8203437328338623
[1, 21928] loss_train: 0.009785, loss_test: 0.005533
time: 0.28806376457214355
time: 2.9335920810699463
[1, 21929] loss_train: 0.008203, loss_test: 0.005531
time: 0.2850630283355713
time: 2.481555223464966
[1, 21930] loss_train: 0.000389, loss_test: 0.005531
time: 0.3090689182281494
time: 2.490213394165039
[1, 21931] loss_train: 0.004958, loss_test: 0.005532
time: 0.2910647392272949
time: 2.451444149017334
[1, 21932] loss_train: 0.006733, loss_test: 0.005532
time: 0.2680649757385254
time: 2.4359006881713867
[1, 21933] loss_train: 0.003299, loss_test: 0.005533
time: 0.27205944061279297
time: 2.5414271354675293
[1, 21934] loss_train: 0.001700, loss_test: 0.005536
time: 0.27706074714660645
time: 2.3580329418182373
[1, 21935] loss_train: 0.002080, loss_test: 0.005539
time: 0.2740600109100342
time: 2.4977102279663086
[1, 21936] loss_train: 0.008783, loss_test: 0.005541
time: 0.2792494297027588
time: 2.422122001647949
[1, 21937] loss_train: 0.004047, loss_test: 0.005544
time: 0.2767786979675293
time: 2.4494833946228027
[1, 21938] loss_train: 0.010239, loss_test: 0.005545
time: 0.2823779582977295
time: 3.4440627098083496
[1, 21939] loss_train: 0.009647, loss_test: 0.005547
time: 0.2740604877471924
time: 2.6781909465789795
[1, 21940] loss_train: 0.007417, loss_test: 0.005548
time: 0.28887510299682617
time: 2.596444845199585
[1, 21941] loss_train: 0.009079, loss_test: 0.005547
time: 1.2860403060913086
time: 2.6665539741516113
[1, 21942] loss_train: 0.005036, loss_test: 0.005548
time: 0.3660759925842285
time: 3.0559191703796387
[1, 21943] loss_train: 0.009830, loss_test: 0.005548
time: 0.2890641689300537
time: 2.76892352104187
[1, 21944] loss_train: 0.005880, loss_test: 0.005549
time: 0.2759380340576172
time: 3.1507325172424316
[1, 21945] loss_train: 0.001623, loss_test: 0.005552
time: 0.2910652160644531
time: 2.4840123653411865
[1, 21946] loss_train: 0.000973, loss_test: 0.005555
time: 0.2960672378540039
time: 2.525099515914917
[1, 21947] loss_train: 0.006823, loss_test: 0.005558
time: 0.29906582832336426
time: 2.8377113342285156
[1, 21948] loss_train: 0.008080, loss_test: 0.005556
time: 0.2795109748840332
time: 3.354780673980713
[1, 21949] loss_train: 0.004318, loss_test: 0.005553
time: 0.31006884574890137
time: 2.3635284900665283
[1, 21950] loss_train: 0.005132, loss_test: 0.005552
time: 0.26605844497680664
time: 2.303515672683716
[1, 21951] loss_train: 0.006905, loss_test: 0.005549
time: 0.2510552406311035
time: 2.2865118980407715
[1, 21952] loss_train: 0.002746, loss_test: 0.005544
time: 0.24605441093444824
time: 2.3295209407806396
[1, 21953] loss_train: 0.006617, loss_test: 0.005539
time: 0.2540569305419922
time: 2.3305206298828125
[1, 21954] loss_train: 0.006156, loss_test: 0.005538
time: 0.27506160736083984
time: 2.4035370349884033
[1, 21955] loss_train: 0.001408, loss_test: 0.005538
time: 0.3180701732635498
time: 2.4655656814575195
[1, 21956] loss_train: 0.006026, loss_test: 0.005536
time: 0.2600579261779785
time: 2.771986961364746
[1, 21957] loss_train: 0.004023, loss_test: 0.005533
time: 0.288449764251709
time: 2.5350704193115234
[1, 21958] loss_train: 0.007159, loss_test: 0.005531
time: 0.283062219619751
time: 2.3655295372009277
[1, 21959] loss_train: 0.004790, loss_test: 0.005528
time: 0.267059326171875
time: 2.3295207023620605
[1, 21960] loss_train: 0.007761, loss_test: 0.005526
time: 0.2600572109222412
time: 2.3785321712493896
[1, 21961] loss_train: 0.003863, loss_test: 0.005526
time: 0.29306483268737793
time: 2.466369152069092
[1, 21962] loss_train: 0.006106, loss_test: 0.005527
time: 0.2857081890106201
time: 2.372926950454712
[1, 21963] loss_train: 0.006561, loss_test: 0.005526
time: 0.24805569648742676
time: 2.3905344009399414
[1, 21964] loss_train: 0.001459, loss_test: 0.005526
time: 0.2690591812133789
time: 2.4529590606689453
[1, 21965] loss_train: 0.010662, loss_test: 0.005524
time: 0.27224135398864746
time: 2.6972339153289795
[1, 21966] loss_train: 0.012150, loss_test: 0.005521
time: 0.28206324577331543
time: 2.6473093032836914
[1, 21967] loss_train: 0.001865, loss_test: 0.005525
time: 0.28386402130126953
time: 2.999863862991333
[1, 21968] loss_train: 0.003885, loss_test: 0.005534
time: 0.2800624370574951
time: 2.859367847442627
[1, 21969] loss_train: 0.006603, loss_test: 0.005544
time: 0.28806471824645996
time: 2.62730073928833
[1, 21970] loss_train: 0.005221, loss_test: 0.005552
time: 0.3320748805999756
time: 2.826328992843628
[1, 21971] loss_train: 0.013828, loss_test: 0.005561
time: 0.45708799362182617
time: 3.1369729042053223
[1, 21972] loss_train: 0.004132, loss_test: 0.005571
time: 0.2730600833892822
time: 2.545569658279419
[1, 21973] loss_train: 0.011176, loss_test: 0.005583
time: 0.2850630283355713
time: 2.735480546951294
[1, 21974] loss_train: 0.004655, loss_test: 0.005580
time: 0.2720601558685303
time: 2.4879608154296875
[1, 21975] loss_train: 0.005859, loss_test: 0.005563
time: 0.2780284881591797
time: 2.4706974029541016
[1, 21976] loss_train: 0.003858, loss_test: 0.005538
time: 0.2830626964569092
time: 2.8926467895507812
[1, 21977] loss_train: 0.005790, loss_test: 0.005522
time: 0.2730600833892822
time: 2.551244020462036
[1, 21978] loss_train: 0.005994, loss_test: 0.005521
time: 0.28206419944763184
time: 2.799677848815918
[1, 21979] loss_train: 0.005950, loss_test: 0.005531
time: 0.28806424140930176
time: 2.6685965061187744
[1, 21980] loss_train: 0.008226, loss_test: 0.005540
time: 0.301067590713501
time: 2.933173894882202
[1, 21981] loss_train: 0.004722, loss_test: 0.005550
time: 0.2750694751739502
time: 2.7643749713897705
[1, 21982] loss_train: 0.009003, loss_test: 0.005555
time: 0.2724127769470215
time: 2.479649543762207
[1, 21983] loss_train: 0.010319, loss_test: 0.005547
time: 0.27906179428100586
time: 2.5525705814361572
[1, 21984] loss_train: 0.005867, loss_test: 0.005541
time: 0.2910642623901367
time: 2.8112921714782715
[1, 21985] loss_train: 0.006898, loss_test: 0.005531
time: 0.28606390953063965
time: 2.4549179077148438
[1, 21986] loss_train: 0.006439, loss_test: 0.005525
time: 0.2730600833892822
time: 2.501767158508301
[1, 21987] loss_train: 0.008657, loss_test: 0.005520
time: 0.27906179428100586
time: 2.7559378147125244
[1, 21988] loss_train: 0.007679, loss_test: 0.005520
time: 0.27006053924560547
time: 2.6117963790893555
[1, 21989] loss_train: 0.002519, loss_test: 0.005523
time: 0.2710597515106201
time: 2.497559070587158
[1, 21990] loss_train: 0.008359, loss_test: 0.005527
time: 0.2892320156097412
time: 2.6552913188934326
[1, 21991] loss_train: 0.012169, loss_test: 0.005533
time: 0.606642484664917
time: 3.16025972366333
[1, 21992] loss_train: 0.017114, loss_test: 0.005539
time: 0.5451195240020752
time: 2.528027057647705
[1, 21993] loss_train: 0.005047, loss_test: 0.005542
time: 0.28606271743774414
time: 2.7295072078704834
[1, 21994] loss_train: 0.018169, loss_test: 0.005547
time: 0.28026747703552246
time: 2.8045365810394287
[1, 21995] loss_train: 0.010942, loss_test: 0.005547
time: 0.27506113052368164
time: 2.7567341327667236
[1, 21996] loss_train: 0.004881, loss_test: 0.005543
time: 0.27185821533203125
time: 2.7286758422851562
[1, 21997] loss_train: 0.001586, loss_test: 0.005537
time: 0.27506184577941895
time: 2.7250852584838867
[1, 21998] loss_train: 0.002109, loss_test: 0.005531
time: 0.27306079864501953
time: 2.553572177886963
[1, 21999] loss_train: 0.006606, loss_test: 0.005527
time: 0.2760610580444336
time: 2.454549551010132
[1, 22000] loss_train: 0.009456, loss_test: 0.005527
time: 0.29107046127319336
time: 2.685793161392212
[1, 22001] loss_train: 0.004355, loss_test: 0.005530
time: 0.2760608196258545
time: 2.7517058849334717
[1, 22002] loss_train: 0.004396, loss_test: 0.005534
time: 0.27506065368652344
time: 3.2627463340759277
[1, 22003] loss_train: 0.008852, loss_test: 0.005538
time: 1.0522689819335938
time: 2.46655535697937
[1, 22004] loss_train: 0.002040, loss_test: 0.005542
time: 0.2730598449707031
time: 2.770620107650757
[1, 22005] loss_train: 0.003255, loss_test: 0.005547
time: 0.2810640335083008
time: 2.7511227130889893
[1, 22006] loss_train: 0.004428, loss_test: 0.005553
time: 0.2760601043701172
time: 2.7072336673736572
[1, 22007] loss_train: 0.005836, loss_test: 0.005556
time: 0.28606295585632324
time: 2.9441230297088623
[1, 22008] loss_train: 0.006922, loss_test: 0.005556
time: 0.29006338119506836
time: 2.4695656299591064
[1, 22009] loss_train: 0.006232, loss_test: 0.005556
time: 0.28007030487060547
time: 2.8565683364868164
[1, 22010] loss_train: 0.007631, loss_test: 0.005558
time: 0.297269344329834
time: 4.108217239379883
[1, 22011] loss_train: 0.014141, loss_test: 0.005550
time: 0.28399157524108887
time: 2.4745538234710693
[1, 22012] loss_train: 0.002050, loss_test: 0.005545
time: 0.3000664710998535
time: 2.684380054473877
[1, 22013] loss_train: 0.012376, loss_test: 0.005536
time: 0.2800624370574951
time: 2.5535829067230225
[1, 22014] loss_train: 0.005399, loss_test: 0.005529
time: 0.33606839179992676
time: 2.437049388885498
[1, 22015] loss_train: 0.006785, loss_test: 0.005522
time: 0.27706193923950195
time: 3.6074581146240234
[1, 22016] loss_train: 0.001232, loss_test: 0.005518
time: 0.2970738410949707
time: 2.674112319946289
[1, 22017] loss_train: 0.002148, loss_test: 0.005517
time: 0.28409719467163086
time: 2.6230928897857666
[1, 22018] loss_train: 0.004777, loss_test: 0.005518
time: 0.27706170082092285
time: 2.523564100265503
[1, 22019] loss_train: 0.003867, loss_test: 0.005519
time: 0.27706146240234375
time: 2.4905567169189453
[1, 22020] loss_train: 0.004842, loss_test: 0.005519
time: 0.30406856536865234
time: 2.532068967819214
[1, 22021] loss_train: 0.007794, loss_test: 0.005517
time: 0.28406333923339844
time: 2.6978437900543213
[1, 22022] loss_train: 0.006296, loss_test: 0.005515
time: 0.2780628204345703
time: 2.813401460647583
[1, 22023] loss_train: 0.003079, loss_test: 0.005514
time: 0.2779381275177002
time: 2.5409512519836426
[1, 22024] loss_train: 0.004917, loss_test: 0.005514
time: 0.274249792098999
time: 2.545145034790039
[1, 22025] loss_train: 0.003359, loss_test: 0.005514
time: 0.28106164932250977
time: 2.5234076976776123
[1, 22026] loss_train: 0.005128, loss_test: 0.005516
time: 0.2760615348815918
time: 2.785623550415039
[1, 22027] loss_train: 0.004897, loss_test: 0.005515
time: 0.2820627689361572
time: 2.723917007446289
[1, 22028] loss_train: 0.012536, loss_test: 0.005514
time: 0.29506564140319824
time: 2.514112710952759
[1, 22029] loss_train: 0.006950, loss_test: 0.005514
time: 0.2787742614746094
time: 2.566736936569214
[1, 22030] loss_train: 0.006830, loss_test: 0.005514
time: 0.3050670623779297
time: 2.6604957580566406
[1, 22031] loss_train: 0.003560, loss_test: 0.005514
time: 0.2976994514465332
time: 2.6242973804473877
[1, 22032] loss_train: 0.004255, loss_test: 0.005514
time: 0.2910635471343994
time: 2.50805401802063
[1, 22033] loss_train: 0.006967, loss_test: 0.005515
time: 0.27906155586242676
time: 2.671360731124878
[1, 22034] loss_train: 0.006873, loss_test: 0.005515
time: 0.28206372261047363
time: 2.6931629180908203
[1, 22035] loss_train: 0.010669, loss_test: 0.005514
time: 0.280062198638916
time: 2.9399378299713135
[1, 22036] loss_train: 0.006020, loss_test: 0.005515
time: 0.2800624370574951
time: 2.6455912590026855
[1, 22037] loss_train: 0.004080, loss_test: 0.005515
time: 0.29506540298461914
time: 2.5900416374206543
[1, 22038] loss_train: 0.011478, loss_test: 0.005515
time: 0.28206372261047363
time: 3.525383472442627
[1, 22039] loss_train: 0.009335, loss_test: 0.005516
time: 0.2830624580383301
time: 2.552564859390259
[1, 22040] loss_train: 0.005956, loss_test: 0.005516
time: 0.2960667610168457
time: 2.71860671043396
[1, 22041] loss_train: 0.006858, loss_test: 0.005517
time: 0.2940659523010254
time: 2.8771119117736816
[1, 22042] loss_train: 0.007781, loss_test: 0.005517
time: 0.2798805236816406
time: 3.033238649368286
[1, 22043] loss_train: 0.006746, loss_test: 0.005516
time: 0.27706146240234375
time: 2.797625780105591
[1, 22044] loss_train: 0.004751, loss_test: 0.005515
time: 0.25705671310424805
time: 2.328521490097046
[1, 22045] loss_train: 0.003810, loss_test: 0.005512
time: 0.24805450439453125
time: 2.33952260017395
[1, 22046] loss_train: 0.005178, loss_test: 0.005511
time: 0.2470545768737793
time: 2.3105170726776123
[1, 22047] loss_train: 0.011761, loss_test: 0.005511
time: 0.2630581855773926
time: 2.512683868408203
[1, 22048] loss_train: 0.002811, loss_test: 0.005511
time: 0.30597925186157227
time: 2.4954652786254883
[1, 22049] loss_train: 0.009088, loss_test: 0.005513
time: 0.2730257511138916
time: 4.079730272293091
[1, 22050] loss_train: 0.005511, loss_test: 0.005515
time: 0.2910640239715576
time: 2.4800589084625244
[1, 22051] loss_train: 0.006716, loss_test: 0.005518
time: 0.25005483627319336
time: 2.6140167713165283
[1, 22052] loss_train: 0.006212, loss_test: 0.005524
time: 0.9592101573944092
time: 2.4571619033813477
[1, 22053] loss_train: 0.000647, loss_test: 0.005527
time: 0.27506065368652344
time: 2.4780733585357666
[1, 22054] loss_train: 0.002825, loss_test: 0.005525
time: 0.27506542205810547
time: 2.690540313720703
[1, 22055] loss_train: 0.013441, loss_test: 0.005525
time: 0.2710597515106201
time: 2.5194711685180664
[1, 22056] loss_train: 0.004706, loss_test: 0.005524
time: 0.27505993843078613
time: 2.5370731353759766
[1, 22057] loss_train: 0.011525, loss_test: 0.005518
time: 0.258056640625
time: 2.878884792327881
[1, 22058] loss_train: 0.002087, loss_test: 0.005516
time: 0.28406333923339844
time: 2.7947490215301514
[1, 22059] loss_train: 0.007613, loss_test: 0.005517
time: 0.27706122398376465
time: 2.5340747833251953
[1, 22060] loss_train: 0.004687, loss_test: 0.005519
time: 0.3400707244873047
time: 2.6101438999176025
[1, 22061] loss_train: 0.012868, loss_test: 0.005521
time: 0.2900669574737549
time: 2.6455841064453125
[1, 22062] loss_train: 0.006681, loss_test: 0.005524
time: 0.28406190872192383
time: 3.615312099456787
[1, 22063] loss_train: 0.004430, loss_test: 0.005530
time: 0.2988312244415283
time: 2.482286214828491
[1, 22064] loss_train: 0.006664, loss_test: 0.005534
time: 0.3489983081817627
time: 2.8414437770843506
[1, 22065] loss_train: 0.005320, loss_test: 0.005538
time: 0.2940640449523926
time: 2.6591367721557617
[1, 22066] loss_train: 0.006912, loss_test: 0.005541
time: 0.2740612030029297
time: 2.5162465572357178
[1, 22067] loss_train: 0.006970, loss_test: 0.005544
time: 0.30193018913269043
time: 2.7524023056030273
[1, 22068] loss_train: 0.006179, loss_test: 0.005543
time: 0.2830631732940674
time: 2.610583543777466
[1, 22069] loss_train: 0.013528, loss_test: 0.005540
time: 0.2780616283416748
time: 2.503416061401367
[1, 22070] loss_train: 0.004988, loss_test: 0.005533
time: 0.291064977645874
time: 2.558572292327881
[1, 22071] loss_train: 0.006145, loss_test: 0.005530
time: 0.2490546703338623
time: 3.1671886444091797
[1, 22072] loss_train: 0.005966, loss_test: 0.005528
time: 0.2720611095428467
time: 2.9120733737945557
[1, 22073] loss_train: 0.007123, loss_test: 0.005527
time: 0.2500612735748291
time: 2.3912837505340576
[1, 22074] loss_train: 0.009585, loss_test: 0.005527
time: 0.2690596580505371
time: 2.4616312980651855
[1, 22075] loss_train: 0.006777, loss_test: 0.005527
time: 0.2800619602203369
time: 2.484556198120117
[1, 22076] loss_train: 0.009559, loss_test: 0.005529
time: 0.25505638122558594
time: 2.649724245071411
[1, 22077] loss_train: 0.006098, loss_test: 0.005530
time: 0.2777276039123535
time: 2.5065605640411377
[1, 22078] loss_train: 0.006709, loss_test: 0.005533
time: 0.2764310836791992
time: 3.3182826042175293
[1, 22079] loss_train: 0.010108, loss_test: 0.005534
time: 0.27106690406799316
time: 2.4935481548309326
[1, 22080] loss_train: 0.002106, loss_test: 0.005535
time: 0.3050680160522461
time: 2.6110358238220215
[1, 22081] loss_train: 0.000796, loss_test: 0.005536
time: 0.2740607261657715
time: 2.535585403442383
[1, 22082] loss_train: 0.007343, loss_test: 0.005536
time: 0.2711372375488281
time: 2.588256359100342
[1, 22083] loss_train: 0.002637, loss_test: 0.005536
time: 0.2765848636627197
time: 2.875358819961548
[1, 22084] loss_train: 0.010112, loss_test: 0.005536
time: 0.2720658779144287
time: 3.4857218265533447
[1, 22085] loss_train: 0.005725, loss_test: 0.005533
time: 0.35336899757385254
time: 3.3282787799835205
[1, 22086] loss_train: 0.004941, loss_test: 0.005530
time: 0.5761234760284424
time: 2.5004024505615234
[1, 22087] loss_train: 0.006166, loss_test: 0.005529
time: 0.2857997417449951
time: 2.7511656284332275
[1, 22088] loss_train: 0.009989, loss_test: 0.005529
time: 0.2770671844482422
time: 2.471086263656616
[1, 22089] loss_train: 0.004993, loss_test: 0.005528
time: 0.2910652160644531
time: 2.5834097862243652
[1, 22090] loss_train: 0.007459, loss_test: 0.005526
time: 0.3030838966369629
time: 2.5722711086273193
[1, 22091] loss_train: 0.000573, loss_test: 0.005524
time: 0.30406761169433594
time: 2.5531020164489746
[1, 22092] loss_train: 0.005919, loss_test: 0.005522
time: 0.28106141090393066
time: 2.6395907402038574
[1, 22093] loss_train: 0.010408, loss_test: 0.005520
time: 0.2760615348815918
time: 2.5881266593933105
[1, 22094] loss_train: 0.010427, loss_test: 0.005518
time: 0.29506611824035645
time: 2.6350150108337402
[1, 22095] loss_train: 0.013565, loss_test: 0.005514
time: 0.29007482528686523
time: 3.371974468231201
[1, 22096] loss_train: 0.004073, loss_test: 0.005511
time: 0.3050673007965088
time: 2.5724165439605713
[1, 22097] loss_train: 0.000568, loss_test: 0.005510
time: 0.2770655155181885
time: 2.6404945850372314
[1, 22098] loss_train: 0.009556, loss_test: 0.005509
time: 0.3100748062133789
time: 2.664597272872925
[1, 22099] loss_train: 0.009632, loss_test: 0.005510
time: 0.27906179428100586
time: 2.5547571182250977
[1, 22100] loss_train: 0.009246, loss_test: 0.005512
time: 0.29607343673706055
time: 3.5987231731414795
[1, 22101] loss_train: 0.009945, loss_test: 0.005513
time: 0.27506041526794434
time: 2.599088191986084
[1, 22102] loss_train: 0.008570, loss_test: 0.005511
time: 0.31006932258605957
time: 2.5095608234405518
[1, 22103] loss_train: 0.008207, loss_test: 0.005511
time: 0.28406357765197754
time: 2.921779155731201
[1, 22104] loss_train: 0.007558, loss_test: 0.005512
time: 0.28406238555908203
time: 3.371887683868408
[1, 22105] loss_train: 0.009603, loss_test: 0.005515
time: 0.2925698757171631
time: 2.847623348236084
[1, 22106] loss_train: 0.004178, loss_test: 0.005518
time: 0.2750115394592285
time: 2.496694326400757
[1, 22107] loss_train: 0.005381, loss_test: 0.005520
time: 0.2850637435913086
time: 2.8907670974731445
[1, 22108] loss_train: 0.007299, loss_test: 0.005520
time: 0.27706241607666016
time: 2.601222515106201
[1, 22109] loss_train: 0.008741, loss_test: 0.005519
time: 1.0082430839538574
time: 3.1082420349121094
[1, 22110] loss_train: 0.003943, loss_test: 0.005517
time: 0.3072011470794678
time: 2.631578207015991
[1, 22111] loss_train: 0.006899, loss_test: 0.005517
time: 0.2780623435974121
time: 3.055481433868408
[1, 22112] loss_train: 0.004785, loss_test: 0.005519
time: 0.27506136894226074
time: 2.499939203262329
[1, 22113] loss_train: 0.005079, loss_test: 0.005524
time: 0.2780625820159912
time: 2.583969831466675
[1, 22114] loss_train: 0.007607, loss_test: 0.005530
time: 0.35121583938598633
time: 2.3600335121154785
[1, 22115] loss_train: 0.001419, loss_test: 0.005538
time: 0.25305604934692383
time: 2.384533405303955
[1, 22116] loss_train: 0.007893, loss_test: 0.005544
time: 0.27506089210510254
time: 2.396536111831665
[1, 22117] loss_train: 0.002523, loss_test: 0.005551
time: 0.26205897331237793
time: 2.481126070022583
[1, 22118] loss_train: 0.006092, loss_test: 0.005554
time: 0.277024507522583
time: 2.6007797718048096
[1, 22119] loss_train: 0.007286, loss_test: 0.005556
time: 0.28806424140930176
time: 2.5475502014160156
[1, 22120] loss_train: 0.008190, loss_test: 0.005552
time: 0.296065092086792
time: 2.900198221206665
[1, 22121] loss_train: 0.006320, loss_test: 0.005546
time: 0.28606438636779785
time: 2.703355073928833
[1, 22122] loss_train: 0.003432, loss_test: 0.005542
time: 0.28806400299072266
time: 2.8280656337738037
[1, 22123] loss_train: 0.006904, loss_test: 0.005537
time: 0.27706098556518555
time: 2.769650936126709
[1, 22124] loss_train: 0.008734, loss_test: 0.005533
time: 0.31006789207458496
time: 2.5166678428649902
[1, 22125] loss_train: 0.007272, loss_test: 0.005529
time: 0.2780647277832031
time: 2.6270334720611572
[1, 22126] loss_train: 0.011278, loss_test: 0.005528
time: 0.2740604877471924
time: 3.156928777694702
[1, 22127] loss_train: 0.002418, loss_test: 0.005527
time: 0.2940547466278076
time: 2.4675652980804443
[1, 22128] loss_train: 0.006899, loss_test: 0.005527
time: 0.27506160736083984
time: 2.5590763092041016
[1, 22129] loss_train: 0.009761, loss_test: 0.005527
time: 0.2890653610229492
time: 2.5396981239318848
[1, 22130] loss_train: 0.012662, loss_test: 0.005527
time: 0.2978212833404541
time: 2.4892468452453613
[1, 22131] loss_train: 0.005334, loss_test: 0.005527
time: 0.29059553146362305
time: 2.5288796424865723
[1, 22132] loss_train: 0.002167, loss_test: 0.005527
time: 0.27706146240234375
time: 2.591505527496338
[1, 22133] loss_train: 0.016174, loss_test: 0.005525
time: 0.3000664710998535
time: 2.648127794265747
[1, 22134] loss_train: 0.012469, loss_test: 0.005521
time: 0.2870640754699707
time: 2.498194932937622
[1, 22135] loss_train: 0.002760, loss_test: 0.005515
time: 0.28406262397766113
time: 2.6684086322784424
[1, 22136] loss_train: 0.004128, loss_test: 0.005511
time: 0.2820615768432617
time: 2.5524497032165527
[1, 22137] loss_train: 0.009425, loss_test: 0.005512
time: 0.2780649662017822
time: 2.455674886703491
[1, 22138] loss_train: 0.002247, loss_test: 0.005517
time: 0.2780640125274658
time: 2.526820421218872
[1, 22139] loss_train: 0.005889, loss_test: 0.005522
time: 0.2820615768432617
time: 2.481555700302124
[1, 22140] loss_train: 0.002471, loss_test: 0.005530
time: 0.29870057106018066
time: 2.59981632232666
[1, 22141] loss_train: 0.007545, loss_test: 0.005536
time: 0.2776064872741699
time: 2.4875566959381104
[1, 22142] loss_train: 0.008880, loss_test: 0.005543
time: 0.2760615348815918
time: 2.604020118713379
[1, 22143] loss_train: 0.006077, loss_test: 0.005548
time: 0.27506017684936523
time: 2.543578863143921
[1, 22144] loss_train: 0.000521, loss_test: 0.005552
time: 0.28806209564208984
time: 2.528078079223633
[1, 22145] loss_train: 0.001924, loss_test: 0.005559
time: 1.0502269268035889
time: 2.624586343765259
[1, 22146] loss_train: 0.001697, loss_test: 0.005565
time: 0.2760627269744873
time: 2.6237001419067383
[1, 22147] loss_train: 0.005537, loss_test: 0.005569
time: 0.27506089210510254
time: 2.4466588497161865
[1, 22148] loss_train: 0.003269, loss_test: 0.005571
time: 0.2760612964630127
time: 2.6966042518615723
[1, 22149] loss_train: 0.008133, loss_test: 0.005570
time: 0.27893710136413574
time: 2.567964553833008
[1, 22150] loss_train: 0.003815, loss_test: 0.005565
time: 0.29802870750427246
time: 2.760221242904663
[1, 22151] loss_train: 0.006037, loss_test: 0.005559
time: 0.2780618667602539
time: 2.470791816711426
[1, 22152] loss_train: 0.000612, loss_test: 0.005557
time: 0.28706812858581543
time: 2.596080780029297
[1, 22153] loss_train: 0.005229, loss_test: 0.005553
time: 0.2740600109100342
time: 3.0946922302246094
[1, 22154] loss_train: 0.000661, loss_test: 0.005551
time: 0.2760653495788574
time: 2.496100902557373
[1, 22155] loss_train: 0.004175, loss_test: 0.005550
time: 0.28056788444519043
time: 2.472827196121216
[1, 22156] loss_train: 0.006572, loss_test: 0.005551
time: 0.28006505966186523
time: 2.470341920852661
[1, 22157] loss_train: 0.001848, loss_test: 0.005554
time: 0.28422999382019043
time: 2.5691418647766113
[1, 22158] loss_train: 0.002392, loss_test: 0.005561
time: 0.2760615348815918
time: 2.595086097717285
[1, 22159] loss_train: 0.009234, loss_test: 0.005566
time: 0.29506492614746094
time: 2.6781139373779297
[1, 22160] loss_train: 0.005734, loss_test: 0.005568
time: 0.2960660457611084
time: 3.0029191970825195
[1, 22161] loss_train: 0.014118, loss_test: 0.005559
time: 0.27763962745666504
time: 2.5045745372772217
[1, 22162] loss_train: 0.004957, loss_test: 0.005541
time: 0.29306578636169434
time: 2.6211981773376465
[1, 22163] loss_train: 0.006227, loss_test: 0.005529
time: 0.27802133560180664
time: 2.4566454887390137
[1, 22164] loss_train: 0.009394, loss_test: 0.005523
time: 0.2875821590423584
time: 2.677590847015381
[1, 22165] loss_train: 0.002424, loss_test: 0.005519
time: 0.27506160736083984
time: 2.624589681625366
[1, 22166] loss_train: 0.006064, loss_test: 0.005518
time: 0.27906203269958496
time: 2.4779319763183594
[1, 22167] loss_train: 0.002549, loss_test: 0.005520
time: 0.2740607261657715
time: 2.5480756759643555
[1, 22168] loss_train: 0.005358, loss_test: 0.005525
time: 0.282062292098999
time: 2.5006020069122314
[1, 22169] loss_train: 0.007238, loss_test: 0.005532
time: 0.2840726375579834
time: 2.6481716632843018
[1, 22170] loss_train: 0.004221, loss_test: 0.005540
time: 0.2930624485015869
time: 2.531485080718994
[1, 22171] loss_train: 0.002065, loss_test: 0.005548
time: 0.28806281089782715
time: 2.46696138381958
[1, 22172] loss_train: 0.003532, loss_test: 0.005550
time: 0.2740609645843506
time: 2.5488805770874023
[1, 22173] loss_train: 0.004610, loss_test: 0.005553
time: 0.2960665225982666
time: 2.593038320541382
[1, 22174] loss_train: 0.005206, loss_test: 0.005549
time: 0.2900676727294922
time: 2.681459426879883
[1, 22175] loss_train: 0.007630, loss_test: 0.005548
time: 0.28106188774108887
time: 2.4864273071289062
[1, 22176] loss_train: 0.001927, loss_test: 0.005546
time: 0.2780618667602539
time: 2.676527976989746
[1, 22177] loss_train: 0.007564, loss_test: 0.005548
time: 0.2800624370574951
time: 2.4795632362365723
[1, 22178] loss_train: 0.007317, loss_test: 0.005547
time: 0.2800619602203369
time: 2.737612724304199
[1, 22179] loss_train: 0.003222, loss_test: 0.005549
time: 0.280062198638916
time: 2.7033660411834717
[1, 22180] loss_train: 0.005689, loss_test: 0.005552
time: 0.30158400535583496
time: 2.460073232650757
[1, 22181] loss_train: 0.013782, loss_test: 0.005546
time: 0.27706193923950195
time: 3.2466530799865723
[1, 22182] loss_train: 0.001121, loss_test: 0.005543
time: 0.2800636291503906
time: 2.4982194900512695
[1, 22183] loss_train: 0.006594, loss_test: 0.005543
time: 0.2922825813293457
time: 2.4868104457855225
[1, 22184] loss_train: 0.004665, loss_test: 0.005545
time: 0.2740602493286133
time: 2.5165648460388184
[1, 22185] loss_train: 0.003367, loss_test: 0.005545
time: 0.2810628414154053
time: 2.5677433013916016
[1, 22186] loss_train: 0.010218, loss_test: 0.005540
time: 0.27689290046691895
time: 2.5139541625976562
[1, 22187] loss_train: 0.000795, loss_test: 0.005537
time: 0.35507893562316895
time: 2.834869146347046
[1, 22188] loss_train: 0.009305, loss_test: 0.005533
time: 0.31705808639526367
time: 2.6343929767608643
[1, 22189] loss_train: 0.009051, loss_test: 0.005529
time: 0.2780611515045166
time: 2.445554494857788
[1, 22190] loss_train: 0.003950, loss_test: 0.005527
time: 0.29706573486328125
time: 2.8099305629730225
[1, 22191] loss_train: 0.009693, loss_test: 0.005525
time: 0.2800629138946533
time: 2.50150465965271
[1, 22192] loss_train: 0.010502, loss_test: 0.005523
time: 0.27498316764831543
time: 2.603756904602051
[1, 22193] loss_train: 0.015469, loss_test: 0.005529
time: 0.2720601558685303
time: 2.7502565383911133
[1, 22194] loss_train: 0.005651, loss_test: 0.005541
time: 0.27906203269958496
time: 2.44307541847229
[1, 22195] loss_train: 0.003393, loss_test: 0.005554
time: 0.29206418991088867
time: 2.461054563522339
[1, 22196] loss_train: 0.007303, loss_test: 0.005562
time: 0.28056836128234863
time: 2.670102834701538
[1, 22197] loss_train: 0.009211, loss_test: 0.005563
time: 0.25705671310424805
time: 2.3165183067321777
[1, 22198] loss_train: 0.003799, loss_test: 0.005559
time: 0.24805474281311035
time: 2.324523687362671
[1, 22199] loss_train: 0.006545, loss_test: 0.005544
time: 0.2465662956237793
time: 2.316519021987915
[1, 22200] loss_train: 0.004641, loss_test: 0.005532
time: 0.2620580196380615
time: 2.3765320777893066
[1, 22201] loss_train: 0.006573, loss_test: 0.005522
time: 0.27906250953674316
time: 2.4906787872314453
[1, 22202] loss_train: 0.002168, loss_test: 0.005514
time: 0.30206751823425293
time: 2.474426031112671
[1, 22203] loss_train: 0.000428, loss_test: 0.005510
time: 0.26405811309814453
time: 2.4859070777893066
[1, 22204] loss_train: 0.004165, loss_test: 0.005515
time: 0.2520561218261719
time: 2.365842342376709
[1, 22205] loss_train: 0.003971, loss_test: 0.005525
time: 0.2560563087463379
time: 2.286625385284424
[1, 22206] loss_train: 0.004671, loss_test: 0.005537
time: 0.2520558834075928
time: 2.3115177154541016
[1, 22207] loss_train: 0.002122, loss_test: 0.005550
time: 0.2510559558868408
time: 2.308516025543213
[1, 22208] loss_train: 0.002342, loss_test: 0.005562
time: 0.2980673313140869
time: 2.3248612880706787
[1, 22209] loss_train: 0.005486, loss_test: 0.005572
time: 0.27266454696655273
time: 2.3296217918395996
[1, 22210] loss_train: 0.005956, loss_test: 0.005575
time: 0.2620575428009033
time: 2.292513370513916
[1, 22211] loss_train: 0.008536, loss_test: 0.005570
time: 0.24805474281311035
time: 2.2985146045684814
[1, 22212] loss_train: 0.005654, loss_test: 0.005556
time: 0.2470550537109375
time: 2.2905123233795166
[1, 22213] loss_train: 0.004239, loss_test: 0.005548
time: 0.25905752182006836
time: 2.266507148742676
[1, 22214] loss_train: 0.003782, loss_test: 0.005545
time: 0.2470555305480957
time: 2.2835099697113037
[1, 22215] loss_train: 0.005066, loss_test: 0.005546
time: 0.2530550956726074
time: 2.278510332107544
[1, 22216] loss_train: 0.006589, loss_test: 0.005548
time: 0.24805426597595215
time: 2.2775115966796875
[1, 22217] loss_train: 0.007066, loss_test: 0.005553
time: 0.2490556240081787
time: 2.265507221221924
[1, 22218] loss_train: 0.003354, loss_test: 0.005560
time: 0.24805498123168945
time: 2.2815098762512207
[1, 22219] loss_train: 0.002785, loss_test: 0.005566
time: 0.24805593490600586
time: 2.27251935005188
[1, 22220] loss_train: 0.002960, loss_test: 0.005571
time: 0.2650585174560547
time: 2.2735090255737305
[1, 22221] loss_train: 0.009675, loss_test: 0.005568
time: 0.25005578994750977
time: 2.270507335662842
[1, 22222] loss_train: 0.011065, loss_test: 0.005568
time: 0.24905681610107422
time: 2.2655045986175537
[1, 22223] loss_train: 0.003481, loss_test: 0.005570
time: 0.2510561943054199
time: 2.2585055828094482
[1, 22224] loss_train: 0.001531, loss_test: 0.005575
time: 0.24805498123168945
time: 2.2655065059661865
[1, 22225] loss_train: 0.000680, loss_test: 0.005579
time: 0.2470555305480957
time: 2.244502067565918
[1, 22226] loss_train: 0.007225, loss_test: 0.005584
time: 0.2490558624267578
time: 2.273507833480835
[1, 22227] loss_train: 0.009087, loss_test: 0.005589
time: 0.2520561218261719
time: 2.269507646560669
[1, 22228] loss_train: 0.007467, loss_test: 0.005593
time: 0.24805450439453125
time: 2.2615063190460205
[1, 22229] loss_train: 0.007232, loss_test: 0.005602
time: 0.24805450439453125
time: 2.2745089530944824
[1, 22230] loss_train: 0.003332, loss_test: 0.005610
time: 0.2630581855773926
time: 2.2385013103485107
[1, 22231] loss_train: 0.006849, loss_test: 0.005612
time: 0.24805498123168945
time: 2.2615058422088623
[1, 22232] loss_train: 0.006710, loss_test: 0.005611
time: 0.24805498123168945
time: 2.248502731323242
[1, 22233] loss_train: 0.004325, loss_test: 0.005610
time: 0.24805521965026855
time: 2.255504846572876
[1, 22234] loss_train: 0.003639, loss_test: 0.005609
time: 0.2540569305419922
time: 2.2755093574523926
[1, 22235] loss_train: 0.005831, loss_test: 0.005610
time: 0.24805498123168945
time: 2.2685070037841797
[1, 22236] loss_train: 0.002516, loss_test: 0.005606
time: 0.24805498123168945
time: 2.261505603790283
[1, 22237] loss_train: 0.003198, loss_test: 0.005600
time: 0.2470548152923584
time: 2.2755093574523926
[1, 22238] loss_train: 0.003686, loss_test: 0.005596
time: 0.24957060813903809
time: 2.2495031356811523
[1, 22239] loss_train: 0.006118, loss_test: 0.005593
time: 0.2490551471710205
time: 2.2725086212158203
[1, 22240] loss_train: 0.003798, loss_test: 0.005590
time: 0.267059326171875
time: 2.2845101356506348
[1, 22241] loss_train: 0.010374, loss_test: 0.005577
time: 0.24805498123168945
time: 2.3115174770355225
[1, 22242] loss_train: 0.008240, loss_test: 0.005567
time: 0.2540569305419922
time: 2.272507905960083
[1, 22243] loss_train: 0.007287, loss_test: 0.005555
time: 0.24805545806884766
time: 2.2565038204193115
[1, 22244] loss_train: 0.005353, loss_test: 0.005552
time: 0.2510557174682617
time: 2.265507698059082
[1, 22245] loss_train: 0.006649, loss_test: 0.005552
time: 0.2499840259552002
time: 2.241501569747925
[1, 22246] loss_train: 0.001667, loss_test: 0.005554
time: 0.25005650520324707
time: 2.250502586364746
[1, 22247] loss_train: 0.007636, loss_test: 0.005559
time: 0.24805545806884766
time: 2.2645061016082764
[1, 22248] loss_train: 0.003737, loss_test: 0.005561
time: 0.25005507469177246
time: 2.2645068168640137
[1, 22249] loss_train: 0.001867, loss_test: 0.005560
time: 0.25005555152893066
time: 2.2465028762817383
[1, 22250] loss_train: 0.005451, loss_test: 0.005549
time: 0.2600576877593994
time: 2.2735085487365723
[1, 22251] loss_train: 0.018224, loss_test: 0.005538
time: 0.2510552406311035
time: 2.267507553100586
[1, 22252] loss_train: 0.007212, loss_test: 0.005530
time: 0.2470552921295166
time: 2.2515029907226562
[1, 22253] loss_train: 0.009588, loss_test: 0.005527
time: 0.24811530113220215
time: 2.257505178451538
[1, 22254] loss_train: 0.008842, loss_test: 0.005529
time: 0.24805521965026855
time: 2.2485010623931885
[1, 22255] loss_train: 0.009745, loss_test: 0.005528
time: 0.2540566921234131
time: 2.2405009269714355
[1, 22256] loss_train: 0.004710, loss_test: 0.005532
time: 0.2490558624267578
time: 2.2445015907287598
[1, 22257] loss_train: 0.007774, loss_test: 0.005539
time: 0.24805474281311035
time: 2.2800133228302
[1, 22258] loss_train: 0.010050, loss_test: 0.005543
time: 0.24805545806884766
time: 2.277508497238159
[1, 22259] loss_train: 0.003004, loss_test: 0.005546
time: 0.24806761741638184
time: 2.2698824405670166
[1, 22260] loss_train: 0.008761, loss_test: 0.005553
time: 0.25905752182006836
time: 2.2715086936950684
[1, 22261] loss_train: 0.002756, loss_test: 0.005563
time: 0.24805521965026855
time: 2.274508476257324
[1, 22262] loss_train: 0.005066, loss_test: 0.005569
time: 0.2520565986633301
time: 2.262505531311035
[1, 22263] loss_train: 0.009609, loss_test: 0.005564
time: 0.24805545806884766
time: 2.24050235748291
[1, 22264] loss_train: 0.006171, loss_test: 0.005558
time: 0.24805521965026855
time: 2.2635064125061035
[1, 22265] loss_train: 0.010384, loss_test: 0.005551
time: 0.2470545768737793
time: 2.2965149879455566
[1, 22266] loss_train: 0.008519, loss_test: 0.005549
time: 0.24805378913879395
time: 2.2575089931488037
[1, 22267] loss_train: 0.005893, loss_test: 0.005547
time: 0.25005459785461426
time: 2.278510093688965
[1, 22268] loss_train: 0.003206, loss_test: 0.005543
time: 0.24805545806884766
time: 2.25750470161438
[1, 22269] loss_train: 0.001484, loss_test: 0.005538
time: 0.2510559558868408
time: 2.2755086421966553
[1, 22270] loss_train: 0.004683, loss_test: 0.005534
time: 0.2630581855773926
time: 2.281510829925537
[1, 22271] loss_train: 0.002925, loss_test: 0.005530
time: 0.2510557174682617
time: 2.272507905960083
[1, 22272] loss_train: 0.000622, loss_test: 0.005525
time: 0.24805474281311035
time: 2.2735087871551514
[1, 22273] loss_train: 0.005548, loss_test: 0.005523
time: 0.25305676460266113
time: 2.261505603790283
[1, 22274] loss_train: 0.001832, loss_test: 0.005527
time: 0.2470543384552002
time: 2.2455027103424072
[1, 22275] loss_train: 0.009497, loss_test: 0.005532
time: 0.2540562152862549
time: 2.2515039443969727
[1, 22276] loss_train: 0.004721, loss_test: 0.005536
time: 0.2510552406311035
time: 2.266507387161255
[1, 22277] loss_train: 0.004149, loss_test: 0.005545
time: 0.25305676460266113
time: 2.2685070037841797
[1, 22278] loss_train: 0.006094, loss_test: 0.005554
time: 0.2470545768737793
time: 2.233499765396118
[1, 22279] loss_train: 0.011375, loss_test: 0.005556
time: 0.25405311584472656
time: 2.247502326965332
[1, 22280] loss_train: 0.004893, loss_test: 0.005556
time: 0.2630586624145508
time: 2.2595062255859375
[1, 22281] loss_train: 0.005410, loss_test: 0.005553
time: 0.2510557174682617
time: 2.2489631175994873
[1, 22282] loss_train: 0.003145, loss_test: 0.005550
time: 0.2510550022125244
time: 2.2610387802124023
[1, 22283] loss_train: 0.008554, loss_test: 0.005543
time: 0.2490551471710205
time: 2.2545042037963867
[1, 22284] loss_train: 0.000682, loss_test: 0.005538
time: 0.24805545806884766
time: 2.2785091400146484
[1, 22285] loss_train: 0.005438, loss_test: 0.005533
time: 0.2490556240081787
time: 2.2545042037963867
[1, 22286] loss_train: 0.005839, loss_test: 0.005529
time: 0.24805474281311035
time: 2.2775096893310547
[1, 22287] loss_train: 0.012168, loss_test: 0.005529
time: 0.254056453704834
time: 2.2785115242004395
[1, 22288] loss_train: 0.009759, loss_test: 0.005534
time: 0.2470569610595703
time: 2.272507905960083
[1, 22289] loss_train: 0.003146, loss_test: 0.005541
time: 0.24805474281311035
time: 2.2485032081604004
[1, 22290] loss_train: 0.010560, loss_test: 0.005551
time: 0.2620577812194824
time: 2.252504348754883
[1, 22291] loss_train: 0.008878, loss_test: 0.005561
time: 0.24805521965026855
time: 2.2715084552764893
[1, 22292] loss_train: 0.006349, loss_test: 0.005570
time: 0.25005602836608887
time: 2.280510187149048
[1, 22293] loss_train: 0.003382, loss_test: 0.005569
time: 0.24805426597595215
time: 2.243502616882324
[1, 22294] loss_train: 0.002173, loss_test: 0.005564
time: 0.25005507469177246
time: 2.290513038635254
[1, 22295] loss_train: 0.010249, loss_test: 0.005559
time: 0.2470543384552002
time: 2.2985143661499023
[1, 22296] loss_train: 0.006914, loss_test: 0.005553
time: 0.24805498123168945
time: 2.2555036544799805
[1, 22297] loss_train: 0.005368, loss_test: 0.005546
time: 0.2470545768737793
time: 2.274508476257324
[1, 22298] loss_train: 0.003708, loss_test: 0.005539
time: 0.2490551471710205
time: 2.279510498046875
[1, 22299] loss_train: 0.002000, loss_test: 0.005534
time: 0.2490549087524414
time: 2.2635061740875244
[1, 22300] loss_train: 0.002248, loss_test: 0.005529
time: 0.2600574493408203
time: 2.2515037059783936
[1, 22301] loss_train: 0.013409, loss_test: 0.005529
time: 0.25005626678466797
time: 2.2565042972564697
[1, 22302] loss_train: 0.002491, loss_test: 0.005531
time: 0.25205564498901367
time: 2.2715084552764893
[1, 22303] loss_train: 0.011243, loss_test: 0.005537
time: 0.25005602836608887
time: 2.2925148010253906
[1, 22304] loss_train: 0.005382, loss_test: 0.005540
time: 0.25305604934692383
time: 2.269507884979248
[1, 22305] loss_train: 0.005518, loss_test: 0.005542
time: 0.2490551471710205
time: 2.261505603790283
[1, 22306] loss_train: 0.012846, loss_test: 0.005544
time: 0.254056453704834
time: 2.243501663208008
[1, 22307] loss_train: 0.007462, loss_test: 0.005541
time: 0.2490546703338623
time: 2.2505035400390625
[1, 22308] loss_train: 0.009021, loss_test: 0.005542
time: 0.2580573558807373
time: 2.234499931335449
[1, 22309] loss_train: 0.007166, loss_test: 0.005540
time: 0.24805569648742676
time: 2.2565114498138428
[1, 22310] loss_train: 0.006898, loss_test: 0.005539
time: 0.2670722007751465
time: 2.25350284576416
[1, 22311] loss_train: 0.009314, loss_test: 0.005535
time: 0.24805641174316406
time: 2.270507574081421
[1, 22312] loss_train: 0.002134, loss_test: 0.005530
time: 0.2580580711364746
time: 2.2545037269592285
[1, 22313] loss_train: 0.006264, loss_test: 0.005526
time: 0.2470545768737793
time: 2.2395012378692627
[1, 22314] loss_train: 0.007381, loss_test: 0.005524
time: 0.25005507469177246
time: 2.265507221221924
[1, 22315] loss_train: 0.003145, loss_test: 0.005522
time: 0.2490549087524414
time: 2.2895123958587646
[1, 22316] loss_train: 0.009401, loss_test: 0.005519
time: 0.24805569648742676
time: 2.2565042972564697
[1, 22317] loss_train: 0.002057, loss_test: 0.005518
time: 0.24805450439453125
time: 2.2455132007598877
[1, 22318] loss_train: 0.001483, loss_test: 0.005518
time: 0.24805569648742676
time: 2.2635064125061035
[1, 22319] loss_train: 0.007662, loss_test: 0.005518
time: 0.2520561218261719
time: 2.2925126552581787
[1, 22320] loss_train: 0.005223, loss_test: 0.005518
time: 0.25905680656433105
time: 2.253504514694214
[1, 22321] loss_train: 0.003940, loss_test: 0.005518
time: 0.2490549087524414
time: 2.28351092338562
[1, 22322] loss_train: 0.004526, loss_test: 0.005519
time: 0.2490553855895996
time: 2.2745091915130615
[1, 22323] loss_train: 0.005665, loss_test: 0.005520
time: 0.24805521965026855
time: 2.2685070037841797
[1, 22324] loss_train: 0.006639, loss_test: 0.005522
time: 0.2470550537109375
time: 2.2775115966796875
[1, 22325] loss_train: 0.008890, loss_test: 0.005523
time: 0.24805474281311035
time: 2.2815234661102295
[1, 22326] loss_train: 0.006547, loss_test: 0.005525
time: 0.25305604934692383
time: 2.2785098552703857
[1, 22327] loss_train: 0.002845, loss_test: 0.005527
time: 0.24805498123168945
time: 2.2605059146881104
[1, 22328] loss_train: 0.005417, loss_test: 0.005528
time: 0.25005578994750977
time: 2.2555038928985596
[1, 22329] loss_train: 0.008902, loss_test: 0.005527
time: 0.24805521965026855
time: 2.3025174140930176
[1, 22330] loss_train: 0.007422, loss_test: 0.005525
time: 0.2600576877593994
time: 2.273508071899414
[1, 22331] loss_train: 0.008811, loss_test: 0.005524
time: 0.2540569305419922
time: 2.3135173320770264
[1, 22332] loss_train: 0.017282, loss_test: 0.005524
time: 0.2490553855895996
time: 2.271507501602173
[1, 22333] loss_train: 0.003890, loss_test: 0.005527
time: 0.25505661964416504
time: 2.2465031147003174
[1, 22334] loss_train: 0.013943, loss_test: 0.005533
time: 0.24805521965026855
time: 2.2600340843200684
[1, 22335] loss_train: 0.001877, loss_test: 0.005541
time: 0.25505638122558594
time: 2.2645068168640137
[1, 22336] loss_train: 0.004136, loss_test: 0.005548
time: 0.2510561943054199
time: 2.245511531829834
[1, 22337] loss_train: 0.003770, loss_test: 0.005552
time: 0.25005578994750977
time: 2.269535541534424
[1, 22338] loss_train: 0.017035, loss_test: 0.005558
time: 0.2490556240081787
time: 2.281534433364868
[1, 22339] loss_train: 0.003370, loss_test: 0.005556
time: 0.24805593490600586
time: 2.2545037269592285
[1, 22340] loss_train: 0.009386, loss_test: 0.005561
time: 0.26105785369873047
time: 2.2585065364837646
[1, 22341] loss_train: 0.007165, loss_test: 0.005562
time: 0.25205492973327637
time: 2.2820138931274414
[1, 22342] loss_train: 0.004011, loss_test: 0.005559
time: 0.2470550537109375
time: 2.2815093994140625
[1, 22343] loss_train: 0.002475, loss_test: 0.005550
time: 0.2520568370819092
time: 2.2835097312927246
[1, 22344] loss_train: 0.004004, loss_test: 0.005539
time: 0.24605464935302734
time: 2.257504463195801
[1, 22345] loss_train: 0.003635, loss_test: 0.005529
time: 0.2470543384552002
time: 2.254504919052124
[1, 22346] loss_train: 0.004938, loss_test: 0.005524
time: 0.24805545806884766
time: 2.2585039138793945
[1, 22347] loss_train: 0.004059, loss_test: 0.005524
time: 0.25005602836608887
time: 2.2525041103363037
[1, 22348] loss_train: 0.006145, loss_test: 0.005528
time: 0.2490541934967041
time: 2.2725088596343994
[1, 22349] loss_train: 0.006561, loss_test: 0.005533
time: 0.2490546703338623
time: 2.244502305984497
[1, 22350] loss_train: 0.005796, loss_test: 0.005538
time: 0.25905752182006836
time: 2.2795095443725586
[1, 22351] loss_train: 0.008078, loss_test: 0.005540
time: 0.2490556240081787
time: 2.2695071697235107
[1, 22352] loss_train: 0.010852, loss_test: 0.005538
time: 0.24805593490600586
time: 2.254007339477539
[1, 22353] loss_train: 0.004824, loss_test: 0.005537
time: 0.2490549087524414
time: 2.256505250930786
[1, 22354] loss_train: 0.006567, loss_test: 0.005536
time: 0.2540562152862549
time: 2.2895123958587646
[1, 22355] loss_train: 0.005222, loss_test: 0.005536
time: 0.24605512619018555
time: 2.250502109527588
[1, 22356] loss_train: 0.004241, loss_test: 0.005536
time: 0.24805641174316406
time: 2.2805097103118896
[1, 22357] loss_train: 0.008834, loss_test: 0.005534
time: 0.2470545768737793
time: 2.2515037059783936
[1, 22358] loss_train: 0.009078, loss_test: 0.005530
time: 0.2490556240081787
time: 2.2505030632019043
[1, 22359] loss_train: 0.007699, loss_test: 0.005529
time: 0.2490558624267578
time: 2.2785086631774902
[1, 22360] loss_train: 0.002933, loss_test: 0.005530
time: 0.2630579471588135
time: 2.26051664352417
[1, 22361] loss_train: 0.006354, loss_test: 0.005532
time: 0.2540569305419922
time: 2.2625062465667725
[1, 22362] loss_train: 0.013168, loss_test: 0.005531
time: 0.25005555152893066
time: 2.3005166053771973
[1, 22363] loss_train: 0.002171, loss_test: 0.005530
time: 0.2470545768737793
time: 2.2585055828094482
[1, 22364] loss_train: 0.005065, loss_test: 0.005529
time: 0.254056453704834
time: 2.2645065784454346
[1, 22365] loss_train: 0.005125, loss_test: 0.005523
time: 0.24805450439453125
time: 2.2625057697296143
[1, 22366] loss_train: 0.004218, loss_test: 0.005521
time: 0.24805545806884766
time: 2.2600183486938477
[1, 22367] loss_train: 0.002728, loss_test: 0.005522
time: 0.24805569648742676
time: 2.248502492904663
[1, 22368] loss_train: 0.002311, loss_test: 0.005524
time: 0.24805498123168945
time: 2.245502471923828
[1, 22369] loss_train: 0.004956, loss_test: 0.005527
time: 0.24805474281311035
time: 2.280510663986206
[1, 22370] loss_train: 0.009787, loss_test: 0.005529
time: 0.2600574493408203
time: 2.2365005016326904
[1, 22371] loss_train: 0.003634, loss_test: 0.005531
time: 0.2470552921295166
time: 2.250505208969116
[1, 22372] loss_train: 0.008306, loss_test: 0.005533
time: 0.2560567855834961
time: 2.2605059146881104
[1, 22373] loss_train: 0.005562, loss_test: 0.005529
time: 0.2470545768737793
time: 2.2935121059417725
[1, 22374] loss_train: 0.004490, loss_test: 0.005524
time: 0.24805545806884766
time: 2.2525041103363037
[1, 22375] loss_train: 0.004113, loss_test: 0.005520
time: 0.2470548152923584
time: 2.267662286758423
[1, 22376] loss_train: 0.006984, loss_test: 0.005518
time: 0.25905823707580566
time: 2.261507987976074
[1, 22377] loss_train: 0.001921, loss_test: 0.005517
time: 0.24805498123168945
time: 2.2615058422088623
[1, 22378] loss_train: 0.014679, loss_test: 0.005516
time: 0.2470545768737793
time: 2.2839395999908447
[1, 22379] loss_train: 0.002181, loss_test: 0.005516
time: 0.2490551471710205
time: 2.2855112552642822
[1, 22380] loss_train: 0.005160, loss_test: 0.005516
time: 0.26605963706970215
time: 2.272508144378662
[1, 22381] loss_train: 0.007850, loss_test: 0.005515
time: 0.24805521965026855
time: 2.3025147914886475
[1, 22382] loss_train: 0.004456, loss_test: 0.005514
time: 0.25005507469177246
time: 2.2625064849853516
[1, 22383] loss_train: 0.004956, loss_test: 0.005514
time: 0.24805450439453125
time: 2.2765097618103027
[1, 22384] loss_train: 0.004240, loss_test: 0.005514
time: 0.25705671310424805
time: 2.241501569747925
[1, 22385] loss_train: 0.005680, loss_test: 0.005513
time: 0.24805498123168945
time: 2.2485034465789795
[1, 22386] loss_train: 0.005758, loss_test: 0.005513
time: 0.2530555725097656
time: 2.279510259628296
[1, 22387] loss_train: 0.008363, loss_test: 0.005513
time: 0.2490546703338623
time: 2.2725086212158203
[1, 22388] loss_train: 0.020965, loss_test: 0.005511
time: 0.25005555152893066
time: 2.27107310295105
[1, 22389] loss_train: 0.004775, loss_test: 0.005513
time: 0.25305604934692383
time: 2.270508050918579
[1, 22390] loss_train: 0.004597, loss_test: 0.005520
time: 0.2600579261779785
time: 2.301017999649048
[1, 22391] loss_train: 0.003912, loss_test: 0.005530
time: 0.25505685806274414
time: 2.2905120849609375
[1, 22392] loss_train: 0.006979, loss_test: 0.005539
time: 0.25305652618408203
time: 2.2415006160736084
[1, 22393] loss_train: 0.002678, loss_test: 0.005552
time: 0.2580578327178955
time: 2.2425010204315186
[1, 22394] loss_train: 0.002621, loss_test: 0.005546
time: 0.24805355072021484
time: 2.240501880645752
[1, 22395] loss_train: 0.003459, loss_test: 0.005540
time: 0.2510552406311035
time: 2.2505037784576416
[1, 22396] loss_train: 0.002827, loss_test: 0.005533
time: 0.247053861618042
time: 2.2495028972625732
[1, 22397] loss_train: 0.007196, loss_test: 0.005529
time: 0.2520565986633301
time: 2.2475032806396484
[1, 22398] loss_train: 0.007784, loss_test: 0.005514
time: 0.2490549087524414
time: 2.2485029697418213
[1, 22399] loss_train: 0.004800, loss_test: 0.005507
time: 0.2510557174682617
time: 2.2485032081604004
[1, 22400] loss_train: 0.002534, loss_test: 0.005506
time: 0.2620577812194824
time: 2.2985143661499023
[1, 22401] loss_train: 0.004366, loss_test: 0.005511
time: 0.2490553855895996
time: 2.268507480621338
[1, 22402] loss_train: 0.002300, loss_test: 0.005515
time: 0.24605441093444824
time: 2.257505178451538
[1, 22403] loss_train: 0.001265, loss_test: 0.005516
time: 0.24805521965026855
time: 2.23349928855896
[1, 22404] loss_train: 0.007430, loss_test: 0.005517
time: 0.254056453704834
time: 2.2925119400024414
[1, 22405] loss_train: 0.004715, loss_test: 0.005519
time: 0.24805593490600586
time: 2.2515034675598145
[1, 22406] loss_train: 0.002949, loss_test: 0.005521
time: 0.2470543384552002
time: 2.2495028972625732
[1, 22407] loss_train: 0.003399, loss_test: 0.005523
time: 0.25005602836608887
time: 2.272510290145874
[1, 22408] loss_train: 0.006640, loss_test: 0.005524
time: 0.24605417251586914
time: 2.2475030422210693
[1, 22409] loss_train: 0.005361, loss_test: 0.005526
time: 0.24806547164916992
time: 2.266507863998413
[1, 22410] loss_train: 0.008128, loss_test: 0.005523
time: 0.2600574493408203
time: 2.2545058727264404
[1, 22411] loss_train: 0.004017, loss_test: 0.005522
time: 0.25005578994750977
time: 2.2805123329162598
[1, 22412] loss_train: 0.007144, loss_test: 0.005520
time: 0.24805450439453125
time: 2.263010025024414
[1, 22413] loss_train: 0.003709, loss_test: 0.005520
time: 0.2470552921295166
time: 2.2525038719177246
[1, 22414] loss_train: 0.008791, loss_test: 0.005521
time: 0.2470536231994629
time: 2.2635061740875244
[1, 22415] loss_train: 0.003743, loss_test: 0.005524
time: 0.2520561218261719
time: 2.268517017364502
[1, 22416] loss_train: 0.018137, loss_test: 0.005526
time: 0.2490551471710205
time: 2.268507719039917
[1, 22417] loss_train: 0.005154, loss_test: 0.005529
time: 0.24805521965026855
time: 2.2465131282806396
[1, 22418] loss_train: 0.009263, loss_test: 0.005533
time: 0.2490549087524414
time: 2.2455027103424072
[1, 22419] loss_train: 0.007746, loss_test: 0.005537
time: 0.2470531463623047
time: 2.2600088119506836
[1, 22420] loss_train: 0.002590, loss_test: 0.005544
time: 0.2620582580566406
time: 2.2595057487487793
[1, 22421] loss_train: 0.007815, loss_test: 0.005547
time: 0.2470545768737793
time: 2.255504846572876
[1, 22422] loss_train: 0.003749, loss_test: 0.005549
time: 0.254056453704834
time: 2.25850510597229
[1, 22423] loss_train: 0.006105, loss_test: 0.005549
time: 0.2470548152923584
time: 2.273508310317993
[1, 22424] loss_train: 0.006559, loss_test: 0.005543
time: 0.2490553855895996
time: 2.2585067749023438
[1, 22425] loss_train: 0.006444, loss_test: 0.005539
time: 0.24805521965026855
time: 2.262507677078247
[1, 22426] loss_train: 0.002373, loss_test: 0.005537
time: 0.2510554790496826
time: 2.2975142002105713
[1, 22427] loss_train: 0.003701, loss_test: 0.005536
time: 0.24605488777160645
time: 2.2615058422088623
[1, 22428] loss_train: 0.004187, loss_test: 0.005538
time: 0.2510554790496826
time: 2.2725086212158203
[1, 22429] loss_train: 0.004830, loss_test: 0.005540
time: 0.25005531311035156
time: 2.245502233505249
[1, 22430] loss_train: 0.004376, loss_test: 0.005543
time: 0.26405835151672363
time: 2.287524461746216
[1, 22431] loss_train: 0.004988, loss_test: 0.005547
time: 0.24805498123168945
time: 2.252504348754883
[1, 22432] loss_train: 0.007504, loss_test: 0.005550
time: 0.25005602836608887
time: 2.2795090675354004
[1, 22433] loss_train: 0.008514, loss_test: 0.005548
time: 0.2580580711364746
time: 2.2625062465667725
[1, 22434] loss_train: 0.007880, loss_test: 0.005549
time: 0.2490556240081787
time: 2.264514207839966
[1, 22435] loss_train: 0.010447, loss_test: 0.005547
time: 0.2470543384552002
time: 2.2605204582214355
[1, 22436] loss_train: 0.003611, loss_test: 0.005548
time: 0.2510557174682617
time: 2.2410051822662354
[1, 22437] loss_train: 0.008835, loss_test: 0.005547
time: 0.24805474281311035
time: 2.267509698867798
[1, 22438] loss_train: 0.001089, loss_test: 0.005546
time: 0.24805498123168945
time: 2.2405009269714355
[1, 22439] loss_train: 0.011814, loss_test: 0.005549
time: 0.24605417251586914
time: 2.2710137367248535
[1, 22440] loss_train: 0.012845, loss_test: 0.005550
time: 0.26405930519104004
time: 2.2665064334869385
[1, 22441] loss_train: 0.004150, loss_test: 0.005549
time: 0.24805474281311035
time: 2.2655069828033447
[1, 22442] loss_train: 0.005705, loss_test: 0.005550
time: 0.24805474281311035
time: 2.2625064849853516
[1, 22443] loss_train: 0.001580, loss_test: 0.005550
time: 0.2470545768737793
time: 2.252316951751709
[1, 22444] loss_train: 0.007988, loss_test: 0.005550
time: 0.2470560073852539
time: 2.2515041828155518
[1, 22445] loss_train: 0.003535, loss_test: 0.005559
time: 0.24805498123168945
time: 2.268507480621338
[1, 22446] loss_train: 0.010213, loss_test: 0.005570
time: 0.2470543384552002
time: 2.2725086212158203
[1, 22447] loss_train: 0.004045, loss_test: 0.005582
time: 0.2540569305419922
time: 2.257506847381592
[1, 22448] loss_train: 0.007305, loss_test: 0.005592
time: 0.24805521965026855
time: 2.2885115146636963
[1, 22449] loss_train: 0.003923, loss_test: 0.005606
time: 0.2470545768737793
time: 2.2505037784576416
[1, 22450] loss_train: 0.013274, loss_test: 0.005608
time: 0.26105737686157227
time: 2.2505037784576416
[1, 22451] loss_train: 0.004967, loss_test: 0.005609
time: 0.24805593490600586
time: 2.2745087146759033
[1, 22452] loss_train: 0.008745, loss_test: 0.005611
time: 0.2470548152923584
time: 2.278521776199341
[1, 22453] loss_train: 0.007755, loss_test: 0.005606
time: 0.24805521965026855
time: 2.2645061016082764
[1, 22454] loss_train: 0.003129, loss_test: 0.005580
time: 0.25005602836608887
time: 2.2645063400268555
[1, 22455] loss_train: 0.006058, loss_test: 0.005557
time: 0.2470552921295166
time: 2.243501901626587
[1, 22456] loss_train: 0.005807, loss_test: 0.005545
time: 0.2510552406311035
time: 2.2705078125
[1, 22457] loss_train: 0.002757, loss_test: 0.005539
time: 0.2470555305480957
time: 2.271507740020752
[1, 22458] loss_train: 0.025030, loss_test: 0.005537
time: 0.2490551471710205
time: 2.2675070762634277
[1, 22459] loss_train: 0.002207, loss_test: 0.005540
time: 0.2490549087524414
time: 2.2635064125061035
[1, 22460] loss_train: 0.004282, loss_test: 0.005546
time: 0.25905752182006836
time: 2.267507553100586
[1, 22461] loss_train: 0.010949, loss_test: 0.005557
time: 0.25705766677856445
time: 2.2665061950683594
[1, 22462] loss_train: 0.009096, loss_test: 0.005566
time: 0.2490558624267578
time: 2.301516532897949
[1, 22463] loss_train: 0.004405, loss_test: 0.005572
time: 0.2520558834075928
time: 2.263507604598999
[1, 22464] loss_train: 0.001469, loss_test: 0.005559
time: 0.2470541000366211
time: 2.263507127761841
[1, 22465] loss_train: 0.004977, loss_test: 0.005544
time: 0.25005507469177246
time: 2.244502544403076
[1, 22466] loss_train: 0.005105, loss_test: 0.005539
time: 0.2470550537109375
time: 2.258504867553711
[1, 22467] loss_train: 0.004976, loss_test: 0.005545
time: 0.25005507469177246
time: 2.2485036849975586
[1, 22468] loss_train: 0.012093, loss_test: 0.005556
time: 0.2510557174682617
time: 2.2535037994384766
[1, 22469] loss_train: 0.009373, loss_test: 0.005564
time: 0.24805450439453125
time: 2.266507625579834
[1, 22470] loss_train: 0.001627, loss_test: 0.005576
time: 0.25905680656433105
time: 2.2285008430480957
[1, 22471] loss_train: 0.006751, loss_test: 0.005584
time: 0.2490553855895996
time: 2.2835166454315186
[1, 22472] loss_train: 0.001142, loss_test: 0.005592
time: 0.25705766677856445
time: 2.2635059356689453
[1, 22473] loss_train: 0.014402, loss_test: 0.005581
time: 0.2470550537109375
time: 2.2495028972625732
[1, 22474] loss_train: 0.001046, loss_test: 0.005573
time: 0.24805474281311035
time: 2.2965142726898193
[1, 22475] loss_train: 0.014393, loss_test: 0.005564
time: 0.24905610084533691
time: 2.2425005435943604
[1, 22476] loss_train: 0.006787, loss_test: 0.005556
time: 0.24805474281311035
time: 2.292512893676758
[1, 22477] loss_train: 0.001425, loss_test: 0.005553
time: 0.2490553855895996
time: 2.2355003356933594
[1, 22478] loss_train: 0.006402, loss_test: 0.005545
time: 0.24805450439453125
time: 2.280510187149048
[1, 22479] loss_train: 0.001235, loss_test: 0.005537
time: 0.25005483627319336
time: 2.2645206451416016
[1, 22480] loss_train: 0.005610, loss_test: 0.005533
time: 0.25905728340148926
time: 2.2885119915008545
[1, 22481] loss_train: 0.005441, loss_test: 0.005530
time: 0.2470543384552002
time: 2.2645068168640137
[1, 22482] loss_train: 0.003337, loss_test: 0.005529
time: 0.24805569648742676
time: 2.249502420425415
[1, 22483] loss_train: 0.003456, loss_test: 0.005528
time: 0.2529723644256592
time: 2.2585055828094482
[1, 22484] loss_train: 0.007014, loss_test: 0.005529
time: 0.2470545768737793
time: 2.2645065784454346
[1, 22485] loss_train: 0.004399, loss_test: 0.005531
time: 0.24905633926391602
time: 2.2665064334869385
[1, 22486] loss_train: 0.007035, loss_test: 0.005532
time: 0.25005531311035156
time: 2.239501476287842
[1, 22487] loss_train: 0.006613, loss_test: 0.005537
time: 0.25905704498291016
time: 2.2565054893493652
[1, 22488] loss_train: 0.001302, loss_test: 0.005542
time: 0.2490549087524414
time: 2.257507801055908
[1, 22489] loss_train: 0.002164, loss_test: 0.005547
time: 0.24805569648742676
time: 2.2795095443725586
[1, 22490] loss_train: 0.010299, loss_test: 0.005552
time: 0.26405858993530273
time: 2.2775092124938965
[1, 22491] loss_train: 0.015370, loss_test: 0.005550
time: 0.24805474281311035
time: 2.2895123958587646
[1, 22492] loss_train: 0.006815, loss_test: 0.005549
time: 0.2510552406311035
time: 2.2595057487487793
[1, 22493] loss_train: 0.012314, loss_test: 0.005547
time: 0.2490553855895996
time: 2.284519672393799
[1, 22494] loss_train: 0.002037, loss_test: 0.005545
time: 0.25205564498901367
time: 2.26102352142334
[1, 22495] loss_train: 0.009423, loss_test: 0.005543
time: 0.24805450439453125
time: 2.2735090255737305
[1, 22496] loss_train: 0.006247, loss_test: 0.005543
time: 0.25505614280700684
time: 2.266507387161255
[1, 22497] loss_train: 0.004326, loss_test: 0.005543
time: 0.25305604934692383
time: 2.275012254714966
[1, 22498] loss_train: 0.007603, loss_test: 0.005541
time: 0.25005555152893066
time: 2.267507314682007
[1, 22499] loss_train: 0.008095, loss_test: 0.005543
time: 0.25005531311035156
time: 2.277510404586792
[1, 22500] loss_train: 0.006003, loss_test: 0.005543
time: 0.2620570659637451
time: 2.2585055828094482
[1, 22501] loss_train: 0.003152, loss_test: 0.005538
time: 0.2470548152923584
time: 2.267507314682007
[1, 22502] loss_train: 0.005043, loss_test: 0.005533
time: 0.24605441093444824
time: 2.254504442214966
[1, 22503] loss_train: 0.008724, loss_test: 0.005530
time: 0.25005578994750977
time: 2.249504804611206
[1, 22504] loss_train: 0.004008, loss_test: 0.005526
time: 0.25505661964416504
time: 2.2194974422454834
[1, 22505] loss_train: 0.009463, loss_test: 0.005525
time: 0.24805474281311035
time: 2.247504234313965
[1, 22506] loss_train: 0.001230, loss_test: 0.005522
time: 0.24805521965026855
time: 2.246502637863159
[1, 22507] loss_train: 0.005606, loss_test: 0.005517
time: 0.24805474281311035
time: 2.2385003566741943
[1, 22508] loss_train: 0.011026, loss_test: 0.005517
time: 0.25305628776550293
time: 2.2475028038024902
[1, 22509] loss_train: 0.002986, loss_test: 0.005518
time: 0.2490551471710205
time: 2.2775096893310547
[1, 22510] loss_train: 0.005444, loss_test: 0.005518
time: 0.2620577812194824
time: 2.241502046585083
[1, 22511] loss_train: 0.006578, loss_test: 0.005517
time: 0.2470550537109375
time: 2.272508144378662
[1, 22512] loss_train: 0.001589, loss_test: 0.005515
time: 0.2470550537109375
time: 2.3065297603607178
[1, 22513] loss_train: 0.005447, loss_test: 0.005514
time: 0.2470548152923584
time: 2.2855117321014404
[1, 22514] loss_train: 0.009178, loss_test: 0.005515
time: 0.24805498123168945
time: 2.2765090465545654
[1, 22515] loss_train: 0.002600, loss_test: 0.005514
time: 0.2490553855895996
time: 2.273508071899414
[1, 22516] loss_train: 0.007796, loss_test: 0.005512
time: 0.24805498123168945
time: 2.2615063190460205
[1, 22517] loss_train: 0.003314, loss_test: 0.005511
time: 0.24805450439453125
time: 2.2835114002227783
[1, 22518] loss_train: 0.005251, loss_test: 0.005511
time: 0.25005555152893066
time: 2.2940165996551514
[1, 22519] loss_train: 0.001470, loss_test: 0.005513
time: 0.2470548152923584
time: 2.2335002422332764
[1, 22520] loss_train: 0.012737, loss_test: 0.005512
time: 0.25905680656433105
time: 2.2885124683380127
[1, 22521] loss_train: 0.005524, loss_test: 0.005512
time: 0.25005555152893066
time: 2.2495036125183105
[1, 22522] loss_train: 0.009594, loss_test: 0.005512
time: 0.25089597702026367
time: 2.2605061531066895
[1, 22523] loss_train: 0.010256, loss_test: 0.005512
time: 0.25005507469177246
time: 2.261505126953125
[1, 22524] loss_train: 0.008603, loss_test: 0.005509
time: 0.24605536460876465
time: 2.2745087146759033
[1, 22525] loss_train: 0.009360, loss_test: 0.005507
time: 0.2510557174682617
time: 2.2335000038146973
[1, 22526] loss_train: 0.007897, loss_test: 0.005508
time: 0.24805498123168945
time: 2.2715089321136475
[1, 22527] loss_train: 0.005938, loss_test: 0.005510
time: 0.2510569095611572
time: 2.2625057697296143
[1, 22528] loss_train: 0.010108, loss_test: 0.005511
time: 0.2470545768737793
time: 2.2365005016326904
[1, 22529] loss_train: 0.003959, loss_test: 0.005514
time: 0.2540569305419922
time: 2.249502658843994
[1, 22530] loss_train: 0.004265, loss_test: 0.005514
time: 0.26405811309814453
time: 2.2505037784576416
[1, 22531] loss_train: 0.006316, loss_test: 0.005516
time: 0.252056360244751
time: 2.2565042972564697
[1, 22532] loss_train: 0.005056, loss_test: 0.005520
time: 0.24805498123168945
time: 2.2635064125061035
[1, 22533] loss_train: 0.005217, loss_test: 0.005525
time: 0.25705766677856445
time: 2.25850510597229
[1, 22534] loss_train: 0.000685, loss_test: 0.005527
time: 0.24805498123168945
time: 2.267507791519165
[1, 22535] loss_train: 0.010622, loss_test: 0.005531
time: 0.25005531311035156
time: 2.2435014247894287
[1, 22536] loss_train: 0.012404, loss_test: 0.005531
time: 0.2470552921295166
time: 2.2515037059783936
[1, 22537] loss_train: 0.003378, loss_test: 0.005532
time: 0.2540559768676758
time: 2.2575058937072754
[1, 22538] loss_train: 0.006946, loss_test: 0.005533
time: 0.24805474281311035
time: 2.230498790740967
[1, 22539] loss_train: 0.005274, loss_test: 0.005533
time: 0.252056360244751
time: 2.258504629135132
[1, 22540] loss_train: 0.006137, loss_test: 0.005534
time: 0.2760610580444336
time: 2.2585055828094482
[1, 22541] loss_train: 0.008526, loss_test: 0.005533
time: 0.25005578994750977
time: 2.2765088081359863
[1, 22542] loss_train: 0.005630, loss_test: 0.005531
time: 0.24805474281311035
time: 2.3525264263153076
[1, 22543] loss_train: 0.005061, loss_test: 0.005532
time: 0.2470541000366211
time: 2.2635064125061035
[1, 22544] loss_train: 0.002692, loss_test: 0.005531
time: 0.24905657768249512
time: 2.2845113277435303
[1, 22545] loss_train: 0.003858, loss_test: 0.005530
time: 0.2600579261779785
time: 2.256504535675049
[1, 22546] loss_train: 0.010534, loss_test: 0.005530
time: 0.2470543384552002
time: 2.265507698059082
[1, 22547] loss_train: 0.001948, loss_test: 0.005530
time: 0.2530558109283447
time: 2.2635064125061035
[1, 22548] loss_train: 0.002650, loss_test: 0.005530
time: 0.2470543384552002
time: 2.271517753601074
[1, 22549] loss_train: 0.004046, loss_test: 0.005531
time: 0.24805521965026855
time: 2.2505037784576416
[1, 22550] loss_train: 0.000947, loss_test: 0.005530
time: 0.26105761528015137
time: 2.2745089530944824
[1, 22551] loss_train: 0.004170, loss_test: 0.005533
time: 0.2490551471710205
time: 2.2545065879821777
[1, 22552] loss_train: 0.006440, loss_test: 0.005533
time: 0.24805521965026855
time: 2.2635061740875244
[1, 22553] loss_train: 0.010075, loss_test: 0.005527
time: 0.24805450439453125
time: 2.2845113277435303
[1, 22554] loss_train: 0.006339, loss_test: 0.005520
time: 0.25305604934692383
time: 2.2395007610321045
[1, 22555] loss_train: 0.006256, loss_test: 0.005515
time: 0.2470550537109375
time: 2.2855112552642822
[1, 22556] loss_train: 0.001877, loss_test: 0.005512
time: 0.2520561218261719
time: 2.2635059356689453
[1, 22557] loss_train: 0.004575, loss_test: 0.005512
time: 0.2470552921295166
time: 2.2365026473999023
[1, 22558] loss_train: 0.008256, loss_test: 0.005511
time: 0.25005435943603516
time: 2.2595055103302
[1, 22559] loss_train: 0.005797, loss_test: 0.005512
time: 0.24805474281311035
time: 2.276522159576416
[1, 22560] loss_train: 0.012640, loss_test: 0.005512
time: 0.26405811309814453
time: 2.2755093574523926
[1, 22561] loss_train: 0.004513, loss_test: 0.005510
time: 0.2520558834075928
time: 2.2655069828033447
[1, 22562] loss_train: 0.019014, loss_test: 0.005508
time: 0.2510561943054199
time: 2.2915122509002686
[1, 22563] loss_train: 0.009602, loss_test: 0.005511
time: 0.24805450439453125
time: 2.2450430393218994
[1, 22564] loss_train: 0.006733, loss_test: 0.005517
time: 0.24805498123168945
time: 2.2485103607177734
[1, 22565] loss_train: 0.003226, loss_test: 0.005526
time: 0.2470555305480957
time: 2.2775092124938965
[1, 22566] loss_train: 0.002591, loss_test: 0.005539
time: 0.2490549087524414
time: 2.2885122299194336
[1, 22567] loss_train: 0.009253, loss_test: 0.005553
time: 0.2470545768737793
time: 2.2525041103363037
[1, 22568] loss_train: 0.007400, loss_test: 0.005565
time: 0.2520558834075928
time: 2.2765090465545654
[1, 22569] loss_train: 0.004846, loss_test: 0.005576
time: 0.2470541000366211
time: 2.252504348754883
[1, 22570] loss_train: 0.006114, loss_test: 0.005583
time: 0.2630579471588135
time: 2.239105701446533
[1, 22571] loss_train: 0.002070, loss_test: 0.005591
time: 0.24805450439453125
time: 2.268507480621338
[1, 22572] loss_train: 0.005591, loss_test: 0.005596
time: 0.2540566921234131
time: 2.256504774093628
[1, 22573] loss_train: 0.011370, loss_test: 0.005592
time: 0.24805593490600586
time: 2.2425010204315186
[1, 22574] loss_train: 0.011306, loss_test: 0.005583
time: 0.251056432723999
time: 2.2565040588378906
[1, 22575] loss_train: 0.002272, loss_test: 0.005581
time: 0.2490549087524414
time: 2.269507884979248
[1, 22576] loss_train: 0.009288, loss_test: 0.005572
time: 0.25005507469177246
time: 2.291512966156006
[1, 22577] loss_train: 0.001971, loss_test: 0.005565
time: 0.24656987190246582
time: 2.2665066719055176
[1, 22578] loss_train: 0.006493, loss_test: 0.005560
time: 0.2510552406311035
time: 2.2635064125061035
[1, 22579] loss_train: 0.003064, loss_test: 0.005558
time: 0.2500584125518799
time: 2.248300790786743
[1, 22580] loss_train: 0.014308, loss_test: 0.005552
time: 0.2600564956665039
time: 2.2745094299316406
[1, 22581] loss_train: 0.000647, loss_test: 0.005552
time: 0.2490553855895996
time: 2.269507884979248
[1, 22582] loss_train: 0.006001, loss_test: 0.005556
time: 0.2540559768676758
time: 2.2655069828033447
[1, 22583] loss_train: 0.004729, loss_test: 0.005559
time: 0.2470545768737793
time: 2.270508289337158
[1, 22584] loss_train: 0.005866, loss_test: 0.005559
time: 0.24605488777160645
time: 2.259505033493042
[1, 22585] loss_train: 0.004934, loss_test: 0.005558
time: 0.24605417251586914
time: 2.2635066509246826
[1, 22586] loss_train: 0.010304, loss_test: 0.005557
time: 0.2510561943054199
time: 2.270507574081421
[1, 22587] loss_train: 0.006565, loss_test: 0.005555
time: 0.2470550537109375
time: 2.2324986457824707
[1, 22588] loss_train: 0.005539, loss_test: 0.005552
time: 0.2470545768737793
time: 2.237501382827759
[1, 22589] loss_train: 0.003631, loss_test: 0.005544
time: 0.2490546703338623
time: 2.2495031356811523
[1, 22590] loss_train: 0.001599, loss_test: 0.005539
time: 0.2600584030151367
time: 2.273507595062256
[1, 22591] loss_train: 0.010299, loss_test: 0.005536
time: 0.2470548152923584
time: 2.2725088596343994
[1, 22592] loss_train: 0.005211, loss_test: 0.005533
time: 0.2510552406311035
time: 2.268507242202759
[1, 22593] loss_train: 0.004838, loss_test: 0.005530
time: 0.2580585479736328
time: 2.271507501602173
[1, 22594] loss_train: 0.008840, loss_test: 0.005529
time: 0.2470552921295166
time: 2.2515034675598145
[1, 22595] loss_train: 0.004706, loss_test: 0.005529
time: 0.2510561943054199
time: 2.2675070762634277
[1, 22596] loss_train: 0.001600, loss_test: 0.005529
time: 0.24805498123168945
time: 2.272510051727295
[1, 22597] loss_train: 0.003881, loss_test: 0.005529
time: 0.25305652618408203
time: 2.2665066719055176
[1, 22598] loss_train: 0.003949, loss_test: 0.005530
time: 0.24805521965026855
time: 2.239502191543579
[1, 22599] loss_train: 0.003644, loss_test: 0.005533
time: 0.2510559558868408
time: 2.260505437850952
[1, 22600] loss_train: 0.008687, loss_test: 0.005537
time: 0.26806068420410156
time: 2.26950740814209
[1, 22601] loss_train: 0.004498, loss_test: 0.005542
time: 0.2540562152862549
time: 2.2475030422210693
[1, 22602] loss_train: 0.003588, loss_test: 0.005546
time: 0.24805450439453125
time: 2.243502140045166
[1, 22603] loss_train: 0.009921, loss_test: 0.005546
time: 0.2470552921295166
time: 2.257504940032959
[1, 22604] loss_train: 0.005470, loss_test: 0.005546
time: 0.2490551471710205
time: 2.2815449237823486
[1, 22605] loss_train: 0.006515, loss_test: 0.005544
time: 0.2520565986633301
time: 2.2505037784576416
[1, 22606] loss_train: 0.015567, loss_test: 0.005534
time: 0.2490553855895996
time: 2.2365002632141113
[1, 22607] loss_train: 0.002666, loss_test: 0.005528
time: 0.24805545806884766
time: 2.2274978160858154
[1, 22608] loss_train: 0.005589, loss_test: 0.005526
time: 0.2470550537109375
time: 2.2375004291534424
[1, 22609] loss_train: 0.005232, loss_test: 0.005527
time: 0.24805450439453125
time: 2.2895123958587646
[1, 22610] loss_train: 0.003628, loss_test: 0.005531
time: 0.2610588073730469
time: 2.2675065994262695
[1, 22611] loss_train: 0.005926, loss_test: 0.005536
time: 0.25705647468566895
time: 2.281511068344116
[1, 22612] loss_train: 0.010956, loss_test: 0.005539
time: 0.24805545806884766
time: 2.263504981994629
[1, 22613] loss_train: 0.005383, loss_test: 0.005540
time: 0.24805569648742676
time: 2.268507480621338
[1, 22614] loss_train: 0.011184, loss_test: 0.005542
time: 0.2490551471710205
time: 2.256504535675049
[1, 22615] loss_train: 0.005462, loss_test: 0.005541
time: 0.24905633926391602
time: 2.252504587173462
[1, 22616] loss_train: 0.008947, loss_test: 0.005536
time: 0.24805498123168945
time: 2.285510778427124
[1, 22617] loss_train: 0.010082, loss_test: 0.005533
time: 0.2490558624267578
time: 2.265507221221924
[1, 22618] loss_train: 0.007596, loss_test: 0.005530
time: 0.2580568790435791
time: 2.2645068168640137
[1, 22619] loss_train: 0.004027, loss_test: 0.005528
time: 0.2490551471710205
time: 2.243501663208008
[1, 22620] loss_train: 0.005340, loss_test: 0.005528
time: 0.261059045791626
time: 2.2645058631896973
[1, 22621] loss_train: 0.006827, loss_test: 0.005529
time: 0.2490556240081787
time: 2.2755086421966553
[1, 22622] loss_train: 0.006733, loss_test: 0.005531
time: 0.24805450439453125
time: 2.2665069103240967
[1, 22623] loss_train: 0.002589, loss_test: 0.005534
time: 0.2510557174682617
time: 2.261505365371704
[1, 22624] loss_train: 0.004246, loss_test: 0.005538
time: 0.2490541934967041
time: 2.272529363632202
[1, 22625] loss_train: 0.009574, loss_test: 0.005540
time: 0.25005507469177246
time: 2.2515034675598145
[1, 22626] loss_train: 0.008182, loss_test: 0.005539
time: 0.2470557689666748
time: 2.2705068588256836
[1, 22627] loss_train: 0.006320, loss_test: 0.005541
time: 0.2490556240081787
time: 2.255504608154297
[1, 22628] loss_train: 0.003165, loss_test: 0.005544
time: 0.24805474281311035
time: 2.2655067443847656
[1, 22629] loss_train: 0.003436, loss_test: 0.005548
time: 0.2490551471710205
time: 2.278510093688965
[1, 22630] loss_train: 0.002875, loss_test: 0.005554
time: 0.263059139251709
time: 2.261514663696289
[1, 22631] loss_train: 0.008682, loss_test: 0.005560
time: 0.2470548152923584
time: 2.285511016845703
[1, 22632] loss_train: 0.005168, loss_test: 0.005566
time: 0.254056453704834
time: 2.29551362991333
[1, 22633] loss_train: 0.008387, loss_test: 0.005570
time: 0.24605417251586914
time: 2.2675070762634277
[1, 22634] loss_train: 0.006213, loss_test: 0.005570
time: 0.2490556240081787
time: 2.255514144897461
[1, 22635] loss_train: 0.004766, loss_test: 0.005570
time: 0.2490551471710205
time: 2.272508144378662
[1, 22636] loss_train: 0.005736, loss_test: 0.005566
time: 0.24805474281311035
time: 2.243502140045166
[1, 22637] loss_train: 0.004149, loss_test: 0.005565
time: 0.2490558624267578
time: 2.2675065994262695
[1, 22638] loss_train: 0.004286, loss_test: 0.005564
time: 0.2470552921295166
time: 2.25850510597229
[1, 22639] loss_train: 0.009086, loss_test: 0.005560
time: 0.2540566921234131
time: 2.2635059356689453
[1, 22640] loss_train: 0.009269, loss_test: 0.005558
time: 0.26105761528015137
time: 2.2835114002227783
[1, 22641] loss_train: 0.002445, loss_test: 0.005555
time: 0.24805426597595215
time: 2.295513868331909
[1, 22642] loss_train: 0.010765, loss_test: 0.005550
time: 0.2530558109283447
time: 2.269507884979248
[1, 22643] loss_train: 0.003729, loss_test: 0.005547
time: 0.25005602836608887
time: 2.2415008544921875
[1, 22644] loss_train: 0.005641, loss_test: 0.005545
time: 0.25005578994750977
time: 2.257506847381592
[1, 22645] loss_train: 0.008144, loss_test: 0.005543
time: 0.2490549087524414
time: 2.275508403778076
[1, 22646] loss_train: 0.006493, loss_test: 0.005543
time: 0.25005602836608887
time: 2.2385003566741943
[1, 22647] loss_train: 0.010862, loss_test: 0.005544
time: 0.24805474281311035
time: 2.2485034465789795
[1, 22648] loss_train: 0.010977, loss_test: 0.005543
time: 0.2520561218261719
time: 2.2645184993743896
[1, 22649] loss_train: 0.004443, loss_test: 0.005544
time: 0.25005626678466797
time: 2.230501174926758
[1, 22650] loss_train: 0.002115, loss_test: 0.005545
time: 0.260056734085083
time: 2.2549185752868652
[1, 22651] loss_train: 0.009850, loss_test: 0.005547
time: 0.24964189529418945
time: 2.261505365371704
[1, 22652] loss_train: 0.002992, loss_test: 0.005550
time: 0.2470548152923584
time: 2.2665066719055176
[1, 22653] loss_train: 0.005425, loss_test: 0.005549
time: 0.2530555725097656
time: 2.2875115871429443
[1, 22654] loss_train: 0.011934, loss_test: 0.005543
time: 0.25905871391296387
time: 2.2525033950805664
[1, 22655] loss_train: 0.004687, loss_test: 0.005535
time: 0.24805569648742676
time: 2.2800204753875732
[1, 22656] loss_train: 0.008797, loss_test: 0.005528
time: 0.24905610084533691
time: 2.2542760372161865
[1, 22657] loss_train: 0.005885, loss_test: 0.005522
time: 0.24805498123168945
time: 2.280510187149048
[1, 22658] loss_train: 0.005165, loss_test: 0.005518
time: 0.2470550537109375
time: 2.2530171871185303
[1, 22659] loss_train: 0.012201, loss_test: 0.005515
time: 0.2470543384552002
time: 2.279510259628296
[1, 22660] loss_train: 0.008189, loss_test: 0.005514
time: 0.2650585174560547
time: 2.265516757965088
[1, 22661] loss_train: 0.002267, loss_test: 0.005513
time: 0.2520561218261719
time: 2.273508310317993
[1, 22662] loss_train: 0.007659, loss_test: 0.005514
time: 0.2490551471710205
time: 2.267507553100586
[1, 22663] loss_train: 0.009422, loss_test: 0.005516
time: 0.2560570240020752
time: 2.283510684967041
[1, 22664] loss_train: 0.006517, loss_test: 0.005517
time: 0.2470555305480957
time: 2.2635059356689453
[1, 22665] loss_train: 0.005421, loss_test: 0.005518
time: 0.25305628776550293
time: 2.291512966156006
[1, 22666] loss_train: 0.003799, loss_test: 0.005520
time: 0.2470541000366211
time: 2.2770485877990723
[1, 22667] loss_train: 0.003610, loss_test: 0.005523
time: 0.252056360244751
time: 2.255009412765503
[1, 22668] loss_train: 0.007483, loss_test: 0.005528
time: 0.24805450439453125
time: 2.2485032081604004
[1, 22669] loss_train: 0.010500, loss_test: 0.005532
time: 0.2490558624267578
time: 2.261505365371704
[1, 22670] loss_train: 0.021695, loss_test: 0.005540
time: 0.26105809211730957
time: 2.298513889312744
[1, 22671] loss_train: 0.015702, loss_test: 0.005552
time: 0.24805474281311035
time: 2.266509532928467
[1, 22672] loss_train: 0.004297, loss_test: 0.005565
time: 0.2470552921295166
time: 2.2515029907226562
[1, 22673] loss_train: 0.002113, loss_test: 0.005576
time: 0.25005531311035156
time: 2.262021064758301
[1, 22674] loss_train: 0.001997, loss_test: 0.005575
time: 0.25005412101745605
time: 2.257505416870117
[1, 22675] loss_train: 0.011334, loss_test: 0.005563
time: 0.25005602836608887
time: 2.2795093059539795
[1, 22676] loss_train: 0.011671, loss_test: 0.005549
time: 0.24805498123168945
time: 2.2665212154388428
[1, 22677] loss_train: 0.006458, loss_test: 0.005538
time: 0.25205564498901367
time: 2.2455027103424072
[1, 22678] loss_train: 0.003841, loss_test: 0.005527
time: 0.24805521965026855
time: 2.2645061016082764
[1, 22679] loss_train: 0.006452, loss_test: 0.005520
time: 0.24907159805297852
time: 2.2675070762634277
[1, 22680] loss_train: 0.000646, loss_test: 0.005515
time: 0.25905752182006836
time: 2.279013156890869
[1, 22681] loss_train: 0.006998, loss_test: 0.005512
time: 0.2470550537109375
time: 2.2935118675231934
[1, 22682] loss_train: 0.009926, loss_test: 0.005512
time: 0.24805498123168945
time: 2.2785098552703857
[1, 22683] loss_train: 0.003375, loss_test: 0.005513
time: 0.2470555305480957
time: 2.2415010929107666
[1, 22684] loss_train: 0.015603, loss_test: 0.005514
time: 0.252056360244751
time: 2.279508590698242
[1, 22685] loss_train: 0.013989, loss_test: 0.005517
time: 0.24746966361999512
time: 2.271507740020752
[1, 22686] loss_train: 0.003489, loss_test: 0.005519
time: 0.2510559558868408
time: 2.273508071899414
[1, 22687] loss_train: 0.000640, loss_test: 0.005518
time: 0.24805569648742676
time: 2.29052472114563
[1, 22688] loss_train: 0.003887, loss_test: 0.005517
time: 0.2530558109283447
time: 2.260505437850952
[1, 22689] loss_train: 0.004196, loss_test: 0.005516
time: 0.24805426597595215
time: 2.2865116596221924
[1, 22690] loss_train: 0.007921, loss_test: 0.005516
time: 0.26006007194519043
time: 2.2635068893432617
[1, 22691] loss_train: 0.005989, loss_test: 0.005517
time: 0.2490553855895996
time: 2.265505790710449
[1, 22692] loss_train: 0.003388, loss_test: 0.005519
time: 0.2470552921295166
time: 2.240504026412964
[1, 22693] loss_train: 0.006588, loss_test: 0.005520
time: 0.2490556240081787
time: 2.2905116081237793
[1, 22694] loss_train: 0.006942, loss_test: 0.005523
time: 0.25305604934692383
time: 2.256505250930786
[1, 22695] loss_train: 0.003809, loss_test: 0.005529
time: 0.24805545806884766
time: 2.2545065879821777
[1, 22696] loss_train: 0.006656, loss_test: 0.005536
time: 0.2470545768737793
time: 2.2625064849853516
[1, 22697] loss_train: 0.004587, loss_test: 0.005542
time: 0.24805450439453125
time: 2.252504348754883
[1, 22698] loss_train: 0.008038, loss_test: 0.005545
time: 0.24805474281311035
time: 2.2755086421966553
[1, 22699] loss_train: 0.002319, loss_test: 0.005547
time: 0.2490553855895996
time: 2.3035173416137695
[1, 22700] loss_train: 0.004319, loss_test: 0.005548
time: 0.26405954360961914
time: 2.290515422821045
[1, 22701] loss_train: 0.003189, loss_test: 0.005551
time: 0.25205516815185547
time: 2.2395009994506836
[1, 22702] loss_train: 0.002379, loss_test: 0.005557
time: 0.2470548152923584
time: 2.2765114307403564
[1, 22703] loss_train: 0.005812, loss_test: 0.005559
time: 0.2490553855895996
time: 2.26950740814209
[1, 22704] loss_train: 0.001849, loss_test: 0.005566
time: 0.2470550537109375
time: 2.275508403778076
[1, 22705] loss_train: 0.010640, loss_test: 0.005563
time: 0.2490553855895996
time: 2.2505037784576416
[1, 22706] loss_train: 0.006507, loss_test: 0.005558
time: 0.24705719947814941
time: 2.2575042247772217
[1, 22707] loss_train: 0.006258, loss_test: 0.005546
time: 0.24724364280700684
time: 2.2485032081604004
[1, 22708] loss_train: 0.007670, loss_test: 0.005537
time: 0.25005483627319336
time: 2.266507148742676
[1, 22709] loss_train: 0.009537, loss_test: 0.005527
time: 0.24705743789672852
time: 2.246502161026001
[1, 22710] loss_train: 0.003821, loss_test: 0.005521
time: 0.26105833053588867
time: 2.270507335662842
[1, 22711] loss_train: 0.003562, loss_test: 0.005517
time: 0.24805569648742676
time: 2.263504981994629
[1, 22712] loss_train: 0.006577, loss_test: 0.005515
time: 0.25005578994750977
time: 2.2885119915008545
[1, 22713] loss_train: 0.004443, loss_test: 0.005517
time: 0.251056432723999
time: 2.284512758255005
[1, 22714] loss_train: 0.001685, loss_test: 0.005520
time: 0.2510554790496826
time: 2.2535040378570557
[1, 22715] loss_train: 0.007629, loss_test: 0.005524
time: 0.2520561218261719
time: 2.266507148742676
[1, 22716] loss_train: 0.004661, loss_test: 0.005528
time: 0.24805474281311035
time: 2.256507396697998
[1, 22717] loss_train: 0.012225, loss_test: 0.005528
time: 0.25005507469177246
time: 2.259505033493042
[1, 22718] loss_train: 0.006127, loss_test: 0.005525
time: 0.24805521965026855
time: 2.2725086212158203
[1, 22719] loss_train: 0.006816, loss_test: 0.005522
time: 0.2530553340911865
time: 2.284842014312744
[1, 22720] loss_train: 0.006735, loss_test: 0.005520
time: 0.26105809211730957
time: 2.237499475479126
[1, 22721] loss_train: 0.005562, loss_test: 0.005518
time: 0.24805498123168945
time: 2.2755093574523926
[1, 22722] loss_train: 0.007837, loss_test: 0.005517
time: 0.2490556240081787
time: 2.2395005226135254
[1, 22723] loss_train: 0.006956, loss_test: 0.005516
time: 0.24805521965026855
time: 2.2605056762695312
[1, 22724] loss_train: 0.000711, loss_test: 0.005514
time: 0.24805474281311035
time: 2.2515039443969727
[1, 22725] loss_train: 0.002042, loss_test: 0.005513
time: 0.24805474281311035
time: 2.318519115447998
[1, 22726] loss_train: 0.010128, loss_test: 0.005512
time: 0.25905704498291016
time: 2.2545111179351807
[1, 22727] loss_train: 0.006773, loss_test: 0.005513
time: 0.24605393409729004
time: 2.268507957458496
[1, 22728] loss_train: 0.009606, loss_test: 0.005513
time: 0.25505661964416504
time: 2.2875113487243652
[1, 22729] loss_train: 0.001643, loss_test: 0.005515
time: 0.2468712329864502
time: 2.384533643722534
[1, 22730] loss_train: 0.016556, loss_test: 0.005514
time: 0.3720829486846924
time: 2.3695294857025146
[1, 22731] loss_train: 0.008871, loss_test: 0.005512
time: 0.2490551471710205
time: 2.2745089530944824
[1, 22732] loss_train: 0.002683, loss_test: 0.005509
time: 0.2940652370452881
time: 2.699998140335083
[1, 22733] loss_train: 0.007185, loss_test: 0.005509
time: 0.45821666717529297
time: 3.6523945331573486
[1, 22734] loss_train: 0.004436, loss_test: 0.005510
time: 0.40506911277770996
time: 3.5552241802215576
[1, 22735] loss_train: 0.003970, loss_test: 0.005511
time: 0.382188081741333
time: 4.6067094802856445
[1, 22736] loss_train: 0.010407, loss_test: 0.005514
time: 0.40410470962524414
time: 3.4646663665771484
[1, 22737] loss_train: 0.008630, loss_test: 0.005517
time: 0.3780653476715088
time: 3.4320874214172363
[1, 22738] loss_train: 0.007421, loss_test: 0.005521
time: 0.4113931655883789
time: 4.08846116065979
[1, 22739] loss_train: 0.007231, loss_test: 0.005528
time: 0.4111168384552002
time: 3.835740566253662
[1, 22740] loss_train: 0.007400, loss_test: 0.005537
time: 0.4369089603424072
time: 3.436465263366699
[1, 22741] loss_train: 0.007100, loss_test: 0.005550
time: 0.42407798767089844
time: 4.033292293548584
[1, 22742] loss_train: 0.007416, loss_test: 0.005560
time: 0.39363861083984375
time: 3.3652918338775635
[1, 22743] loss_train: 0.008872, loss_test: 0.005563
time: 0.3790750503540039
time: 3.418555974960327
[1, 22744] loss_train: 0.013463, loss_test: 0.005562
time: 0.3778653144836426
time: 1729.0133492946625
[1, 22745] loss_train: 0.007380, loss_test: 0.005561
time: 0.3740837574005127
time: 3.3779146671295166
[1, 22746] loss_train: 0.010682, loss_test: 0.005547
time: 0.3133118152618408
time: 4.175637722015381
[1, 22747] loss_train: 0.007265, loss_test: 0.005541
time: 0.4643971920013428
time: 3.3789865970611572
[1, 22748] loss_train: 0.003322, loss_test: 0.005543
time: 0.4018387794494629
time: 3.427499532699585
[1, 22749] loss_train: 0.012866, loss_test: 0.005555
time: 0.4173903465270996
time: 3.3454861640930176
[1, 22750] loss_train: 0.001699, loss_test: 0.005571
time: 0.49343419075012207
time: 3.3203723430633545
[1, 22751] loss_train: 0.002235, loss_test: 0.005591
time: 0.4005095958709717
time: 3.508376359939575
[1, 22752] loss_train: 0.003142, loss_test: 0.005598
time: 0.2815675735473633
time: 2.381532669067383
[1, 22753] loss_train: 0.002027, loss_test: 0.005600
time: 0.28406262397766113
time: 2.3765323162078857
[1, 22754] loss_train: 0.001513, loss_test: 0.005574
time: 0.2800626754760742
time: 2.4953291416168213
[1, 22755] loss_train: 0.005848, loss_test: 0.005554
time: 0.25905752182006836
time: 2.2255361080169678
[1, 22756] loss_train: 0.007266, loss_test: 0.005544
time: 0.24805450439453125
time: 2.391535520553589
[1, 22757] loss_train: 0.008678, loss_test: 0.005543
time: 0.2620580196380615
time: 2.2600128650665283
[1, 22758] loss_train: 0.011199, loss_test: 0.005540
time: 0.267059326171875
time: 2.6275875568389893
[1, 22759] loss_train: 0.001615, loss_test: 0.005545
time: 0.26605844497680664
time: 2.896648645401001
[1, 22760] loss_train: 0.001351, loss_test: 0.005560
time: 0.28406238555908203
time: 2.4005372524261475
[1, 22761] loss_train: 0.004710, loss_test: 0.005576
time: 0.2560563087463379
time: 2.3095171451568604
[1, 22762] loss_train: 0.008260, loss_test: 0.005593
time: 0.256056547164917
time: 2.3315227031707764
[1, 22763] loss_train: 0.007921, loss_test: 0.005612
time: 0.2670581340789795
time: 2.3065185546875
[1, 22764] loss_train: 0.015497, loss_test: 0.005619
time: 0.25705718994140625
time: 2.3245370388031006
[1, 22765] loss_train: 0.004546, loss_test: 0.005626
time: 0.26906275749206543
time: 2.342524290084839
[1, 22766] loss_train: 0.005044, loss_test: 0.005628
time: 0.258056640625
time: 2.4215424060821533
[1, 22767] loss_train: 0.005159, loss_test: 0.005627
time: 0.3030674457550049
time: 2.478564500808716
[1, 22768] loss_train: 0.005211, loss_test: 0.005622
time: 0.27706193923950195
time: 2.4575493335723877
[1, 22769] loss_train: 0.006292, loss_test: 0.005615
time: 0.25305652618408203
time: 2.3255224227905273
[1, 22770] loss_train: 0.004799, loss_test: 0.005612
time: 0.26805949211120605
time: 2.2595081329345703
[1, 22771] loss_train: 0.014643, loss_test: 0.005609
time: 0.2650582790374756
time: 2.266507148742676
[1, 22772] loss_train: 0.004816, loss_test: 0.005609
time: 0.2490553855895996
time: 3.0628273487091064
[1, 22773] loss_train: 0.005833, loss_test: 0.005604
time: 0.260056734085083
time: 2.334533214569092
[1, 22774] loss_train: 0.006745, loss_test: 0.005595
time: 0.2540569305419922
time: 2.360527992248535
[1, 22775] loss_train: 0.008944, loss_test: 0.005585
time: 0.2560567855834961
time: 2.57464337348938
[1, 22776] loss_train: 0.005657, loss_test: 0.005573
time: 0.3430769443511963
time: 2.672703981399536
[1, 22777] loss_train: 0.000703, loss_test: 0.005557
time: 0.2560567855834961
time: 2.293046712875366
[1, 22778] loss_train: 0.005767, loss_test: 0.005544
time: 0.26605987548828125
time: 2.3105881214141846
[1, 22779] loss_train: 0.015529, loss_test: 0.005536
time: 0.26205992698669434
time: 2.288512945175171
[1, 22780] loss_train: 0.006190, loss_test: 0.005532
time: 0.27306032180786133
time: 2.289634943008423
[1, 22781] loss_train: 0.006096, loss_test: 0.005532
time: 0.25006532669067383
time: 2.356529474258423
[1, 22782] loss_train: 0.000617, loss_test: 0.005534
time: 0.2510559558868408
time: 2.4320952892303467
[1, 22783] loss_train: 0.017314, loss_test: 0.005534
time: 0.3000681400299072
time: 2.413531541824341
[1, 22784] loss_train: 0.008934, loss_test: 0.005537
time: 0.2490556240081787
time: 2.434434413909912
[1, 22785] loss_train: 0.000803, loss_test: 0.005541
time: 0.2689704895019531
time: 2.3324272632598877
[1, 22786] loss_train: 0.007219, loss_test: 0.005546
time: 0.24656891822814941
time: 2.267183780670166
[1, 22787] loss_train: 0.008538, loss_test: 0.005547
time: 0.25705742835998535
time: 2.327542304992676
[1, 22788] loss_train: 0.012285, loss_test: 0.005544
time: 0.26105761528015137
time: 2.335521697998047
[1, 22789] loss_train: 0.005985, loss_test: 0.005541
time: 0.25005483627319336
time: 2.2562592029571533
[1, 22790] loss_train: 0.008550, loss_test: 0.005538
time: 0.26105833053588867
time: 2.2695255279541016
[1, 22791] loss_train: 0.008537, loss_test: 0.005535
time: 0.24405336380004883
time: 2.256044864654541
[1, 22792] loss_train: 0.000704, loss_test: 0.005533
time: 0.2426133155822754
time: 2.295865058898926
[1, 22793] loss_train: 0.013626, loss_test: 0.005529
time: 0.2450551986694336
time: 2.280510663986206
[1, 22794] loss_train: 0.003670, loss_test: 0.005529
time: 0.24405384063720703
time: 2.266045331954956
[1, 22795] loss_train: 0.002189, loss_test: 0.005530
time: 0.2430565357208252
time: 2.287447929382324
[1, 22796] loss_train: 0.001773, loss_test: 0.005531
time: 0.24305295944213867
time: 2.2725088596343994
[1, 22797] loss_train: 0.002861, loss_test: 0.005533
time: 0.24805521965026855
time: 2.24650239944458
[1, 22798] loss_train: 0.001872, loss_test: 0.005532
time: 0.24305343627929688
time: 2.270510673522949
[1, 22799] loss_train: 0.003403, loss_test: 0.005532
time: 0.24305438995361328
time: 2.2555201053619385
[1, 22800] loss_train: 0.011481, loss_test: 0.005532
time: 0.2584376335144043
time: 2.2805092334747314
[1, 22801] loss_train: 0.003434, loss_test: 0.005531
time: 0.25305700302124023
time: 2.2905139923095703
[1, 22802] loss_train: 0.000932, loss_test: 0.005533
time: 0.24805521965026855
time: 2.251539468765259
[1, 22803] loss_train: 0.007035, loss_test: 0.005534
time: 0.24407672882080078
time: 2.2509841918945312
[1, 22804] loss_train: 0.017191, loss_test: 0.005533
time: 0.24677395820617676
time: 2.2495100498199463
[1, 22805] loss_train: 0.011525, loss_test: 0.005531
time: 0.24852752685546875
time: 2.254958391189575
[1, 22806] loss_train: 0.002684, loss_test: 0.005530
time: 0.24805498123168945
time: 2.231498956680298
[1, 22807] loss_train: 0.005254, loss_test: 0.005529
time: 0.24305391311645508
time: 2.2635061740875244
[1, 22808] loss_train: 0.005238, loss_test: 0.005529
time: 0.24806451797485352
time: 2.2204959392547607
[1, 22809] loss_train: 0.013349, loss_test: 0.005526
time: 0.24405694007873535
time: 2.2695066928863525
[1, 22810] loss_train: 0.003661, loss_test: 0.005522
time: 0.2630610466003418
time: 2.2685067653656006
[1, 22811] loss_train: 0.002473, loss_test: 0.005518
time: 0.24305391311645508
time: 2.2610127925872803
[1, 22812] loss_train: 0.004903, loss_test: 0.005513
time: 0.24605488777160645
time: 2.3538920879364014
[1, 22813] loss_train: 0.006800, loss_test: 0.005507
time: 0.25305628776550293
time: 2.275054931640625
[1, 22814] loss_train: 0.003077, loss_test: 0.005504
time: 0.24805903434753418
time: 2.2632086277008057
[1, 22815] loss_train: 0.013198, loss_test: 0.005502
time: 0.24506425857543945
time: 2.2744243144989014
[1, 22816] loss_train: 0.005529, loss_test: 0.005502
time: 0.24305343627929688
time: 2.2292630672454834
[1, 22817] loss_train: 0.011630, loss_test: 0.005502
time: 0.25005602836608887
time: 2.2600178718566895
[1, 22818] loss_train: 0.006226, loss_test: 0.005503
time: 0.24489188194274902
time: 2.2395029067993164
[1, 22819] loss_train: 0.008983, loss_test: 0.005505
time: 0.24405503273010254
time: 2.2380032539367676
[1, 22820] loss_train: 0.001911, loss_test: 0.005506
time: 0.2600581645965576
time: 2.2360198497772217
[1, 22821] loss_train: 0.006005, loss_test: 0.005508
time: 0.25005483627319336
time: 2.2767794132232666
[1, 22822] loss_train: 0.004707, loss_test: 0.005508
time: 0.24909520149230957
time: 2.250250816345215
[1, 22823] loss_train: 0.005836, loss_test: 0.005510
time: 0.24405479431152344
time: 2.2538068294525146
[1, 22824] loss_train: 0.005359, loss_test: 0.005513
time: 0.24305438995361328
time: 2.2675068378448486
[1, 22825] loss_train: 0.004582, loss_test: 0.005516
time: 0.2520565986633301
time: 2.275925874710083
[1, 22826] loss_train: 0.008046, loss_test: 0.005520
time: 0.24405384063720703
time: 2.2490217685699463
[1, 22827] loss_train: 0.004618, loss_test: 0.005528
time: 0.24205493927001953
time: 2.2455132007598877
[1, 22828] loss_train: 0.002916, loss_test: 0.005537
time: 0.2440338134765625
time: 2.2397279739379883
[1, 22829] loss_train: 0.006235, loss_test: 0.005546
time: 0.2490546703338623
time: 2.2358062267303467
[1, 22830] loss_train: 0.002907, loss_test: 0.005559
time: 0.2570679187774658
time: 2.259053945541382
[1, 22831] loss_train: 0.001711, loss_test: 0.005573
time: 0.24505400657653809
time: 2.2635130882263184
[1, 22832] loss_train: 0.003119, loss_test: 0.005588
time: 0.2470550537109375
time: 2.2505788803100586
[1, 22833] loss_train: 0.006897, loss_test: 0.005605
time: 0.25087976455688477
time: 2.260504961013794
[1, 22834] loss_train: 0.005737, loss_test: 0.005611
time: 0.2510554790496826
time: 2.2703611850738525
[1, 22835] loss_train: 0.002939, loss_test: 0.005618
time: 0.2450547218322754
time: 2.2854859828948975
[1, 22836] loss_train: 0.006364, loss_test: 0.005613
time: 0.24805498123168945
time: 2.3294177055358887
[1, 22837] loss_train: 0.005897, loss_test: 0.005606
time: 0.2560570240020752
time: 2.3388490676879883
[1, 22838] loss_train: 0.002612, loss_test: 0.005602
time: 0.25305676460266113
time: 2.248507261276245
[1, 22839] loss_train: 0.005409, loss_test: 0.005594
time: 0.24605369567871094
time: 2.269643783569336
[1, 22840] loss_train: 0.014572, loss_test: 0.005578
time: 0.2580571174621582
time: 2.2625067234039307
[1, 22841] loss_train: 0.002446, loss_test: 0.005564
time: 0.24605441093444824
time: 2.233006000518799
[1, 22842] loss_train: 0.005837, loss_test: 0.005555
time: 0.24405455589294434
time: 2.2215192317962646
[1, 22843] loss_train: 0.002776, loss_test: 0.005550
time: 0.24805593490600586
time: 2.2649102210998535
[1, 22844] loss_train: 0.005394, loss_test: 0.005548
time: 0.2430555820465088
time: 2.2715084552764893
[1, 22845] loss_train: 0.005825, loss_test: 0.005545
time: 0.24405455589294434
time: 2.282026529312134
[1, 22846] loss_train: 0.004553, loss_test: 0.005542
time: 0.24705791473388672
time: 2.275956630706787
[1, 22847] loss_train: 0.007372, loss_test: 0.005540
time: 0.2520570755004883
time: 2.3197779655456543
[1, 22848] loss_train: 0.010064, loss_test: 0.005536
time: 0.25205564498901367
time: 2.250281810760498
[1, 22849] loss_train: 0.009845, loss_test: 0.005535
time: 0.25305676460266113
time: 2.2953410148620605
[1, 22850] loss_train: 0.006976, loss_test: 0.005537
time: 0.25805139541625977
time: 2.245502471923828
[1, 22851] loss_train: 0.007717, loss_test: 0.005538
time: 0.24805450439453125
time: 2.261349678039551
[1, 22852] loss_train: 0.009255, loss_test: 0.005541
time: 0.25505685806274414
time: 2.246504306793213
[1, 22853] loss_train: 0.002733, loss_test: 0.005546
time: 0.24605560302734375
time: 2.2875115871429443
[1, 22854] loss_train: 0.007287, loss_test: 0.005549
time: 0.2501206398010254
time: 2.254694700241089
[1, 22855] loss_train: 0.005105, loss_test: 0.005549
time: 0.2508270740509033
time: 2.2317068576812744
[1, 22856] loss_train: 0.004259, loss_test: 0.005549
time: 0.24306106567382812
time: 2.2631258964538574
[1, 22857] loss_train: 0.005908, loss_test: 0.005548
time: 0.25106072425842285
time: 2.2843825817108154
[1, 22858] loss_train: 0.007016, loss_test: 0.005547
time: 0.24605512619018555
time: 2.248007297515869
[1, 22859] loss_train: 0.011873, loss_test: 0.005544
time: 0.24355840682983398
time: 2.234511613845825
[1, 22860] loss_train: 0.008187, loss_test: 0.005541
time: 0.25705718994140625
time: 2.245408773422241
[1, 22861] loss_train: 0.003640, loss_test: 0.005537
time: 0.24805521965026855
time: 2.2885453701019287
[1, 22862] loss_train: 0.005136, loss_test: 0.005533
time: 0.25005578994750977
time: 2.2385003566741943
[1, 22863] loss_train: 0.006998, loss_test: 0.005531
time: 0.25706005096435547
time: 2.297149658203125
[1, 22864] loss_train: 0.003943, loss_test: 0.005529
time: 0.24205422401428223
time: 2.2346901893615723
[1, 22865] loss_train: 0.009107, loss_test: 0.005528
time: 0.24505376815795898
time: 2.244502067565918
[1, 22866] loss_train: 0.006458, loss_test: 0.005526
time: 0.2490558624267578
time: 2.2009265422821045
[1, 22867] loss_train: 0.011732, loss_test: 0.005520
time: 0.24906229972839355
time: 2.272641181945801
[1, 22868] loss_train: 0.017770, loss_test: 0.005516
time: 0.24305367469787598
time: 2.2305126190185547
[1, 22869] loss_train: 0.006437, loss_test: 0.005514
time: 0.2510547637939453
time: 2.2665069103240967
[1, 22870] loss_train: 0.001477, loss_test: 0.005513
time: 0.25905942916870117
time: 2.249504804611206
[1, 22871] loss_train: 0.010497, loss_test: 0.005513
time: 0.24605369567871094
time: 2.274507999420166
[1, 22872] loss_train: 0.003732, loss_test: 0.005513
time: 0.24405479431152344
time: 2.2712745666503906
[1, 22873] loss_train: 0.012199, loss_test: 0.005517
time: 0.25305604934692383
time: 2.2630207538604736
[1, 22874] loss_train: 0.000620, loss_test: 0.005518
time: 0.24805521965026855
time: 2.230173349380493
[1, 22875] loss_train: 0.003960, loss_test: 0.005517
time: 0.2490549087524414
time: 2.2539796829223633
[1, 22876] loss_train: 0.005786, loss_test: 0.005517
time: 0.24285006523132324
time: 2.243511438369751
[1, 22877] loss_train: 0.005344, loss_test: 0.005517
time: 0.2439134120941162
time: 2.211043119430542
[1, 22878] loss_train: 0.006087, loss_test: 0.005517
time: 0.24756217002868652
time: 2.236306667327881
[1, 22879] loss_train: 0.005117, loss_test: 0.005516
time: 0.24805617332458496
time: 2.245004177093506
[1, 22880] loss_train: 0.006002, loss_test: 0.005515
time: 0.25556182861328125
time: 2.221001386642456
[1, 22881] loss_train: 0.006095, loss_test: 0.005514
time: 0.24605464935302734
time: 2.2415010929107666
[1, 22882] loss_train: 0.003573, loss_test: 0.005515
time: 0.24805474281311035
time: 2.230499505996704
[1, 22883] loss_train: 0.006355, loss_test: 0.005518
time: 0.2510557174682617
time: 2.2829737663269043
[1, 22884] loss_train: 0.007839, loss_test: 0.005522
time: 0.24305343627929688
time: 2.2583377361297607
[1, 22885] loss_train: 0.003616, loss_test: 0.005527
time: 0.24605488777160645
time: 2.271526575088501
[1, 22886] loss_train: 0.009433, loss_test: 0.005530
time: 0.24605417251586914
time: 2.2355034351348877
[1, 22887] loss_train: 0.007286, loss_test: 0.005531
time: 0.2510554790496826
time: 2.2755088806152344
[1, 22888] loss_train: 0.001943, loss_test: 0.005532
time: 0.25505709648132324
time: 2.2335023880004883
[1, 22889] loss_train: 0.004876, loss_test: 0.005532
time: 0.24405503273010254
time: 2.235093116760254
[1, 22890] loss_train: 0.006206, loss_test: 0.005531
time: 0.2620582580566406
time: 2.220501661300659
[1, 22891] loss_train: 0.006684, loss_test: 0.005530
time: 0.2580583095550537
time: 2.235508441925049
[1, 22892] loss_train: 0.002837, loss_test: 0.005529
time: 0.24105358123779297
time: 2.2450127601623535
[1, 22893] loss_train: 0.012271, loss_test: 0.005523
time: 0.25205516815185547
time: 2.2545175552368164
[1, 22894] loss_train: 0.007605, loss_test: 0.005520
time: 0.24405360221862793
time: 2.256274461746216
[1, 22895] loss_train: 0.006317, loss_test: 0.005520
time: 0.26596498489379883
time: 2.2720983028411865
[1, 22896] loss_train: 0.009964, loss_test: 0.005523
time: 0.2540566921234131
time: 2.247248888015747
[1, 22897] loss_train: 0.003420, loss_test: 0.005526
time: 0.24656343460083008
time: 2.270954132080078
[1, 22898] loss_train: 0.004870, loss_test: 0.005525
time: 0.24205422401428223
time: 2.2320144176483154
[1, 22899] loss_train: 0.005924, loss_test: 0.005527
time: 0.25356101989746094
time: 2.2304985523223877
[1, 22900] loss_train: 0.005708, loss_test: 0.005526
time: 0.25705742835998535
time: 2.2765512466430664
[1, 22901] loss_train: 0.013234, loss_test: 0.005525
time: 0.24213624000549316
time: 2.2313151359558105
[1, 22902] loss_train: 0.004437, loss_test: 0.005523
time: 0.24367094039916992
time: 2.277040719985962
[1, 22903] loss_train: 0.001885, loss_test: 0.005518
time: 0.2490541934967041
time: 2.2255141735076904
[1, 22904] loss_train: 0.002007, loss_test: 0.005513
time: 0.24405360221862793
time: 2.288292646408081
[1, 22905] loss_train: 0.008601, loss_test: 0.005512
time: 0.2450542449951172
time: 2.281456232070923
[1, 22906] loss_train: 0.011789, loss_test: 0.005513
time: 0.24805426597595215
time: 2.283015251159668
[1, 22907] loss_train: 0.003859, loss_test: 0.005517
time: 0.24305367469787598
time: 2.245501756668091
[1, 22908] loss_train: 0.002922, loss_test: 0.005521
time: 0.24455833435058594
time: 2.259382724761963
[1, 22909] loss_train: 0.001397, loss_test: 0.005527
time: 0.2490551471710205
time: 2.2592427730560303
[1, 22910] loss_train: 0.011560, loss_test: 0.005523
time: 0.2676095962524414
time: 2.289940357208252
[1, 22911] loss_train: 0.000785, loss_test: 0.005524
time: 0.24405622482299805
time: 2.250018358230591
[1, 22912] loss_train: 0.005201, loss_test: 0.005521
time: 0.24941539764404297
time: 2.2774758338928223
[1, 22913] loss_train: 0.004588, loss_test: 0.005519
time: 0.2490549087524414
time: 2.2615087032318115
[1, 22914] loss_train: 0.003285, loss_test: 0.005518
time: 0.2490546703338623
time: 2.2515039443969727
[1, 22915] loss_train: 0.005615, loss_test: 0.005518
time: 0.24805808067321777
time: 2.228005886077881
[1, 22916] loss_train: 0.004054, loss_test: 0.005521
time: 0.25205564498901367
time: 2.256507396697998
[1, 22917] loss_train: 0.009871, loss_test: 0.005520
time: 0.24305462837219238
time: 2.281510591506958
[1, 22918] loss_train: 0.002722, loss_test: 0.005520
time: 0.24621868133544922
time: 2.260814666748047
[1, 22919] loss_train: 0.006614, loss_test: 0.005519
time: 0.24405384063720703
time: 2.245781898498535
[1, 22920] loss_train: 0.003870, loss_test: 0.005518
time: 0.25905799865722656
time: 2.2378978729248047
[1, 22921] loss_train: 0.005195, loss_test: 0.005518
time: 0.2494525909423828
time: 2.2646937370300293
[1, 22922] loss_train: 0.002961, loss_test: 0.005517
time: 0.24805474281311035
time: 2.2909536361694336
[1, 22923] loss_train: 0.006303, loss_test: 0.005517
time: 0.24405455589294434
time: 2.2435009479522705
[1, 22924] loss_train: 0.016852, loss_test: 0.005516
time: 0.2470557689666748
time: 2.2880191802978516
[1, 22925] loss_train: 0.003807, loss_test: 0.005516
time: 0.24805498123168945
time: 2.23350191116333
[1, 22926] loss_train: 0.009229, loss_test: 0.005517
time: 0.25005459785461426
time: 2.2915449142456055
[1, 22927] loss_train: 0.003408, loss_test: 0.005518
time: 0.25005650520324707
time: 2.277204990386963
[1, 22928] loss_train: 0.005011, loss_test: 0.005521
time: 0.24343371391296387
time: 2.25750470161438
[1, 22929] loss_train: 0.006830, loss_test: 0.005524
time: 0.24305462837219238
time: 2.251054286956787
[1, 22930] loss_train: 0.003916, loss_test: 0.005527
time: 0.2630584239959717
time: 2.247931957244873
[1, 22931] loss_train: 0.011490, loss_test: 0.005531
time: 0.2450559139251709
time: 2.2726433277130127
[1, 22932] loss_train: 0.003348, loss_test: 0.005535
time: 0.25305676460266113
time: 2.280014753341675
[1, 22933] loss_train: 0.004184, loss_test: 0.005538
time: 0.2490553855895996
time: 2.259530544281006
[1, 22934] loss_train: 0.004631, loss_test: 0.005542
time: 0.2490546703338623
time: 2.2805206775665283
[1, 22935] loss_train: 0.003306, loss_test: 0.005545
time: 0.2450549602508545
time: 2.277773380279541
[1, 22936] loss_train: 0.005594, loss_test: 0.005546
time: 0.2520561218261719
time: 2.289159059524536
[1, 22937] loss_train: 0.009249, loss_test: 0.005536
time: 0.24805474281311035
time: 2.3354430198669434
[1, 22938] loss_train: 0.006510, loss_test: 0.005525
time: 0.2520582675933838
time: 2.369417667388916
[1, 22939] loss_train: 0.010036, loss_test: 0.005517
time: 0.2600572109222412
time: 2.3365235328674316
[1, 22940] loss_train: 0.000768, loss_test: 0.005513
time: 0.2600574493408203
time: 2.2733335494995117
[1, 22941] loss_train: 0.003983, loss_test: 0.005511
time: 0.25005626678466797
time: 2.2782464027404785
[1, 22942] loss_train: 0.008264, loss_test: 0.005512
time: 0.2520565986633301
time: 2.2565040588378906
[1, 22943] loss_train: 0.004772, loss_test: 0.005514
time: 0.24805474281311035
time: 2.4179015159606934
[1, 22944] loss_train: 0.002740, loss_test: 0.005517
time: 0.2510561943054199
time: 2.3573050498962402
[1, 22945] loss_train: 0.014916, loss_test: 0.005521
time: 0.2502567768096924
time: 2.2587640285491943
[1, 22946] loss_train: 0.004754, loss_test: 0.005521
time: 0.2499830722808838
time: 2.332512140274048
[1, 22947] loss_train: 0.010137, loss_test: 0.005522
time: 0.24205303192138672
time: 2.257014751434326
[1, 22948] loss_train: 0.006046, loss_test: 0.005522
time: 0.24405312538146973
time: 2.2814767360687256
[1, 22949] loss_train: 0.004880, loss_test: 0.005524
time: 0.28106188774108887
time: 2.271012306213379
[1, 22950] loss_train: 0.014401, loss_test: 0.005526
time: 0.25905895233154297
time: 2.2785086631774902
[1, 22951] loss_train: 0.002776, loss_test: 0.005529
time: 0.2450542449951172
time: 2.270735502243042
[1, 22952] loss_train: 0.009013, loss_test: 0.005533
time: 0.2470569610595703
time: 2.2545526027679443
[1, 22953] loss_train: 0.001549, loss_test: 0.005537
time: 0.2490556240081787
time: 2.2716846466064453
[1, 22954] loss_train: 0.012847, loss_test: 0.005543
time: 0.25003480911254883
time: 2.2725672721862793
[1, 22955] loss_train: 0.004747, loss_test: 0.005542
time: 0.24305319786071777
time: 2.266014337539673
[1, 22956] loss_train: 0.005753, loss_test: 0.005542
time: 0.24805426597595215
time: 2.2608373165130615
[1, 22957] loss_train: 0.003181, loss_test: 0.005541
time: 0.25105762481689453
time: 2.2410054206848145
[1, 22958] loss_train: 0.007785, loss_test: 0.005538
time: 0.2490556240081787
time: 2.246880054473877
[1, 22959] loss_train: 0.014727, loss_test: 0.005535
time: 0.2430567741394043
time: 2.246131181716919
[1, 22960] loss_train: 0.006155, loss_test: 0.005535
time: 0.26579856872558594
time: 2.2385098934173584
[1, 22961] loss_train: 0.005806, loss_test: 0.005536
time: 0.24805617332458496
time: 2.2639482021331787
[1, 22962] loss_train: 0.008456, loss_test: 0.005537
time: 0.24705791473388672
time: 2.2455132007598877
[1, 22963] loss_train: 0.006577, loss_test: 0.005538
time: 0.2470548152923584
time: 2.250006914138794
[1, 22964] loss_train: 0.005209, loss_test: 0.005540
time: 0.24805474281311035
time: 2.244501829147339
[1, 22965] loss_train: 0.006385, loss_test: 0.005542
time: 0.24805784225463867
time: 2.2765085697174072
[1, 22966] loss_train: 0.006946, loss_test: 0.005546
time: 0.250471830368042
time: 2.281510353088379
[1, 22967] loss_train: 0.007028, loss_test: 0.005551
time: 0.25505685806274414
time: 2.2550394535064697
[1, 22968] loss_train: 0.003971, loss_test: 0.005555
time: 0.25008416175842285
time: 2.280104875564575
[1, 22969] loss_train: 0.011501, loss_test: 0.005559
time: 0.25305819511413574
time: 2.2949912548065186
[1, 22970] loss_train: 0.002018, loss_test: 0.005564
time: 0.2610595226287842
time: 2.31852126121521
[1, 22971] loss_train: 0.002107, loss_test: 0.005568
time: 0.2450573444366455
time: 2.2859349250793457
[1, 22972] loss_train: 0.003092, loss_test: 0.005569
time: 0.24716949462890625
time: 2.2955195903778076
[1, 22973] loss_train: 0.001767, loss_test: 0.005571
time: 0.2435593605041504
time: 2.2475106716156006
[1, 22974] loss_train: 0.006284, loss_test: 0.005571
time: 0.24805545806884766
time: 2.25801944732666
[1, 22975] loss_train: 0.006210, loss_test: 0.005567
time: 0.2490551471710205
time: 2.3105170726776123
[1, 22976] loss_train: 0.002131, loss_test: 0.005565
time: 0.2530558109283447
time: 2.2934458255767822
[1, 22977] loss_train: 0.009977, loss_test: 0.005553
time: 0.24405384063720703
time: 2.3120269775390625
[1, 22978] loss_train: 0.003966, loss_test: 0.005545
time: 0.24508333206176758
time: 2.256124496459961
[1, 22979] loss_train: 0.022253, loss_test: 0.005534
time: 0.24805545806884766
time: 2.281510353088379
[1, 22980] loss_train: 0.007538, loss_test: 0.005528
time: 0.25905704498291016
time: 2.259188413619995
[1, 22981] loss_train: 0.002679, loss_test: 0.005530
time: 0.2520573139190674
time: 2.2525064945220947
[1, 22982] loss_train: 0.001389, loss_test: 0.005533
time: 0.24405479431152344
time: 2.232501983642578
[1, 22983] loss_train: 0.005699, loss_test: 0.005538
time: 0.249053955078125
time: 2.2500312328338623
[1, 22984] loss_train: 0.006932, loss_test: 0.005541
time: 0.2530555725097656
time: 2.278022050857544
[1, 22985] loss_train: 0.005116, loss_test: 0.005545
time: 0.26406049728393555
time: 2.2605040073394775
[1, 22986] loss_train: 0.003441, loss_test: 0.005551
time: 0.24305343627929688
time: 2.2570223808288574
[1, 22987] loss_train: 0.015019, loss_test: 0.005549
time: 0.25412559509277344
time: 2.2541298866271973
[1, 22988] loss_train: 0.008576, loss_test: 0.005544
time: 0.24305391311645508
time: 2.2709949016571045
[1, 22989] loss_train: 0.001749, loss_test: 0.005542
time: 0.2470548152923584
time: 2.245507001876831
[1, 22990] loss_train: 0.003734, loss_test: 0.005540
time: 0.2640571594238281
time: 2.259232521057129
[1, 22991] loss_train: 0.008671, loss_test: 0.005534
time: 0.2540559768676758
time: 2.278663396835327
[1, 22992] loss_train: 0.003637, loss_test: 0.005535
time: 0.2435603141784668
time: 2.259504795074463
[1, 22993] loss_train: 0.016843, loss_test: 0.005534
time: 0.2450549602508545
time: 2.6474087238311768
[1, 22994] loss_train: 0.006925, loss_test: 0.005535
time: 0.27005958557128906
time: 2.2970166206359863
[1, 22995] loss_train: 0.005814, loss_test: 0.005532
time: 0.2520558834075928
time: 2.3130812644958496
[1, 22996] loss_train: 0.005080, loss_test: 0.005528
time: 0.24458551406860352
time: 2.2755086421966553
[1, 22997] loss_train: 0.010599, loss_test: 0.005525
time: 0.2560572624206543
time: 2.400062322616577
[1, 22998] loss_train: 0.011910, loss_test: 0.005519
time: 0.247056245803833
time: 2.2485055923461914
[1, 22999] loss_train: 0.002135, loss_test: 0.005518
time: 0.25205564498901367
time: 2.239511489868164
[1, 23000] loss_train: 0.005540, loss_test: 0.005519
time: 0.258056640625
time: 2.233168601989746
[1, 23001] loss_train: 0.002200, loss_test: 0.005521
time: 0.25305652618408203
time: 2.254979133605957
[1, 23002] loss_train: 0.004172, loss_test: 0.005523
time: 0.24505400657653809
time: 2.2473185062408447
[1, 23003] loss_train: 0.008890, loss_test: 0.005525
time: 0.24319791793823242
time: 2.259303092956543
[1, 23004] loss_train: 0.010375, loss_test: 0.005524
time: 0.2470555305480957
time: 2.275014877319336
[1, 23005] loss_train: 0.003531, loss_test: 0.005523
time: 0.254056453704834
time: 2.2645087242126465
[1, 23006] loss_train: 0.005770, loss_test: 0.005522
time: 0.24805808067321777
time: 2.2635066509246826
[1, 23007] loss_train: 0.005883, loss_test: 0.005520
time: 0.24605464935302734
time: 2.25850510597229
[1, 23008] loss_train: 0.007428, loss_test: 0.005520
time: 0.24405455589294434
time: 2.2470085620880127
[1, 23009] loss_train: 0.006005, loss_test: 0.005521
time: 0.25515246391296387
time: 2.287534475326538
[1, 23010] loss_train: 0.009471, loss_test: 0.005523
time: 0.26305460929870605
time: 2.2579383850097656
[1, 23011] loss_train: 0.009577, loss_test: 0.005528
time: 0.26247429847717285
time: 2.3843066692352295
[1, 23012] loss_train: 0.004536, loss_test: 0.005533
time: 0.24605369567871094
time: 2.2625069618225098
[1, 23013] loss_train: 0.003426, loss_test: 0.005534
time: 0.2470555305480957
time: 2.3935534954071045
[1, 23014] loss_train: 0.001827, loss_test: 0.005533
time: 0.2830641269683838
time: 2.426541566848755
[1, 23015] loss_train: 0.001422, loss_test: 0.005532
time: 0.27527666091918945
time: 2.3195292949676514
[1, 23016] loss_train: 0.011224, loss_test: 0.005531
time: 0.25705814361572266
time: 2.4071829319000244
[1, 23017] loss_train: 0.006032, loss_test: 0.005530
time: 0.25005578994750977
time: 2.404020071029663
[1, 23018] loss_train: 0.001406, loss_test: 0.005528
time: 0.2760608196258545
time: 2.3481757640838623
[1, 23019] loss_train: 0.004248, loss_test: 0.005528
time: 0.25054049491882324
time: 2.342392921447754
[1, 23020] loss_train: 0.013982, loss_test: 0.005529
time: 0.2740612030029297
time: 2.3090219497680664
[1, 23021] loss_train: 0.006039, loss_test: 0.005531
time: 0.2490549087524414
time: 2.2405035495758057
[1, 23022] loss_train: 0.006353, loss_test: 0.005531
time: 0.24405407905578613
time: 2.3240268230438232
[1, 23023] loss_train: 0.003742, loss_test: 0.005530
time: 0.33907485008239746
time: 2.392535448074341
[1, 23024] loss_train: 0.008501, loss_test: 0.005529
time: 0.25305747985839844
time: 2.479053497314453
[1, 23025] loss_train: 0.005182, loss_test: 0.005527
time: 0.24305367469787598
time: 2.2785277366638184
[1, 23026] loss_train: 0.010395, loss_test: 0.005525
time: 0.3040659427642822
time: 2.383923053741455
[1, 23027] loss_train: 0.005138, loss_test: 0.005521
time: 0.24143290519714355
time: 2.290527582168579
[1, 23028] loss_train: 0.008385, loss_test: 0.005517
time: 0.24255895614624023
time: 2.303528308868408
[1, 23029] loss_train: 0.005573, loss_test: 0.005514
time: 0.2505607604980469
time: 2.325624465942383
[1, 23030] loss_train: 0.010659, loss_test: 0.005508
time: 0.2890627384185791
time: 2.3874218463897705
[1, 23031] loss_train: 0.012647, loss_test: 0.005504
time: 0.24605393409729004
time: 2.284024953842163
[1, 23032] loss_train: 0.012304, loss_test: 0.005499
time: 0.24605321884155273
time: 2.278756856918335
[1, 23033] loss_train: 0.008307, loss_test: 0.005498
time: 0.25005435943603516
time: 2.3059396743774414
[1, 23034] loss_train: 0.004050, loss_test: 0.005501
time: 0.2650594711303711
time: 2.4915573596954346
[1, 23035] loss_train: 0.015092, loss_test: 0.005506
time: 0.2540550231933594
time: 2.2747323513031006
[1, 23036] loss_train: 0.002162, loss_test: 0.005509
time: 0.24405884742736816
time: 2.2894747257232666
[1, 23037] loss_train: 0.000731, loss_test: 0.005510
time: 0.24405384063720703
time: 2.2667856216430664
[1, 23038] loss_train: 0.006863, loss_test: 0.005508
time: 0.24305343627929688
time: 2.2475032806396484
[1, 23039] loss_train: 0.011903, loss_test: 0.005509
time: 0.25200843811035156
time: 2.272390365600586
[1, 23040] loss_train: 0.014230, loss_test: 0.005511
time: 0.25505614280700684
time: 2.2505040168762207
[1, 23041] loss_train: 0.008044, loss_test: 0.005514
time: 0.2510559558868408
time: 2.357027769088745
[1, 23042] loss_train: 0.006247, loss_test: 0.005517
time: 0.2600584030151367
time: 2.281475067138672
[1, 23043] loss_train: 0.004964, loss_test: 0.005516
time: 0.24605369567871094
time: 2.283066987991333
[1, 23044] loss_train: 0.005775, loss_test: 0.005514
time: 0.24305510520935059
time: 2.2365832328796387
[1, 23045] loss_train: 0.003572, loss_test: 0.005517
time: 0.24905681610107422
time: 2.341524124145508
[1, 23046] loss_train: 0.006157, loss_test: 0.005521
time: 0.25505709648132324
time: 2.2665154933929443
[1, 23047] loss_train: 0.005341, loss_test: 0.005527
time: 0.2670588493347168
time: 2.4030609130859375
[1, 23048] loss_train: 0.008302, loss_test: 0.005530
time: 0.2430567741394043
time: 2.2735087871551514
[1, 23049] loss_train: 0.008879, loss_test: 0.005526
time: 0.30606794357299805
time: 2.337524175643921
[1, 23050] loss_train: 0.007546, loss_test: 0.005530
time: 0.269059419631958
time: 2.272791862487793
[1, 23051] loss_train: 0.012432, loss_test: 0.005543
time: 0.24405503273010254
time: 2.292384147644043
[1, 23052] loss_train: 0.005023, loss_test: 0.005568
time: 0.2470555305480957
time: 2.264619827270508
[1, 23053] loss_train: 0.003742, loss_test: 0.005590
time: 0.24505352973937988
time: 2.2455029487609863
[1, 23054] loss_train: 0.002266, loss_test: 0.005611
time: 0.25005507469177246
time: 2.3000190258026123
[1, 23055] loss_train: 0.005151, loss_test: 0.005613
time: 0.24805450439453125
time: 2.2685258388519287
[1, 23056] loss_train: 0.010526, loss_test: 0.005605
time: 0.2600572109222412
time: 2.280510902404785
[1, 23057] loss_train: 0.003694, loss_test: 0.005584
time: 0.2490546703338623
time: 2.2600080966949463
[1, 23058] loss_train: 0.020725, loss_test: 0.005580
time: 0.2510557174682617
time: 2.289768695831299
[1, 23059] loss_train: 0.005377, loss_test: 0.005574
time: 0.24805474281311035
time: 2.282125473022461
[1, 23060] loss_train: 0.002052, loss_test: 0.005565
time: 0.2580606937408447
time: 2.2817883491516113
[1, 23061] loss_train: 0.002470, loss_test: 0.005558
time: 0.2520575523376465
time: 2.263504981994629
[1, 23062] loss_train: 0.007942, loss_test: 0.005555
time: 0.24405479431152344
time: 2.280308723449707
[1, 23063] loss_train: 0.008176, loss_test: 0.005554
time: 0.24805498123168945
time: 2.2775137424468994
[1, 23064] loss_train: 0.004174, loss_test: 0.005556
time: 0.2450563907623291
time: 2.272507667541504
[1, 23065] loss_train: 0.010653, loss_test: 0.005548
time: 0.24405455589294434
time: 2.265023946762085
[1, 23066] loss_train: 0.012816, loss_test: 0.005531
time: 0.24155807495117188
time: 2.249331474304199
[1, 23067] loss_train: 0.012618, loss_test: 0.005533
time: 0.24405360221862793
time: 2.282172203063965
[1, 23068] loss_train: 0.003974, loss_test: 0.005553
time: 0.25505614280700684
time: 2.263239860534668
[1, 23069] loss_train: 0.006865, loss_test: 0.005586
time: 0.24599933624267578
time: 2.2932441234588623
[1, 23070] loss_train: 0.007576, loss_test: 0.005621
time: 0.2620575428009033
time: 2.261509895324707
[1, 23071] loss_train: 0.011375, loss_test: 0.005653
time: 0.24305391311645508
time: 2.2355105876922607
[1, 23072] loss_train: 0.006692, loss_test: 0.005681
time: 0.24405455589294434
time: 2.2644054889678955
[1, 23073] loss_train: 0.001317, loss_test: 0.005709
time: 0.24355864524841309
time: 2.2605180740356445
[1, 23074] loss_train: 0.008836, loss_test: 0.005725
time: 0.2470550537109375
time: 2.2848713397979736
[1, 23075] loss_train: 0.008484, loss_test: 0.005727
time: 0.24528741836547852
time: 2.2920162677764893
[1, 23076] loss_train: 0.001643, loss_test: 0.005709
time: 0.301067590713501
time: 2.32953143119812
[1, 23077] loss_train: 0.008998, loss_test: 0.005683
time: 0.26205945014953613
time: 2.2800137996673584
[1, 23078] loss_train: 0.012809, loss_test: 0.005634
time: 0.2490556240081787
time: 2.2465076446533203
[1, 23079] loss_train: 0.003631, loss_test: 0.005548
time: 0.2490556240081787
time: 2.2780749797821045
[1, 23080] loss_train: 0.007018, loss_test: 0.005520
time: 0.2560575008392334
time: 2.283630132675171
[1, 23081] loss_train: 0.004206, loss_test: 0.005522
time: 0.26706576347351074
time: 2.2264246940612793
[1, 23082] loss_train: 0.007470, loss_test: 0.005540
time: 0.24405479431152344
time: 2.2470474243164062
[1, 23083] loss_train: 0.002184, loss_test: 0.005567
time: 0.24605417251586914
time: 2.2655067443847656
[1, 23084] loss_train: 0.000927, loss_test: 0.005598
time: 0.24305343627929688
time: 2.444063425064087
[1, 23085] loss_train: 0.003697, loss_test: 0.005627
time: 0.24305415153503418
time: 2.2599432468414307
[1, 23086] loss_train: 0.004764, loss_test: 0.005648
time: 0.2470555305480957
time: 2.2838704586029053
[1, 23087] loss_train: 0.001238, loss_test: 0.005663
time: 0.24305391311645508
time: 2.280510425567627
[1, 23088] loss_train: 0.008418, loss_test: 0.005677
time: 0.24505400657653809
time: 2.28338885307312
[1, 23089] loss_train: 0.009018, loss_test: 0.005675
time: 0.25005507469177246
time: 2.2820141315460205
[1, 23090] loss_train: 0.004107, loss_test: 0.005672
time: 0.26205873489379883
time: 2.2435078620910645
[1, 23091] loss_train: 0.003155, loss_test: 0.005672
time: 0.25305676460266113
time: 2.5945796966552734
[1, 23092] loss_train: 0.003885, loss_test: 0.005675
time: 0.3278937339782715
time: 2.686896800994873
[1, 23093] loss_train: 0.006801, loss_test: 0.005669
time: 0.2588682174682617
time: 2.317021369934082
[1, 23094] loss_train: 0.004692, loss_test: 0.005661
time: 0.25205445289611816
time: 2.2955210208892822
[1, 23095] loss_train: 0.004492, loss_test: 0.005651
time: 0.24805545806884766
time: 2.257331371307373
[1, 23096] loss_train: 0.004839, loss_test: 0.005641
time: 0.2520568370819092
time: 2.2785089015960693
[1, 23097] loss_train: 0.001560, loss_test: 0.005635
time: 0.2426745891571045
time: 2.2825212478637695
[1, 23098] loss_train: 0.002268, loss_test: 0.005632
time: 0.25705695152282715
time: 2.276512622833252
[1, 23099] loss_train: 0.008339, loss_test: 0.005624
time: 0.24405360221862793
time: 2.301515817642212
[1, 23100] loss_train: 0.001777, loss_test: 0.005617
time: 0.2630581855773926
time: 2.2500741481781006
[1, 23101] loss_train: 0.007900, loss_test: 0.005612
time: 0.24305367469787598
time: 2.2791051864624023
[1, 23102] loss_train: 0.016140, loss_test: 0.005589
time: 0.2521545886993408
time: 2.30825138092041
[1, 23103] loss_train: 0.011250, loss_test: 0.005566
time: 0.24705743789672852
time: 2.2520110607147217
[1, 23104] loss_train: 0.009289, loss_test: 0.005549
time: 0.24805521965026855
time: 2.271507740020752
[1, 23105] loss_train: 0.002773, loss_test: 0.005542
time: 0.2450544834136963
time: 2.2615058422088623
[1, 23106] loss_train: 0.007013, loss_test: 0.005543
time: 0.2450547218322754
time: 2.2425034046173096
[1, 23107] loss_train: 0.001336, loss_test: 0.005549
time: 0.24905610084533691
time: 2.2625696659088135
[1, 23108] loss_train: 0.007191, loss_test: 0.005558
time: 0.24905657768249512
time: 2.2790987491607666
[1, 23109] loss_train: 0.009497, loss_test: 0.005570
time: 0.2415621280670166
time: 2.2503662109375
[1, 23110] loss_train: 0.006040, loss_test: 0.005581
time: 0.26005983352661133
time: 2.2512571811676025
[1, 23111] loss_train: 0.004015, loss_test: 0.005595
time: 0.2499535083770752
time: 2.2700064182281494
[1, 23112] loss_train: 0.002137, loss_test: 0.005606
time: 0.24301457405090332
time: 2.2523951530456543
[1, 23113] loss_train: 0.004466, loss_test: 0.005605
time: 0.2440626621246338
time: 2.254504680633545
[1, 23114] loss_train: 0.005171, loss_test: 0.005598
time: 0.24255847930908203
time: 2.2957420349121094
[1, 23115] loss_train: 0.003356, loss_test: 0.005583
time: 0.24405360221862793
time: 2.267066717147827
[1, 23116] loss_train: 0.008301, loss_test: 0.005569
time: 0.24505400657653809
time: 2.2865142822265625
[1, 23117] loss_train: 0.003272, loss_test: 0.005557
time: 0.24405336380004883
time: 2.247512102127075
[1, 23118] loss_train: 0.004522, loss_test: 0.005549
time: 0.24305462837219238
time: 2.29201602935791
[1, 23119] loss_train: 0.001596, loss_test: 0.005545
time: 0.24205279350280762
time: 2.2510101795196533
[1, 23120] loss_train: 0.007049, loss_test: 0.005545
time: 0.25505709648132324
time: 2.282470703125
[1, 23121] loss_train: 0.005039, loss_test: 0.005550
time: 0.24405431747436523
time: 2.268688201904297
[1, 23122] loss_train: 0.009772, loss_test: 0.005548
time: 0.24400687217712402
time: 2.240720748901367
[1, 23123] loss_train: 0.000399, loss_test: 0.005547
time: 0.24305415153503418
time: 2.2645106315612793
[1, 23124] loss_train: 0.012308, loss_test: 0.005539
time: 0.24355411529541016
time: 2.2675070762634277
[1, 23125] loss_train: 0.001866, loss_test: 0.005535
time: 0.24105286598205566
time: 2.272519111633301
[1, 23126] loss_train: 0.003564, loss_test: 0.005535
time: 0.2540569305419922
time: 2.246004819869995
[1, 23127] loss_train: 0.005345, loss_test: 0.005534
time: 0.24305415153503418
time: 2.2450051307678223
[1, 23128] loss_train: 0.010697, loss_test: 0.005528
time: 0.24405431747436523
time: 2.2372212409973145
[1, 23129] loss_train: 0.009143, loss_test: 0.005524
time: 0.2530632019042969
time: 2.2751810550689697
[1, 23130] loss_train: 0.005640, loss_test: 0.005522
time: 0.26105785369873047
time: 2.248502254486084
[1, 23131] loss_train: 0.008378, loss_test: 0.005524
time: 0.24205374717712402
time: 2.254434823989868
[1, 23132] loss_train: 0.002622, loss_test: 0.005528
time: 0.2430555820465088
time: 2.2727859020233154
[1, 23133] loss_train: 0.001409, loss_test: 0.005535
time: 0.24405527114868164
time: 2.2745087146759033
[1, 23134] loss_train: 0.006410, loss_test: 0.005540
time: 0.24305438995361328
time: 2.259019374847412
[1, 23135] loss_train: 0.004744, loss_test: 0.005544
time: 0.2510557174682617
time: 2.2525033950805664
[1, 23136] loss_train: 0.007391, loss_test: 0.005546
time: 0.24405503273010254
time: 2.288693428039551
[1, 23137] loss_train: 0.005781, loss_test: 0.005544
time: 0.2520568370819092
time: 2.2668418884277344
[1, 23138] loss_train: 0.002114, loss_test: 0.005545
time: 0.24486732482910156
time: 2.2334470748901367
[1, 23139] loss_train: 0.004468, loss_test: 0.005544
time: 0.2470541000366211
time: 2.2325527667999268
[1, 23140] loss_train: 0.002751, loss_test: 0.005545
time: 0.2600576877593994
time: 2.246006488800049
[1, 23141] loss_train: 0.002471, loss_test: 0.005547
time: 0.25156164169311523
time: 2.2385025024414062
[1, 23142] loss_train: 0.002501, loss_test: 0.005543
time: 0.24605464935302734
time: 2.262028694152832
[1, 23143] loss_train: 0.004166, loss_test: 0.005539
time: 0.2471320629119873
time: 2.2248027324676514
[1, 23144] loss_train: 0.004648, loss_test: 0.005535
time: 0.24405908584594727
time: 2.253204345703125
[1, 23145] loss_train: 0.002341, loss_test: 0.005533
time: 0.25005483627319336
time: 2.2335023880004883
[1, 23146] loss_train: 0.003482, loss_test: 0.005532
time: 0.24405622482299805
time: 2.25028657913208
[1, 23147] loss_train: 0.007743, loss_test: 0.005528
time: 0.24405479431152344
time: 2.2540698051452637
[1, 23148] loss_train: 0.002341, loss_test: 0.005526
time: 0.24505376815795898
time: 2.2365007400512695
[1, 23149] loss_train: 0.006372, loss_test: 0.005525
time: 0.2455599308013916
time: 2.260011672973633
[1, 23150] loss_train: 0.002805, loss_test: 0.005525
time: 0.2580568790435791
time: 2.289515256881714
[1, 23151] loss_train: 0.004056, loss_test: 0.005527
time: 0.2470550537109375
time: 2.2640888690948486
[1, 23152] loss_train: 0.008917, loss_test: 0.005531
time: 0.24805521965026855
time: 2.2646164894104004
[1, 23153] loss_train: 0.005215, loss_test: 0.005533
time: 0.252063512802124
time: 2.284404754638672
[1, 23154] loss_train: 0.007739, loss_test: 0.005534
time: 0.24305367469787598
time: 2.22304368019104
[1, 23155] loss_train: 0.006149, loss_test: 0.005537
time: 0.2505626678466797
time: 2.255507469177246
[1, 23156] loss_train: 0.001841, loss_test: 0.005542
time: 0.24205327033996582
time: 2.237501621246338
[1, 23157] loss_train: 0.002472, loss_test: 0.005548
time: 0.2560560703277588
time: 2.252157211303711
[1, 23158] loss_train: 0.006314, loss_test: 0.005551
time: 0.24305415153503418
time: 2.3039231300354004
[1, 23159] loss_train: 0.003566, loss_test: 0.005552
time: 0.30806899070739746
time: 2.280808210372925
[1, 23160] loss_train: 0.004238, loss_test: 0.005552
time: 0.278062105178833
time: 2.2875120639801025
[1, 23161] loss_train: 0.004219, loss_test: 0.005555
time: 0.25055789947509766
time: 2.3290319442749023
[1, 23162] loss_train: 0.005510, loss_test: 0.005561
time: 0.2540562152862549
time: 2.258043050765991
[1, 23163] loss_train: 0.011427, loss_test: 0.005563
time: 0.24605584144592285
time: 2.276508331298828
[1, 23164] loss_train: 0.010731, loss_test: 0.005558
time: 0.24305462837219238
time: 2.2735085487365723
[1, 23165] loss_train: 0.001725, loss_test: 0.005555
time: 0.24205446243286133
time: 2.2635061740875244
[1, 23166] loss_train: 0.005673, loss_test: 0.005552
time: 0.24405479431152344
time: 2.2765121459960938
[1, 23167] loss_train: 0.002525, loss_test: 0.005550
time: 0.2470550537109375
time: 2.2580854892730713
[1, 23168] loss_train: 0.004740, loss_test: 0.005548
time: 0.25705718994140625
time: 2.3720030784606934
[1, 23169] loss_train: 0.006583, loss_test: 0.005545
time: 0.2590634822845459
time: 2.2795708179473877
[1, 23170] loss_train: 0.004032, loss_test: 0.005542
time: 0.2655632495880127
time: 2.2220568656921387
[1, 23171] loss_train: 0.002825, loss_test: 0.005537
time: 0.24305391311645508
time: 2.25500750541687
[1, 23172] loss_train: 0.006697, loss_test: 0.005532
time: 0.24905753135681152
time: 2.2384586334228516
[1, 23173] loss_train: 0.006714, loss_test: 0.005526
time: 0.24205446243286133
time: 2.293513298034668
[1, 23174] loss_train: 0.008398, loss_test: 0.005521
time: 0.25005507469177246
time: 2.2921297550201416
[1, 23175] loss_train: 0.009929, loss_test: 0.005518
time: 0.2490549087524414
time: 2.2385003566741943
[1, 23176] loss_train: 0.006111, loss_test: 0.005515
time: 0.24605441093444824
time: 2.226938247680664
[1, 23177] loss_train: 0.012110, loss_test: 0.005514
time: 0.24605512619018555
time: 2.216996908187866
[1, 23178] loss_train: 0.001525, loss_test: 0.005514
time: 0.25105977058410645
time: 2.222228765487671
[1, 23179] loss_train: 0.014707, loss_test: 0.005513
time: 0.24205374717712402
time: 2.2895233631134033
[1, 23180] loss_train: 0.007243, loss_test: 0.005512
time: 0.3071293830871582
time: 2.2469820976257324
[1, 23181] loss_train: 0.006115, loss_test: 0.005512
time: 0.24205374717712402
time: 2.246685266494751
[1, 23182] loss_train: 0.012218, loss_test: 0.005513
time: 0.25356197357177734
time: 2.2435050010681152
[1, 23183] loss_train: 0.007192, loss_test: 0.005512
time: 0.2510557174682617
time: 2.276642322540283
[1, 23184] loss_train: 0.014974, loss_test: 0.005514
time: 0.24805402755737305
time: 2.2484183311462402
[1, 23185] loss_train: 0.003946, loss_test: 0.005515
time: 0.24405312538146973
time: 2.2495064735412598
[1, 23186] loss_train: 0.003114, loss_test: 0.005515
time: 0.247056245803833
time: 2.227963924407959
[1, 23187] loss_train: 0.019019, loss_test: 0.005515
time: 0.2430565357208252
time: 2.254513740539551
[1, 23188] loss_train: 0.005098, loss_test: 0.005515
time: 0.25005555152893066
time: 2.2425038814544678
[1, 23189] loss_train: 0.005557, loss_test: 0.005514
time: 0.24405384063720703
time: 2.224498748779297
[1, 23190] loss_train: 0.007585, loss_test: 0.005512
time: 0.2630581855773926
time: 2.240741729736328
[1, 23191] loss_train: 0.009119, loss_test: 0.005511
time: 0.24105358123779297
time: 2.2696781158447266
[1, 23192] loss_train: 0.006377, loss_test: 0.005511
time: 0.2554445266723633
time: 2.289842128753662
[1, 23193] loss_train: 0.005909, loss_test: 0.005513
time: 0.24686670303344727
time: 2.238069772720337
[1, 23194] loss_train: 0.005811, loss_test: 0.005515
time: 0.25005531311035156
time: 2.252293825149536
[1, 23195] loss_train: 0.013629, loss_test: 0.005513
time: 0.24805760383605957
time: 2.257805347442627
[1, 23196] loss_train: 0.004705, loss_test: 0.005512
time: 0.25005555152893066
time: 2.259505271911621
[1, 23197] loss_train: 0.008697, loss_test: 0.005517
time: 0.24805545806884766
time: 2.2535040378570557
[1, 23198] loss_train: 0.002082, loss_test: 0.005521
time: 0.2490551471710205
time: 2.252007484436035
[1, 23199] loss_train: 0.005940, loss_test: 0.005526
time: 0.24405574798583984
time: 2.329535722732544
[1, 23200] loss_train: 0.007929, loss_test: 0.005532
time: 0.2650599479675293
time: 2.306614398956299
[1, 23201] loss_train: 0.009427, loss_test: 0.005535
time: 0.24541687965393066
time: 2.2478182315826416
[1, 23202] loss_train: 0.004499, loss_test: 0.005541
time: 0.24305367469787598
time: 2.260519504547119
[1, 23203] loss_train: 0.004408, loss_test: 0.005546
time: 0.2450549602508545
time: 2.2557759284973145
[1, 23204] loss_train: 0.008028, loss_test: 0.005551
time: 0.24405884742736816
time: 2.260742425918579
[1, 23205] loss_train: 0.004172, loss_test: 0.005554
time: 0.25156164169311523
time: 2.260007858276367
[1, 23206] loss_train: 0.009434, loss_test: 0.005558
time: 0.2450544834136963
time: 2.293515205383301
[1, 23207] loss_train: 0.002039, loss_test: 0.005559
time: 0.24605464935302734
time: 2.2905120849609375
[1, 23208] loss_train: 0.004022, loss_test: 0.005563
time: 0.2520565986633301
time: 2.312021255493164
[1, 23209] loss_train: 0.009153, loss_test: 0.005563
time: 0.24805474281311035
time: 2.2550208568573
[1, 23210] loss_train: 0.002793, loss_test: 0.005565
time: 0.255889892578125
time: 2.312270164489746
[1, 23211] loss_train: 0.008462, loss_test: 0.005562
time: 0.2597157955169678
time: 2.2480499744415283
[1, 23212] loss_train: 0.010127, loss_test: 0.005559
time: 0.24836444854736328
time: 2.2684996128082275
[1, 23213] loss_train: 0.004453, loss_test: 0.005555
time: 0.24905610084533691
time: 2.262505292892456
[1, 23214] loss_train: 0.006123, loss_test: 0.005551
time: 0.24305343627929688
time: 2.2985143661499023
[1, 23215] loss_train: 0.010029, loss_test: 0.005548
time: 0.26405835151672363
time: 2.28751277923584
[1, 23216] loss_train: 0.006872, loss_test: 0.005543
time: 0.24205303192138672
time: 2.2685093879699707
[1, 23217] loss_train: 0.007520, loss_test: 0.005539
time: 0.24405384063720703
time: 2.268540859222412
[1, 23218] loss_train: 0.006103, loss_test: 0.005534
time: 0.24205398559570312
time: 2.2555043697357178
[1, 23219] loss_train: 0.001994, loss_test: 0.005533
time: 0.2540569305419922
time: 2.2895240783691406
[1, 23220] loss_train: 0.007702, loss_test: 0.005528
time: 0.25905752182006836
time: 2.2717771530151367
[1, 23221] loss_train: 0.002400, loss_test: 0.005530
time: 0.24405455589294434
time: 2.2480199337005615
[1, 23222] loss_train: 0.003045, loss_test: 0.005531
time: 0.24605488777160645
time: 2.2995188236236572
[1, 23223] loss_train: 0.008404, loss_test: 0.005534
time: 0.24805521965026855
time: 2.2664544582366943
[1, 23224] loss_train: 0.004952, loss_test: 0.005536
time: 0.24505400657653809
time: 2.279510021209717
[1, 23225] loss_train: 0.015405, loss_test: 0.005533
time: 0.2490546703338623
time: 2.2375025749206543
[1, 23226] loss_train: 0.005226, loss_test: 0.005533
time: 0.24305462837219238
time: 2.264505624771118
[1, 23227] loss_train: 0.007285, loss_test: 0.005531
time: 0.24805402755737305
time: 2.2635090351104736
[1, 23228] loss_train: 0.012252, loss_test: 0.005531
time: 0.24205470085144043
time: 2.2700181007385254
[1, 23229] loss_train: 0.013583, loss_test: 0.005537
time: 0.24305343627929688
time: 2.226423978805542
[1, 23230] loss_train: 0.007471, loss_test: 0.005544
time: 0.2560567855834961
time: 2.276386022567749
[1, 23231] loss_train: 0.006535, loss_test: 0.005544
time: 0.2450544834136963
time: 2.2211527824401855
[1, 23232] loss_train: 0.006302, loss_test: 0.005543
time: 0.2416057586669922
time: 2.2935140132904053
[1, 23233] loss_train: 0.001813, loss_test: 0.005545
time: 0.24305367469787598
time: 2.247549533843994
[1, 23234] loss_train: 0.006424, loss_test: 0.005546
time: 0.24205517768859863
time: 2.2861485481262207
[1, 23235] loss_train: 0.014426, loss_test: 0.005542
time: 0.2450549602508545
time: 2.2765109539031982
[1, 23236] loss_train: 0.002598, loss_test: 0.005537
time: 0.24105358123779297
time: 2.281514883041382
[1, 23237] loss_train: 0.006862, loss_test: 0.005526
time: 0.2470550537109375
time: 2.2745437622070312
[1, 23238] loss_train: 0.004912, loss_test: 0.005520
time: 0.24746012687683105
time: 2.2883307933807373
[1, 23239] loss_train: 0.002888, loss_test: 0.005514
time: 0.2470533847808838
time: 2.2714622020721436
[1, 23240] loss_train: 0.010942, loss_test: 0.005510
time: 0.2579460144042969
time: 2.2969934940338135
[1, 23241] loss_train: 0.005633, loss_test: 0.005506
time: 0.24305367469787598
time: 2.2801342010498047
[1, 23242] loss_train: 0.013781, loss_test: 0.005503
time: 0.25305604934692383
time: 2.2504827976226807
[1, 23243] loss_train: 0.004916, loss_test: 0.005503
time: 0.2435593605041504
time: 2.241520881652832
[1, 23244] loss_train: 0.002089, loss_test: 0.005503
time: 0.247633695602417
time: 2.270508289337158
[1, 23245] loss_train: 0.001673, loss_test: 0.005504
time: 0.2470548152923584
time: 2.2369754314422607
[1, 23246] loss_train: 0.010653, loss_test: 0.005505
time: 0.264601469039917
time: 2.292527198791504
[1, 23247] loss_train: 0.006478, loss_test: 0.005507
time: 0.2530555725097656
time: 2.302783727645874
[1, 23248] loss_train: 0.009233, loss_test: 0.005511
time: 0.2520573139190674
time: 2.262465715408325
[1, 23249] loss_train: 0.003021, loss_test: 0.005517
time: 0.24405336380004883
time: 2.246504783630371
[1, 23250] loss_train: 0.002473, loss_test: 0.005523
time: 0.2620577812194824
time: 2.253504514694214
[1, 23251] loss_train: 0.009341, loss_test: 0.005527
time: 0.24605488777160645
time: 2.2380144596099854
[1, 23252] loss_train: 0.002229, loss_test: 0.005533
time: 0.2470552921295166
time: 2.257506847381592
[1, 23253] loss_train: 0.007173, loss_test: 0.005537
time: 0.2537841796875
time: 2.2726237773895264
[1, 23254] loss_train: 0.009799, loss_test: 0.005539
time: 0.24405336380004883
time: 2.30928635597229
[1, 23255] loss_train: 0.012054, loss_test: 0.005536
time: 0.2510945796966553
time: 2.3165292739868164
[1, 23256] loss_train: 0.011644, loss_test: 0.005536
time: 0.25556063652038574
time: 2.302912712097168
[1, 23257] loss_train: 0.002480, loss_test: 0.005538
time: 0.257061243057251
time: 2.3225290775299072
[1, 23258] loss_train: 0.004480, loss_test: 0.005542
time: 0.24605345726013184
time: 2.2454679012298584
[1, 23259] loss_train: 0.004341, loss_test: 0.005546
time: 0.24305462837219238
time: 2.2675065994262695
[1, 23260] loss_train: 0.003873, loss_test: 0.005548
time: 0.2560570240020752
time: 2.2586467266082764
[1, 23261] loss_train: 0.003215, loss_test: 0.005548
time: 0.26102447509765625
time: 2.266294479370117
[1, 23262] loss_train: 0.005935, loss_test: 0.005546
time: 0.25305604934692383
time: 2.3235855102539062
[1, 23263] loss_train: 0.003391, loss_test: 0.005544
time: 0.2580568790435791
time: 2.257007598876953
[1, 23264] loss_train: 0.004304, loss_test: 0.005544
time: 0.24205398559570312
time: 2.2635202407836914
[1, 23265] loss_train: 0.006092, loss_test: 0.005546
time: 0.25705718994140625
time: 2.2890164852142334
[1, 23266] loss_train: 0.006645, loss_test: 0.005549
time: 0.24205374717712402
time: 2.241503953933716
[1, 23267] loss_train: 0.002189, loss_test: 0.005553
time: 0.24405384063720703
time: 2.2144954204559326
[1, 23268] loss_train: 0.002371, loss_test: 0.005557
time: 0.24205398559570312
time: 2.214259147644043
[1, 23269] loss_train: 0.001682, loss_test: 0.005562
time: 0.2540566921234131
time: 2.2370407581329346
[1, 23270] loss_train: 0.002785, loss_test: 0.005569
time: 0.25406360626220703
time: 2.2401912212371826
[1, 23271] loss_train: 0.004994, loss_test: 0.005571
time: 0.2520561218261719
time: 2.291320562362671
[1, 23272] loss_train: 0.009774, loss_test: 0.005569
time: 0.2480638027191162
time: 2.5082075595855713
[1, 23273] loss_train: 0.005458, loss_test: 0.005563
time: 0.2510559558868408
time: 2.2495179176330566
[1, 23274] loss_train: 0.010537, loss_test: 0.005549
time: 0.25705575942993164
time: 2.294515609741211
[1, 23275] loss_train: 0.008101, loss_test: 0.005538
time: 0.25657033920288086
time: 2.3185250759124756
[1, 23276] loss_train: 0.003287, loss_test: 0.005532
time: 0.27306079864501953
time: 2.360527515411377
[1, 23277] loss_train: 0.003657, loss_test: 0.005530
time: 0.25205540657043457
time: 2.2930171489715576
[1, 23278] loss_train: 0.012060, loss_test: 0.005528
time: 0.27006006240844727
time: 2.2890920639038086
[1, 23279] loss_train: 0.004450, loss_test: 0.005524
time: 0.24605417251586914
time: 2.248223304748535
[1, 23280] loss_train: 0.008942, loss_test: 0.005519
time: 0.2639648914337158
time: 2.2637665271759033
[1, 23281] loss_train: 0.006130, loss_test: 0.005515
time: 0.24605727195739746
time: 2.2430167198181152
[1, 23282] loss_train: 0.004615, loss_test: 0.005514
time: 0.2470550537109375
time: 2.2855148315429688
[1, 23283] loss_train: 0.004981, loss_test: 0.005515
time: 0.2530550956726074
time: 2.2840168476104736
[1, 23284] loss_train: 0.007396, loss_test: 0.005516
time: 0.25005602836608887
time: 2.312993288040161
[1, 23285] loss_train: 0.004257, loss_test: 0.005516
time: 0.24205565452575684
time: 2.2590548992156982
[1, 23286] loss_train: 0.003815, loss_test: 0.005516
time: 0.24399685859680176
time: 2.2577786445617676
[1, 23287] loss_train: 0.005689, loss_test: 0.005517
time: 0.24901819229125977
time: 2.277514934539795
[1, 23288] loss_train: 0.012442, loss_test: 0.005518
time: 0.24205398559570312
time: 2.271507978439331
[1, 23289] loss_train: 0.002934, loss_test: 0.005519
time: 0.2470552921295166
time: 2.254020929336548
[1, 23290] loss_train: 0.003050, loss_test: 0.005519
time: 0.2560567855834961
time: 2.2840168476104736
[1, 23291] loss_train: 0.007430, loss_test: 0.005519
time: 0.24805569648742676
time: 2.2658743858337402
[1, 23292] loss_train: 0.003103, loss_test: 0.005520
time: 0.24405384063720703
time: 2.2465028762817383
[1, 23293] loss_train: 0.005008, loss_test: 0.005522
time: 0.24405479431152344
time: 2.2777912616729736
[1, 23294] loss_train: 0.009705, loss_test: 0.005518
time: 0.2430565357208252
time: 2.2865264415740967
[1, 23295] loss_train: 0.006782, loss_test: 0.005516
time: 0.25505685806274414
time: 2.2675180435180664
[1, 23296] loss_train: 0.010074, loss_test: 0.005516
time: 0.24105310440063477
time: 2.276510000228882
[1, 23297] loss_train: 0.006350, loss_test: 0.005516
time: 0.2490546703338623
time: 2.239543914794922
[1, 23298] loss_train: 0.002517, loss_test: 0.005516
time: 0.24805736541748047
time: 2.2845122814178467
[1, 23299] loss_train: 0.000549, loss_test: 0.005518
time: 0.2645606994628906
time: 2.2474365234375
[1, 23300] loss_train: 0.002631, loss_test: 0.005521
time: 0.2630586624145508
time: 2.2305409908294678
[1, 23301] loss_train: 0.003337, loss_test: 0.005525
time: 0.2560615539550781
time: 2.249227285385132
[1, 23302] loss_train: 0.003501, loss_test: 0.005530
time: 0.24405312538146973
time: 2.2412757873535156
[1, 23303] loss_train: 0.009744, loss_test: 0.005535
time: 0.24905705451965332
time: 2.2345080375671387
[1, 23304] loss_train: 0.005414, loss_test: 0.005539
time: 0.24205255508422852
time: 2.24751353263855
[1, 23305] loss_train: 0.009124, loss_test: 0.005539
time: 0.25305628776550293
time: 2.2590079307556152
[1, 23306] loss_train: 0.011535, loss_test: 0.005548
time: 0.24405431747436523
time: 2.2635083198547363
[1, 23307] loss_train: 0.006596, loss_test: 0.005550
time: 0.24905848503112793
time: 2.262507677078247
[1, 23308] loss_train: 0.005955, loss_test: 0.005550
time: 0.24405479431152344
time: 2.2610247135162354
[1, 23309] loss_train: 0.008335, loss_test: 0.005547
time: 0.25305628776550293
time: 2.260969638824463
[1, 23310] loss_train: 0.004437, loss_test: 0.005545
time: 0.2630584239959717
time: 2.285386800765991
[1, 23311] loss_train: 0.003995, loss_test: 0.005542
time: 0.24090123176574707
time: 2.2723615169525146
[1, 23312] loss_train: 0.006041, loss_test: 0.005540
time: 0.24305462837219238
time: 2.243518114089966
[1, 23313] loss_train: 0.008745, loss_test: 0.005535
time: 0.24305462837219238
time: 2.2830264568328857
[1, 23314] loss_train: 0.010186, loss_test: 0.005529
time: 0.254056453704834
time: 2.2586112022399902
[1, 23315] loss_train: 0.003178, loss_test: 0.005527
time: 0.24805450439453125
time: 2.261043071746826
[1, 23316] loss_train: 0.001474, loss_test: 0.005526
time: 0.24856138229370117
time: 2.2575290203094482
[1, 23317] loss_train: 0.000756, loss_test: 0.005525
time: 0.24305462837219238
time: 2.2845332622528076
[1, 23318] loss_train: 0.003491, loss_test: 0.005524
time: 0.2470545768737793
time: 2.2940196990966797
[1, 23319] loss_train: 0.005314, loss_test: 0.005523
time: 0.2505631446838379
time: 2.2805097103118896
[1, 23320] loss_train: 0.008667, loss_test: 0.005523
time: 0.27156901359558105
time: 2.305516481399536
[1, 23321] loss_train: 0.005122, loss_test: 0.005526
time: 0.2560579776763916
time: 2.2875113487243652
[1, 23322] loss_train: 0.002733, loss_test: 0.005528
time: 0.24405407905578613
time: 2.2995147705078125
[1, 23323] loss_train: 0.012050, loss_test: 0.005526
time: 0.25255870819091797
time: 2.2792470455169678
[1, 23324] loss_train: 0.006187, loss_test: 0.005523
time: 0.2780618667602539
time: 2.2864255905151367
[1, 23325] loss_train: 0.015087, loss_test: 0.005520
time: 0.24205422401428223
time: 2.275350332260132
[1, 23326] loss_train: 0.001163, loss_test: 0.005521
time: 0.2560610771179199
time: 2.2730133533477783
[1, 23327] loss_train: 0.012198, loss_test: 0.005521
time: 0.24205350875854492
time: 2.234501838684082
[1, 23328] loss_train: 0.004000, loss_test: 0.005522
time: 0.25505709648132324
time: 2.2705116271972656
[1, 23329] loss_train: 0.005246, loss_test: 0.005524
time: 0.2490549087524414
time: 2.3075270652770996
[1, 23330] loss_train: 0.005346, loss_test: 0.005523
time: 0.2600574493408203
time: 2.3353114128112793
[1, 23331] loss_train: 0.001941, loss_test: 0.005522
time: 0.25856447219848633
time: 2.262441396713257
[1, 23332] loss_train: 0.002207, loss_test: 0.005524
time: 0.24405336380004883
time: 2.2618966102600098
[1, 23333] loss_train: 0.010217, loss_test: 0.005525
time: 0.24605774879455566
time: 2.2670159339904785
[1, 23334] loss_train: 0.002329, loss_test: 0.005528
time: 0.2540559768676758
time: 2.267510414123535
[1, 23335] loss_train: 0.003245, loss_test: 0.005535
time: 0.2470541000366211
time: 2.248502731323242
[1, 23336] loss_train: 0.003885, loss_test: 0.005544
time: 0.3010900020599365
time: 2.253504514694214
[1, 23337] loss_train: 0.013001, loss_test: 0.005545
time: 0.24805498123168945
time: 2.2790205478668213
[1, 23338] loss_train: 0.010247, loss_test: 0.005544
time: 0.24405407905578613
time: 2.268515110015869
[1, 23339] loss_train: 0.008495, loss_test: 0.005542
time: 0.24265813827514648
time: 2.2291831970214844
[1, 23340] loss_train: 0.003702, loss_test: 0.005539
time: 0.2619616985321045
time: 2.284820318222046
[1, 23341] loss_train: 0.001148, loss_test: 0.005534
time: 0.24105310440063477
time: 2.2766025066375732
[1, 23342] loss_train: 0.007889, loss_test: 0.005533
time: 0.2470550537109375
time: 2.2885046005249023
[1, 23343] loss_train: 0.001699, loss_test: 0.005533
time: 0.24805545806884766
time: 2.254007577896118
[1, 23344] loss_train: 0.005747, loss_test: 0.005534
time: 0.2450544834136963
time: 2.275507926940918
[1, 23345] loss_train: 0.003992, loss_test: 0.005533
time: 0.2650613784790039
time: 2.2616937160491943
[1, 23346] loss_train: 0.007816, loss_test: 0.005530
time: 0.24406027793884277
time: 2.254795789718628
[1, 23347] loss_train: 0.010199, loss_test: 0.005523
time: 0.25707030296325684
time: 2.279914617538452
[1, 23348] loss_train: 0.012335, loss_test: 0.005514
time: 0.2620577812194824
time: 2.3045148849487305
[1, 23349] loss_train: 0.013788, loss_test: 0.005511
time: 0.26606154441833496
time: 2.293426275253296
[1, 23350] loss_train: 0.005073, loss_test: 0.005512
time: 0.2810628414154053
time: 2.282521963119507
[1, 23351] loss_train: 0.003515, loss_test: 0.005516
time: 0.24305415153503418
time: 2.2805094718933105
[1, 23352] loss_train: 0.009145, loss_test: 0.005523
time: 0.24605584144592285
time: 2.296743154525757
[1, 23353] loss_train: 0.002387, loss_test: 0.005525
time: 0.2430562973022461
time: 2.3417797088623047
[1, 23354] loss_train: 0.008761, loss_test: 0.005527
time: 0.24105405807495117
time: 2.2515132427215576
[1, 23355] loss_train: 0.013063, loss_test: 0.005529
time: 0.24305462837219238
time: 2.2367258071899414
[1, 23356] loss_train: 0.003383, loss_test: 0.005530
time: 0.24405360221862793
time: 2.2930989265441895
[1, 23357] loss_train: 0.009584, loss_test: 0.005526
time: 0.2560560703277588
time: 2.303237199783325
[1, 23358] loss_train: 0.002241, loss_test: 0.005518
time: 0.24999642372131348
time: 2.278247117996216
[1, 23359] loss_train: 0.006568, loss_test: 0.005511
time: 0.26806139945983887
time: 2.2505033016204834
[1, 23360] loss_train: 0.015219, loss_test: 0.005507
time: 0.2630581855773926
time: 2.3105199337005615
[1, 23361] loss_train: 0.005394, loss_test: 0.005504
time: 0.25505661964416504
time: 2.2645063400268555
[1, 23362] loss_train: 0.002580, loss_test: 0.005505
time: 0.2450544834136963
time: 2.277508497238159
[1, 23363] loss_train: 0.009495, loss_test: 0.005507
time: 0.24155616760253906
time: 2.234031915664673
[1, 23364] loss_train: 0.013264, loss_test: 0.005509
time: 0.24805498123168945
time: 2.260505437850952
[1, 23365] loss_train: 0.007766, loss_test: 0.005510
time: 0.24405455589294434
time: 2.286705493927002
[1, 23366] loss_train: 0.007714, loss_test: 0.005511
time: 0.24605512619018555
time: 2.2541909217834473
[1, 23367] loss_train: 0.005479, loss_test: 0.005511
time: 0.24805450439453125
time: 2.2479162216186523
[1, 23368] loss_train: 0.001499, loss_test: 0.005514
time: 0.2520561218261719
time: 2.25850510597229
[1, 23369] loss_train: 0.006787, loss_test: 0.005515
time: 0.24905633926391602
time: 2.23293399810791
[1, 23370] loss_train: 0.003073, loss_test: 0.005516
time: 0.26405835151672363
time: 2.2405006885528564
[1, 23371] loss_train: 0.007391, loss_test: 0.005519
time: 0.24305391311645508
time: 2.205493450164795
[1, 23372] loss_train: 0.004311, loss_test: 0.005520
time: 0.25705671310424805
time: 2.290518045425415
[1, 23373] loss_train: 0.003413, loss_test: 0.005522
time: 0.24805378913879395
time: 2.3325259685516357
[1, 23374] loss_train: 0.005449, loss_test: 0.005524
time: 0.25705599784851074
time: 2.414755344390869
[1, 23375] loss_train: 0.010924, loss_test: 0.005517
time: 0.2480628490447998
time: 2.2861971855163574
[1, 23376] loss_train: 0.002891, loss_test: 0.005514
time: 0.25005507469177246
time: 2.2594056129455566
[1, 23377] loss_train: 0.002510, loss_test: 0.005511
time: 0.24556279182434082
time: 2.295823574066162
[1, 23378] loss_train: 0.004280, loss_test: 0.005508
time: 0.24505376815795898
time: 2.224001884460449
[1, 23379] loss_train: 0.004344, loss_test: 0.005504
time: 0.25005578994750977
time: 2.2395026683807373
[1, 23380] loss_train: 0.002755, loss_test: 0.005504
time: 0.25905728340148926
time: 2.2545058727264404
[1, 23381] loss_train: 0.011693, loss_test: 0.005509
time: 0.24605536460876465
time: 2.2470054626464844
[1, 23382] loss_train: 0.004936, loss_test: 0.005516
time: 0.241926908493042
time: 2.2680184841156006
[1, 23383] loss_train: 0.006633, loss_test: 0.005523
time: 0.25505709648132324
time: 2.2330641746520996
[1, 23384] loss_train: 0.003414, loss_test: 0.005530
time: 0.24365735054016113
time: 2.269272804260254
[1, 23385] loss_train: 0.004946, loss_test: 0.005531
time: 0.2470543384552002
time: 2.3257884979248047
[1, 23386] loss_train: 0.012173, loss_test: 0.005529
time: 0.25378894805908203
time: 2.2715160846710205
[1, 23387] loss_train: 0.008033, loss_test: 0.005527
time: 0.2720601558685303
time: 2.28108811378479
[1, 23388] loss_train: 0.006486, loss_test: 0.005526
time: 0.251220703125
time: 2.252506732940674
[1, 23389] loss_train: 0.006338, loss_test: 0.005527
time: 0.24605560302734375
time: 2.2284975051879883
[1, 23390] loss_train: 0.002963, loss_test: 0.005527
time: 0.2620575428009033
time: 2.260009527206421
[1, 23391] loss_train: 0.003941, loss_test: 0.005528
time: 0.25005578994750977
time: 2.2485060691833496
[1, 23392] loss_train: 0.016224, loss_test: 0.005517
time: 0.24505376815795898
time: 2.2625069618225098
[1, 23393] loss_train: 0.011618, loss_test: 0.005512
time: 0.2450542449951172
time: 2.2385005950927734
[1, 23394] loss_train: 0.008618, loss_test: 0.005510
time: 0.24455833435058594
time: 2.245790481567383
[1, 23395] loss_train: 0.009814, loss_test: 0.005509
time: 0.2520596981048584
time: 2.233886957168579
[1, 23396] loss_train: 0.007746, loss_test: 0.005510
time: 0.24805688858032227
time: 2.2465286254882812
[1, 23397] loss_train: 0.004091, loss_test: 0.005512
time: 0.2430577278137207
time: 2.232724189758301
[1, 23398] loss_train: 0.007105, loss_test: 0.005514
time: 0.24305391311645508
time: 2.2395153045654297
[1, 23399] loss_train: 0.011279, loss_test: 0.005513
time: 0.25505709648132324
time: 2.2215023040771484
[1, 23400] loss_train: 0.003209, loss_test: 0.005513
time: 0.2630581855773926
time: 2.2360453605651855
[1, 23401] loss_train: 0.009234, loss_test: 0.005512
time: 0.25005626678466797
time: 2.2134969234466553
[1, 23402] loss_train: 0.009633, loss_test: 0.005512
time: 0.24305462837219238
time: 2.208998680114746
[1, 23403] loss_train: 0.009028, loss_test: 0.005513
time: 0.2470550537109375
time: 2.2736592292785645
[1, 23404] loss_train: 0.009282, loss_test: 0.005513
time: 0.24605536460876465
time: 2.2526934146881104
[1, 23405] loss_train: 0.006116, loss_test: 0.005515
time: 0.24605441093444824
time: 2.235049247741699
[1, 23406] loss_train: 0.001961, loss_test: 0.005516
time: 0.24205541610717773
time: 2.249591827392578
[1, 23407] loss_train: 0.010420, loss_test: 0.005519
time: 0.2490556240081787
time: 2.243210792541504
[1, 23408] loss_train: 0.004886, loss_test: 0.005523
time: 0.24205446243286133
time: 2.2425007820129395
[1, 23409] loss_train: 0.005819, loss_test: 0.005525
time: 0.24205446243286133
time: 2.270012855529785
[1, 23410] loss_train: 0.010503, loss_test: 0.005525
time: 0.2600581645965576
time: 2.247612237930298
[1, 23411] loss_train: 0.004688, loss_test: 0.005522
time: 0.2510559558868408
time: 2.2302932739257812
[1, 23412] loss_train: 0.003939, loss_test: 0.005518
time: 0.24254393577575684
time: 2.233625888824463
[1, 23413] loss_train: 0.009780, loss_test: 0.005514
time: 0.24105310440063477
time: 2.247762441635132
[1, 23414] loss_train: 0.011185, loss_test: 0.005512
time: 0.24410009384155273
time: 2.339299201965332
[1, 23415] loss_train: 0.003667, loss_test: 0.005513
time: 0.2470552921295166
time: 2.406538248062134
[1, 23416] loss_train: 0.005618, loss_test: 0.005515
time: 0.3250725269317627
time: 2.5035595893859863
[1, 23417] loss_train: 0.005738, loss_test: 0.005519
time: 0.2600572109222412
time: 2.5055630207061768
[1, 23418] loss_train: 0.002826, loss_test: 0.005526
time: 0.24405479431152344
time: 2.387533664703369
[1, 23419] loss_train: 0.000858, loss_test: 0.005535
time: 0.3320732116699219
time: 2.278623342514038
[1, 23420] loss_train: 0.006674, loss_test: 0.005544
time: 0.25705671310424805
time: 2.37621808052063
[1, 23421] loss_train: 0.003364, loss_test: 0.005555
time: 0.24605488777160645
time: 2.342195987701416
[1, 23422] loss_train: 0.004382, loss_test: 0.005567
time: 0.30998945236206055
time: 2.2967889308929443
[1, 23423] loss_train: 0.007418, loss_test: 0.005567
time: 0.24405646324157715
time: 2.2345023155212402
[1, 23424] loss_train: 0.005987, loss_test: 0.005565
time: 0.24505352973937988
time: 2.2605140209198
[1, 23425] loss_train: 0.005747, loss_test: 0.005558
time: 0.24005341529846191
time: 2.3925342559814453
[1, 23426] loss_train: 0.013617, loss_test: 0.005547
time: 0.27205991744995117
time: 2.37054181098938
[1, 23427] loss_train: 0.014694, loss_test: 0.005535
time: 0.280062198638916
time: 2.335754871368408
[1, 23428] loss_train: 0.009931, loss_test: 0.005532
time: 0.2740616798400879
time: 2.251218557357788
[1, 23429] loss_train: 0.006836, loss_test: 0.005538
time: 0.2654297351837158
time: 2.3124136924743652
[1, 23430] loss_train: 0.003871, loss_test: 0.005550
time: 0.25705790519714355
time: 2.2440149784088135
[1, 23431] loss_train: 0.006123, loss_test: 0.005565
time: 0.2460644245147705
time: 2.253509283065796
[1, 23432] loss_train: 0.011518, loss_test: 0.005575
time: 0.24605536460876465
time: 2.236006021499634
[1, 23433] loss_train: 0.004937, loss_test: 0.005582
time: 0.2690601348876953
time: 2.2635080814361572
[1, 23434] loss_train: 0.004834, loss_test: 0.005579
time: 0.24605560302734375
time: 2.2365002632141113
[1, 23435] loss_train: 0.010409, loss_test: 0.005577
time: 0.24205398559570312
time: 2.23349928855896
[1, 23436] loss_train: 0.009857, loss_test: 0.005576
time: 0.24305343627929688
time: 2.269270658493042
[1, 23437] loss_train: 0.009485, loss_test: 0.005569
time: 0.25505638122558594
time: 2.2729475498199463
[1, 23438] loss_train: 0.009123, loss_test: 0.005565
time: 0.24805569648742676
time: 2.2625203132629395
[1, 23439] loss_train: 0.007873, loss_test: 0.005557
time: 0.24208498001098633
time: 2.235215425491333
[1, 23440] loss_train: 0.007739, loss_test: 0.005542
time: 0.2620577812194824
time: 2.266515016555786
[1, 23441] loss_train: 0.004111, loss_test: 0.005530
time: 0.25305628776550293
time: 2.254504680633545
[1, 23442] loss_train: 0.003258, loss_test: 0.005525
time: 0.24405336380004883
time: 2.2551028728485107
[1, 23443] loss_train: 0.015115, loss_test: 0.005523
time: 0.24405336380004883
time: 2.2875118255615234
[1, 23444] loss_train: 0.008371, loss_test: 0.005523
time: 0.24405407905578613
time: 2.275017261505127
[1, 23445] loss_train: 0.001170, loss_test: 0.005525
time: 0.27007412910461426
time: 2.3329408168792725
[1, 23446] loss_train: 0.003994, loss_test: 0.005533
time: 0.2481391429901123
time: 2.2776331901550293
[1, 23447] loss_train: 0.008592, loss_test: 0.005537
time: 0.2530696392059326
time: 2.257615327835083
[1, 23448] loss_train: 0.005146, loss_test: 0.005541
time: 0.2490549087524414
time: 2.240406036376953
[1, 23449] loss_train: 0.004795, loss_test: 0.005544
time: 0.25005578994750977
time: 2.249512195587158
[1, 23450] loss_train: 0.003240, loss_test: 0.005548
time: 0.25705766677856445
time: 2.259509801864624
[1, 23451] loss_train: 0.001896, loss_test: 0.005553
time: 0.24855995178222656
time: 2.2945165634155273
[1, 23452] loss_train: 0.006289, loss_test: 0.005557
time: 0.25505709648132324
time: 2.2625060081481934
[1, 23453] loss_train: 0.001082, loss_test: 0.005561
time: 0.25305652618408203
time: 2.30553936958313
[1, 23454] loss_train: 0.004055, loss_test: 0.005566
time: 0.26404500007629395
time: 2.483440399169922
[1, 23455] loss_train: 0.002696, loss_test: 0.005571
time: 0.29312992095947266
time: 2.5393686294555664
[1, 23456] loss_train: 0.013626, loss_test: 0.005560
time: 0.24534320831298828
time: 2.2071142196655273
[1, 23457] loss_train: 0.008432, loss_test: 0.005547
time: 0.24405455589294434
time: 2.2124946117401123
[1, 23458] loss_train: 0.005734, loss_test: 0.005538
time: 0.24306845664978027
time: 2.513453245162964
[1, 23459] loss_train: 0.003697, loss_test: 0.005533
time: 0.27706217765808105
time: 2.3515613079071045
[1, 23460] loss_train: 0.012672, loss_test: 0.005528
time: 0.2560577392578125
time: 2.311556816101074
[1, 23461] loss_train: 0.004362, loss_test: 0.005528
time: 0.2450547218322754
time: 2.222512722015381
[1, 23462] loss_train: 0.006056, loss_test: 0.005529
time: 0.3050673007965088
time: 2.252394914627075
[1, 23463] loss_train: 0.003360, loss_test: 0.005532
time: 0.2450551986694336
time: 2.2423508167266846
[1, 23464] loss_train: 0.008777, loss_test: 0.005531
time: 0.24305963516235352
time: 2.236499786376953
[1, 23465] loss_train: 0.004262, loss_test: 0.005530
time: 0.2450547218322754
time: 2.2625057697296143
[1, 23466] loss_train: 0.004772, loss_test: 0.005523
time: 0.2530553340911865
time: 2.2725110054016113
[1, 23467] loss_train: 0.003005, loss_test: 0.005519
time: 0.2475602626800537
time: 2.2495028972625732
[1, 23468] loss_train: 0.004564, loss_test: 0.005517
time: 0.24405670166015625
time: 2.260504961013794
[1, 23469] loss_train: 0.010127, loss_test: 0.005515
time: 0.24305486679077148
time: 2.255833148956299
[1, 23470] loss_train: 0.007772, loss_test: 0.005507
time: 0.2570769786834717
time: 2.2601733207702637
[1, 23471] loss_train: 0.003991, loss_test: 0.005505
time: 0.251600980758667
time: 2.246009588241577
[1, 23472] loss_train: 0.006181, loss_test: 0.005505
time: 0.24705743789672852
time: 2.2379252910614014
[1, 23473] loss_train: 0.007025, loss_test: 0.005514
time: 0.25005435943603516
time: 2.2835137844085693
[1, 23474] loss_train: 0.007091, loss_test: 0.005528
time: 0.24805498123168945
time: 2.2515032291412354
[1, 23475] loss_train: 0.002152, loss_test: 0.005532
time: 0.2520558834075928
time: 2.2525041103363037
[1, 23476] loss_train: 0.012596, loss_test: 0.005535
time: 0.24805474281311035
time: 2.288522481918335
[1, 23477] loss_train: 0.004416, loss_test: 0.005537
time: 0.2510550022125244
time: 2.27101469039917
[1, 23478] loss_train: 0.004441, loss_test: 0.005538
time: 0.24805521965026855
time: 2.2405121326446533
[1, 23479] loss_train: 0.008574, loss_test: 0.005541
time: 0.2510561943054199
time: 2.248502492904663
[1, 23480] loss_train: 0.002872, loss_test: 0.005536
time: 0.257737398147583
time: 2.2315711975097656
[1, 23481] loss_train: 0.003182, loss_test: 0.005534
time: 0.2490558624267578
time: 2.2398064136505127
[1, 23482] loss_train: 0.004312, loss_test: 0.005536
time: 0.24205613136291504
time: 2.2559995651245117
[1, 23483] loss_train: 0.000802, loss_test: 0.005543
time: 0.25305795669555664
time: 2.271915912628174
[1, 23484] loss_train: 0.010551, loss_test: 0.005549
time: 0.24496006965637207
time: 2.25209903717041
[1, 23485] loss_train: 0.014296, loss_test: 0.005548
time: 0.24506044387817383
time: 2.2309374809265137
[1, 23486] loss_train: 0.011395, loss_test: 0.005542
time: 0.24524545669555664
time: 2.356527090072632
[1, 23487] loss_train: 0.007384, loss_test: 0.005536
time: 0.2630589008331299
time: 2.381544828414917
[1, 23488] loss_train: 0.001823, loss_test: 0.005535
time: 0.2470557689666748
time: 2.3398220539093018
[1, 23489] loss_train: 0.001425, loss_test: 0.005535
time: 0.24305415153503418
time: 2.2378735542297363
[1, 23490] loss_train: 0.003228, loss_test: 0.005536
time: 0.26405930519104004
time: 2.2490150928497314
[1, 23491] loss_train: 0.006453, loss_test: 0.005532
time: 0.2540616989135742
time: 2.2910971641540527
[1, 23492] loss_train: 0.005244, loss_test: 0.005526
time: 0.2530632019042969
time: 2.2537193298339844
[1, 23493] loss_train: 0.010865, loss_test: 0.005520
time: 0.2560598850250244
time: 2.2905147075653076
[1, 23494] loss_train: 0.013521, loss_test: 0.005513
time: 0.25356078147888184
time: 2.2555079460144043
[1, 23495] loss_train: 0.006540, loss_test: 0.005509
time: 0.24505400657653809
time: 2.2799952030181885
[1, 23496] loss_train: 0.006047, loss_test: 0.005508
time: 0.25005483627319336
time: 2.259395122528076
[1, 23497] loss_train: 0.007282, loss_test: 0.005508
time: 0.27505970001220703
time: 2.257514238357544
[1, 23498] loss_train: 0.000743, loss_test: 0.005509
time: 0.2830634117126465
time: 2.304262161254883
[1, 23499] loss_train: 0.003752, loss_test: 0.005510
time: 0.25205516815185547
time: 2.501560688018799
[1, 23500] loss_train: 0.008366, loss_test: 0.005509
time: 0.29506635665893555
time: 2.41304612159729
[1, 23501] loss_train: 0.002157, loss_test: 0.005508
time: 0.24305319786071777
time: 2.250511646270752
[1, 23502] loss_train: 0.003943, loss_test: 0.005507
time: 0.24205422401428223
time: 2.2019970417022705
[1, 23503] loss_train: 0.001552, loss_test: 0.005505
time: 0.24405312538146973
time: 2.361527681350708
[1, 23504] loss_train: 0.003135, loss_test: 0.005504
time: 0.27306032180786133
time: 2.4188287258148193
[1, 23505] loss_train: 0.006613, loss_test: 0.005502
time: 0.24205446243286133
time: 2.2034921646118164
[1, 23506] loss_train: 0.006063, loss_test: 0.005501
time: 0.2545654773712158
time: 2.2231853008270264
[1, 23507] loss_train: 0.002848, loss_test: 0.005503
time: 0.24305438995361328
time: 2.4555604457855225
[1, 23508] loss_train: 0.008225, loss_test: 0.005505
time: 0.24805569648742676
time: 2.226134777069092
[1, 23509] loss_train: 0.006294, loss_test: 0.005507
time: 0.2470545768737793
time: 2.235501527786255
[1, 23510] loss_train: 0.006829, loss_test: 0.005511
time: 0.2740592956542969
time: 2.2385013103485107
[1, 23511] loss_train: 0.010495, loss_test: 0.005521
time: 0.2510688304901123
time: 2.230501413345337
[1, 23512] loss_train: 0.012578, loss_test: 0.005524
time: 0.2520568370819092
time: 2.2424747943878174
[1, 23513] loss_train: 0.008031, loss_test: 0.005528
time: 0.2470541000366211
time: 2.2335007190704346
[1, 23514] loss_train: 0.006717, loss_test: 0.005530
time: 0.2490551471710205
time: 2.2435014247894287
[1, 23515] loss_train: 0.003326, loss_test: 0.005533
time: 0.24405431747436523
time: 2.2328670024871826
[1, 23516] loss_train: 0.000797, loss_test: 0.005534
time: 0.2490546703338623
time: 2.257883071899414
[1, 23517] loss_train: 0.008009, loss_test: 0.005538
time: 0.2450549602508545
time: 2.258504867553711
[1, 23518] loss_train: 0.002949, loss_test: 0.005541
time: 0.24605464935302734
time: 2.238330602645874
[1, 23519] loss_train: 0.007778, loss_test: 0.005543
time: 0.24305343627929688
time: 2.2510104179382324
[1, 23520] loss_train: 0.009885, loss_test: 0.005544
time: 0.265059232711792
time: 2.3285200595855713
[1, 23521] loss_train: 0.010485, loss_test: 0.005544
time: 0.33307409286499023
time: 2.501563310623169
[1, 23522] loss_train: 0.008305, loss_test: 0.005548
time: 0.29506587982177734
time: 2.3155179023742676
[1, 23523] loss_train: 0.004458, loss_test: 0.005558
time: 0.2540566921234131
time: 2.393547773361206
[1, 23524] loss_train: 0.007663, loss_test: 0.005567
time: 0.3070685863494873
time: 2.2635064125061035
[1, 23525] loss_train: 0.004116, loss_test: 0.005568
time: 0.24405384063720703
time: 2.3560822010040283
[1, 23526] loss_train: 0.009739, loss_test: 0.005571
time: 0.29760289192199707
time: 2.253011465072632
[1, 23527] loss_train: 0.006721, loss_test: 0.005576
time: 0.24393248558044434
time: 2.2985141277313232
[1, 23528] loss_train: 0.009698, loss_test: 0.005583
time: 0.2490549087524414
time: 2.372183084487915
[1, 23529] loss_train: 0.019804, loss_test: 0.005605
time: 0.24491310119628906
time: 2.222623586654663
[1, 23530] loss_train: 0.004271, loss_test: 0.005613
time: 0.2600588798522949
time: 2.3453426361083984
[1, 23531] loss_train: 0.004493, loss_test: 0.005603
time: 0.2435617446899414
time: 2.3845319747924805
[1, 23532] loss_train: 0.010085, loss_test: 0.005582
time: 0.35707974433898926
time: 2.4365456104278564
[1, 23533] loss_train: 0.001081, loss_test: 0.005542
time: 0.24305415153503418
time: 2.231499195098877
[1, 23534] loss_train: 0.006830, loss_test: 0.005519
time: 0.3310737609863281
time: 2.248880624771118
[1, 23535] loss_train: 0.001032, loss_test: 0.005512
time: 0.2470545768737793
time: 2.3815181255340576
[1, 23536] loss_train: 0.004072, loss_test: 0.005524
time: 0.25105810165405273
time: 2.333895206451416
[1, 23537] loss_train: 0.002811, loss_test: 0.005544
time: 0.2505660057067871
time: 2.235384225845337
[1, 23538] loss_train: 0.003162, loss_test: 0.005572
time: 0.24313139915466309
time: 2.273569107055664
[1, 23539] loss_train: 0.006904, loss_test: 0.005594
time: 0.2525339126586914
time: 2.252182960510254
[1, 23540] loss_train: 0.008190, loss_test: 0.005601
time: 0.2680644989013672
time: 2.2755112648010254
[1, 23541] loss_train: 0.009058, loss_test: 0.005588
time: 0.24405455589294434
time: 2.245450973510742
[1, 23542] loss_train: 0.009860, loss_test: 0.005574
time: 0.2450551986694336
time: 2.263009548187256
[1, 23543] loss_train: 0.005245, loss_test: 0.005560
time: 0.2450549602508545
time: 2.2680699825286865
[1, 23544] loss_train: 0.004790, loss_test: 0.005548
time: 0.29306459426879883
time: 2.2691590785980225
[1, 23545] loss_train: 0.000869, loss_test: 0.005540
time: 0.24305438995361328
time: 2.22898268699646
[1, 23546] loss_train: 0.001478, loss_test: 0.005537
time: 0.24505376815795898
time: 2.4225637912750244
[1, 23547] loss_train: 0.001838, loss_test: 0.005536
time: 0.24606800079345703
time: 2.2483620643615723
[1, 23548] loss_train: 0.001644, loss_test: 0.005539
time: 0.24805498123168945
time: 2.2485032081604004
[1, 23549] loss_train: 0.006694, loss_test: 0.005542
time: 0.24205398559570312
time: 2.3605287075042725
[1, 23550] loss_train: 0.005591, loss_test: 0.005543
time: 0.25705671310424805
time: 2.5335891246795654
[1, 23551] loss_train: 0.016415, loss_test: 0.005542
time: 0.24705719947814941
time: 2.254018545150757
[1, 23552] loss_train: 0.005004, loss_test: 0.005542
time: 0.24405670166015625
time: 2.220500946044922
[1, 23553] loss_train: 0.005051, loss_test: 0.005542
time: 0.24574613571166992
time: 2.428712844848633
[1, 23554] loss_train: 0.007574, loss_test: 0.005542
time: 0.2470550537109375
time: 2.2436301708221436
[1, 23555] loss_train: 0.006166, loss_test: 0.005542
time: 0.24605464935302734
time: 2.323793411254883
[1, 23556] loss_train: 0.005456, loss_test: 0.005542
time: 0.2670609951019287
time: 2.329521656036377
[1, 23557] loss_train: 0.006328, loss_test: 0.005543
time: 0.32607173919677734
time: 2.5485708713531494
[1, 23558] loss_train: 0.007740, loss_test: 0.005547
time: 0.3810844421386719
time: 2.6405985355377197
[1, 23559] loss_train: 0.007028, loss_test: 0.005548
time: 0.2780616283416748
time: 2.485555410385132
[1, 23560] loss_train: 0.005272, loss_test: 0.005551
time: 0.2800636291503906
time: 2.67559814453125
[1, 23561] loss_train: 0.008547, loss_test: 0.005552
time: 0.26105809211730957
time: 2.668599843978882
[1, 23562] loss_train: 0.000782, loss_test: 0.005554
time: 0.2415611743927002
time: 2.412052631378174
[1, 23563] loss_train: 0.006397, loss_test: 0.005557
time: 0.24405479431152344
time: 2.3479092121124268
[1, 23564] loss_train: 0.002452, loss_test: 0.005562
time: 0.24255943298339844
time: 2.234125852584839
[1, 23565] loss_train: 0.001704, loss_test: 0.005568
time: 0.24405455589294434
time: 2.271510362625122
[1, 23566] loss_train: 0.002221, loss_test: 0.005576
time: 0.2450542449951172
time: 2.2425034046173096
[1, 23567] loss_train: 0.003937, loss_test: 0.005585
time: 0.2450542449951172
time: 2.45855712890625
[1, 23568] loss_train: 0.007536, loss_test: 0.005588
time: 0.24605536460876465
time: 2.319023370742798
[1, 23569] loss_train: 0.004585, loss_test: 0.005593
time: 0.24205446243286133
time: 2.517561912536621
[1, 23570] loss_train: 0.003822, loss_test: 0.005598
time: 0.26456189155578613
time: 2.3305325508117676
[1, 23571] loss_train: 0.007363, loss_test: 0.005595
time: 0.24456024169921875
time: 2.332794666290283
[1, 23572] loss_train: 0.007102, loss_test: 0.005585
time: 0.24899506568908691
time: 2.2681713104248047
[1, 23573] loss_train: 0.004853, loss_test: 0.005576
time: 0.2470545768737793
time: 2.230499267578125
[1, 23574] loss_train: 0.009604, loss_test: 0.005561
time: 0.2490558624267578
time: 2.2775087356567383
[1, 23575] loss_train: 0.004131, loss_test: 0.005554
time: 0.2450544834136963
time: 2.5644352436065674
[1, 23576] loss_train: 0.009817, loss_test: 0.005553
time: 0.2870633602142334
time: 2.3100216388702393
[1, 23577] loss_train: 0.005868, loss_test: 0.005556
time: 0.24305486679077148
time: 2.24550199508667
[1, 23578] loss_train: 0.006176, loss_test: 0.005562
time: 0.24405455589294434
time: 2.252504825592041
[1, 23579] loss_train: 0.003363, loss_test: 0.005572
time: 0.24505352973937988
time: 2.262505054473877
[1, 23580] loss_train: 0.001116, loss_test: 0.005582
time: 0.2610595226287842
time: 2.2495174407958984
[1, 23581] loss_train: 0.008756, loss_test: 0.005589
time: 0.24605584144592285
time: 2.226430654525757
[1, 23582] loss_train: 0.002478, loss_test: 0.005594
time: 0.24480295181274414
time: 2.2405076026916504
[1, 23583] loss_train: 0.002055, loss_test: 0.005590
time: 0.2430555820465088
time: 2.2567360401153564
[1, 23584] loss_train: 0.002653, loss_test: 0.005583
time: 0.24619746208190918
time: 2.2582526206970215
[1, 23585] loss_train: 0.007533, loss_test: 0.005576
time: 0.25005578994750977
time: 2.2318286895751953
[1, 23586] loss_train: 0.010245, loss_test: 0.005572
time: 0.24305319786071777
time: 2.223510980606079
[1, 23587] loss_train: 0.005234, loss_test: 0.005567
time: 0.24405336380004883
time: 2.272508144378662
[1, 23588] loss_train: 0.000643, loss_test: 0.005560
time: 0.24405431747436523
time: 2.2488884925842285
[1, 23589] loss_train: 0.009789, loss_test: 0.005554
time: 0.25305700302124023
time: 2.253908395767212
[1, 23590] loss_train: 0.005675, loss_test: 0.005548
time: 0.25905871391296387
time: 2.244501829147339
[1, 23591] loss_train: 0.019698, loss_test: 0.005550
time: 0.381084680557251
time: 2.3016438484191895
[1, 23592] loss_train: 0.002967, loss_test: 0.005550
time: 0.27506589889526367
time: 2.248008966445923
[1, 23593] loss_train: 0.005839, loss_test: 0.005545
time: 0.24605417251586914
time: 2.219496726989746
[1, 23594] loss_train: 0.003165, loss_test: 0.005542
time: 0.2520558834075928
time: 2.504560947418213
[1, 23595] loss_train: 0.003928, loss_test: 0.005538
time: 0.24305391311645508
time: 2.3395230770111084
[1, 23596] loss_train: 0.007249, loss_test: 0.005534
time: 0.2470550537109375
time: 2.345031499862671
[1, 23597] loss_train: 0.004666, loss_test: 0.005533
time: 0.3090672492980957
time: 2.4729630947113037
[1, 23598] loss_train: 0.002994, loss_test: 0.005536
time: 0.24756264686584473
time: 2.3230550289154053
[1, 23599] loss_train: 0.003957, loss_test: 0.005541
time: 0.24805903434753418
time: 2.286088466644287
[1, 23600] loss_train: 0.004990, loss_test: 0.005547
time: 0.2620584964752197
time: 2.282512903213501
[1, 23601] loss_train: 0.006837, loss_test: 0.005552
time: 0.2450571060180664
time: 2.271512031555176
[1, 23602] loss_train: 0.002888, loss_test: 0.005558
time: 0.2490549087524414
time: 2.2895126342773438
[1, 23603] loss_train: 0.005463, loss_test: 0.005563
time: 0.2540559768676758
time: 2.293513536453247
[1, 23604] loss_train: 0.009973, loss_test: 0.005566
time: 0.2510554790496826
time: 2.2395012378692627
[1, 23605] loss_train: 0.010686, loss_test: 0.005566
time: 0.24805855751037598
time: 2.2645087242126465
[1, 23606] loss_train: 0.006187, loss_test: 0.005561
time: 0.25505733489990234
time: 2.2985999584198
[1, 23607] loss_train: 0.001096, loss_test: 0.005561
time: 0.24405479431152344
time: 2.4751505851745605
[1, 23608] loss_train: 0.005692, loss_test: 0.005559
time: 0.33507728576660156
time: 2.415273904800415
[1, 23609] loss_train: 0.004536, loss_test: 0.005557
time: 0.33307433128356934
time: 2.3005168437957764
[1, 23610] loss_train: 0.007712, loss_test: 0.005554
time: 0.2800624370574951
time: 2.242793560028076
[1, 23611] loss_train: 0.008990, loss_test: 0.005548
time: 0.24305438995361328
time: 2.2560131549835205
[1, 23612] loss_train: 0.004762, loss_test: 0.005542
time: 0.24605488777160645
time: 2.294067144393921
[1, 23613] loss_train: 0.001266, loss_test: 0.005537
time: 0.2740614414215088
time: 2.3034720420837402
[1, 23614] loss_train: 0.007578, loss_test: 0.005533
time: 0.25305676460266113
time: 2.2775092124938965
[1, 23615] loss_train: 0.002740, loss_test: 0.005532
time: 0.2470552921295166
time: 2.381532907485962
[1, 23616] loss_train: 0.005482, loss_test: 0.005531
time: 0.2890634536743164
time: 2.404538869857788
[1, 23617] loss_train: 0.004542, loss_test: 0.005529
time: 0.2800607681274414
time: 2.304659843444824
[1, 23618] loss_train: 0.007637, loss_test: 0.005527
time: 0.24205327033996582
time: 2.2615065574645996
[1, 23619] loss_train: 0.003341, loss_test: 0.005525
time: 0.2540562152862549
time: 2.248032808303833
[1, 23620] loss_train: 0.003553, loss_test: 0.005525
time: 0.2580583095550537
time: 2.2378122806549072
[1, 23621] loss_train: 0.014928, loss_test: 0.005527
time: 0.2490558624267578
time: 2.2540738582611084
[1, 23622] loss_train: 0.010071, loss_test: 0.005530
time: 0.2442777156829834
time: 2.286052703857422
[1, 23623] loss_train: 0.010312, loss_test: 0.005531
time: 0.2490553855895996
time: 2.2421157360076904
[1, 23624] loss_train: 0.004920, loss_test: 0.005533
time: 0.2430565357208252
time: 2.3552350997924805
[1, 23625] loss_train: 0.002990, loss_test: 0.005533
time: 0.24805474281311035
time: 2.2385010719299316
[1, 23626] loss_train: 0.002751, loss_test: 0.005533
time: 0.24605584144592285
time: 2.2380032539367676
[1, 23627] loss_train: 0.009897, loss_test: 0.005534
time: 0.2450556755065918
time: 2.2565059661865234
[1, 23628] loss_train: 0.004188, loss_test: 0.005534
time: 0.2450549602508545
time: 2.2194976806640625
[1, 23629] loss_train: 0.006496, loss_test: 0.005530
time: 0.2450549602508545
time: 2.2515103816986084
[1, 23630] loss_train: 0.006123, loss_test: 0.005527
time: 0.2560570240020752
time: 2.2478647232055664
[1, 23631] loss_train: 0.006211, loss_test: 0.005525
time: 0.24701642990112305
time: 2.3141703605651855
[1, 23632] loss_train: 0.003905, loss_test: 0.005525
time: 0.2510554790496826
time: 2.272526979446411
[1, 23633] loss_train: 0.003911, loss_test: 0.005525
time: 0.24505615234375
time: 2.279158592224121
[1, 23634] loss_train: 0.008871, loss_test: 0.005529
time: 0.2470548152923584
time: 2.2740120887756348
[1, 23635] loss_train: 0.002614, loss_test: 0.005533
time: 0.2490556240081787
time: 2.2920312881469727
[1, 23636] loss_train: 0.001950, loss_test: 0.005538
time: 0.247053861618042
time: 2.486292600631714
[1, 23637] loss_train: 0.005486, loss_test: 0.005544
time: 0.24238848686218262
time: 2.256505250930786
[1, 23638] loss_train: 0.006516, loss_test: 0.005549
time: 0.2630584239959717
time: 2.3968663215637207
[1, 23639] loss_train: 0.005084, loss_test: 0.005553
time: 0.24805331230163574
time: 2.250511407852173
[1, 23640] loss_train: 0.002728, loss_test: 0.005558
time: 0.2560563087463379
time: 2.4515485763549805
[1, 23641] loss_train: 0.006519, loss_test: 0.005563
time: 0.269059419631958
time: 2.3824455738067627
[1, 23642] loss_train: 0.002614, loss_test: 0.005567
time: 0.30706787109375
time: 2.2800142765045166
[1, 23643] loss_train: 0.007446, loss_test: 0.005565
time: 0.24905729293823242
time: 2.282841682434082
[1, 23644] loss_train: 0.013459, loss_test: 0.005561
time: 0.27006053924560547
time: 2.23897123336792
[1, 23645] loss_train: 0.011550, loss_test: 0.005559
time: 0.24405360221862793
time: 2.3108577728271484
[1, 23646] loss_train: 0.005877, loss_test: 0.005560
time: 0.2450551986694336
time: 2.248504400253296
[1, 23647] loss_train: 0.002970, loss_test: 0.005562
time: 0.25005507469177246
time: 2.2583346366882324
[1, 23648] loss_train: 0.020087, loss_test: 0.005560
time: 0.24205446243286133
time: 2.2475035190582275
[1, 23649] loss_train: 0.007539, loss_test: 0.005560
time: 0.24305367469787598
time: 2.2710118293762207
[1, 23650] loss_train: 0.003089, loss_test: 0.005557
time: 0.2600574493408203
time: 2.2655069828033447
[1, 23651] loss_train: 0.007974, loss_test: 0.005553
time: 0.2490558624267578
time: 2.310516595840454
[1, 23652] loss_train: 0.003273, loss_test: 0.005550
time: 0.24805521965026855
time: 2.295513868331909
[1, 23653] loss_train: 0.005033, loss_test: 0.005546
time: 0.24205374717712402
time: 2.2495052814483643
[1, 23654] loss_train: 0.007658, loss_test: 0.005543
time: 0.24805617332458496
time: 2.3659119606018066
[1, 23655] loss_train: 0.005678, loss_test: 0.005539
time: 0.24505400657653809
time: 2.262455701828003
[1, 23656] loss_train: 0.009963, loss_test: 0.005535
time: 0.2530550956726074
time: 2.2639811038970947
[1, 23657] loss_train: 0.004147, loss_test: 0.005534
time: 0.24105596542358398
time: 2.4315807819366455
[1, 23658] loss_train: 0.005264, loss_test: 0.005532
time: 0.29006505012512207
time: 2.4375457763671875
[1, 23659] loss_train: 0.013704, loss_test: 0.005532
time: 0.24405288696289062
time: 2.2895355224609375
[1, 23660] loss_train: 0.001604, loss_test: 0.005533
time: 0.2620584964752197
time: 2.2805233001708984
[1, 23661] loss_train: 0.005148, loss_test: 0.005531
time: 0.24405479431152344
time: 2.3219478130340576
[1, 23662] loss_train: 0.005532, loss_test: 0.005532
time: 0.33707547187805176
time: 2.657581090927124
[1, 23663] loss_train: 0.004456, loss_test: 0.005537
time: 0.27005982398986816
time: 2.431548595428467
[1, 23664] loss_train: 0.004195, loss_test: 0.005547
time: 0.3380744457244873
time: 2.494884729385376
[1, 23665] loss_train: 0.005341, loss_test: 0.005560
time: 0.3070807456970215
time: 2.6305768489837646
[1, 23666] loss_train: 0.006828, loss_test: 0.005574
time: 0.2530555725097656
time: 2.2845120429992676
[1, 23667] loss_train: 0.004489, loss_test: 0.005588
time: 0.24805521965026855
time: 2.2547597885131836
[1, 23668] loss_train: 0.004493, loss_test: 0.005599
time: 0.24305462837219238
time: 2.231930732727051
[1, 23669] loss_train: 0.001810, loss_test: 0.005611
time: 0.24305343627929688
time: 2.224111557006836
[1, 23670] loss_train: 0.009741, loss_test: 0.005611
time: 0.2610607147216797
time: 2.2275116443634033
[1, 23671] loss_train: 0.003081, loss_test: 0.005611
time: 0.24606013298034668
time: 2.257106304168701
[1, 23672] loss_train: 0.007751, loss_test: 0.005604
time: 0.24656009674072266
time: 2.290512800216675
[1, 23673] loss_train: 0.000577, loss_test: 0.005601
time: 0.2940635681152344
time: 2.3520302772521973
[1, 23674] loss_train: 0.004024, loss_test: 0.005592
time: 0.3780848979949951
time: 2.2945168018341064
[1, 23675] loss_train: 0.002746, loss_test: 0.005584
time: 0.2510552406311035
time: 2.2695086002349854
[1, 23676] loss_train: 0.006692, loss_test: 0.005570
time: 0.24305391311645508
time: 2.2504968643188477
[1, 23677] loss_train: 0.010862, loss_test: 0.005547
time: 0.2470541000366211
time: 2.2673864364624023
[1, 23678] loss_train: 0.004722, loss_test: 0.005534
time: 0.3139336109161377
time: 2.288195848464966
[1, 23679] loss_train: 0.003097, loss_test: 0.005529
time: 0.24705767631530762
time: 2.5185816287994385
[1, 23680] loss_train: 0.004169, loss_test: 0.005529
time: 0.2820625305175781
time: 2.3750381469726562
[1, 23681] loss_train: 0.010229, loss_test: 0.005532
time: 0.24305391311645508
time: 2.2675085067749023
[1, 23682] loss_train: 0.011487, loss_test: 0.005541
time: 0.2525794506072998
time: 2.232499361038208
[1, 23683] loss_train: 0.004875, loss_test: 0.005547
time: 0.24305415153503418
time: 2.2509286403656006
[1, 23684] loss_train: 0.002911, loss_test: 0.005551
time: 0.2453773021697998
time: 2.3649256229400635
[1, 23685] loss_train: 0.008648, loss_test: 0.005551
time: 0.24305343627929688
time: 2.2469639778137207
[1, 23686] loss_train: 0.001138, loss_test: 0.005541
time: 0.24805545806884766
time: 2.3716843128204346
[1, 23687] loss_train: 0.002682, loss_test: 0.005530
time: 0.28106117248535156
time: 2.5675747394561768
[1, 23688] loss_train: 0.006412, loss_test: 0.005516
time: 0.2510557174682617
time: 2.5180723667144775
[1, 23689] loss_train: 0.004491, loss_test: 0.005509
time: 0.2960634231567383
time: 2.3815348148345947
[1, 23690] loss_train: 0.008645, loss_test: 0.005507
time: 0.3270726203918457
time: 2.4675521850585938
[1, 23691] loss_train: 0.007917, loss_test: 0.005512
time: 0.3180704116821289
time: 2.3805322647094727
[1, 23692] loss_train: 0.012564, loss_test: 0.005513
time: 0.2490549087524414
time: 2.2810258865356445
[1, 23693] loss_train: 0.010267, loss_test: 0.005512
time: 0.24720287322998047
time: 2.240576982498169
[1, 23694] loss_train: 0.004942, loss_test: 0.005511
time: 0.2450542449951172
time: 2.2735331058502197
[1, 23695] loss_train: 0.007205, loss_test: 0.005510
time: 0.2470543384552002
time: 2.245232343673706
[1, 23696] loss_train: 0.007814, loss_test: 0.005509
time: 0.25385284423828125
time: 2.247872829437256
[1, 23697] loss_train: 0.004075, loss_test: 0.005509
time: 0.2450551986694336
time: 2.299015998840332
[1, 23698] loss_train: 0.007091, loss_test: 0.005509
time: 0.24205350875854492
time: 2.3535265922546387
[1, 23699] loss_train: 0.004900, loss_test: 0.005510
time: 0.24405360221862793
time: 2.3133151531219482
[1, 23700] loss_train: 0.009007, loss_test: 0.005508
time: 0.2560570240020752
time: 2.3245275020599365
[1, 23701] loss_train: 0.014408, loss_test: 0.005504
time: 0.2580564022064209
time: 2.364391326904297
[1, 23702] loss_train: 0.002334, loss_test: 0.005503
time: 0.25756049156188965
time: 2.2911694049835205
[1, 23703] loss_train: 0.003127, loss_test: 0.005501
time: 0.24280858039855957
time: 2.3705313205718994
[1, 23704] loss_train: 0.004708, loss_test: 0.005500
time: 0.24405503273010254
time: 2.3602523803710938
[1, 23705] loss_train: 0.010272, loss_test: 0.005502
time: 0.32253098487854004
time: 2.4585490226745605
[1, 23706] loss_train: 0.004516, loss_test: 0.005504
time: 0.2670590877532959
time: 2.313525915145874
[1, 23707] loss_train: 0.005974, loss_test: 0.005505
time: 0.2470557689666748
time: 2.2465014457702637
[1, 23708] loss_train: 0.011376, loss_test: 0.005509
time: 0.24205350875854492
time: 2.2570111751556396
[1, 23709] loss_train: 0.002528, loss_test: 0.005512
time: 0.2560577392578125
time: 2.2505033016204834
[1, 23710] loss_train: 0.009625, loss_test: 0.005517
time: 0.25905704498291016
time: 2.42254900932312
[1, 23711] loss_train: 0.014869, loss_test: 0.005518
time: 0.24305415153503418
time: 2.3140647411346436
[1, 23712] loss_train: 0.007124, loss_test: 0.005519
time: 0.2695643901824951
time: 2.2632007598876953
[1, 23713] loss_train: 0.004859, loss_test: 0.005522
time: 0.25156354904174805
time: 2.253871202468872
[1, 23714] loss_train: 0.009875, loss_test: 0.005521
time: 0.250246524810791
time: 2.246501922607422
[1, 23715] loss_train: 0.006371, loss_test: 0.005516
time: 0.2450544834136963
time: 2.2460081577301025
[1, 23716] loss_train: 0.004237, loss_test: 0.005513
time: 0.24605417251586914
time: 2.2450177669525146
[1, 23717] loss_train: 0.010569, loss_test: 0.005510
time: 0.24605441093444824
time: 2.2365050315856934
[1, 23718] loss_train: 0.011474, loss_test: 0.005507
time: 0.24305415153503418
time: 2.220496654510498
[1, 23719] loss_train: 0.006699, loss_test: 0.005507
time: 0.24405789375305176
time: 2.2204983234405518
[1, 23720] loss_train: 0.001427, loss_test: 0.005507
time: 0.256056547164917
time: 2.217034339904785
[1, 23721] loss_train: 0.007548, loss_test: 0.005509
time: 0.24405455589294434
time: 2.249797821044922
[1, 23722] loss_train: 0.015006, loss_test: 0.005516
time: 0.24205756187438965
time: 2.250183343887329
[1, 23723] loss_train: 0.003264, loss_test: 0.005519
time: 0.24305438995361328
time: 2.240115165710449
[1, 23724] loss_train: 0.004577, loss_test: 0.005521
time: 0.24406123161315918
time: 2.27496075630188
[1, 23725] loss_train: 0.005615, loss_test: 0.005519
time: 0.27306103706359863
time: 2.296017646789551
[1, 23726] loss_train: 0.002090, loss_test: 0.005516
time: 0.2488250732421875
time: 2.256505250930786
[1, 23727] loss_train: 0.001836, loss_test: 0.005516
time: 0.25305628776550293
time: 2.229498863220215
[1, 23728] loss_train: 0.013891, loss_test: 0.005517
time: 0.2515592575073242
time: 2.25801157951355
[1, 23729] loss_train: 0.001071, loss_test: 0.005521
time: 0.24305462837219238
time: 2.250030279159546
[1, 23730] loss_train: 0.004065, loss_test: 0.005526
time: 0.2580580711364746
time: 2.244236707687378
[1, 23731] loss_train: 0.009051, loss_test: 0.005526
time: 0.2428605556488037
time: 2.2450854778289795
[1, 23732] loss_train: 0.005713, loss_test: 0.005529
time: 0.24605345726013184
time: 2.2488622665405273
[1, 23733] loss_train: 0.006633, loss_test: 0.005528
time: 0.24505996704101562
time: 2.235858678817749
[1, 23734] loss_train: 0.007609, loss_test: 0.005528
time: 0.24305343627929688
time: 2.231504201889038
[1, 23735] loss_train: 0.008941, loss_test: 0.005525
time: 0.24505329132080078
time: 2.218498945236206
[1, 23736] loss_train: 0.005319, loss_test: 0.005516
time: 0.24305319786071777
time: 2.2365012168884277
[1, 23737] loss_train: 0.007966, loss_test: 0.005509
time: 0.2510552406311035
time: 2.259012222290039
[1, 23738] loss_train: 0.009954, loss_test: 0.005502
time: 0.24506497383117676
time: 2.264042615890503
[1, 23739] loss_train: 0.006523, loss_test: 0.005503
time: 0.25005602836608887
time: 2.267226457595825
[1, 23740] loss_train: 0.010205, loss_test: 0.005503
time: 0.2580573558807373
time: 2.25239896774292
[1, 23741] loss_train: 0.004064, loss_test: 0.005506
time: 0.24705839157104492
time: 2.24731707572937
[1, 23742] loss_train: 0.002885, loss_test: 0.005510
time: 0.2435588836669922
time: 2.259505033493042
[1, 23743] loss_train: 0.002387, loss_test: 0.005514
time: 0.2470557689666748
time: 2.253511905670166
[1, 23744] loss_train: 0.013744, loss_test: 0.005515
time: 0.2500569820404053
time: 2.2615067958831787
[1, 23745] loss_train: 0.008474, loss_test: 0.005515
time: 0.2630577087402344
time: 2.2500102519989014
[1, 23746] loss_train: 0.007804, loss_test: 0.005515
time: 0.2470545768737793
time: 2.2466156482696533
[1, 23747] loss_train: 0.002531, loss_test: 0.005513
time: 0.2470548152923584
time: 2.2209410667419434
[1, 23748] loss_train: 0.001822, loss_test: 0.005510
time: 0.25156354904174805
time: 2.2495038509368896
[1, 23749] loss_train: 0.010290, loss_test: 0.005510
time: 0.2510561943054199
time: 2.234499454498291
[1, 23750] loss_train: 0.006109, loss_test: 0.005510
time: 0.26105809211730957
time: 2.272507905960083
[1, 23751] loss_train: 0.005056, loss_test: 0.005509
time: 0.2470552921295166
time: 2.246060609817505
[1, 23752] loss_train: 0.009549, loss_test: 0.005507
time: 0.24305438995361328
time: 2.248502492904663
[1, 23753] loss_train: 0.012204, loss_test: 0.005506
time: 0.25005578994750977
time: 2.252021074295044
[1, 23754] loss_train: 0.012391, loss_test: 0.005508
time: 0.24805474281311035
time: 2.278538227081299
[1, 23755] loss_train: 0.011270, loss_test: 0.005509
time: 0.2470552921295166
time: 2.2500109672546387
[1, 23756] loss_train: 0.007954, loss_test: 0.005509
time: 0.24506187438964844
time: 2.261343240737915
[1, 23757] loss_train: 0.001600, loss_test: 0.005507
time: 0.2470545768737793
time: 2.2204999923706055
[1, 23758] loss_train: 0.008942, loss_test: 0.005507
time: 0.2440354824066162
time: 2.2472305297851562
[1, 23759] loss_train: 0.010312, loss_test: 0.005508
time: 0.24805545806884766
time: 2.2505035400390625
[1, 23760] loss_train: 0.014319, loss_test: 0.005509
time: 0.25905680656433105
time: 2.2590088844299316
[1, 23761] loss_train: 0.005911, loss_test: 0.005508
time: 0.2450544834136963
time: 2.2775144577026367
[1, 23762] loss_train: 0.007729, loss_test: 0.005506
time: 0.24605512619018555
time: 2.2685067653656006
[1, 23763] loss_train: 0.001963, loss_test: 0.005501
time: 0.2450549602508545
time: 2.257506847381592
[1, 23764] loss_train: 0.000602, loss_test: 0.005499
time: 0.24305486679077148
time: 2.2715072631835938
[1, 23765] loss_train: 0.004734, loss_test: 0.005498
time: 0.27006101608276367
time: 2.2648887634277344
[1, 23766] loss_train: 0.005695, loss_test: 0.005500
time: 0.25107669830322266
time: 2.317814588546753
[1, 23767] loss_train: 0.004940, loss_test: 0.005505
time: 0.24505996704101562
time: 2.3133084774017334
[1, 23768] loss_train: 0.004985, loss_test: 0.005510
time: 0.3180713653564453
time: 2.441533327102661
[1, 23769] loss_train: 0.008279, loss_test: 0.005515
time: 0.3090815544128418
time: 2.3880789279937744
[1, 23770] loss_train: 0.003357, loss_test: 0.005522
time: 0.3630800247192383
time: 2.5324714183807373
[1, 23771] loss_train: 0.009266, loss_test: 0.005521
time: 0.24305391311645508
time: 2.394535541534424
[1, 23772] loss_train: 0.000976, loss_test: 0.005520
time: 0.2760615348815918
time: 2.4545485973358154
[1, 23773] loss_train: 0.007803, loss_test: 0.005518
time: 0.3285808563232422
time: 2.6445910930633545
[1, 23774] loss_train: 0.004538, loss_test: 0.005518
time: 0.3395841121673584
time: 2.4006333351135254
[1, 23775] loss_train: 0.007309, loss_test: 0.005519
time: 0.24505901336669922
time: 2.3209166526794434
[1, 23776] loss_train: 0.008472, loss_test: 0.005511
time: 0.24605488777160645
time: 2.4245476722717285
[1, 23777] loss_train: 0.003444, loss_test: 0.005507
time: 0.24605870246887207
time: 2.202786684036255
[1, 23778] loss_train: 0.004316, loss_test: 0.005504
time: 0.27407073974609375
time: 2.3715219497680664
[1, 23779] loss_train: 0.003361, loss_test: 0.005504
time: 0.2920658588409424
time: 2.387533664703369
[1, 23780] loss_train: 0.012625, loss_test: 0.005503
time: 0.25705623626708984
time: 2.4251694679260254
[1, 23781] loss_train: 0.012338, loss_test: 0.005501
time: 0.2540562152862549
time: 2.3015151023864746
[1, 23782] loss_train: 0.008977, loss_test: 0.005505
time: 0.25556206703186035
time: 2.3015248775482178
[1, 23783] loss_train: 0.004122, loss_test: 0.005511
time: 0.24405455589294434
time: 2.386050224304199
[1, 23784] loss_train: 0.002640, loss_test: 0.005512
time: 0.2490541934967041
time: 2.4500625133514404
[1, 23785] loss_train: 0.003318, loss_test: 0.005508
time: 0.24433112144470215
time: 2.253183603286743
[1, 23786] loss_train: 0.001206, loss_test: 0.005504
time: 0.2580580711364746
time: 2.2454400062561035
[1, 23787] loss_train: 0.002591, loss_test: 0.005503
time: 0.3720848560333252
time: 2.2515058517456055
[1, 23788] loss_train: 0.001384, loss_test: 0.005507
time: 0.25205564498901367
time: 2.263009786605835
[1, 23789] loss_train: 0.003738, loss_test: 0.005516
time: 0.24205493927001953
time: 2.2435011863708496
[1, 23790] loss_train: 0.012370, loss_test: 0.005522
time: 0.2580568790435791
time: 2.218496561050415
[1, 23791] loss_train: 0.011718, loss_test: 0.005525
time: 0.24305367469787598
time: 2.257507801055908
[1, 23792] loss_train: 0.007212, loss_test: 0.005526
time: 0.24605464935302734
time: 2.243502140045166
[1, 23793] loss_train: 0.006752, loss_test: 0.005523
time: 0.24390292167663574
time: 2.232499361038208
[1, 23794] loss_train: 0.011239, loss_test: 0.005508
time: 0.24805474281311035
time: 2.2550172805786133
[1, 23795] loss_train: 0.007310, loss_test: 0.005508
time: 0.24805498123168945
time: 2.302490711212158
[1, 23796] loss_train: 0.004348, loss_test: 0.005521
time: 0.25005531311035156
time: 2.267507791519165
[1, 23797] loss_train: 0.004149, loss_test: 0.005541
time: 0.24605441093444824
time: 2.2308919429779053
[1, 23798] loss_train: 0.008933, loss_test: 0.005566
time: 0.24805784225463867
time: 2.2639715671539307
[1, 23799] loss_train: 0.007246, loss_test: 0.005588
time: 0.2445688247680664
time: 2.297515392303467
[1, 23800] loss_train: 0.006611, loss_test: 0.005600
time: 0.273059606552124
time: 2.257504940032959
[1, 23801] loss_train: 0.007086, loss_test: 0.005606
time: 0.24005365371704102
time: 2.23201847076416
[1, 23802] loss_train: 0.004605, loss_test: 0.005587
time: 0.25107336044311523
time: 2.2425029277801514
[1, 23803] loss_train: 0.008695, loss_test: 0.005561
time: 0.24305343627929688
time: 2.2525055408477783
[1, 23804] loss_train: 0.006892, loss_test: 0.005542
time: 0.24305391311645508
time: 2.2365002632141113
[1, 23805] loss_train: 0.009557, loss_test: 0.005528
time: 0.33307361602783203
time: 2.2782933712005615
[1, 23806] loss_train: 0.006368, loss_test: 0.005518
time: 0.24805593490600586
time: 2.2538318634033203
[1, 23807] loss_train: 0.001809, loss_test: 0.005517
time: 0.24205350875854492
time: 2.276121139526367
[1, 23808] loss_train: 0.004227, loss_test: 0.005522
time: 0.24406123161315918
time: 2.2551605701446533
[1, 23809] loss_train: 0.001212, loss_test: 0.005533
time: 0.24305391311645508
time: 2.2469258308410645
[1, 23810] loss_train: 0.003333, loss_test: 0.005547
time: 0.26006269454956055
time: 2.2784841060638428
[1, 23811] loss_train: 0.003514, loss_test: 0.005562
time: 0.24405407905578613
time: 2.270512819290161
[1, 23812] loss_train: 0.002840, loss_test: 0.005577
time: 0.2450542449951172
time: 2.2635066509246826
[1, 23813] loss_train: 0.004766, loss_test: 0.005584
time: 0.24405574798583984
time: 2.2465038299560547
[1, 23814] loss_train: 0.003217, loss_test: 0.005590
time: 0.2510545253753662
time: 2.253507137298584
[1, 23815] loss_train: 0.004454, loss_test: 0.005593
time: 0.2450547218322754
time: 2.2324979305267334
[1, 23816] loss_train: 0.006092, loss_test: 0.005586
time: 0.24405431747436523
time: 2.3750343322753906
[1, 23817] loss_train: 0.003989, loss_test: 0.005574
time: 0.24405312538146973
time: 2.2712318897247314
[1, 23818] loss_train: 0.009538, loss_test: 0.005564
time: 0.256056547164917
time: 2.2615373134613037
[1, 23819] loss_train: 0.002872, loss_test: 0.005558
time: 0.24205923080444336
time: 2.245823383331299
[1, 23820] loss_train: 0.004806, loss_test: 0.005551
time: 0.25705790519714355
time: 2.268521308898926
[1, 23821] loss_train: 0.009658, loss_test: 0.005538
time: 0.24505400657653809
time: 2.2409722805023193
[1, 23822] loss_train: 0.004906, loss_test: 0.005531
time: 0.2504899501800537
time: 2.272012233734131
[1, 23823] loss_train: 0.006576, loss_test: 0.005527
time: 0.2470541000366211
time: 2.2645087242126465
[1, 23824] loss_train: 0.006061, loss_test: 0.005526
time: 0.2450547218322754
time: 2.2535033226013184
[1, 23825] loss_train: 0.003631, loss_test: 0.005526
time: 0.24706625938415527
time: 2.2690248489379883
[1, 23826] loss_train: 0.002990, loss_test: 0.005527
time: 0.25905752182006836
time: 2.2774455547332764
[1, 23827] loss_train: 0.003156, loss_test: 0.005527
time: 0.24805545806884766
time: 2.2525672912597656
[1, 23828] loss_train: 0.005490, loss_test: 0.005525
time: 0.24805569648742676
time: 2.2457656860351562
[1, 23829] loss_train: 0.010039, loss_test: 0.005523
time: 0.2490558624267578
time: 2.2548987865448
[1, 23830] loss_train: 0.000731, loss_test: 0.005524
time: 0.27006030082702637
time: 2.231499433517456
[1, 23831] loss_train: 0.001520, loss_test: 0.005527
time: 0.2510559558868408
time: 2.239746570587158
[1, 23832] loss_train: 0.005996, loss_test: 0.005532
time: 0.2438502311706543
time: 2.2436482906341553
[1, 23833] loss_train: 0.009711, loss_test: 0.005534
time: 0.2490551471710205
time: 2.2705225944519043
[1, 23834] loss_train: 0.015801, loss_test: 0.005533
time: 0.25005602836608887
time: 2.249505043029785
[1, 23835] loss_train: 0.004531, loss_test: 0.005528
time: 0.25005602836608887
time: 2.309020519256592
[1, 23836] loss_train: 0.003314, loss_test: 0.005519
time: 0.24605584144592285
time: 2.273744821548462
[1, 23837] loss_train: 0.005710, loss_test: 0.005516
time: 0.24805545806884766
time: 2.237816572189331
[1, 23838] loss_train: 0.008160, loss_test: 0.005518
time: 0.2510550022125244
time: 2.255505323410034
[1, 23839] loss_train: 0.015049, loss_test: 0.005521
time: 0.2470550537109375
time: 2.2578158378601074
[1, 23840] loss_train: 0.002440, loss_test: 0.005521
time: 0.2562525272369385
time: 2.2838895320892334
[1, 23841] loss_train: 0.009433, loss_test: 0.005522
time: 0.24605822563171387
time: 2.2480244636535645
[1, 23842] loss_train: 0.010269, loss_test: 0.005522
time: 0.2470545768737793
time: 2.253506660461426
[1, 23843] loss_train: 0.002246, loss_test: 0.005520
time: 0.24405455589294434
time: 2.2780117988586426
[1, 23844] loss_train: 0.007972, loss_test: 0.005518
time: 0.24405503273010254
time: 2.219496011734009
[1, 23845] loss_train: 0.008246, loss_test: 0.005518
time: 0.2470545768737793
time: 2.225503444671631
[1, 23846] loss_train: 0.004292, loss_test: 0.005517
time: 0.24605464935302734
time: 2.2425029277801514
[1, 23847] loss_train: 0.003048, loss_test: 0.005517
time: 0.24405407905578613
time: 2.2380409240722656
[1, 23848] loss_train: 0.000470, loss_test: 0.005521
time: 0.24405384063720703
time: 2.255173683166504
[1, 23849] loss_train: 0.007082, loss_test: 0.005523
time: 0.2525594234466553
time: 2.2680437564849854
[1, 23850] loss_train: 0.005278, loss_test: 0.005525
time: 0.2617611885070801
time: 2.2815101146698
[1, 23851] loss_train: 0.005562, loss_test: 0.005526
time: 0.24305343627929688
time: 2.2509233951568604
[1, 23852] loss_train: 0.003490, loss_test: 0.005528
time: 0.29706430435180664
time: 2.3450281620025635
[1, 23853] loss_train: 0.003788, loss_test: 0.005532
time: 0.24305343627929688
time: 2.3100550174713135
[1, 23854] loss_train: 0.008161, loss_test: 0.005534
time: 0.24605512619018555
time: 2.2550628185272217
[1, 23855] loss_train: 0.013565, loss_test: 0.005528
time: 0.24305462837219238
time: 2.241980791091919
[1, 23856] loss_train: 0.006459, loss_test: 0.005523
time: 0.24405741691589355
time: 2.2377076148986816
[1, 23857] loss_train: 0.001493, loss_test: 0.005525
time: 0.24405503273010254
time: 2.246004581451416
[1, 23858] loss_train: 0.004773, loss_test: 0.005531
time: 0.24305367469787598
time: 2.2345004081726074
[1, 23859] loss_train: 0.006194, loss_test: 0.005538
time: 0.24305391311645508
time: 2.257030487060547
[1, 23860] loss_train: 0.008728, loss_test: 0.005543
time: 0.2580573558807373
time: 2.2455034255981445
[1, 23861] loss_train: 0.004836, loss_test: 0.005548
time: 0.2450542449951172
time: 2.2274980545043945
[1, 23862] loss_train: 0.006053, loss_test: 0.005547
time: 0.2470555305480957
time: 2.2390055656433105
[1, 23863] loss_train: 0.009447, loss_test: 0.005542
time: 0.24405407905578613
time: 2.24200439453125
[1, 23864] loss_train: 0.009907, loss_test: 0.005529
time: 0.24405574798583984
time: 2.2395482063293457
[1, 23865] loss_train: 0.010471, loss_test: 0.005513
time: 0.24405646324157715
time: 2.2344119548797607
[1, 23866] loss_train: 0.003806, loss_test: 0.005506
time: 0.252056360244751
time: 2.2605130672454834
[1, 23867] loss_train: 0.008649, loss_test: 0.005502
time: 0.24405431747436523
time: 2.2274978160858154
[1, 23868] loss_train: 0.005535, loss_test: 0.005505
time: 0.24605584144592285
time: 2.2324986457824707
[1, 23869] loss_train: 0.009357, loss_test: 0.005510
time: 0.2450542449951172
time: 2.240501642227173
[1, 23870] loss_train: 0.006763, loss_test: 0.005517
time: 0.2600579261779785
time: 2.2395009994506836
[1, 23871] loss_train: 0.009360, loss_test: 0.005526
time: 0.24855923652648926
time: 2.2508249282836914
[1, 23872] loss_train: 0.004704, loss_test: 0.005535
time: 0.24506115913391113
time: 2.2544679641723633
[1, 23873] loss_train: 0.004173, loss_test: 0.005541
time: 0.24605441093444824
time: 2.2519402503967285
[1, 23874] loss_train: 0.003824, loss_test: 0.005546
time: 0.24807310104370117
time: 2.2460074424743652
[1, 23875] loss_train: 0.005377, loss_test: 0.005544
time: 0.24405789375305176
time: 2.287069797515869
[1, 23876] loss_train: 0.014007, loss_test: 0.005547
time: 0.2620582580566406
time: 2.4091813564300537
[1, 23877] loss_train: 0.001686, loss_test: 0.005536
time: 0.24305367469787598
time: 2.2905209064483643
[1, 23878] loss_train: 0.005718, loss_test: 0.005529
time: 0.2450542449951172
time: 2.241004705429077
[1, 23879] loss_train: 0.010398, loss_test: 0.005525
time: 0.24405407905578613
time: 2.220893621444702
[1, 23880] loss_train: 0.004928, loss_test: 0.005521
time: 0.2560560703277588
time: 2.321246862411499
[1, 23881] loss_train: 0.007472, loss_test: 0.005520
time: 0.24405384063720703
time: 2.216015338897705
[1, 23882] loss_train: 0.001935, loss_test: 0.005520
time: 0.24920272827148438
time: 2.2366416454315186
[1, 23883] loss_train: 0.007079, loss_test: 0.005523
time: 0.24205398559570312
time: 2.2525033950805664
[1, 23884] loss_train: 0.004995, loss_test: 0.005526
time: 0.24205350875854492
time: 2.246006727218628
[1, 23885] loss_train: 0.009595, loss_test: 0.005529
time: 0.24305343627929688
time: 2.238703966140747
[1, 23886] loss_train: 0.006183, loss_test: 0.005531
time: 0.24405479431152344
time: 2.401535749435425
[1, 23887] loss_train: 0.011635, loss_test: 0.005532
time: 0.24605703353881836
time: 2.241081476211548
[1, 23888] loss_train: 0.009712, loss_test: 0.005534
time: 0.24405431747436523
time: 2.2564427852630615
[1, 23889] loss_train: 0.002227, loss_test: 0.005533
time: 0.25105977058410645
time: 2.24503755569458
[1, 23890] loss_train: 0.005560, loss_test: 0.005530
time: 0.2580571174621582
time: 2.231351852416992
[1, 23891] loss_train: 0.003491, loss_test: 0.005527
time: 0.2450573444366455
time: 2.2415244579315186
[1, 23892] loss_train: 0.006238, loss_test: 0.005523
time: 0.2490556240081787
time: 2.268507719039917
[1, 23893] loss_train: 0.003005, loss_test: 0.005520
time: 0.2515597343444824
time: 2.2605044841766357
[1, 23894] loss_train: 0.002747, loss_test: 0.005517
time: 0.24905681610107422
time: 2.311516046524048
[1, 23895] loss_train: 0.010314, loss_test: 0.005517
time: 0.2510545253753662
time: 2.290018081665039
[1, 23896] loss_train: 0.007520, loss_test: 0.005518
time: 0.24505376815795898
time: 2.2355003356933594
[1, 23897] loss_train: 0.004340, loss_test: 0.005520
time: 0.24405479431152344
time: 2.2314982414245605
[1, 23898] loss_train: 0.007328, loss_test: 0.005521
time: 0.25305700302124023
time: 2.357531785964966
[1, 23899] loss_train: 0.015622, loss_test: 0.005512
time: 0.26806116104125977
time: 2.2940306663513184
[1, 23900] loss_train: 0.002823, loss_test: 0.005507
time: 0.27506065368652344
time: 2.243070125579834
[1, 23901] loss_train: 0.006251, loss_test: 0.005502
time: 0.24855995178222656
time: 2.343308687210083
[1, 23902] loss_train: 0.004321, loss_test: 0.005499
time: 0.2490549087524414
time: 2.2725203037261963
[1, 23903] loss_train: 0.009594, loss_test: 0.005498
time: 0.2450551986694336
time: 2.2455050945281982
[1, 23904] loss_train: 0.007021, loss_test: 0.005503
time: 0.25005578994750977
time: 2.2670342922210693
[1, 23905] loss_train: 0.001775, loss_test: 0.005509
time: 0.2470552921295166
time: 2.251006603240967
[1, 23906] loss_train: 0.017832, loss_test: 0.005516
time: 0.24305343627929688
time: 2.25262188911438
[1, 23907] loss_train: 0.004431, loss_test: 0.005516
time: 0.24600744247436523
time: 2.23404598236084
[1, 23908] loss_train: 0.003150, loss_test: 0.005515
time: 0.25005578994750977
time: 2.2204971313476562
[1, 23909] loss_train: 0.003346, loss_test: 0.005511
time: 0.24605727195739746
time: 2.2329821586608887
[1, 23910] loss_train: 0.003167, loss_test: 0.005506
time: 0.2580578327178955
time: 2.2515053749084473
[1, 23911] loss_train: 0.003643, loss_test: 0.005502
time: 0.2470543384552002
time: 2.2465028762817383
[1, 23912] loss_train: 0.005929, loss_test: 0.005498
time: 0.26006221771240234
time: 2.2555034160614014
[1, 23913] loss_train: 0.007501, loss_test: 0.005494
time: 0.24605536460876465
time: 2.248317003250122
[1, 23914] loss_train: 0.001745, loss_test: 0.005493
time: 0.2470552921295166
time: 2.2861738204956055
[1, 23915] loss_train: 0.008206, loss_test: 0.005497
time: 0.25705647468566895
time: 2.2557272911071777
[1, 23916] loss_train: 0.010104, loss_test: 0.005499
time: 0.2470552921295166
time: 2.2290165424346924
[1, 23917] loss_train: 0.006169, loss_test: 0.005500
time: 0.24709248542785645
time: 2.253772735595703
[1, 23918] loss_train: 0.005981, loss_test: 0.005501
time: 0.24805760383605957
time: 2.2305495738983154
[1, 23919] loss_train: 0.012390, loss_test: 0.005497
time: 0.24405384063720703
time: 2.2353384494781494
[1, 23920] loss_train: 0.008769, loss_test: 0.005493
time: 0.25705695152282715
time: 2.2472574710845947
[1, 23921] loss_train: 0.013677, loss_test: 0.005493
time: 0.27706241607666016
time: 2.3920414447784424
[1, 23922] loss_train: 0.003424, loss_test: 0.005496
time: 0.24605512619018555
time: 2.2540090084075928
[1, 23923] loss_train: 0.002218, loss_test: 0.005501
time: 0.2470543384552002
time: 2.309516668319702
[1, 23924] loss_train: 0.005776, loss_test: 0.005504
time: 0.24905657768249512
time: 2.4954681396484375
[1, 23925] loss_train: 0.005596, loss_test: 0.005504
time: 0.25156116485595703
time: 2.294832944869995
[1, 23926] loss_train: 0.005284, loss_test: 0.005501
time: 0.24305415153503418
time: 2.2655086517333984
[1, 23927] loss_train: 0.004198, loss_test: 0.005501
time: 0.2500569820404053
time: 2.3204405307769775
[1, 23928] loss_train: 0.004117, loss_test: 0.005503
time: 0.24794363975524902
time: 2.500236749649048
[1, 23929] loss_train: 0.006989, loss_test: 0.005507
time: 0.24305438995361328
time: 2.258007287979126
[1, 23930] loss_train: 0.005759, loss_test: 0.005512
time: 0.26405882835388184
time: 2.239004373550415
[1, 23931] loss_train: 0.008888, loss_test: 0.005518
time: 0.24959063529968262
time: 2.3725297451019287
[1, 23932] loss_train: 0.004502, loss_test: 0.005525
time: 0.24405527114868164
time: 2.274432897567749
[1, 23933] loss_train: 0.003526, loss_test: 0.005532
time: 0.24405860900878906
time: 2.3461742401123047
[1, 23934] loss_train: 0.007377, loss_test: 0.005536
time: 0.24305462837219238
time: 2.330880880355835
[1, 23935] loss_train: 0.002827, loss_test: 0.005540
time: 0.33007192611694336
time: 2.3180294036865234
[1, 23936] loss_train: 0.002689, loss_test: 0.005543
time: 0.3510754108428955
time: 2.241743326187134
[1, 23937] loss_train: 0.004820, loss_test: 0.005547
time: 0.2450547218322754
time: 2.2425031661987305
[1, 23938] loss_train: 0.004001, loss_test: 0.005549
time: 0.24605464935302734
time: 2.2845211029052734
[1, 23939] loss_train: 0.004479, loss_test: 0.005551
time: 0.31513547897338867
time: 2.2867534160614014
[1, 23940] loss_train: 0.005541, loss_test: 0.005550
time: 0.3070681095123291
time: 2.4805572032928467
[1, 23941] loss_train: 0.004552, loss_test: 0.005550
time: 0.24205327033996582
time: 2.239790916442871
[1, 23942] loss_train: 0.003794, loss_test: 0.005551
time: 0.24806880950927734
time: 2.229768753051758
[1, 23943] loss_train: 0.003648, loss_test: 0.005552
time: 0.25205540657043457
time: 2.3405277729034424
[1, 23944] loss_train: 0.010243, loss_test: 0.005547
time: 0.3070673942565918
time: 2.4015369415283203
[1, 23945] loss_train: 0.013188, loss_test: 0.005539
time: 0.24305391311645508
time: 2.269508123397827
[1, 23946] loss_train: 0.007106, loss_test: 0.005533
time: 0.25305867195129395
time: 2.3685309886932373
[1, 23947] loss_train: 0.007227, loss_test: 0.005527
time: 0.24905657768249512
time: 2.3115153312683105
[1, 23948] loss_train: 0.013483, loss_test: 0.005521
time: 0.2430553436279297
time: 2.2576277256011963
[1, 23949] loss_train: 0.004930, loss_test: 0.005519
time: 0.25005531311035156
time: 2.280937433242798
[1, 23950] loss_train: 0.005891, loss_test: 0.005519
time: 0.27405858039855957
time: 2.4259181022644043
[1, 23951] loss_train: 0.007102, loss_test: 0.005521
time: 0.24505352973937988
time: 2.240501880645752
[1, 23952] loss_train: 0.010730, loss_test: 0.005522
time: 0.24305343627929688
time: 2.4331650733947754
[1, 23953] loss_train: 0.003797, loss_test: 0.005519
time: 0.24505877494812012
time: 2.3045151233673096
[1, 23954] loss_train: 0.008382, loss_test: 0.005519
time: 0.2695624828338623
time: 2.3940396308898926
[1, 23955] loss_train: 0.003754, loss_test: 0.005517
time: 0.25505661964416504
time: 2.259012460708618
[1, 23956] loss_train: 0.011855, loss_test: 0.005514
time: 0.25005435943603516
time: 2.278146743774414
[1, 23957] loss_train: 0.002557, loss_test: 0.005510
time: 0.2780592441558838
time: 2.3108325004577637
[1, 23958] loss_train: 0.000912, loss_test: 0.005507
time: 0.2560586929321289
time: 2.3223724365234375
[1, 23959] loss_train: 0.006082, loss_test: 0.005504
time: 0.25106048583984375
time: 2.2999536991119385
[1, 23960] loss_train: 0.002125, loss_test: 0.005503
time: 0.27601027488708496
time: 2.3067686557769775
[1, 23961] loss_train: 0.005908, loss_test: 0.005503
time: 0.2560567855834961
time: 2.3220512866973877
[1, 23962] loss_train: 0.003102, loss_test: 0.005507
time: 0.24805426597595215
time: 2.3575279712677
[1, 23963] loss_train: 0.005049, loss_test: 0.005513
time: 0.2720606327056885
time: 2.2945127487182617
[1, 23964] loss_train: 0.008420, loss_test: 0.005518
time: 0.2565622329711914
time: 2.310023307800293
[1, 23965] loss_train: 0.007077, loss_test: 0.005524
time: 0.24305438995361328
time: 2.2916438579559326
[1, 23966] loss_train: 0.001271, loss_test: 0.005534
time: 0.26006150245666504
time: 2.3303451538085938
[1, 23967] loss_train: 0.003113, loss_test: 0.005547
time: 0.25305604934692383
time: 2.3390302658081055
[1, 23968] loss_train: 0.003235, loss_test: 0.005557
time: 0.2721126079559326
time: 2.3638479709625244
[1, 23969] loss_train: 0.008165, loss_test: 0.005567
time: 0.2450542449951172
time: 2.408538341522217
[1, 23970] loss_train: 0.002981, loss_test: 0.005575
time: 0.28528928756713867
time: 2.3485255241394043
[1, 23971] loss_train: 0.007296, loss_test: 0.005580
time: 0.27706217765808105
time: 2.2365026473999023
[1, 23972] loss_train: 0.008128, loss_test: 0.005582
time: 0.24405407905578613
time: 2.2525033950805664
[1, 23973] loss_train: 0.004021, loss_test: 0.005581
time: 0.25005531311035156
time: 2.224005937576294
[1, 23974] loss_train: 0.007501, loss_test: 0.005578
time: 0.24305462837219238
time: 2.23089599609375
[1, 23975] loss_train: 0.006420, loss_test: 0.005574
time: 0.24305510520935059
time: 2.232024669647217
[1, 23976] loss_train: 0.005477, loss_test: 0.005564
time: 0.24405479431152344
time: 2.234499454498291
[1, 23977] loss_train: 0.012611, loss_test: 0.005550
time: 0.24405431747436523
time: 2.2213029861450195
[1, 23978] loss_train: 0.005631, loss_test: 0.005539
time: 0.2510552406311035
time: 2.2745094299316406
[1, 23979] loss_train: 0.005858, loss_test: 0.005530
time: 0.2435591220855713
time: 2.2525174617767334
[1, 23980] loss_train: 0.002328, loss_test: 0.005524
time: 0.25705575942993164
time: 2.2865116596221924
[1, 23981] loss_train: 0.006396, loss_test: 0.005521
time: 0.24405527114868164
time: 2.2735161781311035
[1, 23982] loss_train: 0.003699, loss_test: 0.005519
time: 0.24605441093444824
time: 2.2515127658843994
[1, 23983] loss_train: 0.005145, loss_test: 0.005518
time: 0.24305415153503418
time: 2.235501766204834
[1, 23984] loss_train: 0.007274, loss_test: 0.005519
time: 0.24305367469787598
time: 2.257213592529297
[1, 23985] loss_train: 0.003985, loss_test: 0.005520
time: 0.24305510520935059
time: 2.2720260620117188
[1, 23986] loss_train: 0.016804, loss_test: 0.005519
time: 0.25505709648132324
time: 2.2605080604553223
[1, 23987] loss_train: 0.005466, loss_test: 0.005519
time: 0.3569810390472412
time: 2.2953920364379883
[1, 23988] loss_train: 0.000750, loss_test: 0.005519
time: 0.27707338333129883
time: 2.289393663406372
[1, 23989] loss_train: 0.001239, loss_test: 0.005519
time: 0.25240302085876465
time: 2.249504566192627
[1, 23990] loss_train: 0.006536, loss_test: 0.005517
time: 0.2580575942993164
time: 2.2264997959136963
[1, 23991] loss_train: 0.009090, loss_test: 0.005516
time: 0.24305486679077148
time: 2.2564926147460938
[1, 23992] loss_train: 0.003482, loss_test: 0.005512
time: 0.2470545768737793
time: 2.2605059146881104
[1, 23993] loss_train: 0.004031, loss_test: 0.005510
time: 0.24805521965026855
time: 2.262505292892456
[1, 23994] loss_train: 0.007710, loss_test: 0.005510
time: 0.2490558624267578
time: 2.2623441219329834
[1, 23995] loss_train: 0.005406, loss_test: 0.005512
time: 0.24305486679077148
time: 2.3010191917419434
[1, 23996] loss_train: 0.003031, loss_test: 0.005514
time: 0.2455582618713379
time: 2.2803006172180176
[1, 23997] loss_train: 0.006131, loss_test: 0.005518
time: 0.24305462837219238
time: 2.2349328994750977
[1, 23998] loss_train: 0.005276, loss_test: 0.005524
time: 0.2450554370880127
time: 2.263310432434082
[1, 23999] loss_train: 0.009204, loss_test: 0.005525
time: 0.24105405807495117
time: 2.2910616397857666
[1, 24000] loss_train: 0.001496, loss_test: 0.005525
time: 0.2653796672821045
time: 2.3165202140808105
[1, 24001] loss_train: 0.001082, loss_test: 0.005527
time: 0.27005958557128906
time: 2.328521251678467
[1, 24002] loss_train: 0.002155, loss_test: 0.005530
time: 0.2490549087524414
time: 2.3005168437957764
[1, 24003] loss_train: 0.006398, loss_test: 0.005530
time: 0.25305604934692383
time: 2.2495038509368896
[1, 24004] loss_train: 0.005520, loss_test: 0.005528
time: 0.25505614280700684
time: 2.2664804458618164
[1, 24005] loss_train: 0.007135, loss_test: 0.005527
time: 0.2450542449951172
time: 2.239504337310791
[1, 24006] loss_train: 0.007662, loss_test: 0.005527
time: 0.2510554790496826
time: 2.2395033836364746
[1, 24007] loss_train: 0.005202, loss_test: 0.005527
time: 0.24605536460876465
time: 2.2535030841827393
[1, 24008] loss_train: 0.007547, loss_test: 0.005528
time: 0.2510557174682617
time: 2.3285224437713623
[1, 24009] loss_train: 0.004459, loss_test: 0.005528
time: 0.2450544834136963
time: 2.2247352600097656
[1, 24010] loss_train: 0.004684, loss_test: 0.005527
time: 0.26205873489379883
time: 2.2615180015563965
[1, 24011] loss_train: 0.003308, loss_test: 0.005528
time: 0.2449650764465332
time: 2.2991106510162354
[1, 24012] loss_train: 0.009787, loss_test: 0.005528
time: 0.25005531311035156
time: 2.2609002590179443
[1, 24013] loss_train: 0.004476, loss_test: 0.005529
time: 0.24921202659606934
time: 2.296614408493042
[1, 24014] loss_train: 0.003376, loss_test: 0.005531
time: 0.24405336380004883
time: 2.246502161026001
[1, 24015] loss_train: 0.006855, loss_test: 0.005534
time: 0.2470552921295166
time: 2.281510353088379
[1, 24016] loss_train: 0.007829, loss_test: 0.005535
time: 0.2400527000427246
time: 2.255510091781616
[1, 24017] loss_train: 0.008217, loss_test: 0.005530
time: 0.24305367469787598
time: 2.2989377975463867
[1, 24018] loss_train: 0.006750, loss_test: 0.005531
time: 0.2870628833770752
time: 2.281057834625244
[1, 24019] loss_train: 0.006818, loss_test: 0.005539
time: 0.2560386657714844
time: 2.2731688022613525
[1, 24020] loss_train: 0.015139, loss_test: 0.005552
time: 0.2554817199707031
time: 2.2765090465545654
[1, 24021] loss_train: 0.005894, loss_test: 0.005567
time: 0.2450547218322754
time: 2.3145251274108887
[1, 24022] loss_train: 0.000626, loss_test: 0.005582
time: 0.24505376815795898
time: 2.3035342693328857
[1, 24023] loss_train: 0.011701, loss_test: 0.005593
time: 0.25005578994750977
time: 2.3325233459472656
[1, 24024] loss_train: 0.010750, loss_test: 0.005593
time: 0.2600574493408203
time: 2.332521915435791
[1, 24025] loss_train: 0.011211, loss_test: 0.005594
time: 0.2470552921295166
time: 2.334347724914551
[1, 24026] loss_train: 0.003413, loss_test: 0.005587
time: 0.25005555152893066
time: 2.4150867462158203
[1, 24027] loss_train: 0.009789, loss_test: 0.005573
time: 0.3070683479309082
time: 2.278514862060547
[1, 24028] loss_train: 0.003235, loss_test: 0.005551
time: 0.2573738098144531
time: 2.3226406574249268
[1, 24029] loss_train: 0.003681, loss_test: 0.005532
time: 0.24805498123168945
time: 2.280510187149048
[1, 24030] loss_train: 0.009447, loss_test: 0.005522
time: 0.263059139251709
time: 2.262019634246826
[1, 24031] loss_train: 0.010438, loss_test: 0.005518
time: 0.24305343627929688
time: 2.2460074424743652
[1, 24032] loss_train: 0.008520, loss_test: 0.005520
time: 0.24305343627929688
time: 2.4055395126342773
[1, 24033] loss_train: 0.013349, loss_test: 0.005521
time: 0.25705742835998535
time: 2.2447593212127686
[1, 24034] loss_train: 0.004388, loss_test: 0.005522
time: 0.24805521965026855
time: 2.5480234622955322
[1, 24035] loss_train: 0.006486, loss_test: 0.005524
time: 0.251056432723999
time: 2.37204647064209
[1, 24036] loss_train: 0.007302, loss_test: 0.005526
time: 0.29807209968566895
time: 2.306943655014038
[1, 24037] loss_train: 0.003119, loss_test: 0.005528
time: 0.2505631446838379
time: 2.324519157409668
[1, 24038] loss_train: 0.002706, loss_test: 0.005529
time: 0.24405622482299805
time: 2.2345006465911865
[1, 24039] loss_train: 0.011154, loss_test: 0.005527
time: 0.2450549602508545
time: 2.2465083599090576
[1, 24040] loss_train: 0.002010, loss_test: 0.005526
time: 0.2630584239959717
time: 2.266507625579834
[1, 24041] loss_train: 0.002747, loss_test: 0.005526
time: 0.24505400657653809
time: 2.2264983654022217
[1, 24042] loss_train: 0.005580, loss_test: 0.005528
time: 0.24405407905578613
time: 2.2615182399749756
[1, 24043] loss_train: 0.007365, loss_test: 0.005528
time: 0.24605512619018555
time: 2.228832483291626
[1, 24044] loss_train: 0.004870, loss_test: 0.005530
time: 0.24405455589294434
time: 2.25504469871521
[1, 24045] loss_train: 0.008085, loss_test: 0.005530
time: 0.24705767631530762
time: 2.318138360977173
[1, 24046] loss_train: 0.005937, loss_test: 0.005529
time: 0.24205350875854492
time: 2.271366596221924
[1, 24047] loss_train: 0.004709, loss_test: 0.005530
time: 0.2520599365234375
time: 2.239650011062622
[1, 24048] loss_train: 0.006390, loss_test: 0.005527
time: 0.24702715873718262
time: 2.245511054992676
[1, 24049] loss_train: 0.005463, loss_test: 0.005523
time: 0.24405455589294434
time: 2.235499382019043
[1, 24050] loss_train: 0.001138, loss_test: 0.005521
time: 0.25905799865722656
time: 2.4105398654937744
[1, 24051] loss_train: 0.005040, loss_test: 0.005519
time: 0.25705599784851074
time: 2.5210721492767334
[1, 24052] loss_train: 0.002972, loss_test: 0.005518
time: 0.2470548152923584
time: 2.281015396118164
[1, 24053] loss_train: 0.013871, loss_test: 0.005516
time: 0.294064998626709
time: 2.3525264263153076
[1, 24054] loss_train: 0.006511, loss_test: 0.005515
time: 0.25005602836608887
time: 2.2290050983428955
[1, 24055] loss_train: 0.003728, loss_test: 0.005514
time: 0.24505352973937988
time: 2.2259433269500732
[1, 24056] loss_train: 0.016689, loss_test: 0.005512
time: 0.2430570125579834
time: 2.252427339553833
[1, 24057] loss_train: 0.002636, loss_test: 0.005512
time: 0.24605393409729004
time: 2.3658382892608643
[1, 24058] loss_train: 0.003004, loss_test: 0.005511
time: 0.2520742416381836
time: 2.3020005226135254
[1, 24059] loss_train: 0.007595, loss_test: 0.005507
time: 0.24643540382385254
time: 2.2555179595947266
[1, 24060] loss_train: 0.002002, loss_test: 0.005506
time: 0.26105737686157227
time: 2.3215315341949463
[1, 24061] loss_train: 0.005625, loss_test: 0.005507
time: 0.27906250953674316
time: 2.338054895401001
[1, 24062] loss_train: 0.000471, loss_test: 0.005512
time: 0.24306845664978027
time: 2.2800137996673584
[1, 24063] loss_train: 0.001607, loss_test: 0.005520
time: 0.24605369567871094
time: 2.3118081092834473
[1, 24064] loss_train: 0.004152, loss_test: 0.005526
time: 0.24405503273010254
time: 2.269043207168579
[1, 24065] loss_train: 0.004292, loss_test: 0.005532
time: 0.2516324520111084
time: 2.2855124473571777
[1, 24066] loss_train: 0.002906, loss_test: 0.005538
time: 0.2470552921295166
time: 2.292022228240967
[1, 24067] loss_train: 0.002519, loss_test: 0.005545
time: 0.2500629425048828
time: 2.2864460945129395
[1, 24068] loss_train: 0.009409, loss_test: 0.005546
time: 0.2600584030151367
time: 2.2745087146759033
[1, 24069] loss_train: 0.018593, loss_test: 0.005537
time: 0.24605512619018555
time: 2.2821500301361084
[1, 24070] loss_train: 0.018096, loss_test: 0.005522
time: 0.267303466796875
time: 2.247159481048584
[1, 24071] loss_train: 0.006940, loss_test: 0.005513
time: 0.2450542449951172
time: 2.264456033706665
[1, 24072] loss_train: 0.006096, loss_test: 0.005510
time: 0.2450573444366455
time: 2.2696640491485596
[1, 24073] loss_train: 0.007053, loss_test: 0.005513
time: 0.24705839157104492
time: 2.2503726482391357
[1, 24074] loss_train: 0.003397, loss_test: 0.005518
time: 0.2580578327178955
time: 2.3545262813568115
[1, 24075] loss_train: 0.001346, loss_test: 0.005523
time: 0.2850630283355713
time: 2.2860169410705566
[1, 24076] loss_train: 0.012960, loss_test: 0.005526
time: 0.2580564022064209
time: 2.279510259628296
[1, 24077] loss_train: 0.002155, loss_test: 0.005526
time: 0.23905301094055176
time: 2.246828556060791
[1, 24078] loss_train: 0.011970, loss_test: 0.005525
time: 0.24405455589294434
time: 2.2164952754974365
[1, 24079] loss_train: 0.000743, loss_test: 0.005523
time: 0.24205374717712402
time: 2.2234973907470703
[1, 24080] loss_train: 0.008855, loss_test: 0.005521
time: 0.28106236457824707
time: 2.3568098545074463
[1, 24081] loss_train: 0.004502, loss_test: 0.005516
time: 0.25206995010375977
time: 2.381955862045288
[1, 24082] loss_train: 0.005677, loss_test: 0.005513
time: 0.2470545768737793
time: 2.2245047092437744
[1, 24083] loss_train: 0.008442, loss_test: 0.005511
time: 0.24805331230163574
time: 2.233769655227661
[1, 24084] loss_train: 0.007334, loss_test: 0.005509
time: 0.25699901580810547
time: 2.2738635540008545
[1, 24085] loss_train: 0.008165, loss_test: 0.005508
time: 0.25055813789367676
time: 2.2500112056732178
[1, 24086] loss_train: 0.002939, loss_test: 0.005508
time: 0.2455615997314453
time: 2.3795313835144043
[1, 24087] loss_train: 0.007952, loss_test: 0.005510
time: 0.25205492973327637
time: 2.2428104877471924
[1, 24088] loss_train: 0.003025, loss_test: 0.005512
time: 0.24505877494812012
time: 2.3580195903778076
[1, 24089] loss_train: 0.005532, loss_test: 0.005513
time: 0.24205398559570312
time: 2.3481075763702393
[1, 24090] loss_train: 0.011303, loss_test: 0.005514
time: 0.256056547164917
time: 2.2635161876678467
[1, 24091] loss_train: 0.011734, loss_test: 0.005515
time: 0.26806020736694336
time: 2.3305211067199707
[1, 24092] loss_train: 0.004958, loss_test: 0.005514
time: 0.2470557689666748
time: 2.3170225620269775
[1, 24093] loss_train: 0.008693, loss_test: 0.005511
time: 0.25505781173706055
time: 2.4019699096679688
[1, 24094] loss_train: 0.004682, loss_test: 0.005510
time: 0.2470543384552002
time: 2.428361415863037
[1, 24095] loss_train: 0.001688, loss_test: 0.005513
time: 0.24105596542358398
time: 2.2306418418884277
[1, 24096] loss_train: 0.002438, loss_test: 0.005520
time: 0.24776458740234375
time: 2.263657569885254
[1, 24097] loss_train: 0.005805, loss_test: 0.005528
time: 0.28708815574645996
time: 2.2893264293670654
[1, 24098] loss_train: 0.007407, loss_test: 0.005532
time: 0.25905752182006836
time: 2.450546979904175
[1, 24099] loss_train: 0.005712, loss_test: 0.005537
time: 0.24805927276611328
time: 2.2565042972564697
[1, 24100] loss_train: 0.007156, loss_test: 0.005541
time: 0.2630584239959717
time: 2.23350191116333
[1, 24101] loss_train: 0.005462, loss_test: 0.005545
time: 0.25905680656433105
time: 2.3020002841949463
[1, 24102] loss_train: 0.005945, loss_test: 0.005540
time: 0.24706268310546875
time: 2.24910044670105
[1, 24103] loss_train: 0.013368, loss_test: 0.005536
time: 0.24655961990356445
time: 2.265170097351074
[1, 24104] loss_train: 0.000556, loss_test: 0.005536
time: 0.2720611095428467
time: 2.242342948913574
[1, 24105] loss_train: 0.011159, loss_test: 0.005535
time: 0.2435598373413086
time: 2.2347447872161865
[1, 24106] loss_train: 0.003185, loss_test: 0.005532
time: 0.24305343627929688
time: 2.228499174118042
[1, 24107] loss_train: 0.002952, loss_test: 0.005530
time: 0.24605393409729004
time: 2.30302095413208
[1, 24108] loss_train: 0.003271, loss_test: 0.005526
time: 0.2540562152862549
time: 2.243501901626587
[1, 24109] loss_train: 0.001309, loss_test: 0.005520
time: 0.2470541000366211
time: 2.2360217571258545
[1, 24110] loss_train: 0.004572, loss_test: 0.005515
time: 0.26308631896972656
time: 2.363084316253662
[1, 24111] loss_train: 0.009257, loss_test: 0.005510
time: 0.3295934200286865
time: 2.4243295192718506
[1, 24112] loss_train: 0.007715, loss_test: 0.005507
time: 0.2800629138946533
time: 2.264221668243408
[1, 24113] loss_train: 0.004844, loss_test: 0.005507
time: 0.3054835796356201
time: 2.3849356174468994
[1, 24114] loss_train: 0.005175, loss_test: 0.005508
time: 0.24405455589294434
time: 2.24359130859375
[1, 24115] loss_train: 0.003251, loss_test: 0.005509
time: 0.24805736541748047
time: 2.2765097618103027
[1, 24116] loss_train: 0.011857, loss_test: 0.005511
time: 0.24305462837219238
time: 2.2805094718933105
[1, 24117] loss_train: 0.003456, loss_test: 0.005516
time: 0.24305438995361328
time: 2.2542479038238525
[1, 24118] loss_train: 0.008145, loss_test: 0.005519
time: 0.2490558624267578
time: 2.2380924224853516
[1, 24119] loss_train: 0.006735, loss_test: 0.005522
time: 0.25005602836608887
time: 2.313533306121826
[1, 24120] loss_train: 0.008910, loss_test: 0.005523
time: 0.28107285499572754
time: 2.4110019207000732
[1, 24121] loss_train: 0.004099, loss_test: 0.005525
time: 0.2520639896392822
time: 2.5450751781463623
[1, 24122] loss_train: 0.003989, loss_test: 0.005528
time: 0.26406168937683105
time: 2.378532886505127
[1, 24123] loss_train: 0.009268, loss_test: 0.005528
time: 0.24605560302734375
time: 2.4190587997436523
[1, 24124] loss_train: 0.001083, loss_test: 0.005528
time: 0.27742958068847656
time: 2.4787590503692627
[1, 24125] loss_train: 0.010406, loss_test: 0.005530
time: 0.2490551471710205
time: 2.3316915035247803
[1, 24126] loss_train: 0.002915, loss_test: 0.005532
time: 0.256056547164917
time: 2.463623046875
[1, 24127] loss_train: 0.003246, loss_test: 0.005536
time: 0.32607102394104004
time: 2.354526996612549
[1, 24128] loss_train: 0.008943, loss_test: 0.005536
time: 0.26105785369873047
time: 2.3945364952087402
[1, 24129] loss_train: 0.004478, loss_test: 0.005538
time: 0.2470548152923584
time: 2.2505109310150146
[1, 24130] loss_train: 0.007393, loss_test: 0.005540
time: 0.25905704498291016
time: 2.2895116806030273
[1, 24131] loss_train: 0.008112, loss_test: 0.005539
time: 0.2500593662261963
time: 2.3405263423919678
[1, 24132] loss_train: 0.003935, loss_test: 0.005538
time: 0.24456357955932617
time: 2.3821399211883545
[1, 24133] loss_train: 0.012524, loss_test: 0.005535
time: 0.2520561218261719
time: 2.3370492458343506
[1, 24134] loss_train: 0.005024, loss_test: 0.005532
time: 0.24306249618530273
time: 2.265218496322632
[1, 24135] loss_train: 0.009528, loss_test: 0.005529
time: 0.24456024169921875
time: 2.2520060539245605
[1, 24136] loss_train: 0.002692, loss_test: 0.005527
time: 0.25005602836608887
time: 2.2590136528015137
[1, 24137] loss_train: 0.004016, loss_test: 0.005527
time: 0.24405431747436523
time: 2.2748711109161377
[1, 24138] loss_train: 0.005636, loss_test: 0.005528
time: 0.24605488777160645
time: 2.2600107192993164
[1, 24139] loss_train: 0.001391, loss_test: 0.005529
time: 0.24796032905578613
time: 2.253478765487671
[1, 24140] loss_train: 0.004552, loss_test: 0.005531
time: 0.26405763626098633
time: 2.273707151412964
[1, 24141] loss_train: 0.005915, loss_test: 0.005533
time: 0.2470552921295166
time: 2.301250696182251
[1, 24142] loss_train: 0.009445, loss_test: 0.005532
time: 0.3140687942504883
time: 2.3054025173187256
[1, 24143] loss_train: 0.008195, loss_test: 0.005531
time: 0.25505733489990234
time: 2.3715298175811768
[1, 24144] loss_train: 0.006391, loss_test: 0.005527
time: 0.25505709648132324
time: 2.577082872390747
[1, 24145] loss_train: 0.008385, loss_test: 0.005524
time: 0.24305367469787598
time: 2.328523635864258
[1, 24146] loss_train: 0.012783, loss_test: 0.005525
time: 0.24305391311645508
time: 2.2485077381134033
[1, 24147] loss_train: 0.008768, loss_test: 0.005528
time: 0.24205374717712402
time: 2.33854603767395
[1, 24148] loss_train: 0.001732, loss_test: 0.005532
time: 0.2450554370880127
time: 2.475722074508667
[1, 24149] loss_train: 0.008260, loss_test: 0.005533
time: 0.26256227493286133
time: 2.2595386505126953
[1, 24150] loss_train: 0.009316, loss_test: 0.005538
time: 0.26405811309814453
time: 2.3939666748046875
[1, 24151] loss_train: 0.010386, loss_test: 0.005544
time: 0.24826359748840332
time: 2.269763469696045
[1, 24152] loss_train: 0.003527, loss_test: 0.005545
time: 0.2670598030090332
time: 2.2935125827789307
[1, 24153] loss_train: 0.009243, loss_test: 0.005542
time: 0.24805593490600586
time: 2.2615151405334473
[1, 24154] loss_train: 0.014567, loss_test: 0.005544
time: 0.24605536460876465
time: 2.2784881591796875
[1, 24155] loss_train: 0.009112, loss_test: 0.005540
time: 0.2490553855895996
time: 2.292714834213257
[1, 24156] loss_train: 0.006205, loss_test: 0.005533
time: 0.2560575008392334
time: 2.347533702850342
[1, 24157] loss_train: 0.003857, loss_test: 0.005520
time: 0.2540566921234131
time: 2.2905120849609375
[1, 24158] loss_train: 0.010248, loss_test: 0.005514
time: 0.2510557174682617
time: 2.3512485027313232
[1, 24159] loss_train: 0.008569, loss_test: 0.005511
time: 0.24405455589294434
time: 2.28251051902771
[1, 24160] loss_train: 0.003656, loss_test: 0.005512
time: 0.30206799507141113
time: 2.3720438480377197
[1, 24161] loss_train: 0.011262, loss_test: 0.005513
time: 0.2450549602508545
time: 2.391037940979004
[1, 24162] loss_train: 0.003679, loss_test: 0.005515
time: 0.2765693664550781
time: 2.3285317420959473
[1, 24163] loss_train: 0.001358, loss_test: 0.005515
time: 0.2645251750946045
time: 2.338555335998535
[1, 24164] loss_train: 0.015555, loss_test: 0.005514
time: 0.24805450439453125
time: 2.351043462753296
[1, 24165] loss_train: 0.001535, loss_test: 0.005514
time: 0.2630646228790283
time: 2.2905726432800293
[1, 24166] loss_train: 0.002731, loss_test: 0.005516
time: 0.24906587600708008
time: 2.3277344703674316
[1, 24167] loss_train: 0.001494, loss_test: 0.005517
time: 0.2940654754638672
time: 2.2780163288116455
[1, 24168] loss_train: 0.004896, loss_test: 0.005517
time: 0.24505376815795898
time: 2.3935348987579346
[1, 24169] loss_train: 0.008820, loss_test: 0.005517
time: 0.2620582580566406
time: 2.265393018722534
[1, 24170] loss_train: 0.000914, loss_test: 0.005518
time: 0.3140702247619629
time: 2.421085834503174
[1, 24171] loss_train: 0.003469, loss_test: 0.005520
time: 0.2540566921234131
time: 2.3277053833007812
[1, 24172] loss_train: 0.009084, loss_test: 0.005523
time: 0.2589080333709717
time: 2.320241928100586
[1, 24173] loss_train: 0.009666, loss_test: 0.005525
time: 0.24805760383605957
time: 2.247288942337036
[1, 24174] loss_train: 0.007775, loss_test: 0.005527
time: 0.24206185340881348
time: 2.3113911151885986
[1, 24175] loss_train: 0.003033, loss_test: 0.005528
time: 0.2580575942993164
time: 2.372720241546631
[1, 24176] loss_train: 0.001633, loss_test: 0.005529
time: 0.24605512619018555
time: 2.3395233154296875
[1, 24177] loss_train: 0.009111, loss_test: 0.005531
time: 0.2540569305419922
time: 2.2754082679748535
[1, 24178] loss_train: 0.011222, loss_test: 0.005531
time: 0.2510561943054199
time: 2.289519786834717
[1, 24179] loss_train: 0.006457, loss_test: 0.005529
time: 0.24855971336364746
time: 2.356044292449951
[1, 24180] loss_train: 0.011025, loss_test: 0.005528
time: 0.29906606674194336
time: 2.414044141769409
[1, 24181] loss_train: 0.007955, loss_test: 0.005529
time: 0.2600576877593994
time: 2.3300621509552
[1, 24182] loss_train: 0.008316, loss_test: 0.005528
time: 0.24266552925109863
time: 2.2413089275360107
[1, 24183] loss_train: 0.005698, loss_test: 0.005527
time: 0.2750284671783447
time: 2.2833704948425293
[1, 24184] loss_train: 0.007093, loss_test: 0.005525
time: 0.24024033546447754
time: 2.273057460784912
[1, 24185] loss_train: 0.004267, loss_test: 0.005521
time: 0.30806851387023926
time: 2.3335251808166504
[1, 24186] loss_train: 0.007279, loss_test: 0.005517
time: 0.2510640621185303
time: 2.275509834289551
[1, 24187] loss_train: 0.004135, loss_test: 0.005514
time: 0.24605464935302734
time: 2.234501600265503
[1, 24188] loss_train: 0.007887, loss_test: 0.005515
time: 0.24405360221862793
time: 2.243511199951172
[1, 24189] loss_train: 0.009294, loss_test: 0.005518
time: 0.2580702304840088
time: 2.2628889083862305
[1, 24190] loss_train: 0.001555, loss_test: 0.005523
time: 0.279066801071167
time: 2.276196002960205
[1, 24191] loss_train: 0.010836, loss_test: 0.005525
time: 0.24605441093444824
time: 2.241302728652954
[1, 24192] loss_train: 0.009290, loss_test: 0.005523
time: 0.2759578227996826
time: 2.2477188110351562
[1, 24193] loss_train: 0.008285, loss_test: 0.005521
time: 0.24897980690002441
time: 2.3117170333862305
[1, 24194] loss_train: 0.005467, loss_test: 0.005519
time: 0.3070685863494873
time: 2.4239702224731445
[1, 24195] loss_train: 0.005500, loss_test: 0.005517
time: 0.2800629138946533
time: 2.378903388977051
[1, 24196] loss_train: 0.002526, loss_test: 0.005518
time: 0.26405835151672363
time: 2.359039783477783
[1, 24197] loss_train: 0.006194, loss_test: 0.005519
time: 0.27706146240234375
time: 2.275513172149658
[1, 24198] loss_train: 0.008935, loss_test: 0.005520
time: 0.2540559768676758
time: 2.411134958267212
[1, 24199] loss_train: 0.004654, loss_test: 0.005521
time: 0.2503626346588135
time: 2.3956899642944336
[1, 24200] loss_train: 0.001983, loss_test: 0.005522
time: 0.2760605812072754
time: 2.2725088596343994
[1, 24201] loss_train: 0.006051, loss_test: 0.005524
time: 0.291064977645874
time: 2.4012720584869385
[1, 24202] loss_train: 0.001081, loss_test: 0.005524
time: 0.2830624580383301
time: 2.2975144386291504
[1, 24203] loss_train: 0.010710, loss_test: 0.005525
time: 0.2960665225982666
time: 2.3735299110412598
[1, 24204] loss_train: 0.000932, loss_test: 0.005524
time: 0.2540562152862549
time: 2.3055245876312256
[1, 24205] loss_train: 0.012517, loss_test: 0.005523
time: 0.25905656814575195
time: 2.302022695541382
[1, 24206] loss_train: 0.008898, loss_test: 0.005522
time: 0.25705695152282715
time: 2.350003719329834
[1, 24207] loss_train: 0.001752, loss_test: 0.005519
time: 0.26805996894836426
time: 2.5364937782287598
[1, 24208] loss_train: 0.005901, loss_test: 0.005517
time: 0.26206159591674805
time: 2.655212163925171
[1, 24209] loss_train: 0.005225, loss_test: 0.005515
time: 0.34006381034851074
time: 2.3477184772491455
[1, 24210] loss_train: 0.003737, loss_test: 0.005514
time: 0.26289844512939453
time: 2.2795639038085938
[1, 24211] loss_train: 0.005162, loss_test: 0.005514
time: 0.2520568370819092
time: 2.2965164184570312
[1, 24212] loss_train: 0.004505, loss_test: 0.005515
time: 0.25905752182006836
time: 2.2845120429992676
[1, 24213] loss_train: 0.007477, loss_test: 0.005516
time: 0.2580583095550537
time: 2.297516345977783
[1, 24214] loss_train: 0.002513, loss_test: 0.005518
time: 0.2450547218322754
time: 2.372713088989258
[1, 24215] loss_train: 0.001371, loss_test: 0.005523
time: 0.29506516456604004
time: 2.377547025680542
[1, 24216] loss_train: 0.007797, loss_test: 0.005526
time: 0.2690591812133789
time: 2.280510902404785
[1, 24217] loss_train: 0.011023, loss_test: 0.005522
time: 0.24605417251586914
time: 2.2993953227996826
[1, 24218] loss_train: 0.005461, loss_test: 0.005518
time: 0.2575705051422119
time: 2.349520683288574
[1, 24219] loss_train: 0.007667, loss_test: 0.005509
time: 0.24906063079833984
time: 2.3393023014068604
[1, 24220] loss_train: 0.006976, loss_test: 0.005504
time: 0.2870628833770752
time: 2.344329357147217
[1, 24221] loss_train: 0.012851, loss_test: 0.005502
time: 0.29260683059692383
time: 2.337599992752075
[1, 24222] loss_train: 0.005055, loss_test: 0.005504
time: 0.26805925369262695
time: 2.368004083633423
[1, 24223] loss_train: 0.015841, loss_test: 0.005517
time: 0.24805498123168945
time: 2.3405232429504395
[1, 24224] loss_train: 0.002750, loss_test: 0.005533
time: 0.2610604763031006
time: 2.3119747638702393
[1, 24225] loss_train: 0.002968, loss_test: 0.005551
time: 0.26523375511169434
time: 2.405012607574463
[1, 24226] loss_train: 0.003951, loss_test: 0.005560
time: 0.24463176727294922
time: 2.268507480621338
[1, 24227] loss_train: 0.005631, loss_test: 0.005556
time: 0.2580571174621582
time: 2.2495040893554688
[1, 24228] loss_train: 0.009725, loss_test: 0.005541
time: 0.24205255508422852
time: 2.2244982719421387
[1, 24229] loss_train: 0.008702, loss_test: 0.005526
time: 0.24405384063720703
time: 2.2803900241851807
[1, 24230] loss_train: 0.002905, loss_test: 0.005514
time: 0.2560563087463379
time: 2.226498603820801
[1, 24231] loss_train: 0.006805, loss_test: 0.005509
time: 0.2450554370880127
time: 2.256503105163574
[1, 24232] loss_train: 0.003686, loss_test: 0.005508
time: 0.24406981468200684
time: 2.241501808166504
[1, 24233] loss_train: 0.005135, loss_test: 0.005515
time: 0.24305462837219238
time: 2.260504961013794
[1, 24234] loss_train: 0.005123, loss_test: 0.005523
time: 0.2490551471710205
time: 2.2745249271392822
[1, 24235] loss_train: 0.003385, loss_test: 0.005539
time: 0.2450551986694336
time: 2.409120559692383
[1, 24236] loss_train: 0.008512, loss_test: 0.005550
time: 0.27005910873413086
time: 2.45007586479187
[1, 24237] loss_train: 0.013510, loss_test: 0.005545
time: 0.2720305919647217
time: 2.3881423473358154
[1, 24238] loss_train: 0.004869, loss_test: 0.005539
time: 0.2754204273223877
time: 2.3565456867218018
[1, 24239] loss_train: 0.003400, loss_test: 0.005536
time: 0.2690591812133789
time: 2.3195271492004395
[1, 24240] loss_train: 0.003231, loss_test: 0.005536
time: 0.2650599479675293
time: 2.323519706726074
[1, 24241] loss_train: 0.006946, loss_test: 0.005535
time: 0.2540578842163086
time: 2.3236711025238037
[1, 24242] loss_train: 0.012628, loss_test: 0.005532
time: 0.25406384468078613
time: 2.3495876789093018
[1, 24243] loss_train: 0.011803, loss_test: 0.005529
time: 0.25005578994750977
time: 2.3255209922790527
[1, 24244] loss_train: 0.003888, loss_test: 0.005529
time: 0.2510545253753662
time: 2.3205292224884033
[1, 24245] loss_train: 0.006159, loss_test: 0.005530
time: 0.25005555152893066
time: 2.379272699356079
[1, 24246] loss_train: 0.004034, loss_test: 0.005531
time: 0.3065989017486572
time: 2.3071651458740234
[1, 24247] loss_train: 0.006456, loss_test: 0.005532
time: 0.2470533847808838
time: 2.3376123905181885
[1, 24248] loss_train: 0.008409, loss_test: 0.005535
time: 0.25748276710510254
time: 2.3548624515533447
[1, 24249] loss_train: 0.009569, loss_test: 0.005540
time: 0.28406357765197754
time: 2.3750245571136475
[1, 24250] loss_train: 0.004731, loss_test: 0.005543
time: 0.2920663356781006
time: 2.357694387435913
[1, 24251] loss_train: 0.002710, loss_test: 0.005544
time: 0.27706146240234375
time: 2.3135173320770264
[1, 24252] loss_train: 0.007168, loss_test: 0.005543
time: 0.28206324577331543
time: 2.378035068511963
[1, 24253] loss_train: 0.007976, loss_test: 0.005552
time: 0.26105761528015137
time: 2.4228930473327637
[1, 24254] loss_train: 0.005071, loss_test: 0.005560
time: 0.2740604877471924
time: 2.3175101280212402
[1, 24255] loss_train: 0.003580, loss_test: 0.005561
time: 0.2670586109161377
time: 2.3392088413238525
[1, 24256] loss_train: 0.003755, loss_test: 0.005559
time: 0.25005531311035156
time: 2.316009283065796
[1, 24257] loss_train: 0.001764, loss_test: 0.005555
time: 0.26803135871887207
time: 2.3389577865600586
[1, 24258] loss_train: 0.009959, loss_test: 0.005554
time: 0.26405858993530273
time: 2.3345229625701904
[1, 24259] loss_train: 0.007890, loss_test: 0.005550
time: 0.2780628204345703
time: 2.3900394439697266
[1, 24260] loss_train: 0.007533, loss_test: 0.005541
time: 0.2810635566711426
time: 2.4425456523895264
[1, 24261] loss_train: 0.010901, loss_test: 0.005534
time: 0.274059534072876
time: 2.353031873703003
[1, 24262] loss_train: 0.006300, loss_test: 0.005528
time: 0.2698972225189209
time: 2.3080315589904785
[1, 24263] loss_train: 0.007407, loss_test: 0.005523
time: 0.24605441093444824
time: 2.332014322280884
[1, 24264] loss_train: 0.011216, loss_test: 0.005521
time: 0.2480618953704834
time: 2.3354744911193848
[1, 24265] loss_train: 0.008433, loss_test: 0.005519
time: 0.2830634117126465
time: 2.396536111831665
[1, 24266] loss_train: 0.007204, loss_test: 0.005517
time: 0.24605512619018555
time: 2.330521821975708
[1, 24267] loss_train: 0.001104, loss_test: 0.005516
time: 0.25005507469177246
time: 2.2685070037841797
[1, 24268] loss_train: 0.009386, loss_test: 0.005518
time: 0.25705742835998535
time: 2.2725095748901367
[1, 24269] loss_train: 0.007383, loss_test: 0.005520
time: 0.2690603733062744
time: 2.3065154552459717
[1, 24270] loss_train: 0.008256, loss_test: 0.005523
time: 0.2620580196380615
time: 2.282510995864868
[1, 24271] loss_train: 0.002641, loss_test: 0.005528
time: 0.2520568370819092
time: 2.285511016845703
[1, 24272] loss_train: 0.005322, loss_test: 0.005534
time: 0.24605393409729004
time: 2.3095178604125977
[1, 24273] loss_train: 0.012521, loss_test: 0.005539
time: 0.25705599784851074
time: 2.305515766143799
[1, 24274] loss_train: 0.011149, loss_test: 0.005540
time: 0.24605417251586914
time: 2.324852705001831
[1, 24275] loss_train: 0.007892, loss_test: 0.005540
time: 0.27706170082092285
time: 2.372530221939087
[1, 24276] loss_train: 0.004350, loss_test: 0.005542
time: 0.26405882835388184
time: 2.2765088081359863
[1, 24277] loss_train: 0.004874, loss_test: 0.005546
time: 0.2490549087524414
time: 2.2975144386291504
[1, 24278] loss_train: 0.004512, loss_test: 0.005547
time: 0.2740607261657715
time: 2.368530035018921
[1, 24279] loss_train: 0.001798, loss_test: 0.005544
time: 0.25905823707580566
time: 2.4185409545898438
[1, 24280] loss_train: 0.005738, loss_test: 0.005538
time: 0.2960660457611084
time: 2.3365306854248047
[1, 24281] loss_train: 0.010703, loss_test: 0.005534
time: 0.2510559558868408
time: 2.2425034046173096
[1, 24282] loss_train: 0.004486, loss_test: 0.005529
time: 0.2520565986633301
time: 2.2840137481689453
[1, 24283] loss_train: 0.001636, loss_test: 0.005524
time: 0.25305652618408203
time: 2.35302996635437
[1, 24284] loss_train: 0.005170, loss_test: 0.005519
time: 0.27006030082702637
time: 2.3055150508880615
[1, 24285] loss_train: 0.006436, loss_test: 0.005517
time: 0.2540571689605713
time: 2.259504795074463
[1, 24286] loss_train: 0.009723, loss_test: 0.005519
time: 0.2450544834136963
time: 2.323519468307495
[1, 24287] loss_train: 0.005395, loss_test: 0.005520
time: 0.24805474281311035
time: 2.284511089324951
[1, 24288] loss_train: 0.000860, loss_test: 0.005520
time: 0.24805593490600586
time: 2.3005146980285645
[1, 24289] loss_train: 0.006317, loss_test: 0.005519
time: 0.25205564498901367
time: 2.273508310317993
[1, 24290] loss_train: 0.009716, loss_test: 0.005519
time: 0.27906155586242676
time: 2.3625285625457764
[1, 24291] loss_train: 0.001155, loss_test: 0.005521
time: 0.25305676460266113
time: 2.3020927906036377
[1, 24292] loss_train: 0.005812, loss_test: 0.005520
time: 0.2620573043823242
time: 2.3355228900909424
[1, 24293] loss_train: 0.009665, loss_test: 0.005517
time: 0.2470552921295166
time: 2.3175177574157715
[1, 24294] loss_train: 0.008674, loss_test: 0.005513
time: 0.24405360221862793
time: 2.265507459640503
[1, 24295] loss_train: 0.003940, loss_test: 0.005509
time: 0.25005578994750977
time: 2.347524404525757
[1, 24296] loss_train: 0.004342, loss_test: 0.005506
time: 0.2610585689544678
time: 2.286510467529297
[1, 24297] loss_train: 0.005797, loss_test: 0.005504
time: 0.2470557689666748
time: 2.2565038204193115
[1, 24298] loss_train: 0.004047, loss_test: 0.005502
time: 0.24506807327270508
time: 2.262505292892456
[1, 24299] loss_train: 0.003957, loss_test: 0.005503
time: 0.24805450439453125
time: 2.2795214653015137
[1, 24300] loss_train: 0.016288, loss_test: 0.005503
time: 0.2720606327056885
time: 2.276507616043091
[1, 24301] loss_train: 0.004766, loss_test: 0.005503
time: 0.26205873489379883
time: 2.261505603790283
[1, 24302] loss_train: 0.007307, loss_test: 0.005503
time: 0.24405407905578613
time: 2.252504348754883
[1, 24303] loss_train: 0.003535, loss_test: 0.005503
time: 0.24105334281921387
time: 2.2525038719177246
[1, 24304] loss_train: 0.011178, loss_test: 0.005504
time: 0.24205398559570312
time: 2.2505030632019043
[1, 24305] loss_train: 0.002653, loss_test: 0.005505
time: 0.24105405807495117
time: 2.209494113922119
[1, 24306] loss_train: 0.007667, loss_test: 0.005507
time: 0.24505305290222168
time: 2.204493522644043
[1, 24307] loss_train: 0.007343, loss_test: 0.005508
time: 0.25005626678466797
time: 2.276508331298828
[1, 24308] loss_train: 0.004735, loss_test: 0.005509
time: 0.24305510520935059
time: 2.284511089324951
[1, 24309] loss_train: 0.007806, loss_test: 0.005510
time: 0.2620577812194824
time: 2.243501663208008
[1, 24310] loss_train: 0.008844, loss_test: 0.005510
time: 0.2560691833496094
time: 2.233499526977539
[1, 24311] loss_train: 0.011824, loss_test: 0.005511
time: 0.24505400657653809
time: 2.2515125274658203
[1, 24312] loss_train: 0.002749, loss_test: 0.005512
time: 0.24205350875854492
time: 2.2244980335235596
[1, 24313] loss_train: 0.004358, loss_test: 0.005513
time: 0.24605488777160645
time: 2.2435011863708496
[1, 24314] loss_train: 0.016750, loss_test: 0.005513
time: 0.24105381965637207
time: 2.310516119003296
[1, 24315] loss_train: 0.016940, loss_test: 0.005514
time: 0.24605441093444824
time: 2.2795186042785645
[1, 24316] loss_train: 0.003397, loss_test: 0.005515
time: 0.25005507469177246
time: 2.2925126552581787
[1, 24317] loss_train: 0.004710, loss_test: 0.005515
time: 0.25505733489990234
time: 2.253504991531372
[1, 24318] loss_train: 0.004876, loss_test: 0.005514
time: 0.24205279350280762
time: 2.280510187149048
[1, 24319] loss_train: 0.006537, loss_test: 0.005512
time: 0.2450544834136963
time: 2.212998151779175
[1, 24320] loss_train: 0.022668, loss_test: 0.005510
time: 0.25505733489990234
time: 2.209493637084961
[1, 24321] loss_train: 0.001633, loss_test: 0.005509
time: 0.24105334281921387
time: 2.2114949226379395
[1, 24322] loss_train: 0.007228, loss_test: 0.005510
time: 0.24205374717712402
time: 2.2144951820373535
[1, 24323] loss_train: 0.003550, loss_test: 0.005509
time: 0.25905728340148926
time: 2.254504442214966
[1, 24324] loss_train: 0.002052, loss_test: 0.005508
time: 0.26205873489379883
time: 2.300513982772827
[1, 24325] loss_train: 0.007425, loss_test: 0.005506
time: 0.24405479431152344
time: 2.239499807357788
[1, 24326] loss_train: 0.003736, loss_test: 0.005505
time: 0.24105334281921387
time: 2.219496726989746
[1, 24327] loss_train: 0.003284, loss_test: 0.005505
time: 0.24405360221862793
time: 2.2595059871673584
[1, 24328] loss_train: 0.005382, loss_test: 0.005506
time: 0.2450554370880127
time: 2.236499786376953
[1, 24329] loss_train: 0.003636, loss_test: 0.005510
time: 0.24605584144592285
time: 2.2665069103240967
[1, 24330] loss_train: 0.007799, loss_test: 0.005514
time: 0.26405787467956543
time: 2.270508050918579
[1, 24331] loss_train: 0.002584, loss_test: 0.005520
time: 0.24805521965026855
time: 2.2775094509124756
[1, 24332] loss_train: 0.001897, loss_test: 0.005526
time: 0.2510559558868408
time: 2.3005149364471436
[1, 24333] loss_train: 0.000583, loss_test: 0.005536
time: 0.2600572109222412
time: 2.3255202770233154
[1, 24334] loss_train: 0.013509, loss_test: 0.005542
time: 0.2716832160949707
time: 2.303513765335083
[1, 24335] loss_train: 0.004145, loss_test: 0.005547
time: 0.3010671138763428
time: 2.3875346183776855
[1, 24336] loss_train: 0.004028, loss_test: 0.005544
time: 0.29006361961364746
time: 2.3745169639587402
[1, 24337] loss_train: 0.004510, loss_test: 0.005542
time: 0.269059419631958
time: 2.343113660812378
[1, 24338] loss_train: 0.004620, loss_test: 0.005538
time: 0.2560570240020752
time: 2.2930185794830322
[1, 24339] loss_train: 0.007065, loss_test: 0.005537
time: 0.24893903732299805
time: 2.298963785171509
[1, 24340] loss_train: 0.002305, loss_test: 0.005537
time: 0.2715744972229004
time: 2.2945120334625244
[1, 24341] loss_train: 0.005734, loss_test: 0.005537
time: 0.25505757331848145
time: 2.26041841506958
[1, 24342] loss_train: 0.007229, loss_test: 0.005537
time: 0.2502627372741699
time: 2.3375232219696045
[1, 24343] loss_train: 0.004356, loss_test: 0.005536
time: 0.25505638122558594
time: 2.290870428085327
[1, 24344] loss_train: 0.004038, loss_test: 0.005535
time: 0.2505643367767334
time: 2.266277313232422
[1, 24345] loss_train: 0.002315, loss_test: 0.005534
time: 0.25705742835998535
time: 2.2775089740753174
[1, 24346] loss_train: 0.009449, loss_test: 0.005529
time: 0.24605512619018555
time: 2.2649412155151367
[1, 24347] loss_train: 0.011445, loss_test: 0.005517
time: 0.24731850624084473
time: 2.4009037017822266
[1, 24348] loss_train: 0.010080, loss_test: 0.005510
time: 0.2470548152923584
time: 2.2830140590667725
[1, 24349] loss_train: 0.010799, loss_test: 0.005510
time: 0.25205516815185547
time: 2.2995150089263916
[1, 24350] loss_train: 0.010604, loss_test: 0.005515
time: 0.31873655319213867
time: 2.3145182132720947
[1, 24351] loss_train: 0.005275, loss_test: 0.005521
time: 0.25005507469177246
time: 2.271322011947632
[1, 24352] loss_train: 0.009976, loss_test: 0.005532
time: 0.2508580684661865
time: 2.303107738494873
[1, 24353] loss_train: 0.007245, loss_test: 0.005544
time: 0.2470545768737793
time: 2.3495256900787354
[1, 24354] loss_train: 0.005155, loss_test: 0.005553
time: 0.2670629024505615
time: 2.3964855670928955
[1, 24355] loss_train: 0.001074, loss_test: 0.005551
time: 0.2760622501373291
time: 2.3875343799591064
[1, 24356] loss_train: 0.008580, loss_test: 0.005548
time: 0.27506089210510254
time: 2.381539821624756
[1, 24357] loss_train: 0.008160, loss_test: 0.005544
time: 0.2720603942871094
time: 2.3765316009521484
[1, 24358] loss_train: 0.003028, loss_test: 0.005531
time: 0.27006006240844727
time: 2.380532741546631
[1, 24359] loss_train: 0.000933, loss_test: 0.005525
time: 0.267059326171875
time: 2.3840744495391846
[1, 24360] loss_train: 0.007669, loss_test: 0.005523
time: 0.2800617218017578
time: 2.4005370140075684
[1, 24361] loss_train: 0.007168, loss_test: 0.005524
time: 0.26605892181396484
time: 2.397536516189575
[1, 24362] loss_train: 0.006461, loss_test: 0.005526
time: 0.2720611095428467
time: 2.4335436820983887
[1, 24363] loss_train: 0.005954, loss_test: 0.005528
time: 0.27506065368652344
time: 2.382533311843872
[1, 24364] loss_train: 0.002822, loss_test: 0.005533
time: 0.24805474281311035
time: 2.3080289363861084
[1, 24365] loss_train: 0.002208, loss_test: 0.005541
time: 0.24405479431152344
time: 2.2825098037719727
[1, 24366] loss_train: 0.002575, loss_test: 0.005554
time: 0.25905752182006836
time: 2.3352999687194824
[1, 24367] loss_train: 0.008034, loss_test: 0.005564
time: 0.25960326194763184
time: 2.5143887996673584
[1, 24368] loss_train: 0.008360, loss_test: 0.005569
time: 0.26100826263427734
time: 2.353147029876709
[1, 24369] loss_train: 0.004920, loss_test: 0.005572
time: 0.2554445266723633
time: 2.4966094493865967
[1, 24370] loss_train: 0.005077, loss_test: 0.005572
time: 0.2910640239715576
time: 2.4025378227233887
[1, 24371] loss_train: 0.002842, loss_test: 0.005571
time: 0.2560570240020752
time: 2.2550158500671387
[1, 24372] loss_train: 0.006977, loss_test: 0.005559
time: 0.24405384063720703
time: 2.2705376148223877
[1, 24373] loss_train: 0.001423, loss_test: 0.005550
time: 0.2430591583251953
time: 2.306936740875244
[1, 24374] loss_train: 0.002537, loss_test: 0.005542
time: 0.2500596046447754
time: 2.2827796936035156
[1, 24375] loss_train: 0.003234, loss_test: 0.005538
time: 0.24617624282836914
time: 2.2655067443847656
[1, 24376] loss_train: 0.003475, loss_test: 0.005536
time: 0.25023388862609863
time: 2.323519468307495
[1, 24377] loss_train: 0.007981, loss_test: 0.005532
time: 0.28606319427490234
time: 2.378539800643921
[1, 24378] loss_train: 0.005592, loss_test: 0.005530
time: 0.2490549087524414
time: 2.3775317668914795
[1, 24379] loss_train: 0.002821, loss_test: 0.005531
time: 0.2830624580383301
time: 2.3905441761016846
[1, 24380] loss_train: 0.007533, loss_test: 0.005530
time: 0.3001713752746582
time: 2.4098353385925293
[1, 24381] loss_train: 0.004724, loss_test: 0.005529
time: 0.2490551471710205
time: 2.337106704711914
[1, 24382] loss_train: 0.001744, loss_test: 0.005527
time: 0.2630574703216553
time: 2.3505258560180664
[1, 24383] loss_train: 0.004853, loss_test: 0.005523
time: 0.25505638122558594
time: 2.2447919845581055
[1, 24384] loss_train: 0.003842, loss_test: 0.005521
time: 0.24756789207458496
time: 2.259010076522827
[1, 24385] loss_train: 0.003797, loss_test: 0.005519
time: 0.2490544319152832
time: 2.277513265609741
[1, 24386] loss_train: 0.006596, loss_test: 0.005517
time: 0.28806400299072266
time: 2.3625283241271973
[1, 24387] loss_train: 0.003812, loss_test: 0.005517
time: 0.26405835151672363
time: 2.376535415649414
[1, 24388] loss_train: 0.003381, loss_test: 0.005520
time: 0.2600574493408203
time: 2.3085339069366455
[1, 24389] loss_train: 0.010263, loss_test: 0.005520
time: 0.2655653953552246
time: 2.284092903137207
[1, 24390] loss_train: 0.002590, loss_test: 0.005520
time: 0.26605868339538574
time: 2.2865254878997803
[1, 24391] loss_train: 0.001132, loss_test: 0.005521
time: 0.252056360244751
time: 2.2836906909942627
[1, 24392] loss_train: 0.003751, loss_test: 0.005522
time: 0.2630422115325928
time: 2.3279924392700195
[1, 24393] loss_train: 0.005432, loss_test: 0.005521
time: 0.25797533988952637
time: 2.401923418045044
[1, 24394] loss_train: 0.009004, loss_test: 0.005518
time: 0.2537524700164795
time: 2.395040988922119
[1, 24395] loss_train: 0.008730, loss_test: 0.005516
time: 0.28572988510131836
time: 2.4543702602386475
[1, 24396] loss_train: 0.004528, loss_test: 0.005517
time: 0.2710597515106201
time: 2.2885122299194336
[1, 24397] loss_train: 0.009941, loss_test: 0.005511
time: 0.26605868339538574
time: 2.3421225547790527
[1, 24398] loss_train: 0.006593, loss_test: 0.005505
time: 0.26205873489379883
time: 2.434335708618164
[1, 24399] loss_train: 0.012314, loss_test: 0.005502
time: 0.28105807304382324
time: 2.3163607120513916
[1, 24400] loss_train: 0.007454, loss_test: 0.005507
time: 0.2830624580383301
time: 2.3755414485931396
[1, 24401] loss_train: 0.007962, loss_test: 0.005516
time: 0.2630581855773926
time: 2.3235206604003906
[1, 24402] loss_train: 0.004557, loss_test: 0.005530
time: 0.28806304931640625
time: 2.4265425205230713
[1, 24403] loss_train: 0.002900, loss_test: 0.005543
time: 0.267059326171875
time: 2.371373176574707
[1, 24404] loss_train: 0.003507, loss_test: 0.005541
time: 0.25305604934692383
time: 2.3730340003967285
[1, 24405] loss_train: 0.008766, loss_test: 0.005537
time: 0.25705647468566895
time: 2.3554694652557373
[1, 24406] loss_train: 0.000810, loss_test: 0.005530
time: 0.28106188774108887
time: 2.306124687194824
[1, 24407] loss_train: 0.004430, loss_test: 0.005532
time: 0.25905680656433105
time: 2.2755649089813232
[1, 24408] loss_train: 0.011735, loss_test: 0.005538
time: 0.24902606010437012
time: 2.320392370223999
[1, 24409] loss_train: 0.006984, loss_test: 0.005546
time: 0.25005555152893066
time: 2.2495033740997314
[1, 24410] loss_train: 0.009616, loss_test: 0.005559
time: 0.26105761528015137
time: 2.323061227798462
[1, 24411] loss_train: 0.004947, loss_test: 0.005572
time: 0.2870640754699707
time: 2.3120205402374268
[1, 24412] loss_train: 0.008851, loss_test: 0.005572
time: 0.252056360244751
time: 2.281510353088379
[1, 24413] loss_train: 0.004276, loss_test: 0.005561
time: 0.24105286598205566
time: 2.252307176589966
[1, 24414] loss_train: 0.002628, loss_test: 0.005554
time: 0.2485666275024414
time: 2.2730252742767334
[1, 24415] loss_train: 0.011923, loss_test: 0.005540
time: 0.24405550956726074
time: 2.2820045948028564
[1, 24416] loss_train: 0.002865, loss_test: 0.005530
time: 0.25096869468688965
time: 2.3177385330200195
[1, 24417] loss_train: 0.002599, loss_test: 0.005521
time: 0.258056640625
time: 2.314517021179199
[1, 24418] loss_train: 0.008957, loss_test: 0.005504
time: 0.25705695152282715
time: 2.2950170040130615
[1, 24419] loss_train: 0.001864, loss_test: 0.005495
time: 0.2450551986694336
time: 2.291513204574585
[1, 24420] loss_train: 0.002782, loss_test: 0.005492
time: 0.28106188774108887
time: 2.2785089015960693
[1, 24421] loss_train: 0.015051, loss_test: 0.005492
time: 0.2610585689544678
time: 2.311516523361206
[1, 24422] loss_train: 0.010091, loss_test: 0.005495
time: 0.2600574493408203
time: 2.2855114936828613
[1, 24423] loss_train: 0.005682, loss_test: 0.005499
time: 0.24805521965026855
time: 2.283541440963745
[1, 24424] loss_train: 0.006246, loss_test: 0.005501
time: 0.24105286598205566
time: 2.2389180660247803
[1, 24425] loss_train: 0.010659, loss_test: 0.005502
time: 0.24906682968139648
time: 2.3157737255096436
[1, 24426] loss_train: 0.006563, loss_test: 0.005502
time: 0.25005578994750977
time: 2.3004300594329834
[1, 24427] loss_train: 0.013539, loss_test: 0.005504
time: 0.25587010383605957
time: 2.2735090255737305
[1, 24428] loss_train: 0.007224, loss_test: 0.005507
time: 0.2450547218322754
time: 2.30151629447937
[1, 24429] loss_train: 0.013376, loss_test: 0.005512
time: 0.25205564498901367
time: 2.464686632156372
[1, 24430] loss_train: 0.010097, loss_test: 0.005514
time: 0.27906227111816406
time: 2.3435328006744385
[1, 24431] loss_train: 0.003222, loss_test: 0.005516
time: 0.25705695152282715
time: 2.295017957687378
[1, 24432] loss_train: 0.001532, loss_test: 0.005521
time: 0.2620580196380615
time: 2.2870125770568848
[1, 24433] loss_train: 0.002744, loss_test: 0.005526
time: 0.24505376815795898
time: 2.2992749214172363
[1, 24434] loss_train: 0.008325, loss_test: 0.005532
time: 0.2520570755004883
time: 2.268212080001831
[1, 24435] loss_train: 0.006375, loss_test: 0.005537
time: 0.24505376815795898
time: 2.2755093574523926
[1, 24436] loss_train: 0.003726, loss_test: 0.005547
time: 0.25305652618408203
time: 2.3815314769744873
[1, 24437] loss_train: 0.015793, loss_test: 0.005550
time: 0.2560575008392334
time: 2.409538507461548
[1, 24438] loss_train: 0.006568, loss_test: 0.005549
time: 0.2720615863800049
time: 2.4465482234954834
[1, 24439] loss_train: 0.006019, loss_test: 0.005547
time: 0.27006006240844727
time: 2.3405234813690186
[1, 24440] loss_train: 0.005832, loss_test: 0.005544
time: 0.2760608196258545
time: 2.3245203495025635
[1, 24441] loss_train: 0.007749, loss_test: 0.005542
time: 0.24805521965026855
time: 2.2545039653778076
[1, 24442] loss_train: 0.004078, loss_test: 0.005541
time: 0.2430572509765625
time: 2.2695071697235107
[1, 24443] loss_train: 0.011239, loss_test: 0.005536
time: 0.24305391311645508
time: 2.2715084552764893
[1, 24444] loss_train: 0.004840, loss_test: 0.005532
time: 0.24305367469787598
time: 2.274012565612793
[1, 24445] loss_train: 0.007978, loss_test: 0.005531
time: 0.2490556240081787
time: 2.2925126552581787
[1, 24446] loss_train: 0.007686, loss_test: 0.005534
time: 0.2490549087524414
time: 2.279510259628296
[1, 24447] loss_train: 0.002416, loss_test: 0.005538
time: 0.24605441093444824
time: 2.3025169372558594
[1, 24448] loss_train: 0.001464, loss_test: 0.005544
time: 0.2520568370819092
time: 2.2975144386291504
[1, 24449] loss_train: 0.006838, loss_test: 0.005542
time: 0.27506113052368164
time: 2.33152174949646
[1, 24450] loss_train: 0.010657, loss_test: 0.005539
time: 0.27306103706359863
time: 2.34352445602417
[1, 24451] loss_train: 0.011182, loss_test: 0.005537
time: 0.2720603942871094
time: 2.4205410480499268
[1, 24452] loss_train: 0.007493, loss_test: 0.005536
time: 0.26805925369262695
time: 2.3505258560180664
[1, 24453] loss_train: 0.005521, loss_test: 0.005534
time: 0.3180711269378662
time: 2.615586757659912
[1, 24454] loss_train: 0.006968, loss_test: 0.005533
time: 0.3780837059020996
time: 2.293513536453247
[1, 24455] loss_train: 0.008689, loss_test: 0.005532
time: 0.2650587558746338
time: 2.2124950885772705
[1, 24456] loss_train: 0.001995, loss_test: 0.005529
time: 0.24605512619018555
time: 2.23449969291687
[1, 24457] loss_train: 0.010880, loss_test: 0.005532
time: 0.24605441093444824
time: 2.2925126552581787
[1, 24458] loss_train: 0.008328, loss_test: 0.005537
time: 0.2455739974975586
time: 2.2375004291534424
[1, 24459] loss_train: 0.006788, loss_test: 0.005545
time: 0.24305415153503418
time: 2.274507761001587
[1, 24460] loss_train: 0.005702, loss_test: 0.005551
time: 0.282062292098999
time: 2.297513484954834
[1, 24461] loss_train: 0.002693, loss_test: 0.005557
time: 0.25505733489990234
time: 2.2935128211975098
[1, 24462] loss_train: 0.003947, loss_test: 0.005561
time: 0.25705909729003906
time: 2.2815098762512207
[1, 24463] loss_train: 0.003814, loss_test: 0.005567
time: 0.2435600757598877
time: 2.278075695037842
[1, 24464] loss_train: 0.009386, loss_test: 0.005567
time: 0.29506540298461914
time: 2.3545262813568115
[1, 24465] loss_train: 0.000661, loss_test: 0.005573
time: 0.2580573558807373
time: 2.2645068168640137
[1, 24466] loss_train: 0.008800, loss_test: 0.005558
time: 0.24605488777160645
time: 2.2685067653656006
[1, 24467] loss_train: 0.001530, loss_test: 0.005548
time: 0.2620580196380615
time: 2.3025152683258057
[1, 24468] loss_train: 0.004867, loss_test: 0.005538
time: 0.2510554790496826
time: 2.280510187149048
[1, 24469] loss_train: 0.003798, loss_test: 0.005532
time: 0.24805450439453125
time: 2.257505416870117
[1, 24470] loss_train: 0.014712, loss_test: 0.005528
time: 0.2580568790435791
time: 2.2405014038085938
[1, 24471] loss_train: 0.003266, loss_test: 0.005519
time: 0.24605536460876465
time: 2.2415010929107666
[1, 24472] loss_train: 0.007402, loss_test: 0.005520
time: 0.25705647468566895
time: 2.2705085277557373
[1, 24473] loss_train: 0.005207, loss_test: 0.005516
time: 0.2510547637939453
time: 2.3245205879211426
[1, 24474] loss_train: 0.002805, loss_test: 0.005513
time: 0.25505638122558594
time: 2.283511161804199
[1, 24475] loss_train: 0.002149, loss_test: 0.005510
time: 0.2890646457672119
time: 2.298513650894165
[1, 24476] loss_train: 0.007994, loss_test: 0.005508
time: 0.2510552406311035
time: 2.281510353088379
[1, 24477] loss_train: 0.004724, loss_test: 0.005505
time: 0.2470555305480957
time: 2.2825100421905518
[1, 24478] loss_train: 0.005060, loss_test: 0.005504
time: 0.2520565986633301
time: 2.2900147438049316
[1, 24479] loss_train: 0.006753, loss_test: 0.005503
time: 0.2560579776763916
time: 2.311516761779785
[1, 24480] loss_train: 0.003730, loss_test: 0.005503
time: 0.2600572109222412
time: 2.272516965866089
[1, 24481] loss_train: 0.005429, loss_test: 0.005502
time: 0.24605417251586914
time: 2.3045151233673096
[1, 24482] loss_train: 0.008307, loss_test: 0.005502
time: 0.25305604934692383
time: 2.3036201000213623
[1, 24483] loss_train: 0.001307, loss_test: 0.005504
time: 0.25905680656433105
time: 2.2627904415130615
[1, 24484] loss_train: 0.015208, loss_test: 0.005502
time: 0.2450547218322754
time: 2.2753329277038574
[1, 24485] loss_train: 0.003842, loss_test: 0.005502
time: 0.2720043659210205
time: 2.473766803741455
[1, 24486] loss_train: 0.010806, loss_test: 0.005501
time: 0.2520558834075928
time: 2.304677963256836
[1, 24487] loss_train: 0.010385, loss_test: 0.005501
time: 0.263059139251709
time: 2.307037115097046
[1, 24488] loss_train: 0.005498, loss_test: 0.005504
time: 0.2510559558868408
time: 2.29551362991333
[1, 24489] loss_train: 0.010467, loss_test: 0.005505
time: 0.2510552406311035
time: 2.3095169067382812
[1, 24490] loss_train: 0.008455, loss_test: 0.005507
time: 0.26656341552734375
time: 2.3181819915771484
[1, 24491] loss_train: 0.000789, loss_test: 0.005508
time: 0.25705671310424805
time: 2.305849313735962
[1, 24492] loss_train: 0.005222, loss_test: 0.005511
time: 0.26805853843688965
time: 2.275012731552124
[1, 24493] loss_train: 0.002056, loss_test: 0.005510
time: 0.24805474281311035
time: 2.2854299545288086
[1, 24494] loss_train: 0.007309, loss_test: 0.005509
time: 0.25905776023864746
time: 2.3425240516662598
[1, 24495] loss_train: 0.010141, loss_test: 0.005509
time: 0.24405407905578613
time: 2.266021966934204
[1, 24496] loss_train: 0.001724, loss_test: 0.005510
time: 0.2510557174682617
time: 2.296165943145752
[1, 24497] loss_train: 0.004970, loss_test: 0.005510
time: 0.24405455589294434
time: 2.3008086681365967
[1, 24498] loss_train: 0.004114, loss_test: 0.005511
time: 0.24505376815795898
time: 2.2584283351898193
[1, 24499] loss_train: 0.004744, loss_test: 0.005514
time: 0.24305343627929688
time: 2.267423391342163
[1, 24500] loss_train: 0.005522, loss_test: 0.005518
time: 0.26205897331237793
time: 2.292513847351074
[1, 24501] loss_train: 0.002115, loss_test: 0.005523
time: 0.24573850631713867
time: 2.3275325298309326
[1, 24502] loss_train: 0.001256, loss_test: 0.005529
time: 0.24405479431152344
time: 2.320518732070923
[1, 24503] loss_train: 0.002412, loss_test: 0.005537
time: 0.24605464935302734
time: 2.3145179748535156
[1, 24504] loss_train: 0.006914, loss_test: 0.005543
time: 0.25305628776550293
time: 2.4120283126831055
[1, 24505] loss_train: 0.003517, loss_test: 0.005548
time: 0.27306222915649414
time: 2.3684701919555664
[1, 24506] loss_train: 0.005028, loss_test: 0.005550
time: 0.2540585994720459
time: 2.3032712936401367
[1, 24507] loss_train: 0.010721, loss_test: 0.005543
time: 0.2520558834075928
time: 2.2855262756347656
[1, 24508] loss_train: 0.006723, loss_test: 0.005536
time: 0.25505900382995605
time: 2.364734172821045
[1, 24509] loss_train: 0.005120, loss_test: 0.005529
time: 0.26413464546203613
time: 2.2815101146698
[1, 24510] loss_train: 0.006823, loss_test: 0.005520
time: 0.26405811309814453
time: 2.2820825576782227
[1, 24511] loss_train: 0.003754, loss_test: 0.005514
time: 0.2504863739013672
time: 2.3010177612304688
[1, 24512] loss_train: 0.007385, loss_test: 0.005508
time: 0.29006505012512207
time: 2.3062968254089355
[1, 24513] loss_train: 0.005969, loss_test: 0.005504
time: 0.2730371952056885
time: 2.3796732425689697
[1, 24514] loss_train: 0.007086, loss_test: 0.005503
time: 0.2710599899291992
time: 2.3841512203216553
[1, 24515] loss_train: 0.012139, loss_test: 0.005504
time: 0.27906203269958496
time: 2.290417194366455
[1, 24516] loss_train: 0.001740, loss_test: 0.005508
time: 0.2540569305419922
time: 2.352525234222412
[1, 24517] loss_train: 0.005283, loss_test: 0.005513
time: 0.24605393409729004
time: 2.392535448074341
[1, 24518] loss_train: 0.016790, loss_test: 0.005522
time: 0.24805688858032227
time: 2.419541835784912
[1, 24519] loss_train: 0.005349, loss_test: 0.005531
time: 0.3815431594848633
time: 2.351170778274536
[1, 24520] loss_train: 0.002940, loss_test: 0.005542
time: 0.26105761528015137
time: 2.6246068477630615
[1, 24521] loss_train: 0.004592, loss_test: 0.005539
time: 0.2547342777252197
time: 2.287569761276245
[1, 24522] loss_train: 0.005435, loss_test: 0.005537
time: 0.24481606483459473
time: 2.3355648517608643
[1, 24523] loss_train: 0.002252, loss_test: 0.005535
time: 0.2523224353790283
time: 2.399535894393921
[1, 24524] loss_train: 0.007978, loss_test: 0.005530
time: 0.2540569305419922
time: 2.4025373458862305
[1, 24525] loss_train: 0.009979, loss_test: 0.005525
time: 0.24305343627929688
time: 2.268014430999756
[1, 24526] loss_train: 0.004304, loss_test: 0.005521
time: 0.2510561943054199
time: 2.2940163612365723
[1, 24527] loss_train: 0.007314, loss_test: 0.005517
time: 0.2630586624145508
time: 2.3140499591827393
[1, 24528] loss_train: 0.005431, loss_test: 0.005512
time: 0.2650587558746338
time: 2.3975794315338135
[1, 24529] loss_train: 0.006485, loss_test: 0.005509
time: 0.25806307792663574
time: 2.3305482864379883
[1, 24530] loss_train: 0.000800, loss_test: 0.005507
time: 0.27005982398986816
time: 2.3184351921081543
[1, 24531] loss_train: 0.002095, loss_test: 0.005505
time: 0.2540578842163086
time: 2.28421688079834
[1, 24532] loss_train: 0.002438, loss_test: 0.005508
time: 0.2490549087524414
time: 2.257505178451538
[1, 24533] loss_train: 0.001759, loss_test: 0.005516
time: 0.25305628776550293
time: 2.3055286407470703
[1, 24534] loss_train: 0.006638, loss_test: 0.005525
time: 0.2600579261779785
time: 2.302515745162964
[1, 24535] loss_train: 0.007291, loss_test: 0.005534
time: 0.25005555152893066
time: 2.3415257930755615
[1, 24536] loss_train: 0.004881, loss_test: 0.005543
time: 0.2490553855895996
time: 2.2816004753112793
[1, 24537] loss_train: 0.003953, loss_test: 0.005548
time: 0.2607550621032715
time: 2.329299211502075
[1, 24538] loss_train: 0.006814, loss_test: 0.005550
time: 0.2650585174560547
time: 2.270507335662842
[1, 24539] loss_train: 0.004577, loss_test: 0.005548
time: 0.252056360244751
time: 2.3080427646636963
[1, 24540] loss_train: 0.014415, loss_test: 0.005538
time: 0.2760624885559082
time: 2.3650364875793457
[1, 24541] loss_train: 0.003235, loss_test: 0.005530
time: 0.2710607051849365
time: 2.276848554611206
[1, 24542] loss_train: 0.002133, loss_test: 0.005526
time: 0.25292539596557617
time: 2.3311524391174316
[1, 24543] loss_train: 0.007193, loss_test: 0.005521
time: 0.252758264541626
time: 2.3105180263519287
[1, 24544] loss_train: 0.010974, loss_test: 0.005513
time: 0.31507372856140137
time: 2.359398603439331
[1, 24545] loss_train: 0.002579, loss_test: 0.005510
time: 0.2720601558685303
time: 2.312533140182495
[1, 24546] loss_train: 0.005509, loss_test: 0.005507
time: 0.26806020736694336
time: 2.3065249919891357
[1, 24547] loss_train: 0.005178, loss_test: 0.005507
time: 0.24805450439453125
time: 2.3125174045562744
[1, 24548] loss_train: 0.009972, loss_test: 0.005508
time: 0.2690601348876953
time: 2.3325212001800537
[1, 24549] loss_train: 0.011965, loss_test: 0.005505
time: 0.2710599899291992
time: 2.304020881652832
[1, 24550] loss_train: 0.006455, loss_test: 0.005505
time: 0.27306056022644043
time: 2.410539388656616
[1, 24551] loss_train: 0.002164, loss_test: 0.005509
time: 0.249603271484375
time: 2.3293514251708984
[1, 24552] loss_train: 0.001187, loss_test: 0.005514
time: 0.2520594596862793
time: 2.3460283279418945
[1, 24553] loss_train: 0.010006, loss_test: 0.005521
time: 0.24405384063720703
time: 2.2605061531066895
[1, 24554] loss_train: 0.003760, loss_test: 0.005529
time: 0.2620580196380615
time: 2.2658891677856445
[1, 24555] loss_train: 0.006653, loss_test: 0.005534
time: 0.24887704849243164
time: 2.2735071182250977
[1, 24556] loss_train: 0.002213, loss_test: 0.005541
time: 0.2470548152923584
time: 2.2710132598876953
[1, 24557] loss_train: 0.002668, loss_test: 0.005538
time: 0.2470543384552002
time: 2.40453839302063
[1, 24558] loss_train: 0.005298, loss_test: 0.005536
time: 0.2785656452178955
time: 2.3795325756073
[1, 24559] loss_train: 0.004635, loss_test: 0.005536
time: 0.24305415153503418
time: 2.260009765625
[1, 24560] loss_train: 0.006317, loss_test: 0.005533
time: 0.2580568790435791
time: 2.2845141887664795
[1, 24561] loss_train: 0.022219, loss_test: 0.005536
time: 0.26105690002441406
time: 2.293755531311035
[1, 24562] loss_train: 0.010870, loss_test: 0.005537
time: 0.24505376815795898
time: 2.3633875846862793
[1, 24563] loss_train: 0.004760, loss_test: 0.005536
time: 0.2786130905151367
time: 2.411550521850586
[1, 24564] loss_train: 0.008316, loss_test: 0.005536
time: 0.2560577392578125
time: 2.3206560611724854
[1, 24565] loss_train: 0.006081, loss_test: 0.005536
time: 0.24605607986450195
time: 2.3246238231658936
[1, 24566] loss_train: 0.008748, loss_test: 0.005527
time: 0.2450549602508545
time: 2.3660552501678467
[1, 24567] loss_train: 0.005969, loss_test: 0.005521
time: 0.24805521965026855
time: 2.319021701812744
[1, 24568] loss_train: 0.007696, loss_test: 0.005519
time: 0.26711010932922363
time: 2.3235201835632324
[1, 24569] loss_train: 0.002949, loss_test: 0.005520
time: 0.2830636501312256
time: 2.297513246536255
[1, 24570] loss_train: 0.009713, loss_test: 0.005520
time: 0.26805925369262695
time: 2.2895123958587646
[1, 24571] loss_train: 0.004996, loss_test: 0.005522
time: 0.24305367469787598
time: 2.2505033016204834
[1, 24572] loss_train: 0.002335, loss_test: 0.005522
time: 0.2510557174682617
time: 2.256504774093628
[1, 24573] loss_train: 0.005068, loss_test: 0.005523
time: 0.24205446243286133
time: 2.2324984073638916
[1, 24574] loss_train: 0.004484, loss_test: 0.005523
time: 0.2450542449951172
time: 2.3465254306793213
[1, 24575] loss_train: 0.007371, loss_test: 0.005525
time: 0.26805996894836426
time: 2.3283743858337402
[1, 24576] loss_train: 0.005984, loss_test: 0.005525
time: 0.2490546703338623
time: 2.368529796600342
[1, 24577] loss_train: 0.002891, loss_test: 0.005525
time: 0.2540562152862549
time: 2.2745089530944824
[1, 24578] loss_train: 0.006184, loss_test: 0.005525
time: 0.24405407905578613
time: 2.295513391494751
[1, 24579] loss_train: 0.002741, loss_test: 0.005525
time: 0.25705599784851074
time: 2.2915241718292236
[1, 24580] loss_train: 0.007655, loss_test: 0.005526
time: 0.30106639862060547
time: 2.3200244903564453
[1, 24581] loss_train: 0.005833, loss_test: 0.005527
time: 0.2630579471588135
time: 2.286510944366455
[1, 24582] loss_train: 0.013733, loss_test: 0.005522
time: 0.2540571689605713
time: 2.3825325965881348
[1, 24583] loss_train: 0.003250, loss_test: 0.005518
time: 0.26805973052978516
time: 2.321518898010254
[1, 24584] loss_train: 0.006897, loss_test: 0.005517
time: 0.2490549087524414
time: 2.279510259628296
[1, 24585] loss_train: 0.006255, loss_test: 0.005519
time: 0.24805545806884766
time: 2.279510259628296
[1, 24586] loss_train: 0.008625, loss_test: 0.005520
time: 0.24805450439453125
time: 2.321519613265991
[1, 24587] loss_train: 0.004200, loss_test: 0.005523
time: 0.2510554790496826
time: 2.2885141372680664
[1, 24588] loss_train: 0.002986, loss_test: 0.005526
time: 0.24605536460876465
time: 2.275508403778076
[1, 24589] loss_train: 0.004112, loss_test: 0.005534
time: 0.2510554790496826
time: 2.256504535675049
[1, 24590] loss_train: 0.002200, loss_test: 0.005541
time: 0.25705623626708984
time: 2.2630093097686768
[1, 24591] loss_train: 0.003957, loss_test: 0.005550
time: 0.24805569648742676
time: 2.28351092338562
[1, 24592] loss_train: 0.004976, loss_test: 0.005554
time: 0.2650589942932129
time: 2.384533166885376
[1, 24593] loss_train: 0.012295, loss_test: 0.005550
time: 0.25005483627319336
time: 2.35552716255188
[1, 24594] loss_train: 0.006614, loss_test: 0.005541
time: 0.2520565986633301
time: 2.3335213661193848
[1, 24595] loss_train: 0.009081, loss_test: 0.005531
time: 0.24605441093444824
time: 2.255504846572876
[1, 24596] loss_train: 0.010099, loss_test: 0.005525
time: 0.2780625820159912
time: 2.2895116806030273
[1, 24597] loss_train: 0.005804, loss_test: 0.005527
time: 0.2490544319152832
time: 2.305516004562378
[1, 24598] loss_train: 0.004778, loss_test: 0.005534
time: 0.2670598030090332
time: 2.314526319503784
[1, 24599] loss_train: 0.004343, loss_test: 0.005544
time: 0.24805569648742676
time: 2.3185179233551025
[1, 24600] loss_train: 0.009801, loss_test: 0.005558
time: 0.26105761528015137
time: 2.290515184402466
[1, 24601] loss_train: 0.008488, loss_test: 0.005572
time: 0.25505685806274414
time: 2.2925119400024414
[1, 24602] loss_train: 0.010984, loss_test: 0.005589
time: 0.2470552921295166
time: 2.3015148639678955
[1, 24603] loss_train: 0.013402, loss_test: 0.005610
time: 0.2740609645843506
time: 2.356527328491211
[1, 24604] loss_train: 0.004759, loss_test: 0.005622
time: 0.2800614833831787
time: 2.3135175704956055
[1, 24605] loss_train: 0.013804, loss_test: 0.005633
time: 0.2540569305419922
time: 2.3275203704833984
[1, 24606] loss_train: 0.003216, loss_test: 0.005637
time: 0.24405384063720703
time: 2.241502046585083
[1, 24607] loss_train: 0.006921, loss_test: 0.005618
time: 0.31907153129577637
time: 2.2945127487182617
[1, 24608] loss_train: 0.003527, loss_test: 0.005595
time: 0.29306578636169434
time: 2.4570541381835938
[1, 24609] loss_train: 0.008174, loss_test: 0.005571
time: 0.2740609645843506
time: 2.5525705814361572
[1, 24610] loss_train: 0.007093, loss_test: 0.005556
time: 0.2630574703216553
time: 2.401538133621216
[1, 24611] loss_train: 0.006442, loss_test: 0.005550
time: 0.39908862113952637
time: 2.4075381755828857
[1, 24612] loss_train: 0.010021, loss_test: 0.005550
time: 0.30606842041015625
time: 2.299513816833496
[1, 24613] loss_train: 0.007517, loss_test: 0.005552
time: 0.2470555305480957
time: 2.3695297241210938
[1, 24614] loss_train: 0.004225, loss_test: 0.005558
time: 0.3310739994049072
time: 2.408538579940796
[1, 24615] loss_train: 0.011480, loss_test: 0.005562
time: 0.3740825653076172
time: 2.6505932807922363
[1, 24616] loss_train: 0.002011, loss_test: 0.005569
time: 0.2600581645965576
time: 2.582227945327759
[1, 24617] loss_train: 0.005009, loss_test: 0.005577
time: 0.2630593776702881
time: 2.5195627212524414
[1, 24618] loss_train: 0.005046, loss_test: 0.005585
time: 0.24405550956726074
time: 2.390533447265625
[1, 24619] loss_train: 0.001016, loss_test: 0.005594
time: 0.24205327033996582
time: 2.2975127696990967
[1, 24620] loss_train: 0.006311, loss_test: 0.005599
time: 0.25705623626708984
time: 2.2325000762939453
[1, 24621] loss_train: 0.003863, loss_test: 0.005605
time: 0.2510552406311035
time: 2.2475032806396484
[1, 24622] loss_train: 0.005785, loss_test: 0.005607
time: 0.24805450439453125
time: 2.423551321029663
[1, 24623] loss_train: 0.006610, loss_test: 0.005598
time: 0.3519630432128906
time: 2.5312235355377197
[1, 24624] loss_train: 0.005431, loss_test: 0.005587
time: 0.3410763740539551
time: 2.338522434234619
[1, 24625] loss_train: 0.002131, loss_test: 0.005579
time: 0.320070743560791
time: 2.5030624866485596
[1, 24626] loss_train: 0.005210, loss_test: 0.005568
time: 0.2830626964569092
time: 2.422544240951538
[1, 24627] loss_train: 0.007358, loss_test: 0.005556
time: 0.24405407905578613
time: 2.2975146770477295
[1, 24628] loss_train: 0.005557, loss_test: 0.005549
time: 0.2450542449951172
time: 2.2785093784332275
[1, 24629] loss_train: 0.006866, loss_test: 0.005542
time: 0.24405384063720703
time: 2.2855112552642822
[1, 24630] loss_train: 0.006780, loss_test: 0.005538
time: 0.2580583095550537
time: 2.355032444000244
[1, 24631] loss_train: 0.007185, loss_test: 0.005536
time: 0.27706098556518555
time: 2.3255205154418945
[1, 24632] loss_train: 0.011245, loss_test: 0.005537
time: 0.24405407905578613
time: 2.302525758743286
[1, 24633] loss_train: 0.005543, loss_test: 0.005543
time: 0.3090689182281494
time: 2.2925126552581787
[1, 24634] loss_train: 0.001348, loss_test: 0.005553
time: 0.24305415153503418
time: 2.25750470161438
[1, 24635] loss_train: 0.011326, loss_test: 0.005562
time: 0.24405455589294434
time: 2.37553071975708
[1, 24636] loss_train: 0.006320, loss_test: 0.005565
time: 0.25305652618408203
time: 2.238003969192505
[1, 24637] loss_train: 0.004013, loss_test: 0.005569
time: 0.25305604934692383
time: 2.268507242202759
[1, 24638] loss_train: 0.005782, loss_test: 0.005565
time: 0.24305486679077148
time: 2.2274975776672363
[1, 24639] loss_train: 0.004562, loss_test: 0.005554
time: 0.24505352973937988
time: 2.230499505996704
[1, 24640] loss_train: 0.012808, loss_test: 0.005541
time: 0.25905823707580566
time: 2.2565033435821533
[1, 24641] loss_train: 0.005980, loss_test: 0.005520
time: 0.2830631732940674
time: 2.2945313453674316
[1, 24642] loss_train: 0.008424, loss_test: 0.005507
time: 0.2510557174682617
time: 2.3625288009643555
[1, 24643] loss_train: 0.006787, loss_test: 0.005503
time: 0.24305367469787598
time: 2.294015884399414
[1, 24644] loss_train: 0.004135, loss_test: 0.005508
time: 0.24305391311645508
time: 2.2735092639923096
[1, 24645] loss_train: 0.006203, loss_test: 0.005519
time: 0.24005389213562012
time: 2.2545042037963867
[1, 24646] loss_train: 0.002164, loss_test: 0.005537
time: 0.25305676460266113
time: 2.3135221004486084
[1, 24647] loss_train: 0.009264, loss_test: 0.005557
time: 0.2450549602508545
time: 2.3075153827667236
[1, 24648] loss_train: 0.005865, loss_test: 0.005576
time: 0.2450549602508545
time: 2.3650994300842285
[1, 24649] loss_train: 0.010970, loss_test: 0.005564
time: 0.30606722831726074
time: 2.4055378437042236
[1, 24650] loss_train: 0.002978, loss_test: 0.005555
time: 0.267059326171875
time: 2.282519817352295
[1, 24651] loss_train: 0.003346, loss_test: 0.005550
time: 0.2470557689666748
time: 2.3395369052886963
[1, 24652] loss_train: 0.008118, loss_test: 0.005544
time: 0.267059326171875
time: 2.399536609649658
[1, 24653] loss_train: 0.001153, loss_test: 0.005542
time: 0.25705718994140625
time: 2.321519374847412
[1, 24654] loss_train: 0.004156, loss_test: 0.005539
time: 0.2580575942993164
time: 2.385533094406128
[1, 24655] loss_train: 0.006107, loss_test: 0.005535
time: 0.24805545806884766
time: 2.2675068378448486
[1, 24656] loss_train: 0.008541, loss_test: 0.005533
time: 0.24205470085144043
time: 2.3315231800079346
[1, 24657] loss_train: 0.001542, loss_test: 0.005531
time: 0.2580575942993164
time: 2.4035377502441406
[1, 24658] loss_train: 0.010027, loss_test: 0.005526
time: 0.2530558109283447
time: 2.3105173110961914
[1, 24659] loss_train: 0.003428, loss_test: 0.005523
time: 0.26105761528015137
time: 2.3075168132781982
[1, 24660] loss_train: 0.003686, loss_test: 0.005522
time: 0.26605844497680664
time: 2.443547010421753
[1, 24661] loss_train: 0.005939, loss_test: 0.005520
time: 0.25905847549438477
time: 2.427544355392456
[1, 24662] loss_train: 0.002196, loss_test: 0.005519
time: 0.24605417251586914
time: 2.4095418453216553
[1, 24663] loss_train: 0.009586, loss_test: 0.005516
time: 0.25005483627319336
time: 2.281513214111328
[1, 24664] loss_train: 0.005750, loss_test: 0.005513
time: 0.2620575428009033
time: 2.280510187149048
[1, 24665] loss_train: 0.004539, loss_test: 0.005511
time: 0.2450544834136963
time: 2.2475028038024902
[1, 24666] loss_train: 0.003739, loss_test: 0.005509
time: 0.2450542449951172
time: 2.2545063495635986
[1, 24667] loss_train: 0.000727, loss_test: 0.005507
time: 0.24605441093444824
time: 2.2515034675598145
[1, 24668] loss_train: 0.011242, loss_test: 0.005505
time: 0.24605584144592285
time: 2.2715070247650146
[1, 24669] loss_train: 0.003732, loss_test: 0.005505
time: 0.24605417251586914
time: 2.270508289337158
[1, 24670] loss_train: 0.002357, loss_test: 0.005506
time: 0.2560575008392334
time: 2.234499216079712
[1, 24671] loss_train: 0.008199, loss_test: 0.005504
time: 0.24405527114868164
time: 2.2405025959014893
[1, 24672] loss_train: 0.003317, loss_test: 0.005503
time: 0.24805474281311035
time: 2.269508123397827
[1, 24673] loss_train: 0.004650, loss_test: 0.005504
time: 0.24405431747436523
time: 2.2244975566864014
[1, 24674] loss_train: 0.003321, loss_test: 0.005508
time: 0.24205350875854492
time: 2.227498769760132
[1, 24675] loss_train: 0.007359, loss_test: 0.005511
time: 0.2510557174682617
time: 2.2915122509002686
[1, 24676] loss_train: 0.015013, loss_test: 0.005506
time: 0.2650594711303711
time: 2.361527919769287
[1, 24677] loss_train: 0.001609, loss_test: 0.005504
time: 0.2470550537109375
time: 2.3380563259124756
[1, 24678] loss_train: 0.003138, loss_test: 0.005504
time: 0.2450549602508545
time: 2.22249698638916
[1, 24679] loss_train: 0.000482, loss_test: 0.005505
time: 0.24205374717712402
time: 2.231499433517456
[1, 24680] loss_train: 0.001317, loss_test: 0.005509
time: 0.2720601558685303
time: 2.267507314682007
[1, 24681] loss_train: 0.011912, loss_test: 0.005508
time: 0.24405455589294434
time: 2.260505437850952
[1, 24682] loss_train: 0.013177, loss_test: 0.005507
time: 0.24505400657653809
time: 2.270508289337158
[1, 24683] loss_train: 0.010494, loss_test: 0.005507
time: 0.24405384063720703
time: 2.254504442214966
[1, 24684] loss_train: 0.004340, loss_test: 0.005510
time: 0.25005507469177246
time: 2.2505123615264893
[1, 24685] loss_train: 0.004618, loss_test: 0.005514
time: 0.24405527114868164
time: 2.2825098037719727
[1, 24686] loss_train: 0.014427, loss_test: 0.005517
time: 0.24505376815795898
time: 2.2765088081359863
[1, 24687] loss_train: 0.001920, loss_test: 0.005520
time: 0.24805545806884766
time: 2.242501735687256
[1, 24688] loss_train: 0.008615, loss_test: 0.005520
time: 0.25005602836608887
time: 2.2264978885650635
[1, 24689] loss_train: 0.002587, loss_test: 0.005519
time: 0.24605393409729004
time: 2.2605061531066895
[1, 24690] loss_train: 0.002460, loss_test: 0.005518
time: 0.2580571174621582
time: 2.2535042762756348
[1, 24691] loss_train: 0.011671, loss_test: 0.005517
time: 0.24205350875854492
time: 2.2475032806396484
[1, 24692] loss_train: 0.004657, loss_test: 0.005516
time: 0.25005507469177246
time: 2.2395009994506836
[1, 24693] loss_train: 0.002775, loss_test: 0.005517
time: 0.24305391311645508
time: 2.2745110988616943
[1, 24694] loss_train: 0.007370, loss_test: 0.005521
time: 0.24405360221862793
time: 2.242501974105835
[1, 24695] loss_train: 0.010640, loss_test: 0.005525
time: 0.24205327033996582
time: 2.282510995864868
[1, 24696] loss_train: 0.013424, loss_test: 0.005519
time: 0.24805474281311035
time: 2.2695069313049316
[1, 24697] loss_train: 0.007970, loss_test: 0.005514
time: 0.24405527114868164
time: 2.2855100631713867
[1, 24698] loss_train: 0.003879, loss_test: 0.005512
time: 0.2510559558868408
time: 2.259509801864624
[1, 24699] loss_train: 0.005041, loss_test: 0.005511
time: 0.24305295944213867
time: 2.2475032806396484
[1, 24700] loss_train: 0.001825, loss_test: 0.005513
time: 0.2620580196380615
time: 2.2535040378570557
[1, 24701] loss_train: 0.010246, loss_test: 0.005516
time: 0.2456822395324707
time: 2.2515041828155518
[1, 24702] loss_train: 0.005133, loss_test: 0.005518
time: 0.24405384063720703
time: 2.238517999649048
[1, 24703] loss_train: 0.003172, loss_test: 0.005521
time: 0.24305367469787598
time: 2.2375004291534424
[1, 24704] loss_train: 0.008585, loss_test: 0.005521
time: 0.2490556240081787
time: 2.2405006885528564
[1, 24705] loss_train: 0.001135, loss_test: 0.005521
time: 0.24305438995361328
time: 2.2475056648254395
[1, 24706] loss_train: 0.011060, loss_test: 0.005520
time: 0.2450542449951172
time: 2.2234978675842285
[1, 24707] loss_train: 0.005841, loss_test: 0.005518
time: 0.24205374717712402
time: 2.257504463195801
[1, 24708] loss_train: 0.005456, loss_test: 0.005518
time: 0.2470548152923584
time: 2.2755093574523926
[1, 24709] loss_train: 0.005136, loss_test: 0.005518
time: 0.24505400657653809
time: 2.3855388164520264
[1, 24710] loss_train: 0.003480, loss_test: 0.005520
time: 0.3240687847137451
time: 2.4015393257141113
[1, 24711] loss_train: 0.001698, loss_test: 0.005522
time: 0.2740626335144043
time: 2.390535354614258
[1, 24712] loss_train: 0.001094, loss_test: 0.005527
time: 0.2560560703277588
time: 2.271517038345337
[1, 24713] loss_train: 0.012299, loss_test: 0.005532
time: 0.24605417251586914
time: 2.259514570236206
[1, 24714] loss_train: 0.006467, loss_test: 0.005539
time: 0.24405407905578613
time: 2.2277886867523193
[1, 24715] loss_train: 0.004985, loss_test: 0.005545
time: 0.24805450439453125
time: 2.2485201358795166
[1, 24716] loss_train: 0.008436, loss_test: 0.005542
time: 0.24605822563171387
time: 2.271536350250244
[1, 24717] loss_train: 0.005344, loss_test: 0.005539
time: 0.24605393409729004
time: 2.2740375995635986
[1, 24718] loss_train: 0.002653, loss_test: 0.005534
time: 0.24388456344604492
time: 2.2696533203125
[1, 24719] loss_train: 0.008452, loss_test: 0.005530
time: 0.24882745742797852
time: 2.2380051612854004
[1, 24720] loss_train: 0.007291, loss_test: 0.005526
time: 0.26105761528015137
time: 2.275512456893921
[1, 24721] loss_train: 0.003327, loss_test: 0.005522
time: 0.2620577812194824
time: 2.4305434226989746
[1, 24722] loss_train: 0.004716, loss_test: 0.005521
time: 0.2540562152862549
time: 2.6384496688842773
[1, 24723] loss_train: 0.005325, loss_test: 0.005520
time: 0.25090718269348145
time: 2.368985891342163
[1, 24724] loss_train: 0.006818, loss_test: 0.005520
time: 0.2490370273590088
time: 2.388266086578369
[1, 24725] loss_train: 0.001618, loss_test: 0.005521
time: 0.27005982398986816
time: 2.371530055999756
[1, 24726] loss_train: 0.000969, loss_test: 0.005519
time: 0.3070683479309082
time: 2.3575284481048584
[1, 24727] loss_train: 0.005341, loss_test: 0.005520
time: 0.30606889724731445
time: 2.3580338954925537
[1, 24728] loss_train: 0.008106, loss_test: 0.005522
time: 0.24405407905578613
time: 2.406538963317871
[1, 24729] loss_train: 0.009341, loss_test: 0.005525
time: 0.25055813789367676
time: 2.3867809772491455
[1, 24730] loss_train: 0.003125, loss_test: 0.005529
time: 0.3000645637512207
time: 2.418541193008423
[1, 24731] loss_train: 0.004447, loss_test: 0.005533
time: 0.2830617427825928
time: 2.360671281814575
[1, 24732] loss_train: 0.008244, loss_test: 0.005531
time: 0.24609899520874023
time: 2.4105405807495117
[1, 24733] loss_train: 0.009545, loss_test: 0.005522
time: 0.27506256103515625
time: 2.33952260017395
[1, 24734] loss_train: 0.012320, loss_test: 0.005514
time: 0.2510557174682617
time: 2.295513391494751
[1, 24735] loss_train: 0.016914, loss_test: 0.005513
time: 0.2490551471710205
time: 2.305516242980957
[1, 24736] loss_train: 0.008309, loss_test: 0.005517
time: 0.24405455589294434
time: 2.23801326751709
[1, 24737] loss_train: 0.004683, loss_test: 0.005522
time: 0.2450542449951172
time: 2.253007173538208
[1, 24738] loss_train: 0.006721, loss_test: 0.005525
time: 0.24505376815795898
time: 2.244013786315918
[1, 24739] loss_train: 0.004223, loss_test: 0.005524
time: 0.2450544834136963
time: 2.3085169792175293
[1, 24740] loss_train: 0.004185, loss_test: 0.005522
time: 0.2617065906524658
time: 2.480031728744507
[1, 24741] loss_train: 0.004541, loss_test: 0.005515
time: 0.25505757331848145
time: 2.2805099487304688
[1, 24742] loss_train: 0.005773, loss_test: 0.005511
time: 0.2659339904785156
time: 2.3281333446502686
[1, 24743] loss_train: 0.001825, loss_test: 0.005505
time: 0.25705766677856445
time: 2.488564968109131
[1, 24744] loss_train: 0.004124, loss_test: 0.005503
time: 0.24405455589294434
time: 2.382532835006714
[1, 24745] loss_train: 0.002761, loss_test: 0.005506
time: 0.24783778190612793
time: 2.3790512084960938
[1, 24746] loss_train: 0.002900, loss_test: 0.005514
time: 0.2470548152923584
time: 2.2760133743286133
[1, 24747] loss_train: 0.000990, loss_test: 0.005524
time: 0.24305486679077148
time: 2.2869324684143066
[1, 24748] loss_train: 0.002582, loss_test: 0.005539
time: 0.25505614280700684
time: 2.3078103065490723
[1, 24749] loss_train: 0.004161, loss_test: 0.005554
time: 0.24954867362976074
time: 2.2872698307037354
[1, 24750] loss_train: 0.003950, loss_test: 0.005569
time: 0.2630648612976074
time: 2.280083417892456
[1, 24751] loss_train: 0.009367, loss_test: 0.005572
time: 0.25005555152893066
time: 2.2735087871551514
[1, 24752] loss_train: 0.001917, loss_test: 0.005574
time: 0.2576301097869873
time: 2.296513557434082
[1, 24753] loss_train: 0.004474, loss_test: 0.005571
time: 0.25005626678466797
time: 2.2535040378570557
[1, 24754] loss_train: 0.004053, loss_test: 0.005568
time: 0.2435598373413086
time: 2.222001314163208
[1, 24755] loss_train: 0.005204, loss_test: 0.005561
time: 0.24605512619018555
time: 2.243009328842163
[1, 24756] loss_train: 0.005573, loss_test: 0.005557
time: 0.25505757331848145
time: 2.2691047191619873
[1, 24757] loss_train: 0.003906, loss_test: 0.005554
time: 0.2450547218322754
time: 2.260861396789551
[1, 24758] loss_train: 0.001870, loss_test: 0.005549
time: 0.2480616569519043
time: 2.3531007766723633
[1, 24759] loss_train: 0.008060, loss_test: 0.005542
time: 0.24805474281311035
time: 2.2735085487365723
[1, 24760] loss_train: 0.000652, loss_test: 0.005539
time: 0.28806495666503906
time: 2.304936408996582
[1, 24761] loss_train: 0.005825, loss_test: 0.005537
time: 0.27486300468444824
time: 2.3090155124664307
[1, 24762] loss_train: 0.002859, loss_test: 0.005535
time: 0.24405765533447266
time: 2.2493791580200195
[1, 24763] loss_train: 0.003487, loss_test: 0.005534
time: 0.2530555725097656
time: 2.266011953353882
[1, 24764] loss_train: 0.009148, loss_test: 0.005529
time: 0.2430570125579834
time: 2.310518264770508
[1, 24765] loss_train: 0.012204, loss_test: 0.005519
time: 0.24805474281311035
time: 2.3544719219207764
[1, 24766] loss_train: 0.002509, loss_test: 0.005514
time: 0.24305295944213867
time: 2.2605061531066895
[1, 24767] loss_train: 0.012365, loss_test: 0.005514
time: 0.24805593490600586
time: 2.4375579357147217
[1, 24768] loss_train: 0.002112, loss_test: 0.005513
time: 0.24905633926391602
time: 2.3146305084228516
[1, 24769] loss_train: 0.009696, loss_test: 0.005514
time: 0.3030672073364258
time: 2.583577871322632
[1, 24770] loss_train: 0.012068, loss_test: 0.005514
time: 0.3760828971862793
time: 2.4320576190948486
[1, 24771] loss_train: 0.008676, loss_test: 0.005515
time: 0.24405407905578613
time: 2.3655285835266113
[1, 24772] loss_train: 0.003559, loss_test: 0.005516
time: 0.2510559558868408
time: 2.4295458793640137
[1, 24773] loss_train: 0.005092, loss_test: 0.005515
time: 0.2540557384490967
time: 2.2385005950927734
[1, 24774] loss_train: 0.006115, loss_test: 0.005513
time: 0.2490541934967041
time: 2.307516098022461
[1, 24775] loss_train: 0.013872, loss_test: 0.005514
time: 0.25305819511413574
time: 2.2585058212280273
[1, 24776] loss_train: 0.012511, loss_test: 0.005518
time: 0.2650585174560547
time: 2.409053087234497
[1, 24777] loss_train: 0.005229, loss_test: 0.005516
time: 0.2510554790496826
time: 2.393206834793091
[1, 24778] loss_train: 0.000585, loss_test: 0.005512
time: 0.24605464935302734
time: 2.5000391006469727
[1, 24779] loss_train: 0.002980, loss_test: 0.005508
time: 0.25859594345092773
time: 2.3386919498443604
[1, 24780] loss_train: 0.010539, loss_test: 0.005508
time: 0.26406121253967285
time: 2.3535385131835938
[1, 24781] loss_train: 0.004751, loss_test: 0.005509
time: 0.3210718631744385
time: 2.3985366821289062
[1, 24782] loss_train: 0.005109, loss_test: 0.005512
time: 0.25205564498901367
time: 2.28953218460083
[1, 24783] loss_train: 0.010198, loss_test: 0.005516
time: 0.2980659008026123
time: 2.4945719242095947
[1, 24784] loss_train: 0.011277, loss_test: 0.005521
time: 0.2450544834136963
time: 2.2321290969848633
[1, 24785] loss_train: 0.000837, loss_test: 0.005528
time: 0.24605488777160645
time: 2.2795097827911377
[1, 24786] loss_train: 0.005488, loss_test: 0.005533
time: 0.2430567741394043
time: 2.240636110305786
[1, 24787] loss_train: 0.007736, loss_test: 0.005538
time: 0.24706006050109863
time: 2.293539047241211
[1, 24788] loss_train: 0.009963, loss_test: 0.005540
time: 0.25740575790405273
time: 2.274019956588745
[1, 24789] loss_train: 0.010422, loss_test: 0.005535
time: 0.24405360221862793
time: 2.374533176422119
[1, 24790] loss_train: 0.001317, loss_test: 0.005533
time: 0.25905728340148926
time: 2.2760121822357178
[1, 24791] loss_train: 0.007733, loss_test: 0.005526
time: 0.24605512619018555
time: 2.257505178451538
[1, 24792] loss_train: 0.009666, loss_test: 0.005518
time: 0.2600572109222412
time: 2.313021659851074
[1, 24793] loss_train: 0.005172, loss_test: 0.005513
time: 0.25005435943603516
time: 2.391051769256592
[1, 24794] loss_train: 0.001610, loss_test: 0.005512
time: 0.25455522537231445
time: 2.286330461502075
[1, 24795] loss_train: 0.000615, loss_test: 0.005512
time: 0.2450566291809082
time: 2.2736082077026367
[1, 24796] loss_train: 0.002989, loss_test: 0.005510
time: 0.2419450283050537
time: 2.2780215740203857
[1, 24797] loss_train: 0.008418, loss_test: 0.005508
time: 0.24296927452087402
time: 2.2861297130584717
[1, 24798] loss_train: 0.003272, loss_test: 0.005506
time: 0.24998188018798828
time: 2.2765345573425293
[1, 24799] loss_train: 0.008280, loss_test: 0.005504
time: 0.25305628776550293
time: 2.231501579284668
[1, 24800] loss_train: 0.006995, loss_test: 0.005502
time: 0.26105761528015137
time: 2.255505084991455
[1, 24801] loss_train: 0.012047, loss_test: 0.005500
time: 0.24405384063720703
time: 2.294419288635254
[1, 24802] loss_train: 0.002203, loss_test: 0.005499
time: 0.24655866622924805
time: 2.2710301876068115
[1, 24803] loss_train: 0.003988, loss_test: 0.005500
time: 0.25305652618408203
time: 2.3155267238616943
[1, 24804] loss_train: 0.003329, loss_test: 0.005501
time: 0.258056640625
time: 2.2943811416625977
[1, 24805] loss_train: 0.004494, loss_test: 0.005504
time: 0.26205945014953613
time: 2.3712046146392822
[1, 24806] loss_train: 0.004982, loss_test: 0.005507
time: 0.24405407905578613
time: 2.3015167713165283
[1, 24807] loss_train: 0.000597, loss_test: 0.005513
time: 0.27706217765808105
time: 2.4265427589416504
[1, 24808] loss_train: 0.001996, loss_test: 0.005520
time: 0.26606011390686035
time: 2.4320099353790283
[1, 24809] loss_train: 0.001973, loss_test: 0.005532
time: 0.2630593776702881
time: 2.356527090072632
[1, 24810] loss_train: 0.004146, loss_test: 0.005542
time: 0.2910647392272949
time: 2.341531276702881
[1, 24811] loss_train: 0.010480, loss_test: 0.005537
time: 0.27205991744995117
time: 2.395040988922119
[1, 24812] loss_train: 0.011194, loss_test: 0.005527
time: 0.25809264183044434
time: 2.450557231903076
[1, 24813] loss_train: 0.013261, loss_test: 0.005519
time: 0.25705623626708984
time: 2.389042377471924
[1, 24814] loss_train: 0.010627, loss_test: 0.005514
time: 0.25105738639831543
time: 2.2909231185913086
[1, 24815] loss_train: 0.010111, loss_test: 0.005507
time: 0.25032615661621094
time: 2.3198065757751465
[1, 24816] loss_train: 0.006131, loss_test: 0.005505
time: 0.27768874168395996
time: 2.308525562286377
[1, 24817] loss_train: 0.007941, loss_test: 0.005505
time: 0.2580568790435791
time: 2.3085250854492188
[1, 24818] loss_train: 0.003673, loss_test: 0.005507
time: 0.27506041526794434
time: 2.288109302520752
[1, 24819] loss_train: 0.006026, loss_test: 0.005511
time: 0.25505638122558594
time: 2.377004384994507
[1, 24820] loss_train: 0.009986, loss_test: 0.005517
time: 0.2620580196380615
time: 2.3265204429626465
[1, 24821] loss_train: 0.010216, loss_test: 0.005523
time: 0.2560567855834961
time: 2.2758662700653076
[1, 24822] loss_train: 0.014976, loss_test: 0.005530
time: 0.25305819511413574
time: 2.2936201095581055
[1, 24823] loss_train: 0.004681, loss_test: 0.005535
time: 0.2870645523071289
time: 2.310516119003296
[1, 24824] loss_train: 0.004617, loss_test: 0.005537
time: 0.2920651435852051
time: 2.2495031356811523
[1, 24825] loss_train: 0.006208, loss_test: 0.005537
time: 0.24305367469787598
time: 2.260011672973633
[1, 24826] loss_train: 0.002377, loss_test: 0.005532
time: 0.24563956260681152
time: 2.3570339679718018
[1, 24827] loss_train: 0.004696, loss_test: 0.005528
time: 0.2740607261657715
time: 2.2939467430114746
[1, 24828] loss_train: 0.004304, loss_test: 0.005525
time: 0.2580571174621582
time: 2.2479209899902344
[1, 24829] loss_train: 0.011128, loss_test: 0.005522
time: 0.24232864379882812
time: 2.277765989303589
[1, 24830] loss_train: 0.006155, loss_test: 0.005521
time: 0.26158595085144043
time: 2.336026668548584
[1, 24831] loss_train: 0.007033, loss_test: 0.005521
time: 0.2540555000305176
time: 2.366529703140259
[1, 24832] loss_train: 0.003645, loss_test: 0.005522
time: 0.24405431747436523
time: 2.27051043510437
[1, 24833] loss_train: 0.003580, loss_test: 0.005522
time: 0.24505400657653809
time: 2.495957136154175
[1, 24834] loss_train: 0.006983, loss_test: 0.005523
time: 0.2600572109222412
time: 2.2990190982818604
[1, 24835] loss_train: 0.002273, loss_test: 0.005526
time: 0.2630581855773926
time: 2.2791054248809814
[1, 24836] loss_train: 0.009235, loss_test: 0.005533
time: 0.24505376815795898
time: 2.2565054893493652
[1, 24837] loss_train: 0.004908, loss_test: 0.005541
time: 0.2510552406311035
time: 2.2870171070098877
[1, 24838] loss_train: 0.010884, loss_test: 0.005544
time: 0.24505853652954102
time: 2.3032398223876953
[1, 24839] loss_train: 0.002080, loss_test: 0.005549
time: 0.2650597095489502
time: 2.340524911880493
[1, 24840] loss_train: 0.000616, loss_test: 0.005557
time: 0.27492308616638184
time: 2.386329174041748
[1, 24841] loss_train: 0.003766, loss_test: 0.005567
time: 0.2530701160430908
time: 2.3031840324401855
[1, 24842] loss_train: 0.005687, loss_test: 0.005569
time: 0.2557206153869629
time: 2.3305234909057617
[1, 24843] loss_train: 0.001665, loss_test: 0.005574
time: 0.2510557174682617
time: 2.24700665473938
[1, 24844] loss_train: 0.002608, loss_test: 0.005579
time: 0.2510552406311035
time: 2.28851318359375
[1, 24845] loss_train: 0.003134, loss_test: 0.005583
time: 0.25705599784851074
time: 2.381047487258911
[1, 24846] loss_train: 0.008717, loss_test: 0.005580
time: 0.2670588493347168
time: 2.2920403480529785
[1, 24847] loss_train: 0.005190, loss_test: 0.005574
time: 0.269059419631958
time: 2.5381722450256348
[1, 24848] loss_train: 0.005854, loss_test: 0.005560
time: 0.2490546703338623
time: 2.3905487060546875
[1, 24849] loss_train: 0.009390, loss_test: 0.005539
time: 0.36808133125305176
time: 2.588082790374756
[1, 24850] loss_train: 0.008277, loss_test: 0.005526
time: 0.26806020736694336
time: 2.317519187927246
[1, 24851] loss_train: 0.003028, loss_test: 0.005518
time: 0.24605488777160645
time: 2.257504940032959
[1, 24852] loss_train: 0.002878, loss_test: 0.005515
time: 0.2620575428009033
time: 2.29152250289917
[1, 24853] loss_train: 0.006851, loss_test: 0.005515
time: 0.2510552406311035
time: 2.316518545150757
[1, 24854] loss_train: 0.014163, loss_test: 0.005518
time: 0.24805450439453125
time: 2.319366216659546
[1, 24855] loss_train: 0.003068, loss_test: 0.005520
time: 0.24505400657653809
time: 2.4061944484710693
[1, 24856] loss_train: 0.004957, loss_test: 0.005520
time: 0.27706098556518555
time: 2.399179458618164
[1, 24857] loss_train: 0.005027, loss_test: 0.005519
time: 0.2450573444366455
time: 2.3525259494781494
[1, 24858] loss_train: 0.006968, loss_test: 0.005517
time: 0.25055909156799316
time: 2.291512966156006
[1, 24859] loss_train: 0.009810, loss_test: 0.005513
time: 0.25005578994750977
time: 2.2935123443603516
[1, 24860] loss_train: 0.005193, loss_test: 0.005510
time: 0.2710599899291992
time: 2.3570311069488525
[1, 24861] loss_train: 0.005461, loss_test: 0.005509
time: 0.2610585689544678
time: 2.3311495780944824
[1, 24862] loss_train: 0.009935, loss_test: 0.005508
time: 0.26605844497680664
time: 2.313530206680298
[1, 24863] loss_train: 0.009276, loss_test: 0.005507
time: 0.2610607147216797
time: 2.315462827682495
[1, 24864] loss_train: 0.001494, loss_test: 0.005508
time: 0.2506222724914551
time: 2.3154783248901367
[1, 24865] loss_train: 0.006394, loss_test: 0.005509
time: 0.24898147583007812
time: 2.2661192417144775
[1, 24866] loss_train: 0.012941, loss_test: 0.005507
time: 0.2580571174621582
time: 2.2875115871429443
[1, 24867] loss_train: 0.011501, loss_test: 0.005506
time: 0.25005578994750977
time: 2.2860145568847656
[1, 24868] loss_train: 0.006843, loss_test: 0.005508
time: 0.2470543384552002
time: 2.290513038635254
[1, 24869] loss_train: 0.003814, loss_test: 0.005510
time: 0.24805474281311035
time: 2.3025147914886475
[1, 24870] loss_train: 0.007487, loss_test: 0.005512
time: 0.2830634117126465
time: 2.4365460872650146
[1, 24871] loss_train: 0.004104, loss_test: 0.005509
time: 0.25305628776550293
time: 2.377016305923462
[1, 24872] loss_train: 0.002115, loss_test: 0.005509
time: 0.25506114959716797
time: 2.287360429763794
[1, 24873] loss_train: 0.001232, loss_test: 0.005512
time: 0.2600584030151367
time: 2.3820817470550537
[1, 24874] loss_train: 0.010659, loss_test: 0.005517
time: 0.24989676475524902
time: 2.2969987392425537
[1, 24875] loss_train: 0.003664, loss_test: 0.005525
time: 0.25505685806274414
time: 2.3505256175994873
[1, 24876] loss_train: 0.008987, loss_test: 0.005533
time: 0.2600579261779785
time: 2.3211793899536133
[1, 24877] loss_train: 0.004707, loss_test: 0.005532
time: 0.2530558109283447
time: 2.295017719268799
[1, 24878] loss_train: 0.000906, loss_test: 0.005542
time: 0.25005578994750977
time: 2.2948923110961914
[1, 24879] loss_train: 0.003577, loss_test: 0.005546
time: 0.2490544319152832
time: 2.2825112342834473
[1, 24880] loss_train: 0.009735, loss_test: 0.005547
time: 0.26405787467956543
time: 2.3825223445892334
[1, 24881] loss_train: 0.006770, loss_test: 0.005540
time: 0.3396732807159424
time: 2.4086356163024902
[1, 24882] loss_train: 0.006984, loss_test: 0.005530
time: 0.2520601749420166
time: 2.3425002098083496
[1, 24883] loss_train: 0.003588, loss_test: 0.005524
time: 0.3791365623474121
time: 2.51517391204834
[1, 24884] loss_train: 0.000783, loss_test: 0.005522
time: 0.26405763626098633
time: 2.3275234699249268
[1, 24885] loss_train: 0.003962, loss_test: 0.005522
time: 0.25305604934692383
time: 2.2920188903808594
[1, 24886] loss_train: 0.006218, loss_test: 0.005524
time: 0.2540552616119385
time: 2.3164472579956055
[1, 24887] loss_train: 0.002522, loss_test: 0.005524
time: 0.3160700798034668
time: 2.2889997959136963
[1, 24888] loss_train: 0.001831, loss_test: 0.005520
time: 0.2560575008392334
time: 2.300513982772827
[1, 24889] loss_train: 0.003079, loss_test: 0.005520
time: 0.3920407295227051
time: 2.337118148803711
[1, 24890] loss_train: 0.004013, loss_test: 0.005523
time: 0.27506041526794434
time: 2.311741590499878
[1, 24891] loss_train: 0.002462, loss_test: 0.005525
time: 0.25505709648132324
time: 2.3145196437835693
[1, 24892] loss_train: 0.001832, loss_test: 0.005528
time: 0.2490556240081787
time: 2.289825916290283
[1, 24893] loss_train: 0.014067, loss_test: 0.005528
time: 0.2600579261779785
time: 2.2777960300445557
[1, 24894] loss_train: 0.007176, loss_test: 0.005528
time: 0.25005507469177246
time: 2.3025150299072266
[1, 24895] loss_train: 0.003865, loss_test: 0.005530
time: 0.2490551471710205
time: 2.2829554080963135
[1, 24896] loss_train: 0.002574, loss_test: 0.005533
time: 0.24805474281311035
time: 2.302525758743286
[1, 24897] loss_train: 0.003460, loss_test: 0.005534
time: 0.2520561218261719
time: 2.4110426902770996
[1, 24898] loss_train: 0.002182, loss_test: 0.005536
time: 0.26456284523010254
time: 2.270012855529785
[1, 24899] loss_train: 0.009132, loss_test: 0.005538
time: 0.254056453704834
time: 2.3680336475372314
[1, 24900] loss_train: 0.004322, loss_test: 0.005537
time: 0.28406333923339844
time: 2.3600423336029053
[1, 24901] loss_train: 0.011114, loss_test: 0.005532
time: 0.252056360244751
time: 2.3215301036834717
[1, 24902] loss_train: 0.004959, loss_test: 0.005525
time: 0.28156614303588867
time: 2.3288228511810303
[1, 24903] loss_train: 0.002517, loss_test: 0.005520
time: 0.2720606327056885
time: 2.361459970474243
[1, 24904] loss_train: 0.002607, loss_test: 0.005517
time: 0.24905753135681152
time: 2.6550447940826416
[1, 24905] loss_train: 0.007796, loss_test: 0.005514
time: 0.25005578994750977
time: 2.319037437438965
[1, 24906] loss_train: 0.007729, loss_test: 0.005512
time: 0.2600572109222412
time: 2.2871479988098145
[1, 24907] loss_train: 0.003224, loss_test: 0.005510
time: 0.2490549087524414
time: 2.362529993057251
[1, 24908] loss_train: 0.011143, loss_test: 0.005508
time: 0.36403441429138184
time: 2.4924209117889404
[1, 24909] loss_train: 0.006724, loss_test: 0.005506
time: 0.27205944061279297
time: 2.319054126739502
[1, 24910] loss_train: 0.001314, loss_test: 0.005506
time: 0.2650578022003174
time: 2.3171255588531494
[1, 24911] loss_train: 0.006979, loss_test: 0.005506
time: 0.25756311416625977
time: 2.3224544525146484
[1, 24912] loss_train: 0.003181, loss_test: 0.005505
time: 0.25905728340148926
time: 2.3204126358032227
[1, 24913] loss_train: 0.006520, loss_test: 0.005505
time: 0.2510554790496826
time: 2.304715156555176
[1, 24914] loss_train: 0.007037, loss_test: 0.005508
time: 0.25103330612182617
time: 2.2885169982910156
[1, 24915] loss_train: 0.009167, loss_test: 0.005509
time: 0.2490549087524414
time: 2.2960174083709717
[1, 24916] loss_train: 0.006218, loss_test: 0.005511
time: 0.2540569305419922
time: 2.2695059776306152
[1, 24917] loss_train: 0.003627, loss_test: 0.005510
time: 0.24805474281311035
time: 2.293513536453247
[1, 24918] loss_train: 0.005391, loss_test: 0.005510
time: 0.2540576457977295
time: 2.2495040893554688
[1, 24919] loss_train: 0.002550, loss_test: 0.005511
time: 0.25205540657043457
time: 2.27101993560791
[1, 24920] loss_train: 0.008160, loss_test: 0.005511
time: 0.2720608711242676
time: 2.2563462257385254
[1, 24921] loss_train: 0.001950, loss_test: 0.005513
time: 0.24780654907226562
time: 2.2859907150268555
[1, 24922] loss_train: 0.008537, loss_test: 0.005512
time: 0.25505614280700684
time: 2.272351026535034
[1, 24923] loss_train: 0.007229, loss_test: 0.005511
time: 0.25298094749450684
time: 2.2857086658477783
[1, 24924] loss_train: 0.000472, loss_test: 0.005511
time: 0.25005578994750977
time: 2.273507595062256
[1, 24925] loss_train: 0.012580, loss_test: 0.005505
time: 0.2510569095611572
time: 2.282510757446289
[1, 24926] loss_train: 0.002045, loss_test: 0.005504
time: 0.24805474281311035
time: 2.2705330848693848
[1, 24927] loss_train: 0.011078, loss_test: 0.005503
time: 0.2505619525909424
time: 2.2883589267730713
[1, 24928] loss_train: 0.010226, loss_test: 0.005505
time: 0.25005531311035156
time: 2.292513370513916
[1, 24929] loss_train: 0.004455, loss_test: 0.005507
time: 0.2490544319152832
time: 2.2856802940368652
[1, 24930] loss_train: 0.012635, loss_test: 0.005508
time: 0.28856682777404785
time: 2.2916150093078613
[1, 24931] loss_train: 0.004621, loss_test: 0.005510
time: 0.26606082916259766
time: 2.272977590560913
[1, 24932] loss_train: 0.006199, loss_test: 0.005510
time: 0.2530207633972168
time: 2.2766096591949463
[1, 24933] loss_train: 0.005019, loss_test: 0.005510
time: 0.26105809211730957
time: 2.2810473442077637
[1, 24934] loss_train: 0.007662, loss_test: 0.005507
time: 0.24829316139221191
time: 2.257007598876953
[1, 24935] loss_train: 0.005377, loss_test: 0.005508
time: 0.2510554790496826
time: 2.298017978668213
[1, 24936] loss_train: 0.009055, loss_test: 0.005510
time: 0.2800617218017578
time: 2.3915352821350098
[1, 24937] loss_train: 0.002357, loss_test: 0.005510
time: 0.25205564498901367
time: 2.310549736022949
[1, 24938] loss_train: 0.003655, loss_test: 0.005511
time: 0.2630589008331299
time: 2.3221216201782227
[1, 24939] loss_train: 0.007842, loss_test: 0.005510
time: 0.2590615749359131
time: 2.2992968559265137
[1, 24940] loss_train: 0.005691, loss_test: 0.005509
time: 0.26805901527404785
time: 2.3324029445648193
[1, 24941] loss_train: 0.004320, loss_test: 0.005508
time: 0.25505733489990234
time: 2.34915828704834
[1, 24942] loss_train: 0.001923, loss_test: 0.005504
time: 0.2580564022064209
time: 2.278034210205078
[1, 24943] loss_train: 0.002142, loss_test: 0.005503
time: 0.24805450439453125
time: 2.2701783180236816
[1, 24944] loss_train: 0.002436, loss_test: 0.005505
time: 0.29506540298461914
time: 2.3555335998535156
[1, 24945] loss_train: 0.012372, loss_test: 0.005507
time: 0.2870643138885498
time: 2.3920373916625977
[1, 24946] loss_train: 0.008685, loss_test: 0.005508
time: 0.2883760929107666
time: 2.406614065170288
[1, 24947] loss_train: 0.006036, loss_test: 0.005510
time: 0.2443394660949707
time: 2.332526683807373
[1, 24948] loss_train: 0.014658, loss_test: 0.005509
time: 0.24958014488220215
time: 2.3675169944763184
[1, 24949] loss_train: 0.008311, loss_test: 0.005502
time: 0.2760646343231201
time: 2.2790255546569824
[1, 24950] loss_train: 0.005689, loss_test: 0.005500
time: 0.2740604877471924
time: 2.3152003288269043
[1, 24951] loss_train: 0.004976, loss_test: 0.005500
time: 0.26405882835388184
time: 2.3185179233551025
[1, 24952] loss_train: 0.007240, loss_test: 0.005503
time: 0.25305700302124023
time: 2.2895114421844482
[1, 24953] loss_train: 0.005837, loss_test: 0.005506
time: 0.24605441093444824
time: 2.2905113697052
[1, 24954] loss_train: 0.000963, loss_test: 0.005508
time: 0.26806044578552246
time: 2.311918020248413
[1, 24955] loss_train: 0.002923, loss_test: 0.005506
time: 0.24805593490600586
time: 2.286863088607788
[1, 24956] loss_train: 0.004653, loss_test: 0.005502
time: 0.24600982666015625
time: 2.3461763858795166
[1, 24957] loss_train: 0.015495, loss_test: 0.005501
time: 0.26805925369262695
time: 2.3801872730255127
[1, 24958] loss_train: 0.002618, loss_test: 0.005499
time: 0.269061803817749
time: 2.3324315547943115
[1, 24959] loss_train: 0.007248, loss_test: 0.005498
time: 0.24605393409729004
time: 2.2920172214508057
[1, 24960] loss_train: 0.006585, loss_test: 0.005499
time: 0.2780728340148926
time: 2.357536554336548
[1, 24961] loss_train: 0.006197, loss_test: 0.005502
time: 0.27006101608276367
time: 2.387533187866211
[1, 24962] loss_train: 0.007914, loss_test: 0.005506
time: 0.25705718994140625
time: 2.3255317211151123
[1, 24963] loss_train: 0.006195, loss_test: 0.005512
time: 0.25705885887145996
time: 2.339242696762085
[1, 24964] loss_train: 0.008381, loss_test: 0.005517
time: 0.28072476387023926
time: 2.364651679992676
[1, 24965] loss_train: 0.008549, loss_test: 0.005520
time: 0.26318860054016113
time: 2.343524694442749
[1, 24966] loss_train: 0.005554, loss_test: 0.005523
time: 0.2710602283477783
time: 2.287510633468628
[1, 24967] loss_train: 0.003614, loss_test: 0.005526
time: 0.2740609645843506
time: 2.3320255279541016
[1, 24968] loss_train: 0.012763, loss_test: 0.005526
time: 0.24805593490600586
time: 2.329981565475464
[1, 24969] loss_train: 0.004389, loss_test: 0.005525
time: 0.24805450439453125
time: 2.285923957824707
[1, 24970] loss_train: 0.001389, loss_test: 0.005522
time: 0.26405882835388184
time: 2.2675092220306396
[1, 24971] loss_train: 0.001603, loss_test: 0.005521
time: 0.2450542449951172
time: 2.3417296409606934
[1, 24972] loss_train: 0.004740, loss_test: 0.005521
time: 0.273223876953125
time: 2.4085450172424316
[1, 24973] loss_train: 0.001216, loss_test: 0.005523
time: 0.2450544834136963
time: 2.2740132808685303
[1, 24974] loss_train: 0.009151, loss_test: 0.005524
time: 0.2470541000366211
time: 2.5025634765625
[1, 24975] loss_train: 0.009245, loss_test: 0.005522
time: 0.2510561943054199
time: 2.337029457092285
[1, 24976] loss_train: 0.012023, loss_test: 0.005523
time: 0.2470550537109375
time: 2.2960169315338135
[1, 24977] loss_train: 0.009944, loss_test: 0.005521
time: 0.25705718994140625
time: 2.2800326347351074
[1, 24978] loss_train: 0.016282, loss_test: 0.005520
time: 0.2511172294616699
time: 2.2246832847595215
[1, 24979] loss_train: 0.002849, loss_test: 0.005520
time: 0.25505614280700684
time: 2.2780392169952393
[1, 24980] loss_train: 0.005850, loss_test: 0.005520
time: 0.2605133056640625
time: 2.317377805709839
[1, 24981] loss_train: 0.004295, loss_test: 0.005521
time: 0.2830626964569092
time: 2.3155364990234375
[1, 24982] loss_train: 0.001767, loss_test: 0.005524
time: 0.2470550537109375
time: 2.2365081310272217
[1, 24983] loss_train: 0.006055, loss_test: 0.005529
time: 0.24205374717712402
time: 2.242508888244629
[1, 24984] loss_train: 0.005599, loss_test: 0.005535
time: 0.24405431747436523
time: 2.272508382797241
[1, 24985] loss_train: 0.001934, loss_test: 0.005540
time: 0.24405455589294434
time: 2.222630023956299
[1, 24986] loss_train: 0.002527, loss_test: 0.005547
time: 0.24706363677978516
time: 2.252941131591797
[1, 24987] loss_train: 0.004877, loss_test: 0.005552
time: 0.24563169479370117
time: 2.2677500247955322
[1, 24988] loss_train: 0.001309, loss_test: 0.005560
time: 0.24205374717712402
time: 2.229003667831421
[1, 24989] loss_train: 0.007479, loss_test: 0.005565
time: 0.24605321884155273
time: 2.230498790740967
[1, 24990] loss_train: 0.001154, loss_test: 0.005569
time: 0.2620573043823242
time: 2.2370169162750244
[1, 24991] loss_train: 0.004850, loss_test: 0.005568
time: 0.2470550537109375
time: 2.258517265319824
[1, 24992] loss_train: 0.006128, loss_test: 0.005566
time: 0.2450544834136963
time: 2.2435014247894287
[1, 24993] loss_train: 0.010956, loss_test: 0.005564
time: 0.2470550537109375
time: 2.2329678535461426
[1, 24994] loss_train: 0.003067, loss_test: 0.005562
time: 0.24505376815795898
time: 2.2639458179473877
[1, 24995] loss_train: 0.007946, loss_test: 0.005561
time: 0.2510554790496826
time: 2.257018804550171
[1, 24996] loss_train: 0.009691, loss_test: 0.005551
time: 0.24305367469787598
time: 2.2568252086639404
[1, 24997] loss_train: 0.001383, loss_test: 0.005545
time: 0.24605345726013184
time: 2.234502077102661
[1, 24998] loss_train: 0.004674, loss_test: 0.005539
time: 0.2510554790496826
time: 2.241503953933716
[1, 24999] loss_train: 0.013079, loss_test: 0.005525
time: 0.2455580234527588
time: 2.2375123500823975
[1, 25000] loss_train: 0.009278, loss_test: 0.005510
time: 0.26605868339538574
time: 2.25300931930542
[1, 25001] loss_train: 0.006093, loss_test: 0.005503
time: 0.24605441093444824
time: 2.256504774093628
[1, 25002] loss_train: 0.003935, loss_test: 0.005501
time: 0.24205374717712402
time: 2.249039888381958
[1, 25003] loss_train: 0.001408, loss_test: 0.005504
time: 0.25305652618408203
time: 2.2329652309417725
[1, 25004] loss_train: 0.012366, loss_test: 0.005508
time: 0.24409008026123047
time: 2.2600796222686768
[1, 25005] loss_train: 0.003724, loss_test: 0.005510
time: 0.24405384063720703
time: 2.255504608154297
[1, 25006] loss_train: 0.006405, loss_test: 0.005513
time: 0.2430572509765625
time: 2.2362921237945557
[1, 25007] loss_train: 0.007399, loss_test: 0.005515
time: 0.2490553855895996
time: 2.2540314197540283
[1, 25008] loss_train: 0.006287, loss_test: 0.005515
time: 0.24305367469787598
time: 2.253007650375366
[1, 25009] loss_train: 0.004193, loss_test: 0.005511
time: 0.24605607986450195
time: 2.2805123329162598
[1, 25010] loss_train: 0.007503, loss_test: 0.005509
time: 0.25505685806274414
time: 2.219496250152588
[1, 25011] loss_train: 0.005079, loss_test: 0.005505
time: 0.24605727195739746
time: 2.2470054626464844
[1, 25012] loss_train: 0.013506, loss_test: 0.005505
time: 0.24305391311645508
time: 2.241629123687744
[1, 25013] loss_train: 0.004334, loss_test: 0.005506
time: 0.2470567226409912
time: 2.2330029010772705
[1, 25014] loss_train: 0.000735, loss_test: 0.005511
time: 0.24424457550048828
time: 2.261586904525757
[1, 25015] loss_train: 0.011150, loss_test: 0.005516
time: 0.26405906677246094
time: 2.255505084991455
[1, 25016] loss_train: 0.005847, loss_test: 0.005523
time: 0.2455580234527588
time: 2.234499931335449
[1, 25017] loss_train: 0.003281, loss_test: 0.005532
time: 0.2490551471710205
time: 2.2430076599121094
[1, 25018] loss_train: 0.004717, loss_test: 0.005541
time: 0.24605417251586914
time: 2.2535042762756348
[1, 25019] loss_train: 0.005971, loss_test: 0.005541
time: 0.25205564498901367
time: 2.2485029697418213
[1, 25020] loss_train: 0.007073, loss_test: 0.005535
time: 0.2630584239959717
time: 2.2442586421966553
[1, 25021] loss_train: 0.007869, loss_test: 0.005528
time: 0.2510552406311035
time: 2.261565923690796
[1, 25022] loss_train: 0.002167, loss_test: 0.005525
time: 0.24205350875854492
time: 2.247230291366577
[1, 25023] loss_train: 0.009424, loss_test: 0.005522
time: 0.2567746639251709
time: 2.248505115509033
[1, 25024] loss_train: 0.005125, loss_test: 0.005522
time: 0.2510550022125244
time: 2.2456471920013428
[1, 25025] loss_train: 0.003841, loss_test: 0.005523
time: 0.24734735488891602
time: 2.2610135078430176
[1, 25026] loss_train: 0.005515, loss_test: 0.005522
time: 0.24206185340881348
time: 2.233159065246582
[1, 25027] loss_train: 0.001801, loss_test: 0.005522
time: 0.2540590763092041
time: 2.2465033531188965
[1, 25028] loss_train: 0.003162, loss_test: 0.005522
time: 0.24305438995361328
time: 2.2600080966949463
[1, 25029] loss_train: 0.008976, loss_test: 0.005520
time: 0.25705671310424805
time: 2.33402419090271
[1, 25030] loss_train: 0.001859, loss_test: 0.005520
time: 0.2580583095550537
time: 2.2285029888153076
[1, 25031] loss_train: 0.005895, loss_test: 0.005519
time: 0.24605464935302734
time: 2.2425014972686768
[1, 25032] loss_train: 0.001256, loss_test: 0.005518
time: 0.2435591220855713
time: 2.2450034618377686
[1, 25033] loss_train: 0.002724, loss_test: 0.005521
time: 0.2505612373352051
time: 2.239734649658203
[1, 25034] loss_train: 0.004160, loss_test: 0.005525
time: 0.24707269668579102
time: 2.2426271438598633
[1, 25035] loss_train: 0.001175, loss_test: 0.005534
time: 0.2540562152862549
time: 2.233502149581909
[1, 25036] loss_train: 0.005250, loss_test: 0.005540
time: 0.24305391311645508
time: 2.2535040378570557
[1, 25037] loss_train: 0.011665, loss_test: 0.005534
time: 0.2470545768737793
time: 2.2605063915252686
[1, 25038] loss_train: 0.008349, loss_test: 0.005522
time: 0.27306365966796875
time: 2.272012710571289
[1, 25039] loss_train: 0.001648, loss_test: 0.005516
time: 0.2520558834075928
time: 2.2520499229431152
[1, 25040] loss_train: 0.004440, loss_test: 0.005514
time: 0.25705695152282715
time: 2.2448062896728516
[1, 25041] loss_train: 0.003273, loss_test: 0.005515
time: 0.2510557174682617
time: 2.312521457672119
[1, 25042] loss_train: 0.003912, loss_test: 0.005517
time: 0.24605441093444824
time: 2.3033299446105957
[1, 25043] loss_train: 0.005418, loss_test: 0.005520
time: 0.25505685806274414
time: 2.254007339477539
[1, 25044] loss_train: 0.008533, loss_test: 0.005525
time: 0.24105381965637207
time: 2.2530088424682617
[1, 25045] loss_train: 0.006743, loss_test: 0.005530
time: 0.24505352973937988
time: 2.254009485244751
[1, 25046] loss_train: 0.004116, loss_test: 0.005532
time: 0.24305367469787598
time: 2.2495033740997314
[1, 25047] loss_train: 0.006928, loss_test: 0.005532
time: 0.24455761909484863
time: 2.278974771499634
[1, 25048] loss_train: 0.001684, loss_test: 0.005533
time: 0.24105453491210938
time: 2.2756400108337402
[1, 25049] loss_train: 0.010074, loss_test: 0.005528
time: 0.24608421325683594
time: 2.311769723892212
[1, 25050] loss_train: 0.005052, loss_test: 0.005523
time: 0.2727193832397461
time: 2.2698028087615967
[1, 25051] loss_train: 0.007032, loss_test: 0.005521
time: 0.24805569648742676
time: 2.250495195388794
[1, 25052] loss_train: 0.003618, loss_test: 0.005518
time: 0.24205374717712402
time: 2.322521686553955
[1, 25053] loss_train: 0.004222, loss_test: 0.005514
time: 0.2470555305480957
time: 2.266507148742676
[1, 25054] loss_train: 0.008755, loss_test: 0.005513
time: 0.2560570240020752
time: 2.2620089054107666
[1, 25055] loss_train: 0.006425, loss_test: 0.005512
time: 0.2450542449951172
time: 2.2651095390319824
[1, 25056] loss_train: 0.007844, loss_test: 0.005510
time: 0.2490551471710205
time: 2.252781867980957
[1, 25057] loss_train: 0.005459, loss_test: 0.005513
time: 0.24205446243286133
time: 2.2775185108184814
[1, 25058] loss_train: 0.007678, loss_test: 0.005517
time: 0.2670598030090332
time: 2.290224075317383
[1, 25059] loss_train: 0.000703, loss_test: 0.005522
time: 0.25949859619140625
time: 2.274867057800293
[1, 25060] loss_train: 0.004552, loss_test: 0.005527
time: 0.260059118270874
time: 2.3076250553131104
[1, 25061] loss_train: 0.008235, loss_test: 0.005533
time: 0.24405360221862793
time: 2.299464702606201
[1, 25062] loss_train: 0.005941, loss_test: 0.005532
time: 0.29306554794311523
time: 2.3464503288269043
[1, 25063] loss_train: 0.019944, loss_test: 0.005523
time: 0.24605512619018555
time: 2.2843735218048096
[1, 25064] loss_train: 0.011505, loss_test: 0.005515
time: 0.24205374717712402
time: 2.26853609085083
[1, 25065] loss_train: 0.006391, loss_test: 0.005510
time: 0.24305510520935059
time: 2.2440176010131836
[1, 25066] loss_train: 0.001641, loss_test: 0.005508
time: 0.2720603942871094
time: 2.288025140762329
[1, 25067] loss_train: 0.005070, loss_test: 0.005506
time: 0.25005626678466797
time: 2.3310344219207764
[1, 25068] loss_train: 0.008796, loss_test: 0.005509
time: 0.24605464935302734
time: 2.257505416870117
[1, 25069] loss_train: 0.003721, loss_test: 0.005516
time: 0.2930643558502197
time: 2.2633955478668213
[1, 25070] loss_train: 0.005686, loss_test: 0.005520
time: 0.2566497325897217
time: 2.2775089740753174
[1, 25071] loss_train: 0.008172, loss_test: 0.005523
time: 0.24605464935302734
time: 2.2559380531311035
[1, 25072] loss_train: 0.004636, loss_test: 0.005527
time: 0.2502009868621826
time: 2.291388988494873
[1, 25073] loss_train: 0.002712, loss_test: 0.005534
time: 0.24805474281311035
time: 2.233502149581909
[1, 25074] loss_train: 0.000608, loss_test: 0.005543
time: 0.24705767631530762
time: 2.282517433166504
[1, 25075] loss_train: 0.001549, loss_test: 0.005556
time: 0.24305343627929688
time: 2.3115193843841553
[1, 25076] loss_train: 0.004734, loss_test: 0.005557
time: 0.24405407905578613
time: 2.256437063217163
[1, 25077] loss_train: 0.003747, loss_test: 0.005558
time: 0.26805925369262695
time: 2.3015148639678955
[1, 25078] loss_train: 0.008325, loss_test: 0.005555
time: 0.24405384063720703
time: 2.256402015686035
[1, 25079] loss_train: 0.012341, loss_test: 0.005549
time: 0.24305367469787598
time: 2.2957727909088135
[1, 25080] loss_train: 0.004678, loss_test: 0.005543
time: 0.283062219619751
time: 2.365565061569214
[1, 25081] loss_train: 0.003163, loss_test: 0.005538
time: 0.25505900382995605
time: 2.2266862392425537
[1, 25082] loss_train: 0.005278, loss_test: 0.005532
time: 0.2469162940979004
time: 2.297999858856201
[1, 25083] loss_train: 0.003530, loss_test: 0.005529
time: 0.2470550537109375
time: 2.2314984798431396
[1, 25084] loss_train: 0.002171, loss_test: 0.005530
time: 0.2850632667541504
time: 2.294513702392578
[1, 25085] loss_train: 0.002386, loss_test: 0.005529
time: 0.24605441093444824
time: 2.255504608154297
[1, 25086] loss_train: 0.006958, loss_test: 0.005529
time: 0.24405407905578613
time: 2.2660322189331055
[1, 25087] loss_train: 0.008800, loss_test: 0.005525
time: 0.2690606117248535
time: 2.381967306137085
[1, 25088] loss_train: 0.005741, loss_test: 0.005521
time: 0.2490553855895996
time: 2.286646842956543
[1, 25089] loss_train: 0.003328, loss_test: 0.005520
time: 0.25005626678466797
time: 2.2805094718933105
[1, 25090] loss_train: 0.003432, loss_test: 0.005519
time: 0.25905728340148926
time: 2.26279354095459
[1, 25091] loss_train: 0.000672, loss_test: 0.005518
time: 0.24500823020935059
time: 2.260913610458374
[1, 25092] loss_train: 0.008685, loss_test: 0.005516
time: 0.2440943717956543
time: 2.292978048324585
[1, 25093] loss_train: 0.013285, loss_test: 0.005513
time: 0.24500346183776855
time: 2.2569828033447266
[1, 25094] loss_train: 0.012330, loss_test: 0.005511
time: 0.25002026557922363
time: 2.271989345550537
[1, 25095] loss_train: 0.004861, loss_test: 0.005512
time: 0.2490558624267578
time: 2.258990526199341
[1, 25096] loss_train: 0.005594, loss_test: 0.005513
time: 0.2470548152923584
time: 2.3945350646972656
[1, 25097] loss_train: 0.003639, loss_test: 0.005513
time: 0.2450547218322754
time: 2.222505807876587
[1, 25098] loss_train: 0.004418, loss_test: 0.005513
time: 0.24305343627929688
time: 2.2681546211242676
[1, 25099] loss_train: 0.008489, loss_test: 0.005513
time: 0.2560567855834961
time: 2.2445383071899414
[1, 25100] loss_train: 0.002445, loss_test: 0.005512
time: 0.26105785369873047
time: 2.4745922088623047
[1, 25101] loss_train: 0.006798, loss_test: 0.005511
time: 0.2490546703338623
time: 2.2605059146881104
[1, 25102] loss_train: 0.001423, loss_test: 0.005510
time: 0.24205398559570312
time: 2.255195140838623
[1, 25103] loss_train: 0.002218, loss_test: 0.005507
time: 0.2490553855895996
time: 2.3883957862854004
[1, 25104] loss_train: 0.006445, loss_test: 0.005506
time: 0.2630586624145508
time: 2.2506794929504395
[1, 25105] loss_train: 0.007642, loss_test: 0.005506
time: 0.24505329132080078
time: 2.3278653621673584
[1, 25106] loss_train: 0.014632, loss_test: 0.005506
time: 0.2690601348876953
time: 2.498314619064331
[1, 25107] loss_train: 0.006389, loss_test: 0.005505
time: 0.25600194931030273
time: 2.630214214324951
[1, 25108] loss_train: 0.005973, loss_test: 0.005505
time: 0.378084659576416
time: 2.368303060531616
[1, 25109] loss_train: 0.002845, loss_test: 0.005506
time: 0.2450549602508545
time: 2.2992630004882812
[1, 25110] loss_train: 0.013745, loss_test: 0.005506
time: 0.3160696029663086
time: 2.345525026321411
[1, 25111] loss_train: 0.009780, loss_test: 0.005505
time: 0.2630574703216553
time: 2.256131649017334
[1, 25112] loss_train: 0.004585, loss_test: 0.005502
time: 0.25905847549438477
time: 2.46425461769104
[1, 25113] loss_train: 0.003071, loss_test: 0.005500
time: 0.25197815895080566
time: 2.2649543285369873
[1, 25114] loss_train: 0.004295, loss_test: 0.005498
time: 0.24297022819519043
time: 2.260028123855591
[1, 25115] loss_train: 0.005594, loss_test: 0.005497
time: 0.24296212196350098
time: 2.4445114135742188
[1, 25116] loss_train: 0.001653, loss_test: 0.005496
time: 0.24405384063720703
time: 2.2777440547943115
[1, 25117] loss_train: 0.002008, loss_test: 0.005495
time: 0.24305391311645508
time: 2.2685070037841797
[1, 25118] loss_train: 0.009118, loss_test: 0.005495
time: 0.24605560302734375
time: 2.259505033493042
[1, 25119] loss_train: 0.000683, loss_test: 0.005495
time: 0.24405407905578613
time: 2.2765090465545654
[1, 25120] loss_train: 0.007526, loss_test: 0.005496
time: 0.25705742835998535
time: 2.2309563159942627
[1, 25121] loss_train: 0.003611, loss_test: 0.005497
time: 0.24760794639587402
time: 2.398383378982544
[1, 25122] loss_train: 0.013768, loss_test: 0.005496
time: 0.24805498123168945
time: 2.3399345874786377
[1, 25123] loss_train: 0.001124, loss_test: 0.005496
time: 0.2435314655303955
time: 2.3105318546295166
[1, 25124] loss_train: 0.008926, loss_test: 0.005496
time: 0.2620580196380615
time: 2.2595057487487793
[1, 25125] loss_train: 0.006052, loss_test: 0.005497
time: 0.24805855751037598
time: 2.2405011653900146
[1, 25126] loss_train: 0.004347, loss_test: 0.005498
time: 0.2510554790496826
time: 2.239501714706421
[1, 25127] loss_train: 0.011753, loss_test: 0.005500
time: 0.24405407905578613
time: 2.2395009994506836
[1, 25128] loss_train: 0.013927, loss_test: 0.005507
time: 0.2490549087524414
time: 2.2729744911193848
[1, 25129] loss_train: 0.004413, loss_test: 0.005515
time: 0.24905753135681152
time: 2.2583224773406982
[1, 25130] loss_train: 0.003931, loss_test: 0.005521
time: 0.3110692501068115
time: 2.261380434036255
[1, 25131] loss_train: 0.002811, loss_test: 0.005522
time: 0.2438490390777588
time: 2.4825096130371094
[1, 25132] loss_train: 0.004035, loss_test: 0.005524
time: 0.24605441093444824
time: 2.223497152328491
[1, 25133] loss_train: 0.004759, loss_test: 0.005526
time: 0.24305415153503418
time: 2.272507667541504
[1, 25134] loss_train: 0.007592, loss_test: 0.005524
time: 0.24405384063720703
time: 2.358124256134033
[1, 25135] loss_train: 0.010440, loss_test: 0.005519
time: 0.2450544834136963
time: 2.3645291328430176
[1, 25136] loss_train: 0.006260, loss_test: 0.005514
time: 0.2470550537109375
time: 2.286511182785034
[1, 25137] loss_train: 0.004785, loss_test: 0.005509
time: 0.2520561218261719
time: 2.3459372520446777
[1, 25138] loss_train: 0.011650, loss_test: 0.005509
time: 0.24605441093444824
time: 2.2492833137512207
[1, 25139] loss_train: 0.002894, loss_test: 0.005514
time: 0.2540602684020996
time: 2.4698245525360107
[1, 25140] loss_train: 0.009416, loss_test: 0.005521
time: 0.34633874893188477
time: 2.449549913406372
[1, 25141] loss_train: 0.003652, loss_test: 0.005528
time: 0.24805426597595215
time: 2.2715089321136475
[1, 25142] loss_train: 0.002937, loss_test: 0.005537
time: 0.2760615348815918
time: 2.37011981010437
[1, 25143] loss_train: 0.000906, loss_test: 0.005549
time: 0.25905680656433105
time: 2.4627764225006104
[1, 25144] loss_train: 0.007444, loss_test: 0.005556
time: 0.24805498123168945
time: 2.2578494548797607
[1, 25145] loss_train: 0.005075, loss_test: 0.005561
time: 0.25388646125793457
time: 2.2402524948120117
[1, 25146] loss_train: 0.002676, loss_test: 0.005568
time: 0.24405360221862793
time: 2.2495086193084717
[1, 25147] loss_train: 0.003063, loss_test: 0.005575
time: 0.24905705451965332
time: 2.243576765060425
[1, 25148] loss_train: 0.002108, loss_test: 0.005583
time: 0.24701523780822754
time: 2.2480103969573975
[1, 25149] loss_train: 0.008869, loss_test: 0.005585
time: 0.2510104179382324
time: 2.275665521621704
[1, 25150] loss_train: 0.002289, loss_test: 0.005587
time: 0.2690598964691162
time: 2.374546527862549
[1, 25151] loss_train: 0.009819, loss_test: 0.005566
time: 0.25305676460266113
time: 2.2675070762634277
[1, 25152] loss_train: 0.007630, loss_test: 0.005544
time: 0.24405407905578613
time: 2.2545063495635986
[1, 25153] loss_train: 0.004294, loss_test: 0.005528
time: 0.252056360244751
time: 2.3145179748535156
[1, 25154] loss_train: 0.000524, loss_test: 0.005517
time: 0.24305391311645508
time: 2.3665287494659424
[1, 25155] loss_train: 0.006074, loss_test: 0.005508
time: 0.24805593490600586
time: 2.3041698932647705
[1, 25156] loss_train: 0.003089, loss_test: 0.005501
time: 0.2498314380645752
time: 2.335416316986084
[1, 25157] loss_train: 0.004676, loss_test: 0.005499
time: 0.24305438995361328
time: 2.239840269088745
[1, 25158] loss_train: 0.005427, loss_test: 0.005497
time: 0.24703049659729004
time: 2.238959550857544
[1, 25159] loss_train: 0.002806, loss_test: 0.005498
time: 0.2450258731842041
time: 2.258545160293579
[1, 25160] loss_train: 0.013646, loss_test: 0.005497
time: 0.2710597515106201
time: 2.2765092849731445
[1, 25161] loss_train: 0.011072, loss_test: 0.005497
time: 0.24405431747436523
time: 2.267850875854492
[1, 25162] loss_train: 0.002582, loss_test: 0.005497
time: 0.25005483627319336
time: 2.249011754989624
[1, 25163] loss_train: 0.005443, loss_test: 0.005496
time: 0.24405384063720703
time: 2.2270023822784424
[1, 25164] loss_train: 0.016768, loss_test: 0.005496
time: 0.25005507469177246
time: 2.2525041103363037
[1, 25165] loss_train: 0.005229, loss_test: 0.005497
time: 0.24205422401428223
time: 2.2379584312438965
[1, 25166] loss_train: 0.010051, loss_test: 0.005501
time: 0.2450547218322754
time: 2.246171712875366
[1, 25167] loss_train: 0.007996, loss_test: 0.005504
time: 0.2418968677520752
time: 2.224041700363159
[1, 25168] loss_train: 0.004511, loss_test: 0.005507
time: 0.2470548152923584
time: 2.2271995544433594
[1, 25169] loss_train: 0.003837, loss_test: 0.005506
time: 0.24305486679077148
time: 2.241501808166504
[1, 25170] loss_train: 0.004380, loss_test: 0.005507
time: 0.258056640625
time: 2.2399518489837646
[1, 25171] loss_train: 0.005740, loss_test: 0.005507
time: 0.24405455589294434
time: 2.257941246032715
[1, 25172] loss_train: 0.009032, loss_test: 0.005509
time: 0.2478020191192627
time: 2.2415311336517334
[1, 25173] loss_train: 0.008480, loss_test: 0.005509
time: 0.24805426597595215
time: 2.31183123588562
[1, 25174] loss_train: 0.004063, loss_test: 0.005508
time: 0.24801111221313477
time: 2.2698254585266113
[1, 25175] loss_train: 0.004683, loss_test: 0.005508
time: 0.24605464935302734
time: 2.3279480934143066
[1, 25176] loss_train: 0.004374, loss_test: 0.005509
time: 0.2580575942993164
time: 2.2260169982910156
[1, 25177] loss_train: 0.011537, loss_test: 0.005513
time: 0.2470569610595703
time: 2.2413952350616455
[1, 25178] loss_train: 0.005425, loss_test: 0.005515
time: 0.24806666374206543
time: 2.252336025238037
[1, 25179] loss_train: 0.002577, loss_test: 0.005517
time: 0.24305438995361328
time: 2.2655317783355713
[1, 25180] loss_train: 0.001394, loss_test: 0.005520
time: 0.2698371410369873
time: 2.2986462116241455
[1, 25181] loss_train: 0.003885, loss_test: 0.005521
time: 0.25005555152893066
time: 2.272508144378662
[1, 25182] loss_train: 0.008386, loss_test: 0.005523
time: 0.2520561218261719
time: 2.264508008956909
[1, 25183] loss_train: 0.006625, loss_test: 0.005525
time: 0.24405455589294434
time: 2.2400059700012207
[1, 25184] loss_train: 0.010886, loss_test: 0.005526
time: 0.2510552406311035
time: 2.2395009994506836
[1, 25185] loss_train: 0.002458, loss_test: 0.005527
time: 0.24405431747436523
time: 2.2460076808929443
[1, 25186] loss_train: 0.006352, loss_test: 0.005528
time: 0.24205303192138672
time: 2.2269482612609863
[1, 25187] loss_train: 0.007687, loss_test: 0.005529
time: 0.24305367469787598
time: 2.2511589527130127
[1, 25188] loss_train: 0.001462, loss_test: 0.005533
time: 0.2470545768737793
time: 2.2130346298217773
[1, 25189] loss_train: 0.004303, loss_test: 0.005537
time: 0.24400615692138672
time: 2.2409605979919434
[1, 25190] loss_train: 0.000830, loss_test: 0.005542
time: 0.2618846893310547
time: 2.232815980911255
[1, 25191] loss_train: 0.001954, loss_test: 0.005551
time: 0.24605512619018555
time: 2.3656132221221924
[1, 25192] loss_train: 0.007809, loss_test: 0.005556
time: 0.24405407905578613
time: 2.2254974842071533
[1, 25193] loss_train: 0.003468, loss_test: 0.005561
time: 0.2470557689666748
time: 2.284510612487793
[1, 25194] loss_train: 0.011809, loss_test: 0.005555
time: 0.2540569305419922
time: 2.2234995365142822
[1, 25195] loss_train: 0.012394, loss_test: 0.005535
time: 0.24305462837219238
time: 2.2642972469329834
[1, 25196] loss_train: 0.003289, loss_test: 0.005523
time: 0.24314641952514648
time: 2.2602949142456055
[1, 25197] loss_train: 0.003887, loss_test: 0.005517
time: 0.24616599082946777
time: 2.2469887733459473
[1, 25198] loss_train: 0.003436, loss_test: 0.005514
time: 0.24501299858093262
time: 2.2169480323791504
[1, 25199] loss_train: 0.003768, loss_test: 0.005514
time: 0.24384665489196777
time: 2.27988338470459
[1, 25200] loss_train: 0.006255, loss_test: 0.005517
time: 0.26805996894836426
time: 2.261505126953125
[1, 25201] loss_train: 0.007149, loss_test: 0.005520
time: 0.24805450439453125
time: 2.2615063190460205
[1, 25202] loss_train: 0.005986, loss_test: 0.005521
time: 0.24305438995361328
time: 2.2139973640441895
[1, 25203] loss_train: 0.010947, loss_test: 0.005523
time: 0.24205446243286133
time: 2.2264974117279053
[1, 25204] loss_train: 0.006546, loss_test: 0.005523
time: 0.2540562152862549
time: 2.2275032997131348
[1, 25205] loss_train: 0.009182, loss_test: 0.005524
time: 0.2540585994720459
time: 2.2565042972564697
[1, 25206] loss_train: 0.008854, loss_test: 0.005527
time: 0.2490558624267578
time: 2.2552382946014404
[1, 25207] loss_train: 0.009234, loss_test: 0.005529
time: 0.2442002296447754
time: 2.2719154357910156
[1, 25208] loss_train: 0.008166, loss_test: 0.005533
time: 0.24460124969482422
time: 2.211494207382202
[1, 25209] loss_train: 0.004275, loss_test: 0.005536
time: 0.24305438995361328
time: 2.249616861343384
[1, 25210] loss_train: 0.006960, loss_test: 0.005539
time: 0.26105833053588867
time: 2.2170021533966064
[1, 25211] loss_train: 0.010164, loss_test: 0.005541
time: 0.24305415153503418
time: 2.2675063610076904
[1, 25212] loss_train: 0.006687, loss_test: 0.005540
time: 0.24805545806884766
time: 2.242501974105835
[1, 25213] loss_train: 0.007512, loss_test: 0.005536
time: 0.24305415153503418
time: 2.285512924194336
[1, 25214] loss_train: 0.001945, loss_test: 0.005532
time: 0.24805498123168945
time: 2.259087085723877
[1, 25215] loss_train: 0.004944, loss_test: 0.005530
time: 0.24205398559570312
time: 2.273550033569336
[1, 25216] loss_train: 0.005331, loss_test: 0.005531
time: 0.2505970001220703
time: 2.257009983062744
[1, 25217] loss_train: 0.004982, loss_test: 0.005533
time: 0.24305343627929688
time: 2.252504348754883
[1, 25218] loss_train: 0.002729, loss_test: 0.005535
time: 0.256056547164917
time: 2.2470219135284424
[1, 25219] loss_train: 0.009351, loss_test: 0.005535
time: 0.24605464935302734
time: 2.280512571334839
[1, 25220] loss_train: 0.004276, loss_test: 0.005535
time: 0.2560567855834961
time: 2.2412936687469482
[1, 25221] loss_train: 0.000627, loss_test: 0.005537
time: 0.24405407905578613
time: 2.239353895187378
[1, 25222] loss_train: 0.000925, loss_test: 0.005541
time: 0.2540576457977295
time: 2.234036445617676
[1, 25223] loss_train: 0.004200, loss_test: 0.005540
time: 0.24399781227111816
time: 2.24297833442688
[1, 25224] loss_train: 0.004736, loss_test: 0.005540
time: 0.24903655052185059
time: 2.2317707538604736
[1, 25225] loss_train: 0.006699, loss_test: 0.005538
time: 0.24205350875854492
time: 2.218000888824463
[1, 25226] loss_train: 0.007493, loss_test: 0.005538
time: 0.2487177848815918
time: 2.2438459396362305
[1, 25227] loss_train: 0.011345, loss_test: 0.005542
time: 0.251056432723999
time: 2.2385001182556152
[1, 25228] loss_train: 0.008863, loss_test: 0.005550
time: 0.2470552921295166
time: 2.248504638671875
[1, 25229] loss_train: 0.002662, loss_test: 0.005556
time: 0.24205350875854492
time: 2.2178189754486084
[1, 25230] loss_train: 0.006577, loss_test: 0.005556
time: 0.26456236839294434
time: 2.234006881713867
[1, 25231] loss_train: 0.006390, loss_test: 0.005551
time: 0.24405384063720703
time: 2.249922037124634
[1, 25232] loss_train: 0.005440, loss_test: 0.005547
time: 0.25190186500549316
time: 2.2670891284942627
[1, 25233] loss_train: 0.010820, loss_test: 0.005543
time: 0.24300551414489746
time: 2.2350335121154785
[1, 25234] loss_train: 0.005438, loss_test: 0.005534
time: 0.24496102333068848
time: 2.2190473079681396
[1, 25235] loss_train: 0.010179, loss_test: 0.005525
time: 0.2499856948852539
time: 2.2549726963043213
[1, 25236] loss_train: 0.013774, loss_test: 0.005526
time: 0.2430112361907959
time: 2.2314140796661377
[1, 25237] loss_train: 0.002488, loss_test: 0.005524
time: 0.24405431747436523
time: 2.299922466278076
[1, 25238] loss_train: 0.007153, loss_test: 0.005522
time: 0.25005555152893066
time: 2.2905118465423584
[1, 25239] loss_train: 0.009604, loss_test: 0.005521
time: 0.2540562152862549
time: 2.3700528144836426
[1, 25240] loss_train: 0.005745, loss_test: 0.005521
time: 0.26405930519104004
time: 2.2663023471832275
[1, 25241] loss_train: 0.007674, loss_test: 0.005523
time: 0.24805474281311035
time: 2.297466516494751
[1, 25242] loss_train: 0.007755, loss_test: 0.005527
time: 0.28606343269348145
time: 2.36260986328125
[1, 25243] loss_train: 0.001847, loss_test: 0.005534
time: 0.33307409286499023
time: 2.323211669921875
[1, 25244] loss_train: 0.004052, loss_test: 0.005543
time: 0.2450547218322754
time: 2.2529642581939697
[1, 25245] loss_train: 0.006349, loss_test: 0.005551
time: 0.251035213470459
time: 2.278057336807251
[1, 25246] loss_train: 0.005219, loss_test: 0.005561
time: 0.24772191047668457
time: 2.2511816024780273
[1, 25247] loss_train: 0.004993, loss_test: 0.005576
time: 0.24803948402404785
time: 2.271906614303589
[1, 25248] loss_train: 0.002211, loss_test: 0.005590
time: 0.2470550537109375
time: 2.2525036334991455
[1, 25249] loss_train: 0.008511, loss_test: 0.005596
time: 0.2470548152923584
time: 2.253504514694214
[1, 25250] loss_train: 0.006890, loss_test: 0.005597
time: 0.25895261764526367
time: 2.265507936477661
[1, 25251] loss_train: 0.008455, loss_test: 0.005589
time: 0.269059419631958
time: 2.3995370864868164
[1, 25252] loss_train: 0.006568, loss_test: 0.005576
time: 0.2450542449951172
time: 2.2642478942871094
[1, 25253] loss_train: 0.007431, loss_test: 0.005564
time: 0.25005650520324707
time: 2.231696605682373
[1, 25254] loss_train: 0.004224, loss_test: 0.005554
time: 0.2490556240081787
time: 2.2544190883636475
[1, 25255] loss_train: 0.007275, loss_test: 0.005547
time: 0.24505400657653809
time: 2.245501756668091
[1, 25256] loss_train: 0.004548, loss_test: 0.005543
time: 0.2450544834136963
time: 2.243683338165283
[1, 25257] loss_train: 0.009875, loss_test: 0.005541
time: 0.25003623962402344
time: 2.251199722290039
[1, 25258] loss_train: 0.004338, loss_test: 0.005539
time: 0.24537348747253418
time: 2.272630214691162
[1, 25259] loss_train: 0.009325, loss_test: 0.005539
time: 0.24605464935302734
time: 2.270010471343994
[1, 25260] loss_train: 0.012618, loss_test: 0.005534
time: 0.26606035232543945
time: 2.2676424980163574
[1, 25261] loss_train: 0.010325, loss_test: 0.005533
time: 0.25005555152893066
time: 2.2505033016204834
[1, 25262] loss_train: 0.005872, loss_test: 0.005536
time: 0.24305367469787598
time: 2.22149658203125
[1, 25263] loss_train: 0.001941, loss_test: 0.005539
time: 0.2450547218322754
time: 2.2385005950927734
[1, 25264] loss_train: 0.005246, loss_test: 0.005538
time: 0.2470545768737793
time: 2.2368552684783936
[1, 25265] loss_train: 0.004861, loss_test: 0.005535
time: 0.24605393409729004
time: 2.22627329826355
[1, 25266] loss_train: 0.005827, loss_test: 0.005531
time: 0.2450551986694336
time: 2.236372232437134
[1, 25267] loss_train: 0.003834, loss_test: 0.005526
time: 0.24361228942871094
time: 2.2070534229278564
[1, 25268] loss_train: 0.009540, loss_test: 0.005523
time: 0.24397706985473633
time: 2.238614320755005
[1, 25269] loss_train: 0.005297, loss_test: 0.005523
time: 0.24405455589294434
time: 2.3255207538604736
[1, 25270] loss_train: 0.002865, loss_test: 0.005524
time: 0.28806376457214355
time: 2.3025155067443848
[1, 25271] loss_train: 0.007816, loss_test: 0.005527
time: 0.2450549602508545
time: 2.2395029067993164
[1, 25272] loss_train: 0.005753, loss_test: 0.005529
time: 0.24405407905578613
time: 2.2911059856414795
[1, 25273] loss_train: 0.007736, loss_test: 0.005534
time: 0.2620580196380615
time: 2.3044419288635254
[1, 25274] loss_train: 0.004981, loss_test: 0.005539
time: 0.25053882598876953
time: 2.355320930480957
[1, 25275] loss_train: 0.001731, loss_test: 0.005547
time: 0.2441272735595703
time: 2.2869699001312256
[1, 25276] loss_train: 0.006682, loss_test: 0.005552
time: 0.24602937698364258
time: 2.334364652633667
[1, 25277] loss_train: 0.008066, loss_test: 0.005556
time: 0.2510557174682617
time: 2.234511613845825
[1, 25278] loss_train: 0.008100, loss_test: 0.005554
time: 0.2450542449951172
time: 2.2432737350463867
[1, 25279] loss_train: 0.002756, loss_test: 0.005550
time: 0.24305367469787598
time: 2.2435038089752197
[1, 25280] loss_train: 0.007622, loss_test: 0.005548
time: 0.28406333923339844
time: 2.3130745887756348
[1, 25281] loss_train: 0.005307, loss_test: 0.005545
time: 0.2560570240020752
time: 2.424542188644409
[1, 25282] loss_train: 0.009484, loss_test: 0.005540
time: 0.3250713348388672
time: 2.4418740272521973
[1, 25283] loss_train: 0.003696, loss_test: 0.005538
time: 0.25505638122558594
time: 2.3413643836975098
[1, 25284] loss_train: 0.004083, loss_test: 0.005535
time: 0.28403544425964355
time: 2.3285927772521973
[1, 25285] loss_train: 0.005550, loss_test: 0.005535
time: 0.2450547218322754
time: 2.2795097827911377
[1, 25286] loss_train: 0.003016, loss_test: 0.005537
time: 0.25305652618408203
time: 2.2663516998291016
[1, 25287] loss_train: 0.000798, loss_test: 0.005542
time: 0.2490556240081787
time: 2.3017213344573975
[1, 25288] loss_train: 0.005031, loss_test: 0.005551
time: 0.254056453704834
time: 2.299514055252075
[1, 25289] loss_train: 0.005254, loss_test: 0.005558
time: 0.24405360221862793
time: 2.3135194778442383
[1, 25290] loss_train: 0.014545, loss_test: 0.005564
time: 0.2960655689239502
time: 2.393322467803955
[1, 25291] loss_train: 0.000928, loss_test: 0.005572
time: 0.252056360244751
time: 2.2277448177337646
[1, 25292] loss_train: 0.006094, loss_test: 0.005578
time: 0.2510554790496826
time: 2.2779462337493896
[1, 25293] loss_train: 0.011928, loss_test: 0.005576
time: 0.23897218704223633
time: 2.221268892288208
[1, 25294] loss_train: 0.004163, loss_test: 0.005574
time: 0.24301362037658691
time: 2.220978260040283
[1, 25295] loss_train: 0.005319, loss_test: 0.005569
time: 0.2550375461578369
time: 2.4110448360443115
[1, 25296] loss_train: 0.004975, loss_test: 0.005564
time: 0.25905728340148926
time: 2.2284979820251465
[1, 25297] loss_train: 0.003843, loss_test: 0.005554
time: 0.2450551986694336
time: 2.2594995498657227
[1, 25298] loss_train: 0.007733, loss_test: 0.005545
time: 0.25505638122558594
time: 2.3365230560302734
[1, 25299] loss_train: 0.007561, loss_test: 0.005538
time: 0.2560572624206543
time: 2.324239492416382
[1, 25300] loss_train: 0.005763, loss_test: 0.005530
time: 0.26473093032836914
time: 2.2447426319122314
[1, 25301] loss_train: 0.007878, loss_test: 0.005526
time: 0.24605512619018555
time: 2.2414321899414062
[1, 25302] loss_train: 0.017206, loss_test: 0.005524
time: 0.24893808364868164
time: 2.2489829063415527
[1, 25303] loss_train: 0.007462, loss_test: 0.005522
time: 0.24903082847595215
time: 2.2609965801239014
[1, 25304] loss_train: 0.004831, loss_test: 0.005518
time: 0.2529900074005127
time: 2.263984441757202
[1, 25305] loss_train: 0.003815, loss_test: 0.005515
time: 0.24985504150390625
time: 2.239914655685425
[1, 25306] loss_train: 0.007835, loss_test: 0.005514
time: 0.2520558834075928
time: 2.2865195274353027
[1, 25307] loss_train: 0.002034, loss_test: 0.005512
time: 0.2540555000305176
time: 2.27051043510437
[1, 25308] loss_train: 0.003609, loss_test: 0.005509
time: 0.24305486679077148
time: 2.252687931060791
[1, 25309] loss_train: 0.006834, loss_test: 0.005508
time: 0.24405455589294434
time: 2.234920024871826
[1, 25310] loss_train: 0.009307, loss_test: 0.005506
time: 0.2670598030090332
time: 2.259061336517334
[1, 25311] loss_train: 0.003278, loss_test: 0.005503
time: 0.2520565986633301
time: 2.2379441261291504
[1, 25312] loss_train: 0.004161, loss_test: 0.005501
time: 0.2530558109283447
time: 2.2445051670074463
[1, 25313] loss_train: 0.007544, loss_test: 0.005499
time: 0.25086140632629395
time: 2.318476676940918
[1, 25314] loss_train: 0.007365, loss_test: 0.005498
time: 0.2510557174682617
time: 2.2636468410491943
[1, 25315] loss_train: 0.006928, loss_test: 0.005497
time: 0.2600576877593994
time: 2.234499931335449
[1, 25316] loss_train: 0.023015, loss_test: 0.005495
time: 0.24305367469787598
time: 2.227503538131714
[1, 25317] loss_train: 0.008350, loss_test: 0.005494
time: 0.2490553855895996
time: 2.244847059249878
[1, 25318] loss_train: 0.012130, loss_test: 0.005494
time: 0.24205350875854492
time: 2.2445030212402344
[1, 25319] loss_train: 0.020517, loss_test: 0.005494
time: 0.24805426597595215
time: 2.305744171142578
[1, 25320] loss_train: 0.005729, loss_test: 0.005497
time: 0.27706146240234375
time: 2.3030295372009277
[1, 25321] loss_train: 0.012743, loss_test: 0.005499
time: 0.24405384063720703
time: 2.235065460205078
[1, 25322] loss_train: 0.002266, loss_test: 0.005500
time: 0.24486136436462402
time: 2.241100311279297
[1, 25323] loss_train: 0.003035, loss_test: 0.005500
time: 0.24405455589294434
time: 2.2375004291534424
[1, 25324] loss_train: 0.001913, loss_test: 0.005502
time: 0.2520561218261719
time: 2.2915124893188477
[1, 25325] loss_train: 0.005204, loss_test: 0.005506
time: 0.2540566921234131
time: 2.2485029697418213
[1, 25326] loss_train: 0.007548, loss_test: 0.005510
time: 0.24405431747436523
time: 2.2154953479766846
[1, 25327] loss_train: 0.007250, loss_test: 0.005512
time: 0.24405455589294434
time: 2.2455036640167236
[1, 25328] loss_train: 0.007061, loss_test: 0.005514
time: 0.2580578327178955
time: 2.247504234313965
[1, 25329] loss_train: 0.005957, loss_test: 0.005513
time: 0.24205398559570312
time: 2.231145143508911
[1, 25330] loss_train: 0.007694, loss_test: 0.005512
time: 0.31421709060668945
time: 2.241504669189453
[1, 25331] loss_train: 0.015475, loss_test: 0.005511
time: 0.24405431747436523
time: 2.2526535987854004
[1, 25332] loss_train: 0.005119, loss_test: 0.005511
time: 0.27301645278930664
time: 2.4587974548339844
[1, 25333] loss_train: 0.009694, loss_test: 0.005509
time: 0.2580575942993164
time: 2.2755091190338135
[1, 25334] loss_train: 0.006566, loss_test: 0.005508
time: 0.2490556240081787
time: 2.2733778953552246
[1, 25335] loss_train: 0.017525, loss_test: 0.005509
time: 0.2450547218322754
time: 2.236499547958374
[1, 25336] loss_train: 0.004626, loss_test: 0.005509
time: 0.260059118270874
time: 2.267024040222168
[1, 25337] loss_train: 0.004148, loss_test: 0.005508
time: 0.2470545768737793
time: 2.244502305984497
[1, 25338] loss_train: 0.003621, loss_test: 0.005505
time: 0.2490558624267578
time: 2.2605044841766357
[1, 25339] loss_train: 0.005684, loss_test: 0.005502
time: 0.24605536460876465
time: 2.2711377143859863
[1, 25340] loss_train: 0.003139, loss_test: 0.005499
time: 0.2830631732940674
time: 2.27852725982666
[1, 25341] loss_train: 0.001921, loss_test: 0.005498
time: 0.24705862998962402
time: 2.2448296546936035
[1, 25342] loss_train: 0.008329, loss_test: 0.005497
time: 0.2510557174682617
time: 2.218496084213257
[1, 25343] loss_train: 0.001453, loss_test: 0.005497
time: 0.24605512619018555
time: 2.247502088546753
[1, 25344] loss_train: 0.000781, loss_test: 0.005502
time: 0.254056453704834
time: 2.2470273971557617
[1, 25345] loss_train: 0.005450, loss_test: 0.005508
time: 0.24805498123168945
time: 2.256504774093628
[1, 25346] loss_train: 0.008448, loss_test: 0.005514
time: 0.25005602836608887
time: 2.249502658843994
[1, 25347] loss_train: 0.004798, loss_test: 0.005517
time: 0.2450549602508545
time: 2.2612996101379395
[1, 25348] loss_train: 0.001883, loss_test: 0.005522
time: 0.2545781135559082
time: 2.265211582183838
[1, 25349] loss_train: 0.004156, loss_test: 0.005526
time: 0.25005602836608887
time: 2.260449171066284
[1, 25350] loss_train: 0.008568, loss_test: 0.005527
time: 0.29506611824035645
time: 2.3575382232666016
[1, 25351] loss_train: 0.006185, loss_test: 0.005525
time: 0.24405431747436523
time: 2.254504680633545
[1, 25352] loss_train: 0.009847, loss_test: 0.005515
time: 0.32807207107543945
time: 2.2626612186431885
[1, 25353] loss_train: 0.010246, loss_test: 0.005500
time: 0.2470548152923584
time: 2.2608835697174072
[1, 25354] loss_train: 0.005278, loss_test: 0.005491
time: 0.24805498123168945
time: 2.2365028858184814
[1, 25355] loss_train: 0.005304, loss_test: 0.005488
time: 0.24605488777160645
time: 2.2693593502044678
[1, 25356] loss_train: 0.009010, loss_test: 0.005491
time: 0.24805402755737305
time: 2.270509958267212
[1, 25357] loss_train: 0.004507, loss_test: 0.005496
time: 0.2450547218322754
time: 2.2831668853759766
[1, 25358] loss_train: 0.008777, loss_test: 0.005501
time: 0.2450542449951172
time: 2.2998318672180176
[1, 25359] loss_train: 0.007190, loss_test: 0.005506
time: 0.2430562973022461
time: 2.251634120941162
[1, 25360] loss_train: 0.003879, loss_test: 0.005506
time: 0.25705766677856445
time: 2.275516986846924
[1, 25361] loss_train: 0.007422, loss_test: 0.005504
time: 0.24405479431152344
time: 2.263507843017578
[1, 25362] loss_train: 0.007474, loss_test: 0.005500
time: 0.24305319786071777
time: 2.2805094718933105
[1, 25363] loss_train: 0.004388, loss_test: 0.005496
time: 0.25905823707580566
time: 2.2675070762634277
[1, 25364] loss_train: 0.003371, loss_test: 0.005492
time: 0.24605417251586914
time: 2.284370183944702
[1, 25365] loss_train: 0.017622, loss_test: 0.005492
time: 0.2490556240081787
time: 2.2695069313049316
[1, 25366] loss_train: 0.007592, loss_test: 0.005494
time: 0.24605512619018555
time: 2.227814197540283
[1, 25367] loss_train: 0.014398, loss_test: 0.005498
time: 0.2510566711425781
time: 2.2714571952819824
[1, 25368] loss_train: 0.015344, loss_test: 0.005501
time: 0.24479889869689941
time: 2.2836380004882812
[1, 25369] loss_train: 0.004854, loss_test: 0.005505
time: 0.25305628776550293
time: 2.255514144897461
[1, 25370] loss_train: 0.000883, loss_test: 0.005504
time: 0.25705647468566895
time: 2.2525033950805664
[1, 25371] loss_train: 0.004623, loss_test: 0.005504
time: 0.25305724143981934
time: 2.257227897644043
[1, 25372] loss_train: 0.008566, loss_test: 0.005499
time: 0.24305391311645508
time: 2.2705061435699463
[1, 25373] loss_train: 0.001697, loss_test: 0.005496
time: 0.24305343627929688
time: 2.229325771331787
[1, 25374] loss_train: 0.004556, loss_test: 0.005495
time: 0.2490558624267578
time: 2.248194456100464
[1, 25375] loss_train: 0.003131, loss_test: 0.005495
time: 0.2540566921234131
time: 2.2616641521453857
[1, 25376] loss_train: 0.001451, loss_test: 0.005496
time: 0.24603056907653809
time: 2.255955934524536
[1, 25377] loss_train: 0.003767, loss_test: 0.005500
time: 0.24392271041870117
time: 2.243077516555786
[1, 25378] loss_train: 0.007422, loss_test: 0.005503
time: 0.24302458763122559
time: 2.2243404388427734
[1, 25379] loss_train: 0.006366, loss_test: 0.005504
time: 0.25005650520324707
time: 2.24116849899292
[1, 25380] loss_train: 0.006488, loss_test: 0.005503
time: 0.2616078853607178
time: 2.22149920463562
[1, 25381] loss_train: 0.005463, loss_test: 0.005500
time: 0.25005531311035156
time: 2.246882915496826
[1, 25382] loss_train: 0.010041, loss_test: 0.005497
time: 0.24305415153503418
time: 2.2451579570770264
[1, 25383] loss_train: 0.004601, loss_test: 0.005495
time: 0.25005578994750977
time: 2.2410731315612793
[1, 25384] loss_train: 0.005583, loss_test: 0.005494
time: 0.24903583526611328
time: 2.2320401668548584
[1, 25385] loss_train: 0.010887, loss_test: 0.005495
time: 0.24805569648742676
time: 2.2635064125061035
[1, 25386] loss_train: 0.009572, loss_test: 0.005497
time: 0.24505376815795898
time: 2.237008810043335
[1, 25387] loss_train: 0.009770, loss_test: 0.005499
time: 0.2580575942993164
time: 2.2665069103240967
[1, 25388] loss_train: 0.007770, loss_test: 0.005502
time: 0.2450542449951172
time: 2.2155070304870605
[1, 25389] loss_train: 0.004719, loss_test: 0.005504
time: 0.25505757331848145
time: 2.3795313835144043
[1, 25390] loss_train: 0.003426, loss_test: 0.005506
time: 0.2580580711364746
time: 2.233499526977539
[1, 25391] loss_train: 0.004774, loss_test: 0.005509
time: 0.24605441093444824
time: 2.326303720474243
[1, 25392] loss_train: 0.002192, loss_test: 0.005512
time: 0.24706459045410156
time: 2.2771787643432617
[1, 25393] loss_train: 0.002666, loss_test: 0.005514
time: 0.24605464935302734
time: 2.281024217605591
[1, 25394] loss_train: 0.005426, loss_test: 0.005519
time: 0.2510554790496826
time: 2.2941207885742188
[1, 25395] loss_train: 0.015367, loss_test: 0.005522
time: 0.24314236640930176
time: 2.2475945949554443
[1, 25396] loss_train: 0.007450, loss_test: 0.005524
time: 0.24405431747436523
time: 2.2505033016204834
[1, 25397] loss_train: 0.006821, loss_test: 0.005523
time: 0.24205327033996582
time: 2.2645092010498047
[1, 25398] loss_train: 0.002704, loss_test: 0.005522
time: 0.24605441093444824
time: 2.275023937225342
[1, 25399] loss_train: 0.005348, loss_test: 0.005522
time: 0.24903416633605957
time: 2.343104124069214
[1, 25400] loss_train: 0.003013, loss_test: 0.005522
time: 0.28106260299682617
time: 2.2929625511169434
[1, 25401] loss_train: 0.001741, loss_test: 0.005523
time: 0.24503111839294434
time: 2.2620108127593994
[1, 25402] loss_train: 0.008696, loss_test: 0.005525
time: 0.2489476203918457
time: 2.239995241165161
[1, 25403] loss_train: 0.002545, loss_test: 0.005529
time: 0.24371790885925293
time: 2.2395248413085938
[1, 25404] loss_train: 0.007203, loss_test: 0.005527
time: 0.24405431747436523
time: 2.260124921798706
[1, 25405] loss_train: 0.004142, loss_test: 0.005526
time: 0.24305438995361328
time: 2.2385001182556152
[1, 25406] loss_train: 0.005084, loss_test: 0.005521
time: 0.24305367469787598
time: 2.2415008544921875
[1, 25407] loss_train: 0.005077, loss_test: 0.005519
time: 0.24405431747436523
time: 2.209494113922119
[1, 25408] loss_train: 0.007129, loss_test: 0.005517
time: 0.24805474281311035
time: 2.250608444213867
[1, 25409] loss_train: 0.004076, loss_test: 0.005516
time: 0.24305367469787598
time: 2.260828733444214
[1, 25410] loss_train: 0.002978, loss_test: 0.005517
time: 0.25705742835998535
time: 2.2765097618103027
[1, 25411] loss_train: 0.004741, loss_test: 0.005518
time: 0.24505376815795898
time: 2.2407212257385254
[1, 25412] loss_train: 0.017777, loss_test: 0.005515
time: 0.2549910545349121
time: 2.2789535522460938
[1, 25413] loss_train: 0.003971, loss_test: 0.005515
time: 0.24395108222961426
time: 2.282688617706299
[1, 25414] loss_train: 0.003421, loss_test: 0.005516
time: 0.2500569820404053
time: 2.242988109588623
[1, 25415] loss_train: 0.004297, loss_test: 0.005517
time: 0.24905610084533691
time: 2.2604281902313232
[1, 25416] loss_train: 0.004078, loss_test: 0.005517
time: 0.2450544834136963
time: 2.239504814147949
[1, 25417] loss_train: 0.005657, loss_test: 0.005519
time: 0.24205327033996582
time: 2.2355003356933594
[1, 25418] loss_train: 0.005717, loss_test: 0.005520
time: 0.24305486679077148
time: 2.2500481605529785
[1, 25419] loss_train: 0.009001, loss_test: 0.005522
time: 0.24305343627929688
time: 2.2276804447174072
[1, 25420] loss_train: 0.006915, loss_test: 0.005521
time: 0.25505638122558594
time: 2.253434181213379
[1, 25421] loss_train: 0.002603, loss_test: 0.005519
time: 0.2830638885498047
time: 2.416264772415161
[1, 25422] loss_train: 0.005984, loss_test: 0.005518
time: 0.24605584144592285
time: 2.294294834136963
[1, 25423] loss_train: 0.004174, loss_test: 0.005516
time: 0.25005531311035156
time: 2.2525501251220703
[1, 25424] loss_train: 0.007535, loss_test: 0.005515
time: 0.2420971393585205
time: 2.251014471054077
[1, 25425] loss_train: 0.004353, loss_test: 0.005513
time: 0.2429966926574707
time: 2.2388768196105957
[1, 25426] loss_train: 0.002986, loss_test: 0.005510
time: 0.24358010292053223
time: 2.241502046585083
[1, 25427] loss_train: 0.004475, loss_test: 0.005512
time: 0.24305319786071777
time: 2.2390079498291016
[1, 25428] loss_train: 0.003536, loss_test: 0.005515
time: 0.2470548152923584
time: 2.2319061756134033
[1, 25429] loss_train: 0.001420, loss_test: 0.005522
time: 0.24405503273010254
time: 2.222646951675415
[1, 25430] loss_train: 0.000669, loss_test: 0.005531
time: 0.2596309185028076
time: 2.246502161026001
[1, 25431] loss_train: 0.002425, loss_test: 0.005544
time: 0.24205327033996582
time: 2.2100799083709717
[1, 25432] loss_train: 0.014232, loss_test: 0.005541
time: 0.24801230430603027
time: 2.2300350666046143
[1, 25433] loss_train: 0.007301, loss_test: 0.005535
time: 0.2429826259613037
time: 2.2331414222717285
[1, 25434] loss_train: 0.006059, loss_test: 0.005527
time: 0.24605512619018555
time: 2.250502586364746
[1, 25435] loss_train: 0.007441, loss_test: 0.005517
time: 0.24205398559570312
time: 2.23950457572937
[1, 25436] loss_train: 0.001246, loss_test: 0.005510
time: 0.24405336380004883
time: 2.248502492904663
[1, 25437] loss_train: 0.001824, loss_test: 0.005506
time: 0.2510559558868408
time: 2.2425012588500977
[1, 25438] loss_train: 0.003931, loss_test: 0.005502
time: 0.24205398559570312
time: 2.2248194217681885
[1, 25439] loss_train: 0.003622, loss_test: 0.005501
time: 0.24351859092712402
time: 2.254504442214966
[1, 25440] loss_train: 0.006880, loss_test: 0.005499
time: 0.2580575942993164
time: 2.2336204051971436
[1, 25441] loss_train: 0.003862, loss_test: 0.005497
time: 0.24540424346923828
time: 2.2264974117279053
[1, 25442] loss_train: 0.001574, loss_test: 0.005497
time: 0.24405407905578613
time: 2.265507221221924
[1, 25443] loss_train: 0.006280, loss_test: 0.005496
time: 0.24205398559570312
time: 2.259010076522827
[1, 25444] loss_train: 0.000516, loss_test: 0.005497
time: 0.24405407905578613
time: 2.2630083560943604
[1, 25445] loss_train: 0.003536, loss_test: 0.005498
time: 0.24205327033996582
time: 2.2545077800750732
[1, 25446] loss_train: 0.002324, loss_test: 0.005501
time: 0.24105405807495117
time: 2.23844575881958
[1, 25447] loss_train: 0.006254, loss_test: 0.005504
time: 0.24205708503723145
time: 2.2478771209716797
[1, 25448] loss_train: 0.004074, loss_test: 0.005508
time: 0.24405455589294434
time: 2.2693395614624023
[1, 25449] loss_train: 0.001104, loss_test: 0.005514
time: 0.24405407905578613
time: 2.2629315853118896
[1, 25450] loss_train: 0.003272, loss_test: 0.005519
time: 0.26596927642822266
time: 2.4028866291046143
[1, 25451] loss_train: 0.002174, loss_test: 0.005529
time: 0.2450542449951172
time: 2.3315205574035645
[1, 25452] loss_train: 0.006296, loss_test: 0.005537
time: 0.2450551986694336
time: 2.2745091915130615
[1, 25453] loss_train: 0.002999, loss_test: 0.005549
time: 0.24405384063720703
time: 2.262829542160034
[1, 25454] loss_train: 0.011515, loss_test: 0.005552
time: 0.24405455589294434
time: 2.219255208969116
[1, 25455] loss_train: 0.009123, loss_test: 0.005545
time: 0.24105310440063477
time: 2.235499382019043
[1, 25456] loss_train: 0.004817, loss_test: 0.005540
time: 0.2475605010986328
time: 2.2310900688171387
[1, 25457] loss_train: 0.009851, loss_test: 0.005531
time: 0.2431349754333496
time: 2.252434015274048
[1, 25458] loss_train: 0.009272, loss_test: 0.005519
time: 0.2600584030151367
time: 2.2559266090393066
[1, 25459] loss_train: 0.005988, loss_test: 0.005512
time: 0.2420046329498291
time: 2.251030921936035
[1, 25460] loss_train: 0.002294, loss_test: 0.005508
time: 0.2619614601135254
time: 2.2324841022491455
[1, 25461] loss_train: 0.006872, loss_test: 0.005507
time: 0.24805545806884766
time: 2.25750732421875
[1, 25462] loss_train: 0.003634, loss_test: 0.005505
time: 0.2530558109283447
time: 2.237499713897705
[1, 25463] loss_train: 0.002295, loss_test: 0.005503
time: 0.2470557689666748
time: 2.2285008430480957
[1, 25464] loss_train: 0.003206, loss_test: 0.005502
time: 0.2470557689666748
time: 2.2775111198425293
[1, 25465] loss_train: 0.002437, loss_test: 0.005500
time: 0.2470550537109375
time: 2.274639129638672
[1, 25466] loss_train: 0.013457, loss_test: 0.005499
time: 0.2586045265197754
time: 2.2906744480133057
[1, 25467] loss_train: 0.008582, loss_test: 0.005499
time: 0.2450544834136963
time: 2.2361955642700195
[1, 25468] loss_train: 0.002272, loss_test: 0.005498
time: 0.24403095245361328
time: 2.2573752403259277
[1, 25469] loss_train: 0.009932, loss_test: 0.005498
time: 0.24805450439453125
time: 2.3016207218170166
[1, 25470] loss_train: 0.006226, loss_test: 0.005500
time: 0.29906654357910156
time: 2.4935572147369385
[1, 25471] loss_train: 0.008278, loss_test: 0.005501
time: 0.25305604934692383
time: 2.2701992988586426
[1, 25472] loss_train: 0.006174, loss_test: 0.005500
time: 0.24605441093444824
time: 2.2430033683776855
[1, 25473] loss_train: 0.006024, loss_test: 0.005499
time: 0.2450551986694336
time: 2.36869478225708
[1, 25474] loss_train: 0.008734, loss_test: 0.005498
time: 0.28206300735473633
time: 2.3925795555114746
[1, 25475] loss_train: 0.001405, loss_test: 0.005498
time: 0.2560582160949707
time: 2.3960249423980713
[1, 25476] loss_train: 0.002600, loss_test: 0.005497
time: 0.24305415153503418
time: 2.424504518508911
[1, 25477] loss_train: 0.003717, loss_test: 0.005496
time: 0.2560567855834961
time: 2.2588419914245605
[1, 25478] loss_train: 0.007645, loss_test: 0.005495
time: 0.27537965774536133
time: 2.2975146770477295
[1, 25479] loss_train: 0.003534, loss_test: 0.005495
time: 0.2470543384552002
time: 2.260436534881592
[1, 25480] loss_train: 0.002878, loss_test: 0.005496
time: 0.258561372756958
time: 2.25150465965271
[1, 25481] loss_train: 0.002122, loss_test: 0.005497
time: 0.24405455589294434
time: 2.2625057697296143
[1, 25482] loss_train: 0.008350, loss_test: 0.005499
time: 0.24805545806884766
time: 2.2505812644958496
[1, 25483] loss_train: 0.005686, loss_test: 0.005503
time: 0.24305438995361328
time: 2.2956655025482178
[1, 25484] loss_train: 0.017222, loss_test: 0.005500
time: 0.2510550022125244
time: 2.3775291442871094
[1, 25485] loss_train: 0.006925, loss_test: 0.005498
time: 0.2513315677642822
time: 2.283510446548462
[1, 25486] loss_train: 0.010048, loss_test: 0.005494
time: 0.2470545768737793
time: 2.2505621910095215
[1, 25487] loss_train: 0.010638, loss_test: 0.005493
time: 0.24405503273010254
time: 2.3385250568389893
[1, 25488] loss_train: 0.009815, loss_test: 0.005496
time: 0.2490551471710205
time: 2.3535258769989014
[1, 25489] loss_train: 0.005921, loss_test: 0.005505
time: 0.24605441093444824
time: 2.234499454498291
[1, 25490] loss_train: 0.001049, loss_test: 0.005510
time: 0.25905776023864746
time: 2.2375001907348633
[1, 25491] loss_train: 0.003122, loss_test: 0.005510
time: 0.2510554790496826
time: 2.3345227241516113
[1, 25492] loss_train: 0.005115, loss_test: 0.005508
time: 0.2630581855773926
time: 2.260601043701172
[1, 25493] loss_train: 0.005627, loss_test: 0.005504
time: 0.24584174156188965
time: 2.262540578842163
[1, 25494] loss_train: 0.008592, loss_test: 0.005501
time: 0.24805545806884766
time: 2.286609649658203
[1, 25495] loss_train: 0.005677, loss_test: 0.005499
time: 0.2459566593170166
time: 2.269026041030884
[1, 25496] loss_train: 0.008442, loss_test: 0.005498
time: 0.25291967391967773
time: 2.236025094985962
[1, 25497] loss_train: 0.008519, loss_test: 0.005497
time: 0.24780583381652832
time: 2.2631630897521973
[1, 25498] loss_train: 0.007939, loss_test: 0.005497
time: 0.24503374099731445
time: 2.269503116607666
[1, 25499] loss_train: 0.010460, loss_test: 0.005496
time: 0.2450542449951172
time: 2.2495052814483643
[1, 25500] loss_train: 0.002849, loss_test: 0.005496
time: 0.2560567855834961
time: 2.258244037628174
[1, 25501] loss_train: 0.010200, loss_test: 0.005497
time: 0.24505400657653809
time: 2.2413909435272217
[1, 25502] loss_train: 0.005213, loss_test: 0.005500
time: 0.24205422401428223
time: 2.2785117626190186
[1, 25503] loss_train: 0.003181, loss_test: 0.005504
time: 0.24405455589294434
time: 2.25992751121521
[1, 25504] loss_train: 0.001139, loss_test: 0.005510
time: 0.2430565357208252
time: 2.2503318786621094
[1, 25505] loss_train: 0.002591, loss_test: 0.005520
time: 0.252056360244751
time: 2.6716017723083496
[1, 25506] loss_train: 0.004917, loss_test: 0.005530
time: 0.26406192779541016
time: 2.3824703693389893
[1, 25507] loss_train: 0.006433, loss_test: 0.005543
time: 0.24405431747436523
time: 2.3097846508026123
[1, 25508] loss_train: 0.004203, loss_test: 0.005555
time: 0.2450547218322754
time: 2.276948928833008
[1, 25509] loss_train: 0.009364, loss_test: 0.005561
time: 0.24605488777160645
time: 2.246384859085083
[1, 25510] loss_train: 0.012458, loss_test: 0.005559
time: 0.25705766677856445
time: 2.232164144515991
[1, 25511] loss_train: 0.011399, loss_test: 0.005554
time: 0.24512076377868652
time: 2.243722677230835
[1, 25512] loss_train: 0.002661, loss_test: 0.005554
time: 0.24605607986450195
time: 2.266266107559204
[1, 25513] loss_train: 0.007336, loss_test: 0.005552
time: 0.2450559139251709
time: 2.2325003147125244
[1, 25514] loss_train: 0.001450, loss_test: 0.005555
time: 0.24405384063720703
time: 2.2540085315704346
[1, 25515] loss_train: 0.010040, loss_test: 0.005549
time: 0.24505329132080078
time: 2.267420530319214
[1, 25516] loss_train: 0.006634, loss_test: 0.005542
time: 0.2520561218261719
time: 2.2764124870300293
[1, 25517] loss_train: 0.002067, loss_test: 0.005539
time: 0.2455921173095703
time: 2.2394049167633057
[1, 25518] loss_train: 0.002242, loss_test: 0.005538
time: 0.24105429649353027
time: 2.244180202484131
[1, 25519] loss_train: 0.008069, loss_test: 0.005536
time: 0.24119019508361816
time: 2.23994779586792
[1, 25520] loss_train: 0.004859, loss_test: 0.005535
time: 0.2580571174621582
time: 2.4642555713653564
[1, 25521] loss_train: 0.010338, loss_test: 0.005535
time: 0.24503588676452637
time: 2.2244293689727783
[1, 25522] loss_train: 0.005420, loss_test: 0.005535
time: 0.24405407905578613
time: 2.3503451347351074
[1, 25523] loss_train: 0.003845, loss_test: 0.005525
time: 0.24405407905578613
time: 2.260315179824829
[1, 25524] loss_train: 0.002352, loss_test: 0.005515
time: 0.2450551986694336
time: 2.253274917602539
[1, 25525] loss_train: 0.001942, loss_test: 0.005504
time: 0.24305415153503418
time: 2.262906312942505
[1, 25526] loss_train: 0.003888, loss_test: 0.005497
time: 0.24339747428894043
time: 2.262770652770996
[1, 25527] loss_train: 0.001416, loss_test: 0.005492
time: 0.24471592903137207
time: 2.251560688018799
[1, 25528] loss_train: 0.001386, loss_test: 0.005488
time: 0.24800872802734375
time: 2.2309560775756836
[1, 25529] loss_train: 0.002285, loss_test: 0.005489
time: 0.24991250038146973
time: 2.257927417755127
[1, 25530] loss_train: 0.009861, loss_test: 0.005493
time: 0.25572633743286133
time: 2.2402291297912598
[1, 25531] loss_train: 0.005881, loss_test: 0.005498
time: 0.24805474281311035
time: 2.2554240226745605
[1, 25532] loss_train: 0.005892, loss_test: 0.005503
time: 0.2450544834136963
time: 2.2360527515411377
[1, 25533] loss_train: 0.015120, loss_test: 0.005501
time: 0.24605441093444824
time: 2.2946250438690186
[1, 25534] loss_train: 0.005548, loss_test: 0.005503
time: 0.24305343627929688
time: 2.2545039653778076
[1, 25535] loss_train: 0.008607, loss_test: 0.005504
time: 0.24605441093444824
time: 2.2319412231445312
[1, 25536] loss_train: 0.002275, loss_test: 0.005504
time: 0.24805521965026855
time: 2.250943183898926
[1, 25537] loss_train: 0.006022, loss_test: 0.005506
time: 0.2450542449951172
time: 2.2343058586120605
[1, 25538] loss_train: 0.001981, loss_test: 0.005508
time: 0.24184679985046387
time: 2.2641520500183105
[1, 25539] loss_train: 0.007667, loss_test: 0.005510
time: 0.24502968788146973
time: 2.2409701347351074
[1, 25540] loss_train: 0.007041, loss_test: 0.005509
time: 0.25867366790771484
time: 2.2383077144622803
[1, 25541] loss_train: 0.009657, loss_test: 0.005506
time: 0.25251245498657227
time: 2.249505043029785
[1, 25542] loss_train: 0.005427, loss_test: 0.005505
time: 0.24405431747436523
time: 2.284511089324951
[1, 25543] loss_train: 0.003392, loss_test: 0.005504
time: 0.24805474281311035
time: 2.2265419960021973
[1, 25544] loss_train: 0.007906, loss_test: 0.005504
time: 0.24682354927062988
time: 2.259986162185669
[1, 25545] loss_train: 0.014749, loss_test: 0.005504
time: 0.25705742835998535
time: 2.248502492904663
[1, 25546] loss_train: 0.010499, loss_test: 0.005504
time: 0.2470552921295166
time: 2.248501777648926
[1, 25547] loss_train: 0.007409, loss_test: 0.005502
time: 0.2490551471710205
time: 2.23835825920105
[1, 25548] loss_train: 0.004240, loss_test: 0.005501
time: 0.2540571689605713
time: 2.261773109436035
[1, 25549] loss_train: 0.015434, loss_test: 0.005500
time: 0.24705719947814941
time: 2.2334487438201904
[1, 25550] loss_train: 0.005730, loss_test: 0.005500
time: 0.2560575008392334
time: 2.269613742828369
[1, 25551] loss_train: 0.001330, loss_test: 0.005499
time: 0.2470536231994629
time: 2.2515041828155518
[1, 25552] loss_train: 0.002982, loss_test: 0.005498
time: 0.2450547218322754
time: 2.2705066204071045
[1, 25553] loss_train: 0.003344, loss_test: 0.005498
time: 0.2560563087463379
time: 2.228498935699463
[1, 25554] loss_train: 0.007121, loss_test: 0.005498
time: 0.25005555152893066
time: 2.2545042037963867
[1, 25555] loss_train: 0.007515, loss_test: 0.005500
time: 0.24605441093444824
time: 2.257504940032959
[1, 25556] loss_train: 0.008301, loss_test: 0.005502
time: 0.2470548152923584
time: 2.6073782444000244
[1, 25557] loss_train: 0.001730, loss_test: 0.005507
time: 0.36589860916137695
time: 2.322519063949585
[1, 25558] loss_train: 0.005371, loss_test: 0.005512
time: 0.24805521965026855
time: 2.255154609680176
[1, 25559] loss_train: 0.002583, loss_test: 0.005517
time: 0.24305415153503418
time: 2.240013837814331
[1, 25560] loss_train: 0.001924, loss_test: 0.005524
time: 0.2560572624206543
time: 2.2298519611358643
[1, 25561] loss_train: 0.002591, loss_test: 0.005532
time: 0.24605679512023926
time: 2.278313636779785
[1, 25562] loss_train: 0.006687, loss_test: 0.005538
time: 0.2520568370819092
time: 2.323939323425293
[1, 25563] loss_train: 0.005425, loss_test: 0.005543
time: 0.2470543384552002
time: 2.2584660053253174
[1, 25564] loss_train: 0.002271, loss_test: 0.005545
time: 0.24405431747436523
time: 2.259505271911621
[1, 25565] loss_train: 0.002793, loss_test: 0.005549
time: 0.24405407905578613
time: 2.318026542663574
[1, 25566] loss_train: 0.006325, loss_test: 0.005553
time: 0.2560572624206543
time: 2.2475054264068604
[1, 25567] loss_train: 0.008772, loss_test: 0.005556
time: 0.24305391311645508
time: 2.292512893676758
[1, 25568] loss_train: 0.014156, loss_test: 0.005531
time: 0.252056360244751
time: 2.291562080383301
[1, 25569] loss_train: 0.009400, loss_test: 0.005516
time: 0.24805545806884766
time: 2.281024932861328
[1, 25570] loss_train: 0.003272, loss_test: 0.005511
time: 0.26405858993530273
time: 2.378091812133789
[1, 25571] loss_train: 0.007711, loss_test: 0.005512
time: 0.24300312995910645
time: 2.2319834232330322
[1, 25572] loss_train: 0.008750, loss_test: 0.005521
time: 0.24403047561645508
time: 2.248704195022583
[1, 25573] loss_train: 0.001982, loss_test: 0.005533
time: 0.2450549602508545
time: 2.2613344192504883
[1, 25574] loss_train: 0.005062, loss_test: 0.005540
time: 0.2520568370819092
time: 2.2345776557922363
[1, 25575] loss_train: 0.006098, loss_test: 0.005544
time: 0.2470555305480957
time: 2.418264389038086
[1, 25576] loss_train: 0.001479, loss_test: 0.005543
time: 0.25005626678466797
time: 2.395268678665161
[1, 25577] loss_train: 0.006407, loss_test: 0.005537
time: 0.25806093215942383
time: 2.3568642139434814
[1, 25578] loss_train: 0.014542, loss_test: 0.005532
time: 0.24993038177490234
time: 2.2687482833862305
[1, 25579] loss_train: 0.012919, loss_test: 0.005529
time: 0.26598048210144043
time: 2.263970375061035
[1, 25580] loss_train: 0.008094, loss_test: 0.005522
time: 0.2670013904571533
time: 2.2479918003082275
[1, 25581] loss_train: 0.012142, loss_test: 0.005515
time: 0.24802851676940918
time: 2.277959108352661
[1, 25582] loss_train: 0.008321, loss_test: 0.005510
time: 0.3040332794189453
time: 2.2559964656829834
[1, 25583] loss_train: 0.012383, loss_test: 0.005510
time: 0.2430102825164795
time: 2.225588321685791
[1, 25584] loss_train: 0.006425, loss_test: 0.005510
time: 0.24405336380004883
time: 2.236499786376953
[1, 25585] loss_train: 0.008399, loss_test: 0.005513
time: 0.24305438995361328
time: 2.2616701126098633
[1, 25586] loss_train: 0.005929, loss_test: 0.005516
time: 0.2470552921295166
time: 2.3035147190093994
[1, 25587] loss_train: 0.011957, loss_test: 0.005517
time: 0.24505400657653809
time: 2.2505033016204834
[1, 25588] loss_train: 0.005594, loss_test: 0.005520
time: 0.24805545806884766
time: 2.2695119380950928
[1, 25589] loss_train: 0.010225, loss_test: 0.005526
time: 0.2540562152862549
time: 2.3069801330566406
[1, 25590] loss_train: 0.007399, loss_test: 0.005528
time: 0.29280877113342285
time: 2.3735406398773193
[1, 25591] loss_train: 0.006044, loss_test: 0.005537
time: 0.24605512619018555
time: 2.2779674530029297
[1, 25592] loss_train: 0.001818, loss_test: 0.005547
time: 0.24801182746887207
time: 2.2454895973205566
[1, 25593] loss_train: 0.012189, loss_test: 0.005557
time: 0.2470555305480957
time: 2.267507553100586
[1, 25594] loss_train: 0.004644, loss_test: 0.005563
time: 0.24305391311645508
time: 2.2460741996765137
[1, 25595] loss_train: 0.001605, loss_test: 0.005559
time: 0.2450544834136963
time: 2.2631916999816895
[1, 25596] loss_train: 0.002110, loss_test: 0.005557
time: 0.2450549602508545
time: 2.247006416320801
[1, 25597] loss_train: 0.012513, loss_test: 0.005553
time: 0.2580568790435791
time: 2.25221586227417
[1, 25598] loss_train: 0.008519, loss_test: 0.005548
time: 0.24405431747436523
time: 2.2645673751831055
[1, 25599] loss_train: 0.003721, loss_test: 0.005545
time: 0.24792814254760742
time: 2.2424261569976807
[1, 25600] loss_train: 0.009222, loss_test: 0.005539
time: 0.2560570240020752
time: 2.273343086242676
[1, 25601] loss_train: 0.003690, loss_test: 0.005533
time: 0.25705695152282715
time: 2.2497141361236572
[1, 25602] loss_train: 0.006336, loss_test: 0.005528
time: 0.24400854110717773
time: 2.2479875087738037
[1, 25603] loss_train: 0.011999, loss_test: 0.005523
time: 0.24802136421203613
time: 2.2308707237243652
[1, 25604] loss_train: 0.004049, loss_test: 0.005522
time: 0.24205422401428223
time: 2.2895140647888184
[1, 25605] loss_train: 0.002274, loss_test: 0.005521
time: 0.2628955841064453
time: 2.3929622173309326
[1, 25606] loss_train: 0.008116, loss_test: 0.005523
time: 0.24505376815795898
time: 2.2498018741607666
[1, 25607] loss_train: 0.005349, loss_test: 0.005520
time: 0.24505400657653809
time: 2.3615286350250244
[1, 25608] loss_train: 0.003825, loss_test: 0.005517
time: 0.280062198638916
time: 2.3965907096862793
[1, 25609] loss_train: 0.005150, loss_test: 0.005514
time: 0.25005602836608887
time: 2.26950740814209
[1, 25610] loss_train: 0.005034, loss_test: 0.005513
time: 0.265059232711792
time: 2.4529552459716797
[1, 25611] loss_train: 0.004955, loss_test: 0.005513
time: 0.25501370429992676
time: 2.2367136478424072
[1, 25612] loss_train: 0.003862, loss_test: 0.005516
time: 0.2470545768737793
time: 2.4810903072357178
[1, 25613] loss_train: 0.004189, loss_test: 0.005520
time: 0.2540562152862549
time: 2.3155181407928467
[1, 25614] loss_train: 0.004648, loss_test: 0.005526
time: 0.3230714797973633
time: 2.245502233505249
[1, 25615] loss_train: 0.010717, loss_test: 0.005529
time: 0.2490546703338623
time: 2.24750018119812
[1, 25616] loss_train: 0.007557, loss_test: 0.005528
time: 0.26105761528015137
time: 2.5330705642700195
[1, 25617] loss_train: 0.007599, loss_test: 0.005525
time: 0.2890641689300537
time: 2.384977340698242
[1, 25618] loss_train: 0.021997, loss_test: 0.005519
time: 0.25755953788757324
time: 2.3465144634246826
[1, 25619] loss_train: 0.005283, loss_test: 0.005519
time: 0.24305486679077148
time: 2.3210949897766113
[1, 25620] loss_train: 0.002482, loss_test: 0.005520
time: 0.341367244720459
time: 2.2845115661621094
[1, 25621] loss_train: 0.005114, loss_test: 0.005522
time: 0.24905753135681152
time: 2.448547840118408
[1, 25622] loss_train: 0.006228, loss_test: 0.005524
time: 0.3050680160522461
time: 2.312516927719116
[1, 25623] loss_train: 0.002552, loss_test: 0.005524
time: 0.24605441093444824
time: 2.2365005016326904
[1, 25624] loss_train: 0.009634, loss_test: 0.005524
time: 0.27306032180786133
time: 2.3325231075286865
[1, 25625] loss_train: 0.005048, loss_test: 0.005523
time: 0.24805569648742676
time: 2.2297022342681885
[1, 25626] loss_train: 0.006125, loss_test: 0.005524
time: 0.24305391311645508
time: 2.3835337162017822
[1, 25627] loss_train: 0.006443, loss_test: 0.005523
time: 0.24805498123168945
time: 2.3194501399993896
[1, 25628] loss_train: 0.014053, loss_test: 0.005518
time: 0.2940647602081299
time: 2.3425285816192627
[1, 25629] loss_train: 0.011643, loss_test: 0.005515
time: 0.2450544834136963
time: 2.233973503112793
[1, 25630] loss_train: 0.005208, loss_test: 0.005516
time: 0.2620575428009033
time: 2.3495521545410156
[1, 25631] loss_train: 0.004457, loss_test: 0.005520
time: 0.2410581111907959
time: 2.5755014419555664
[1, 25632] loss_train: 0.005708, loss_test: 0.005523
time: 0.39308762550354004
time: 2.450547933578491
[1, 25633] loss_train: 0.009207, loss_test: 0.005524
time: 0.24305438995361328
time: 2.221496343612671
[1, 25634] loss_train: 0.006023, loss_test: 0.005523
time: 0.24305343627929688
time: 2.323519468307495
[1, 25635] loss_train: 0.001319, loss_test: 0.005524
time: 0.2830650806427002
time: 2.235983371734619
[1, 25636] loss_train: 0.005191, loss_test: 0.005526
time: 0.2920670509338379
time: 2.3099892139434814
[1, 25637] loss_train: 0.007791, loss_test: 0.005526
time: 0.24505400657653809
time: 2.230504035949707
[1, 25638] loss_train: 0.011079, loss_test: 0.005523
time: 0.31307196617126465
time: 2.2572686672210693
[1, 25639] loss_train: 0.008690, loss_test: 0.005519
time: 0.24308276176452637
time: 2.2751991748809814
[1, 25640] loss_train: 0.003085, loss_test: 0.005518
time: 0.2670595645904541
time: 2.222926378250122
[1, 25641] loss_train: 0.003635, loss_test: 0.005518
time: 0.24401164054870605
time: 2.2359821796417236
[1, 25642] loss_train: 0.010433, loss_test: 0.005518
time: 0.24593567848205566
time: 2.2370505332946777
[1, 25643] loss_train: 0.003137, loss_test: 0.005518
time: 0.2470557689666748
time: 2.2723355293273926
[1, 25644] loss_train: 0.003571, loss_test: 0.005515
time: 0.25205492973327637
time: 2.2440242767333984
[1, 25645] loss_train: 0.006122, loss_test: 0.005512
time: 0.24405455589294434
time: 2.257504463195801
[1, 25646] loss_train: 0.012757, loss_test: 0.005502
time: 0.2510552406311035
time: 2.2392327785491943
[1, 25647] loss_train: 0.019302, loss_test: 0.005493
time: 0.24805474281311035
time: 2.2682785987854004
[1, 25648] loss_train: 0.008109, loss_test: 0.005492
time: 0.24505400657653809
time: 2.2453818321228027
[1, 25649] loss_train: 0.008302, loss_test: 0.005498
time: 0.24279570579528809
time: 2.243072271347046
[1, 25650] loss_train: 0.006993, loss_test: 0.005507
time: 0.2600367069244385
time: 2.240051507949829
[1, 25651] loss_train: 0.004283, loss_test: 0.005515
time: 0.24305438995361328
time: 2.229053497314453
[1, 25652] loss_train: 0.004431, loss_test: 0.005526
time: 0.24305343627929688
time: 2.2330102920532227
[1, 25653] loss_train: 0.005905, loss_test: 0.005530
time: 0.24405407905578613
time: 2.227263927459717
[1, 25654] loss_train: 0.012466, loss_test: 0.005530
time: 0.24692416191101074
time: 2.320979595184326
[1, 25655] loss_train: 0.002154, loss_test: 0.005517
time: 0.2470550537109375
time: 2.256169319152832
[1, 25656] loss_train: 0.004086, loss_test: 0.005508
time: 0.24802088737487793
time: 2.261507749557495
[1, 25657] loss_train: 0.001802, loss_test: 0.005501
time: 0.24605441093444824
time: 2.2424399852752686
[1, 25658] loss_train: 0.003274, loss_test: 0.005495
time: 0.2450549602508545
time: 2.257031202316284
[1, 25659] loss_train: 0.006831, loss_test: 0.005493
time: 0.24305319786071777
time: 2.2565064430236816
[1, 25660] loss_train: 0.005633, loss_test: 0.005494
time: 0.2670605182647705
time: 2.2475039958953857
[1, 25661] loss_train: 0.006177, loss_test: 0.005499
time: 0.24405479431152344
time: 2.257103681564331
[1, 25662] loss_train: 0.009608, loss_test: 0.005508
time: 0.24605441093444824
time: 2.2174956798553467
[1, 25663] loss_train: 0.004412, loss_test: 0.005517
time: 0.24305415153503418
time: 2.2468655109405518
[1, 25664] loss_train: 0.006546, loss_test: 0.005520
time: 0.24905705451965332
time: 2.2422924041748047
[1, 25665] loss_train: 0.003668, loss_test: 0.005523
time: 0.2450261116027832
time: 2.263028621673584
[1, 25666] loss_train: 0.013416, loss_test: 0.005522
time: 0.24105334281921387
time: 2.270508050918579
[1, 25667] loss_train: 0.006281, loss_test: 0.005516
time: 0.24205374717712402
time: 2.259322166442871
[1, 25668] loss_train: 0.001083, loss_test: 0.005512
time: 0.2520561218261719
time: 2.241501808166504
[1, 25669] loss_train: 0.003460, loss_test: 0.005510
time: 0.24405407905578613
time: 2.2475109100341797
[1, 25670] loss_train: 0.007870, loss_test: 0.005507
time: 0.2600576877593994
time: 2.255507230758667
[1, 25671] loss_train: 0.006101, loss_test: 0.005504
time: 0.24605417251586914
time: 2.2365002632141113
[1, 25672] loss_train: 0.000698, loss_test: 0.005503
time: 0.24305415153503418
time: 2.245847225189209
[1, 25673] loss_train: 0.005206, loss_test: 0.005501
time: 0.2470555305480957
time: 2.25150465965271
[1, 25674] loss_train: 0.003503, loss_test: 0.005503
time: 0.2446608543395996
time: 2.2186381816864014
[1, 25675] loss_train: 0.011275, loss_test: 0.005504
time: 0.24405384063720703
time: 2.2787976264953613
[1, 25676] loss_train: 0.005228, loss_test: 0.005506
time: 0.24765849113464355
time: 2.2921454906463623
[1, 25677] loss_train: 0.010265, loss_test: 0.005499
time: 0.25505638122558594
time: 2.2442498207092285
[1, 25678] loss_train: 0.002157, loss_test: 0.005498
time: 0.2459859848022461
time: 2.2785086631774902
[1, 25679] loss_train: 0.004979, loss_test: 0.005499
time: 0.25005650520324707
time: 2.204493284225464
[1, 25680] loss_train: 0.011025, loss_test: 0.005504
time: 0.26405882835388184
time: 2.2535037994384766
[1, 25681] loss_train: 0.010242, loss_test: 0.005511
time: 0.2490558624267578
time: 2.2480216026306152
[1, 25682] loss_train: 0.002463, loss_test: 0.005517
time: 0.24306583404541016
time: 2.263617515563965
[1, 25683] loss_train: 0.002786, loss_test: 0.005519
time: 0.24305462837219238
time: 2.2400100231170654
[1, 25684] loss_train: 0.008367, loss_test: 0.005522
time: 0.243056058883667
time: 2.241572856903076
[1, 25685] loss_train: 0.007299, loss_test: 0.005523
time: 0.24305415153503418
time: 2.2449870109558105
[1, 25686] loss_train: 0.001618, loss_test: 0.005522
time: 0.24405431747436523
time: 2.2365007400512695
[1, 25687] loss_train: 0.016202, loss_test: 0.005520
time: 0.24405384063720703
time: 2.207493543624878
[1, 25688] loss_train: 0.004119, loss_test: 0.005513
time: 0.24305462837219238
time: 2.2365002632141113
[1, 25689] loss_train: 0.008247, loss_test: 0.005505
time: 0.24405407905578613
time: 2.2196788787841797
[1, 25690] loss_train: 0.014051, loss_test: 0.005499
time: 0.2600584030151367
time: 2.2380058765411377
[1, 25691] loss_train: 0.000947, loss_test: 0.005495
time: 0.24305367469787598
time: 2.238908290863037
[1, 25692] loss_train: 0.004320, loss_test: 0.005493
time: 0.24205398559570312
time: 2.231140613555908
[1, 25693] loss_train: 0.006684, loss_test: 0.005492
time: 0.24205350875854492
time: 2.228565216064453
[1, 25694] loss_train: 0.003608, loss_test: 0.005493
time: 0.24205327033996582
time: 2.2419910430908203
[1, 25695] loss_train: 0.008379, loss_test: 0.005494
time: 0.24953055381774902
time: 2.2179934978485107
[1, 25696] loss_train: 0.008967, loss_test: 0.005495
time: 0.24202203750610352
time: 2.269991397857666
[1, 25697] loss_train: 0.005272, loss_test: 0.005496
time: 0.2440028190612793
time: 2.244971752166748
[1, 25698] loss_train: 0.006329, loss_test: 0.005497
time: 0.24303698539733887
time: 2.217987060546875
[1, 25699] loss_train: 0.006077, loss_test: 0.005499
time: 0.2430119514465332
time: 2.2369651794433594
[1, 25700] loss_train: 0.008221, loss_test: 0.005498
time: 0.2660090923309326
time: 2.256978988647461
[1, 25701] loss_train: 0.002645, loss_test: 0.005499
time: 0.24402213096618652
time: 2.2522428035736084
[1, 25702] loss_train: 0.004029, loss_test: 0.005501
time: 0.24305367469787598
time: 2.2409019470214844
[1, 25703] loss_train: 0.008356, loss_test: 0.005502
time: 0.24305343627929688
time: 2.2295010089874268
[1, 25704] loss_train: 0.008408, loss_test: 0.005501
time: 0.247056245803833
time: 2.2413923740386963
[1, 25705] loss_train: 0.003389, loss_test: 0.005502
time: 0.2580573558807373
time: 2.256504774093628
[1, 25706] loss_train: 0.016029, loss_test: 0.005498
time: 0.2620584964752197
time: 2.2598865032196045
[1, 25707] loss_train: 0.004193, loss_test: 0.005498
time: 0.24305367469787598
time: 2.2205049991607666
[1, 25708] loss_train: 0.007663, loss_test: 0.005497
time: 0.2481069564819336
time: 2.228780746459961
[1, 25709] loss_train: 0.013189, loss_test: 0.005495
time: 0.25905752182006836
time: 2.2264978885650635
[1, 25710] loss_train: 0.003115, loss_test: 0.005498
time: 0.25826525688171387
time: 2.2523345947265625
[1, 25711] loss_train: 0.002596, loss_test: 0.005503
time: 0.25005578994750977
time: 2.246746301651001
[1, 25712] loss_train: 0.004238, loss_test: 0.005509
time: 0.24905657768249512
time: 2.2965126037597656
[1, 25713] loss_train: 0.005278, loss_test: 0.005516
time: 0.2810633182525635
time: 2.2509379386901855
[1, 25714] loss_train: 0.005340, loss_test: 0.005523
time: 0.2450547218322754
time: 2.2261834144592285
[1, 25715] loss_train: 0.007515, loss_test: 0.005532
time: 0.24798917770385742
time: 2.220994234085083
[1, 25716] loss_train: 0.007316, loss_test: 0.005538
time: 0.24702191352844238
time: 2.2309751510620117
[1, 25717] loss_train: 0.006689, loss_test: 0.005542
time: 0.24901533126831055
time: 2.2580127716064453
[1, 25718] loss_train: 0.005819, loss_test: 0.005545
time: 0.24396061897277832
time: 2.2450053691864014
[1, 25719] loss_train: 0.011269, loss_test: 0.005546
time: 0.25199127197265625
time: 2.238043785095215
[1, 25720] loss_train: 0.005034, loss_test: 0.005549
time: 0.25777435302734375
time: 2.2571942806243896
[1, 25721] loss_train: 0.008939, loss_test: 0.005554
time: 0.25101447105407715
time: 2.2107093334198
[1, 25722] loss_train: 0.001764, loss_test: 0.005562
time: 0.24405431747436523
time: 2.2475032806396484
[1, 25723] loss_train: 0.005716, loss_test: 0.005565
time: 0.24805474281311035
time: 2.23313045501709
[1, 25724] loss_train: 0.006948, loss_test: 0.005568
time: 0.24405503273010254
time: 2.2525031566619873
[1, 25725] loss_train: 0.007535, loss_test: 0.005566
time: 0.25505733489990234
time: 2.2405102252960205
[1, 25726] loss_train: 0.003617, loss_test: 0.005566
time: 0.24305367469787598
time: 2.2388224601745605
[1, 25727] loss_train: 0.006872, loss_test: 0.005564
time: 0.2540583610534668
time: 2.2229442596435547
[1, 25728] loss_train: 0.001255, loss_test: 0.005562
time: 0.24605488777160645
time: 2.227431058883667
[1, 25729] loss_train: 0.006215, loss_test: 0.005559
time: 0.24600934982299805
time: 2.2819764614105225
[1, 25730] loss_train: 0.017088, loss_test: 0.005548
time: 0.25603580474853516
time: 2.2410266399383545
[1, 25731] loss_train: 0.006317, loss_test: 0.005541
time: 0.24405455589294434
time: 2.22049617767334
[1, 25732] loss_train: 0.008898, loss_test: 0.005537
time: 0.24305343627929688
time: 2.2365002632141113
[1, 25733] loss_train: 0.010709, loss_test: 0.005540
time: 0.24605464935302734
time: 2.2513585090637207
[1, 25734] loss_train: 0.004863, loss_test: 0.005549
time: 0.24305391311645508
time: 2.2610082626342773
[1, 25735] loss_train: 0.002033, loss_test: 0.005550
time: 0.25005602836608887
time: 2.259101152420044
[1, 25736] loss_train: 0.002560, loss_test: 0.005553
time: 0.2475595474243164
time: 2.2664003372192383
[1, 25737] loss_train: 0.004813, loss_test: 0.005552
time: 0.2450544834136963
time: 2.253293752670288
[1, 25738] loss_train: 0.005945, loss_test: 0.005546
time: 0.2470548152923584
time: 2.255199909210205
[1, 25739] loss_train: 0.004472, loss_test: 0.005540
time: 0.24405431747436523
time: 2.2447898387908936
[1, 25740] loss_train: 0.002795, loss_test: 0.005534
time: 0.2580583095550537
time: 2.2445015907287598
[1, 25741] loss_train: 0.003832, loss_test: 0.005529
time: 0.24305415153503418
time: 2.2632765769958496
[1, 25742] loss_train: 0.004551, loss_test: 0.005527
time: 0.24505376815795898
time: 2.234790325164795
[1, 25743] loss_train: 0.007120, loss_test: 0.005526
time: 0.24246549606323242
time: 2.259211540222168
[1, 25744] loss_train: 0.003706, loss_test: 0.005527
time: 0.24605488777160645
time: 2.248267412185669
[1, 25745] loss_train: 0.007105, loss_test: 0.005529
time: 0.24401259422302246
time: 2.260274887084961
[1, 25746] loss_train: 0.003503, loss_test: 0.005534
time: 0.2490553855895996
time: 2.255504846572876
[1, 25747] loss_train: 0.003801, loss_test: 0.005539
time: 0.24405431747436523
time: 2.2535037994384766
[1, 25748] loss_train: 0.000431, loss_test: 0.005546
time: 0.24405455589294434
time: 2.2445015907287598
[1, 25749] loss_train: 0.005678, loss_test: 0.005552
time: 0.24405455589294434
time: 2.254598379135132
[1, 25750] loss_train: 0.007876, loss_test: 0.005560
time: 0.2620577812194824
time: 2.2435898780822754
[1, 25751] loss_train: 0.002682, loss_test: 0.005568
time: 0.24405455589294434
time: 2.2635059356689453
[1, 25752] loss_train: 0.002544, loss_test: 0.005576
time: 0.24355721473693848
time: 2.2493622303009033
[1, 25753] loss_train: 0.004420, loss_test: 0.005583
time: 0.24405407905578613
time: 2.2465131282806396
[1, 25754] loss_train: 0.013599, loss_test: 0.005582
time: 0.2466423511505127
time: 2.2588953971862793
[1, 25755] loss_train: 0.004087, loss_test: 0.005583
time: 0.2421267032623291
time: 2.260519504547119
[1, 25756] loss_train: 0.005302, loss_test: 0.005582
time: 0.24405431747436523
time: 2.243501663208008
[1, 25757] loss_train: 0.011310, loss_test: 0.005580
time: 0.24205446243286133
time: 2.2525041103363037
[1, 25758] loss_train: 0.007459, loss_test: 0.005577
time: 0.24381136894226074
time: 2.232079029083252
[1, 25759] loss_train: 0.005284, loss_test: 0.005573
time: 0.2470695972442627
time: 2.2555038928985596
[1, 25760] loss_train: 0.003351, loss_test: 0.005571
time: 0.25905823707580566
time: 2.247361660003662
[1, 25761] loss_train: 0.009312, loss_test: 0.005568
time: 0.24305462837219238
time: 2.2679173946380615
[1, 25762] loss_train: 0.005254, loss_test: 0.005565
time: 0.2470560073852539
time: 2.2420573234558105
[1, 25763] loss_train: 0.007693, loss_test: 0.005558
time: 0.2455592155456543
time: 2.2682950496673584
[1, 25764] loss_train: 0.001144, loss_test: 0.005552
time: 0.24405407905578613
time: 2.245006799697876
[1, 25765] loss_train: 0.004742, loss_test: 0.005544
time: 0.24329090118408203
time: 2.229957342147827
[1, 25766] loss_train: 0.009717, loss_test: 0.005534
time: 0.24502086639404297
time: 2.2465429306030273
[1, 25767] loss_train: 0.007690, loss_test: 0.005531
time: 0.25205540657043457
time: 2.2715084552764893
[1, 25768] loss_train: 0.001901, loss_test: 0.005529
time: 0.24505400657653809
time: 2.233499765396118
[1, 25769] loss_train: 0.004812, loss_test: 0.005528
time: 0.24305438995361328
time: 2.2485032081604004
[1, 25770] loss_train: 0.005486, loss_test: 0.005529
time: 0.25807690620422363
time: 2.249861717224121
[1, 25771] loss_train: 0.001989, loss_test: 0.005530
time: 0.25005578994750977
time: 2.2590596675872803
[1, 25772] loss_train: 0.004688, loss_test: 0.005531
time: 0.25505709648132324
time: 2.283510208129883
[1, 25773] loss_train: 0.005512, loss_test: 0.005530
time: 0.2455592155456543
time: 2.261364221572876
[1, 25774] loss_train: 0.009038, loss_test: 0.005528
time: 0.2470555305480957
time: 2.244124174118042
[1, 25775] loss_train: 0.001727, loss_test: 0.005526
time: 0.25005602836608887
time: 2.286968946456909
[1, 25776] loss_train: 0.005444, loss_test: 0.005525
time: 0.2470088005065918
time: 2.2719743251800537
[1, 25777] loss_train: 0.002534, loss_test: 0.005524
time: 0.24299860000610352
time: 2.299705743789673
[1, 25778] loss_train: 0.003745, loss_test: 0.005526
time: 0.24405407905578613
time: 2.252650260925293
[1, 25779] loss_train: 0.008419, loss_test: 0.005524
time: 0.2490553855895996
time: 2.290349245071411
[1, 25780] loss_train: 0.003943, loss_test: 0.005528
time: 0.25705671310424805
time: 2.2505037784576416
[1, 25781] loss_train: 0.004808, loss_test: 0.005538
time: 0.24605441093444824
time: 2.2775096893310547
[1, 25782] loss_train: 0.007821, loss_test: 0.005554
time: 0.24205374717712402
time: 2.263519763946533
[1, 25783] loss_train: 0.011437, loss_test: 0.005589
time: 0.25505685806274414
time: 2.2875115871429443
[1, 25784] loss_train: 0.006297, loss_test: 0.005638
time: 0.2470545768737793
time: 2.306516647338867
[1, 25785] loss_train: 0.014962, loss_test: 0.005684
time: 0.24505352973937988
time: 2.3060598373413086
[1, 25786] loss_train: 0.003002, loss_test: 0.005735
time: 0.2502114772796631
time: 2.3129518032073975
[1, 25787] loss_train: 0.005968, loss_test: 0.005740
time: 0.2530200481414795
time: 2.241973638534546
[1, 25788] loss_train: 0.004224, loss_test: 0.005726
time: 0.24387526512145996
time: 2.2331273555755615
[1, 25789] loss_train: 0.015457, loss_test: 0.005683
time: 0.2460329532623291
time: 2.2348577976226807
[1, 25790] loss_train: 0.004418, loss_test: 0.005622
time: 0.25705695152282715
time: 2.244506359100342
[1, 25791] loss_train: 0.011146, loss_test: 0.005561
time: 0.24605393409729004
time: 2.233499050140381
[1, 25792] loss_train: 0.004334, loss_test: 0.005520
time: 0.24305438995361328
time: 2.2555065155029297
[1, 25793] loss_train: 0.006637, loss_test: 0.005506
time: 0.2470548152923584
time: 2.271507740020752
[1, 25794] loss_train: 0.004532, loss_test: 0.005522
time: 0.2620584964752197
time: 2.2415037155151367
[1, 25795] loss_train: 0.008373, loss_test: 0.005560
time: 0.24505400657653809
time: 2.243502378463745
[1, 25796] loss_train: 0.008713, loss_test: 0.005610
time: 0.24005365371704102
time: 2.251012086868286
[1, 25797] loss_train: 0.004525, loss_test: 0.005668
time: 0.24305462837219238
time: 2.245227098464966
[1, 25798] loss_train: 0.004792, loss_test: 0.005707
time: 0.24305438995361328
time: 2.248504400253296
[1, 25799] loss_train: 0.006711, loss_test: 0.005735
time: 0.25305700302124023
time: 2.251582145690918
[1, 25800] loss_train: 0.004967, loss_test: 0.005734
time: 0.2580578327178955
time: 2.260432481765747
[1, 25801] loss_train: 0.006213, loss_test: 0.005731
time: 0.24605488777160645
time: 2.2445068359375
[1, 25802] loss_train: 0.015875, loss_test: 0.005710
time: 0.24805545806884766
time: 2.2698988914489746
[1, 25803] loss_train: 0.006760, loss_test: 0.005692
time: 0.24605655670166016
time: 2.2825112342834473
[1, 25804] loss_train: 0.007671, loss_test: 0.005656
time: 0.2450542449951172
time: 2.3097143173217773
[1, 25805] loss_train: 0.004063, loss_test: 0.005621
time: 0.25022053718566895
time: 2.2917163372039795
[1, 25806] loss_train: 0.003805, loss_test: 0.005600
time: 0.25705718994140625
time: 2.279256820678711
[1, 25807] loss_train: 0.004278, loss_test: 0.005590
time: 0.24405694007873535
time: 2.2344634532928467
[1, 25808] loss_train: 0.005058, loss_test: 0.005591
time: 0.24490666389465332
time: 2.2760815620422363
[1, 25809] loss_train: 0.004345, loss_test: 0.005600
time: 0.24836111068725586
time: 2.266105890274048
[1, 25810] loss_train: 0.004986, loss_test: 0.005612
time: 0.2650585174560547
time: 2.286580801010132
[1, 25811] loss_train: 0.008917, loss_test: 0.005618
time: 0.25005602836608887
time: 2.26450777053833
[1, 25812] loss_train: 0.002311, loss_test: 0.005626
time: 0.2580571174621582
time: 2.242006540298462
[1, 25813] loss_train: 0.003779, loss_test: 0.005632
time: 0.25305700302124023
time: 2.261505603790283
[1, 25814] loss_train: 0.007981, loss_test: 0.005631
time: 0.2537238597869873
time: 2.285386800765991
[1, 25815] loss_train: 0.007065, loss_test: 0.005622
time: 0.24404597282409668
time: 2.2335236072540283
[1, 25816] loss_train: 0.009539, loss_test: 0.005602
time: 0.2609896659851074
time: 2.2599966526031494
[1, 25817] loss_train: 0.005239, loss_test: 0.005580
time: 0.2440204620361328
time: 2.2871673107147217
[1, 25818] loss_train: 0.007124, loss_test: 0.005554
time: 0.2540562152862549
time: 2.3642821311950684
[1, 25819] loss_train: 0.007242, loss_test: 0.005538
time: 0.2450566291809082
time: 2.2436580657958984
[1, 25820] loss_train: 0.003367, loss_test: 0.005530
time: 0.26605892181396484
time: 2.2425014972686768
[1, 25821] loss_train: 0.006175, loss_test: 0.005527
time: 0.2450549602508545
time: 2.256517171859741
[1, 25822] loss_train: 0.002995, loss_test: 0.005523
time: 0.2450544834136963
time: 2.2405807971954346
[1, 25823] loss_train: 0.003115, loss_test: 0.005520
time: 0.24305415153503418
time: 2.246227264404297
[1, 25824] loss_train: 0.001652, loss_test: 0.005512
time: 0.2439100742340088
time: 2.217794179916382
[1, 25825] loss_train: 0.004116, loss_test: 0.005505
time: 0.24400925636291504
time: 2.302959442138672
[1, 25826] loss_train: 0.005808, loss_test: 0.005500
time: 0.2448420524597168
time: 2.2702255249023438
[1, 25827] loss_train: 0.014184, loss_test: 0.005495
time: 0.24305367469787598
time: 2.2455029487609863
[1, 25828] loss_train: 0.007113, loss_test: 0.005492
time: 0.24205279350280762
time: 2.2367193698883057
[1, 25829] loss_train: 0.012474, loss_test: 0.005491
time: 0.24305415153503418
time: 2.2535037994384766
[1, 25830] loss_train: 0.006776, loss_test: 0.005489
time: 0.27306079864501953
time: 2.436544895172119
[1, 25831] loss_train: 0.006467, loss_test: 0.005488
time: 0.2890644073486328
time: 2.3245201110839844
[1, 25832] loss_train: 0.008973, loss_test: 0.005488
time: 0.28806447982788086
time: 2.3535282611846924
[1, 25833] loss_train: 0.008679, loss_test: 0.005490
time: 0.24205374717712402
time: 2.380737543106079
[1, 25834] loss_train: 0.005134, loss_test: 0.005494
time: 0.24814200401306152
time: 2.238046884536743
[1, 25835] loss_train: 0.005868, loss_test: 0.005494
time: 0.24294090270996094
time: 2.2304983139038086
[1, 25836] loss_train: 0.006329, loss_test: 0.005496
time: 0.24405670166015625
time: 2.248023509979248
[1, 25837] loss_train: 0.002037, loss_test: 0.005495
time: 0.24305438995361328
time: 2.220001697540283
[1, 25838] loss_train: 0.008065, loss_test: 0.005497
time: 0.24605512619018555
time: 2.221498489379883
[1, 25839] loss_train: 0.008969, loss_test: 0.005498
time: 0.24405455589294434
time: 2.2415008544921875
[1, 25840] loss_train: 0.007945, loss_test: 0.005498
time: 0.2670595645904541
time: 2.208880662918091
[1, 25841] loss_train: 0.008718, loss_test: 0.005498
time: 0.2450554370880127
time: 2.245502233505249
[1, 25842] loss_train: 0.004962, loss_test: 0.005497
time: 0.2450549602508545
time: 2.3383724689483643
[1, 25843] loss_train: 0.011718, loss_test: 0.005494
time: 0.2430565357208252
time: 2.266409158706665
[1, 25844] loss_train: 0.004593, loss_test: 0.005489
time: 0.24603033065795898
time: 2.2671620845794678
[1, 25845] loss_train: 0.007185, loss_test: 0.005486
time: 0.24805474281311035
time: 2.2383639812469482
[1, 25846] loss_train: 0.008907, loss_test: 0.005484
time: 0.24305367469787598
time: 2.2503855228424072
[1, 25847] loss_train: 0.002609, loss_test: 0.005485
time: 0.25305652618408203
time: 2.221311330795288
[1, 25848] loss_train: 0.000469, loss_test: 0.005488
time: 0.24305391311645508
time: 2.2828779220581055
[1, 25849] loss_train: 0.006612, loss_test: 0.005491
time: 0.25005602836608887
time: 2.2625083923339844
[1, 25850] loss_train: 0.008461, loss_test: 0.005494
time: 0.25705742835998535
time: 2.2395007610321045
[1, 25851] loss_train: 0.008396, loss_test: 0.005498
time: 0.24305319786071777
time: 2.2474515438079834
[1, 25852] loss_train: 0.005436, loss_test: 0.005501
time: 0.2454853057861328
time: 2.239145517349243
[1, 25853] loss_train: 0.002887, loss_test: 0.005506
time: 0.25905704498291016
time: 2.2505040168762207
[1, 25854] loss_train: 0.005617, loss_test: 0.005510
time: 0.24305415153503418
time: 2.2627856731414795
[1, 25855] loss_train: 0.007535, loss_test: 0.005513
time: 0.24305391311645508
time: 2.2590749263763428
[1, 25856] loss_train: 0.015055, loss_test: 0.005510
time: 0.24505400657653809
time: 2.2588460445404053
[1, 25857] loss_train: 0.006330, loss_test: 0.005507
time: 0.2490556240081787
time: 2.2905120849609375
[1, 25858] loss_train: 0.003149, loss_test: 0.005504
time: 0.2470552921295166
time: 2.248504400253296
[1, 25859] loss_train: 0.003395, loss_test: 0.005503
time: 0.24305415153503418
time: 2.24631404876709
[1, 25860] loss_train: 0.004134, loss_test: 0.005504
time: 0.2564680576324463
time: 2.26493501663208
[1, 25861] loss_train: 0.010023, loss_test: 0.005501
time: 0.2450551986694336
time: 2.2247543334960938
[1, 25862] loss_train: 0.004254, loss_test: 0.005502
time: 0.2529938220977783
time: 2.2680070400238037
[1, 25863] loss_train: 0.005104, loss_test: 0.005504
time: 0.24605464935302734
time: 2.245513439178467
[1, 25864] loss_train: 0.006069, loss_test: 0.005509
time: 0.24405384063720703
time: 2.269510269165039
[1, 25865] loss_train: 0.001701, loss_test: 0.005516
time: 0.24605464935302734
time: 2.241501808166504
[1, 25866] loss_train: 0.011095, loss_test: 0.005523
time: 0.24805521965026855
time: 2.240286350250244
[1, 25867] loss_train: 0.000464, loss_test: 0.005532
time: 0.24405384063720703
time: 2.2402262687683105
[1, 25868] loss_train: 0.005365, loss_test: 0.005543
time: 0.2450549602508545
time: 2.2815639972686768
[1, 25869] loss_train: 0.004722, loss_test: 0.005554
time: 0.2450547218322754
time: 2.273763418197632
[1, 25870] loss_train: 0.012511, loss_test: 0.005559
time: 0.2620584964752197
time: 2.297513484954834
[1, 25871] loss_train: 0.015494, loss_test: 0.005557
time: 0.2510557174682617
time: 2.331573009490967
[1, 25872] loss_train: 0.010837, loss_test: 0.005547
time: 0.24205350875854492
time: 2.257505178451538
[1, 25873] loss_train: 0.004293, loss_test: 0.005543
time: 0.2454056739807129
time: 2.272508382797241
[1, 25874] loss_train: 0.001790, loss_test: 0.005536
time: 0.24305415153503418
time: 2.2410595417022705
[1, 25875] loss_train: 0.007595, loss_test: 0.005525
time: 0.25005602836608887
time: 2.257458209991455
[1, 25876] loss_train: 0.007732, loss_test: 0.005522
time: 0.245560884475708
time: 2.2360973358154297
[1, 25877] loss_train: 0.015307, loss_test: 0.005525
time: 0.2450542449951172
time: 2.296351671218872
[1, 25878] loss_train: 0.003440, loss_test: 0.005529
time: 0.2540738582611084
time: 2.2529048919677734
[1, 25879] loss_train: 0.000767, loss_test: 0.005534
time: 0.2509620189666748
time: 2.2280404567718506
[1, 25880] loss_train: 0.010882, loss_test: 0.005538
time: 0.25603699684143066
time: 2.2445054054260254
[1, 25881] loss_train: 0.004906, loss_test: 0.005542
time: 0.24405455589294434
time: 2.258504867553711
[1, 25882] loss_train: 0.009899, loss_test: 0.005536
time: 0.24205422401428223
time: 2.288511276245117
[1, 25883] loss_train: 0.003056, loss_test: 0.005521
time: 0.25305724143981934
time: 2.247504949569702
[1, 25884] loss_train: 0.010872, loss_test: 0.005509
time: 0.24405455589294434
time: 2.2565064430236816
[1, 25885] loss_train: 0.004060, loss_test: 0.005500
time: 0.24520516395568848
time: 2.246161699295044
[1, 25886] loss_train: 0.011194, loss_test: 0.005494
time: 0.2450544834136963
time: 2.3103504180908203
[1, 25887] loss_train: 0.006344, loss_test: 0.005494
time: 0.2510559558868408
time: 2.3025147914886475
[1, 25888] loss_train: 0.011370, loss_test: 0.005495
time: 0.2490558624267578
time: 2.2547597885131836
[1, 25889] loss_train: 0.000981, loss_test: 0.005499
time: 0.24901986122131348
time: 2.256378412246704
[1, 25890] loss_train: 0.006456, loss_test: 0.005506
time: 0.2630586624145508
time: 2.247502326965332
[1, 25891] loss_train: 0.007641, loss_test: 0.005517
time: 0.24905610084533691
time: 2.3575267791748047
[1, 25892] loss_train: 0.007156, loss_test: 0.005525
time: 0.2450542449951172
time: 2.2905113697052
[1, 25893] loss_train: 0.007577, loss_test: 0.005527
time: 0.2490551471710205
time: 2.2931313514709473
[1, 25894] loss_train: 0.010038, loss_test: 0.005528
time: 0.2520558834075928
time: 2.333521604537964
[1, 25895] loss_train: 0.006100, loss_test: 0.005520
time: 0.2580578327178955
time: 2.3315210342407227
[1, 25896] loss_train: 0.004960, loss_test: 0.005518
time: 0.26405882835388184
time: 2.3660659790039062
[1, 25897] loss_train: 0.003187, loss_test: 0.005518
time: 0.2650587558746338
time: 2.297513723373413
[1, 25898] loss_train: 0.003532, loss_test: 0.005519
time: 0.25005173683166504
time: 2.23250675201416
[1, 25899] loss_train: 0.002163, loss_test: 0.005520
time: 0.2490551471710205
time: 2.3030200004577637
[1, 25900] loss_train: 0.005919, loss_test: 0.005520
time: 0.2630584239959717
time: 2.2665064334869385
[1, 25901] loss_train: 0.011988, loss_test: 0.005520
time: 0.24305462837219238
time: 2.271507978439331
[1, 25902] loss_train: 0.002758, loss_test: 0.005519
time: 0.24405527114868164
time: 2.264505386352539
[1, 25903] loss_train: 0.005959, loss_test: 0.005516
time: 0.24305367469787598
time: 2.2400052547454834
[1, 25904] loss_train: 0.008252, loss_test: 0.005514
time: 0.24405384063720703
time: 2.2605061531066895
[1, 25905] loss_train: 0.011027, loss_test: 0.005513
time: 0.24305438995361328
time: 2.271507501602173
[1, 25906] loss_train: 0.004483, loss_test: 0.005512
time: 0.24305343627929688
time: 2.2505037784576416
[1, 25907] loss_train: 0.004477, loss_test: 0.005510
time: 0.24405431747436523
time: 2.261474609375
[1, 25908] loss_train: 0.003178, loss_test: 0.005507
time: 0.25005531311035156
time: 2.3705320358276367
[1, 25909] loss_train: 0.002207, loss_test: 0.005505
time: 0.24505376815795898
time: 2.3052539825439453
[1, 25910] loss_train: 0.017596, loss_test: 0.005503
time: 0.2630579471588135
time: 2.2765097618103027
[1, 25911] loss_train: 0.002865, loss_test: 0.005503
time: 0.24105358123779297
time: 2.271507740020752
[1, 25912] loss_train: 0.006321, loss_test: 0.005504
time: 0.24305391311645508
time: 2.3425240516662598
[1, 25913] loss_train: 0.006077, loss_test: 0.005504
time: 0.24805569648742676
time: 2.3105180263519287
[1, 25914] loss_train: 0.002214, loss_test: 0.005504
time: 0.25505614280700684
time: 2.290512800216675
[1, 25915] loss_train: 0.006364, loss_test: 0.005504
time: 0.2600581645965576
time: 2.3615264892578125
[1, 25916] loss_train: 0.002464, loss_test: 0.005504
time: 0.32807374000549316
time: 2.410538911819458
[1, 25917] loss_train: 0.006649, loss_test: 0.005506
time: 0.2600584030151367
time: 2.3805320262908936
[1, 25918] loss_train: 0.002210, loss_test: 0.005510
time: 0.256056547164917
time: 2.3115172386169434
[1, 25919] loss_train: 0.009415, loss_test: 0.005509
time: 0.27506136894226074
time: 2.4295430183410645
[1, 25920] loss_train: 0.000895, loss_test: 0.005511
time: 0.27005982398986816
time: 2.3925349712371826
[1, 25921] loss_train: 0.001207, loss_test: 0.005516
time: 0.2650589942932129
time: 2.3845338821411133
[1, 25922] loss_train: 0.008108, loss_test: 0.005518
time: 0.25705671310424805
time: 2.3255205154418945
[1, 25923] loss_train: 0.005121, loss_test: 0.005518
time: 0.25505709648132324
time: 2.320518732070923
[1, 25924] loss_train: 0.004463, loss_test: 0.005518
time: 0.24405360221862793
time: 2.284511089324951
[1, 25925] loss_train: 0.005922, loss_test: 0.005518
time: 0.25305628776550293
time: 2.258504629135132
[1, 25926] loss_train: 0.005989, loss_test: 0.005516
time: 0.2540566921234131
time: 2.2927372455596924
[1, 25927] loss_train: 0.004677, loss_test: 0.005515
time: 0.2520565986633301
time: 2.312516212463379
[1, 25928] loss_train: 0.012181, loss_test: 0.005514
time: 0.25905799865722656
time: 2.345524311065674
[1, 25929] loss_train: 0.004946, loss_test: 0.005514
time: 0.3100700378417969
time: 2.3775312900543213
[1, 25930] loss_train: 0.008372, loss_test: 0.005503
time: 0.2600576877593994
time: 2.3645286560058594
[1, 25931] loss_train: 0.001690, loss_test: 0.005498
time: 0.3700835704803467
time: 2.5498692989349365
[1, 25932] loss_train: 0.004633, loss_test: 0.005497
time: 0.2620580196380615
time: 2.430544376373291
[1, 25933] loss_train: 0.007859, loss_test: 0.005498
time: 0.26805973052978516
time: 2.4425454139709473
[1, 25934] loss_train: 0.003009, loss_test: 0.005499
time: 0.3720836639404297
time: 2.4735536575317383
[1, 25935] loss_train: 0.024322, loss_test: 0.005502
time: 0.2920675277709961
time: 2.345524549484253
[1, 25936] loss_train: 0.007345, loss_test: 0.005505
time: 0.2530546188354492
time: 2.2975142002105713
[1, 25937] loss_train: 0.007988, loss_test: 0.005507
time: 0.2450711727142334
time: 2.349524974822998
[1, 25938] loss_train: 0.003153, loss_test: 0.005509
time: 0.2530558109283447
time: 2.305020809173584
[1, 25939] loss_train: 0.008799, loss_test: 0.005509
time: 0.2490558624267578
time: 2.2605209350585938
[1, 25940] loss_train: 0.014403, loss_test: 0.005510
time: 0.2645120620727539
time: 2.294022798538208
[1, 25941] loss_train: 0.005750, loss_test: 0.005509
time: 0.25005602836608887
time: 2.276012420654297
[1, 25942] loss_train: 0.007088, loss_test: 0.005509
time: 0.24405455589294434
time: 2.249091625213623
[1, 25943] loss_train: 0.005003, loss_test: 0.005507
time: 0.25005531311035156
time: 2.2690141201019287
[1, 25944] loss_train: 0.004947, loss_test: 0.005506
time: 0.2450544834136963
time: 2.2395691871643066
[1, 25945] loss_train: 0.007457, loss_test: 0.005505
time: 0.2490546703338623
time: 2.271152973175049
[1, 25946] loss_train: 0.013883, loss_test: 0.005504
time: 0.2450547218322754
time: 2.2665414810180664
[1, 25947] loss_train: 0.010495, loss_test: 0.005502
time: 0.24605512619018555
time: 2.2962698936462402
[1, 25948] loss_train: 0.003896, loss_test: 0.005501
time: 0.25505685806274414
time: 2.393535614013672
[1, 25949] loss_train: 0.006260, loss_test: 0.005498
time: 0.27606201171875
time: 2.332584857940674
[1, 25950] loss_train: 0.008187, loss_test: 0.005497
time: 0.25907254219055176
time: 2.2920260429382324
[1, 25951] loss_train: 0.003607, loss_test: 0.005497
time: 0.2580568790435791
time: 2.2965216636657715
[1, 25952] loss_train: 0.006397, loss_test: 0.005497
time: 0.24605369567871094
time: 2.262023687362671
[1, 25953] loss_train: 0.006334, loss_test: 0.005499
time: 0.24405360221862793
time: 2.2699806690216064
[1, 25954] loss_train: 0.008073, loss_test: 0.005501
time: 0.2640571594238281
time: 2.2775120735168457
[1, 25955] loss_train: 0.002992, loss_test: 0.005504
time: 0.254056453704834
time: 2.279510498046875
[1, 25956] loss_train: 0.002308, loss_test: 0.005506
time: 0.25905728340148926
time: 2.303515672683716
[1, 25957] loss_train: 0.005198, loss_test: 0.005507
time: 0.24605512619018555
time: 2.2725112438201904
[1, 25958] loss_train: 0.001568, loss_test: 0.005509
time: 0.2620584964752197
time: 2.2765085697174072
[1, 25959] loss_train: 0.005851, loss_test: 0.005509
time: 0.2540555000305176
time: 2.3812410831451416
[1, 25960] loss_train: 0.008899, loss_test: 0.005509
time: 0.2670619487762451
time: 2.3831522464752197
[1, 25961] loss_train: 0.005538, loss_test: 0.005504
time: 0.2560558319091797
time: 2.424583911895752
[1, 25962] loss_train: 0.004740, loss_test: 0.005501
time: 0.2818942070007324
time: 2.5333454608917236
[1, 25963] loss_train: 0.001983, loss_test: 0.005499
time: 0.2530558109283447
time: 2.2775092124938965
[1, 25964] loss_train: 0.001853, loss_test: 0.005499
time: 0.25705718994140625
time: 2.3320271968841553
[1, 25965] loss_train: 0.005160, loss_test: 0.005502
time: 0.2890644073486328
time: 2.4110605716705322
[1, 25966] loss_train: 0.002408, loss_test: 0.005507
time: 0.3290719985961914
time: 2.459763288497925
[1, 25967] loss_train: 0.002716, loss_test: 0.005512
time: 0.252056360244751
time: 2.5010881423950195
[1, 25968] loss_train: 0.002896, loss_test: 0.005519
time: 0.2830624580383301
time: 2.592794179916382
[1, 25969] loss_train: 0.008660, loss_test: 0.005524
time: 0.37908411026000977
time: 2.4115400314331055
[1, 25970] loss_train: 0.003684, loss_test: 0.005529
time: 0.26607179641723633
time: 2.398547649383545
[1, 25971] loss_train: 0.008738, loss_test: 0.005527
time: 0.2450549602508545
time: 2.3370258808135986
[1, 25972] loss_train: 0.006721, loss_test: 0.005524
time: 0.26405954360961914
time: 2.398041248321533
[1, 25973] loss_train: 0.013555, loss_test: 0.005520
time: 0.28406286239624023
time: 2.4125523567199707
[1, 25974] loss_train: 0.001877, loss_test: 0.005520
time: 0.24805426597595215
time: 2.272608757019043
[1, 25975] loss_train: 0.005271, loss_test: 0.005519
time: 0.2433016300201416
time: 2.4945590496063232
[1, 25976] loss_train: 0.007710, loss_test: 0.005519
time: 0.2560577392578125
time: 2.4784305095672607
[1, 25977] loss_train: 0.006810, loss_test: 0.005516
time: 0.29006290435791016
time: 2.335522413253784
[1, 25978] loss_train: 0.003513, loss_test: 0.005515
time: 0.40409231185913086
time: 2.324528455734253
[1, 25979] loss_train: 0.001174, loss_test: 0.005516
time: 0.2450547218322754
time: 2.2500059604644775
[1, 25980] loss_train: 0.012123, loss_test: 0.005516
time: 0.2630586624145508
time: 2.3625288009643555
[1, 25981] loss_train: 0.017491, loss_test: 0.005512
time: 0.2470545768737793
time: 2.3230273723602295
[1, 25982] loss_train: 0.004306, loss_test: 0.005510
time: 0.24805474281311035
time: 2.235029697418213
[1, 25983] loss_train: 0.003665, loss_test: 0.005508
time: 0.24405384063720703
time: 2.3105087280273438
[1, 25984] loss_train: 0.005077, loss_test: 0.005507
time: 0.3059542179107666
time: 2.3175294399261475
[1, 25985] loss_train: 0.004213, loss_test: 0.005507
time: 0.24805474281311035
time: 2.25949764251709
[1, 25986] loss_train: 0.006883, loss_test: 0.005505
time: 0.24305391311645508
time: 2.2505035400390625
[1, 25987] loss_train: 0.000534, loss_test: 0.005505
time: 0.2450547218322754
time: 2.2860140800476074
[1, 25988] loss_train: 0.000930, loss_test: 0.005507
time: 0.24505615234375
time: 2.266516923904419
[1, 25989] loss_train: 0.013794, loss_test: 0.005507
time: 0.2502143383026123
time: 2.3585305213928223
[1, 25990] loss_train: 0.003746, loss_test: 0.005509
time: 0.26459288597106934
time: 2.319836378097534
[1, 25991] loss_train: 0.013609, loss_test: 0.005506
time: 0.265059232711792
time: 2.309518337249756
[1, 25992] loss_train: 0.006087, loss_test: 0.005503
time: 0.26805996894836426
time: 2.3335766792297363
[1, 25993] loss_train: 0.005977, loss_test: 0.005500
time: 0.25505757331848145
time: 2.280517339706421
[1, 25994] loss_train: 0.010826, loss_test: 0.005498
time: 0.25505661964416504
time: 2.2975189685821533
[1, 25995] loss_train: 0.007906, loss_test: 0.005497
time: 0.2455589771270752
time: 2.276113986968994
[1, 25996] loss_train: 0.008900, loss_test: 0.005499
time: 0.25505685806274414
time: 2.2417190074920654
[1, 25997] loss_train: 0.007381, loss_test: 0.005501
time: 0.24605679512023926
time: 2.2972865104675293
[1, 25998] loss_train: 0.008927, loss_test: 0.005503
time: 0.24556756019592285
time: 2.2670211791992188
[1, 25999] loss_train: 0.001704, loss_test: 0.005505
time: 0.24400830268859863
time: 2.2614362239837646
[1, 26000] loss_train: 0.008699, loss_test: 0.005507
time: 0.30106663703918457
time: 2.2785215377807617
[1, 26001] loss_train: 0.005117, loss_test: 0.005508
time: 0.24805450439453125
time: 2.260969400405884
[1, 26002] loss_train: 0.002487, loss_test: 0.005508
time: 0.2510557174682617
time: 2.274508237838745
[1, 26003] loss_train: 0.003648, loss_test: 0.005509
time: 0.251056432723999
time: 2.3203604221343994
[1, 26004] loss_train: 0.009470, loss_test: 0.005510
time: 0.26105785369873047
time: 2.326249361038208
[1, 26005] loss_train: 0.010760, loss_test: 0.005511
time: 0.25281453132629395
time: 2.401310920715332
[1, 26006] loss_train: 0.006591, loss_test: 0.005513
time: 0.26105833053588867
time: 2.452319383621216
[1, 26007] loss_train: 0.004289, loss_test: 0.005515
time: 0.3250713348388672
time: 2.7503199577331543
[1, 26008] loss_train: 0.009498, loss_test: 0.005515
time: 0.3000671863555908
time: 2.5461251735687256
[1, 26009] loss_train: 0.005251, loss_test: 0.005514
time: 0.2738068103790283
time: 2.5768988132476807
[1, 26010] loss_train: 0.005071, loss_test: 0.005514
time: 0.4521160125732422
time: 2.433290719985962
[1, 26011] loss_train: 0.008364, loss_test: 0.005515
time: 0.2780623435974121
time: 2.5125114917755127
[1, 26012] loss_train: 0.003467, loss_test: 0.005519
time: 0.34807658195495605
time: 2.8436386585235596
[1, 26013] loss_train: 0.005064, loss_test: 0.005523
time: 0.3580787181854248
time: 2.770643949508667
[1, 26014] loss_train: 0.007727, loss_test: 0.005527
time: 0.2920651435852051
time: 2.573582887649536
[1, 26015] loss_train: 0.005969, loss_test: 0.005531
time: 0.2910640239715576
time: 2.648592472076416
[1, 26016] loss_train: 0.004976, loss_test: 0.005534
time: 0.29506444931030273
time: 2.4530558586120605
[1, 26017] loss_train: 0.003950, loss_test: 0.005538
time: 0.2870633602142334
time: 2.492175579071045
[1, 26018] loss_train: 0.007918, loss_test: 0.005536
time: 0.28608131408691406
time: 2.479556083679199
[1, 26019] loss_train: 0.003349, loss_test: 0.005536
time: 0.30448031425476074
time: 2.4987778663635254
[1, 26020] loss_train: 0.011190, loss_test: 0.005532
time: 0.3200709819793701
time: 2.508079767227173
[1, 26021] loss_train: 0.009297, loss_test: 0.005532
time: 0.2830653190612793
time: 2.5365684032440186
[1, 26022] loss_train: 0.005240, loss_test: 0.005532
time: 0.31506967544555664
time: 2.4700562953948975
[1, 26023] loss_train: 0.004381, loss_test: 0.005532
time: 0.30106639862060547
time: 2.488942861557007
[1, 26024] loss_train: 0.004453, loss_test: 0.005531
time: 0.2820618152618408
time: 2.4135403633117676
[1, 26025] loss_train: 0.007474, loss_test: 0.005530
time: 0.28782176971435547
time: 2.5375277996063232
[1, 26026] loss_train: 0.013033, loss_test: 0.005529
time: 0.2760615348815918
time: 2.363539695739746
[1, 26027] loss_train: 0.009695, loss_test: 0.005532
time: 0.25588130950927734
time: 2.4600183963775635
[1, 26028] loss_train: 0.008632, loss_test: 0.005539
time: 0.3482329845428467
time: 2.56632137298584
[1, 26029] loss_train: 0.007329, loss_test: 0.005549
time: 0.27906203269958496
time: 2.4891867637634277
[1, 26030] loss_train: 0.001999, loss_test: 0.005550
time: 0.2910645008087158
time: 2.5250682830810547
[1, 26031] loss_train: 0.005548, loss_test: 0.005551
time: 0.2670605182647705
time: 2.4265310764312744
[1, 26032] loss_train: 0.008292, loss_test: 0.005551
time: 0.30538058280944824
time: 2.5260732173919678
[1, 26033] loss_train: 0.005790, loss_test: 0.005552
time: 0.2600579261779785
time: 2.58626651763916
[1, 26034] loss_train: 0.003400, loss_test: 0.005552
time: 0.33584094047546387
time: 2.7129716873168945
[1, 26035] loss_train: 0.004368, loss_test: 0.005551
time: 0.32235145568847656
time: 2.552907943725586
[1, 26036] loss_train: 0.007290, loss_test: 0.005552
time: 0.2680668830871582
time: 2.4077508449554443
[1, 26037] loss_train: 0.008079, loss_test: 0.005556
time: 0.2675650119781494
time: 2.439275026321411
[1, 26038] loss_train: 0.014679, loss_test: 0.005556
time: 0.27906227111816406
time: 2.4384138584136963
[1, 26039] loss_train: 0.006147, loss_test: 0.005553
time: 0.2620577812194824
time: 2.4515485763549805
[1, 26040] loss_train: 0.005447, loss_test: 0.005549
time: 0.29370903968811035
time: 2.4235522747039795
[1, 26041] loss_train: 0.005249, loss_test: 0.005544
time: 0.26806116104125977
time: 2.426544666290283
[1, 26042] loss_train: 0.007995, loss_test: 0.005541
time: 0.2560586929321289
time: 2.3960421085357666
[1, 26043] loss_train: 0.001862, loss_test: 0.005539
time: 0.3020660877227783
time: 2.430549383163452
[1, 26044] loss_train: 0.002814, loss_test: 0.005537
time: 0.263059139251709
time: 2.4626307487487793
[1, 26045] loss_train: 0.010164, loss_test: 0.005537
time: 0.2670586109161377
time: 2.425081491470337
[1, 26046] loss_train: 0.004100, loss_test: 0.005535
time: 0.26107335090637207
time: 2.4906530380249023
[1, 26047] loss_train: 0.003478, loss_test: 0.005530
time: 0.27506089210510254
time: 2.4965579509735107
[1, 26048] loss_train: 0.001269, loss_test: 0.005526
time: 0.2625617980957031
time: 2.567577838897705
[1, 26049] loss_train: 0.004644, loss_test: 0.005522
time: 0.2720603942871094
time: 2.5485692024230957
[1, 26050] loss_train: 0.002310, loss_test: 0.005518
time: 0.2850627899169922
time: 2.430046558380127
[1, 26051] loss_train: 0.012310, loss_test: 0.005512
time: 0.29906582832336426
time: 2.713460683822632
[1, 26052] loss_train: 0.005144, loss_test: 0.005509
time: 0.3270726203918457
time: 2.5483460426330566
[1, 26053] loss_train: 0.005922, loss_test: 0.005507
time: 0.2870631217956543
time: 2.433896064758301
[1, 26054] loss_train: 0.005663, loss_test: 0.005507
time: 0.25905799865722656
time: 2.466054916381836
[1, 26055] loss_train: 0.009895, loss_test: 0.005507
time: 0.2940640449523926
time: 2.373035192489624
[1, 26056] loss_train: 0.001812, loss_test: 0.005508
time: 0.2740437984466553
time: 2.4324722290039062
[1, 26057] loss_train: 0.006619, loss_test: 0.005510
time: 0.25905728340148926
time: 2.459444999694824
[1, 26058] loss_train: 0.009336, loss_test: 0.005513
time: 0.278062105178833
time: 2.425936222076416
[1, 26059] loss_train: 0.006613, loss_test: 0.005513
time: 0.2725706100463867
time: 2.373152256011963
[1, 26060] loss_train: 0.004873, loss_test: 0.005515
time: 0.2940652370452881
time: 2.4335451126098633
[1, 26061] loss_train: 0.010829, loss_test: 0.005516
time: 0.26405954360961914
time: 2.3715310096740723
[1, 26062] loss_train: 0.010964, loss_test: 0.005518
time: 0.25505638122558594
time: 2.380532741546631
[1, 26063] loss_train: 0.003598, loss_test: 0.005521
time: 0.27306151390075684
time: 2.4345438480377197
[1, 26064] loss_train: 0.002251, loss_test: 0.005524
time: 0.25905704498291016
time: 2.4215424060821533
[1, 26065] loss_train: 0.004401, loss_test: 0.005526
time: 0.28058958053588867
time: 2.4212605953216553
[1, 26066] loss_train: 0.012263, loss_test: 0.005528
time: 0.2877776622772217
time: 2.4046502113342285
[1, 26067] loss_train: 0.005376, loss_test: 0.005531
time: 0.3010685443878174
time: 2.5095605850219727
[1, 26068] loss_train: 0.007551, loss_test: 0.005534
time: 0.2820620536804199
time: 2.451054573059082
[1, 26069] loss_train: 0.007115, loss_test: 0.005538
time: 0.2720601558685303
time: 2.457550048828125
[1, 26070] loss_train: 0.007295, loss_test: 0.005539
time: 0.2870635986328125
time: 2.381035804748535
[1, 26071] loss_train: 0.010157, loss_test: 0.005541
time: 0.2560575008392334
time: 2.466989517211914
[1, 26072] loss_train: 0.008004, loss_test: 0.005543
time: 0.2600581645965576
time: 2.462951421737671
[1, 26073] loss_train: 0.003599, loss_test: 0.005545
time: 0.2780601978302002
time: 2.448667526245117
[1, 26074] loss_train: 0.004633, loss_test: 0.005545
time: 0.28106188774108887
time: 2.387040615081787
[1, 26075] loss_train: 0.012524, loss_test: 0.005546
time: 0.27706146240234375
time: 2.3825325965881348
[1, 26076] loss_train: 0.007163, loss_test: 0.005548
time: 0.26805973052978516
time: 2.3705389499664307
[1, 26077] loss_train: 0.004819, loss_test: 0.005549
time: 0.26607179641723633
time: 2.4200453758239746
[1, 26078] loss_train: 0.000784, loss_test: 0.005550
time: 0.27357006072998047
time: 2.391566753387451
[1, 26079] loss_train: 0.001400, loss_test: 0.005553
time: 0.2623918056488037
time: 2.371124267578125
[1, 26080] loss_train: 0.003974, loss_test: 0.005558
time: 0.2750668525695801
time: 2.406057596206665
[1, 26081] loss_train: 0.000684, loss_test: 0.005565
time: 0.2760610580444336
time: 2.425541877746582
[1, 26082] loss_train: 0.009692, loss_test: 0.005564
time: 0.258056640625
time: 2.405921459197998
[1, 26083] loss_train: 0.005061, loss_test: 0.005563
time: 0.2672712802886963
time: 2.4120469093322754
[1, 26084] loss_train: 0.004200, loss_test: 0.005561
time: 0.27006077766418457
time: 2.453554391860962
[1, 26085] loss_train: 0.000836, loss_test: 0.005561
time: 0.27706098556518555
time: 2.451554775238037
[1, 26086] loss_train: 0.005344, loss_test: 0.005561
time: 0.28406286239624023
time: 2.4530532360076904
[1, 26087] loss_train: 0.006008, loss_test: 0.005559
time: 0.26605916023254395
time: 2.440462827682495
[1, 26088] loss_train: 0.003502, loss_test: 0.005556
time: 0.2580564022064209
time: 2.408541440963745
[1, 26089] loss_train: 0.003272, loss_test: 0.005551
time: 0.27606201171875
time: 2.420271396636963
[1, 26090] loss_train: 0.010647, loss_test: 0.005540
time: 0.2781403064727783
time: 2.5685741901397705
[1, 26091] loss_train: 0.005761, loss_test: 0.005532
time: 0.2770655155181885
time: 2.498716354370117
[1, 26092] loss_train: 0.009060, loss_test: 0.005509
time: 0.26405811309814453
time: 2.5205678939819336
[1, 26093] loss_train: 0.007728, loss_test: 0.005496
time: 0.3690798282623291
time: 2.5125620365142822
[1, 26094] loss_train: 0.013027, loss_test: 0.005488
time: 0.280062198638916
time: 2.552431344985962
[1, 26095] loss_train: 0.005318, loss_test: 0.005490
time: 0.2939436435699463
time: 2.48785662651062
[1, 26096] loss_train: 0.015384, loss_test: 0.005496
time: 0.25406503677368164
time: 2.3781771659851074
[1, 26097] loss_train: 0.001849, loss_test: 0.005506
time: 0.2710607051849365
time: 2.53537654876709
[1, 26098] loss_train: 0.003911, loss_test: 0.005510
time: 0.2960660457611084
time: 2.794955253601074
[1, 26099] loss_train: 0.007217, loss_test: 0.005510
time: 0.3830850124359131
time: 2.664313554763794
[1, 26100] loss_train: 0.005903, loss_test: 0.005505
time: 0.3027369976043701
time: 2.687319040298462
[1, 26101] loss_train: 0.006364, loss_test: 0.005496
time: 0.29006385803222656
time: 2.6087467670440674
[1, 26102] loss_train: 0.001905, loss_test: 0.005488
time: 0.28657960891723633
time: 2.5950400829315186
[1, 26103] loss_train: 0.006577, loss_test: 0.005483
time: 0.29806995391845703
time: 2.6497385501861572
[1, 26104] loss_train: 0.007871, loss_test: 0.005483
time: 0.2911665439605713
time: 2.5727696418762207
[1, 26105] loss_train: 0.001372, loss_test: 0.005487
time: 0.2810628414154053
time: 2.5220320224761963
[1, 26106] loss_train: 0.011186, loss_test: 0.005495
time: 0.264056921005249
time: 2.520575523376465
[1, 26107] loss_train: 0.007474, loss_test: 0.005499
time: 0.3180723190307617
time: 2.602862596511841
[1, 26108] loss_train: 0.005300, loss_test: 0.005504
time: 0.28012657165527344
time: 2.508342742919922
[1, 26109] loss_train: 0.005227, loss_test: 0.005508
time: 0.27706289291381836
time: 2.4166104793548584
[1, 26110] loss_train: 0.012206, loss_test: 0.005503
time: 0.29437923431396484
time: 2.622750759124756
[1, 26111] loss_train: 0.010862, loss_test: 0.005500
time: 0.34008240699768066
time: 2.47501277923584
[1, 26112] loss_train: 0.010667, loss_test: 0.005499
time: 0.2800633907318115
time: 2.3805320262908936
[1, 26113] loss_train: 0.010602, loss_test: 0.005501
time: 0.2600564956665039
time: 2.4745583534240723
[1, 26114] loss_train: 0.002532, loss_test: 0.005507
time: 0.2690598964691162
time: 2.393038034439087
[1, 26115] loss_train: 0.005258, loss_test: 0.005514
time: 0.2650599479675293
time: 2.484126091003418
[1, 26116] loss_train: 0.003209, loss_test: 0.005522
time: 0.26605892181396484
time: 2.449143171310425
[1, 26117] loss_train: 0.005064, loss_test: 0.005526
time: 0.2740590572357178
time: 2.4019315242767334
[1, 26118] loss_train: 0.005708, loss_test: 0.005530
time: 0.2870638370513916
time: 2.430556535720825
[1, 26119] loss_train: 0.005661, loss_test: 0.005532
time: 0.28406262397766113
time: 2.4318416118621826
[1, 26120] loss_train: 0.004030, loss_test: 0.005534
time: 0.2832322120666504
time: 2.5475521087646484
[1, 26121] loss_train: 0.009178, loss_test: 0.005534
time: 0.29706597328186035
time: 2.5716450214385986
[1, 26122] loss_train: 0.005199, loss_test: 0.005535
time: 0.3431079387664795
time: 2.800626754760742
[1, 26123] loss_train: 0.007154, loss_test: 0.005538
time: 0.2960655689239502
time: 2.6815993785858154
[1, 26124] loss_train: 0.003768, loss_test: 0.005542
time: 0.35007786750793457
time: 2.5455713272094727
[1, 26125] loss_train: 0.006657, loss_test: 0.005544
time: 0.2650585174560547
time: 2.423253059387207
[1, 26126] loss_train: 0.007231, loss_test: 0.005542
time: 0.2709004878997803
time: 2.387514591217041
[1, 26127] loss_train: 0.003745, loss_test: 0.005542
time: 0.2683444023132324
time: 2.497711181640625
[1, 26128] loss_train: 0.003083, loss_test: 0.005543
time: 0.27005887031555176
time: 2.3942298889160156
[1, 26129] loss_train: 0.006373, loss_test: 0.005542
time: 0.2650563716888428
time: 2.4255146980285645
[1, 26130] loss_train: 0.004989, loss_test: 0.005539
time: 0.29544854164123535
time: 2.386939287185669
[1, 26131] loss_train: 0.012718, loss_test: 0.005530
time: 0.26605916023254395
time: 2.4090518951416016
[1, 26132] loss_train: 0.010458, loss_test: 0.005521
time: 0.27756524085998535
time: 2.4235455989837646
[1, 26133] loss_train: 0.002200, loss_test: 0.005518
time: 0.26605868339538574
time: 2.4067916870117188
[1, 26134] loss_train: 0.009377, loss_test: 0.005521
time: 0.28206324577331543
time: 2.423544406890869
[1, 26135] loss_train: 0.007573, loss_test: 0.005530
time: 0.2560572624206543
time: 2.4140431880950928
[1, 26136] loss_train: 0.006604, loss_test: 0.005541
time: 0.27706122398376465
time: 2.397993564605713
[1, 26137] loss_train: 0.001780, loss_test: 0.005545
time: 0.2660677433013916
time: 2.4448435306549072
[1, 26138] loss_train: 0.001757, loss_test: 0.005538
time: 0.2702667713165283
time: 2.4105398654937744
[1, 26139] loss_train: 0.002761, loss_test: 0.005529
time: 0.29056715965270996
time: 2.385850667953491
[1, 26140] loss_train: 0.005297, loss_test: 0.005522
time: 0.3339405059814453
time: 2.420542001724243
[1, 26141] loss_train: 0.007818, loss_test: 0.005517
time: 0.3030698299407959
time: 2.8241517543792725
[1, 26142] loss_train: 0.011577, loss_test: 0.005514
time: 0.28311729431152344
time: 2.9473745822906494
[1, 26143] loss_train: 0.002783, loss_test: 0.005512
time: 0.26605916023254395
time: 2.6826164722442627
[1, 26144] loss_train: 0.004635, loss_test: 0.005514
time: 0.2650585174560547
time: 2.5646605491638184
[1, 26145] loss_train: 0.007878, loss_test: 0.005515
time: 0.2869877815246582
time: 2.441466808319092
[1, 26146] loss_train: 0.011178, loss_test: 0.005510
time: 0.25705647468566895
time: 2.4943108558654785
[1, 26147] loss_train: 0.009425, loss_test: 0.005507
time: 0.2815587520599365
time: 2.487060546875
[1, 26148] loss_train: 0.013435, loss_test: 0.005504
time: 0.3045768737792969
time: 2.5223236083984375
[1, 26149] loss_train: 0.018368, loss_test: 0.005507
time: 0.27306103706359863
time: 2.3979451656341553
[1, 26150] loss_train: 0.003457, loss_test: 0.005523
time: 0.27457094192504883
time: 2.419602394104004
[1, 26151] loss_train: 0.010211, loss_test: 0.005542
time: 0.27205920219421387
time: 2.4083516597747803
[1, 26152] loss_train: 0.006066, loss_test: 0.005565
time: 0.2760610580444336
time: 2.4125423431396484
[1, 26153] loss_train: 0.003054, loss_test: 0.005579
time: 0.269059419631958
time: 2.4625535011291504
[1, 26154] loss_train: 0.005382, loss_test: 0.005568
time: 0.28307652473449707
time: 2.5071589946746826
[1, 26155] loss_train: 0.008428, loss_test: 0.005549
time: 0.407360315322876
time: 2.4655771255493164
[1, 26156] loss_train: 0.010017, loss_test: 0.005533
time: 0.26805925369262695
time: 2.6256654262542725
[1, 26157] loss_train: 0.007766, loss_test: 0.005523
time: 0.2780606746673584
time: 2.6035938262939453
[1, 26158] loss_train: 0.003028, loss_test: 0.005519
time: 0.3230712413787842
time: 3.1169559955596924
[1, 26159] loss_train: 0.005075, loss_test: 0.005519
time: 0.45011329650878906
time: 3.137613296508789
[1, 26160] loss_train: 0.003956, loss_test: 0.005523
time: 0.42209458351135254
time: 2.850640058517456
[1, 26161] loss_train: 0.002597, loss_test: 0.005529
time: 0.5421748161315918
time: 2.6441233158111572
[1, 26162] loss_train: 0.006522, loss_test: 0.005535
time: 0.2690591812133789
time: 2.8826913833618164
[1, 26163] loss_train: 0.011022, loss_test: 0.005536
time: 0.3948493003845215
time: 2.868276357650757
[1, 26164] loss_train: 0.005125, loss_test: 0.005536
time: 0.3750882148742676
time: 2.8319485187530518
[1, 26165] loss_train: 0.001641, loss_test: 0.005539
time: 0.274059534072876
time: 2.523068904876709
[1, 26166] loss_train: 0.015657, loss_test: 0.005531
time: 0.282062292098999
time: 2.5443320274353027
[1, 26167] loss_train: 0.013746, loss_test: 0.005527
time: 0.42809247970581055
time: 2.460925817489624
[1, 26168] loss_train: 0.003439, loss_test: 0.005530
time: 0.2710690498352051
time: 2.464492082595825
[1, 26169] loss_train: 0.007326, loss_test: 0.005536
time: 0.4142751693725586
time: 2.473613977432251
[1, 26170] loss_train: 0.000618, loss_test: 0.005547
time: 0.28406405448913574
time: 2.453052043914795
[1, 26171] loss_train: 0.006430, loss_test: 0.005560
time: 0.2650585174560547
time: 2.4155423641204834
[1, 26172] loss_train: 0.003910, loss_test: 0.005570
time: 0.27506113052368164
time: 2.4025375843048096
[1, 26173] loss_train: 0.011214, loss_test: 0.005578
time: 0.27906131744384766
time: 2.579261064529419
[1, 26174] loss_train: 0.009547, loss_test: 0.005581
time: 0.26605892181396484
time: 2.661360025405884
[1, 26175] loss_train: 0.009327, loss_test: 0.005575
time: 0.2710845470428467
time: 2.4889235496520996
[1, 26176] loss_train: 0.004327, loss_test: 0.005552
time: 0.29306483268737793
time: 2.7322452068328857
[1, 26177] loss_train: 0.001681, loss_test: 0.005537
time: 0.34807705879211426
time: 2.6150949001312256
[1, 26178] loss_train: 0.011536, loss_test: 0.005526
time: 0.2860677242279053
time: 2.6432945728302
[1, 26179] loss_train: 0.005647, loss_test: 0.005517
time: 0.28206443786621094
time: 2.5873663425445557
[1, 26180] loss_train: 0.007874, loss_test: 0.005512
time: 0.35338592529296875
time: 2.6012074947357178
[1, 26181] loss_train: 0.005559, loss_test: 0.005510
time: 0.2940647602081299
time: 2.5250563621520996
[1, 26182] loss_train: 0.008221, loss_test: 0.005511
time: 0.2800612449645996
time: 2.476508140563965
[1, 26183] loss_train: 0.005563, loss_test: 0.005514
time: 0.2870638370513916
time: 2.496771812438965
[1, 26184] loss_train: 0.006778, loss_test: 0.005517
time: 0.29506492614746094
time: 2.832878351211548
[1, 26185] loss_train: 0.008236, loss_test: 0.005519
time: 0.28606390953063965
time: 2.5347540378570557
[1, 26186] loss_train: 0.008152, loss_test: 0.005519
time: 0.31006789207458496
time: 2.5634708404541016
[1, 26187] loss_train: 0.005516, loss_test: 0.005520
time: 0.2690763473510742
time: 2.6319446563720703
[1, 26188] loss_train: 0.001108, loss_test: 0.005522
time: 0.28957390785217285
time: 2.652266502380371
[1, 26189] loss_train: 0.001685, loss_test: 0.005526
time: 0.27506113052368164
time: 2.5465188026428223
[1, 26190] loss_train: 0.004779, loss_test: 0.005527
time: 0.2980663776397705
time: 2.704604387283325
[1, 26191] loss_train: 0.007157, loss_test: 0.005525
time: 0.4270939826965332
time: 2.708111047744751
[1, 26192] loss_train: 0.006250, loss_test: 0.005521
time: 0.3070671558380127
time: 2.476302146911621
[1, 26193] loss_train: 0.003637, loss_test: 0.005517
time: 0.26805901527404785
time: 2.4079675674438477
[1, 26194] loss_train: 0.009720, loss_test: 0.005510
time: 0.2850015163421631
time: 2.3769352436065674
[1, 26195] loss_train: 0.005893, loss_test: 0.005507
time: 0.2834746837615967
time: 2.401221752166748
[1, 26196] loss_train: 0.002746, loss_test: 0.005505
time: 0.2960805892944336
time: 2.442558526992798
[1, 26197] loss_train: 0.005214, loss_test: 0.005504
time: 0.27706098556518555
time: 2.393174409866333
[1, 26198] loss_train: 0.006996, loss_test: 0.005505
time: 0.2740602493286133
time: 2.379533529281616
[1, 26199] loss_train: 0.004811, loss_test: 0.005508
time: 0.2780797481536865
time: 2.4035370349884033
[1, 26200] loss_train: 0.004642, loss_test: 0.005509
time: 0.30206751823425293
time: 2.41253924369812
[1, 26201] loss_train: 0.005490, loss_test: 0.005510
time: 0.27706122398376465
time: 2.4396088123321533
[1, 26202] loss_train: 0.002115, loss_test: 0.005509
time: 0.2696082592010498
time: 2.4425604343414307
[1, 26203] loss_train: 0.010069, loss_test: 0.005508
time: 0.2780628204345703
time: 2.463557720184326
[1, 26204] loss_train: 0.006191, loss_test: 0.005508
time: 0.27008509635925293
time: 2.446150779724121
[1, 26205] loss_train: 0.003336, loss_test: 0.005504
time: 0.2740607261657715
time: 2.4265429973602295
[1, 26206] loss_train: 0.007750, loss_test: 0.005502
time: 0.3380763530731201
time: 2.4985625743865967
[1, 26207] loss_train: 0.004486, loss_test: 0.005499
time: 0.2740604877471924
time: 2.4250473976135254
[1, 26208] loss_train: 0.006227, loss_test: 0.005499
time: 0.27706146240234375
time: 2.5622026920318604
[1, 26209] loss_train: 0.007500, loss_test: 0.005498
time: 0.31306934356689453
time: 2.6153953075408936
[1, 26210] loss_train: 0.007198, loss_test: 0.005498
time: 0.31609177589416504
time: 2.4620983600616455
[1, 26211] loss_train: 0.012686, loss_test: 0.005496
time: 0.3160715103149414
time: 2.553863525390625
[1, 26212] loss_train: 0.004329, loss_test: 0.005495
time: 0.3030681610107422
time: 2.4230449199676514
[1, 26213] loss_train: 0.004886, loss_test: 0.005495
time: 0.28206300735473633
time: 2.422553539276123
[1, 26214] loss_train: 0.007469, loss_test: 0.005495
time: 0.2980663776397705
time: 2.4611549377441406
[1, 26215] loss_train: 0.003342, loss_test: 0.005495
time: 0.2875697612762451
time: 2.3680338859558105
[1, 26216] loss_train: 0.003715, loss_test: 0.005495
time: 0.283069372177124
time: 2.48417592048645
[1, 26217] loss_train: 0.005953, loss_test: 0.005494
time: 0.31507015228271484
time: 2.5541555881500244
[1, 26218] loss_train: 0.001957, loss_test: 0.005495
time: 0.28107404708862305
time: 2.4216971397399902
[1, 26219] loss_train: 0.014929, loss_test: 0.005496
time: 0.3780832290649414
time: 2.459482192993164
[1, 26220] loss_train: 0.014233, loss_test: 0.005500
time: 0.2960655689239502
time: 2.55857253074646
[1, 26221] loss_train: 0.000787, loss_test: 0.005500
time: 0.29506826400756836
time: 2.4795544147491455
[1, 26222] loss_train: 0.000776, loss_test: 0.005500
time: 0.296065092086792
time: 2.6930999755859375
[1, 26223] loss_train: 0.003971, loss_test: 0.005501
time: 0.4156355857849121
time: 2.5091052055358887
[1, 26224] loss_train: 0.000654, loss_test: 0.005504
time: 0.2988276481628418
time: 2.421173572540283
[1, 26225] loss_train: 0.010801, loss_test: 0.005507
time: 0.2820625305175781
time: 2.8218603134155273
[1, 26226] loss_train: 0.018990, loss_test: 0.005508
time: 0.37215566635131836
time: 2.4635496139526367
[1, 26227] loss_train: 0.002252, loss_test: 0.005510
time: 0.2988779544830322
time: 2.415830373764038
[1, 26228] loss_train: 0.008131, loss_test: 0.005512
time: 0.2872025966644287
time: 2.7343828678131104
[1, 26229] loss_train: 0.007341, loss_test: 0.005511
time: 0.30806827545166016
time: 2.435547351837158
[1, 26230] loss_train: 0.008716, loss_test: 0.005503
time: 0.29906558990478516
time: 2.5218162536621094
[1, 26231] loss_train: 0.005883, loss_test: 0.005496
time: 0.3460814952850342
time: 2.453549861907959
[1, 26232] loss_train: 0.017162, loss_test: 0.005491
time: 0.3020670413970947
time: 2.4165408611297607
[1, 26233] loss_train: 0.005691, loss_test: 0.005491
time: 0.29206371307373047
time: 2.4075591564178467
[1, 26234] loss_train: 0.010519, loss_test: 0.005494
time: 0.2966301441192627
time: 2.516563892364502
[1, 26235] loss_train: 0.005954, loss_test: 0.005498
time: 0.3103935718536377
time: 2.5194642543792725
[1, 26236] loss_train: 0.005739, loss_test: 0.005500
time: 0.29706549644470215
time: 2.3935372829437256
[1, 26237] loss_train: 0.008162, loss_test: 0.005501
time: 0.29306530952453613
time: 2.630185604095459
[1, 26238] loss_train: 0.004987, loss_test: 0.005502
time: 0.2980661392211914
time: 2.422542095184326
[1, 26239] loss_train: 0.002327, loss_test: 0.005502
time: 0.2830619812011719
time: 2.3940439224243164
[1, 26240] loss_train: 0.007843, loss_test: 0.005502
time: 0.30007147789001465
time: 2.4232025146484375
[1, 26241] loss_train: 0.004665, loss_test: 0.005502
time: 0.27907562255859375
time: 2.4119927883148193
[1, 26242] loss_train: 0.001910, loss_test: 0.005501
time: 0.2789483070373535
time: 2.401644468307495
[1, 26243] loss_train: 0.004134, loss_test: 0.005502
time: 0.2881593704223633
time: 2.3977205753326416
[1, 26244] loss_train: 0.005996, loss_test: 0.005506
time: 0.27506136894226074
time: 2.38753604888916
[1, 26245] loss_train: 0.003911, loss_test: 0.005511
time: 0.2810659408569336
time: 2.4015398025512695
[1, 26246] loss_train: 0.004762, loss_test: 0.005520
time: 0.2830629348754883
time: 2.446549892425537
[1, 26247] loss_train: 0.011751, loss_test: 0.005525
time: 0.2820618152618408
time: 2.383544445037842
[1, 26248] loss_train: 0.004729, loss_test: 0.005529
time: 0.27306032180786133
time: 2.4546687602996826
[1, 26249] loss_train: 0.010128, loss_test: 0.005524
time: 0.29706573486328125
time: 2.506115198135376
[1, 26250] loss_train: 0.001032, loss_test: 0.005523
time: 0.30606770515441895
time: 2.5714662075042725
[1, 26251] loss_train: 0.002035, loss_test: 0.005523
time: 0.32307004928588867
time: 2.4793059825897217
[1, 26252] loss_train: 0.006392, loss_test: 0.005521
time: 0.2820618152618408
time: 2.4105470180511475
[1, 26253] loss_train: 0.009592, loss_test: 0.005515
time: 0.3120696544647217
time: 2.793794631958008
[1, 26254] loss_train: 0.005533, loss_test: 0.005513
time: 0.5162234306335449
time: 3.076556921005249
[1, 26255] loss_train: 0.005968, loss_test: 0.005513
time: 0.2855701446533203
time: 2.691283702850342
[1, 26256] loss_train: 0.013382, loss_test: 0.005511
time: 0.29906630516052246
time: 2.548630714416504
[1, 26257] loss_train: 0.005567, loss_test: 0.005513
time: 0.2951493263244629
time: 2.6277263164520264
[1, 26258] loss_train: 0.008369, loss_test: 0.005519
time: 0.3180701732635498
time: 2.5735790729522705
[1, 26259] loss_train: 0.007062, loss_test: 0.005526
time: 0.28606343269348145
time: 2.4225494861602783
[1, 26260] loss_train: 0.006580, loss_test: 0.005533
time: 0.30406737327575684
time: 2.4219443798065186
[1, 26261] loss_train: 0.004208, loss_test: 0.005541
time: 0.29506516456604004
time: 2.4358179569244385
[1, 26262] loss_train: 0.005006, loss_test: 0.005538
time: 0.291064977645874
time: 2.4495484828948975
[1, 26263] loss_train: 0.003954, loss_test: 0.005531
time: 0.30007314682006836
time: 2.4002647399902344
[1, 26264] loss_train: 0.009196, loss_test: 0.005526
time: 0.2800629138946533
time: 2.456702947616577
[1, 26265] loss_train: 0.008699, loss_test: 0.005520
time: 0.29006528854370117
time: 2.390087604522705
[1, 26266] loss_train: 0.001338, loss_test: 0.005512
time: 0.2780618667602539
time: 2.397536039352417
[1, 26267] loss_train: 0.009099, loss_test: 0.005507
time: 0.29706573486328125
time: 2.649519443511963
[1, 26268] loss_train: 0.006206, loss_test: 0.005505
time: 0.28806567192077637
time: 2.4998292922973633
[1, 26269] loss_train: 0.003314, loss_test: 0.005505
time: 0.322070837020874
time: 2.441826343536377
[1, 26270] loss_train: 0.003660, loss_test: 0.005509
time: 0.3160586357116699
time: 2.45255708694458
[1, 26271] loss_train: 0.006046, loss_test: 0.005512
time: 0.2940645217895508
time: 2.417813301086426
[1, 26272] loss_train: 0.004094, loss_test: 0.005514
time: 0.29006457328796387
time: 2.4755544662475586
[1, 26273] loss_train: 0.008872, loss_test: 0.005508
time: 0.29306483268737793
time: 2.4285471439361572
[1, 26274] loss_train: 0.009849, loss_test: 0.005501
time: 0.28305888175964355
time: 2.45513653755188
[1, 26275] loss_train: 0.003500, loss_test: 0.005498
time: 0.2820711135864258
time: 2.404151439666748
[1, 26276] loss_train: 0.005589, loss_test: 0.005496
time: 0.2820625305175781
time: 2.4285545349121094
[1, 26277] loss_train: 0.003153, loss_test: 0.005497
time: 0.2837562561035156
time: 2.8118560314178467
[1, 26278] loss_train: 0.008080, loss_test: 0.005499
time: 0.35107898712158203
time: 2.7746198177337646
[1, 26279] loss_train: 0.013094, loss_test: 0.005498
time: 0.3230721950531006
time: 2.6285884380340576
[1, 26280] loss_train: 0.006510, loss_test: 0.005496
time: 0.31507062911987305
time: 2.6220309734344482
[1, 26281] loss_train: 0.009969, loss_test: 0.005496
time: 0.4629666805267334
time: 2.6123788356781006
[1, 26282] loss_train: 0.006560, loss_test: 0.005497
time: 0.3115873336791992
time: 2.685492753982544
[1, 26283] loss_train: 0.005160, loss_test: 0.005499
time: 0.29506635665893555
time: 2.6150898933410645
[1, 26284] loss_train: 0.003399, loss_test: 0.005501
time: 0.44825029373168945
time: 2.553074598312378
[1, 26285] loss_train: 0.008209, loss_test: 0.005503
time: 0.30806899070739746
time: 2.7836337089538574
[1, 26286] loss_train: 0.001730, loss_test: 0.005505
time: 0.3000659942626953
time: 2.5665881633758545
[1, 26287] loss_train: 0.002480, loss_test: 0.005506
time: 0.29706525802612305
time: 2.5039713382720947
[1, 26288] loss_train: 0.005419, loss_test: 0.005507
time: 0.3075864315032959
time: 3.0500199794769287
[1, 26289] loss_train: 0.004972, loss_test: 0.005504
time: 0.52968430519104
time: 2.669599771499634
[1, 26290] loss_train: 0.009531, loss_test: 0.005503
time: 0.3160703182220459
time: 3.221736192703247
[1, 26291] loss_train: 0.004540, loss_test: 0.005502
time: 0.4500858783721924
time: 3.165938138961792
[1, 26292] loss_train: 0.003407, loss_test: 0.005498
time: 0.30806779861450195
time: 2.7537593841552734
[1, 26293] loss_train: 0.006003, loss_test: 0.005496
time: 0.34662890434265137
time: 2.6734683513641357
[1, 26294] loss_train: 0.004531, loss_test: 0.005494
time: 0.35307860374450684
time: 2.525249719619751
[1, 26295] loss_train: 0.006537, loss_test: 0.005493
time: 0.3210716247558594
time: 2.47609281539917
[1, 26296] loss_train: 0.002284, loss_test: 0.005494
time: 0.3012099266052246
time: 2.476558208465576
[1, 26297] loss_train: 0.007742, loss_test: 0.005495
time: 0.34066152572631836
time: 2.5035603046417236
[1, 26298] loss_train: 0.007296, loss_test: 0.005497
time: 0.29006385803222656
time: 2.6366114616394043
[1, 26299] loss_train: 0.015757, loss_test: 0.005494
time: 0.3160707950592041
time: 2.436544179916382
[1, 26300] loss_train: 0.009086, loss_test: 0.005492
time: 0.30606842041015625
time: 2.541081190109253
[1, 26301] loss_train: 0.008553, loss_test: 0.005492
time: 0.28507542610168457
time: 2.7201998233795166
[1, 26302] loss_train: 0.006919, loss_test: 0.005492
time: 0.3692917823791504
time: 2.588684320449829
[1, 26303] loss_train: 0.004907, loss_test: 0.005491
time: 0.2880704402923584
time: 2.380124807357788
[1, 26304] loss_train: 0.003319, loss_test: 0.005490
time: 0.28106212615966797
time: 2.4395463466644287
[1, 26305] loss_train: 0.002594, loss_test: 0.005488
time: 0.27906131744384766
time: 2.405540704727173
[1, 26306] loss_train: 0.006233, loss_test: 0.005487
time: 0.29654765129089355
time: 2.6283774375915527
[1, 26307] loss_train: 0.002464, loss_test: 0.005487
time: 0.29006528854370117
time: 2.476020097732544
[1, 26308] loss_train: 0.006071, loss_test: 0.005486
time: 0.29706549644470215
time: 2.472057342529297
[1, 26309] loss_train: 0.005760, loss_test: 0.005488
time: 0.28029370307922363
time: 2.397554636001587
[1, 26310] loss_train: 0.002625, loss_test: 0.005490
time: 0.3020668029785156
time: 2.4275426864624023
[1, 26311] loss_train: 0.001029, loss_test: 0.005493
time: 0.29307079315185547
time: 2.4650256633758545
[1, 26312] loss_train: 0.003832, loss_test: 0.005498
time: 0.3340752124786377
time: 2.7455544471740723
[1, 26313] loss_train: 0.002759, loss_test: 0.005505
time: 0.30106639862060547
time: 2.455549955368042
[1, 26314] loss_train: 0.001138, loss_test: 0.005514
time: 0.31907033920288086
time: 2.4905643463134766
[1, 26315] loss_train: 0.006618, loss_test: 0.005520
time: 0.3000659942626953
time: 2.416541337966919
[1, 26316] loss_train: 0.007053, loss_test: 0.005524
time: 0.28806376457214355
time: 2.3615972995758057
[1, 26317] loss_train: 0.010789, loss_test: 0.005521
time: 0.2780618667602539
time: 2.448042631149292
[1, 26318] loss_train: 0.001521, loss_test: 0.005521
time: 0.2920651435852051
time: 2.3885366916656494
[1, 26319] loss_train: 0.004827, loss_test: 0.005520
time: 0.2870643138885498
time: 2.394066572189331
[1, 26320] loss_train: 0.011543, loss_test: 0.005519
time: 0.2980659008026123
time: 2.3875467777252197
[1, 26321] loss_train: 0.004240, loss_test: 0.005518
time: 0.283062219619751
time: 2.4465560913085938
[1, 26322] loss_train: 0.011301, loss_test: 0.005512
time: 0.2780611515045166
time: 2.4353413581848145
[1, 26323] loss_train: 0.019408, loss_test: 0.005522
time: 0.2817270755767822
time: 2.3781967163085938
[1, 26324] loss_train: 0.011097, loss_test: 0.005555
time: 0.29464221000671387
time: 2.4211137294769287
[1, 26325] loss_train: 0.008774, loss_test: 0.005607
time: 0.27706146240234375
time: 2.5610063076019287
[1, 26326] loss_train: 0.008481, loss_test: 0.005665
time: 0.29906606674194336
time: 2.4808218479156494
[1, 26327] loss_train: 0.005494, loss_test: 0.005713
time: 0.30707621574401855
time: 2.43693208694458
[1, 26328] loss_train: 0.005723, loss_test: 0.005721
time: 0.2850632667541504
time: 2.449284553527832
[1, 26329] loss_train: 0.008391, loss_test: 0.005681
time: 0.39777445793151855
time: 2.900721549987793
[1, 26330] loss_train: 0.005339, loss_test: 0.005612
time: 0.3320746421813965
time: 2.471060037612915
[1, 26331] loss_train: 0.006536, loss_test: 0.005550
time: 0.30234432220458984
time: 2.6399319171905518
[1, 26332] loss_train: 0.012693, loss_test: 0.005515
time: 0.34319305419921875
time: 2.534564971923828
[1, 26333] loss_train: 0.003438, loss_test: 0.005503
time: 0.29706740379333496
time: 2.3952856063842773
[1, 26334] loss_train: 0.005132, loss_test: 0.005510
time: 0.27506113052368164
time: 2.6845953464508057
[1, 26335] loss_train: 0.006031, loss_test: 0.005533
time: 0.3630809783935547
time: 2.770509719848633
[1, 26336] loss_train: 0.003071, loss_test: 0.005563
time: 0.2870635986328125
time: 2.506479024887085
[1, 26337] loss_train: 0.007851, loss_test: 0.005590
time: 0.31249308586120605
time: 2.6386494636535645
[1, 26338] loss_train: 0.007143, loss_test: 0.005612
time: 0.3095719814300537
time: 2.5330698490142822
[1, 26339] loss_train: 0.009985, loss_test: 0.005609
time: 0.288067102432251
time: 2.52656626701355
[1, 26340] loss_train: 0.004699, loss_test: 0.005598
time: 0.30207109451293945
time: 2.4470720291137695
[1, 26341] loss_train: 0.006878, loss_test: 0.005587
time: 0.2930779457092285
time: 2.459277629852295
[1, 26342] loss_train: 0.006558, loss_test: 0.005568
time: 0.3666701316833496
time: 2.5910699367523193
[1, 26343] loss_train: 0.008845, loss_test: 0.005550
time: 0.2975304126739502
time: 2.4337220191955566
[1, 26344] loss_train: 0.007605, loss_test: 0.005539
time: 0.28806376457214355
time: 2.467052936553955
[1, 26345] loss_train: 0.005577, loss_test: 0.005537
time: 0.30618882179260254
time: 2.418372392654419
[1, 26346] loss_train: 0.005754, loss_test: 0.005542
time: 0.3210725784301758
time: 2.4630541801452637
[1, 26347] loss_train: 0.004427, loss_test: 0.005549
time: 0.2870631217956543
time: 2.4017832279205322
[1, 26348] loss_train: 0.020090, loss_test: 0.005559
time: 0.28406238555908203
time: 2.4878783226013184
[1, 26349] loss_train: 0.000664, loss_test: 0.005574
time: 0.28406286239624023
time: 2.448061466217041
[1, 26350] loss_train: 0.017892, loss_test: 0.005595
time: 0.303067684173584
time: 2.5977296829223633
[1, 26351] loss_train: 0.009560, loss_test: 0.005602
time: 0.30406832695007324
time: 2.451054096221924
[1, 26352] loss_train: 0.005805, loss_test: 0.005594
time: 0.28606438636779785
time: 2.5358822345733643
[1, 26353] loss_train: 0.005029, loss_test: 0.005575
time: 0.29506397247314453
time: 2.474169969558716
[1, 26354] loss_train: 0.005832, loss_test: 0.005555
time: 0.3583967685699463
time: 2.3995394706726074
[1, 26355] loss_train: 0.005395, loss_test: 0.005536
time: 0.27506017684936523
time: 2.5015599727630615
[1, 26356] loss_train: 0.006074, loss_test: 0.005522
time: 0.32207226753234863
time: 2.4890596866607666
[1, 26357] loss_train: 0.002887, loss_test: 0.005513
time: 0.2850639820098877
time: 2.437075614929199
[1, 26358] loss_train: 0.002814, loss_test: 0.005510
time: 0.29506516456604004
time: 2.4550652503967285
[1, 26359] loss_train: 0.007726, loss_test: 0.005515
time: 0.3175826072692871
time: 2.482036590576172
[1, 26360] loss_train: 0.007742, loss_test: 0.005525
time: 0.3340423107147217
time: 2.507636308670044
[1, 26361] loss_train: 0.009851, loss_test: 0.005536
time: 0.28406310081481934
time: 2.449314832687378
[1, 26362] loss_train: 0.001367, loss_test: 0.005550
time: 0.29423975944519043
time: 2.5396130084991455
[1, 26363] loss_train: 0.002898, loss_test: 0.005568
time: 0.2920644283294678
time: 2.445546865463257
[1, 26364] loss_train: 0.006925, loss_test: 0.005580
time: 0.29306554794311523
time: 2.4655513763427734
[1, 26365] loss_train: 0.012161, loss_test: 0.005585
time: 0.3020665645599365
time: 2.444547414779663
[1, 26366] loss_train: 0.007603, loss_test: 0.005575
time: 0.2875688076019287
time: 2.404043436050415
[1, 26367] loss_train: 0.015619, loss_test: 0.005554
time: 0.29056882858276367
time: 2.4073023796081543
[1, 26368] loss_train: 0.009985, loss_test: 0.005539
time: 0.28980541229248047
time: 2.413540840148926
[1, 26369] loss_train: 0.005082, loss_test: 0.005530
time: 0.2870631217956543
time: 2.402498245239258
[1, 26370] loss_train: 0.008025, loss_test: 0.005522
time: 0.32207155227661133
time: 2.720296859741211
[1, 26371] loss_train: 0.009384, loss_test: 0.005518
time: 0.32407164573669434
time: 2.4868407249450684
[1, 26372] loss_train: 0.004650, loss_test: 0.005514
time: 0.28453946113586426
time: 2.5849366188049316
[1, 26373] loss_train: 0.004425, loss_test: 0.005512
time: 0.30715489387512207
time: 2.552319288253784
[1, 26374] loss_train: 0.002310, loss_test: 0.005511
time: 0.2960672378540039
time: 2.6076102256774902
[1, 26375] loss_train: 0.006610, loss_test: 0.005508
time: 0.29306507110595703
time: 2.71018123626709
[1, 26376] loss_train: 0.007264, loss_test: 0.005504
time: 0.31506991386413574
time: 2.6252987384796143
[1, 26377] loss_train: 0.006479, loss_test: 0.005500
time: 0.3080782890319824
time: 2.4261317253112793
[1, 26378] loss_train: 0.008209, loss_test: 0.005497
time: 0.3660268783569336
time: 2.576758623123169
[1, 26379] loss_train: 0.006201, loss_test: 0.005495
time: 0.2910640239715576
time: 2.4104862213134766
[1, 26380] loss_train: 0.004207, loss_test: 0.005495
time: 0.3020670413970947
time: 2.4249773025512695
[1, 26381] loss_train: 0.002339, loss_test: 0.005498
time: 0.2870640754699707
time: 2.434563398361206
[1, 26382] loss_train: 0.009352, loss_test: 0.005500
time: 0.2968883514404297
time: 2.4262149333953857
[1, 26383] loss_train: 0.008262, loss_test: 0.005502
time: 0.29306483268737793
time: 2.4225425720214844
[1, 26384] loss_train: 0.006789, loss_test: 0.005505
time: 0.2890636920928955
time: 2.4035415649414062
[1, 26385] loss_train: 0.006765, loss_test: 0.005507
time: 0.27506065368652344
time: 2.5356595516204834
[1, 26386] loss_train: 0.000978, loss_test: 0.005509
time: 0.3050704002380371
time: 2.5555801391601562
[1, 26387] loss_train: 0.014637, loss_test: 0.005508
time: 0.332073450088501
time: 2.4163525104522705
[1, 26388] loss_train: 0.004639, loss_test: 0.005508
time: 0.29506540298461914
time: 2.4518086910247803
[1, 26389] loss_train: 0.002590, loss_test: 0.005509
time: 0.31137728691101074
time: 2.5944252014160156
[1, 26390] loss_train: 0.009957, loss_test: 0.005510
time: 0.3290736675262451
time: 2.5485479831695557
[1, 26391] loss_train: 0.000671, loss_test: 0.005512
time: 0.32407212257385254
time: 2.4401419162750244
[1, 26392] loss_train: 0.009129, loss_test: 0.005513
time: 0.2870640754699707
time: 2.585472583770752
[1, 26393] loss_train: 0.008703, loss_test: 0.005513
time: 0.2910642623901367
time: 2.4465723037719727
[1, 26394] loss_train: 0.006207, loss_test: 0.005512
time: 0.3120722770690918
time: 2.4340598583221436
[1, 26395] loss_train: 0.005041, loss_test: 0.005511
time: 0.297360897064209
time: 2.4108726978302
[1, 26396] loss_train: 0.006415, loss_test: 0.005511
time: 0.292064905166626
time: 2.4345381259918213
[1, 26397] loss_train: 0.003602, loss_test: 0.005510
time: 0.3000671863555908
time: 2.689870595932007
[1, 26398] loss_train: 0.003443, loss_test: 0.005510
time: 0.3120696544647217
time: 2.4865565299987793
[1, 26399] loss_train: 0.005289, loss_test: 0.005510
time: 0.29906630516052246
time: 2.478816509246826
[1, 26400] loss_train: 0.003585, loss_test: 0.005510
time: 0.30806851387023926
time: 2.49429988861084
[1, 26401] loss_train: 0.003825, loss_test: 0.005510
time: 0.3781309127807617
time: 2.542114496231079
[1, 26402] loss_train: 0.010256, loss_test: 0.005510
time: 0.2830619812011719
time: 2.4461910724639893
[1, 26403] loss_train: 0.006149, loss_test: 0.005509
time: 0.2760610580444336
time: 2.396536350250244
[1, 26404] loss_train: 0.006498, loss_test: 0.005509
time: 0.3015706539154053
time: 2.417970895767212
[1, 26405] loss_train: 0.002626, loss_test: 0.005508
time: 0.2866804599761963
time: 2.399250030517578
[1, 26406] loss_train: 0.009371, loss_test: 0.005507
time: 0.3120694160461426
time: 2.5518457889556885
[1, 26407] loss_train: 0.002262, loss_test: 0.005507
time: 0.28640031814575195
time: 2.4147226810455322
[1, 26408] loss_train: 0.008939, loss_test: 0.005506
time: 0.3030667304992676
time: 2.4065394401550293
[1, 26409] loss_train: 0.004613, loss_test: 0.005507
time: 0.28606605529785156
time: 2.4015378952026367
[1, 26410] loss_train: 0.006308, loss_test: 0.005508
time: 0.33357954025268555
time: 2.4575603008270264
[1, 26411] loss_train: 0.002751, loss_test: 0.005510
time: 0.4803304672241211
time: 2.7262463569641113
[1, 26412] loss_train: 0.002552, loss_test: 0.005512
time: 0.2890641689300537
time: 2.428070306777954
[1, 26413] loss_train: 0.012116, loss_test: 0.005512
time: 0.2950725555419922
time: 2.428163766860962
[1, 26414] loss_train: 0.004315, loss_test: 0.005512
time: 0.2850635051727295
time: 2.3939976692199707
[1, 26415] loss_train: 0.003564, loss_test: 0.005511
time: 0.31920599937438965
time: 2.422541856765747
[1, 26416] loss_train: 0.001333, loss_test: 0.005511
time: 0.289064884185791
time: 2.4770586490631104
[1, 26417] loss_train: 0.005546, loss_test: 0.005512
time: 0.2980649471282959
time: 2.434549570083618
[1, 26418] loss_train: 0.006188, loss_test: 0.005516
time: 0.29506587982177734
time: 2.425050973892212
[1, 26419] loss_train: 0.005118, loss_test: 0.005519
time: 0.2910640239715576
time: 2.429708480834961
[1, 26420] loss_train: 0.002010, loss_test: 0.005523
time: 0.31507301330566406
time: 2.476173162460327
[1, 26421] loss_train: 0.004318, loss_test: 0.005526
time: 0.2870645523071289
time: 2.4336254596710205
[1, 26422] loss_train: 0.005057, loss_test: 0.005529
time: 0.29706597328186035
time: 2.4355735778808594
[1, 26423] loss_train: 0.007374, loss_test: 0.005527
time: 0.28806400299072266
time: 2.3970754146575928
[1, 26424] loss_train: 0.003141, loss_test: 0.005528
time: 0.2830936908721924
time: 2.4435462951660156
[1, 26425] loss_train: 0.000600, loss_test: 0.005530
time: 0.28106069564819336
time: 2.4083690643310547
[1, 26426] loss_train: 0.003955, loss_test: 0.005533
time: 0.2940645217895508
time: 2.386115312576294
[1, 26427] loss_train: 0.007543, loss_test: 0.005536
time: 0.283095121383667
time: 2.42811918258667
[1, 26428] loss_train: 0.000998, loss_test: 0.005540
time: 0.2920644283294678
time: 2.4224274158477783
[1, 26429] loss_train: 0.009674, loss_test: 0.005538
time: 0.2890646457672119
time: 2.405557632446289
[1, 26430] loss_train: 0.004147, loss_test: 0.005536
time: 0.29506564140319824
time: 2.4365522861480713
[1, 26431] loss_train: 0.012958, loss_test: 0.005525
time: 0.28606200218200684
time: 2.414947748184204
[1, 26432] loss_train: 0.009013, loss_test: 0.005513
time: 0.31006908416748047
time: 2.4245426654815674
[1, 26433] loss_train: 0.004975, loss_test: 0.005507
time: 0.2910637855529785
time: 2.4325199127197266
[1, 26434] loss_train: 0.013986, loss_test: 0.005503
time: 0.28513121604919434
time: 2.441579580307007
[1, 26435] loss_train: 0.005951, loss_test: 0.005503
time: 0.3110804557800293
time: 2.4932057857513428
[1, 26436] loss_train: 0.004020, loss_test: 0.005505
time: 0.2810630798339844
time: 2.3732242584228516
[1, 26437] loss_train: 0.004325, loss_test: 0.005507
time: 0.29099106788635254
time: 2.4298248291015625
[1, 26438] loss_train: 0.007442, loss_test: 0.005507
time: 0.2760591506958008
time: 2.3910462856292725
[1, 26439] loss_train: 0.008580, loss_test: 0.005509
time: 0.2850632667541504
time: 2.3965375423431396
[1, 26440] loss_train: 0.004545, loss_test: 0.005507
time: 0.3010678291320801
time: 2.4475488662719727
[1, 26441] loss_train: 0.002275, loss_test: 0.005504
time: 0.30406737327575684
time: 2.404057025909424
[1, 26442] loss_train: 0.005388, loss_test: 0.005502
time: 0.29206418991088867
time: 2.4645519256591797
[1, 26443] loss_train: 0.006175, loss_test: 0.005500
time: 0.29706597328186035
time: 2.42799711227417
[1, 26444] loss_train: 0.009362, loss_test: 0.005499
time: 0.2926337718963623
time: 2.452402353286743
[1, 26445] loss_train: 0.004700, loss_test: 0.005497
time: 0.29107165336608887
time: 2.4067699909210205
[1, 26446] loss_train: 0.005556, loss_test: 0.005495
time: 0.28606343269348145
time: 2.3985369205474854
[1, 26447] loss_train: 0.007629, loss_test: 0.005494
time: 0.3050682544708252
time: 2.4075448513031006
[1, 26448] loss_train: 0.005195, loss_test: 0.005494
time: 0.28406238555908203
time: 2.3776655197143555
[1, 26449] loss_train: 0.005270, loss_test: 0.005496
time: 0.28806447982788086
time: 2.411539077758789
[1, 26450] loss_train: 0.000873, loss_test: 0.005499
time: 0.31006860733032227
time: 2.438688278198242
[1, 26451] loss_train: 0.002025, loss_test: 0.005503
time: 0.29035210609436035
time: 2.4319419860839844
[1, 26452] loss_train: 0.003322, loss_test: 0.005509
time: 0.2940652370452881
time: 2.4063568115234375
[1, 26453] loss_train: 0.012813, loss_test: 0.005511
time: 0.29306578636169434
time: 2.4186453819274902
[1, 26454] loss_train: 0.012953, loss_test: 0.005509
time: 0.29006361961364746
time: 2.4215431213378906
[1, 26455] loss_train: 0.002762, loss_test: 0.005508
time: 0.2940647602081299
time: 2.4118423461914062
[1, 26456] loss_train: 0.013515, loss_test: 0.005503
time: 0.2810652256011963
time: 2.395538091659546
[1, 26457] loss_train: 0.002037, loss_test: 0.005500
time: 0.2980656623840332
time: 2.4128668308258057
[1, 26458] loss_train: 0.005270, loss_test: 0.005500
time: 0.282062292098999
time: 2.494572877883911
[1, 26459] loss_train: 0.002660, loss_test: 0.005503
time: 0.2945716381072998
time: 2.3770954608917236
[1, 26460] loss_train: 0.002277, loss_test: 0.005507
time: 0.31506919860839844
time: 2.4572179317474365
[1, 26461] loss_train: 0.002563, loss_test: 0.005511
time: 0.28107571601867676
time: 2.4210643768310547
[1, 26462] loss_train: 0.009833, loss_test: 0.005517
time: 0.29006266593933105
time: 2.7348318099975586
[1, 26463] loss_train: 0.002459, loss_test: 0.005525
time: 0.3230717182159424
time: 2.564589500427246
[1, 26464] loss_train: 0.003723, loss_test: 0.005534
time: 0.3160700798034668
time: 2.520563840866089
[1, 26465] loss_train: 0.010322, loss_test: 0.005540
time: 0.2830634117126465
time: 2.4899535179138184
[1, 26466] loss_train: 0.008282, loss_test: 0.005546
time: 0.3090682029724121
time: 2.4657883644104004
[1, 26467] loss_train: 0.002395, loss_test: 0.005549
time: 0.29607367515563965
time: 2.4865825176239014
[1, 26468] loss_train: 0.009864, loss_test: 0.005543
time: 0.3342897891998291
time: 2.5092785358428955
[1, 26469] loss_train: 0.007038, loss_test: 0.005526
time: 0.2820625305175781
time: 2.439619302749634
[1, 26470] loss_train: 0.003172, loss_test: 0.005510
time: 0.3050680160522461
time: 2.489558696746826
[1, 26471] loss_train: 0.003532, loss_test: 0.005501
time: 0.292064905166626
time: 2.43554949760437
[1, 26472] loss_train: 0.005206, loss_test: 0.005497
time: 0.2820620536804199
time: 2.5709733963012695
[1, 26473] loss_train: 0.010274, loss_test: 0.005497
time: 0.29557228088378906
time: 2.61202073097229
[1, 26474] loss_train: 0.002950, loss_test: 0.005498
time: 0.27706336975097656
time: 2.455451488494873
[1, 26475] loss_train: 0.000521, loss_test: 0.005498
time: 0.27306199073791504
time: 2.3945353031158447
[1, 26476] loss_train: 0.006575, loss_test: 0.005500
time: 0.28006434440612793
time: 2.400301933288574
[1, 26477] loss_train: 0.001910, loss_test: 0.005503
time: 0.2755889892578125
time: 2.389310121536255
[1, 26478] loss_train: 0.005956, loss_test: 0.005507
time: 0.2815670967102051
time: 2.398550033569336
[1, 26479] loss_train: 0.000666, loss_test: 0.005509
time: 0.2710597515106201
time: 2.382563591003418
[1, 26480] loss_train: 0.000866, loss_test: 0.005512
time: 0.29906582832336426
time: 2.4435648918151855
[1, 26481] loss_train: 0.007336, loss_test: 0.005514
time: 0.29006409645080566
time: 2.3865342140197754
[1, 26482] loss_train: 0.010657, loss_test: 0.005514
time: 0.2710599899291992
time: 2.435553550720215
[1, 26483] loss_train: 0.007051, loss_test: 0.005514
time: 0.28606367111206055
time: 2.4105985164642334
[1, 26484] loss_train: 0.003413, loss_test: 0.005516
time: 0.27503395080566406
time: 2.3881850242614746
[1, 26485] loss_train: 0.001289, loss_test: 0.005519
time: 0.29106712341308594
time: 2.399160623550415
[1, 26486] loss_train: 0.006781, loss_test: 0.005521
time: 0.2845757007598877
time: 2.420530080795288
[1, 26487] loss_train: 0.008024, loss_test: 0.005521
time: 0.29306530952453613
time: 2.3925352096557617
[1, 26488] loss_train: 0.008045, loss_test: 0.005518
time: 0.2780616283416748
time: 2.3625175952911377
[1, 26489] loss_train: 0.007151, loss_test: 0.005515
time: 0.27706122398376465
time: 2.4060440063476562
[1, 26490] loss_train: 0.009148, loss_test: 0.005511
time: 0.2910647392272949
time: 2.440065383911133
[1, 26491] loss_train: 0.009184, loss_test: 0.005507
time: 0.27906084060668945
time: 2.367530107498169
[1, 26492] loss_train: 0.004463, loss_test: 0.005505
time: 0.27773451805114746
time: 2.375985860824585
[1, 26493] loss_train: 0.011210, loss_test: 0.005502
time: 0.2841758728027344
time: 2.385185718536377
[1, 26494] loss_train: 0.007343, loss_test: 0.005501
time: 0.28206372261047363
time: 2.4066109657287598
[1, 26495] loss_train: 0.005302, loss_test: 0.005500
time: 0.27506136894226074
time: 2.397050619125366
[1, 26496] loss_train: 0.006884, loss_test: 0.005500
time: 0.2910654544830322
time: 2.4175405502319336
[1, 26497] loss_train: 0.005297, loss_test: 0.005500
time: 0.27906155586242676
time: 2.39953875541687
[1, 26498] loss_train: 0.004101, loss_test: 0.005501
time: 0.28106212615966797
time: 2.4277000427246094
[1, 26499] loss_train: 0.004203, loss_test: 0.005502
time: 0.28606367111206055
time: 2.4011452198028564
[1, 26500] loss_train: 0.006738, loss_test: 0.005499
time: 0.29006433486938477
time: 2.44754958152771
[1, 26501] loss_train: 0.008153, loss_test: 0.005498
time: 0.30560946464538574
time: 2.455394983291626
[1, 26502] loss_train: 0.005600, loss_test: 0.005500
time: 0.2690601348876953
time: 2.3835561275482178
[1, 26503] loss_train: 0.000889, loss_test: 0.005502
time: 0.27306032180786133
time: 2.398536443710327
[1, 26504] loss_train: 0.005710, loss_test: 0.005506
time: 0.27606201171875
time: 2.399759531021118
[1, 26505] loss_train: 0.004137, loss_test: 0.005508
time: 0.27906346321105957
time: 2.425048589706421
[1, 26506] loss_train: 0.004232, loss_test: 0.005509
time: 0.2820618152618408
time: 2.3754796981811523
[1, 26507] loss_train: 0.008058, loss_test: 0.005510
time: 0.2870643138885498
time: 2.407721757888794
[1, 26508] loss_train: 0.003848, loss_test: 0.005509
time: 0.2800734043121338
time: 2.4140822887420654
[1, 26509] loss_train: 0.003434, loss_test: 0.005509
time: 0.28804445266723633
time: 2.4095513820648193
[1, 26510] loss_train: 0.001502, loss_test: 0.005509
time: 0.296065092086792
time: 2.4250476360321045
[1, 26511] loss_train: 0.012815, loss_test: 0.005511
time: 0.28406286239624023
time: 2.402536392211914
[1, 26512] loss_train: 0.005438, loss_test: 0.005513
time: 0.2740602493286133
time: 2.39454984664917
[1, 26513] loss_train: 0.002139, loss_test: 0.005515
time: 0.2780632972717285
time: 2.42354416847229
[1, 26514] loss_train: 0.011413, loss_test: 0.005518
time: 0.2940664291381836
time: 2.4045369625091553
[1, 26515] loss_train: 0.009776, loss_test: 0.005522
time: 0.28806424140930176
time: 2.382294178009033
[1, 26516] loss_train: 0.005687, loss_test: 0.005520
time: 0.28206777572631836
time: 2.3977043628692627
[1, 26517] loss_train: 0.010682, loss_test: 0.005514
time: 0.2830803394317627
time: 2.36934757232666
[1, 26518] loss_train: 0.003242, loss_test: 0.005509
time: 0.2830641269683838
time: 2.412403106689453
[1, 26519] loss_train: 0.006533, loss_test: 0.005503
time: 0.27506089210510254
time: 2.38049054145813
[1, 26520] loss_train: 0.005532, loss_test: 0.005498
time: 0.29706621170043945
time: 2.406538248062134
[1, 26521] loss_train: 0.007313, loss_test: 0.005497
time: 0.291064977645874
time: 2.4153525829315186
[1, 26522] loss_train: 0.003499, loss_test: 0.005499
time: 0.2890651226043701
time: 2.4055373668670654
[1, 26523] loss_train: 0.005228, loss_test: 0.005502
time: 0.27906155586242676
time: 2.402987241744995
[1, 26524] loss_train: 0.002565, loss_test: 0.005509
time: 0.2870638370513916
time: 2.3967111110687256
[1, 26525] loss_train: 0.001178, loss_test: 0.005516
time: 0.27506041526794434
time: 2.3790595531463623
[1, 26526] loss_train: 0.007953, loss_test: 0.005525
time: 0.27306056022644043
time: 2.3735408782958984
[1, 26527] loss_train: 0.003372, loss_test: 0.005534
time: 0.2890641689300537
time: 2.4161319732666016
[1, 26528] loss_train: 0.002435, loss_test: 0.005541
time: 0.2770669460296631
time: 2.3835337162017822
[1, 26529] loss_train: 0.003536, loss_test: 0.005547
time: 0.2810628414154053
time: 2.4165401458740234
[1, 26530] loss_train: 0.003176, loss_test: 0.005552
time: 0.2960641384124756
time: 2.430544137954712
[1, 26531] loss_train: 0.011768, loss_test: 0.005547
time: 0.2950315475463867
time: 2.4140448570251465
[1, 26532] loss_train: 0.004665, loss_test: 0.005544
time: 0.3235781192779541
time: 2.8363208770751953
[1, 26533] loss_train: 0.003761, loss_test: 0.005541
time: 0.32607293128967285
time: 2.8538570404052734
[1, 26534] loss_train: 0.011879, loss_test: 0.005540
time: 0.461942195892334
time: 2.8377184867858887
[1, 26535] loss_train: 0.009338, loss_test: 0.005538
time: 0.3568239212036133
time: 2.8264858722686768
[1, 26536] loss_train: 0.009485, loss_test: 0.005532
time: 0.2940652370452881
time: 2.7750372886657715
[1, 26537] loss_train: 0.004864, loss_test: 0.005527
time: 0.3253030776977539
time: 2.4560511112213135
[1, 26538] loss_train: 0.007574, loss_test: 0.005524
time: 0.38408589363098145
time: 2.472557544708252
[1, 26539] loss_train: 0.005124, loss_test: 0.005519
time: 0.2720608711242676
time: 2.393038749694824
[1, 26540] loss_train: 0.005491, loss_test: 0.005516
time: 0.2960648536682129
time: 2.41454815864563
[1, 26541] loss_train: 0.001734, loss_test: 0.005515
time: 0.26805973052978516
time: 2.4087820053100586
[1, 26542] loss_train: 0.005858, loss_test: 0.005514
time: 0.2710597515106201
time: 2.6310698986053467
[1, 26543] loss_train: 0.001997, loss_test: 0.005513
time: 0.2720615863800049
time: 2.5376150608062744
[1, 26544] loss_train: 0.016752, loss_test: 0.005510
time: 0.27706146240234375
time: 2.4599950313568115
[1, 26545] loss_train: 0.003711, loss_test: 0.005508
time: 0.27306032180786133
time: 2.574080467224121
[1, 26546] loss_train: 0.016936, loss_test: 0.005503
time: 0.28406357765197754
time: 2.782168388366699
[1, 26547] loss_train: 0.008590, loss_test: 0.005501
time: 0.28565025329589844
time: 2.540921449661255
[1, 26548] loss_train: 0.007524, loss_test: 0.005501
time: 0.2830641269683838
time: 2.44423770904541
[1, 26549] loss_train: 0.011676, loss_test: 0.005504
time: 0.3000671863555908
time: 2.609088182449341
[1, 26550] loss_train: 0.004905, loss_test: 0.005504
time: 0.2850620746612549
time: 2.40108060836792
[1, 26551] loss_train: 0.003720, loss_test: 0.005502
time: 0.29506611824035645
time: 2.396538734436035
[1, 26552] loss_train: 0.006448, loss_test: 0.005501
time: 0.28406262397766113
time: 2.3916120529174805
[1, 26553] loss_train: 0.007141, loss_test: 0.005500
time: 0.2721891403198242
time: 2.413996696472168
[1, 26554] loss_train: 0.003789, loss_test: 0.005499
time: 0.264467716217041
time: 2.3997862339019775
[1, 26555] loss_train: 0.003647, loss_test: 0.005501
time: 0.2710592746734619
time: 2.7696642875671387
[1, 26556] loss_train: 0.004486, loss_test: 0.005502
time: 0.28806304931640625
time: 2.5530755519866943
[1, 26557] loss_train: 0.004614, loss_test: 0.005502
time: 0.33107423782348633
time: 2.5641775131225586
[1, 26558] loss_train: 0.005708, loss_test: 0.005504
time: 0.2796163558959961
time: 2.9738755226135254
[1, 26559] loss_train: 0.009241, loss_test: 0.005502
time: 0.3782052993774414
time: 3.2731399536132812
[1, 26560] loss_train: 0.004426, loss_test: 0.005503
time: 0.44968652725219727
time: 2.5684781074523926
[1, 26561] loss_train: 0.009143, loss_test: 0.005505
time: 0.4320869445800781
time: 2.871180534362793
[1, 26562] loss_train: 0.004682, loss_test: 0.005508
time: 0.4010908603668213
time: 2.7652690410614014
[1, 26563] loss_train: 0.007114, loss_test: 0.005510
time: 0.29906630516052246
time: 2.8502416610717773
[1, 26564] loss_train: 0.010476, loss_test: 0.005511
time: 0.29306483268737793
time: 2.409534454345703
[1, 26565] loss_train: 0.012364, loss_test: 0.005511
time: 0.2730598449707031
time: 2.467057704925537
[1, 26566] loss_train: 0.005774, loss_test: 0.005511
time: 0.2863423824310303
time: 2.435637950897217
[1, 26567] loss_train: 0.004368, loss_test: 0.005512
time: 0.2850635051727295
time: 2.95766019821167
[1, 26568] loss_train: 0.006092, loss_test: 0.005512
time: 0.2880666255950928
time: 2.858186721801758
[1, 26569] loss_train: 0.006748, loss_test: 0.005506
time: 0.4561944007873535
time: 2.9260880947113037
[1, 26570] loss_train: 0.003733, loss_test: 0.005504
time: 0.28806376457214355
time: 2.7076053619384766
[1, 26571] loss_train: 0.003743, loss_test: 0.005505
time: 0.29906558990478516
time: 2.6828112602233887
[1, 26572] loss_train: 0.001210, loss_test: 0.005509
time: 0.3180735111236572
time: 2.6601059436798096
[1, 26573] loss_train: 0.002889, loss_test: 0.005517
time: 0.2820625305175781
time: 2.725114345550537
[1, 26574] loss_train: 0.003335, loss_test: 0.005517
time: 0.4089210033416748
time: 2.665626287460327
[1, 26575] loss_train: 0.009628, loss_test: 0.005512
time: 0.3520777225494385
time: 2.822632074356079
[1, 26576] loss_train: 0.006972, loss_test: 0.005509
time: 0.29906582832336426
time: 2.4565582275390625
[1, 26577] loss_train: 0.004742, loss_test: 0.005510
time: 0.28663063049316406
time: 2.4914276599884033
[1, 26578] loss_train: 0.007465, loss_test: 0.005513
time: 0.27771854400634766
time: 2.408720016479492
[1, 26579] loss_train: 0.002458, loss_test: 0.005518
time: 0.3430025577545166
time: 2.5219340324401855
[1, 26580] loss_train: 0.003213, loss_test: 0.005525
time: 0.3643972873687744
time: 2.7961955070495605
[1, 26581] loss_train: 0.004827, loss_test: 0.005530
time: 0.2950739860534668
time: 2.5531270503997803
[1, 26582] loss_train: 0.007187, loss_test: 0.005532
time: 0.4803483486175537
time: 2.8459532260894775
[1, 26583] loss_train: 0.004095, loss_test: 0.005534
time: 0.2986612319946289
time: 2.52980899810791
[1, 26584] loss_train: 0.018844, loss_test: 0.005520
time: 0.2830643653869629
time: 2.5589003562927246
[1, 26585] loss_train: 0.011869, loss_test: 0.005508
time: 0.29706573486328125
time: 2.4375505447387695
[1, 26586] loss_train: 0.004668, loss_test: 0.005506
time: 0.2870631217956543
time: 2.63006854057312
[1, 26587] loss_train: 0.006039, loss_test: 0.005511
time: 0.39908933639526367
time: 2.5702428817749023
[1, 26588] loss_train: 0.006398, loss_test: 0.005523
time: 0.4546482563018799
time: 2.54866361618042
[1, 26589] loss_train: 0.004564, loss_test: 0.005536
time: 0.3451218605041504
time: 2.871649742126465
[1, 26590] loss_train: 0.006244, loss_test: 0.005544
time: 0.39386892318725586
time: 2.5088131427764893
[1, 26591] loss_train: 0.002044, loss_test: 0.005542
time: 0.29506540298461914
time: 2.4922304153442383
[1, 26592] loss_train: 0.009884, loss_test: 0.005538
time: 0.2870030403137207
time: 2.505713939666748
[1, 26593] loss_train: 0.016430, loss_test: 0.005535
time: 0.3050675392150879
time: 2.500563859939575
[1, 26594] loss_train: 0.017192, loss_test: 0.005539
time: 0.2780616283416748
time: 2.397540807723999
[1, 26595] loss_train: 0.005618, loss_test: 0.005541
time: 0.28106188774108887
time: 2.5813586711883545
[1, 26596] loss_train: 0.004444, loss_test: 0.005542
time: 0.3720824718475342
time: 2.6340951919555664
[1, 26597] loss_train: 0.006622, loss_test: 0.005543
time: 0.27706098556518555
time: 2.603912830352783
[1, 26598] loss_train: 0.003694, loss_test: 0.005546
time: 0.5977528095245361
time: 2.696645736694336
[1, 26599] loss_train: 0.005629, loss_test: 0.005545
time: 0.29006528854370117
time: 2.4125382900238037
[1, 26600] loss_train: 0.007849, loss_test: 0.005546
time: 0.2960660457611084
time: 2.3784685134887695
[1, 26601] loss_train: 0.005245, loss_test: 0.005552
time: 0.27556610107421875
time: 2.4258861541748047
[1, 26602] loss_train: 0.006739, loss_test: 0.005560
time: 0.27106356620788574
time: 2.3995368480682373
[1, 26603] loss_train: 0.002471, loss_test: 0.005571
time: 0.27906131744384766
time: 2.3845601081848145
[1, 26604] loss_train: 0.004090, loss_test: 0.005581
time: 0.2778027057647705
time: 2.414541721343994
[1, 26605] loss_train: 0.002053, loss_test: 0.005593
time: 0.26605701446533203
time: 2.5345799922943115
[1, 26606] loss_train: 0.009382, loss_test: 0.005597
time: 0.33054184913635254
time: 2.843656301498413
[1, 26607] loss_train: 0.004376, loss_test: 0.005599
time: 0.292522668838501
time: 2.979301691055298
[1, 26608] loss_train: 0.009710, loss_test: 0.005588
time: 0.45510125160217285
time: 2.8136301040649414
[1, 26609] loss_train: 0.011057, loss_test: 0.005566
time: 0.2881157398223877
time: 2.485990285873413
[1, 26610] loss_train: 0.008432, loss_test: 0.005542
time: 0.3050706386566162
time: 2.5830047130584717
[1, 26611] loss_train: 0.013199, loss_test: 0.005523
time: 0.3110687732696533
time: 2.970665216445923
[1, 26612] loss_train: 0.009339, loss_test: 0.005512
time: 0.28606534004211426
time: 2.658099889755249
[1, 26613] loss_train: 0.002543, loss_test: 0.005507
time: 0.3120691776275635
time: 2.558574914932251
[1, 26614] loss_train: 0.012413, loss_test: 0.005507
time: 0.28606390953063965
time: 2.7294933795928955
[1, 26615] loss_train: 0.001545, loss_test: 0.005511
time: 0.3080015182495117
time: 2.955930233001709
[1, 26616] loss_train: 0.005007, loss_test: 0.005519
time: 0.2761874198913574
time: 2.441632032394409
[1, 26617] loss_train: 0.006496, loss_test: 0.005530
time: 0.2920651435852051
time: 2.4780678749084473
[1, 26618] loss_train: 0.007129, loss_test: 0.005540
time: 0.28406262397766113
time: 2.4504501819610596
[1, 26619] loss_train: 0.013883, loss_test: 0.005543
time: 0.3110690116882324
time: 2.4834301471710205
[1, 26620] loss_train: 0.003488, loss_test: 0.005542
time: 0.2925848960876465
time: 2.546783208847046
[1, 26621] loss_train: 0.006071, loss_test: 0.005540
time: 0.28406262397766113
time: 2.6534504890441895
[1, 26622] loss_train: 0.007700, loss_test: 0.005533
time: 0.28406405448913574
time: 2.659358263015747
[1, 26623] loss_train: 0.007334, loss_test: 0.005528
time: 0.3230714797973633
time: 2.5495705604553223
[1, 26624] loss_train: 0.008309, loss_test: 0.005524
time: 0.2920658588409424
time: 2.639875650405884
[1, 26625] loss_train: 0.007390, loss_test: 0.005521
time: 0.4030895233154297
time: 2.5433008670806885
[1, 26626] loss_train: 0.013363, loss_test: 0.005518
time: 0.3420438766479492
time: 2.7519845962524414
[1, 26627] loss_train: 0.006905, loss_test: 0.005516
time: 0.2850625514984131
time: 2.4465572834014893
[1, 26628] loss_train: 0.004243, loss_test: 0.005514
time: 0.2960653305053711
time: 2.4385552406311035
[1, 26629] loss_train: 0.001308, loss_test: 0.005512
time: 0.30106663703918457
time: 2.6205835342407227
[1, 26630] loss_train: 0.003639, loss_test: 0.005510
time: 0.30606770515441895
time: 2.597026824951172
[1, 26631] loss_train: 0.002956, loss_test: 0.005509
time: 0.2740645408630371
time: 2.77315616607666
[1, 26632] loss_train: 0.001194, loss_test: 0.005510
time: 0.2920646667480469
time: 2.4595508575439453
[1, 26633] loss_train: 0.003462, loss_test: 0.005512
time: 0.2960653305053711
time: 2.7443275451660156
[1, 26634] loss_train: 0.006339, loss_test: 0.005516
time: 0.29306483268737793
time: 2.413543224334717
[1, 26635] loss_train: 0.001639, loss_test: 0.005523
time: 0.29506540298461914
time: 2.403879165649414
[1, 26636] loss_train: 0.010417, loss_test: 0.005525
time: 0.2705981731414795
time: 2.3522090911865234
[1, 26637] loss_train: 0.003431, loss_test: 0.005527
time: 0.2890639305114746
time: 2.4365484714508057
[1, 26638] loss_train: 0.005044, loss_test: 0.005527
time: 0.28692150115966797
time: 2.415417432785034
[1, 26639] loss_train: 0.008570, loss_test: 0.005521
time: 0.28106188774108887
time: 2.428046703338623
[1, 26640] loss_train: 0.002008, loss_test: 0.005518
time: 0.2890636920928955
time: 2.452565908432007
[1, 26641] loss_train: 0.005290, loss_test: 0.005516
time: 0.27706122398376465
time: 2.412057399749756
[1, 26642] loss_train: 0.010266, loss_test: 0.005512
time: 0.29308605194091797
time: 2.425773859024048
[1, 26643] loss_train: 0.004620, loss_test: 0.005509
time: 0.27706170082092285
time: 2.4328858852386475
[1, 26644] loss_train: 0.003984, loss_test: 0.005509
time: 0.2820627689361572
time: 2.400650978088379
[1, 26645] loss_train: 0.002314, loss_test: 0.005509
time: 0.29407358169555664
time: 2.4440274238586426
[1, 26646] loss_train: 0.007664, loss_test: 0.005509
time: 0.29006433486938477
time: 2.5125627517700195
[1, 26647] loss_train: 0.001940, loss_test: 0.005509
time: 0.28806328773498535
time: 2.635617971420288
[1, 26648] loss_train: 0.011347, loss_test: 0.005507
time: 0.29306554794311523
time: 2.4289450645446777
[1, 26649] loss_train: 0.011475, loss_test: 0.005506
time: 0.2850644588470459
time: 2.487253189086914
[1, 26650] loss_train: 0.007746, loss_test: 0.005510
time: 0.2920656204223633
time: 2.442552089691162
[1, 26651] loss_train: 0.010130, loss_test: 0.005516
time: 0.28106212615966797
time: 2.4165406227111816
[1, 26652] loss_train: 0.006653, loss_test: 0.005524
time: 0.27906227111816406
time: 2.4060418605804443
[1, 26653] loss_train: 0.002658, loss_test: 0.005530
time: 0.2720603942871094
time: 2.407538414001465
[1, 26654] loss_train: 0.006407, loss_test: 0.005532
time: 0.278062105178833
time: 2.442554235458374
[1, 26655] loss_train: 0.001817, loss_test: 0.005535
time: 0.291064977645874
time: 2.3955390453338623
[1, 26656] loss_train: 0.007971, loss_test: 0.005538
time: 0.2710587978363037
time: 2.420056104660034
[1, 26657] loss_train: 0.006109, loss_test: 0.005533
time: 0.28511619567871094
time: 2.390399694442749
[1, 26658] loss_train: 0.010996, loss_test: 0.005527
time: 0.27906322479248047
time: 2.4102447032928467
[1, 26659] loss_train: 0.007291, loss_test: 0.005522
time: 0.2748429775238037
time: 2.4265737533569336
[1, 26660] loss_train: 0.009279, loss_test: 0.005514
time: 0.29006528854370117
time: 2.39654803276062
[1, 26661] loss_train: 0.009772, loss_test: 0.005508
time: 0.2830636501312256
time: 2.4175398349761963
[1, 26662] loss_train: 0.000963, loss_test: 0.005504
time: 0.2740614414215088
time: 2.3980534076690674
[1, 26663] loss_train: 0.006074, loss_test: 0.005504
time: 0.2910642623901367
time: 2.389040231704712
[1, 26664] loss_train: 0.001441, loss_test: 0.005504
time: 0.28106164932250977
time: 2.4266862869262695
[1, 26665] loss_train: 0.004766, loss_test: 0.005508
time: 0.2890639305114746
time: 2.5030717849731445
[1, 26666] loss_train: 0.002270, loss_test: 0.005515
time: 0.2710597515106201
time: 2.6645264625549316
[1, 26667] loss_train: 0.002832, loss_test: 0.005524
time: 0.34903478622436523
time: 2.6037912368774414
[1, 26668] loss_train: 0.004039, loss_test: 0.005534
time: 0.3110690116882324
time: 2.5165629386901855
[1, 26669] loss_train: 0.002841, loss_test: 0.005537
time: 0.28607821464538574
time: 2.6927459239959717
[1, 26670] loss_train: 0.000839, loss_test: 0.005544
time: 0.3110692501068115
time: 2.4759109020233154
[1, 26671] loss_train: 0.007314, loss_test: 0.005546
time: 0.3956568241119385
time: 2.617279291152954
[1, 26672] loss_train: 0.003872, loss_test: 0.005545
time: 0.30806827545166016
time: 2.553077459335327
[1, 26673] loss_train: 0.002311, loss_test: 0.005546
time: 0.281064510345459
time: 2.492069959640503
[1, 26674] loss_train: 0.019771, loss_test: 0.005533
time: 0.31306910514831543
time: 2.448549747467041
[1, 26675] loss_train: 0.011522, loss_test: 0.005512
time: 0.26405906677246094
time: 2.438048839569092
[1, 26676] loss_train: 0.002955, loss_test: 0.005501
time: 0.2737553119659424
time: 2.4330201148986816
[1, 26677] loss_train: 0.004519, loss_test: 0.005497
time: 0.27806782722473145
time: 2.3734874725341797
[1, 26678] loss_train: 0.002827, loss_test: 0.005497
time: 0.27324795722961426
time: 2.5571961402893066
[1, 26679] loss_train: 0.007287, loss_test: 0.005501
time: 0.28406286239624023
time: 2.8049280643463135
[1, 26680] loss_train: 0.005335, loss_test: 0.005506
time: 0.4380977153778076
time: 2.5028157234191895
[1, 26681] loss_train: 0.012192, loss_test: 0.005504
time: 0.2830801010131836
time: 2.587552309036255
[1, 26682] loss_train: 0.006006, loss_test: 0.005503
time: 0.303067684173584
time: 2.7424240112304688
[1, 26683] loss_train: 0.004330, loss_test: 0.005499
time: 0.28406286239624023
time: 2.55039381980896
[1, 26684] loss_train: 0.006442, loss_test: 0.005498
time: 0.2920560836791992
time: 2.8651723861694336
[1, 26685] loss_train: 0.009174, loss_test: 0.005497
time: 0.28906679153442383
time: 2.8705036640167236
[1, 26686] loss_train: 0.003195, loss_test: 0.005495
time: 0.34507131576538086
time: 2.480062246322632
[1, 26687] loss_train: 0.007716, loss_test: 0.005492
time: 0.2795288562774658
time: 2.896925210952759
[1, 26688] loss_train: 0.002154, loss_test: 0.005490
time: 0.31006813049316406
time: 2.57845139503479
[1, 26689] loss_train: 0.008769, loss_test: 0.005490
time: 0.42697882652282715
time: 2.7671380043029785
[1, 26690] loss_train: 0.001480, loss_test: 0.005492
time: 0.29106664657592773
time: 2.8081512451171875
[1, 26691] loss_train: 0.006467, loss_test: 0.005495
time: 0.2920644283294678
time: 2.806701183319092
[1, 26692] loss_train: 0.004300, loss_test: 0.005499
time: 0.45510101318359375
time: 2.6283748149871826
[1, 26693] loss_train: 0.007663, loss_test: 0.005502
time: 0.2850635051727295
time: 2.5843989849090576
[1, 26694] loss_train: 0.001982, loss_test: 0.005507
time: 0.27706098556518555
time: 2.4190638065338135
[1, 26695] loss_train: 0.008062, loss_test: 0.005511
time: 0.4267852306365967
time: 2.4775569438934326
[1, 26696] loss_train: 0.008524, loss_test: 0.005514
time: 0.2960686683654785
time: 2.4295148849487305
[1, 26697] loss_train: 0.000828, loss_test: 0.005519
time: 0.27103614807128906
time: 2.4823665618896484
[1, 26698] loss_train: 0.015280, loss_test: 0.005515
time: 0.28068041801452637
time: 2.669302225112915
[1, 26699] loss_train: 0.000445, loss_test: 0.005514
time: 0.3120570182800293
time: 2.932447671890259
[1, 26700] loss_train: 0.011670, loss_test: 0.005511
time: 0.31506896018981934
time: 2.3937201499938965
[1, 26701] loss_train: 0.005684, loss_test: 0.005508
time: 0.29006481170654297
time: 3.100029468536377
[1, 26702] loss_train: 0.002776, loss_test: 0.005507
time: 0.43309688568115234
time: 2.645167112350464
[1, 26703] loss_train: 0.002762, loss_test: 0.005504
time: 0.33812808990478516
time: 2.6340491771698
[1, 26704] loss_train: 0.002160, loss_test: 0.005506
time: 0.2760612964630127
time: 2.683600425720215
[1, 26705] loss_train: 0.012069, loss_test: 0.005504
time: 0.27306032180786133
time: 2.5139896869659424
[1, 26706] loss_train: 0.008214, loss_test: 0.005503
time: 0.38608574867248535
time: 2.5270183086395264
[1, 26707] loss_train: 0.001205, loss_test: 0.005501
time: 0.2760612964630127
time: 2.410557985305786
[1, 26708] loss_train: 0.011135, loss_test: 0.005498
time: 0.2850630283355713
time: 2.583012580871582
[1, 26709] loss_train: 0.008535, loss_test: 0.005495
time: 0.27906250953674316
time: 2.4752004146575928
[1, 26710] loss_train: 0.004511, loss_test: 0.005493
time: 0.30606746673583984
time: 2.4630069732666016
[1, 26711] loss_train: 0.008781, loss_test: 0.005491
time: 0.33400392532348633
time: 2.649517297744751
[1, 26712] loss_train: 0.011537, loss_test: 0.005490
time: 0.2933216094970703
time: 2.995662212371826
[1, 26713] loss_train: 0.004528, loss_test: 0.005490
time: 0.2960655689239502
time: 2.5762696266174316
[1, 26714] loss_train: 0.006169, loss_test: 0.005489
time: 0.2830638885498047
time: 2.5918893814086914
[1, 26715] loss_train: 0.009312, loss_test: 0.005490
time: 0.3270730972290039
time: 2.4854841232299805
[1, 26716] loss_train: 0.008705, loss_test: 0.005490
time: 0.3269476890563965
time: 2.524453639984131
[1, 26717] loss_train: 0.003873, loss_test: 0.005490
time: 0.3180716037750244
time: 2.7850804328918457
[1, 26718] loss_train: 0.000481, loss_test: 0.005491
time: 0.4359922409057617
time: 2.6654136180877686
[1, 26719] loss_train: 0.010031, loss_test: 0.005491
time: 0.32507991790771484
time: 2.8763630390167236
[1, 26720] loss_train: 0.005514, loss_test: 0.005489
time: 0.2920653820037842
time: 2.5260865688323975
[1, 26721] loss_train: 0.004794, loss_test: 0.005488
time: 0.2890639305114746
time: 2.4069466590881348
[1, 26722] loss_train: 0.012646, loss_test: 0.005486
time: 0.28806424140930176
time: 2.4990649223327637
[1, 26723] loss_train: 0.007720, loss_test: 0.005485
time: 0.2845768928527832
time: 2.4021830558776855
[1, 26724] loss_train: 0.007996, loss_test: 0.005483
time: 0.27005982398986816
time: 2.432126045227051
[1, 26725] loss_train: 0.006251, loss_test: 0.005481
time: 0.29306459426879883
time: 2.407564640045166
[1, 26726] loss_train: 0.003441, loss_test: 0.005480
time: 0.2780923843383789
time: 2.407363176345825
[1, 26727] loss_train: 0.002702, loss_test: 0.005480
time: 0.2780623435974121
time: 2.4450535774230957
[1, 26728] loss_train: 0.006749, loss_test: 0.005480
time: 0.28806376457214355
time: 2.4185407161712646
[1, 26729] loss_train: 0.004291, loss_test: 0.005481
time: 0.27306032180786133
time: 2.4810588359832764
[1, 26730] loss_train: 0.005392, loss_test: 0.005481
time: 0.28806352615356445
time: 2.3779404163360596
[1, 26731] loss_train: 0.008863, loss_test: 0.005480
time: 0.2800614833831787
time: 2.3742480278015137
[1, 26732] loss_train: 0.002131, loss_test: 0.005479
time: 0.27585935592651367
time: 2.4539601802825928
[1, 26733] loss_train: 0.006758, loss_test: 0.005481
time: 0.27005863189697266
time: 2.374608278274536
[1, 26734] loss_train: 0.002413, loss_test: 0.005484
time: 0.2690598964691162
time: 2.5850765705108643
[1, 26735] loss_train: 0.008106, loss_test: 0.005487
time: 0.283109188079834
time: 3.0835673809051514
[1, 26736] loss_train: 0.007001, loss_test: 0.005490
time: 0.30525803565979004
time: 2.5719268321990967
[1, 26737] loss_train: 0.007318, loss_test: 0.005494
time: 0.2870643138885498
time: 2.578998327255249
[1, 26738] loss_train: 0.010438, loss_test: 0.005496
time: 0.2940664291381836
time: 2.6505930423736572
[1, 26739] loss_train: 0.004198, loss_test: 0.005499
time: 0.29706692695617676
time: 2.4285430908203125
[1, 26740] loss_train: 0.007516, loss_test: 0.005503
time: 0.3030667304992676
time: 2.4990789890289307
[1, 26741] loss_train: 0.004997, loss_test: 0.005507
time: 0.2740743160247803
time: 2.382688045501709
[1, 26742] loss_train: 0.001507, loss_test: 0.005510
time: 0.275468111038208
time: 2.4461328983306885
[1, 26743] loss_train: 0.006348, loss_test: 0.005513
time: 0.282062292098999
time: 2.3820607662200928
[1, 26744] loss_train: 0.004852, loss_test: 0.005515
time: 0.2780611515045166
time: 2.386749744415283
[1, 26745] loss_train: 0.006232, loss_test: 0.005517
time: 0.27306032180786133
time: 2.4685542583465576
[1, 26746] loss_train: 0.006593, loss_test: 0.005517
time: 0.28106212615966797
time: 2.3559110164642334
[1, 26747] loss_train: 0.005887, loss_test: 0.005518
time: 0.2738173007965088
time: 2.6097800731658936
[1, 26748] loss_train: 0.004583, loss_test: 0.005519
time: 0.28806495666503906
time: 2.3893933296203613
[1, 26749] loss_train: 0.005526, loss_test: 0.005520
time: 0.28106236457824707
time: 2.44905161857605
[1, 26750] loss_train: 0.005925, loss_test: 0.005521
time: 0.32009387016296387
time: 2.398536205291748
[1, 26751] loss_train: 0.001988, loss_test: 0.005522
time: 0.2820627689361572
time: 2.5999224185943604
[1, 26752] loss_train: 0.001411, loss_test: 0.005526
time: 0.34607768058776855
time: 2.6540369987487793
[1, 26753] loss_train: 0.005239, loss_test: 0.005530
time: 0.3010671138763428
time: 2.7572145462036133
[1, 26754] loss_train: 0.002976, loss_test: 0.005536
time: 0.29906606674194336
time: 2.764171838760376
[1, 26755] loss_train: 0.016398, loss_test: 0.005531
time: 0.39308643341064453
time: 2.6586077213287354
[1, 26756] loss_train: 0.005182, loss_test: 0.005527
time: 0.28606438636779785
time: 2.4280595779418945
[1, 26757] loss_train: 0.003270, loss_test: 0.005526
time: 0.29206347465515137
time: 2.956702709197998
[1, 26758] loss_train: 0.005141, loss_test: 0.005525
time: 0.283062219619751
time: 2.5458710193634033
[1, 26759] loss_train: 0.006391, loss_test: 0.005526
time: 0.4030892848968506
time: 2.961056709289551
[1, 26760] loss_train: 0.015064, loss_test: 0.005522
time: 0.3320748805999756
time: 3.1335666179656982
[1, 26761] loss_train: 0.004409, loss_test: 0.005520
time: 0.3030669689178467
time: 2.6169378757476807
[1, 26762] loss_train: 0.003733, loss_test: 0.005521
time: 0.41345787048339844
time: 2.8875372409820557
[1, 26763] loss_train: 0.003463, loss_test: 0.005523
time: 0.28110408782958984
time: 2.901468276977539
[1, 26764] loss_train: 0.008771, loss_test: 0.005529
time: 0.37008190155029297
time: 2.952340841293335
[1, 26765] loss_train: 0.002869, loss_test: 0.005533
time: 0.28257060050964355
time: 2.7858049869537354
[1, 26766] loss_train: 0.009208, loss_test: 0.005540
time: 0.29306554794311523
time: 2.629861831665039
[1, 26767] loss_train: 0.012470, loss_test: 0.005541
time: 0.2780623435974121
time: 2.587083578109741
[1, 26768] loss_train: 0.003805, loss_test: 0.005538
time: 0.2953488826751709
time: 2.4936020374298096
[1, 26769] loss_train: 0.011566, loss_test: 0.005533
time: 0.2870640754699707
time: 2.4926254749298096
[1, 26770] loss_train: 0.002769, loss_test: 0.005528
time: 0.2950742244720459
time: 2.44427227973938
[1, 26771] loss_train: 0.012593, loss_test: 0.005523
time: 0.2760615348815918
time: 2.5050673484802246
[1, 26772] loss_train: 0.005202, loss_test: 0.005519
time: 0.38108396530151367
time: 2.4081830978393555
[1, 26773] loss_train: 0.007260, loss_test: 0.005517
time: 0.2870633602142334
time: 2.4191367626190186
[1, 26774] loss_train: 0.005050, loss_test: 0.005517
time: 0.2870635986328125
time: 2.4230241775512695
[1, 26775] loss_train: 0.004019, loss_test: 0.005520
time: 0.26319146156311035
time: 2.401435613632202
[1, 26776] loss_train: 0.004909, loss_test: 0.005522
time: 0.37435388565063477
time: 2.5055649280548096
[1, 26777] loss_train: 0.003195, loss_test: 0.005523
time: 0.29306507110595703
time: 2.4925596714019775
[1, 26778] loss_train: 0.002834, loss_test: 0.005525
time: 0.5700125694274902
time: 3.153268575668335
[1, 26779] loss_train: 0.004823, loss_test: 0.005530
time: 0.2932109832763672
time: 2.4385509490966797
[1, 26780] loss_train: 0.005785, loss_test: 0.005533
time: 0.29906654357910156
time: 2.4155402183532715
[1, 26781] loss_train: 0.010937, loss_test: 0.005522
time: 0.2720603942871094
time: 2.387037992477417
[1, 26782] loss_train: 0.005732, loss_test: 0.005514
time: 0.27205991744995117
time: 2.3840372562408447
[1, 26783] loss_train: 0.002821, loss_test: 0.005508
time: 0.28106069564819336
time: 2.405005693435669
[1, 26784] loss_train: 0.011514, loss_test: 0.005503
time: 0.2690589427947998
time: 2.381079912185669
[1, 26785] loss_train: 0.006303, loss_test: 0.005502
time: 0.2706418037414551
time: 2.3953747749328613
[1, 26786] loss_train: 0.003641, loss_test: 0.005501
time: 0.28351664543151855
time: 2.39875864982605
[1, 26787] loss_train: 0.007108, loss_test: 0.005499
time: 0.28606414794921875
time: 2.375539541244507
[1, 26788] loss_train: 0.007421, loss_test: 0.005493
time: 0.27006077766418457
time: 2.3960418701171875
[1, 26789] loss_train: 0.004987, loss_test: 0.005491
time: 0.2710602283477783
time: 2.3695297241210938
[1, 26790] loss_train: 0.002614, loss_test: 0.005492
time: 0.2910654544830322
time: 2.3992855548858643
[1, 26791] loss_train: 0.004015, loss_test: 0.005496
time: 0.2740614414215088
time: 2.376530885696411
[1, 26792] loss_train: 0.006715, loss_test: 0.005502
time: 0.2740628719329834
time: 2.3952529430389404
[1, 26793] loss_train: 0.016898, loss_test: 0.005500
time: 0.27205967903137207
time: 2.3605284690856934
[1, 26794] loss_train: 0.011431, loss_test: 0.005503
time: 0.2700984477996826
time: 2.389301061630249
[1, 26795] loss_train: 0.009254, loss_test: 0.005510
time: 0.278062105178833
time: 2.3730356693267822
[1, 26796] loss_train: 0.005530, loss_test: 0.005517
time: 0.27006053924560547
time: 2.3720335960388184
[1, 26797] loss_train: 0.003179, loss_test: 0.005520
time: 0.27706074714660645
time: 2.3550353050231934
[1, 26798] loss_train: 0.004836, loss_test: 0.005516
time: 0.27205944061279297
time: 2.3775320053100586
[1, 26799] loss_train: 0.012742, loss_test: 0.005512
time: 0.2690601348876953
time: 2.859846591949463
[1, 26800] loss_train: 0.010154, loss_test: 0.005501
time: 0.39121198654174805
time: 2.7721750736236572
[1, 26801] loss_train: 0.011113, loss_test: 0.005492
time: 0.33007311820983887
time: 2.485642671585083
[1, 26802] loss_train: 0.008522, loss_test: 0.005486
time: 0.2813746929168701
time: 2.560803174972534
[1, 26803] loss_train: 0.003428, loss_test: 0.005483
time: 0.2820620536804199
time: 2.4755542278289795
[1, 26804] loss_train: 0.004747, loss_test: 0.005484
time: 0.27906155586242676
time: 2.3855338096618652
[1, 26805] loss_train: 0.005006, loss_test: 0.005488
time: 0.2730598449707031
time: 2.4025378227233887
[1, 26806] loss_train: 0.005931, loss_test: 0.005494
time: 0.2720615863800049
time: 2.406043767929077
[1, 26807] loss_train: 0.002624, loss_test: 0.005502
time: 0.27006101608276367
time: 2.3935487270355225
[1, 26808] loss_train: 0.006523, loss_test: 0.005509
time: 0.2762613296508789
time: 2.397841691970825
[1, 26809] loss_train: 0.005867, loss_test: 0.005516
time: 0.2710604667663574
time: 2.360527753829956
[1, 26810] loss_train: 0.003945, loss_test: 0.005523
time: 0.29506516456604004
time: 2.513500452041626
[1, 26811] loss_train: 0.002939, loss_test: 0.005531
time: 0.4461333751678467
time: 2.5289530754089355
[1, 26812] loss_train: 0.002981, loss_test: 0.005540
time: 0.2816951274871826
time: 2.391057014465332
[1, 26813] loss_train: 0.009207, loss_test: 0.005538
time: 0.3030667304992676
time: 2.445549488067627
[1, 26814] loss_train: 0.018247, loss_test: 0.005522
time: 0.2890646457672119
time: 2.4134702682495117
[1, 26815] loss_train: 0.002870, loss_test: 0.005514
time: 0.2850635051727295
time: 2.4245502948760986
[1, 26816] loss_train: 0.004625, loss_test: 0.005508
time: 0.2870638370513916
time: 2.407539129257202
[1, 26817] loss_train: 0.007920, loss_test: 0.005503
time: 0.28806328773498535
time: 2.522608518600464
[1, 26818] loss_train: 0.008625, loss_test: 0.005497
time: 0.33007383346557617
time: 2.6081783771514893
[1, 26819] loss_train: 0.006281, loss_test: 0.005494
time: 0.2536039352416992
time: 2.299482583999634
[1, 26820] loss_train: 0.006960, loss_test: 0.005494
time: 0.26805901527404785
time: 2.2835144996643066
[1, 26821] loss_train: 0.008597, loss_test: 0.005497
time: 0.24754619598388672
time: 2.2749412059783936
[1, 26822] loss_train: 0.007194, loss_test: 0.005501
time: 0.2470552921295166
time: 2.3068692684173584
[1, 26823] loss_train: 0.010974, loss_test: 0.005507
time: 0.2540559768676758
time: 2.2665135860443115
[1, 26824] loss_train: 0.009122, loss_test: 0.005510
time: 0.2670586109161377
time: 2.300738573074341
[1, 26825] loss_train: 0.004526, loss_test: 0.005515
time: 0.2560555934906006
time: 2.2862000465393066
[1, 26826] loss_train: 0.009586, loss_test: 0.005515
time: 0.2490558624267578
time: 2.258504867553711
[1, 26827] loss_train: 0.011314, loss_test: 0.005518
time: 0.2470555305480957
time: 2.278221607208252
[1, 26828] loss_train: 0.003984, loss_test: 0.005513
time: 0.25505614280700684
time: 2.2960290908813477
[1, 26829] loss_train: 0.002040, loss_test: 0.005515
time: 0.254056453704834
time: 2.3015172481536865
[1, 26830] loss_train: 0.004834, loss_test: 0.005517
time: 0.27106213569641113
time: 2.293515205383301
[1, 26831] loss_train: 0.004667, loss_test: 0.005522
time: 0.25277018547058105
time: 2.2975142002105713
[1, 26832] loss_train: 0.006757, loss_test: 0.005528
time: 0.2470552921295166
time: 2.2795088291168213
[1, 26833] loss_train: 0.001338, loss_test: 0.005537
time: 0.2620580196380615
time: 2.2858400344848633
[1, 26834] loss_train: 0.003629, loss_test: 0.005546
time: 0.2470545768737793
time: 2.265007972717285
[1, 26835] loss_train: 0.000959, loss_test: 0.005557
time: 0.25505852699279785
time: 2.2646117210388184
[1, 26836] loss_train: 0.009596, loss_test: 0.005556
time: 0.24805474281311035
time: 2.272430658340454
[1, 26837] loss_train: 0.011584, loss_test: 0.005544
time: 0.2600569725036621
time: 2.265507698059082
[1, 26838] loss_train: 0.006129, loss_test: 0.005530
time: 0.24805521965026855
time: 2.2650113105773926
[1, 26839] loss_train: 0.005387, loss_test: 0.005520
time: 0.2540550231933594
time: 2.256510019302368
[1, 26840] loss_train: 0.006360, loss_test: 0.005513
time: 0.26105833053588867
time: 2.2785098552703857
[1, 26841] loss_train: 0.004142, loss_test: 0.005509
time: 0.24805617332458496
time: 2.2647593021392822
[1, 26842] loss_train: 0.002142, loss_test: 0.005508
time: 0.24805736541748047
time: 2.2630856037139893
[1, 26843] loss_train: 0.007101, loss_test: 0.005506
time: 0.2560594081878662
time: 2.2765414714813232
[1, 26844] loss_train: 0.004748, loss_test: 0.005506
time: 0.2470569610595703
time: 2.2634639739990234
[1, 26845] loss_train: 0.006154, loss_test: 0.005506
time: 0.2510557174682617
time: 2.284019708633423
[1, 26846] loss_train: 0.006036, loss_test: 0.005506
time: 0.2475602626800537
time: 2.2785253524780273
[1, 26847] loss_train: 0.003994, loss_test: 0.005503
time: 0.2560567855834961
time: 2.276510000228882
[1, 26848] loss_train: 0.006189, loss_test: 0.005500
time: 0.25005602836608887
time: 2.285048484802246
[1, 26849] loss_train: 0.006977, loss_test: 0.005500
time: 0.24805474281311035
time: 2.288949966430664
[1, 26850] loss_train: 0.008037, loss_test: 0.005502
time: 0.26605963706970215
time: 2.3055152893066406
[1, 26851] loss_train: 0.017923, loss_test: 0.005506
time: 0.2520565986633301
time: 2.3072469234466553
[1, 26852] loss_train: 0.006993, loss_test: 0.005509
time: 0.2490553855895996
time: 2.279510021209717
[1, 26853] loss_train: 0.004237, loss_test: 0.005511
time: 0.2490549087524414
time: 2.2725086212158203
[1, 26854] loss_train: 0.016180, loss_test: 0.005512
time: 0.25905704498291016
time: 2.2680113315582275
[1, 26855] loss_train: 0.016945, loss_test: 0.005512
time: 0.24805498123168945
time: 2.2675089836120605
[1, 26856] loss_train: 0.005707, loss_test: 0.005510
time: 0.2470545768737793
time: 2.267507791519165
[1, 26857] loss_train: 0.004884, loss_test: 0.005509
time: 0.24505352973937988
time: 2.249645233154297
[1, 26858] loss_train: 0.007827, loss_test: 0.005508
time: 0.25505638122558594
time: 2.278657913208008
[1, 26859] loss_train: 0.009316, loss_test: 0.005507
time: 0.24905610084533691
time: 2.2741568088531494
[1, 26860] loss_train: 0.005303, loss_test: 0.005506
time: 0.26405930519104004
time: 2.446061372756958
[1, 26861] loss_train: 0.003124, loss_test: 0.005506
time: 0.2730598449707031
time: 2.5080666542053223
[1, 26862] loss_train: 0.004772, loss_test: 0.005507
time: 0.2490553855895996
time: 2.3810367584228516
[1, 26863] loss_train: 0.006049, loss_test: 0.005509
time: 0.2470543384552002
time: 2.2513418197631836
[1, 26864] loss_train: 0.006726, loss_test: 0.005511
time: 0.2490549087524414
time: 2.319131374359131
[1, 26865] loss_train: 0.010879, loss_test: 0.005508
time: 0.26405835151672363
time: 2.3130269050598145
[1, 26866] loss_train: 0.006451, loss_test: 0.005503
time: 0.25105762481689453
time: 2.2514007091522217
[1, 26867] loss_train: 0.004147, loss_test: 0.005500
time: 0.2510552406311035
time: 2.265084981918335
[1, 26868] loss_train: 0.009244, loss_test: 0.005497
time: 0.25606226921081543
time: 2.2649364471435547
[1, 26869] loss_train: 0.006666, loss_test: 0.005497
time: 0.25305604934692383
time: 2.3036322593688965
[1, 26870] loss_train: 0.015902, loss_test: 0.005498
time: 0.2890646457672119
time: 2.311519145965576
[1, 26871] loss_train: 0.008984, loss_test: 0.005502
time: 0.24505400657653809
time: 2.3534963130950928
[1, 26872] loss_train: 0.010103, loss_test: 0.005509
time: 0.25305676460266113
time: 2.2925124168395996
[1, 26873] loss_train: 0.003390, loss_test: 0.005515
time: 0.24605488777160645
time: 2.2775092124938965
[1, 26874] loss_train: 0.005214, loss_test: 0.005520
time: 0.24605417251586914
time: 2.2405006885528564
[1, 26875] loss_train: 0.005146, loss_test: 0.005521
time: 0.24805498123168945
time: 2.2545039653778076
[1, 26876] loss_train: 0.006182, loss_test: 0.005519
time: 0.254056453704834
time: 2.271507978439331
[1, 26877] loss_train: 0.001993, loss_test: 0.005515
time: 0.2580573558807373
time: 2.261024236679077
[1, 26878] loss_train: 0.005420, loss_test: 0.005511
time: 0.2450547218322754
time: 2.274508237838745
[1, 26879] loss_train: 0.002002, loss_test: 0.005506
time: 0.26105785369873047
time: 2.240510940551758
[1, 26880] loss_train: 0.005622, loss_test: 0.005504
time: 0.2590775489807129
time: 2.255509376525879
[1, 26881] loss_train: 0.012392, loss_test: 0.005504
time: 0.26105785369873047
time: 2.2495036125183105
[1, 26882] loss_train: 0.007863, loss_test: 0.005507
time: 0.2470541000366211
time: 2.237072467803955
[1, 26883] loss_train: 0.004309, loss_test: 0.005511
time: 0.26405858993530273
time: 2.2505035400390625
[1, 26884] loss_train: 0.002668, loss_test: 0.005516
time: 0.2470545768737793
time: 2.2355003356933594
[1, 26885] loss_train: 0.007515, loss_test: 0.005516
time: 0.25005507469177246
time: 2.2885143756866455
[1, 26886] loss_train: 0.008631, loss_test: 0.005513
time: 0.28106260299682617
time: 2.3895342350006104
[1, 26887] loss_train: 0.000671, loss_test: 0.005512
time: 0.28806376457214355
time: 2.4305458068847656
[1, 26888] loss_train: 0.011200, loss_test: 0.005509
time: 0.2585415840148926
time: 2.3515284061431885
[1, 26889] loss_train: 0.001445, loss_test: 0.005508
time: 0.2560560703277588
time: 2.2194976806640625
[1, 26890] loss_train: 0.008640, loss_test: 0.005506
time: 0.2670598030090332
time: 2.2314984798431396
[1, 26891] loss_train: 0.005962, loss_test: 0.005502
time: 0.2470552921295166
time: 2.2284979820251465
[1, 26892] loss_train: 0.000891, loss_test: 0.005502
time: 0.25305676460266113
time: 2.2445013523101807
[1, 26893] loss_train: 0.004031, loss_test: 0.005501
time: 0.2470557689666748
time: 2.234067440032959
[1, 26894] loss_train: 0.005423, loss_test: 0.005502
time: 0.2540557384490967
time: 2.2745089530944824
[1, 26895] loss_train: 0.005506, loss_test: 0.005503
time: 0.2510550022125244
time: 2.2495038509368896
[1, 26896] loss_train: 0.004662, loss_test: 0.005506
time: 0.2520561218261719
time: 2.238499879837036
[1, 26897] loss_train: 0.004900, loss_test: 0.005508
time: 0.2490541934967041
time: 2.2655069828033447
[1, 26898] loss_train: 0.010373, loss_test: 0.005509
time: 0.2540581226348877
time: 2.2354986667633057
[1, 26899] loss_train: 0.007649, loss_test: 0.005506
time: 0.2490556240081787
time: 2.2495028972625732
[1, 26900] loss_train: 0.006991, loss_test: 0.005502
time: 0.2650582790374756
time: 2.2465035915374756
[1, 26901] loss_train: 0.006597, loss_test: 0.005497
time: 0.24805402755737305
time: 2.23850154876709
[1, 26902] loss_train: 0.005236, loss_test: 0.005498
time: 0.25905799865722656
time: 2.234504222869873
[1, 26903] loss_train: 0.006207, loss_test: 0.005503
time: 0.2470552921295166
time: 2.207493305206299
[1, 26904] loss_train: 0.005641, loss_test: 0.005501
time: 0.252056360244751
time: 2.3515257835388184
[1, 26905] loss_train: 0.007487, loss_test: 0.005499
time: 0.2600569725036621
time: 2.2435035705566406
[1, 26906] loss_train: 0.005159, loss_test: 0.005496
time: 0.2580580711364746
time: 2.2395005226135254
[1, 26907] loss_train: 0.004577, loss_test: 0.005493
time: 0.24805474281311035
time: 2.2154958248138428
[1, 26908] loss_train: 0.002755, loss_test: 0.005492
time: 0.2540566921234131
time: 2.2395002841949463
[1, 26909] loss_train: 0.008174, loss_test: 0.005492
time: 0.2470541000366211
time: 2.256505250930786
[1, 26910] loss_train: 0.011434, loss_test: 0.005492
time: 0.27005982398986816
time: 2.227499008178711
[1, 26911] loss_train: 0.005578, loss_test: 0.005492
time: 0.2470545768737793
time: 2.2455050945281982
[1, 26912] loss_train: 0.004414, loss_test: 0.005492
time: 0.25305604934692383
time: 2.231499671936035
[1, 26913] loss_train: 0.002362, loss_test: 0.005493
time: 0.2470543384552002
time: 2.2570085525512695
[1, 26914] loss_train: 0.005694, loss_test: 0.005496
time: 0.2620573043823242
time: 2.220496416091919
[1, 26915] loss_train: 0.009875, loss_test: 0.005499
time: 0.24605488777160645
time: 2.2375009059906006
[1, 26916] loss_train: 0.006282, loss_test: 0.005501
time: 0.25005507469177246
time: 2.2725183963775635
[1, 26917] loss_train: 0.000591, loss_test: 0.005504
time: 0.2470550537109375
time: 2.2495129108428955
[1, 26918] loss_train: 0.004671, loss_test: 0.005505
time: 0.2600574493408203
time: 2.2465031147003174
[1, 26919] loss_train: 0.003579, loss_test: 0.005505
time: 0.2470550537109375
time: 2.235499858856201
[1, 26920] loss_train: 0.021960, loss_test: 0.005505
time: 0.26605987548828125
time: 2.250502586364746
[1, 26921] loss_train: 0.005431, loss_test: 0.005506
time: 0.25305604934692383
time: 2.255007743835449
[1, 26922] loss_train: 0.000896, loss_test: 0.005510
time: 0.26357150077819824
time: 2.2365002632141113
[1, 26923] loss_train: 0.010340, loss_test: 0.005512
time: 0.25005507469177246
time: 2.241501569747925
[1, 26924] loss_train: 0.002492, loss_test: 0.005515
time: 0.252056360244751
time: 2.2375001907348633
[1, 26925] loss_train: 0.003944, loss_test: 0.005518
time: 0.24805450439453125
time: 2.2575056552886963
[1, 26926] loss_train: 0.004206, loss_test: 0.005514
time: 0.25705695152282715
time: 2.2545042037963867
[1, 26927] loss_train: 0.005002, loss_test: 0.005513
time: 0.2490553855895996
time: 2.2375001907348633
[1, 26928] loss_train: 0.009612, loss_test: 0.005507
time: 0.25305628776550293
time: 2.2545042037963867
[1, 26929] loss_train: 0.012623, loss_test: 0.005498
time: 0.2470548152923584
time: 2.230498790740967
[1, 26930] loss_train: 0.004907, loss_test: 0.005488
time: 0.27306079864501953
time: 2.244501829147339
[1, 26931] loss_train: 0.007370, loss_test: 0.005483
time: 0.24805474281311035
time: 2.2335000038146973
[1, 26932] loss_train: 0.014540, loss_test: 0.005481
time: 0.2520558834075928
time: 2.2655084133148193
[1, 26933] loss_train: 0.002713, loss_test: 0.005481
time: 0.2470557689666748
time: 2.258504629135132
[1, 26934] loss_train: 0.005079, loss_test: 0.005484
time: 0.2540566921234131
time: 2.249502658843994
[1, 26935] loss_train: 0.005780, loss_test: 0.005489
time: 0.24805474281311035
time: 2.231504440307617
[1, 26936] loss_train: 0.009785, loss_test: 0.005496
time: 0.25205540657043457
time: 2.2565090656280518
[1, 26937] loss_train: 0.002719, loss_test: 0.005504
time: 0.24805593490600586
time: 2.2565042972564697
[1, 26938] loss_train: 0.000979, loss_test: 0.005514
time: 0.25305914878845215
time: 2.230498790740967
[1, 26939] loss_train: 0.010381, loss_test: 0.005527
time: 0.2470550537109375
time: 2.222496747970581
[1, 26940] loss_train: 0.005265, loss_test: 0.005533
time: 0.27306079864501953
time: 2.2415032386779785
[1, 26941] loss_train: 0.002682, loss_test: 0.005534
time: 0.2490558624267578
time: 2.2295002937316895
[1, 26942] loss_train: 0.001907, loss_test: 0.005535
time: 0.2510561943054199
time: 2.234499454498291
[1, 26943] loss_train: 0.002561, loss_test: 0.005537
time: 0.24605798721313477
time: 2.2455036640167236
[1, 26944] loss_train: 0.007222, loss_test: 0.005540
time: 0.2600574493408203
time: 2.257505178451538
[1, 26945] loss_train: 0.004573, loss_test: 0.005542
time: 0.2470548152923584
time: 2.2605087757110596
[1, 26946] loss_train: 0.001404, loss_test: 0.005544
time: 0.25505638122558594
time: 2.2415013313293457
[1, 26947] loss_train: 0.012174, loss_test: 0.005543
time: 0.2477123737335205
time: 2.2395007610321045
[1, 26948] loss_train: 0.001989, loss_test: 0.005541
time: 0.25005531311035156
time: 2.235520601272583
[1, 26949] loss_train: 0.004883, loss_test: 0.005538
time: 0.2475581169128418
time: 2.227498769760132
[1, 26950] loss_train: 0.003089, loss_test: 0.005536
time: 0.26205873489379883
time: 2.234499216079712
[1, 26951] loss_train: 0.008605, loss_test: 0.005527
time: 0.24805450439453125
time: 2.2254996299743652
[1, 26952] loss_train: 0.011012, loss_test: 0.005516
time: 0.2490551471710205
time: 2.2104952335357666
[1, 26953] loss_train: 0.002945, loss_test: 0.005510
time: 0.2490544319152832
time: 2.2350056171417236
[1, 26954] loss_train: 0.008637, loss_test: 0.005504
time: 0.2490558624267578
time: 2.2645058631896973
[1, 26955] loss_train: 0.006192, loss_test: 0.005501
time: 0.2470552921295166
time: 2.2344987392425537
[1, 26956] loss_train: 0.001555, loss_test: 0.005502
time: 0.2490556240081787
time: 2.2244975566864014
[1, 26957] loss_train: 0.004845, loss_test: 0.005505
time: 0.251056432723999
time: 2.2264978885650635
[1, 26958] loss_train: 0.003981, loss_test: 0.005510
time: 0.25205516815185547
time: 2.2405014038085938
[1, 26959] loss_train: 0.003353, loss_test: 0.005516
time: 0.24605464935302734
time: 2.2395026683807373
[1, 26960] loss_train: 0.000802, loss_test: 0.005524
time: 0.2630586624145508
time: 2.2274980545043945
[1, 26961] loss_train: 0.002067, loss_test: 0.005533
time: 0.25005602836608887
time: 2.212494373321533
[1, 26962] loss_train: 0.004865, loss_test: 0.005540
time: 0.24805474281311035
time: 2.2264983654022217
[1, 26963] loss_train: 0.008195, loss_test: 0.005543
time: 0.2470552921295166
time: 2.235499620437622
[1, 26964] loss_train: 0.001831, loss_test: 0.005544
time: 0.2470550537109375
time: 2.243501901626587
[1, 26965] loss_train: 0.003847, loss_test: 0.005546
time: 0.2490549087524414
time: 2.219496011734009
[1, 26966] loss_train: 0.003038, loss_test: 0.005546
time: 0.2470533847808838
time: 2.2224979400634766
[1, 26967] loss_train: 0.001933, loss_test: 0.005544
time: 0.2470545768737793
time: 2.252504348754883
[1, 26968] loss_train: 0.013492, loss_test: 0.005539
time: 0.24805521965026855
time: 2.2515034675598145
[1, 26969] loss_train: 0.003900, loss_test: 0.005534
time: 0.24806714057922363
time: 2.217496156692505
[1, 26970] loss_train: 0.013785, loss_test: 0.005514
time: 0.26105761528015137
time: 2.2625067234039307
[1, 26971] loss_train: 0.004721, loss_test: 0.005505
time: 0.2470545768737793
time: 2.2435033321380615
[1, 26972] loss_train: 0.011259, loss_test: 0.005506
time: 0.24805545806884766
time: 2.2164955139160156
[1, 26973] loss_train: 0.003798, loss_test: 0.005520
time: 0.25305652618408203
time: 2.2425014972686768
[1, 26974] loss_train: 0.007228, loss_test: 0.005540
time: 0.2510557174682617
time: 2.2535040378570557
[1, 26975] loss_train: 0.007689, loss_test: 0.005560
time: 0.2520565986633301
time: 2.2285001277923584
[1, 26976] loss_train: 0.005173, loss_test: 0.005580
time: 0.24805545806884766
time: 2.231498956680298
[1, 26977] loss_train: 0.010148, loss_test: 0.005600
time: 0.2520558834075928
time: 2.224501371383667
[1, 26978] loss_train: 0.003921, loss_test: 0.005596
time: 0.2490558624267578
time: 2.2455480098724365
[1, 26979] loss_train: 0.007192, loss_test: 0.005576
time: 0.25305652618408203
time: 2.2375032901763916
[1, 26980] loss_train: 0.006271, loss_test: 0.005546
time: 0.2600572109222412
time: 2.240501642227173
[1, 26981] loss_train: 0.003976, loss_test: 0.005519
time: 0.2530558109283447
time: 2.2505035400390625
[1, 26982] loss_train: 0.013378, loss_test: 0.005510
time: 0.24605417251586914
time: 2.226498603820801
[1, 26983] loss_train: 0.004626, loss_test: 0.005517
time: 0.254056453704834
time: 2.2645063400268555
[1, 26984] loss_train: 0.007277, loss_test: 0.005531
time: 0.24905610084533691
time: 2.2314977645874023
[1, 26985] loss_train: 0.007290, loss_test: 0.005541
time: 0.2510547637939453
time: 2.2475032806396484
[1, 26986] loss_train: 0.002940, loss_test: 0.005552
time: 0.2470545768737793
time: 2.257505416870117
[1, 26987] loss_train: 0.002704, loss_test: 0.005563
time: 0.2530555725097656
time: 2.2254998683929443
[1, 26988] loss_train: 0.004999, loss_test: 0.005572
time: 0.24605536460876465
time: 2.2455008029937744
[1, 26989] loss_train: 0.008999, loss_test: 0.005577
time: 0.24805426597595215
time: 2.240504264831543
[1, 26990] loss_train: 0.017025, loss_test: 0.005577
time: 0.2580568790435791
time: 2.2585055828094482
[1, 26991] loss_train: 0.004924, loss_test: 0.005574
time: 0.25005578994750977
time: 2.2314987182617188
[1, 26992] loss_train: 0.006160, loss_test: 0.005567
time: 0.24805617332458496
time: 2.2275002002716064
[1, 26993] loss_train: 0.010291, loss_test: 0.005547
time: 0.24805474281311035
time: 2.2725090980529785
[1, 26994] loss_train: 0.005504, loss_test: 0.005533
time: 0.24805521965026855
time: 2.2214977741241455
[1, 26995] loss_train: 0.006966, loss_test: 0.005523
time: 0.2470550537109375
time: 2.2545039653778076
[1, 26996] loss_train: 0.002659, loss_test: 0.005518
time: 0.24805521965026855
time: 2.2405011653900146
[1, 26997] loss_train: 0.003289, loss_test: 0.005515
time: 0.25005578994750977
time: 2.2515034675598145
[1, 26998] loss_train: 0.003518, loss_test: 0.005512
time: 0.2470548152923584
time: 2.260507822036743
[1, 26999] loss_train: 0.005694, loss_test: 0.005511
time: 0.24805521965026855
time: 2.2385048866271973
[1, 27000] loss_train: 0.002108, loss_test: 0.005510
time: 0.2610585689544678
time: 2.2495028972625732
[1, 27001] loss_train: 0.005859, loss_test: 0.005510
time: 0.24805474281311035
time: 2.242501735687256
[1, 27002] loss_train: 0.014204, loss_test: 0.005511
time: 0.2470555305480957
time: 2.276611328125
[1, 27003] loss_train: 0.001573, loss_test: 0.005511
time: 0.25005531311035156
time: 2.2255008220672607
[1, 27004] loss_train: 0.014466, loss_test: 0.005515
time: 0.24805545806884766
time: 2.2635037899017334
[1, 27005] loss_train: 0.004900, loss_test: 0.005514
time: 0.2470543384552002
time: 2.230499744415283
[1, 27006] loss_train: 0.009968, loss_test: 0.005511
time: 0.24805593490600586
time: 2.261505365371704
[1, 27007] loss_train: 0.008260, loss_test: 0.005510
time: 0.24605417251586914
time: 2.2485053539276123
[1, 27008] loss_train: 0.001474, loss_test: 0.005508
time: 0.2470555305480957
time: 2.2375004291534424
[1, 27009] loss_train: 0.001674, loss_test: 0.005510
time: 0.24805545806884766
time: 2.2284982204437256
[1, 27010] loss_train: 0.004328, loss_test: 0.005516
time: 0.2580575942993164
time: 2.271507978439331
[1, 27011] loss_train: 0.000710, loss_test: 0.005527
time: 0.24805521965026855
time: 2.235499620437622
[1, 27012] loss_train: 0.005733, loss_test: 0.005539
time: 0.2470550537109375
time: 2.2295000553131104
[1, 27013] loss_train: 0.003012, loss_test: 0.005555
time: 0.24805521965026855
time: 2.2425026893615723
[1, 27014] loss_train: 0.003874, loss_test: 0.005564
time: 0.2468724250793457
time: 2.255505084991455
[1, 27015] loss_train: 0.005557, loss_test: 0.005570
time: 0.24605345726013184
time: 2.2505037784576416
[1, 27016] loss_train: 0.008088, loss_test: 0.005570
time: 0.2470548152923584
time: 2.2385010719299316
[1, 27017] loss_train: 0.016391, loss_test: 0.005557
time: 0.24805474281311035
time: 2.2475032806396484
[1, 27018] loss_train: 0.009842, loss_test: 0.005542
time: 0.24605417251586914
time: 2.2375149726867676
[1, 27019] loss_train: 0.009092, loss_test: 0.005531
time: 0.2470548152923584
time: 2.257505178451538
[1, 27020] loss_train: 0.002785, loss_test: 0.005526
time: 0.2600579261779785
time: 2.296513080596924
[1, 27021] loss_train: 0.003338, loss_test: 0.005520
time: 0.25505709648132324
time: 2.2809433937072754
[1, 27022] loss_train: 0.009474, loss_test: 0.005517
time: 0.25005602836608887
time: 2.2905125617980957
[1, 27023] loss_train: 0.000788, loss_test: 0.005518
time: 0.24805450439453125
time: 2.242502212524414
[1, 27024] loss_train: 0.006386, loss_test: 0.005521
time: 0.25205564498901367
time: 2.2264983654022217
[1, 27025] loss_train: 0.006234, loss_test: 0.005521
time: 0.2470557689666748
time: 2.223496675491333
[1, 27026] loss_train: 0.002390, loss_test: 0.005522
time: 0.2470548152923584
time: 2.2485127449035645
[1, 27027] loss_train: 0.014357, loss_test: 0.005521
time: 0.2490549087524414
time: 2.269320487976074
[1, 27028] loss_train: 0.007431, loss_test: 0.005519
time: 0.25205492973327637
time: 2.229499578475952
[1, 27029] loss_train: 0.004285, loss_test: 0.005515
time: 0.2470552921295166
time: 2.231499433517456
[1, 27030] loss_train: 0.008744, loss_test: 0.005511
time: 0.2600574493408203
time: 2.255504846572876
[1, 27031] loss_train: 0.008990, loss_test: 0.005509
time: 0.2540559768676758
time: 2.2485032081604004
[1, 27032] loss_train: 0.004000, loss_test: 0.005507
time: 0.2525820732116699
time: 2.2405009269714355
[1, 27033] loss_train: 0.005469, loss_test: 0.005505
time: 0.2470543384552002
time: 2.2224972248077393
[1, 27034] loss_train: 0.005725, loss_test: 0.005504
time: 0.2470548152923584
time: 2.2735085487365723
[1, 27035] loss_train: 0.009843, loss_test: 0.005503
time: 0.24805593490600586
time: 2.244502544403076
[1, 27036] loss_train: 0.009588, loss_test: 0.005505
time: 0.2490551471710205
time: 2.223497152328491
[1, 27037] loss_train: 0.007289, loss_test: 0.005508
time: 0.24805665016174316
time: 2.233267307281494
[1, 27038] loss_train: 0.002539, loss_test: 0.005510
time: 0.247053861618042
time: 2.2375011444091797
[1, 27039] loss_train: 0.005727, loss_test: 0.005513
time: 0.2470545768737793
time: 2.230499505996704
[1, 27040] loss_train: 0.005487, loss_test: 0.005517
time: 0.2650587558746338
time: 2.2445011138916016
[1, 27041] loss_train: 0.002402, loss_test: 0.005521
time: 0.24805617332458496
time: 2.2264978885650635
[1, 27042] loss_train: 0.008221, loss_test: 0.005526
time: 0.24605464935302734
time: 2.2274982929229736
[1, 27043] loss_train: 0.003868, loss_test: 0.005531
time: 0.24605441093444824
time: 2.2274982929229736
[1, 27044] loss_train: 0.006720, loss_test: 0.005536
time: 0.25305604934692383
time: 2.2475030422210693
[1, 27045] loss_train: 0.006868, loss_test: 0.005538
time: 0.2470550537109375
time: 2.2134947776794434
[1, 27046] loss_train: 0.003694, loss_test: 0.005541
time: 0.2470548152923584
time: 2.2505033016204834
[1, 27047] loss_train: 0.013467, loss_test: 0.005542
time: 0.24805521965026855
time: 2.2425036430358887
[1, 27048] loss_train: 0.001555, loss_test: 0.005544
time: 0.25505614280700684
time: 2.228499412536621
[1, 27049] loss_train: 0.019270, loss_test: 0.005536
time: 0.2470543384552002
time: 2.228498935699463
[1, 27050] loss_train: 0.006406, loss_test: 0.005530
time: 0.25905776023864746
time: 2.2385003566741943
[1, 27051] loss_train: 0.009331, loss_test: 0.005528
time: 0.2470550537109375
time: 2.22249698638916
[1, 27052] loss_train: 0.008124, loss_test: 0.005530
time: 0.2540557384490967
time: 2.2495057582855225
[1, 27053] loss_train: 0.008229, loss_test: 0.005535
time: 0.24805545806884766
time: 2.243501663208008
[1, 27054] loss_train: 0.005870, loss_test: 0.005540
time: 0.2540566921234131
time: 2.2415013313293457
[1, 27055] loss_train: 0.008596, loss_test: 0.005548
time: 0.24805569648742676
time: 2.2275002002716064
[1, 27056] loss_train: 0.005711, loss_test: 0.005552
time: 0.2600574493408203
time: 2.25650691986084
[1, 27057] loss_train: 0.006007, loss_test: 0.005550
time: 0.24805474281311035
time: 2.243502378463745
[1, 27058] loss_train: 0.007560, loss_test: 0.005547
time: 0.2540557384490967
time: 2.2345023155212402
[1, 27059] loss_train: 0.002482, loss_test: 0.005537
time: 0.24805521965026855
time: 2.232499599456787
[1, 27060] loss_train: 0.012497, loss_test: 0.005525
time: 0.2700619697570801
time: 2.2355003356933594
[1, 27061] loss_train: 0.004708, loss_test: 0.005514
time: 0.2490553855895996
time: 2.21049427986145
[1, 27062] loss_train: 0.006384, loss_test: 0.005507
time: 0.2510557174682617
time: 2.247502326965332
[1, 27063] loss_train: 0.008323, loss_test: 0.005504
time: 0.24805521965026855
time: 2.2425014972686768
[1, 27064] loss_train: 0.008067, loss_test: 0.005505
time: 0.2580580711364746
time: 2.246502161026001
[1, 27065] loss_train: 0.004627, loss_test: 0.005508
time: 0.24805521965026855
time: 2.2525060176849365
[1, 27066] loss_train: 0.004429, loss_test: 0.005513
time: 0.2490549087524414
time: 2.2375009059906006
[1, 27067] loss_train: 0.001917, loss_test: 0.005518
time: 0.2470543384552002
time: 2.253507375717163
[1, 27068] loss_train: 0.005027, loss_test: 0.005522
time: 0.25305652618408203
time: 2.249502658843994
[1, 27069] loss_train: 0.005644, loss_test: 0.005526
time: 0.24805521965026855
time: 2.242501735687256
[1, 27070] loss_train: 0.002308, loss_test: 0.005531
time: 0.2650582790374756
time: 2.2495038509368896
[1, 27071] loss_train: 0.000846, loss_test: 0.005538
time: 0.2470543384552002
time: 2.23551082611084
[1, 27072] loss_train: 0.004438, loss_test: 0.005545
time: 0.2500572204589844
time: 2.259505033493042
[1, 27073] loss_train: 0.010588, loss_test: 0.005547
time: 0.24805450439453125
time: 2.229499101638794
[1, 27074] loss_train: 0.000751, loss_test: 0.005551
time: 0.25305628776550293
time: 2.2244975566864014
[1, 27075] loss_train: 0.003853, loss_test: 0.005556
time: 0.24805521965026855
time: 2.2485053539276123
[1, 27076] loss_train: 0.002915, loss_test: 0.005562
time: 0.2490558624267578
time: 2.246501922607422
[1, 27077] loss_train: 0.006675, loss_test: 0.005563
time: 0.24605488777160645
time: 2.231499671936035
[1, 27078] loss_train: 0.005997, loss_test: 0.005559
time: 0.2470550537109375
time: 2.243501663208008
[1, 27079] loss_train: 0.005217, loss_test: 0.005557
time: 0.25005507469177246
time: 2.2527151107788086
[1, 27080] loss_train: 0.009925, loss_test: 0.005553
time: 0.25705790519714355
time: 2.221497058868408
[1, 27081] loss_train: 0.015616, loss_test: 0.005543
time: 0.24805617332458496
time: 2.235499858856201
[1, 27082] loss_train: 0.005038, loss_test: 0.005536
time: 0.2470564842224121
time: 2.235499858856201
[1, 27083] loss_train: 0.005387, loss_test: 0.005530
time: 0.2510552406311035
time: 2.2204971313476562
[1, 27084] loss_train: 0.003769, loss_test: 0.005528
time: 0.24805521965026855
time: 2.2415032386779785
[1, 27085] loss_train: 0.011742, loss_test: 0.005531
time: 0.2510550022125244
time: 2.22649884223938
[1, 27086] loss_train: 0.014760, loss_test: 0.005535
time: 0.24805474281311035
time: 2.2355000972747803
[1, 27087] loss_train: 0.006593, loss_test: 0.005537
time: 0.25305628776550293
time: 2.2655067443847656
[1, 27088] loss_train: 0.000640, loss_test: 0.005540
time: 0.2470543384552002
time: 2.228498697280884
[1, 27089] loss_train: 0.008567, loss_test: 0.005543
time: 0.25005578994750977
time: 2.2395009994506836
[1, 27090] loss_train: 0.010387, loss_test: 0.005545
time: 0.2600576877593994
time: 2.271507740020752
[1, 27091] loss_train: 0.007533, loss_test: 0.005544
time: 0.251056432723999
time: 2.2294998168945312
[1, 27092] loss_train: 0.006528, loss_test: 0.005544
time: 0.2470552921295166
time: 2.248502731323242
[1, 27093] loss_train: 0.006792, loss_test: 0.005542
time: 0.2490551471710205
time: 2.215496063232422
[1, 27094] loss_train: 0.006876, loss_test: 0.005540
time: 0.2470550537109375
time: 2.224496841430664
[1, 27095] loss_train: 0.007965, loss_test: 0.005538
time: 0.254056453704834
time: 2.231499433517456
[1, 27096] loss_train: 0.007729, loss_test: 0.005535
time: 0.24805450439453125
time: 2.2455027103424072
[1, 27097] loss_train: 0.005115, loss_test: 0.005529
time: 0.2470548152923584
time: 2.2395009994506836
[1, 27098] loss_train: 0.002234, loss_test: 0.005518
time: 0.24805450439453125
time: 2.2345004081726074
[1, 27099] loss_train: 0.008928, loss_test: 0.005511
time: 0.2560567855834961
time: 2.256504774093628
[1, 27100] loss_train: 0.009471, loss_test: 0.005508
time: 0.2650585174560547
time: 2.2355005741119385
[1, 27101] loss_train: 0.001644, loss_test: 0.005504
time: 0.24805474281311035
time: 2.2345001697540283
[1, 27102] loss_train: 0.002209, loss_test: 0.005502
time: 0.2470555305480957
time: 2.2535040378570557
[1, 27103] loss_train: 0.003536, loss_test: 0.005502
time: 0.2510561943054199
time: 2.2254977226257324
[1, 27104] loss_train: 0.003736, loss_test: 0.005507
time: 0.24605512619018555
time: 2.22249698638916
[1, 27105] loss_train: 0.009621, loss_test: 0.005511
time: 0.2490556240081787
time: 2.215010404586792
[1, 27106] loss_train: 0.008425, loss_test: 0.005516
time: 0.24605488777160645
time: 2.237499952316284
[1, 27107] loss_train: 0.007399, loss_test: 0.005518
time: 0.25905776023864746
time: 2.221496343612671
[1, 27108] loss_train: 0.008141, loss_test: 0.005517
time: 0.2470555305480957
time: 2.2314987182617188
[1, 27109] loss_train: 0.004402, loss_test: 0.005515
time: 0.2520558834075928
time: 2.2375009059906006
[1, 27110] loss_train: 0.002007, loss_test: 0.005515
time: 0.2580568790435791
time: 2.236499786376953
[1, 27111] loss_train: 0.005466, loss_test: 0.005516
time: 0.2600586414337158
time: 2.2375004291534424
[1, 27112] loss_train: 0.007527, loss_test: 0.005512
time: 0.24605488777160645
time: 2.2515034675598145
[1, 27113] loss_train: 0.010729, loss_test: 0.005499
time: 0.2510561943054199
time: 2.2405004501342773
[1, 27114] loss_train: 0.003356, loss_test: 0.005492
time: 0.2560570240020752
time: 2.2264978885650635
[1, 27115] loss_train: 0.004485, loss_test: 0.005489
time: 0.25505685806274414
time: 2.256504774093628
[1, 27116] loss_train: 0.006379, loss_test: 0.005488
time: 0.24605464935302734
time: 2.2330031394958496
[1, 27117] loss_train: 0.002309, loss_test: 0.005489
time: 0.25005578994750977
time: 2.2144951820373535
[1, 27118] loss_train: 0.002834, loss_test: 0.005489
time: 0.24605464935302734
time: 2.2395172119140625
[1, 27119] loss_train: 0.005887, loss_test: 0.005491
time: 0.2470545768737793
time: 2.2284984588623047
[1, 27120] loss_train: 0.003657, loss_test: 0.005493
time: 0.25905799865722656
time: 2.4805541038513184
[1, 27121] loss_train: 0.000960, loss_test: 0.005494
time: 0.25005531311035156
time: 2.32051944732666
[1, 27122] loss_train: 0.001907, loss_test: 0.005497
time: 0.24405455589294434
time: 2.257411479949951
[1, 27123] loss_train: 0.008245, loss_test: 0.005499
time: 0.24805593490600586
time: 2.257507562637329
[1, 27124] loss_train: 0.007489, loss_test: 0.005501
time: 0.24405360221862793
time: 2.2745091915130615
[1, 27125] loss_train: 0.009567, loss_test: 0.005503
time: 0.2490549087524414
time: 2.317518711090088
[1, 27126] loss_train: 0.007238, loss_test: 0.005505
time: 0.2470548152923584
time: 2.3155181407928467
[1, 27127] loss_train: 0.002499, loss_test: 0.005508
time: 0.25305604934692383
time: 2.3850817680358887
[1, 27128] loss_train: 0.007577, loss_test: 0.005511
time: 0.263059139251709
time: 2.322521448135376
[1, 27129] loss_train: 0.008446, loss_test: 0.005512
time: 0.2520558834075928
time: 2.4005372524261475
[1, 27130] loss_train: 0.006212, loss_test: 0.005513
time: 0.2600576877593994
time: 2.399536371231079
[1, 27131] loss_train: 0.010014, loss_test: 0.005511
time: 0.24605441093444824
time: 2.2905116081237793
[1, 27132] loss_train: 0.003023, loss_test: 0.005511
time: 0.283062219619751
time: 2.493557929992676
[1, 27133] loss_train: 0.008564, loss_test: 0.005509
time: 0.2650597095489502
time: 2.3005144596099854
[1, 27134] loss_train: 0.004767, loss_test: 0.005510
time: 0.24505400657653809
time: 2.307518482208252
[1, 27135] loss_train: 0.009578, loss_test: 0.005510
time: 0.24605512619018555
time: 2.336521863937378
[1, 27136] loss_train: 0.005473, loss_test: 0.005512
time: 0.24405479431152344
time: 2.3095152378082275
[1, 27137] loss_train: 0.002196, loss_test: 0.005514
time: 0.27106142044067383
time: 2.2435009479522705
[1, 27138] loss_train: 0.002551, loss_test: 0.005518
time: 0.26405906677246094
time: 2.399538278579712
[1, 27139] loss_train: 0.002208, loss_test: 0.005522
time: 0.2740604877471924
time: 2.3645288944244385
[1, 27140] loss_train: 0.012436, loss_test: 0.005518
time: 0.25705718994140625
time: 2.385533094406128
[1, 27141] loss_train: 0.002396, loss_test: 0.005518
time: 0.24405384063720703
time: 2.3959107398986816
[1, 27142] loss_train: 0.005620, loss_test: 0.005519
time: 0.2740614414215088
time: 2.461550235748291
[1, 27143] loss_train: 0.003770, loss_test: 0.005521
time: 0.24205422401428223
time: 2.3405230045318604
[1, 27144] loss_train: 0.000875, loss_test: 0.005524
time: 0.252056360244751
time: 2.6056971549987793
[1, 27145] loss_train: 0.013527, loss_test: 0.005525
time: 0.3130683898925781
time: 2.5112006664276123
[1, 27146] loss_train: 0.001917, loss_test: 0.005529
time: 0.27506089210510254
time: 2.4651100635528564
[1, 27147] loss_train: 0.005837, loss_test: 0.005532
time: 0.4168572425842285
time: 2.457549810409546
[1, 27148] loss_train: 0.003330, loss_test: 0.005534
time: 0.2870633602142334
time: 2.466068983078003
[1, 27149] loss_train: 0.004934, loss_test: 0.005533
time: 0.2780616283416748
time: 2.490556478500366
[1, 27150] loss_train: 0.012417, loss_test: 0.005532
time: 0.3000669479370117
time: 2.4535489082336426
[1, 27151] loss_train: 0.000454, loss_test: 0.005534
time: 0.27572083473205566
time: 2.4182050228118896
[1, 27152] loss_train: 0.001852, loss_test: 0.005536
time: 0.2725648880004883
time: 2.468332052230835
[1, 27153] loss_train: 0.005049, loss_test: 0.005538
time: 0.2720603942871094
time: 2.4140119552612305
[1, 27154] loss_train: 0.007467, loss_test: 0.005535
time: 0.27506136894226074
time: 2.4350693225860596
[1, 27155] loss_train: 0.007840, loss_test: 0.005522
time: 0.28206324577331543
time: 2.5028181076049805
[1, 27156] loss_train: 0.005315, loss_test: 0.005511
time: 0.28106236457824707
time: 2.556570053100586
[1, 27157] loss_train: 0.007377, loss_test: 0.005501
time: 0.2865724563598633
time: 2.4716689586639404
[1, 27158] loss_train: 0.008548, loss_test: 0.005495
time: 0.2730600833892822
time: 2.4443016052246094
[1, 27159] loss_train: 0.004967, loss_test: 0.005495
time: 0.2470550537109375
time: 2.393537759780884
[1, 27160] loss_train: 0.004249, loss_test: 0.005500
time: 0.2910640239715576
time: 2.4965732097625732
[1, 27161] loss_train: 0.007778, loss_test: 0.005508
time: 0.2800633907318115
time: 2.5465030670166016
[1, 27162] loss_train: 0.004420, loss_test: 0.005515
time: 0.31056737899780273
time: 2.525709867477417
[1, 27163] loss_train: 0.008113, loss_test: 0.005522
time: 0.27828264236450195
time: 2.492555618286133
[1, 27164] loss_train: 0.013491, loss_test: 0.005525
time: 0.28406286239624023
time: 2.492565631866455
[1, 27165] loss_train: 0.009010, loss_test: 0.005522
time: 0.28406286239624023
time: 2.4881389141082764
[1, 27166] loss_train: 0.004494, loss_test: 0.005513
time: 0.27906179428100586
time: 2.472553014755249
[1, 27167] loss_train: 0.005892, loss_test: 0.005507
time: 0.2910642623901367
time: 2.585155725479126
[1, 27168] loss_train: 0.001952, loss_test: 0.005503
time: 0.2890632152557373
time: 2.5090701580047607
[1, 27169] loss_train: 0.004240, loss_test: 0.005505
time: 0.2920646667480469
time: 2.507652759552002
[1, 27170] loss_train: 0.001707, loss_test: 0.005514
time: 0.3000674247741699
time: 2.6145894527435303
[1, 27171] loss_train: 0.005154, loss_test: 0.005527
time: 0.28606271743774414
time: 2.429544448852539
[1, 27172] loss_train: 0.008664, loss_test: 0.005536
time: 0.2760608196258545
time: 2.576723098754883
[1, 27173] loss_train: 0.005833, loss_test: 0.005543
time: 0.2830634117126465
time: 2.5065863132476807
[1, 27174] loss_train: 0.004289, loss_test: 0.005547
time: 0.28206682205200195
time: 2.5143237113952637
[1, 27175] loss_train: 0.001201, loss_test: 0.005553
time: 0.27506065368652344
time: 2.4515018463134766
[1, 27176] loss_train: 0.000727, loss_test: 0.005561
time: 0.282062292098999
time: 2.480560064315796
[1, 27177] loss_train: 0.009931, loss_test: 0.005562
time: 0.2850644588470459
time: 2.4705522060394287
[1, 27178] loss_train: 0.008966, loss_test: 0.005555
time: 0.2870638370513916
time: 2.4655535221099854
[1, 27179] loss_train: 0.004681, loss_test: 0.005549
time: 0.2760610580444336
time: 2.4515483379364014
[1, 27180] loss_train: 0.009802, loss_test: 0.005532
time: 0.3000662326812744
time: 2.4570558071136475
[1, 27181] loss_train: 0.007665, loss_test: 0.005514
time: 0.2765674591064453
time: 2.4791738986968994
[1, 27182] loss_train: 0.009719, loss_test: 0.005503
time: 0.27906274795532227
time: 2.460076332092285
[1, 27183] loss_train: 0.007871, loss_test: 0.005499
time: 0.29306483268737793
time: 2.5806429386138916
[1, 27184] loss_train: 0.005211, loss_test: 0.005500
time: 0.287064790725708
time: 2.664595365524292
[1, 27185] loss_train: 0.004624, loss_test: 0.005503
time: 0.29306459426879883
time: 2.536076784133911
[1, 27186] loss_train: 0.003441, loss_test: 0.005507
time: 0.27706074714660645
time: 2.47955584526062
[1, 27187] loss_train: 0.003379, loss_test: 0.005509
time: 0.28606367111206055
time: 2.534576177597046
[1, 27188] loss_train: 0.010475, loss_test: 0.005509
time: 0.42908644676208496
time: 2.6381003856658936
[1, 27189] loss_train: 0.003676, loss_test: 0.005508
time: 0.2877237796783447
time: 2.5261409282684326
[1, 27190] loss_train: 0.004219, loss_test: 0.005508
time: 0.30907559394836426
time: 2.448310375213623
[1, 27191] loss_train: 0.007995, loss_test: 0.005508
time: 0.2830629348754883
time: 2.550687313079834
[1, 27192] loss_train: 0.005076, loss_test: 0.005507
time: 0.27506256103515625
time: 2.5585598945617676
[1, 27193] loss_train: 0.006136, loss_test: 0.005508
time: 0.29506492614746094
time: 2.782639265060425
[1, 27194] loss_train: 0.013458, loss_test: 0.005510
time: 0.27707839012145996
time: 2.550955057144165
[1, 27195] loss_train: 0.004831, loss_test: 0.005513
time: 0.2825927734375
time: 2.5275650024414062
[1, 27196] loss_train: 0.001141, loss_test: 0.005517
time: 0.2850635051727295
time: 2.3055155277252197
[1, 27197] loss_train: 0.008738, loss_test: 0.005520
time: 0.258056640625
time: 2.378532886505127
[1, 27198] loss_train: 0.008950, loss_test: 0.005522
time: 0.29514360427856445
time: 2.455155372619629
[1, 27199] loss_train: 0.001929, loss_test: 0.005523
time: 0.2740604877471924
time: 2.4351181983947754
[1, 27200] loss_train: 0.002121, loss_test: 0.005524
time: 0.3050680160522461
time: 2.4675514698028564
[1, 27201] loss_train: 0.005449, loss_test: 0.005523
time: 0.3016088008880615
time: 2.7085909843444824
[1, 27202] loss_train: 0.004683, loss_test: 0.005522
time: 0.28406286239624023
time: 2.658731698989868
[1, 27203] loss_train: 0.004580, loss_test: 0.005522
time: 0.2930731773376465
time: 3.0184712409973145
[1, 27204] loss_train: 0.007318, loss_test: 0.005520
time: 0.2970290184020996
time: 2.4535534381866455
[1, 27205] loss_train: 0.005263, loss_test: 0.005519
time: 0.25705766677856445
time: 2.6354339122772217
[1, 27206] loss_train: 0.006115, loss_test: 0.005518
time: 0.28406238555908203
time: 2.432563543319702
[1, 27207] loss_train: 0.005380, loss_test: 0.005517
time: 0.2630593776702881
time: 2.3924477100372314
[1, 27208] loss_train: 0.002616, loss_test: 0.005516
time: 0.2523949146270752
time: 2.414686441421509
[1, 27209] loss_train: 0.006624, loss_test: 0.005518
time: 0.2610585689544678
time: 2.622586250305176
[1, 27210] loss_train: 0.009204, loss_test: 0.005519
time: 0.2870640754699707
time: 2.3380537033081055
[1, 27211] loss_train: 0.005184, loss_test: 0.005521
time: 0.2550618648529053
time: 2.456202745437622
[1, 27212] loss_train: 0.015765, loss_test: 0.005523
time: 0.29807162284851074
time: 2.550874948501587
[1, 27213] loss_train: 0.009878, loss_test: 0.005528
time: 0.3140695095062256
time: 2.4665513038635254
[1, 27214] loss_train: 0.013689, loss_test: 0.005534
time: 0.303067684173584
time: 2.6475915908813477
[1, 27215] loss_train: 0.006800, loss_test: 0.005541
time: 0.2870643138885498
time: 2.6691339015960693
[1, 27216] loss_train: 0.011009, loss_test: 0.005548
time: 0.29387617111206055
time: 2.33052134513855
[1, 27217] loss_train: 0.005544, loss_test: 0.005549
time: 0.2470550537109375
time: 2.3735299110412598
[1, 27218] loss_train: 0.007804, loss_test: 0.005545
time: 0.2710604667663574
time: 2.4555490016937256
[1, 27219] loss_train: 0.001749, loss_test: 0.005536
time: 0.25705838203430176
time: 2.2925124168395996
[1, 27220] loss_train: 0.007826, loss_test: 0.005527
time: 0.26806092262268066
time: 2.5635719299316406
[1, 27221] loss_train: 0.006847, loss_test: 0.005518
time: 0.2450547218322754
time: 2.238506555557251
[1, 27222] loss_train: 0.001755, loss_test: 0.005511
time: 0.24605417251586914
time: 2.2535040378570557
[1, 27223] loss_train: 0.002550, loss_test: 0.005507
time: 0.25705814361572266
time: 2.2945127487182617
[1, 27224] loss_train: 0.009386, loss_test: 0.005508
time: 0.25905752182006836
time: 2.269510269165039
[1, 27225] loss_train: 0.007745, loss_test: 0.005511
time: 0.26605868339538574
time: 2.2865121364593506
[1, 27226] loss_train: 0.014690, loss_test: 0.005514
time: 0.26805877685546875
time: 2.244502544403076
[1, 27227] loss_train: 0.002703, loss_test: 0.005519
time: 0.2560582160949707
time: 2.2855119705200195
[1, 27228] loss_train: 0.009670, loss_test: 0.005522
time: 0.24405336380004883
time: 2.2475035190582275
[1, 27229] loss_train: 0.010652, loss_test: 0.005525
time: 0.2540566921234131
time: 2.2444684505462646
[1, 27230] loss_train: 0.003697, loss_test: 0.005529
time: 0.2710611820220947
time: 2.3165178298950195
[1, 27231] loss_train: 0.009175, loss_test: 0.005530
time: 0.280062198638916
time: 2.5863471031188965
[1, 27232] loss_train: 0.000881, loss_test: 0.005530
time: 0.2940654754638672
time: 2.4135396480560303
[1, 27233] loss_train: 0.003157, loss_test: 0.005532
time: 0.2740604877471924
time: 2.4840617179870605
[1, 27234] loss_train: 0.009336, loss_test: 0.005531
time: 0.2800617218017578
time: 2.620586395263672
[1, 27235] loss_train: 0.011282, loss_test: 0.005529
time: 0.267059326171875
time: 2.4555492401123047
[1, 27236] loss_train: 0.005197, loss_test: 0.005527
time: 0.2890639305114746
time: 2.550075054168701
[1, 27237] loss_train: 0.005461, loss_test: 0.005524
time: 0.2850642204284668
time: 2.433934450149536
[1, 27238] loss_train: 0.003261, loss_test: 0.005523
time: 0.28206491470336914
time: 2.5682008266448975
[1, 27239] loss_train: 0.003812, loss_test: 0.005523
time: 0.2820277214050293
time: 2.496161699295044
[1, 27240] loss_train: 0.005158, loss_test: 0.005525
time: 0.2890639305114746
time: 2.9076361656188965
[1, 27241] loss_train: 0.014035, loss_test: 0.005517
time: 0.27506256103515625
time: 2.469289541244507
[1, 27242] loss_train: 0.006473, loss_test: 0.005509
time: 0.2850637435913086
time: 2.5075604915618896
[1, 27243] loss_train: 0.008514, loss_test: 0.005504
time: 0.2830624580383301
time: 2.5400493144989014
[1, 27244] loss_train: 0.006021, loss_test: 0.005503
time: 0.28806638717651367
time: 2.8732810020446777
[1, 27245] loss_train: 0.008010, loss_test: 0.005505
time: 0.29706549644470215
time: 2.524202823638916
[1, 27246] loss_train: 0.010967, loss_test: 0.005510
time: 0.29137301445007324
time: 2.745614528656006
[1, 27247] loss_train: 0.007943, loss_test: 0.005519
time: 0.31006789207458496
time: 2.559884548187256
[1, 27248] loss_train: 0.007642, loss_test: 0.005528
time: 0.27706122398376465
time: 2.4170446395874023
[1, 27249] loss_train: 0.003144, loss_test: 0.005535
time: 0.3380751609802246
time: 2.9188425540924072
[1, 27250] loss_train: 0.009048, loss_test: 0.005538
time: 0.2980659008026123
time: 2.5415773391723633
[1, 27251] loss_train: 0.002856, loss_test: 0.005539
time: 0.3130645751953125
time: 2.7463629245758057
[1, 27252] loss_train: 0.007166, loss_test: 0.005536
time: 0.30806922912597656
time: 2.5089168548583984
[1, 27253] loss_train: 0.007827, loss_test: 0.005533
time: 0.2769351005554199
time: 2.880246877670288
[1, 27254] loss_train: 0.007083, loss_test: 0.005529
time: 0.29706716537475586
time: 2.568580150604248
[1, 27255] loss_train: 0.008531, loss_test: 0.005526
time: 0.3130621910095215
time: 2.46590256690979
[1, 27256] loss_train: 0.004999, loss_test: 0.005525
time: 0.27928781509399414
time: 2.66581654548645
[1, 27257] loss_train: 0.004068, loss_test: 0.005525
time: 0.28406357765197754
time: 2.46298885345459
[1, 27258] loss_train: 0.001673, loss_test: 0.005528
time: 0.2789762020111084
time: 2.5760395526885986
[1, 27259] loss_train: 0.002322, loss_test: 0.005533
time: 0.2829868793487549
time: 2.4919817447662354
[1, 27260] loss_train: 0.002517, loss_test: 0.005540
time: 0.2999603748321533
time: 2.561011791229248
[1, 27261] loss_train: 0.003559, loss_test: 0.005547
time: 0.29903316497802734
time: 2.4573769569396973
[1, 27262] loss_train: 0.005092, loss_test: 0.005554
time: 0.2470545768737793
time: 2.394535541534424
[1, 27263] loss_train: 0.009623, loss_test: 0.005554
time: 0.29506635665893555
time: 2.4415502548217773
[1, 27264] loss_train: 0.005550, loss_test: 0.005552
time: 0.24605488777160645
time: 2.773162603378296
[1, 27265] loss_train: 0.003849, loss_test: 0.005551
time: 0.2515599727630615
time: 2.344548225402832
[1, 27266] loss_train: 0.009988, loss_test: 0.005546
time: 0.29282212257385254
time: 2.421542167663574
[1, 27267] loss_train: 0.005687, loss_test: 0.005540
time: 0.2830662727355957
time: 2.3756589889526367
[1, 27268] loss_train: 0.001654, loss_test: 0.005538
time: 0.2779104709625244
time: 2.396092176437378
[1, 27269] loss_train: 0.009461, loss_test: 0.005529
time: 0.2809255123138428
time: 2.387962579727173
[1, 27270] loss_train: 0.001056, loss_test: 0.005523
time: 0.25905656814575195
time: 2.3045153617858887
[1, 27271] loss_train: 0.007560, loss_test: 0.005516
time: 0.31507015228271484
time: 2.4690563678741455
[1, 27272] loss_train: 0.004565, loss_test: 0.005510
time: 0.28606343269348145
time: 2.454054117202759
[1, 27273] loss_train: 0.004845, loss_test: 0.005507
time: 0.2870628833770752
time: 2.657376289367676
[1, 27274] loss_train: 0.000729, loss_test: 0.005505
time: 0.27906203269958496
time: 2.6387219429016113
[1, 27275] loss_train: 0.005534, loss_test: 0.005504
time: 0.27898740768432617
time: 2.514066219329834
[1, 27276] loss_train: 0.012590, loss_test: 0.005503
time: 0.28707027435302734
time: 2.514627456665039
[1, 27277] loss_train: 0.007822, loss_test: 0.005503
time: 0.28606367111206055
time: 2.476552963256836
[1, 27278] loss_train: 0.004639, loss_test: 0.005503
time: 0.2760605812072754
time: 2.284015417098999
[1, 27279] loss_train: 0.005383, loss_test: 0.005504
time: 0.24605441093444824
time: 2.254504680633545
[1, 27280] loss_train: 0.014543, loss_test: 0.005504
time: 0.25943946838378906
time: 2.243516683578491
[1, 27281] loss_train: 0.002394, loss_test: 0.005504
time: 0.2490553855895996
time: 2.2745141983032227
[1, 27282] loss_train: 0.003852, loss_test: 0.005505
time: 0.25005578994750977
time: 2.291022300720215
[1, 27283] loss_train: 0.004818, loss_test: 0.005507
time: 0.2580571174621582
time: 2.306516647338867
[1, 27284] loss_train: 0.008703, loss_test: 0.005508
time: 0.2529122829437256
time: 2.270369052886963
[1, 27285] loss_train: 0.003753, loss_test: 0.005509
time: 0.24805450439453125
time: 2.2895162105560303
[1, 27286] loss_train: 0.008456, loss_test: 0.005509
time: 0.2450542449951172
time: 2.234501838684082
[1, 27287] loss_train: 0.005274, loss_test: 0.005511
time: 0.24405431747436523
time: 2.244502067565918
[1, 27288] loss_train: 0.004886, loss_test: 0.005513
time: 0.2470545768737793
time: 2.2535252571105957
[1, 27289] loss_train: 0.002428, loss_test: 0.005517
time: 0.25505709648132324
time: 2.256559371948242
[1, 27290] loss_train: 0.004630, loss_test: 0.005518
time: 0.2580578327178955
time: 2.2578139305114746
[1, 27291] loss_train: 0.010355, loss_test: 0.005518
time: 0.2510552406311035
time: 2.259505271911621
[1, 27292] loss_train: 0.006173, loss_test: 0.005520
time: 0.2740616798400879
time: 2.349034547805786
[1, 27293] loss_train: 0.005495, loss_test: 0.005524
time: 0.25505661964416504
time: 2.3378093242645264
[1, 27294] loss_train: 0.004361, loss_test: 0.005531
time: 0.24805521965026855
time: 2.3506860733032227
[1, 27295] loss_train: 0.010116, loss_test: 0.005538
time: 0.24405384063720703
time: 2.3510286808013916
[1, 27296] loss_train: 0.004873, loss_test: 0.005543
time: 0.2470545768737793
time: 2.2820141315460205
[1, 27297] loss_train: 0.006015, loss_test: 0.005543
time: 0.24405384063720703
time: 2.2595090866088867
[1, 27298] loss_train: 0.004946, loss_test: 0.005545
time: 0.24805569648742676
time: 2.2795188426971436
[1, 27299] loss_train: 0.003511, loss_test: 0.005546
time: 0.24605560302734375
time: 2.2713382244110107
[1, 27300] loss_train: 0.002466, loss_test: 0.005549
time: 0.26405954360961914
time: 2.2612357139587402
[1, 27301] loss_train: 0.013629, loss_test: 0.005546
time: 0.24405455589294434
time: 2.3008522987365723
[1, 27302] loss_train: 0.005779, loss_test: 0.005540
time: 0.2490553855895996
time: 2.4658148288726807
[1, 27303] loss_train: 0.005782, loss_test: 0.005535
time: 0.3720836639404297
time: 2.6906015872955322
[1, 27304] loss_train: 0.005475, loss_test: 0.005530
time: 0.34107518196105957
time: 2.5145630836486816
[1, 27305] loss_train: 0.008795, loss_test: 0.005521
time: 0.3050715923309326
time: 2.397536277770996
[1, 27306] loss_train: 0.004384, loss_test: 0.005514
time: 0.256056547164917
time: 2.2595055103302
[1, 27307] loss_train: 0.004055, loss_test: 0.005507
time: 0.25905871391296387
time: 2.2705078125
[1, 27308] loss_train: 0.001568, loss_test: 0.005504
time: 0.2510557174682617
time: 2.2505033016204834
[1, 27309] loss_train: 0.010774, loss_test: 0.005501
time: 0.2470557689666748
time: 2.3005154132843018
[1, 27310] loss_train: 0.008301, loss_test: 0.005498
time: 0.2760612964630127
time: 2.44954776763916
[1, 27311] loss_train: 0.001761, loss_test: 0.005494
time: 0.2520561218261719
time: 2.25750470161438
[1, 27312] loss_train: 0.002785, loss_test: 0.005489
time: 0.25505709648132324
time: 2.2975950241088867
[1, 27313] loss_train: 0.006858, loss_test: 0.005484
time: 0.2520601749420166
time: 2.263126850128174
[1, 27314] loss_train: 0.008300, loss_test: 0.005481
time: 0.25005459785461426
time: 2.256505250930786
[1, 27315] loss_train: 0.002874, loss_test: 0.005479
time: 0.2470548152923584
time: 2.278730630874634
[1, 27316] loss_train: 0.006070, loss_test: 0.005480
time: 0.25901007652282715
time: 2.3053998947143555
[1, 27317] loss_train: 0.012736, loss_test: 0.005481
time: 0.2470552921295166
time: 2.273010492324829
[1, 27318] loss_train: 0.000655, loss_test: 0.005483
time: 0.24605512619018555
time: 2.4155502319335938
[1, 27319] loss_train: 0.012003, loss_test: 0.005484
time: 0.26105785369873047
time: 2.298020362854004
[1, 27320] loss_train: 0.012885, loss_test: 0.005481
time: 0.26805973052978516
time: 2.3175292015075684
[1, 27321] loss_train: 0.002543, loss_test: 0.005481
time: 0.25205540657043457
time: 2.352034091949463
[1, 27322] loss_train: 0.009622, loss_test: 0.005481
time: 0.2510554790496826
time: 2.322538375854492
[1, 27323] loss_train: 0.005999, loss_test: 0.005481
time: 0.2475597858428955
time: 2.3463752269744873
[1, 27324] loss_train: 0.004732, loss_test: 0.005482
time: 0.2585577964782715
time: 2.301980495452881
[1, 27325] loss_train: 0.004156, loss_test: 0.005483
time: 0.254025936126709
time: 2.3037140369415283
[1, 27326] loss_train: 0.007411, loss_test: 0.005484
time: 0.256056547164917
time: 2.2665064334869385
[1, 27327] loss_train: 0.004884, loss_test: 0.005486
time: 0.25205564498901367
time: 2.256009340286255
[1, 27328] loss_train: 0.006502, loss_test: 0.005488
time: 0.24605393409729004
time: 2.270508050918579
[1, 27329] loss_train: 0.004564, loss_test: 0.005492
time: 0.2470545768737793
time: 2.253504753112793
[1, 27330] loss_train: 0.006135, loss_test: 0.005498
time: 0.2830634117126465
time: 2.3941686153411865
[1, 27331] loss_train: 0.011685, loss_test: 0.005500
time: 0.2600576877593994
time: 2.3180062770843506
[1, 27332] loss_train: 0.009176, loss_test: 0.005500
time: 0.2540559768676758
time: 2.370150089263916
[1, 27333] loss_train: 0.003147, loss_test: 0.005500
time: 0.2569572925567627
time: 2.27992844581604
[1, 27334] loss_train: 0.009870, loss_test: 0.005496
time: 0.2520565986633301
time: 2.386035203933716
[1, 27335] loss_train: 0.005693, loss_test: 0.005495
time: 0.24805426597595215
time: 2.2750136852264404
[1, 27336] loss_train: 0.002845, loss_test: 0.005495
time: 0.24605417251586914
time: 2.3015153408050537
[1, 27337] loss_train: 0.008984, loss_test: 0.005496
time: 0.2470552921295166
time: 2.2772908210754395
[1, 27338] loss_train: 0.009515, loss_test: 0.005497
time: 0.2536771297454834
time: 2.3483428955078125
[1, 27339] loss_train: 0.004517, loss_test: 0.005498
time: 0.2510554790496826
time: 2.3620381355285645
[1, 27340] loss_train: 0.002116, loss_test: 0.005499
time: 0.26888608932495117
time: 2.2549872398376465
[1, 27341] loss_train: 0.004397, loss_test: 0.005500
time: 0.26499438285827637
time: 2.3626129627227783
[1, 27342] loss_train: 0.008749, loss_test: 0.005501
time: 0.25705718994140625
time: 2.372530221939087
[1, 27343] loss_train: 0.001999, loss_test: 0.005499
time: 0.25705766677856445
time: 2.321537971496582
[1, 27344] loss_train: 0.005144, loss_test: 0.005497
time: 0.2490553855895996
time: 2.32051944732666
[1, 27345] loss_train: 0.009135, loss_test: 0.005496
time: 0.24805521965026855
time: 2.322021961212158
[1, 27346] loss_train: 0.000548, loss_test: 0.005494
time: 0.25305676460266113
time: 2.4198060035705566
[1, 27347] loss_train: 0.006242, loss_test: 0.005494
time: 0.2490549087524414
time: 2.401167631149292
[1, 27348] loss_train: 0.005638, loss_test: 0.005494
time: 0.2490549087524414
time: 2.308403968811035
[1, 27349] loss_train: 0.002265, loss_test: 0.005495
time: 0.2600581645965576
time: 2.278921604156494
[1, 27350] loss_train: 0.014251, loss_test: 0.005495
time: 0.2630035877227783
time: 2.3324363231658936
[1, 27351] loss_train: 0.005856, loss_test: 0.005495
time: 0.2580571174621582
time: 2.268507719039917
[1, 27352] loss_train: 0.008260, loss_test: 0.005495
time: 0.2510552406311035
time: 2.2725112438201904
[1, 27353] loss_train: 0.005070, loss_test: 0.005498
time: 0.25905704498291016
time: 2.4235446453094482
[1, 27354] loss_train: 0.003794, loss_test: 0.005501
time: 0.27306175231933594
time: 2.360079288482666
[1, 27355] loss_train: 0.007674, loss_test: 0.005504
time: 0.25105762481689453
time: 2.508561372756958
[1, 27356] loss_train: 0.001792, loss_test: 0.005507
time: 0.25305628776550293
time: 2.23551869392395
[1, 27357] loss_train: 0.003218, loss_test: 0.005507
time: 0.24605488777160645
time: 2.2951271533966064
[1, 27358] loss_train: 0.003154, loss_test: 0.005510
time: 0.256056547164917
time: 2.349294424057007
[1, 27359] loss_train: 0.015041, loss_test: 0.005507
time: 0.3070685863494873
time: 2.4802684783935547
[1, 27360] loss_train: 0.007183, loss_test: 0.005504
time: 0.28106188774108887
time: 2.4755613803863525
[1, 27361] loss_train: 0.007262, loss_test: 0.005501
time: 0.3210723400115967
time: 2.3155171871185303
[1, 27362] loss_train: 0.006879, loss_test: 0.005498
time: 0.25705718994140625
time: 2.472276449203491
[1, 27363] loss_train: 0.001195, loss_test: 0.005497
time: 0.2720603942871094
time: 2.498558759689331
[1, 27364] loss_train: 0.006599, loss_test: 0.005492
time: 0.2850630283355713
time: 2.301102876663208
[1, 27365] loss_train: 0.012871, loss_test: 0.005490
time: 0.25670695304870605
time: 2.260472059249878
[1, 27366] loss_train: 0.005283, loss_test: 0.005488
time: 0.2560267448425293
time: 2.2869627475738525
[1, 27367] loss_train: 0.007833, loss_test: 0.005488
time: 0.2530379295349121
time: 2.3449747562408447
[1, 27368] loss_train: 0.001730, loss_test: 0.005487
time: 0.30106234550476074
time: 2.5117247104644775
[1, 27369] loss_train: 0.009026, loss_test: 0.005486
time: 0.2830626964569092
time: 2.507295608520508
[1, 27370] loss_train: 0.005611, loss_test: 0.005485
time: 0.27506113052368164
time: 2.4005372524261475
[1, 27371] loss_train: 0.006190, loss_test: 0.005487
time: 0.269059419631958
time: 2.375035285949707
[1, 27372] loss_train: 0.001809, loss_test: 0.005489
time: 0.27956485748291016
time: 2.3007640838623047
[1, 27373] loss_train: 0.004531, loss_test: 0.005490
time: 0.2580573558807373
time: 2.335703134536743
[1, 27374] loss_train: 0.003576, loss_test: 0.005491
time: 0.29170703887939453
time: 2.3935444355010986
[1, 27375] loss_train: 0.006344, loss_test: 0.005491
time: 0.25505638122558594
time: 2.3566293716430664
[1, 27376] loss_train: 0.003573, loss_test: 0.005490
time: 0.25211167335510254
time: 2.2856740951538086
[1, 27377] loss_train: 0.005600, loss_test: 0.005491
time: 0.25705909729003906
time: 2.3255198001861572
[1, 27378] loss_train: 0.005041, loss_test: 0.005493
time: 0.2487776279449463
time: 2.2669167518615723
[1, 27379] loss_train: 0.002695, loss_test: 0.005497
time: 0.25205564498901367
time: 2.317518949508667
[1, 27380] loss_train: 0.007541, loss_test: 0.005498
time: 0.26105737686157227
time: 2.384038209915161
[1, 27381] loss_train: 0.001644, loss_test: 0.005501
time: 0.2670586109161377
time: 2.7079079151153564
[1, 27382] loss_train: 0.000647, loss_test: 0.005505
time: 0.26651430130004883
time: 2.411069393157959
[1, 27383] loss_train: 0.007778, loss_test: 0.005515
time: 0.30806827545166016
time: 2.7473745346069336
[1, 27384] loss_train: 0.003982, loss_test: 0.005525
time: 0.2630589008331299
time: 2.4130442142486572
[1, 27385] loss_train: 0.014341, loss_test: 0.005528
time: 0.2600581645965576
time: 2.322521448135376
[1, 27386] loss_train: 0.003136, loss_test: 0.005532
time: 0.2470550537109375
time: 2.321406364440918
[1, 27387] loss_train: 0.008736, loss_test: 0.005530
time: 0.25505638122558594
time: 2.2566120624542236
[1, 27388] loss_train: 0.003887, loss_test: 0.005526
time: 0.25206756591796875
time: 2.328557252883911
[1, 27389] loss_train: 0.001312, loss_test: 0.005524
time: 0.2475571632385254
time: 2.2601609230041504
[1, 27390] loss_train: 0.006092, loss_test: 0.005521
time: 0.28406310081481934
time: 2.258009910583496
[1, 27391] loss_train: 0.003656, loss_test: 0.005518
time: 0.26805901527404785
time: 2.3420426845550537
[1, 27392] loss_train: 0.007840, loss_test: 0.005511
time: 0.2690603733062744
time: 2.4445464611053467
[1, 27393] loss_train: 0.007687, loss_test: 0.005504
time: 0.2620582580566406
time: 2.4555492401123047
[1, 27394] loss_train: 0.011761, loss_test: 0.005497
time: 0.2980663776397705
time: 2.731536865234375
[1, 27395] loss_train: 0.011405, loss_test: 0.005493
time: 0.25956201553344727
time: 2.4490585327148438
[1, 27396] loss_train: 0.007616, loss_test: 0.005490
time: 0.25705671310424805
time: 2.2545053958892822
[1, 27397] loss_train: 0.002625, loss_test: 0.005490
time: 0.2470545768737793
time: 2.2389187812805176
[1, 27398] loss_train: 0.006630, loss_test: 0.005491
time: 0.24677395820617676
time: 2.2499654293060303
[1, 27399] loss_train: 0.013593, loss_test: 0.005494
time: 0.25505709648132324
time: 2.237499713897705
[1, 27400] loss_train: 0.007583, loss_test: 0.005497
time: 0.25705671310424805
time: 2.276520252227783
[1, 27401] loss_train: 0.011126, loss_test: 0.005499
time: 0.2470552921295166
time: 2.23600435256958
[1, 27402] loss_train: 0.001396, loss_test: 0.005501
time: 0.24305438995361328
time: 2.2645063400268555
[1, 27403] loss_train: 0.004691, loss_test: 0.005502
time: 0.24605441093444824
time: 2.255012035369873
[1, 27404] loss_train: 0.010880, loss_test: 0.005505
time: 0.24605441093444824
time: 2.3060402870178223
[1, 27405] loss_train: 0.013500, loss_test: 0.005507
time: 0.24405336380004883
time: 2.4519433975219727
[1, 27406] loss_train: 0.015264, loss_test: 0.005509
time: 0.29106712341308594
time: 2.3523826599121094
[1, 27407] loss_train: 0.007657, loss_test: 0.005509
time: 0.3180701732635498
time: 2.281721353530884
[1, 27408] loss_train: 0.009926, loss_test: 0.005511
time: 0.2570195198059082
time: 2.2801337242126465
[1, 27409] loss_train: 0.005408, loss_test: 0.005512
time: 0.26805877685546875
time: 2.2808287143707275
[1, 27410] loss_train: 0.007632, loss_test: 0.005510
time: 0.3080012798309326
time: 2.257521629333496
[1, 27411] loss_train: 0.006877, loss_test: 0.005508
time: 0.24405431747436523
time: 2.2655131816864014
[1, 27412] loss_train: 0.001330, loss_test: 0.005506
time: 0.24305319786071777
time: 2.2605090141296387
[1, 27413] loss_train: 0.001710, loss_test: 0.005503
time: 0.24405384063720703
time: 2.2535042762756348
[1, 27414] loss_train: 0.004688, loss_test: 0.005501
time: 0.25305652618408203
time: 2.2525038719177246
[1, 27415] loss_train: 0.001361, loss_test: 0.005500
time: 0.24305415153503418
time: 2.2527337074279785
[1, 27416] loss_train: 0.003975, loss_test: 0.005502
time: 0.2470545768737793
time: 2.271592617034912
[1, 27417] loss_train: 0.013474, loss_test: 0.005503
time: 0.2450556755065918
time: 2.2355005741119385
[1, 27418] loss_train: 0.005905, loss_test: 0.005506
time: 0.25005578994750977
time: 2.2574596405029297
[1, 27419] loss_train: 0.003519, loss_test: 0.005512
time: 0.2450549602508545
time: 2.267507791519165
[1, 27420] loss_train: 0.004140, loss_test: 0.005520
time: 0.2670595645904541
time: 2.2755157947540283
[1, 27421] loss_train: 0.008600, loss_test: 0.005529
time: 0.25905752182006836
time: 2.273880958557129
[1, 27422] loss_train: 0.006273, loss_test: 0.005534
time: 0.2450559139251709
time: 2.2515039443969727
[1, 27423] loss_train: 0.007814, loss_test: 0.005529
time: 0.24405360221862793
time: 2.2759342193603516
[1, 27424] loss_train: 0.007221, loss_test: 0.005526
time: 0.24464774131774902
time: 2.326327085494995
[1, 27425] loss_train: 0.005125, loss_test: 0.005523
time: 0.26067161560058594
time: 2.3855342864990234
[1, 27426] loss_train: 0.006868, loss_test: 0.005521
time: 0.25005459785461426
time: 2.264967441558838
[1, 27427] loss_train: 0.014673, loss_test: 0.005513
time: 0.25055885314941406
time: 2.2750132083892822
[1, 27428] loss_train: 0.004784, loss_test: 0.005507
time: 0.24505400657653809
time: 2.221497058868408
[1, 27429] loss_train: 0.002616, loss_test: 0.005504
time: 0.25305652618408203
time: 2.275012969970703
[1, 27430] loss_train: 0.007205, loss_test: 0.005504
time: 0.27506184577941895
time: 2.2294981479644775
[1, 27431] loss_train: 0.005323, loss_test: 0.005514
time: 0.2890639305114746
time: 2.2675070762634277
[1, 27432] loss_train: 0.004759, loss_test: 0.005527
time: 0.254056453704834
time: 2.4774391651153564
[1, 27433] loss_train: 0.005727, loss_test: 0.005539
time: 0.27706122398376465
time: 2.297524929046631
[1, 27434] loss_train: 0.001449, loss_test: 0.005538
time: 0.38573527336120605
time: 2.435246229171753
[1, 27435] loss_train: 0.002206, loss_test: 0.005529
time: 0.29132962226867676
time: 2.31722092628479
[1, 27436] loss_train: 0.006138, loss_test: 0.005520
time: 0.25705623626708984
time: 2.324535846710205
[1, 27437] loss_train: 0.004587, loss_test: 0.005511
time: 0.29006433486938477
time: 2.4045443534851074
[1, 27438] loss_train: 0.009023, loss_test: 0.005506
time: 0.24205350875854492
time: 2.2655155658721924
[1, 27439] loss_train: 0.005961, loss_test: 0.005504
time: 0.2470543384552002
time: 2.2580080032348633
[1, 27440] loss_train: 0.001773, loss_test: 0.005505
time: 0.2560563087463379
time: 2.301814556121826
[1, 27441] loss_train: 0.001089, loss_test: 0.005509
time: 0.2600576877593994
time: 2.290675163269043
[1, 27442] loss_train: 0.010568, loss_test: 0.005508
time: 0.25905919075012207
time: 2.3065290451049805
[1, 27443] loss_train: 0.006729, loss_test: 0.005504
time: 0.25305891036987305
time: 2.251466989517212
[1, 27444] loss_train: 0.010230, loss_test: 0.005499
time: 0.24605536460876465
time: 2.2820136547088623
[1, 27445] loss_train: 0.010524, loss_test: 0.005496
time: 0.24605512619018555
time: 2.275508165359497
[1, 27446] loss_train: 0.004623, loss_test: 0.005495
time: 0.2470548152923584
time: 2.2655160427093506
[1, 27447] loss_train: 0.009108, loss_test: 0.005495
time: 0.2490549087524414
time: 2.279510021209717
[1, 27448] loss_train: 0.008917, loss_test: 0.005497
time: 0.2450542449951172
time: 2.2485156059265137
[1, 27449] loss_train: 0.005673, loss_test: 0.005501
time: 0.24805474281311035
time: 2.2904281616210938
[1, 27450] loss_train: 0.007535, loss_test: 0.005505
time: 0.26033473014831543
time: 2.2751002311706543
[1, 27451] loss_train: 0.008482, loss_test: 0.005512
time: 0.2529458999633789
time: 2.2669830322265625
[1, 27452] loss_train: 0.006225, loss_test: 0.005520
time: 0.24605488777160645
time: 2.255506753921509
[1, 27453] loss_train: 0.003522, loss_test: 0.005523
time: 0.2450542449951172
time: 2.2750132083892822
[1, 27454] loss_train: 0.006602, loss_test: 0.005522
time: 0.24805498123168945
time: 2.269507646560669
[1, 27455] loss_train: 0.010745, loss_test: 0.005520
time: 0.24605560302734375
time: 2.2665066719055176
[1, 27456] loss_train: 0.005246, loss_test: 0.005516
time: 0.2525594234466553
time: 2.255504846572876
[1, 27457] loss_train: 0.003195, loss_test: 0.005510
time: 0.24805474281311035
time: 2.2755889892578125
[1, 27458] loss_train: 0.004447, loss_test: 0.005507
time: 0.2520561218261719
time: 2.3010504245758057
[1, 27459] loss_train: 0.009401, loss_test: 0.005507
time: 0.24805474281311035
time: 2.2924036979675293
[1, 27460] loss_train: 0.006265, loss_test: 0.005507
time: 0.26398396492004395
time: 2.2699100971221924
[1, 27461] loss_train: 0.004956, loss_test: 0.005510
time: 0.25452470779418945
time: 2.251314878463745
[1, 27462] loss_train: 0.016071, loss_test: 0.005508
time: 0.25005483627319336
time: 2.2350058555603027
[1, 27463] loss_train: 0.004350, loss_test: 0.005508
time: 0.24305343627929688
time: 2.2375006675720215
[1, 27464] loss_train: 0.005363, loss_test: 0.005510
time: 0.24805498123168945
time: 2.2615084648132324
[1, 27465] loss_train: 0.009599, loss_test: 0.005514
time: 0.2630579471588135
time: 2.287014961242676
[1, 27466] loss_train: 0.005582, loss_test: 0.005516
time: 0.24605512619018555
time: 2.2435014247894287
[1, 27467] loss_train: 0.013650, loss_test: 0.005528
time: 0.2450542449951172
time: 2.276855945587158
[1, 27468] loss_train: 0.006230, loss_test: 0.005541
time: 0.24805426597595215
time: 2.2655184268951416
[1, 27469] loss_train: 0.009017, loss_test: 0.005553
time: 0.2530558109283447
time: 2.266507148742676
[1, 27470] loss_train: 0.001284, loss_test: 0.005543
time: 0.26405811309814453
time: 2.2465949058532715
[1, 27471] loss_train: 0.004666, loss_test: 0.005523
time: 0.24405670166015625
time: 2.2430708408355713
[1, 27472] loss_train: 0.003579, loss_test: 0.005507
time: 0.24605512619018555
time: 2.263395309448242
[1, 27473] loss_train: 0.005055, loss_test: 0.005500
time: 0.25202322006225586
time: 2.2809693813323975
[1, 27474] loss_train: 0.005313, loss_test: 0.005499
time: 0.2440319061279297
time: 2.267972946166992
[1, 27475] loss_train: 0.003082, loss_test: 0.005506
time: 0.24602699279785156
time: 2.2679636478424072
[1, 27476] loss_train: 0.007420, loss_test: 0.005516
time: 0.2500483989715576
time: 2.2366342544555664
[1, 27477] loss_train: 0.004937, loss_test: 0.005527
time: 0.2510554790496826
time: 2.2520077228546143
[1, 27478] loss_train: 0.007917, loss_test: 0.005537
time: 0.24505400657653809
time: 2.2764813899993896
[1, 27479] loss_train: 0.004660, loss_test: 0.005546
time: 0.2520561218261719
time: 2.254528522491455
[1, 27480] loss_train: 0.008919, loss_test: 0.005553
time: 0.26105761528015137
time: 2.262009620666504
[1, 27481] loss_train: 0.005835, loss_test: 0.005557
time: 0.2510552406311035
time: 2.2715086936950684
[1, 27482] loss_train: 0.006170, loss_test: 0.005556
time: 0.2470550537109375
time: 2.2571818828582764
[1, 27483] loss_train: 0.006873, loss_test: 0.005557
time: 0.25505685806274414
time: 2.2691986560821533
[1, 27484] loss_train: 0.005491, loss_test: 0.005556
time: 0.24305367469787598
time: 2.2464630603790283
[1, 27485] loss_train: 0.007426, loss_test: 0.005556
time: 0.2540559768676758
time: 2.3430283069610596
[1, 27486] loss_train: 0.010854, loss_test: 0.005552
time: 0.25005507469177246
time: 2.245502471923828
[1, 27487] loss_train: 0.002924, loss_test: 0.005548
time: 0.2530558109283447
time: 2.2635066509246826
[1, 27488] loss_train: 0.003436, loss_test: 0.005539
time: 0.2435603141784668
time: 2.2550079822540283
[1, 27489] loss_train: 0.007015, loss_test: 0.005531
time: 0.2580568790435791
time: 2.3750357627868652
[1, 27490] loss_train: 0.010041, loss_test: 0.005514
time: 0.27906179428100586
time: 2.2911908626556396
[1, 27491] loss_train: 0.003064, loss_test: 0.005505
time: 0.3370795249938965
time: 2.2918131351470947
[1, 27492] loss_train: 0.013714, loss_test: 0.005499
time: 0.2514214515686035
time: 2.257983684539795
[1, 27493] loss_train: 0.005391, loss_test: 0.005496
time: 0.25003933906555176
time: 2.2619645595550537
[1, 27494] loss_train: 0.011889, loss_test: 0.005498
time: 0.24399805068969727
time: 2.238715648651123
[1, 27495] loss_train: 0.009055, loss_test: 0.005503
time: 0.2580575942993164
time: 2.251008987426758
[1, 27496] loss_train: 0.006581, loss_test: 0.005508
time: 0.2520558834075928
time: 2.2645070552825928
[1, 27497] loss_train: 0.007042, loss_test: 0.005513
time: 0.2470545768737793
time: 2.267509698867798
[1, 27498] loss_train: 0.012144, loss_test: 0.005518
time: 0.24405336380004883
time: 2.248502492904663
[1, 27499] loss_train: 0.007924, loss_test: 0.005523
time: 0.2560582160949707
time: 2.2695071697235107
[1, 27500] loss_train: 0.008103, loss_test: 0.005524
time: 0.2670588493347168
time: 2.279510736465454
[1, 27501] loss_train: 0.007067, loss_test: 0.005520
time: 0.24805450439453125
time: 2.282031536102295
[1, 27502] loss_train: 0.010503, loss_test: 0.005515
time: 0.2470550537109375
time: 2.236895799636841
[1, 27503] loss_train: 0.004169, loss_test: 0.005510
time: 0.2470555305480957
time: 2.2576515674591064
[1, 27504] loss_train: 0.005698, loss_test: 0.005507
time: 0.25705718994140625
time: 2.3296945095062256
[1, 27505] loss_train: 0.004715, loss_test: 0.005510
time: 0.24605464935302734
time: 2.3326079845428467
[1, 27506] loss_train: 0.001402, loss_test: 0.005515
time: 0.2540557384490967
time: 2.2935128211975098
[1, 27507] loss_train: 0.003497, loss_test: 0.005523
time: 0.25705695152282715
time: 2.334533214569092
[1, 27508] loss_train: 0.005486, loss_test: 0.005533
time: 0.2450547218322754
time: 2.2415003776550293
[1, 27509] loss_train: 0.011366, loss_test: 0.005541
time: 0.2470552921295166
time: 2.277508497238159
[1, 27510] loss_train: 0.007777, loss_test: 0.005549
time: 0.25705671310424805
time: 2.2465109825134277
[1, 27511] loss_train: 0.002198, loss_test: 0.005558
time: 0.2600576877593994
time: 2.238008499145508
[1, 27512] loss_train: 0.000791, loss_test: 0.005566
time: 0.2470555305480957
time: 2.2785089015960693
[1, 27513] loss_train: 0.004801, loss_test: 0.005571
time: 0.26405811309814453
time: 2.315023899078369
[1, 27514] loss_train: 0.003746, loss_test: 0.005574
time: 0.3120720386505127
time: 2.3343663215637207
[1, 27515] loss_train: 0.005688, loss_test: 0.005573
time: 0.27906155586242676
time: 2.275423526763916
[1, 27516] loss_train: 0.019249, loss_test: 0.005532
time: 0.2500612735748291
time: 2.2600386142730713
[1, 27517] loss_train: 0.011482, loss_test: 0.005509
time: 0.24605584144592285
time: 2.2535035610198975
[1, 27518] loss_train: 0.002823, loss_test: 0.005503
time: 0.24805450439453125
time: 2.2580106258392334
[1, 27519] loss_train: 0.001750, loss_test: 0.005506
time: 0.2530555725097656
time: 2.2755095958709717
[1, 27520] loss_train: 0.006804, loss_test: 0.005520
time: 0.25705647468566895
time: 2.242504119873047
[1, 27521] loss_train: 0.005307, loss_test: 0.005538
time: 0.24405407905578613
time: 2.2820141315460205
[1, 27522] loss_train: 0.007358, loss_test: 0.005551
time: 0.2540559768676758
time: 2.280510425567627
[1, 27523] loss_train: 0.006256, loss_test: 0.005556
time: 0.26605844497680664
time: 2.3495259284973145
[1, 27524] loss_train: 0.002161, loss_test: 0.005563
time: 0.3028090000152588
time: 2.295525550842285
[1, 27525] loss_train: 0.009725, loss_test: 0.005561
time: 0.25056004524230957
time: 2.273458957672119
[1, 27526] loss_train: 0.006158, loss_test: 0.005549
time: 0.25905704498291016
time: 2.309485912322998
[1, 27527] loss_train: 0.006242, loss_test: 0.005531
time: 0.24805521965026855
time: 2.2631430625915527
[1, 27528] loss_train: 0.010084, loss_test: 0.005519
time: 0.2490549087524414
time: 2.2625064849853516
[1, 27529] loss_train: 0.003101, loss_test: 0.005507
time: 0.2470543384552002
time: 2.233010768890381
[1, 27530] loss_train: 0.002945, loss_test: 0.005497
time: 0.26605844497680664
time: 2.2645068168640137
[1, 27531] loss_train: 0.008321, loss_test: 0.005492
time: 0.24505400657653809
time: 2.3135175704956055
[1, 27532] loss_train: 0.006313, loss_test: 0.005493
time: 0.29006457328796387
time: 2.287513017654419
[1, 27533] loss_train: 0.006152, loss_test: 0.005498
time: 0.2820620536804199
time: 2.317523956298828
[1, 27534] loss_train: 0.004041, loss_test: 0.005505
time: 0.27006030082702637
time: 2.3316304683685303
[1, 27535] loss_train: 0.012552, loss_test: 0.005512
time: 0.2604033946990967
time: 2.2845115661621094
[1, 27536] loss_train: 0.015238, loss_test: 0.005514
time: 0.24505400657653809
time: 2.25478458404541
[1, 27537] loss_train: 0.005278, loss_test: 0.005516
time: 0.24855923652648926
time: 2.2820141315460205
[1, 27538] loss_train: 0.005392, loss_test: 0.005518
time: 0.2800612449645996
time: 2.46805739402771
[1, 27539] loss_train: 0.007106, loss_test: 0.005517
time: 0.31357336044311523
time: 2.343524217605591
[1, 27540] loss_train: 0.002785, loss_test: 0.005516
time: 0.26556396484375
time: 2.325150728225708
[1, 27541] loss_train: 0.016690, loss_test: 0.005514
time: 0.2490541934967041
time: 2.2549073696136475
[1, 27542] loss_train: 0.010068, loss_test: 0.005513
time: 0.2510552406311035
time: 2.2937426567077637
[1, 27543] loss_train: 0.001727, loss_test: 0.005515
time: 0.2560596466064453
time: 2.275625705718994
[1, 27544] loss_train: 0.004129, loss_test: 0.005517
time: 0.26105785369873047
time: 2.4350481033325195
[1, 27545] loss_train: 0.009559, loss_test: 0.005517
time: 0.24805498123168945
time: 2.3875341415405273
[1, 27546] loss_train: 0.002383, loss_test: 0.005519
time: 0.25005555152893066
time: 2.29451322555542
[1, 27547] loss_train: 0.005463, loss_test: 0.005518
time: 0.262770414352417
time: 2.2505037784576416
[1, 27548] loss_train: 0.002253, loss_test: 0.005517
time: 0.2530558109283447
time: 2.2495038509368896
[1, 27549] loss_train: 0.006810, loss_test: 0.005509
time: 0.24558091163635254
time: 2.2560274600982666
[1, 27550] loss_train: 0.003696, loss_test: 0.005504
time: 0.2600574493408203
time: 2.256812334060669
[1, 27551] loss_train: 0.004035, loss_test: 0.005501
time: 0.2490551471710205
time: 2.243501901626587
[1, 27552] loss_train: 0.011912, loss_test: 0.005495
time: 0.25005578994750977
time: 2.2328546047210693
[1, 27553] loss_train: 0.003414, loss_test: 0.005493
time: 0.24605441093444824
time: 2.309856653213501
[1, 27554] loss_train: 0.007409, loss_test: 0.005491
time: 0.2446730136871338
time: 2.3510384559631348
[1, 27555] loss_train: 0.009225, loss_test: 0.005489
time: 0.2760612964630127
time: 2.3925352096557617
[1, 27556] loss_train: 0.007990, loss_test: 0.005488
time: 0.25005578994750977
time: 2.3005239963531494
[1, 27557] loss_train: 0.007116, loss_test: 0.005488
time: 0.2490549087524414
time: 2.344832420349121
[1, 27558] loss_train: 0.005199, loss_test: 0.005489
time: 0.2446579933166504
time: 2.293375253677368
[1, 27559] loss_train: 0.002150, loss_test: 0.005489
time: 0.2548696994781494
time: 2.291527032852173
[1, 27560] loss_train: 0.004145, loss_test: 0.005488
time: 0.26605844497680664
time: 2.4175186157226562
[1, 27561] loss_train: 0.007508, loss_test: 0.005488
time: 0.26428890228271484
time: 2.2775096893310547
[1, 27562] loss_train: 0.006880, loss_test: 0.005490
time: 0.3630812168121338
time: 2.4249768257141113
[1, 27563] loss_train: 0.006181, loss_test: 0.005491
time: 0.26806187629699707
time: 2.3815360069274902
[1, 27564] loss_train: 0.001568, loss_test: 0.005489
time: 0.28606390953063965
time: 2.4294703006744385
[1, 27565] loss_train: 0.004780, loss_test: 0.005489
time: 0.2620577812194824
time: 2.398153781890869
[1, 27566] loss_train: 0.002090, loss_test: 0.005490
time: 0.2650582790374756
time: 2.302924156188965
[1, 27567] loss_train: 0.011075, loss_test: 0.005491
time: 0.2540099620819092
time: 2.4708545207977295
[1, 27568] loss_train: 0.005375, loss_test: 0.005492
time: 0.3210716247558594
time: 2.6135847568511963
[1, 27569] loss_train: 0.007630, loss_test: 0.005493
time: 0.3310732841491699
time: 2.5515708923339844
[1, 27570] loss_train: 0.004931, loss_test: 0.005493
time: 0.26883792877197266
time: 2.3155181407928467
[1, 27571] loss_train: 0.004610, loss_test: 0.005494
time: 0.2540562152862549
time: 2.3290276527404785
[1, 27572] loss_train: 0.013002, loss_test: 0.005493
time: 0.25905871391296387
time: 2.3342511653900146
[1, 27573] loss_train: 0.006877, loss_test: 0.005493
time: 0.26273512840270996
time: 2.357377767562866
[1, 27574] loss_train: 0.001033, loss_test: 0.005491
time: 0.266965389251709
time: 2.296689510345459
[1, 27575] loss_train: 0.008747, loss_test: 0.005491
time: 0.24605417251586914
time: 2.3220386505126953
[1, 27576] loss_train: 0.005652, loss_test: 0.005491
time: 0.2850635051727295
time: 2.5350725650787354
[1, 27577] loss_train: 0.008389, loss_test: 0.005493
time: 0.251056432723999
time: 2.402539014816284
[1, 27578] loss_train: 0.003316, loss_test: 0.005496
time: 0.25505685806274414
time: 2.3240227699279785
[1, 27579] loss_train: 0.001538, loss_test: 0.005499
time: 0.2720603942871094
time: 2.3590304851531982
[1, 27580] loss_train: 0.005387, loss_test: 0.005500
time: 0.29006481170654297
time: 2.3508012294769287
[1, 27581] loss_train: 0.006734, loss_test: 0.005497
time: 0.25505590438842773
time: 2.3320226669311523
[1, 27582] loss_train: 0.007662, loss_test: 0.005496
time: 0.2496638298034668
time: 2.38254714012146
[1, 27583] loss_train: 0.007136, loss_test: 0.005495
time: 0.2588493824005127
time: 2.358102560043335
[1, 27584] loss_train: 0.009026, loss_test: 0.005499
time: 0.2580571174621582
time: 2.609583854675293
[1, 27585] loss_train: 0.010709, loss_test: 0.005507
time: 0.318070650100708
time: 2.372532844543457
[1, 27586] loss_train: 0.008047, loss_test: 0.005519
time: 0.2580568790435791
time: 2.2935116291046143
[1, 27587] loss_train: 0.010983, loss_test: 0.005532
time: 0.2630589008331299
time: 2.2985267639160156
[1, 27588] loss_train: 0.000614, loss_test: 0.005542
time: 0.2780647277832031
time: 2.3395276069641113
[1, 27589] loss_train: 0.003982, loss_test: 0.005547
time: 0.25505757331848145
time: 2.348733425140381
[1, 27590] loss_train: 0.005352, loss_test: 0.005550
time: 0.28806424140930176
time: 2.4139046669006348
[1, 27591] loss_train: 0.013751, loss_test: 0.005542
time: 0.2830662727355957
time: 2.4262120723724365
[1, 27592] loss_train: 0.002528, loss_test: 0.005533
time: 0.2670605182647705
time: 3.1047418117523193
[1, 27593] loss_train: 0.005828, loss_test: 0.005524
time: 0.5380525588989258
time: 3.499140501022339
[1, 27594] loss_train: 0.004384, loss_test: 0.005515
time: 0.5948927402496338
time: 3.3128981590270996
[1, 27595] loss_train: 0.014308, loss_test: 0.005510
time: 0.2800619602203369
time: 2.4315438270568848
[1, 27596] loss_train: 0.000483, loss_test: 0.005507
time: 0.28206324577331543
time: 2.4685513973236084
[1, 27597] loss_train: 0.003033, loss_test: 0.005503
time: 0.27006006240844727
time: 2.468554973602295
[1, 27598] loss_train: 0.006819, loss_test: 0.005500
time: 0.28490233421325684
time: 2.6040565967559814
[1, 27599] loss_train: 0.012608, loss_test: 0.005498
time: 0.26405858993530273
time: 2.3815579414367676
[1, 27600] loss_train: 0.005858, loss_test: 0.005498
time: 0.27006030082702637
time: 2.273508071899414
[1, 27601] loss_train: 0.014633, loss_test: 0.005500
time: 0.24605441093444824
time: 2.259010076522827
[1, 27602] loss_train: 0.006817, loss_test: 0.005505
time: 0.24455785751342773
time: 2.2951512336730957
[1, 27603] loss_train: 0.004433, loss_test: 0.005509
time: 0.2510559558868408
time: 2.325552225112915
[1, 27604] loss_train: 0.008852, loss_test: 0.005512
time: 0.26105809211730957
time: 2.3884873390197754
[1, 27605] loss_train: 0.005140, loss_test: 0.005514
time: 0.2670590877532959
time: 2.420541286468506
[1, 27606] loss_train: 0.009100, loss_test: 0.005512
time: 0.2890641689300537
time: 3.6644251346588135
[1, 27607] loss_train: 0.003899, loss_test: 0.005508
time: 0.6439392566680908
time: 3.4708495140075684
[1, 27608] loss_train: 0.001892, loss_test: 0.005503
time: 0.256056547164917
time: 2.327069044113159
[1, 27609] loss_train: 0.004710, loss_test: 0.005500
time: 0.25005555152893066
time: 2.4190080165863037
[1, 27610] loss_train: 0.016526, loss_test: 0.005496
time: 0.3200714588165283
time: 2.390550136566162
[1, 27611] loss_train: 0.008429, loss_test: 0.005496
time: 0.24859356880187988
time: 2.2920050621032715
[1, 27612] loss_train: 0.008074, loss_test: 0.005496
time: 0.26456403732299805
time: 2.3605284690856934
[1, 27613] loss_train: 0.005197, loss_test: 0.005498
time: 0.30106663703918457
time: 2.255506992340088
[1, 27614] loss_train: 0.004908, loss_test: 0.005501
time: 0.2510552406311035
time: 2.3005170822143555
[1, 27615] loss_train: 0.006427, loss_test: 0.005501
time: 0.36208009719848633
time: 2.274013042449951
[1, 27616] loss_train: 0.002792, loss_test: 0.005503
time: 0.2530553340911865
time: 2.294034004211426
[1, 27617] loss_train: 0.001801, loss_test: 0.005506
time: 0.256056547164917
time: 2.3209571838378906
[1, 27618] loss_train: 0.004911, loss_test: 0.005506
time: 0.2525606155395508
time: 2.2699382305145264
[1, 27619] loss_train: 0.006076, loss_test: 0.005505
time: 0.2580084800720215
time: 2.37154483795166
[1, 27620] loss_train: 0.005366, loss_test: 0.005505
time: 0.2760610580444336
time: 2.2990174293518066
[1, 27621] loss_train: 0.012922, loss_test: 0.005503
time: 0.2470550537109375
time: 2.2610089778900146
[1, 27622] loss_train: 0.008186, loss_test: 0.005503
time: 0.2620580196380615
time: 2.2600114345550537
[1, 27623] loss_train: 0.004045, loss_test: 0.005502
time: 0.24805450439453125
time: 2.248506546020508
[1, 27624] loss_train: 0.003023, loss_test: 0.005501
time: 0.2630581855773926
time: 2.3070781230926514
[1, 27625] loss_train: 0.005664, loss_test: 0.005500
time: 0.25005507469177246
time: 2.2625067234039307
[1, 27626] loss_train: 0.005805, loss_test: 0.005499
time: 0.2560563087463379
time: 2.2708852291107178
[1, 27627] loss_train: 0.006792, loss_test: 0.005498
time: 0.25301575660705566
time: 2.36201548576355
[1, 27628] loss_train: 0.007336, loss_test: 0.005498
time: 0.3079566955566406
time: 2.486992359161377
[1, 27629] loss_train: 0.013710, loss_test: 0.005499
time: 0.357072114944458
time: 2.3795318603515625
[1, 27630] loss_train: 0.003552, loss_test: 0.005501
time: 0.2630581855773926
time: 2.3911867141723633
[1, 27631] loss_train: 0.003079, loss_test: 0.005503
time: 0.3010671138763428
time: 2.4918692111968994
[1, 27632] loss_train: 0.006915, loss_test: 0.005505
time: 0.25670671463012695
time: 2.5761351585388184
[1, 27633] loss_train: 0.007055, loss_test: 0.005507
time: 0.588137149810791
time: 3.557694673538208
[1, 27634] loss_train: 0.002642, loss_test: 0.005510
time: 0.553138017654419
time: 2.881363868713379
[1, 27635] loss_train: 0.001560, loss_test: 0.005511
time: 0.2540626525878906
time: 2.41448974609375
[1, 27636] loss_train: 0.010050, loss_test: 0.005509
time: 0.3180708885192871
time: 2.506585121154785
[1, 27637] loss_train: 0.002357, loss_test: 0.005506
time: 0.3000664710998535
time: 2.4615635871887207
[1, 27638] loss_train: 0.003489, loss_test: 0.005506
time: 0.2740604877471924
time: 2.4189836978912354
[1, 27639] loss_train: 0.002206, loss_test: 0.005509
time: 0.27506160736083984
time: 2.3155176639556885
[1, 27640] loss_train: 0.005629, loss_test: 0.005513
time: 0.2820627689361572
time: 2.3710341453552246
[1, 27641] loss_train: 0.003889, loss_test: 0.005517
time: 0.2600576877593994
time: 2.3141074180603027
[1, 27642] loss_train: 0.004148, loss_test: 0.005522
time: 0.2530555725097656
time: 2.421060800552368
[1, 27643] loss_train: 0.005540, loss_test: 0.005521
time: 0.2580568790435791
time: 3.1115081310272217
[1, 27644] loss_train: 0.010042, loss_test: 0.005516
time: 0.4921383857727051
time: 3.6549131870269775
[1, 27645] loss_train: 0.004737, loss_test: 0.005512
time: 0.5114960670471191
time: 2.460697650909424
[1, 27646] loss_train: 0.000514, loss_test: 0.005511
time: 0.2780754566192627
time: 2.3830478191375732
[1, 27647] loss_train: 0.003611, loss_test: 0.005511
time: 0.2580568790435791
time: 2.4305429458618164
[1, 27648] loss_train: 0.003994, loss_test: 0.005509
time: 0.2710103988647461
time: 2.4145548343658447
[1, 27649] loss_train: 0.002051, loss_test: 0.005510
time: 0.2555849552154541
time: 2.3182458877563477
[1, 27650] loss_train: 0.007606, loss_test: 0.005510
time: 0.6111359596252441
time: 3.4851109981536865
[1, 27651] loss_train: 0.005928, loss_test: 0.005509
time: 0.5146446228027344
time: 3.0358448028564453
[1, 27652] loss_train: 0.007085, loss_test: 0.005508
time: 0.2658350467681885
time: 2.42454195022583
[1, 27653] loss_train: 0.006489, loss_test: 0.005506
time: 0.3050675392150879
time: 2.421006441116333
[1, 27654] loss_train: 0.013372, loss_test: 0.005504
time: 0.26799678802490234
time: 2.4026541709899902
[1, 27655] loss_train: 0.021493, loss_test: 0.005502
time: 0.2520561218261719
time: 2.3635287284851074
[1, 27656] loss_train: 0.010919, loss_test: 0.005507
time: 0.25005483627319336
time: 2.962662935256958
[1, 27657] loss_train: 0.003234, loss_test: 0.005516
time: 0.5396316051483154
time: 3.4784295558929443
[1, 27658] loss_train: 0.004557, loss_test: 0.005526
time: 0.5361418724060059
time: 2.4812023639678955
[1, 27659] loss_train: 0.007348, loss_test: 0.005528
time: 0.27706241607666016
time: 2.7376110553741455
[1, 27660] loss_train: 0.002436, loss_test: 0.005526
time: 0.6085443496704102
time: 3.3622286319732666
[1, 27661] loss_train: 0.005419, loss_test: 0.005524
time: 0.5531327724456787
time: 2.789860486984253
[1, 27662] loss_train: 0.004708, loss_test: 0.005520
time: 0.25905728340148926
time: 2.378035545349121
[1, 27663] loss_train: 0.006891, loss_test: 0.005517
time: 0.2680482864379883
time: 3.4930174350738525
[1, 27664] loss_train: 0.010869, loss_test: 0.005516
time: 0.4360015392303467
time: 4.310922145843506
[1, 27665] loss_train: 0.008461, loss_test: 0.005519
time: 0.3890416622161865
time: 2.70060396194458
[1, 27666] loss_train: 0.013181, loss_test: 0.005523
time: 0.29906654357910156
time: 2.3922805786132812
[1, 27667] loss_train: 0.005616, loss_test: 0.005527
time: 0.2690591812133789
time: 2.413543224334717
[1, 27668] loss_train: 0.001032, loss_test: 0.005533
time: 0.26405978202819824
time: 2.599581718444824
[1, 27669] loss_train: 0.005389, loss_test: 0.005530
time: 0.25905823707580566
time: 2.2765088081359863
[1, 27670] loss_train: 0.008527, loss_test: 0.005515
time: 0.2670588493347168
time: 2.3026845455169678
[1, 27671] loss_train: 0.007237, loss_test: 0.005500
time: 0.25005507469177246
time: 2.343076467514038
[1, 27672] loss_train: 0.010824, loss_test: 0.005490
time: 0.2760617733001709
time: 2.3002960681915283
[1, 27673] loss_train: 0.001536, loss_test: 0.005488
time: 0.24903273582458496
time: 2.2628185749053955
[1, 27674] loss_train: 0.003194, loss_test: 0.005492
time: 0.24512624740600586
time: 2.2743499279022217
[1, 27675] loss_train: 0.005725, loss_test: 0.005500
time: 0.24805474281311035
time: 2.274015188217163
[1, 27676] loss_train: 0.010349, loss_test: 0.005512
time: 0.25005578994750977
time: 2.2535035610198975
[1, 27677] loss_train: 0.006247, loss_test: 0.005521
time: 0.26105785369873047
time: 2.2855119705200195
[1, 27678] loss_train: 0.004371, loss_test: 0.005525
time: 0.3000669479370117
time: 2.310516357421875
[1, 27679] loss_train: 0.005677, loss_test: 0.005522
time: 0.25905704498291016
time: 2.2365007400512695
[1, 27680] loss_train: 0.011357, loss_test: 0.005518
time: 0.26456284523010254
time: 2.296374797821045
[1, 27681] loss_train: 0.008456, loss_test: 0.005513
time: 0.2630589008331299
time: 2.268203020095825
[1, 27682] loss_train: 0.010158, loss_test: 0.005507
time: 0.25057244300842285
time: 2.369926691055298
[1, 27683] loss_train: 0.006934, loss_test: 0.005500
time: 0.33707404136657715
time: 2.2610082626342773
[1, 27684] loss_train: 0.013762, loss_test: 0.005491
time: 0.2520568370819092
time: 2.4208037853240967
[1, 27685] loss_train: 0.005677, loss_test: 0.005486
time: 0.25556349754333496
time: 2.271836757659912
[1, 27686] loss_train: 0.001068, loss_test: 0.005485
time: 0.2490553855895996
time: 2.3875513076782227
[1, 27687] loss_train: 0.006428, loss_test: 0.005490
time: 0.25360655784606934
time: 2.347913980484009
[1, 27688] loss_train: 0.007513, loss_test: 0.005498
time: 0.2510709762573242
time: 2.30895733833313
[1, 27689] loss_train: 0.005093, loss_test: 0.005507
time: 0.24399971961975098
time: 2.2709732055664062
[1, 27690] loss_train: 0.001361, loss_test: 0.005520
time: 0.2600533962249756
time: 2.301398277282715
[1, 27691] loss_train: 0.003918, loss_test: 0.005531
time: 0.2820701599121094
time: 2.281520128250122
[1, 27692] loss_train: 0.005422, loss_test: 0.005537
time: 0.24905753135681152
time: 2.3205184936523438
[1, 27693] loss_train: 0.007464, loss_test: 0.005537
time: 0.24605560302734375
time: 2.2806990146636963
[1, 27694] loss_train: 0.005752, loss_test: 0.005534
time: 0.24805569648742676
time: 2.2765088081359863
[1, 27695] loss_train: 0.007359, loss_test: 0.005530
time: 0.2470555305480957
time: 2.2775089740753174
[1, 27696] loss_train: 0.004946, loss_test: 0.005525
time: 0.24305367469787598
time: 2.2778093814849854
[1, 27697] loss_train: 0.004510, loss_test: 0.005522
time: 0.25905752182006836
time: 2.299025297164917
[1, 27698] loss_train: 0.002918, loss_test: 0.005519
time: 0.25305962562561035
time: 2.266148805618286
[1, 27699] loss_train: 0.000851, loss_test: 0.005517
time: 0.24431753158569336
time: 2.284130573272705
[1, 27700] loss_train: 0.002693, loss_test: 0.005517
time: 0.2579166889190674
time: 2.291447401046753
[1, 27701] loss_train: 0.003009, loss_test: 0.005517
time: 0.2620577812194824
time: 2.2547106742858887
[1, 27702] loss_train: 0.002551, loss_test: 0.005518
time: 0.2560575008392334
time: 2.3150243759155273
[1, 27703] loss_train: 0.002756, loss_test: 0.005520
time: 0.24805688858032227
time: 2.3120219707489014
[1, 27704] loss_train: 0.006283, loss_test: 0.005520
time: 0.28507041931152344
time: 2.302091121673584
[1, 27705] loss_train: 0.002921, loss_test: 0.005521
time: 0.2492201328277588
time: 2.2719645500183105
[1, 27706] loss_train: 0.005195, loss_test: 0.005526
time: 0.25905656814575195
time: 2.2865240573883057
[1, 27707] loss_train: 0.003987, loss_test: 0.005530
time: 0.261066198348999
time: 2.2870705127716064
[1, 27708] loss_train: 0.005819, loss_test: 0.005537
time: 0.2470550537109375
time: 2.524564743041992
[1, 27709] loss_train: 0.009904, loss_test: 0.005538
time: 0.2510552406311035
time: 2.295522451400757
[1, 27710] loss_train: 0.005383, loss_test: 0.005536
time: 0.2620577812194824
time: 2.3010199069976807
[1, 27711] loss_train: 0.003988, loss_test: 0.005533
time: 0.2560570240020752
time: 2.2415010929107666
[1, 27712] loss_train: 0.004116, loss_test: 0.005531
time: 0.2530558109283447
time: 2.300941228866577
[1, 27713] loss_train: 0.011122, loss_test: 0.005524
time: 0.24608111381530762
time: 2.2661612033843994
[1, 27714] loss_train: 0.006416, loss_test: 0.005518
time: 0.24805593490600586
time: 2.2860755920410156
[1, 27715] loss_train: 0.001661, loss_test: 0.005516
time: 0.2490546703338623
time: 2.2792184352874756
[1, 27716] loss_train: 0.008107, loss_test: 0.005511
time: 0.25998759269714355
time: 2.279529571533203
[1, 27717] loss_train: 0.005254, loss_test: 0.005508
time: 0.24405455589294434
time: 2.268012285232544
[1, 27718] loss_train: 0.006530, loss_test: 0.005505
time: 0.2470552921295166
time: 2.2705326080322266
[1, 27719] loss_train: 0.004982, loss_test: 0.005503
time: 0.2470543384552002
time: 2.272508382797241
[1, 27720] loss_train: 0.009152, loss_test: 0.005499
time: 0.2670588493347168
time: 2.247662305831909
[1, 27721] loss_train: 0.007749, loss_test: 0.005499
time: 0.24205613136291504
time: 2.2902698516845703
[1, 27722] loss_train: 0.012466, loss_test: 0.005500
time: 0.320070743560791
time: 2.3434722423553467
[1, 27723] loss_train: 0.009623, loss_test: 0.005502
time: 0.25205564498901367
time: 2.2595410346984863
[1, 27724] loss_train: 0.005462, loss_test: 0.005506
time: 0.2610585689544678
time: 2.272250175476074
[1, 27725] loss_train: 0.002901, loss_test: 0.005509
time: 0.24405455589294434
time: 2.3415348529815674
[1, 27726] loss_train: 0.001930, loss_test: 0.005508
time: 0.24505329132080078
time: 2.2365007400512695
[1, 27727] loss_train: 0.012138, loss_test: 0.005510
time: 0.2450547218322754
time: 2.278510332107544
[1, 27728] loss_train: 0.007734, loss_test: 0.005512
time: 0.2470552921295166
time: 2.253997564315796
[1, 27729] loss_train: 0.007682, loss_test: 0.005514
time: 0.24656391143798828
time: 2.33504056930542
[1, 27730] loss_train: 0.000581, loss_test: 0.005514
time: 0.3670811653137207
time: 2.4655535221099854
[1, 27731] loss_train: 0.003182, loss_test: 0.005512
time: 0.26706385612487793
time: 2.3318030834198
[1, 27732] loss_train: 0.007907, loss_test: 0.005509
time: 0.24929094314575195
time: 2.3320257663726807
[1, 27733] loss_train: 0.009894, loss_test: 0.005508
time: 0.2510552406311035
time: 2.325993299484253
[1, 27734] loss_train: 0.007302, loss_test: 0.005505
time: 0.2760605812072754
time: 2.5085623264312744
[1, 27735] loss_train: 0.000993, loss_test: 0.005502
time: 0.30406808853149414
time: 2.7466135025024414
[1, 27736] loss_train: 0.009201, loss_test: 0.005499
time: 0.3120691776275635
time: 2.4000284671783447
[1, 27737] loss_train: 0.009281, loss_test: 0.005500
time: 0.25505948066711426
time: 2.606916904449463
[1, 27738] loss_train: 0.004310, loss_test: 0.005502
time: 0.25124073028564453
time: 2.338616132736206
[1, 27739] loss_train: 0.004025, loss_test: 0.005506
time: 0.2560563087463379
time: 2.3505358695983887
[1, 27740] loss_train: 0.011159, loss_test: 0.005509
time: 0.2960655689239502
time: 2.3595309257507324
[1, 27741] loss_train: 0.012766, loss_test: 0.005509
time: 0.25005507469177246
time: 2.298513889312744
[1, 27742] loss_train: 0.004298, loss_test: 0.005509
time: 0.28236985206604004
time: 2.2926738262176514
[1, 27743] loss_train: 0.001111, loss_test: 0.005510
time: 0.25005626678466797
time: 2.3260409832000732
[1, 27744] loss_train: 0.007586, loss_test: 0.005511
time: 0.2555382251739502
time: 2.306786060333252
[1, 27745] loss_train: 0.008187, loss_test: 0.005511
time: 0.2590365409851074
time: 2.319758892059326
[1, 27746] loss_train: 0.001519, loss_test: 0.005514
time: 0.25705933570861816
time: 2.4102535247802734
[1, 27747] loss_train: 0.003088, loss_test: 0.005519
time: 0.24805498123168945
time: 2.3175389766693115
[1, 27748] loss_train: 0.016025, loss_test: 0.005515
time: 0.2470541000366211
time: 2.267508029937744
[1, 27749] loss_train: 0.007293, loss_test: 0.005513
time: 0.24805426597595215
time: 2.2865118980407715
[1, 27750] loss_train: 0.007247, loss_test: 0.005512
time: 0.26105737686157227
time: 2.361598014831543
[1, 27751] loss_train: 0.001499, loss_test: 0.005512
time: 0.26805996894836426
time: 2.4538159370422363
[1, 27752] loss_train: 0.005011, loss_test: 0.005512
time: 0.27306151390075684
time: 2.4445464611053467
[1, 27753] loss_train: 0.003874, loss_test: 0.005512
time: 0.2710607051849365
time: 3.2396388053894043
[1, 27754] loss_train: 0.005373, loss_test: 0.005512
time: 0.5336306095123291
time: 4.295613527297974
[1, 27755] loss_train: 0.004745, loss_test: 0.005511
time: 0.5964341163635254
time: 2.973173141479492
[1, 27756] loss_train: 0.002454, loss_test: 0.005513
time: 0.24805474281311035
time: 2.292884111404419
[1, 27757] loss_train: 0.001932, loss_test: 0.005515
time: 0.2630581855773926
time: 2.5729310512542725
[1, 27758] loss_train: 0.004609, loss_test: 0.005518
time: 0.2530558109283447
time: 2.386063575744629
[1, 27759] loss_train: 0.005648, loss_test: 0.005521
time: 0.2580568790435791
time: 2.3792428970336914
[1, 27760] loss_train: 0.003220, loss_test: 0.005522
time: 0.2920651435852051
time: 2.3329918384552
[1, 27761] loss_train: 0.003694, loss_test: 0.005520
time: 0.31807446479797363
time: 2.453566074371338
[1, 27762] loss_train: 0.004180, loss_test: 0.005518
time: 0.3110687732696533
time: 2.493278980255127
[1, 27763] loss_train: 0.007011, loss_test: 0.005517
time: 0.26605868339538574
time: 2.3765318393707275
[1, 27764] loss_train: 0.009448, loss_test: 0.005515
time: 0.27005958557128906
time: 2.3129348754882812
[1, 27765] loss_train: 0.003796, loss_test: 0.005516
time: 0.25505685806274414
time: 2.2961337566375732
[1, 27766] loss_train: 0.012043, loss_test: 0.005509
time: 0.25005531311035156
time: 2.2618727684020996
[1, 27767] loss_train: 0.008880, loss_test: 0.005501
time: 0.25005531311035156
time: 2.277862071990967
[1, 27768] loss_train: 0.010628, loss_test: 0.005494
time: 0.2630579471588135
time: 2.267514228820801
[1, 27769] loss_train: 0.013906, loss_test: 0.005494
time: 0.2450549602508545
time: 2.333542585372925
[1, 27770] loss_train: 0.008399, loss_test: 0.005504
time: 0.3110685348510742
time: 2.3515264987945557
[1, 27771] loss_train: 0.003258, loss_test: 0.005517
time: 0.2600576877593994
time: 2.503107786178589
[1, 27772] loss_train: 0.012012, loss_test: 0.005531
time: 0.27506089210510254
time: 2.4206602573394775
[1, 27773] loss_train: 0.002850, loss_test: 0.005540
time: 0.252460241317749
time: 2.408888339996338
[1, 27774] loss_train: 0.001931, loss_test: 0.005540
time: 0.26605916023254395
time: 2.38980770111084
[1, 27775] loss_train: 0.004122, loss_test: 0.005532
time: 0.29306626319885254
time: 3.50113844871521
[1, 27776] loss_train: 0.005768, loss_test: 0.005520
time: 0.3601045608520508
time: 3.4037466049194336
[1, 27777] loss_train: 0.007862, loss_test: 0.005510
time: 0.28406357765197754
time: 2.3055198192596436
[1, 27778] loss_train: 0.005032, loss_test: 0.005497
time: 0.250913143157959
time: 2.2437384128570557
[1, 27779] loss_train: 0.005964, loss_test: 0.005487
time: 0.25505614280700684
time: 2.346026659011841
[1, 27780] loss_train: 0.003677, loss_test: 0.005480
time: 0.27794671058654785
time: 2.324831962585449
[1, 27781] loss_train: 0.005558, loss_test: 0.005480
time: 0.24917888641357422
time: 2.2440006732940674
[1, 27782] loss_train: 0.008728, loss_test: 0.005482
time: 0.24999403953552246
time: 2.2731568813323975
[1, 27783] loss_train: 0.005331, loss_test: 0.005485
time: 0.31857728958129883
time: 2.3770358562469482
[1, 27784] loss_train: 0.011133, loss_test: 0.005488
time: 0.26405882835388184
time: 2.9586007595062256
[1, 27785] loss_train: 0.002633, loss_test: 0.005489
time: 0.5041122436523438
time: 3.3546812534332275
[1, 27786] loss_train: 0.012948, loss_test: 0.005490
time: 0.46810388565063477
time: 3.6965131759643555
[1, 27787] loss_train: 0.010857, loss_test: 0.005491
time: 0.3870725631713867
time: 3.386043071746826
[1, 27788] loss_train: 0.004428, loss_test: 0.005493
time: 0.41942906379699707
time: 3.534048557281494
[1, 27789] loss_train: 0.005834, loss_test: 0.005495
time: 0.6211380958557129
time: 3.758878469467163
[1, 27790] loss_train: 0.006970, loss_test: 0.005495
time: 0.6171362400054932
time: 3.582777261734009
[1, 27791] loss_train: 0.003869, loss_test: 0.005494
time: 0.4710273742675781
time: 3.48773455619812
[1, 27792] loss_train: 0.006505, loss_test: 0.005493
time: 0.4521000385284424
time: 3.5563225746154785
[1, 27793] loss_train: 0.002102, loss_test: 0.005491
time: 0.39046549797058105
time: 3.3354744911193848
[1, 27794] loss_train: 0.001632, loss_test: 0.005489
time: 0.5731234550476074
time: 3.6201467514038086
[1, 27795] loss_train: 0.005653, loss_test: 0.005486
time: 0.5096256732940674
time: 3.4398772716522217
[1, 27796] loss_train: 0.004125, loss_test: 0.005484
time: 0.510653018951416
time: 3.4323887825012207
[1, 27797] loss_train: 0.009564, loss_test: 0.005483
time: 0.4439849853515625
time: 3.53613543510437
[1, 27798] loss_train: 0.003196, loss_test: 0.005484
time: 0.37308287620544434
time: 3.3203234672546387
[1, 27799] loss_train: 0.004487, loss_test: 0.005486
time: 0.5762810707092285
time: 3.64578914642334
[1, 27800] loss_train: 0.003995, loss_test: 0.005492
time: 0.5280570983886719
time: 3.404301166534424
[1, 27801] loss_train: 0.003826, loss_test: 0.005500
time: 0.5491223335266113
time: 3.5016376972198486
[1, 27802] loss_train: 0.002788, loss_test: 0.005511
time: 0.46703505516052246
time: 3.660623550415039
[1, 27803] loss_train: 0.005913, loss_test: 0.005522
time: 0.4231381416320801
time: 3.848813533782959
[1, 27804] loss_train: 0.010385, loss_test: 0.005530
time: 0.5987956523895264
time: 3.6000301837921143
[1, 27805] loss_train: 0.003616, loss_test: 0.005536
time: 0.5281167030334473
time: 3.5539677143096924
[1, 27806] loss_train: 0.002940, loss_test: 0.005544
time: 0.6816093921661377
time: 3.5905239582061768
[1, 27807] loss_train: 0.008674, loss_test: 0.005535
time: 0.48010778427124023
time: 3.863548994064331
[1, 27808] loss_train: 0.010987, loss_test: 0.005520
time: 0.331068754196167
time: 3.3090052604675293
[1, 27809] loss_train: 0.000791, loss_test: 0.005513
time: 0.48810768127441406
time: 3.409727096557617
[1, 27810] loss_train: 0.002634, loss_test: 0.005512
time: 0.5581247806549072
time: 3.324336290359497
[1, 27811] loss_train: 0.006060, loss_test: 0.005514
time: 0.5476474761962891
time: 3.571012020111084
[1, 27812] loss_train: 0.001328, loss_test: 0.005519
time: 0.44309353828430176
time: 3.7080256938934326
[1, 27813] loss_train: 0.007750, loss_test: 0.005526
time: 0.5433981418609619
time: 3.518674373626709
[1, 27814] loss_train: 0.003994, loss_test: 0.005529
time: 0.49761271476745605
time: 3.629149913787842
[1, 27815] loss_train: 0.011032, loss_test: 0.005538
time: 0.3820838928222656
time: 3.3478705883026123
[1, 27816] loss_train: 0.004479, loss_test: 0.005543
time: 0.45410895347595215
time: 3.512331008911133
[1, 27817] loss_train: 0.006693, loss_test: 0.005549
time: 0.5371198654174805
time: 3.404608964920044
[1, 27818] loss_train: 0.006907, loss_test: 0.005548
time: 0.5489945411682129
time: 3.4209775924682617
[1, 27819] loss_train: 0.004352, loss_test: 0.005546
time: 0.5451169013977051
time: 3.6042776107788086
[1, 27820] loss_train: 0.009380, loss_test: 0.005538
time: 0.5376279354095459
time: 3.344900131225586
[1, 27821] loss_train: 0.011874, loss_test: 0.005531
time: 0.3670821189880371
time: 3.653092384338379
[1, 27822] loss_train: 0.001282, loss_test: 0.005519
time: 0.6017906665802002
time: 3.4103569984436035
[1, 27823] loss_train: 0.008464, loss_test: 0.005510
time: 0.5286784172058105
time: 3.768113136291504
[1, 27824] loss_train: 0.009808, loss_test: 0.005505
time: 0.5731234550476074
time: 3.5628817081451416
[1, 27825] loss_train: 0.003546, loss_test: 0.005501
time: 0.5068750381469727
time: 3.425039529800415
[1, 27826] loss_train: 0.009949, loss_test: 0.005499
time: 0.44260644912719727
time: 3.5683610439300537
[1, 27827] loss_train: 0.006240, loss_test: 0.005501
time: 0.48995065689086914
time: 3.4380533695220947
[1, 27828] loss_train: 0.004096, loss_test: 0.005504
time: 0.5281217098236084
time: 3.457021951675415
[1, 27829] loss_train: 0.007929, loss_test: 0.005508
time: 0.4951510429382324
time: 3.263733148574829
[1, 27830] loss_train: 0.009260, loss_test: 0.005512
time: 0.5772204399108887
time: 3.4382848739624023
[1, 27831] loss_train: 0.001576, loss_test: 0.005517
time: 0.4567272663116455
time: 3.341738224029541
[1, 27832] loss_train: 0.005940, loss_test: 0.005521
time: 0.5151150226593018
time: 3.36924147605896
[1, 27833] loss_train: 0.005779, loss_test: 0.005522
time: 0.39008665084838867
time: 3.6608195304870605
[1, 27834] loss_train: 0.001470, loss_test: 0.005522
time: 0.38808608055114746
time: 3.4963300228118896
[1, 27835] loss_train: 0.005411, loss_test: 0.005521
time: 0.5288074016571045
time: 3.761911630630493
[1, 27836] loss_train: 0.002355, loss_test: 0.005521
time: 0.47310543060302734
time: 3.390594244003296
[1, 27837] loss_train: 0.013393, loss_test: 0.005520
time: 0.5401222705841064
time: 3.4035022258758545
[1, 27838] loss_train: 0.005930, loss_test: 0.005520
time: 0.4921090602874756
time: 3.6370248794555664
[1, 27839] loss_train: 0.007177, loss_test: 0.005511
time: 0.5146820545196533
time: 3.1833548545837402
[1, 27840] loss_train: 0.001498, loss_test: 0.005501
time: 0.4340991973876953
time: 3.737131357192993
[1, 27841] loss_train: 0.001580, loss_test: 0.005497
time: 0.5671393871307373
time: 3.6087253093719482
[1, 27842] loss_train: 0.007189, loss_test: 0.005496
time: 0.3820962905883789
time: 3.7781317234039307
[1, 27843] loss_train: 0.008037, loss_test: 0.005496
time: 0.6631729602813721
time: 3.6947274208068848
[1, 27844] loss_train: 0.015872, loss_test: 0.005494
time: 0.6722288131713867
time: 3.520160436630249
[1, 27845] loss_train: 0.005510, loss_test: 0.005492
time: 0.45900559425354004
time: 3.5846915245056152
[1, 27846] loss_train: 0.009147, loss_test: 0.005492
time: 0.7052702903747559
time: 3.473814010620117
[1, 27847] loss_train: 0.009410, loss_test: 0.005491
time: 0.497211217880249
time: 3.545722246170044
[1, 27848] loss_train: 0.010935, loss_test: 0.005491
time: 0.3990800380706787
time: 3.347822427749634
[1, 27849] loss_train: 0.006485, loss_test: 0.005494
time: 0.42821264266967773
time: 3.563873291015625
[1, 27850] loss_train: 0.005058, loss_test: 0.005497
time: 0.6018903255462646
time: 3.5636422634124756
[1, 27851] loss_train: 0.002627, loss_test: 0.005499
time: 0.5371370315551758
time: 3.5264394283294678
[1, 27852] loss_train: 0.007792, loss_test: 0.005500
time: 0.46032142639160156
time: 4.14717960357666
[1, 27853] loss_train: 0.003869, loss_test: 0.005500
time: 0.6545321941375732
time: 4.704046726226807
[1, 27854] loss_train: 0.009639, loss_test: 0.005501
time: 0.5368468761444092
time: 5.376943111419678
[1, 27855] loss_train: 0.003991, loss_test: 0.005500
time: 0.5864262580871582
time: 4.547893762588501
[1, 27856] loss_train: 0.010273, loss_test: 0.005502
time: 0.677701473236084
time: 5.019998788833618
[1, 27857] loss_train: 0.004550, loss_test: 0.005503
time: 0.6719739437103271
time: 3.8663337230682373
[1, 27858] loss_train: 0.005232, loss_test: 0.005503
time: 0.7476527690887451
time: 4.816504716873169
[1, 27859] loss_train: 0.000936, loss_test: 0.005503
time: 0.5171146392822266
time: 3.6396350860595703
[1, 27860] loss_train: 0.011391, loss_test: 0.005508
time: 0.8448669910430908
time: 3.9264776706695557
[1, 27861] loss_train: 0.010363, loss_test: 0.005514
time: 0.5596332550048828
time: 3.4096293449401855
[1, 27862] loss_train: 0.008120, loss_test: 0.005521
time: 0.5681290626525879
time: 3.3917813301086426
[1, 27863] loss_train: 0.001737, loss_test: 0.005530
time: 0.38808631896972656
time: 3.550638198852539
[1, 27864] loss_train: 0.014806, loss_test: 0.005530
time: 0.2930729389190674
time: 3.344644069671631
[1, 27865] loss_train: 0.001750, loss_test: 0.005530
time: 0.5371191501617432
time: 3.549687623977661
[1, 27866] loss_train: 0.004569, loss_test: 0.005530
time: 0.509117841720581
time: 3.533316135406494
[1, 27867] loss_train: 0.005482, loss_test: 0.005529
time: 0.5286891460418701
time: 3.3308053016662598
[1, 27868] loss_train: 0.000861, loss_test: 0.005529
time: 0.48610877990722656
time: 3.4769608974456787
[1, 27869] loss_train: 0.004221, loss_test: 0.005528
time: 0.5091159343719482
time: 3.2941367626190186
[1, 27870] loss_train: 0.012240, loss_test: 0.005524
time: 0.5643680095672607
time: 3.625913619995117
[1, 27871] loss_train: 0.010769, loss_test: 0.005519
time: 0.40608930587768555
time: 3.1513915061950684
[1, 27872] loss_train: 0.002302, loss_test: 0.005514
time: 0.44410204887390137
time: 3.5438144207000732
[1, 27873] loss_train: 0.003501, loss_test: 0.005511
time: 0.30808115005493164
time: 3.314188241958618
[1, 27874] loss_train: 0.009531, loss_test: 0.005508
time: 0.4631617069244385
time: 3.546238422393799
[1, 27875] loss_train: 0.004387, loss_test: 0.005505
time: 0.6076300144195557
time: 3.6047585010528564
[1, 27876] loss_train: 0.004826, loss_test: 0.005505
time: 0.4974477291107178
time: 3.7255587577819824
[1, 27877] loss_train: 0.005567, loss_test: 0.005503
time: 0.529796838760376
time: 3.4274024963378906
[1, 27878] loss_train: 0.002548, loss_test: 0.005501
time: 0.4956483840942383
time: 3.2480521202087402
[1, 27879] loss_train: 0.006423, loss_test: 0.005497
time: 0.45910191535949707
time: 3.496108293533325
[1, 27880] loss_train: 0.004111, loss_test: 0.005493
time: 0.5320134162902832
time: 3.1407217979431152
[1, 27881] loss_train: 0.002264, loss_test: 0.005489
time: 0.44413089752197266
time: 3.618659496307373
[1, 27882] loss_train: 0.007574, loss_test: 0.005486
time: 0.307070255279541
time: 3.2588608264923096
[1, 27883] loss_train: 0.002028, loss_test: 0.005487
time: 0.4223344326019287
time: 3.561868190765381
[1, 27884] loss_train: 0.003576, loss_test: 0.005490
time: 0.6282446384429932
time: 3.3879988193511963
[1, 27885] loss_train: 0.004336, loss_test: 0.005497
time: 0.5571231842041016
time: 3.494147777557373
[1, 27886] loss_train: 0.008041, loss_test: 0.005504
time: 0.4686164855957031
time: 3.3112523555755615
[1, 27887] loss_train: 0.003526, loss_test: 0.005514
time: 0.5232369899749756
time: 3.312822103500366
[1, 27888] loss_train: 0.011760, loss_test: 0.005518
time: 0.44060707092285156
time: 3.6954596042633057
[1, 27889] loss_train: 0.004072, loss_test: 0.005520
time: 0.5276494026184082
time: 3.3469748497009277
[1, 27890] loss_train: 0.004033, loss_test: 0.005521
time: 0.5621466636657715
time: 3.664700984954834
[1, 27891] loss_train: 0.005922, loss_test: 0.005519
time: 0.541161060333252
time: 3.170358419418335
[1, 27892] loss_train: 0.015476, loss_test: 0.005508
time: 0.42233729362487793
time: 3.5324106216430664
[1, 27893] loss_train: 0.006681, loss_test: 0.005501
time: 0.2807738780975342
time: 3.3590612411499023
[1, 27894] loss_train: 0.008476, loss_test: 0.005497
time: 0.4818227291107178
time: 3.424198627471924
[1, 27895] loss_train: 0.004933, loss_test: 0.005495
time: 0.5831282138824463
time: 3.3169469833374023
[1, 27896] loss_train: 0.002740, loss_test: 0.005496
time: 0.5151050090789795
time: 3.4459927082061768
[1, 27897] loss_train: 0.010477, loss_test: 0.005498
time: 0.5361969470977783
time: 3.3326821327209473
[1, 27898] loss_train: 0.004538, loss_test: 0.005499
time: 0.5341198444366455
time: 3.140037775039673
[1, 27899] loss_train: 0.004859, loss_test: 0.005500
time: 0.4811077117919922
time: 3.1836743354797363
[1, 27900] loss_train: 0.007246, loss_test: 0.005499
time: 0.2710599899291992
time: 2.394880771636963
[1, 27901] loss_train: 0.003015, loss_test: 0.005497
time: 0.2490551471710205
time: 2.296525716781616
[1, 27902] loss_train: 0.001859, loss_test: 0.005497
time: 0.24805474281311035
time: 2.2725088596343994
[1, 27903] loss_train: 0.004290, loss_test: 0.005496
time: 0.296065092086792
time: 2.3810441493988037
[1, 27904] loss_train: 0.004556, loss_test: 0.005497
time: 0.2620573043823242
time: 2.326603412628174
[1, 27905] loss_train: 0.001917, loss_test: 0.005499
time: 0.24805498123168945
time: 2.3849096298217773
[1, 27906] loss_train: 0.006277, loss_test: 0.005501
time: 0.28806614875793457
time: 2.4701504707336426
[1, 27907] loss_train: 0.003277, loss_test: 0.005504
time: 0.2540562152862549
time: 2.628939151763916
[1, 27908] loss_train: 0.003876, loss_test: 0.005507
time: 0.5461416244506836
time: 3.810421943664551
[1, 27909] loss_train: 0.011234, loss_test: 0.005503
time: 0.559128999710083
time: 3.683875560760498
[1, 27910] loss_train: 0.007990, loss_test: 0.005499
time: 0.5973351001739502
time: 3.289215326309204
[1, 27911] loss_train: 0.003828, loss_test: 0.005497
time: 0.2720603942871094
time: 2.468721866607666
[1, 27912] loss_train: 0.006113, loss_test: 0.005497
time: 0.26105785369873047
time: 2.390037775039673
[1, 27913] loss_train: 0.004391, loss_test: 0.005499
time: 0.274061918258667
time: 2.4150569438934326
[1, 27914] loss_train: 0.000359, loss_test: 0.005500
time: 0.2890639305114746
time: 2.8646416664123535
[1, 27915] loss_train: 0.006166, loss_test: 0.005502
time: 0.5241386890411377
time: 3.7758922576904297
[1, 27916] loss_train: 0.007434, loss_test: 0.005503
time: 0.5681281089782715
time: 4.452034950256348
[1, 27917] loss_train: 0.006471, loss_test: 0.005505
time: 0.8071026802062988
time: 4.025906801223755
[1, 27918] loss_train: 0.010982, loss_test: 0.005508
time: 0.30006980895996094
time: 2.5465729236602783
[1, 27919] loss_train: 0.010463, loss_test: 0.005512
time: 0.2910645008087158
time: 2.4450554847717285
[1, 27920] loss_train: 0.007424, loss_test: 0.005517
time: 0.3490767478942871
time: 3.4168753623962402
[1, 27921] loss_train: 0.010864, loss_test: 0.005523
time: 0.8260419368743896
time: 5.316626787185669
[1, 27922] loss_train: 0.005611, loss_test: 0.005527
time: 0.8284163475036621
time: 5.225095987319946
[1, 27923] loss_train: 0.001973, loss_test: 0.005526
time: 0.6568295955657959
time: 4.182632207870483
[1, 27924] loss_train: 0.006499, loss_test: 0.005527
time: 0.27706146240234375
time: 2.370602607727051
[1, 27925] loss_train: 0.003398, loss_test: 0.005524
time: 0.2540566921234131
time: 2.468082904815674
[1, 27926] loss_train: 0.003229, loss_test: 0.005520
time: 0.3430764675140381
time: 4.166460275650024
[1, 27927] loss_train: 0.010051, loss_test: 0.005518
time: 0.6694278717041016
time: 5.252943515777588
[1, 27928] loss_train: 0.003908, loss_test: 0.005516
time: 0.5673563480377197
time: 4.5213463306427
[1, 27929] loss_train: 0.006745, loss_test: 0.005516
time: 0.8670179843902588
time: 3.2540500164031982
[1, 27930] loss_train: 0.002167, loss_test: 0.005515
time: 0.2903318405151367
time: 2.768631935119629
[1, 27931] loss_train: 0.010766, loss_test: 0.005516
time: 0.2532963752746582
time: 2.6615116596221924
[1, 27932] loss_train: 0.009526, loss_test: 0.005518
time: 0.38364410400390625
time: 2.4526541233062744
[1, 27933] loss_train: 0.009372, loss_test: 0.005517
time: 0.32107067108154297
time: 4.3609912395477295
[1, 27934] loss_train: 0.001627, loss_test: 0.005517
time: 0.9987461566925049
time: 4.69011664390564
[1, 27935] loss_train: 0.004307, loss_test: 0.005516
time: 0.9412093162536621
time: 4.942738771438599
[1, 27936] loss_train: 0.002293, loss_test: 0.005517
time: 0.6893272399902344
time: 3.587778329849243
[1, 27937] loss_train: 0.003252, loss_test: 0.005519
time: 0.28606295585632324
time: 2.5169854164123535
[1, 27938] loss_train: 0.008379, loss_test: 0.005518
time: 0.6411426067352295
time: 4.876387119293213
[1, 27939] loss_train: 0.004901, loss_test: 0.005518
time: 0.9253935813903809
time: 4.805074214935303
[1, 27940] loss_train: 0.001983, loss_test: 0.005519
time: 0.9332189559936523
time: 4.7815446853637695
[1, 27941] loss_train: 0.001494, loss_test: 0.005522
time: 0.7550549507141113
time: 2.651592969894409
[1, 27942] loss_train: 0.004112, loss_test: 0.005525
time: 0.2630610466003418
time: 3.6526577472686768
[1, 27943] loss_train: 0.004791, loss_test: 0.005528
time: 0.6439576148986816
time: 5.403288841247559
[1, 27944] loss_train: 0.005041, loss_test: 0.005532
time: 0.6839563846588135
time: 4.787261247634888
[1, 27945] loss_train: 0.010729, loss_test: 0.005532
time: 0.6269474029541016
time: 3.359813690185547
[1, 27946] loss_train: 0.003255, loss_test: 0.005532
time: 0.28416943550109863
time: 2.5003042221069336
[1, 27947] loss_train: 0.002406, loss_test: 0.005534
time: 0.29306507110595703
time: 3.0159735679626465
[1, 27948] loss_train: 0.007518, loss_test: 0.005535
time: 0.3690824508666992
time: 3.633105516433716
[1, 27949] loss_train: 0.004676, loss_test: 0.005535
time: 0.7356939315795898
time: 6.178981781005859
[1, 27950] loss_train: 0.004652, loss_test: 0.005533
time: 1.2921369075775146
time: 5.429166793823242
[1, 27951] loss_train: 0.002203, loss_test: 0.005533
time: 0.8040251731872559
time: 4.992377042770386
[1, 27952] loss_train: 0.007855, loss_test: 0.005531
time: 0.3290736675262451
time: 2.5950839519500732
[1, 27953] loss_train: 0.008767, loss_test: 0.005527
time: 0.30606818199157715
time: 3.0765204429626465
[1, 27954] loss_train: 0.014517, loss_test: 0.005520
time: 0.6501643657684326
time: 2.659604787826538
[1, 27955] loss_train: 0.014573, loss_test: 0.005512
time: 0.3410756587982178
time: 3.1199262142181396
[1, 27956] loss_train: 0.005678, loss_test: 0.005508
time: 0.5451762676239014
time: 4.037257671356201
[1, 27957] loss_train: 0.004670, loss_test: 0.005508
time: 0.4870624542236328
time: 4.24224591255188
[1, 27958] loss_train: 0.008280, loss_test: 0.005508
time: 1.0166847705841064
time: 4.698622703552246
[1, 27959] loss_train: 0.005185, loss_test: 0.005508
time: 0.29506516456604004
time: 2.8623883724212646
[1, 27960] loss_train: 0.004022, loss_test: 0.005508
time: 0.3030674457550049
time: 2.4695518016815186
[1, 27961] loss_train: 0.011371, loss_test: 0.005507
time: 0.3075737953186035
time: 2.7675647735595703
[1, 27962] loss_train: 0.011618, loss_test: 0.005506
time: 0.3310732841491699
time: 2.759122133255005
[1, 27963] loss_train: 0.006156, loss_test: 0.005504
time: 0.332073450088501
time: 2.749617099761963
[1, 27964] loss_train: 0.003778, loss_test: 0.005501
time: 0.32107043266296387
time: 2.708606004714966
[1, 27965] loss_train: 0.004890, loss_test: 0.005498
time: 0.3200714588165283
time: 2.62648344039917
[1, 27966] loss_train: 0.009081, loss_test: 0.005496
time: 0.27005910873413086
time: 2.259373664855957
[1, 27967] loss_train: 0.004056, loss_test: 0.005495
time: 0.2489628791809082
time: 2.331973075866699
[1, 27968] loss_train: 0.009317, loss_test: 0.005494
time: 0.24702954292297363
time: 2.3562021255493164
[1, 27969] loss_train: 0.003718, loss_test: 0.005495
time: 0.25905752182006836
time: 3.7788572311401367
[1, 27970] loss_train: 0.004159, loss_test: 0.005496
time: 0.5774445533752441
time: 3.744302988052368
[1, 27971] loss_train: 0.005154, loss_test: 0.005498
time: 0.5221154689788818
time: 3.7667007446289062
[1, 27972] loss_train: 0.007491, loss_test: 0.005500
time: 0.38083744049072266
time: 2.4454448223114014
[1, 27973] loss_train: 0.004394, loss_test: 0.005504
time: 0.24798965454101562
time: 2.3898916244506836
[1, 27974] loss_train: 0.006701, loss_test: 0.005506
time: 0.26607561111450195
time: 2.416797399520874
[1, 27975] loss_train: 0.006322, loss_test: 0.005503
time: 0.26105809211730957
time: 3.32820987701416
[1, 27976] loss_train: 0.003534, loss_test: 0.005500
time: 0.5699527263641357
time: 3.6582462787628174
[1, 27977] loss_train: 0.010659, loss_test: 0.005498
time: 0.5291693210601807
time: 6.386277437210083
[1, 27978] loss_train: 0.004803, loss_test: 0.005499
time: 0.8529584407806396
time: 4.3801538944244385
[1, 27979] loss_train: 0.005099, loss_test: 0.005499
time: 0.30500125885009766
time: 2.5327467918395996
[1, 27980] loss_train: 0.012934, loss_test: 0.005497
time: 0.30606794357299805
time: 2.519069194793701
[1, 27981] loss_train: 0.002708, loss_test: 0.005498
time: 0.2920646667480469
time: 2.568575143814087
[1, 27982] loss_train: 0.010087, loss_test: 0.005499
time: 0.2870635986328125
time: 2.6872878074645996
[1, 27983] loss_train: 0.002293, loss_test: 0.005499
time: 0.35788559913635254
time: 2.7028987407684326
[1, 27984] loss_train: 0.004676, loss_test: 0.005502
time: 0.28606319427490234
time: 2.3386590480804443
[1, 27985] loss_train: 0.007371, loss_test: 0.005504
time: 0.26805901527404785
time: 2.308518409729004
[1, 27986] loss_train: 0.006778, loss_test: 0.005505
time: 0.2531614303588867
time: 2.3144125938415527
[1, 27987] loss_train: 0.013380, loss_test: 0.005506
time: 0.2530555725097656
time: 2.3130221366882324
[1, 27988] loss_train: 0.003629, loss_test: 0.005508
time: 0.3270728588104248
time: 2.422541618347168
[1, 27989] loss_train: 0.004890, loss_test: 0.005511
time: 0.2980659008026123
time: 2.757303237915039
[1, 27990] loss_train: 0.001635, loss_test: 0.005513
time: 0.2796945571899414
time: 2.3928306102752686
[1, 27991] loss_train: 0.015156, loss_test: 0.005515
time: 0.25705647468566895
time: 2.2930171489715576
[1, 27992] loss_train: 0.001849, loss_test: 0.005516
time: 0.2490551471710205
time: 2.356527090072632
[1, 27993] loss_train: 0.009527, loss_test: 0.005516
time: 0.2470533847808838
time: 2.4230239391326904
[1, 27994] loss_train: 0.005516, loss_test: 0.005515
time: 0.2455599308013916
time: 2.2520153522491455
[1, 27995] loss_train: 0.003114, loss_test: 0.005515
time: 0.2475581169128418
time: 2.277726650238037
[1, 27996] loss_train: 0.002760, loss_test: 0.005518
time: 0.24805450439453125
time: 2.3611233234405518
[1, 27997] loss_train: 0.005212, loss_test: 0.005520
time: 0.24899721145629883
time: 2.3088748455047607
[1, 27998] loss_train: 0.002364, loss_test: 0.005525
time: 0.2540571689605713
time: 2.300093412399292
[1, 27999] loss_train: 0.005152, loss_test: 0.005531
time: 0.24405431747436523
time: 2.34163761138916
[1, 28000] loss_train: 0.008491, loss_test: 0.005532
time: 0.279071569442749
time: 2.3095169067382812
[1, 28001] loss_train: 0.010222, loss_test: 0.005529
time: 0.28705883026123047
time: 2.4966156482696533
[1, 28002] loss_train: 0.006618, loss_test: 0.005526
time: 0.28406286239624023
time: 2.4495041370391846
[1, 28003] loss_train: 0.005497, loss_test: 0.005523
time: 0.28106236457824707
time: 2.3470075130462646
[1, 28004] loss_train: 0.002652, loss_test: 0.005521
time: 0.2760612964630127
time: 2.460625648498535
[1, 28005] loss_train: 0.008510, loss_test: 0.005518
time: 0.28907012939453125
time: 2.359835624694824
[1, 28006] loss_train: 0.005290, loss_test: 0.005514
time: 0.292064905166626
time: 2.3340277671813965
[1, 28007] loss_train: 0.006551, loss_test: 0.005512
time: 0.30106639862060547
time: 2.4302029609680176
[1, 28008] loss_train: 0.004082, loss_test: 0.005513
time: 0.26405906677246094
time: 2.659620761871338
[1, 28009] loss_train: 0.012093, loss_test: 0.005516
time: 0.7184450626373291
time: 4.482128143310547
[1, 28010] loss_train: 0.004740, loss_test: 0.005520
time: 1.1895689964294434
time: 3.2139620780944824
[1, 28011] loss_train: 0.002799, loss_test: 0.005525
time: 0.26105785369873047
time: 2.342026948928833
[1, 28012] loss_train: 0.003534, loss_test: 0.005528
time: 0.2510559558868408
time: 2.2755091190338135
[1, 28013] loss_train: 0.000636, loss_test: 0.005528
time: 0.2540557384490967
time: 2.2895147800445557
[1, 28014] loss_train: 0.009317, loss_test: 0.005528
time: 0.29506516456604004
time: 2.4190452098846436
[1, 28015] loss_train: 0.005789, loss_test: 0.005528
time: 0.28806376457214355
time: 2.436913013458252
[1, 28016] loss_train: 0.007943, loss_test: 0.005529
time: 0.2920653820037842
time: 2.4499197006225586
[1, 28017] loss_train: 0.004990, loss_test: 0.005531
time: 0.27205991744995117
time: 2.4325621128082275
[1, 28018] loss_train: 0.004857, loss_test: 0.005535
time: 0.2766430377960205
time: 3.19677996635437
[1, 28019] loss_train: 0.002407, loss_test: 0.005536
time: 0.27306056022644043
time: 2.4003541469573975
[1, 28020] loss_train: 0.004425, loss_test: 0.005538
time: 0.279757022857666
time: 2.4047696590423584
[1, 28021] loss_train: 0.006239, loss_test: 0.005539
time: 0.2630584239959717
time: 3.440620183944702
[1, 28022] loss_train: 0.000678, loss_test: 0.005544
time: 0.44060611724853516
time: 3.8423845767974854
[1, 28023] loss_train: 0.005953, loss_test: 0.005549
time: 0.34607648849487305
time: 2.4960689544677734
[1, 28024] loss_train: 0.003094, loss_test: 0.005557
time: 0.2734379768371582
time: 2.900709867477417
[1, 28025] loss_train: 0.008038, loss_test: 0.005563
time: 0.5318374633789062
time: 3.487683057785034
[1, 28026] loss_train: 0.005196, loss_test: 0.005568
time: 0.791377067565918
time: 2.8310136795043945
[1, 28027] loss_train: 0.004349, loss_test: 0.005572
time: 0.25705718994140625
time: 3.1396331787109375
[1, 28028] loss_train: 0.003549, loss_test: 0.005577
time: 0.45710062980651855
time: 5.9830992221832275
[1, 28029] loss_train: 0.005897, loss_test: 0.005581
time: 0.7982611656188965
time: 4.000582695007324
[1, 28030] loss_train: 0.007627, loss_test: 0.005578
time: 0.6980850696563721
time: 4.468577146530151
[1, 28031] loss_train: 0.009606, loss_test: 0.005568
time: 0.639582633972168
time: 3.521979808807373
[1, 28032] loss_train: 0.003563, loss_test: 0.005558
time: 1.0799639225006104
time: 5.497899055480957
[1, 28033] loss_train: 0.003110, loss_test: 0.005552
time: 0.6796317100524902
time: 4.516691446304321
[1, 28034] loss_train: 0.010830, loss_test: 0.005540
time: 0.31891965866088867
time: 2.567568778991699
[1, 28035] loss_train: 0.004825, loss_test: 0.005532
time: 0.3160407543182373
time: 4.41519021987915
[1, 28036] loss_train: 0.010330, loss_test: 0.005525
time: 0.658421516418457
time: 5.180532693862915
[1, 28037] loss_train: 0.007997, loss_test: 0.005521
time: 0.3180809020996094
time: 3.5340776443481445
[1, 28038] loss_train: 0.006100, loss_test: 0.005524
time: 0.6681981086730957
time: 4.928563117980957
[1, 28039] loss_train: 0.006870, loss_test: 0.005535
time: 0.6518220901489258
time: 3.597182035446167
[1, 28040] loss_train: 0.009165, loss_test: 0.005552
time: 0.38408541679382324
time: 4.1396119594573975
[1, 28041] loss_train: 0.001638, loss_test: 0.005572
time: 1.0097384452819824
time: 4.701911926269531
[1, 28042] loss_train: 0.012107, loss_test: 0.005583
time: 0.34407615661621094
time: 3.8472485542297363
[1, 28043] loss_train: 0.003278, loss_test: 0.005579
time: 0.4410984516143799
time: 5.4808337688446045
[1, 28044] loss_train: 0.007149, loss_test: 0.005573
time: 0.39708805084228516
time: 3.1202383041381836
[1, 28045] loss_train: 0.007873, loss_test: 0.005556
time: 0.5971336364746094
time: 4.720332145690918
[1, 28046] loss_train: 0.006986, loss_test: 0.005540
time: 0.8507447242736816
time: 4.185801029205322
[1, 28047] loss_train: 0.005520, loss_test: 0.005527
time: 0.30206727981567383
time: 2.5656614303588867
[1, 28048] loss_train: 0.011681, loss_test: 0.005523
time: 0.25105929374694824
time: 2.2679567337036133
[1, 28049] loss_train: 0.000759, loss_test: 0.005525
time: 0.25005531311035156
time: 2.578587532043457
[1, 28050] loss_train: 0.013457, loss_test: 0.005536
time: 0.625138521194458
time: 3.5723929405212402
[1, 28051] loss_train: 0.005330, loss_test: 0.005548
time: 0.5401206016540527
time: 2.7169251441955566
[1, 28052] loss_train: 0.004828, loss_test: 0.005558
time: 0.2530558109283447
time: 2.4675521850585938
[1, 28053] loss_train: 0.008222, loss_test: 0.005546
time: 0.31306910514831543
time: 2.358527660369873
[1, 28054] loss_train: 0.001530, loss_test: 0.005535
time: 0.27306079864501953
time: 2.3834264278411865
[1, 28055] loss_train: 0.003997, loss_test: 0.005526
time: 0.25505638122558594
time: 2.322209119796753
[1, 28056] loss_train: 0.003199, loss_test: 0.005519
time: 0.25756049156188965
time: 2.2455127239227295
[1, 28057] loss_train: 0.010533, loss_test: 0.005515
time: 0.2470550537109375
time: 2.259868860244751
[1, 28058] loss_train: 0.005875, loss_test: 0.005513
time: 0.25505924224853516
time: 2.270507335662842
[1, 28059] loss_train: 0.004529, loss_test: 0.005513
time: 0.24205350875854492
time: 2.246715545654297
[1, 28060] loss_train: 0.007102, loss_test: 0.005512
time: 0.2673335075378418
time: 2.2322309017181396
[1, 28061] loss_train: 0.001312, loss_test: 0.005512
time: 0.2530558109283447
time: 2.2250142097473145
[1, 28062] loss_train: 0.001508, loss_test: 0.005514
time: 0.2580571174621582
time: 2.3100311756134033
[1, 28063] loss_train: 0.006867, loss_test: 0.005514
time: 0.25905704498291016
time: 2.4862077236175537
[1, 28064] loss_train: 0.016275, loss_test: 0.005511
time: 0.27159810066223145
time: 2.7230331897735596
[1, 28065] loss_train: 0.009003, loss_test: 0.005508
time: 0.2650589942932129
time: 2.30551815032959
[1, 28066] loss_train: 0.016199, loss_test: 0.005508
time: 0.2470543384552002
time: 2.2560081481933594
[1, 28067] loss_train: 0.002519, loss_test: 0.005510
time: 0.2520561218261719
time: 2.2745182514190674
[1, 28068] loss_train: 0.004466, loss_test: 0.005514
time: 0.2490549087524414
time: 2.282153844833374
[1, 28069] loss_train: 0.002358, loss_test: 0.005518
time: 0.26005983352661133
time: 2.456467628479004
[1, 28070] loss_train: 0.003125, loss_test: 0.005520
time: 0.269059419631958
time: 2.3295207023620605
[1, 28071] loss_train: 0.011840, loss_test: 0.005521
time: 0.43506479263305664
time: 2.5675904750823975
[1, 28072] loss_train: 0.010500, loss_test: 0.005522
time: 0.25005531311035156
time: 2.3070194721221924
[1, 28073] loss_train: 0.006811, loss_test: 0.005522
time: 0.2490549087524414
time: 2.2745091915130615
[1, 28074] loss_train: 0.004306, loss_test: 0.005524
time: 0.25505638122558594
time: 2.359168529510498
[1, 28075] loss_train: 0.009558, loss_test: 0.005528
time: 0.34807705879211426
time: 2.305516004562378
[1, 28076] loss_train: 0.006143, loss_test: 0.005532
time: 0.27005934715270996
time: 2.374530792236328
[1, 28077] loss_train: 0.011868, loss_test: 0.005536
time: 0.24805474281311035
time: 2.2607598304748535
[1, 28078] loss_train: 0.009158, loss_test: 0.005538
time: 0.2470548152923584
time: 2.308272361755371
[1, 28079] loss_train: 0.002824, loss_test: 0.005532
time: 0.24405431747436523
time: 2.2798380851745605
[1, 28080] loss_train: 0.013375, loss_test: 0.005526
time: 0.2610208988189697
time: 2.2957894802093506
[1, 28081] loss_train: 0.008044, loss_test: 0.005525
time: 0.2490553855895996
time: 2.284512758255005
[1, 28082] loss_train: 0.007609, loss_test: 0.005532
time: 0.2560570240020752
time: 2.306515693664551
[1, 28083] loss_train: 0.003052, loss_test: 0.005544
time: 0.24505400657653809
time: 2.248505115509033
[1, 28084] loss_train: 0.006194, loss_test: 0.005556
time: 0.24405431747436523
time: 2.3425347805023193
[1, 28085] loss_train: 0.003508, loss_test: 0.005572
time: 0.2490556240081787
time: 2.3285319805145264
[1, 28086] loss_train: 0.008465, loss_test: 0.005586
time: 0.2600564956665039
time: 2.3210318088531494
[1, 28087] loss_train: 0.008375, loss_test: 0.005594
time: 0.2525596618652344
time: 2.3164420127868652
[1, 28088] loss_train: 0.003888, loss_test: 0.005595
time: 0.25505733489990234
time: 2.2721610069274902
[1, 28089] loss_train: 0.005283, loss_test: 0.005590
time: 0.24898266792297363
time: 2.3099658489227295
[1, 28090] loss_train: 0.002815, loss_test: 0.005588
time: 0.27501940727233887
time: 2.401500701904297
[1, 28091] loss_train: 0.007026, loss_test: 0.005574
time: 0.25506019592285156
time: 2.3005144596099854
[1, 28092] loss_train: 0.003289, loss_test: 0.005562
time: 0.25305604934692383
time: 2.306515693664551
[1, 28093] loss_train: 0.008437, loss_test: 0.005551
time: 0.24505376815795898
time: 2.309530019760132
[1, 28094] loss_train: 0.009797, loss_test: 0.005534
time: 0.24405431747436523
time: 2.284511089324951
[1, 28095] loss_train: 0.002490, loss_test: 0.005519
time: 0.2470543384552002
time: 2.3100204467773438
[1, 28096] loss_train: 0.001679, loss_test: 0.005511
time: 0.2490553855895996
time: 2.3028385639190674
[1, 28097] loss_train: 0.010663, loss_test: 0.005502
time: 0.24306130409240723
time: 2.2440478801727295
[1, 28098] loss_train: 0.013175, loss_test: 0.005496
time: 0.24745750427246094
time: 2.271657943725586
[1, 28099] loss_train: 0.004331, loss_test: 0.005493
time: 0.2469770908355713
time: 2.252985715866089
[1, 28100] loss_train: 0.003996, loss_test: 0.005493
time: 0.26126527786254883
time: 2.266507148742676
[1, 28101] loss_train: 0.007255, loss_test: 0.005493
time: 0.2470543384552002
time: 2.301311731338501
[1, 28102] loss_train: 0.010847, loss_test: 0.005494
time: 0.2510554790496826
time: 2.30551815032959
[1, 28103] loss_train: 0.005119, loss_test: 0.005494
time: 0.28406333923339844
time: 2.274508237838745
[1, 28104] loss_train: 0.003007, loss_test: 0.005491
time: 0.2583580017089844
time: 2.3015146255493164
[1, 28105] loss_train: 0.004280, loss_test: 0.005488
time: 0.26806044578552246
time: 2.247502565383911
[1, 28106] loss_train: 0.005610, loss_test: 0.005485
time: 0.25905704498291016
time: 2.2651937007904053
[1, 28107] loss_train: 0.002973, loss_test: 0.005482
time: 0.2683408260345459
time: 2.309525966644287
[1, 28108] loss_train: 0.003327, loss_test: 0.005482
time: 0.25506043434143066
time: 2.28904128074646
[1, 28109] loss_train: 0.014206, loss_test: 0.005482
time: 0.26105690002441406
time: 2.2809598445892334
[1, 28110] loss_train: 0.007914, loss_test: 0.005483
time: 0.26105761528015137
time: 2.3245317935943604
[1, 28111] loss_train: 0.001406, loss_test: 0.005486
time: 0.2670598030090332
time: 2.430145025253296
[1, 28112] loss_train: 0.010808, loss_test: 0.005488
time: 0.25505614280700684
time: 2.2650094032287598
[1, 28113] loss_train: 0.014016, loss_test: 0.005491
time: 0.25505638122558594
time: 2.3465123176574707
[1, 28114] loss_train: 0.003328, loss_test: 0.005496
time: 0.24805450439453125
time: 2.3644659519195557
[1, 28115] loss_train: 0.008929, loss_test: 0.005499
time: 0.2560441493988037
time: 2.450939178466797
[1, 28116] loss_train: 0.003269, loss_test: 0.005502
time: 0.2900660037994385
time: 2.466627359390259
[1, 28117] loss_train: 0.004430, loss_test: 0.005504
time: 0.27506136894226074
time: 2.30654239654541
[1, 28118] loss_train: 0.003294, loss_test: 0.005506
time: 0.29506492614746094
time: 2.3015284538269043
[1, 28119] loss_train: 0.007237, loss_test: 0.005505
time: 0.24514532089233398
time: 2.2715418338775635
[1, 28120] loss_train: 0.000889, loss_test: 0.005507
time: 0.27906227111816406
time: 2.2563910484313965
[1, 28121] loss_train: 0.012652, loss_test: 0.005500
time: 0.2485954761505127
time: 2.2535040378570557
[1, 28122] loss_train: 0.007753, loss_test: 0.005494
time: 0.2490551471710205
time: 2.266789436340332
[1, 28123] loss_train: 0.001855, loss_test: 0.005491
time: 0.24806475639343262
time: 2.2574257850646973
[1, 28124] loss_train: 0.003784, loss_test: 0.005490
time: 0.25305604934692383
time: 2.2806551456451416
[1, 28125] loss_train: 0.006199, loss_test: 0.005490
time: 0.2475588321685791
time: 2.2625060081481934
[1, 28126] loss_train: 0.006718, loss_test: 0.005490
time: 0.24605441093444824
time: 2.2385013103485107
[1, 28127] loss_train: 0.008668, loss_test: 0.005492
time: 0.24655818939208984
time: 2.2745094299316406
[1, 28128] loss_train: 0.008707, loss_test: 0.005493
time: 0.2490549087524414
time: 2.2565901279449463
[1, 28129] loss_train: 0.005066, loss_test: 0.005493
time: 0.2490551471710205
time: 2.3054399490356445
[1, 28130] loss_train: 0.007546, loss_test: 0.005493
time: 0.26642560958862305
time: 2.3128855228424072
[1, 28131] loss_train: 0.008868, loss_test: 0.005493
time: 0.2510535717010498
time: 2.53814435005188
[1, 28132] loss_train: 0.007252, loss_test: 0.005494
time: 0.289064884185791
time: 2.4250833988189697
[1, 28133] loss_train: 0.008201, loss_test: 0.005495
time: 0.25305604934692383
time: 2.2645065784454346
[1, 28134] loss_train: 0.006250, loss_test: 0.005496
time: 0.2540566921234131
time: 2.5516369342803955
[1, 28135] loss_train: 0.010373, loss_test: 0.005496
time: 0.25505638122558594
time: 2.2903127670288086
[1, 28136] loss_train: 0.003155, loss_test: 0.005495
time: 0.24605441093444824
time: 2.281524419784546
[1, 28137] loss_train: 0.011704, loss_test: 0.005492
time: 0.25305604934692383
time: 2.6773948669433594
[1, 28138] loss_train: 0.003053, loss_test: 0.005490
time: 0.267059326171875
time: 2.3655295372009277
[1, 28139] loss_train: 0.003045, loss_test: 0.005489
time: 0.27005982398986816
time: 2.6294984817504883
[1, 28140] loss_train: 0.006380, loss_test: 0.005489
time: 0.2670588493347168
time: 2.3255198001861572
[1, 28141] loss_train: 0.003355, loss_test: 0.005490
time: 0.2600576877593994
time: 2.2985165119171143
[1, 28142] loss_train: 0.006950, loss_test: 0.005491
time: 0.2520561218261719
time: 2.292513132095337
[1, 28143] loss_train: 0.003017, loss_test: 0.005493
time: 0.25205564498901367
time: 2.2985141277313232
[1, 28144] loss_train: 0.013210, loss_test: 0.005494
time: 0.25205540657043457
time: 2.3215200901031494
[1, 28145] loss_train: 0.004461, loss_test: 0.005497
time: 0.26805901527404785
time: 2.275015354156494
[1, 28146] loss_train: 0.004827, loss_test: 0.005500
time: 0.24805426597595215
time: 2.264026165008545
[1, 28147] loss_train: 0.008113, loss_test: 0.005503
time: 0.2580704689025879
time: 2.2427120208740234
[1, 28148] loss_train: 0.003845, loss_test: 0.005506
time: 0.24621176719665527
time: 2.2901742458343506
[1, 28149] loss_train: 0.005336, loss_test: 0.005505
time: 0.25005507469177246
time: 2.311523675918579
[1, 28150] loss_train: 0.005699, loss_test: 0.005504
time: 0.26793622970581055
time: 2.275244951248169
[1, 28151] loss_train: 0.001747, loss_test: 0.005506
time: 0.2690598964691162
time: 2.3515257835388184
[1, 28152] loss_train: 0.005895, loss_test: 0.005508
time: 0.3000667095184326
time: 2.5915799140930176
[1, 28153] loss_train: 0.001040, loss_test: 0.005508
time: 0.25705671310424805
time: 2.3525266647338867
[1, 28154] loss_train: 0.013708, loss_test: 0.005505
time: 0.2620584964752197
time: 2.2890279293060303
[1, 28155] loss_train: 0.005910, loss_test: 0.005508
time: 0.2490553855895996
time: 2.310020685195923
[1, 28156] loss_train: 0.005811, loss_test: 0.005518
time: 0.2540569305419922
time: 2.3510327339172363
[1, 28157] loss_train: 0.010436, loss_test: 0.005530
time: 0.2580571174621582
time: 2.278925895690918
[1, 28158] loss_train: 0.002659, loss_test: 0.005545
time: 0.24746060371398926
time: 2.2707581520080566
[1, 28159] loss_train: 0.005249, loss_test: 0.005553
time: 0.24805474281311035
time: 2.2730743885040283
[1, 28160] loss_train: 0.003238, loss_test: 0.005556
time: 0.2648489475250244
time: 2.317591905593872
[1, 28161] loss_train: 0.004641, loss_test: 0.005552
time: 0.2530555725097656
time: 2.283522844314575
[1, 28162] loss_train: 0.007316, loss_test: 0.005541
time: 0.2540569305419922
time: 2.3292758464813232
[1, 28163] loss_train: 0.007890, loss_test: 0.005524
time: 0.2540562152862549
time: 2.326328992843628
[1, 28164] loss_train: 0.004867, loss_test: 0.005513
time: 0.2600579261779785
time: 2.4117956161499023
[1, 28165] loss_train: 0.008758, loss_test: 0.005505
time: 0.27006006240844727
time: 2.3805317878723145
[1, 28166] loss_train: 0.006906, loss_test: 0.005501
time: 0.2540566921234131
time: 2.4124596118927
[1, 28167] loss_train: 0.004062, loss_test: 0.005501
time: 0.28106236457824707
time: 2.351525068283081
[1, 28168] loss_train: 0.004399, loss_test: 0.005506
time: 0.2630581855773926
time: 2.318519115447998
[1, 28169] loss_train: 0.000782, loss_test: 0.005516
time: 0.2690591812133789
time: 2.370532751083374
[1, 28170] loss_train: 0.003627, loss_test: 0.005526
time: 0.2850632667541504
time: 2.614234685897827
[1, 28171] loss_train: 0.004846, loss_test: 0.005537
time: 0.27906274795532227
time: 2.533379554748535
[1, 28172] loss_train: 0.005031, loss_test: 0.005548
time: 0.31506991386413574
time: 2.370051383972168
[1, 28173] loss_train: 0.002319, loss_test: 0.005561
time: 0.25705766677856445
time: 2.289337396621704
[1, 28174] loss_train: 0.001243, loss_test: 0.005577
time: 0.27306056022644043
time: 2.3351705074310303
[1, 28175] loss_train: 0.003694, loss_test: 0.005592
time: 0.27606201171875
time: 2.699725866317749
[1, 28176] loss_train: 0.008321, loss_test: 0.005597
time: 0.2830629348754883
time: 2.563107967376709
[1, 28177] loss_train: 0.004778, loss_test: 0.005598
time: 0.25804758071899414
time: 2.393664836883545
[1, 28178] loss_train: 0.006388, loss_test: 0.005593
time: 0.2720603942871094
time: 2.308018922805786
[1, 28179] loss_train: 0.005129, loss_test: 0.005585
time: 0.2540562152862549
time: 2.5030646324157715
[1, 28180] loss_train: 0.005112, loss_test: 0.005574
time: 0.38408398628234863
time: 2.4855566024780273
[1, 28181] loss_train: 0.003816, loss_test: 0.005560
time: 0.3650813102722168
time: 2.4200642108917236
[1, 28182] loss_train: 0.004416, loss_test: 0.005549
time: 0.2758903503417969
time: 2.398805618286133
[1, 28183] loss_train: 0.004436, loss_test: 0.005538
time: 0.26105833053588867
time: 2.351867914199829
[1, 28184] loss_train: 0.006029, loss_test: 0.005528
time: 0.2778639793395996
time: 2.3655662536621094
[1, 28185] loss_train: 0.006163, loss_test: 0.005519
time: 0.2520568370819092
time: 2.3230206966400146
[1, 28186] loss_train: 0.001797, loss_test: 0.005509
time: 0.2630584239959717
time: 2.343524694442749
[1, 28187] loss_train: 0.001459, loss_test: 0.005505
time: 0.25205564498901367
time: 2.389927864074707
[1, 28188] loss_train: 0.007350, loss_test: 0.005500
time: 0.24793171882629395
time: 2.346437454223633
[1, 28189] loss_train: 0.004167, loss_test: 0.005498
time: 0.3000662326812744
time: 3.0140037536621094
[1, 28190] loss_train: 0.005529, loss_test: 0.005498
time: 0.3089332580566406
time: 2.4718823432922363
[1, 28191] loss_train: 0.004310, loss_test: 0.005499
time: 0.25305628776550293
time: 2.567214250564575
[1, 28192] loss_train: 0.006016, loss_test: 0.005500
time: 0.2790653705596924
time: 2.3551957607269287
[1, 28193] loss_train: 0.004564, loss_test: 0.005501
time: 0.25905776023864746
time: 2.442127227783203
[1, 28194] loss_train: 0.004968, loss_test: 0.005503
time: 0.2630584239959717
time: 2.6585943698883057
[1, 28195] loss_train: 0.009895, loss_test: 0.005508
time: 0.2600574493408203
time: 2.404334783554077
[1, 28196] loss_train: 0.004729, loss_test: 0.005515
time: 0.3180699348449707
time: 2.5353333950042725
[1, 28197] loss_train: 0.000780, loss_test: 0.005520
time: 0.2650585174560547
time: 2.3495523929595947
[1, 28198] loss_train: 0.005066, loss_test: 0.005525
time: 0.27733826637268066
time: 2.350342273712158
[1, 28199] loss_train: 0.003806, loss_test: 0.005530
time: 0.25105738639831543
time: 2.3685312271118164
[1, 28200] loss_train: 0.004686, loss_test: 0.005533
time: 0.2720601558685303
time: 2.3644707202911377
[1, 28201] loss_train: 0.007811, loss_test: 0.005536
time: 0.278062105178833
time: 2.3829801082611084
[1, 28202] loss_train: 0.002956, loss_test: 0.005539
time: 0.2650597095489502
time: 2.370323657989502
[1, 28203] loss_train: 0.003228, loss_test: 0.005541
time: 0.25505566596984863
time: 2.337557792663574
[1, 28204] loss_train: 0.005295, loss_test: 0.005542
time: 0.28106236457824707
time: 2.3225512504577637
[1, 28205] loss_train: 0.009025, loss_test: 0.005535
time: 0.26703476905822754
time: 2.3307008743286133
[1, 28206] loss_train: 0.004998, loss_test: 0.005531
time: 0.2650585174560547
time: 2.3615286350250244
[1, 28207] loss_train: 0.004415, loss_test: 0.005527
time: 0.28406357765197754
time: 2.683614730834961
[1, 28208] loss_train: 0.002402, loss_test: 0.005523
time: 0.29506611824035645
time: 2.360527992248535
[1, 28209] loss_train: 0.007666, loss_test: 0.005516
time: 0.2670598030090332
time: 2.4868712425231934
[1, 28210] loss_train: 0.008540, loss_test: 0.005510
time: 0.3010671138763428
time: 2.6309263706207275
[1, 28211] loss_train: 0.014717, loss_test: 0.005504
time: 0.4068171977996826
time: 2.571054697036743
[1, 28212] loss_train: 0.004539, loss_test: 0.005502
time: 0.28106188774108887
time: 2.3915352821350098
[1, 28213] loss_train: 0.002751, loss_test: 0.005503
time: 0.27156543731689453
time: 2.6065540313720703
[1, 28214] loss_train: 0.006618, loss_test: 0.005502
time: 0.27006030082702637
time: 2.419323444366455
[1, 28215] loss_train: 0.004249, loss_test: 0.005500
time: 0.2820627689361572
time: 2.344527006149292
[1, 28216] loss_train: 0.009560, loss_test: 0.005498
